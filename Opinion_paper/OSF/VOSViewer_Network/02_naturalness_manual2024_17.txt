FN Clarivate Anlytics Web of Science
VR 1.0
PT C
AU Assmann, PF
    Dembling, S
    Nearey, TM
AF Assmann, Peter F
    Dembling, Sophie
    Nearey, Terrance M
TI Investigating the Uncanny Valley Effect for Prosody
SO INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING
LA English
DE [Uncanny Valley, Naturalness in Speech, Phonetics]
AB In natural speech, there is a moderate correlation between the fundamental frequency and formant frequencies across talkers. The present study used a high-quality vocoder to manipulate these properties and determine their contribution to perceived naturalness and voice gender. The stimuli were re-synthesized sentences spoken by two adult males and two adult females. Scale factors were chosen for each sentence and for each talker to produce frequency-shifted versions with a specified mean fundamental frequency (F0) ranging from 60 Hz to 450 Hz in 10 steps, paired with 10 steps in geometric mean formant frequencies ranging from 850 Hz to 2500 Hz. Listeners judged frequency-shifted sentences as more natural when F0 and formant frequencies followed the co-variation of F0 and formant frequencies in natural voices. Sentences with low F0s and low formant frequencies were perceived as masculine, while sentences with high F0 and high formant frequencies were assigned high ratings of femininity. Sentences with "mismatched" F0 and formant frequencies were assigned ratings near the midpoint of the range, indicating gender ambiguity. Frequency-shifted sentences derived from male talkers received consistently higher ratings of masculinity than those derived from females, while sentences from female talkers received higher ratings of femininity, even when assigned scale factors appropriate for the opposite gender, indicating that factors other than F0 and mean formant frequencies contribute to perceived gender.
CR 999
NR 999
SN 2308-457X
J9 INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING
JI INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING
PD 2006 SEPT
PY 2006
VL 1-5
IS 19
BP 889
EP 892
DI 10.21437/Interspeech.2006-297
DA 2024-01-09
ER

PT C
AU Baird, A
    Joergensen, S H
    Parada-Cabaleiro, E
    Hantke, S
    Cummins, N
    Schuller, B
AF Baird, Alice
    Joergensen, Stina Hasse
    Parada-Cabaleiro, Emilia
    Hantke, Simone
    Cummins, Nicholas
    Schuller, Bjoern
TI Perception of Paralinguistic Traits in Synthesized Voices
SO Proceedings of AM ’17, London, United Kingdom
LA English
DE Synthesized Voice, Humanisation of Synthesis, Human–Machine Interaction, Paralinguistic Traits, Personification Debate
AB Along with the rise of artificial intelligence and the internet-of-things, synthesized voices are now common in daily--life, providing us with guidance, assistance, and even companionship. From formant to concatenative synthesis, the synthesized voice continues to be defined by the same traits we prescribe to ourselves. When the recorded voice is synthesized, does our perception of its new machine embodiment change, and can we consider an alternative, more inclusive form? To begin evaluating the impact of aesthetic design, this study presents a first--step perception test to explore the paralinguistic traits of the synthesized voice. Using a corpus of 13 synthesized voices, constructed from acoustic concatenative speech synthesis, we assessed the response of 23 listeners from differing cultural backgrounds. To evaluate if perception shifts from the defined traits, we asked listeners to assigned traits of age, gender, accent origin, and human--likeness. Results present a difference in perception for age and human--likeness across voices, and a general agreement across listeners for both gender and accent origin. Connections found between age, gender and human--likeness call for further exploration into a more participatory and inclusive synthesized vocal identity.
CR 999
NR 999
J9 P AM ’17 London
JI P AM ’17 London
PD 2017 AUG
PY 2017
VL 999
IS 12
BP 23
EP 26
DI 10.1145/3123514.3123528
DA 2024-01-09
ER

PT C
AU Baird, A
    Parada-Cabaleiro, E
    Hantke, S
    Burkhardt, F
    Cummins, N
    Schuller, B
AF Baird, Alice
    Parada-Cabaleiro, Emilia
    Hantke, Simone
    Burkhardt, Felix
    Cummins, Nicholas
    Schuller, Bjoern
TI The Perception and Analysis of the Likeability and Human Likeness of Synthesized Speech
SO INTERSPEECH 2018
LA English
DE synthesized voices, human likeness, likeability
AB The synthesized voice has become an ever present aspect of daily life. Heard through our smart-devices and from public announcements, engineers continue in an endeavour to achieve naturalness in such voices. Yet, the degree to which these methods can produce likeable, human like voices, has not been fully evaluated. With recent advancements in synthetic speech technology suggesting that human like imitation is more obtainable, this study asked 25 listeners to evaluate both the likeability and human likeness of a corpus of 13 German male voices, produced via 5 synthesis approaches (from formant to hybrid unit selection, deep neural network systems), and 1 Human control. Results show that unlike visual artificially intelligent elements – as posed by the concept of the Uncanny Valley – likeability consistently improves along with human likeness for the synthesized voice, with recent methods achieving substantially closer results to human speech than older methods. A small scale acoustic analysis shows that the F0 of hybrid systems correlates less closely to human speech with a higher standard deviation for F0. This analysis suggests that limited variance in F0 is linked to a reduction in human likeness, resulting in lower likeability for conventional synthetic speech methods.
CR Mitchell WJ, 2011, I-PERCEPTION, V2, P10, DOI 10.1068/i0415
    Romportl Jan, 2014, Text, Speech and Dialogue. 17th International Conference, TSD 2014. Proceedings: LNCS 8655, P595, DOI 10.1007/978-3-319-10816-2_72
    Baird A, 2018, J AUDIO ENG SOC, V66, P277, DOI 10.17743/jaes.2018.0023
    Baird Alice, 2017, P 12 INT AUDIO MOSTL, DOI [10.1145/3123514.3123528, DOI 10.1145/3123514.3123528]
NR 4
SN 2308-457X
J9 INTERSPEECH
JI Interspeech 2018
PD 2018 SEPT 06
PY 2018
BP 2863
EP 2867
DI 10.21437/Interspeech.2018-1093
DA 2024-01-09
ER

PT [Placeholder]
AU Cabral, JP
    Cowan, BR
    Zibrek, K
    McDonnell, R
AF Cabral, João Paulo
    Cowan, Benjamin R
    Zibrek, Katja
    McDonnell, Rachel
TI The Influence of Synthetic Voice on the Evaluation of a Virtual Character
SO INTERSPEECH 2017
LA English
ID expressive speech, synthetic voice evaluation, avatars
AB Graphical realism and the naturalness of the voice used are important aspects to consider when designing a virtual agent or character. In this work, we evaluate how synthetic speech impacts people’s perceptions of a rendered virtual character. Using a controlled experiment, we focus on the role that speech, in particular voice expressiveness in the form of personality, has on the assessment of voice level and character level perceptions. We found that people rated a real human voice as more expressive, understandable and likeable than the expressive synthetic voice we developed. Contrary to our expectations, we found that the voices did not have a significant impact on the character level judgments; people in the voice conditions did not significantly vary on their ratings of appeal, credibility, human-likeness and voice matching the character. The implications this has for character design and how this compares with previous work are discussed.
CR Gong L, 2007, HUM COMMUN RES, V33, P163, DOI 10.1111/j.1468-2958.2007.00295.x
    Lee EJ, 2010, COMPUT HUM BEHAV, V26, P665, DOI 10.1016/j.chb.2010.01.003
    Mitchell WJ, 2011, I-PERCEPTION, V2, P10, DOI 10.1068/i0415
NR 3
J9 INTERSPEECH 2017
JI Interspeech 2017
PD 2017 AUG
PY 2017
VL 999
IS 2308-457X
BP 229
EP 233
DI 10.21437/Interspeech.2017-325
DA 2024-01-09
ER

PT J
AU Diel, A
    Lewis, M
AF Diel, Alexander
    Lewis, Michael
TI The vocal uncanny valley: Deviation from typical organic voices best explains uncanniness.
SO Computers in Human Behavior Reports
LA English
DE uncanny valley, voice processing, pathological voice, voice distortion, text-to-speech, deviation from familiarity
AB The uncanny valley describes the negative evaluation of near humanlike artificial entities. Previous research withsynthetic and real voices failed to find an uncanny valley of voices. This may have been due to an incompleteselection of stimuli. In Experiment 1 (n = 50), synthetic, normal, and deviating voices (distorted and patho-logical) were rated on uncanniness and human likeness and categorized as human or non-human. Results showeda non-monotonic function when the uncanniness was plotted against human likeness indicative of an uncannyvalley. However, the shape could be divided into two monotonic functions based on voice type (synthetic vsdeviating). Categorization ambiguity could not predict voice uncanniness but moderated the effect of realism onuncanniness. Experiment 2 (n = 35) found that perceived organicness, animacy, and mind attribution of voicessignificantly moderated the effect of realism on uncanniness. Results indicate a vocal uncanny valley driven bydeviations from typical human voices. While voices can fall into an uncanny valley, synthetic voices successfullyescape it. Finally, the results support the account that uncanniness is caused by deviations from familiar cate-gories, rather than categorical ambiguity or the misattribution of mind or animacy.
CR Baird A, 2018, J AUDIO ENG SOC, V66, P277, DOI 10.17743/jaes.2018.0023
    Baird A, 2018, INTERSPEECH, P2863, DOI 10.21437/Interspeech.2018-1093
    Kühne K, 2020, FRONT NEUROROBOTICS, V14, DOI 10.3389/fnbot.2020.593732
    Mitchell WJ, 2011, I-PERCEPTION, V2, P10, DOI 10.1068/i0415
    Romportl Jan, 2014, Text, Speech and Dialogue. 17th International Conference, TSD 2014. Proceedings: LNCS 8655, P595, DOI 10.1007/978-3-319-10816-2_72
    Schreibelmayr S, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.787499
NR 6
J9 Research Square
JI Research Square
PD 2024 MAY 14
PY 2024
VL 14
BP 1
EP 15
DI 10.1016/j.chbr.2024.100430
DA 2024-01-09
ER

PT C
AU Ehret, J
    Bönsch, A
    Aspöck, L
    Röhr, C T
    Baumann, S
    Grice, M
    Fels, J
    Kuhlen, T W
AF Ehret, Jonathan
    Bönsch, Andrea
    Aspöck, Lukas
    Röhr, Christine T
    Baumann, Stefan
    Grice, Martine
    Fels, Janina
    Kuhlen, Thorsten W
TI Do Prosody and Embodiment Influence the Perceived Naturalness of Conversational Agents’ Speech?
SO ACM Trans. Appl. Percept.
LA English
ID Computing methodologies, Phonology, morphology, Intelligent agents, Human-centered computing, User studies, Natural language interfaces,
DE Embodied conversational agents (ECAs), virtual acoustics, prosody, accentuation, speech, text-to-speech, audio, embodiment
AB For conversational agents’ speech, either all possible sentences have to be prerecorded by voice actors or the required utterances can be synthesized. While synthesizing speech is more flexible and economic in production, it also potentially reduces the perceived naturalness of the agents among others due to mistakes at various linguistic levels. In our article, we are interested in the impact of adequate and inadequate prosody, here particularly in terms of accent placement, on the perceived naturalness and aliveness of the agents. We compare (1) inadequate prosody, as generated by off-the-shelf text-to-speech (TTS) engines with synthetic output; (2) the same inadequate prosody imitated by trained human speakers; and (3) adequate prosody produced by those speakers. The speech was presented either as audio-only or by embodied, anthropomorphic agents, to investigate the potential masking effect by a simultaneous visual representation of those virtual agents. To this end, we conducted an online study with 40 participants listening to four different dialogues each presented in the three Speech levels and the two Embodiment levels. Results confirmed that adequate prosody in human speech is perceived as more natural (and the agents are perceived as more alive) than inadequate prosody in both human (2) and synthetic speech (1). Thus, it is not sufficient to just use a human voice for an agents’ speech to be perceived as natural—it is decisive whether the prosodic realisation is adequate or not. Furthermore, and surprisingly, we found no masking effect by speaker embodiment, since neither a human voice with inadequate prosody nor a synthetic voice was judged as more natural, when a virtual agent was visible compared to the audio-only condition. On the contrary, the human voice was even judged as less “alive” when accompanied by a virtual agent. In sum, our results emphasize, on the one hand, the importance of adequate prosody for perceived naturalness, especially in terms of accents being placed on important words in the phrase, while showing, on the other hand, that the embodiment of virtual agents plays a minor role in the naturalness ratings of voices.
CR Gong L, 2007, HUM COMMUN RES, V33, P163, DOI 10.1111/j.1468-2958.2007.00295.x
    Kühne K, 2020, FRONT NEUROROBOTICS, V14, DOI 10.3389/fnbot.2020.593732
    Seaborn K, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3386867
NR 3
J9 ACM T APPL PERCEPT
JI ACM T. Appl. Percept.
PD 2021 OCT
PY 2021
VL 18
IS 4
BP 1
EP 15
DI 10.1145/3486580
DA 2024-01-09
ER

PT [Placeholder]
AU Eyssel, F
    Kuchenbrandt, D 
    Bobinger, S
    de Ruiter, L
    Hegel, F
AF Eyssel, Friederike
    Kuchenbrandt, Dieta 
    Bobinger, Simon
    de Ruiter, Laura
    Hegel, Frank
TI 'If You Sound Like Me, You Must Be More Human’: On the Interplay of Robot and User Features on Human-Robot Acceptance and Anthropomorphism
SO HRI '12: Proceedings of the seventh annual ACM/IEEE international conference on Human-Robot Interaction
LA [Placeholder]
DE Human-Robot Interaction; Anthropomorphism; Gender Stereotypes; Social Robotics.
AB In an experiment we manipulated a robot’s voice in two ways: First, we varied robot gender; second, we equipped the robot with a human-like or a robot-like synthesized voice. Moreover, we took into account user gender and tested effects of these factors on human–robot acceptance, psychological closeness and psychological anthropomorphism. When participants formed an impression of a same-gender robot, the robot was perceived more positively. Participants also felt more psychological closeness to the same-gender robot. Similarly, the same-gender robot was anthropomorphized more strongly, but only when it utilized a human-like voice. Results indicate that a projection mechanism could underlie these effects.
CR 999
NR 999
J9 ACM HRI '12
JI ACM HRI '12
PD 2012 MARCH
PY 2012
VL 7
BP 125
EP 126
DI 10.1145/2157689.2157717
DA 2024-01-09
ER

PT C
AU Ferstl, Y
    Thomas, S
    Guiard, C
    Ennis, C
    McDonnell, R
AF Ferstl, Ylva
    Thomas, Sean
    Guiard, Cédric
    Ennis, Cathy
    McDonnell, Rachel
TI Human or Robot?: Investigating voice, appearance and gesture motion realism of conversational social agents
SO IVA '21: Proceedings of the 21st ACM International Conference on Intelligent Virtual Agents
LA English
DE gesture motion, text-to-speech, animation style, perception, conversational agents, agent design, human-computer interfaces, anthropomorphism
AB Research on creation of virtual humans enables increasing automatization of their behavior, including synthesis of verbal and nonverbal behavior. As the achievable realism of different aspects of agent design evolves asynchronously, it is important to understand if and how divergence in realism between behavioral channels can elicit negative user responses. Specifically, in this work, we investigate the question of whether autonomous virtual agents relying on synthetic text-to-speech voices should portray a corresponding level of realism in the non-verbal channels of motion and visual appearance, or if, alternatively, the best available realism of each channel should be used. In two perceptual studies, we assess how realism of voice, motion, and appearance influence the perceived match of speech and gesture motion, as well as the agent's likability and human-likeness. Our results suggest that maximizing realism of voice and motion is preferable even when this leads to realism mismatches, but for visual appearance, lower realism may be preferable. (A video abstract can be found at https://youtu.be/arfZZ-hxD1Y.)
CR Baird A, 2018, INTERSPEECH, P2863, DOI 10.21437/Interspeech.2018-1093
    Cabral JP, 2017, INTERSPEECH, P229, DOI 10.21437/Interspeech.2017-325
    Kühne K, 2020, FRONT NEUROROBOTICS, V14, DOI 10.3389/fnbot.2020.593732
NR 3
J9 ACM INT Virt Agents
JI ACM Int. Virt. Agents
PD 2021 SEPT
PY 2021
VL 21
BP 76
EP 83
DI 10.1145/3472306.3478338
DA 2024-01-09
ER

PT C
AU Ilves, M
    Surakka, V
    Vanhala, T
AF Ilves, Mirja
    Surakka, Veikko
    Vanhala, Toni
TI The effects of emotionally worded synthesized speech on the ratings of emotions and voice quality
SO ACM Affective Computing and Intelligent Interaction 2011
LA English
DE emotions; speech synthesis; facial expression; voice quality
ID human-centered computing, human computer Interaction
AB The present research investigated how the verbal content of synthetic messages affects participants' emotional responses and the ratings of voice quality. 28 participants listened to emotionally worded sentences produced by a monotonous and a prosodic tone of voice while the activity of corrugator supercilii facial muscle was measured. Ratings of emotions and voice quality were also collected. The results showed that the ratings of emotions were significantly affected by the emotional contents of the sentences. The prosodic tone of voice evoked more emotion-relevant ratings of arousal than the monotonous voice. Corrugator responses did not seem to reflect emotional reactions. Interestingly, the quality of the same voice was rated higher when the content of the sentences was positive as compared to the neutral and negative sentences. Thus, the emotional content of the spoken messages can be used to regulate users' emotions and to evoke positive feelings about the voices.
CR 999
NR 999
J9 ACM ASCII
JI ACM ASCII 2011
PD 2011 OCT
PY 2011
VL 4
BP 588
EP 598
DA 2024-01-09
ER

PT J
AU Klopfenstein, M
AF Klopfenstein, Marie
TI  Speech naturalness ratings and perceptual correlates of highly natural and unnatural speech in hypokinetic dysarthria secondary to Parkinson’s disease
SO Journal of Interactional Research in Communication Disorders
LA English
DE dysarthria, speech naturalness, speech perception 
AB Despite the importance of speech naturalness to treatment outcomes, little research has been done on what constitutes speech naturalness and how to best maximize naturalness in relationship to other treatment goals like intelligibility. This study investigated the speech naturalness ratings of individuals with dysarthria and the associated perceptual correlates of highly natural and unnatural speech. Four speakers with hypokinetic dysarthria secondary to Parkinson’s disease were recorded and rated for naturalness by 69 students in Communication Disorders. Students were presented with 436 speech samples and asked to provide speech naturalness ratings on a 1-9 Likert scale. After rating speech samples, subjects listed perceptual cues associated with samples rated most and least natural and weighted each cue on a visual analog scale. The data on naturalness ratings showed that spontaneous speech was rated the least natural on average, while sentences from a short story were rated slightly more natural and individually read sentences were rated the most natural of all of the utterance types. Thirteen themes emerged from the perceptual cues collected. Of the thirteen themes, intelligibility was rated significantly more important than other cues in highly natural speech and intelligibility and articulation were rated significantly more important than other cues in highly unnatural speech.
CR MARTIN RR, 1984, J SPEECH HEAR DISORD, V49, P53, DOI 10.1044/jshd.4901.53
NR 1
J9 J INTERACT RES COM D
JI J. Interact. Res. Com. D.
PD 2016 JUNE 21
PY 2016
VL 7
IS 1
BP 123
EP 146
DI 10.1558/jircd.v7i1.27932 
DA 2024-01-09
ER

PT C
AU Malisz, Z
    Henter, G E
    Valentini-Botinhao, C
    Watts, O
    Beskow, J
    Gustafson, J
AF Malisz, Zofia
    Henter, Gustav Eje
    Valentini-Botinhao, Cassia
    Watts, Oliver
    Beskow, Jonas
    Gustafson, Joakim
TI [Placeholder]
SO Proceedings of the 19th International Congress of Phonetic Sciences ICPhS 2019.
LA Speech synthesis, scientific methodology, speech technology
DE English
AB Decades of gradual advances in speech synthesis have recently culminated in exponential improvements fuelled by deep learning. This quantum leap has the potential to finally deliver realistic, controllable, and robust synthetic stimuli for speech experiments. In this article, we discuss these and other implications for phonetic sciences. We substantiate our argument by evaluating classic rulebased formant synthesis against state-of-the-art synthesisers on a) subjective naturalness ratings and b) a behavioural measure (reaction times in a lexical decision task). We also differentiate between text-to-speech and speech-to-speech methods. Naturalness ratings indicate that all modern systems are substantially closer to natural speech than formant synthesis. Reaction times for several modern systems do not differ substantially from natural speech, meaning that the processing gap observed in older systems, and reproduced with our formant synthesiser, is no longer evident. Importantly, some speech-tospeech methods are nearly indistinguishable from natural speech on both measures.
CR 999
NR 999
J9 ICPhS 2019
JI ICPhS 2019
PD 2019 AUG 04
PY 2019
VL 19
BP 487
EP 491
DI 10.31234/osf.io/dxvhc
DA 2024-01-09
ER

PT C
AU McGinn, C
    Torre, I
AF McGinn, Conor
    Torre, Ilaria
TI Can you tell the robot by the voice? An exploratory study on the role of voice in the perception of robots
SO 14th ACM/IEEE international Conference on human-robot interaction (HRI)
LA English
DE Robot design; Voice; Speech; Mental model
AB It is well established that a robot’s visual appearance plays a significant role in how it is perceived. Considerable time and resources are usually dedicated to help ensure that the visual aesthetics of social robots are pleasing to users and helps facilitate clear communication. However, relatively little consideration is given to how the voice of the robot should sound, which may have adverse effects on acceptance and clarity of communication. In this study, we explore the mental images people form when they hear robots speaking. In our experiment, participants listened to several voices, and for each voice they were asked to choose a robot, from a selection of eight commonly used social robot platforms, that was best suited to have that voice. The voices were manipulated in terms of naturalness, gender, and accent. Results showed that a) participants seldom matched robots with the voices that were used in previous HRI studies, b) the gender and naturalness vocal manipulations strongly affected participants’ selection, and c) the linguistic content of the utterances spoken by the voices does not affect people’s selection. This finding suggests that people associate voices with robot pictures, even when the content of spoken utterances was unintelligible. Our findings indicate that both a robot’s voice and its appearance contribute to robot perception. Thus, giving a mismatched voice to a robot might introduce a confounding effect in HRI studies. We therefore suggest that voice design should be considered more thoroughly when planning spoken human-robot interactions.
CR Eyssel F, 2012, ACMIEEE INT CONF HUM, P125
    Mitchell WJ, 2011, I-PERCEPTION, V2, P10, DOI 10.1068/i0415
    Tamagawa R, 2011, INT J SOC ROBOT, V3, P253, DOI 10.1007/s12369-011-0100-4
NR 3
J9 ACMIEEE INT CONF HUM
JI ACMIEEE Int. Conf. Hum.
PD 2019
PY 2019
VL 14
BP 211
EP 221
DI 10.1109/HRI.2019.8673279
DA 2024-01-09
ER

PT J
AU Nusbaum, H C
    Francis, A L
    Henly, A S
AF Nusbaum, Howard C
    Francis, Alexander L
    Henly, Anne S
TI Measuring the naturalness of synthetic speech
SO International Journal of Speech Technology,
LA English
DE synthetic speech, naturalness, intelligibility, perception
AB Even the highest quality synthetic speech generated by rule sounds unlike human speech. As the intel-ligibility of rule-based synthetic speech improves, and the number of applications for synthetic speech increases,the naturalness of synthetic speech will become an important factor in determining its use. In order to improve thisaspect of the quality of synthetic speech it is necessary to have diagnostic tests that can measure naturalness. Cur-rently, all of the available metrics for evaluating the acceptability of synthetic speech do not distinguish sufficientlybetween measuring overall acceptability (including naturalness) and simply measuring the ability of listeners toextract intelligible information from the signal. In this paper we propose a new methodology for measuring thenaturalness of particular aspects of synthesized speech, independent of the intelligibility of the speech. Althoughnaturalness is a multidimensional, subjective quality of speech, this methodology makes it possible to assess theseparate contributions of prosodic, segmental, and source characteristics of the utterance. In two experiments, lis-teners reliably differentiated the naturalness of speech produced by two male talkers and two text-to-speech systems.Furthermore, they reliably differentiated between the two text-to-speech systems. The results of these experimentsdemonstrate that perception of naturalness is affected by information contained within the smallest part of speech,the glottal pulse, and by information contained within the prosodic structure of a syllable. These results show thatthis new methodology does provide a solid basis for measuring and diagnosing the naturalness of synthetic speech.
CR 999
NR 999
J9 International Journal of Speech Technology
JI Int. J. of Speech Technology
PD 1995
PY 1995
VL 1
BP 7
EP 19
DI 10.1007/BF02277176
DA 2024-01-09
ER

PT J
AU Ratcliff, A
    Coughlin, S
    Lehman, M
AF Ratcliff, Ann
    Coughlin, Sue
    Lehman, Mark
TI Factors influencing ratings of speech naturalness in augmentative and alternative communication
SO Augmentative and Alternative Communication
LA [Placeholder]
DE augmentative and alternative communication (AAC), speech naturalness, synthesized speech 
AB The concept of speech naturalness has been used in the field of speech-language pathology as a clinical measure of perceptual quality of “normal” and “not normal” speech. Whereas measures of intelligibility have been commonly used to assess the quality of voice output augmentative and alternative communication (AAC) devices using DECTalk™ speech, measures of speech naturalness have not. Three studies were conducted to determine the effects of manipulation of rate, pitch, and pause on ratings of speech naturalness by naive listeners of DECTalk synthetic speech. The results indicate that DECTalk speech characterized by faster rate and no added pauses was perceived as being more natural than speech with slow rate and added pauses. Manipulation of pitch had no effect on naturalness ratings.
CR MARTIN RR, 1984, J SPEECH HEAR DISORD, V49, P53, DOI 10.1044/jshd.4901.53
NR 1
J9 AUGMENT ALTERN COMM
JI Augment. Altern. Comm.
PD 2002 MARCH 18
PY 2002
VL 18
IS 1
BP 11
EP 19
DI 10.1080/aac.18.1.11.19
DA 2024-01-09
ER

PT C
AU Romportl, J
AF Romportl, Jan
TI Speech synthesis and uncanny valley
SO International conference on text, speech, and dialogue
LA English
DE text-to-speech synthesis; spoken dialogue system; uncanny valley; experiment
AB The paper discusses a hypothesis relating high quality text-to-speech(TTS) synthesis in spoken dialogue systems with the concept of “uncannyvalley”. It introduces a “Wizard-of-Oz” experiment with 30 volunteers engagedin conversations with two synthetic voices of different naturalness. The results ofthe experiment are summarized and interpreted, leading to the conclusion that theTTS uncanny valley effect in dialogue systems can probably be superseded andinverted by a positive attitude of the systems’ users toward new technologies.
CR 999
NR 999
J9 Speech and Dialogue. 17th International Conference, TSD 2014. Proceedings: LNCS 8655
JI Speech and Dialogue. 17th International Conference, TSD 2014. Proceedings: LNCS 8655
PY 2014
BP 595
EP 602
DI 10.1007/978-3-319-10816-2_72
DA 2024-01-09
ER

PT C
AU Urakami, J
    Sutthithatip, S
    Moore, B A
AF Urakami, Jaqueline
    Sutthithatip, Sujitra
    Moore, Billie Akwa
TI The effect of naturalness of voice and empathic responses on enjoyment, attitudes and motivation for interacting with a voice user interface
SO Human-Computer Interaction. Multimodal and Natural Interaction: Thematic Area, HCI 2020
LA English
DE Voice user interface, Empathy, Human likeness
AB In human-computer interaction much attention is given to the devel-opment of natural and intuitive Voice User Interfaces (VUI). However, previousresearch has shown that humanlike systems will not necessarily be perceived pos-itive by users. The study reported here examined the effect of human likeness onusers’ rating of enjoyment, attitudes and motivation to use VUI in a Wizard-of-Ozexperiment. Two attributes of human likeness, voice of the system (humanlike vs.machinelike) and social behavior of the system (expressing empathy vs. neutral)were manipulated. Regression analyses confirmed that perceived empathy of theVUI improved interaction enjoyment, attitude towards the system, and intrinsicmotivation but no effect of voice was found. Session order also affected par-ticipants’ evaluation. In the second session, participants rated the VUI as morenegative than in the first session. The results indicate that a VUI that expressessocial behavior (e.g. showing empathy) is perceived as more favorable by the user.Furthermore, changing user expectations pose a challenge for the design of theVUI. The dynamics of user interactions must be taken into account when designingthe VUI.
CR Ilves M, 2013, BEHAV INFORM TECHNOL, V32, P117, DOI 10.1080/0144929X.2012.702285
    Mitchell WJ, 2011, I-PERCEPTION, V2, P10, DOI 10.1068/i0415
NR 2
J9 Human-Computer Interaction. Multimodal and Natural Interaction. Thematic Area, HCI 2020 Held as Part of the 22nd International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12182)
JI Human-Computer Interaction. Multimodal and Natural Interaction. Thematic Area, HCI 2020 Held as Part of the 22nd International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12182)
PD 2020 JULY 10
PY 2020
VL 12182
BP 244
EP 259
DI 10.1007/978-3-030-49062-1_17
DA 2024-01-09
ER


PT C
AU Velner, E
    Boersma, P P G
    de Graaf, M M A
AF Velner, Ella
    Boersma, Paul P G
    de Graaf, Maartje M A
TI Intonation in Robot Speech: Does it work the same as with people?
SO HRI '20: Proceedings of the 2020 ACM/IEEE International Conference on Human-Robot Interaction
LA English
DE Conversation Analysis; Human-Robot Interaction; Linguistics; Speech Intonation; Turn Taking
AB Human-robot interaction (HRI) research aims to design natural interactions between humans and robots. Intonation, a social signaling function in human speech investigated thoroughly in linguistics, has not yet been studied in HRI. This study investigates the effect of robot speech intonation in four conditions (no intonation, focus intonation, end-of-utterance intonation, or combined intonation) on conversational naturalness, social engagement, and people’s humanlike perception of the robot collecting objective and subjective data of participant conversations (n = 120). Our results showed that humanlike intonation partially improved subjective naturalness but not observed fluency, and that intonation partially improved social engagement but did not affect humanlike perceptions of the robot. Given that our results mainly differed from our hypotheses based on human speech intonation, we discuss the implications and provide suggestions for future research to further investigate conversational naturalness in robot speech intonation.
CR 999
NR 999
J9 ACMIEEE INT CONF HUM
JI ACMIEEE INT CONF HUM
PD 2020 MARCH 09
PY 2020
BP 569
EP 578
DI 10.1145/3319502.3374801
DA 2024-01-09
ER

EF