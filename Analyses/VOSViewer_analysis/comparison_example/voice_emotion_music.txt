FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Paquette, S
   Rigoulot, S
   Grunewald, K
   Lehmann, A
AF Paquette, S.
   Rigoulot, S.
   Grunewald, K.
   Lehmann, A.
TI Temporal decoding of vocal and musical emotions: Same code, different
   timecourse?
SO BRAIN RESEARCH
LA English
DT Article
DE Music; Voice; Emotion; Timecourse; ERPs
ID VOICE; SPEECH; COMMUNICATION; VOCALIZATIONS; PERFORMANCE; SOUND
AB From a baby's cry to a piece of music, we perceive emotions from our auditory environment every day. Many theories bring forward the concept of common neural substrates for the perception of vocal and musical emotions. It has been proposed that, for us to perceive emotions, music recruits emotional circuits that evolved for the processing of biologically relevant vocalizations (e.g., screams, laughs). Although some studies have found similarities between voice and instrumental music in terms of acoustic cues and neural correlates, little is known about their processing timecourse. To further understand how vocal and instrumental emotional sounds are perceived, we used EEG to compare the neural processing timecourse of both stimuli type expressed with a varying degree of complexity (vocal/musical affect bursts and emotion-embedded speech/music). Vocal stimuli in general, as well as musical/vocal bursts, were associated with a more concise sensory trace at initial stages of analysis (smaller N1), although vocal bursts had shorter latencies than the musical ones. As for the P2 - vocal affect bursts and Emotion-Embedded Musical stimuli were associated with earlier P2s. These results support the idea that emotional vocal stimuli are differentiated early from other sources and provide insight into the common neurobiological underpinnings of auditory emotions.
C1 [Paquette, S.; Lehmann, A.] McGill Univ, Dept Otolaryngol Head & Neck Surg, Room D05-5711,1001 Decarie Blvd, Montreal, PQ H4A 3J1, Canada.
   [Paquette, S.; Rigoulot, S.; Grunewald, K.; Lehmann, A.] McGill Univ, Ctr Res Brain Language & Mus, Montreal, PQ, Canada.
   [Rigoulot, S.] Univ Quebec Trois Rivieres, Dept Psychol, Trois Rivieres, PQ, Canada.
   [Paquette, S.; Rigoulot, S.; Grunewald, K.; Lehmann, A.] Univ Montreal, Int Lab Brain Mus & Sound Res, Montreal, PQ, Canada.
C3 McGill University; McGill University; University of Quebec; University
   of Quebec Trois Rivieres; Universite de Montreal
RP Paquette, S (corresponding author), McGill Univ, Dept Otolaryngol Head & Neck Surg, Room D05-5711,1001 Decarie Blvd, Montreal, PQ H4A 3J1, Canada.
EM sebastien.paquette@mcgill.ca
RI Rigoulot, Simon/ABF-5776-2020; Grunewald, Karina/IAM-6892-2023;
   Grunewald, Karina/AAQ-9368-2020
OI Grunewald, Karina/0000-0002-1440-823X
FU Fonds de recherche du Quebec (FRQ); Canadian Institute of Health
   Research (CIHR); Institute for Data Valorization (IVADO); MITACS
   Globalink internship
FX The project described was supported by a Fonds de recherche du Quebec
   (FRQ) salary award to AL and by Postdoctoral Awards from the Canadian
   Institute of Health Research (CIHR) and the Institute for Data
   Valorization (IVADO) to SP, as well as a MITACS Globalink internship to
   KG.
CR Ahmed DG, 2018, CLIN EEG NEUROSCI, V49, P143, DOI 10.1177/1550059417733386
   [Anonymous], DECODER EMOTIONS TRA
   [Anonymous], 2007, P 10 INT C DIG AUD E
   [Anonymous], 2000, HDB EMOTIONS
   Aubé W, 2015, SOC COGN AFFECT NEUR, V10, P399, DOI 10.1093/scan/nsu067
   Belin P, 2004, TRENDS COGN SCI, V8, P129, DOI 10.1016/j.tics.2004.01.008
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Bowling DL, 2017, SCI REP-UK, V7, DOI 10.1038/srep41070
   Brown S, 2000, ORIGINS OF MUSIC, P271
   Charest I, 2009, BMC NEUROSCI, V10, DOI 10.1186/1471-2202-10-127
   Chartrand JP, 2007, NEUROREPORT, V18, P335, DOI 10.1097/WNR.0b013e328013cea9
   Curtis ME, 2010, EMOTION, V10, P335, DOI 10.1037/a0017928
   Darwin C., 1872, P374
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Deroche MLD, 2019, EAR HEARING, V40, P1197, DOI 10.1097/AUD.0000000000000701
   Frühholz S, 2016, NEUROSCI BIOBEHAV R, V68, P96, DOI 10.1016/j.neubiorev.2016.05.002
   Gosselin N, 2015, CORTEX, V71, P171, DOI 10.1016/j.cortex.2015.06.022
   HALPERN DL, 1986, PERCEPT PSYCHOPHYS, V39, P77, DOI 10.3758/BF03211488
   Hawk ST, 2009, EMOTION, V9, P293, DOI 10.1037/a0015178
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Iredale JM, 2013, INT J PSYCHOPHYSIOL, V89, P483, DOI 10.1016/j.ijpsycho.2013.06.025
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Key APF, 2005, DEV NEUROPSYCHOL, V27, P183, DOI 10.1207/s15326942dn2702_1
   Lopez-Calderon J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00213
   Mullen T., 2012, CLEANLINE EEGLAB PLU
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Obleser J, 2011, NEUROIMAGE, V55, P713, DOI 10.1016/j.neuroimage.2010.12.020
   Paquette S, 2018, HEARING RES, V370, P272, DOI 10.1016/j.heares.2018.08.009
   Paquette S, 2018, ANN NY ACAD SCI, V1423, P329, DOI 10.1111/nyas.13666
   Paquette S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00509
   Paulmann S, 2008, NEUROREPORT, V19, P209, DOI 10.1097/WNR.0b013e3282f454db
   Paulmann S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00345
   Pell MD, 2015, BIOL PSYCHOL, V111, P14, DOI 10.1016/j.biopsycho.2015.08.008
   Pell MD, 2009, J PHONETICS, V37, P417, DOI 10.1016/j.wocn.2009.07.005
   Pell MD, 2002, BRAIN COGNITION, V48, P499, DOI 10.1006/brxg.2001.1406
   Peretz I., 2013, HDB MUSIC EMOTION TH, P99, DOI [10.1093/acprof:oso/9780199230143.003.0005, DOI 10.1093/ACPROF:OSO/9780199230143.003.0005]
   Rigoulot S, 2015, NEUROSCIENCE, V290, P175, DOI 10.1016/j.neuroscience.2015.01.033
   Sachs ME, 2018, NEUROIMAGE, V174, P1, DOI 10.1016/j.neuroimage.2018.02.058
   SCHERER KR, 1994, EMOTIONS: ESSAYS ON EMOTION THEORY, P161
   Stratou G, 2013, INT CONF AFFECT, P147, DOI 10.1109/ACII.2013.31
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
NR 43
TC 3
Z9 3
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0006-8993
EI 1872-6240
J9 BRAIN RES
JI Brain Res.
PD AUG 15
PY 2020
VL 1741
AR 146887
DI 10.1016/j.brainres.2020.146887
PG 6
WC Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Neurosciences & Neurology
GA LW8SW
UT WOS:000539414700012
PM 32422128
DA 2024-01-09
ER

PT J
AU Beveridge, S
   Knox, D
AF Beveridge, Scott
   Knox, Don
TI Popular music and the role of vocal melody in perceived emotion
SO PSYCHOLOGY OF MUSIC
LA English
DT Article
DE emotion; popular music; technology; voice
ID EXPRESSION; RECOGNITION; PERFORMANCE
AB The voice plays a crucial role in expressing emotion in popular music. However, the importance of the voice in this context has not been systematically assessed. This study investigates the emotional effect of vocal features in popular music. In particular, it focuses on nonverbal characteristics, including vocal melody and rhythm. To determine the efficacy of these features, they are used to construct a computational Music Emotion Recognition (MER) system. The system is based on the circumplex model that expresses emotion in terms of arousal and valence. Two independent studies were used to develop the system. The first study established models for predicting arousal and valence based on a range of acoustical and nonverbal vocal features. The second study was used for independent validation of these models. Results show that features describing rhythmic qualities of the vocal line produce emotion models with a high level of generalizability. In particular these models reliably predict emotional valence, a well-known issue in existing Music Emotion Recognition systems.
C1 [Beveridge, Scott] Univ Mus Carl Maria von Weber, IMM, Leubnitzer Str 17b, D-01069 Dresden, Germany.
   [Knox, Don] Glasgow Caledonian Univ, Glasgow, Lanark, Scotland.
C3 Glasgow Caledonian University
RP Beveridge, S (corresponding author), Univ Mus Carl Maria von Weber, IMM, Leubnitzer Str 17b, D-01069 Dresden, Germany.
EM Scott.Beveridge@hfmdd.de
OI Knox, Don/0000-0003-1303-1183
FU Engineering and Physical Sciences Research Council [EP/F00558X/1]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This
   research was funded by the Engineering and Physical Sciences Research
   Council (grant no. EP/F00558X/1).
CR [Anonymous], 2001, ROCK PRIMARY TEXT DE
   [Anonymous], 2013, 2013 IEEE INT C MULT
   [Anonymous], 2013, P INT SOC MUS INF RE
   [Anonymous], PSYCHOL MUSIC
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Burns G., 1987, Popular Music, V6, P1, DOI [DOI 10.1017/S026114, 10.1017/S0261143000006577, DOI 10.1017/S0261143000006577]
   Celma O., 2006, WORKSH MAST GAP INF
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Dibben N., 2014, Expressiveness in Music Performance: Empirical Approaches Across Styles and Cultures, P117, DOI [10.1093/acprof:oso/9780199659647.003.0007, DOI 10.1093/ACPROF:OSO/9780199659647.003.0007]
   Eerola T., 2004, P INT C MUS INF RETR, P22
   Eerola T., 2009, Proceedings of the International Conference on Music Information Retrieval ISMIR, P621
   Eerola T, 2011, J NEW MUSIC RES, V40, P349, DOI 10.1080/09298215.2011.602195
   Eno B., 1996, A Year With Swollen Appendices: Brian Eno's Diary
   Frank E., 2005, Data mining: Practical machine learning tools and techniques
   Gabrielsson A., 2010, HDB MUSIC EMOTION TH, P367, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0014
   GERARDI GM, 1995, MUSIC PERCEPT, V12, P279
   Gundlach RH, 1935, AM J PSYCHOL, V47, P624, DOI 10.2307/1416007
   Hevner K, 1936, AM J PSYCHOL, V48, P246, DOI 10.2307/1415746
   Hevner K, 1935, AM J PSYCHOL, V47, P103, DOI 10.2307/1416710
   Hevner K, 1937, AM J PSYCHOL, V49, P621, DOI 10.2307/1416385
   Hubbard T.L, 1998, PSYCHOMUSICOLOGY J R, V17, P36, DOI DOI 10.1037/H0094060
   Humphrey EJ, 2012, ISMIR, P403
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Juslin P., 2010, Handbook of Music and Emotion: Theory, Research, Applications, P453, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0017
   Juslin PN, 2010, MUSIC ANAL, V29, P334, DOI 10.1111/j.1468-2249.2011.00323.x
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Juslin PN, 1999, MUSIC PERCEPT, V17, P197
   Juslin PN, 1997, MUSIC SCI, V1, P225, DOI DOI 10.1177/102986499700100205
   Kim Y. E., 2006, 7 INT C MUS INF RETR
   Kuhn M., 2013, Applied predictive modeling, V26
   Kursa MB, 2010, J STAT SOFTW, V36, P1, DOI 10.18637/jss.v036.i11
   Lartillot O., 2007, P INT C DIG AUD EFF, DOI DOI 10.1007/978-3-540-78246-9_31
   Lindström E, 2006, MUSIC SCI, V10, P85, DOI 10.1177/102986490601000105
   Lu L, 2006, IEEE T AUDIO SPEECH, V14, P5, DOI 10.1109/TSA.2005.860344
   McKay C., 2006, P INT COMP MUS C, P302
   Pachet F., 2004, Journal of negative results in speech and audio sciences, V1, P1
   Pachet F, 2012, CH CRC DATA MIN KNOW, P305
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Sturm BL, 2013, J INTELL INF SYST, V41, P371, DOI 10.1007/s10844-013-0250-y
   Tabachnick BG., 2007, USING MULTIVARIATE S, VVol. 5, P481
   Warner T., 2003, Pop music-technology and creativity: Trevor horn and the digital revolution
   WEDIN L, 1972, SCAND J PSYCHOL, V13, P241, DOI 10.1111/j.1467-9450.1972.tb00072.x
   Yang Y., 2007, 2007 IEEE INT C MULT, P208, DOI 10.1109/ICME.2007.4284623
   ZAJONC RB, 1968, J PERS SOC PSYCHOL, V9, P1, DOI 10.1037/h0025848
NR 44
TC 4
Z9 4
U1 1
U2 25
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0305-7356
EI 1741-3087
J9 PSYCHOL MUSIC
JI Psychol. Music
PD MAY
PY 2018
VL 46
IS 3
BP 411
EP 423
DI 10.1177/0305735617713834
PG 13
WC Psychology, Educational; Psychology, Applied; Music; Psychology,
   Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Psychology; Music
GA GC6RT
UT WOS:000429920400007
OA Green Accepted
DA 2024-01-09
ER

PT J
AU Bänziger, T
   Patel, S
   Scherer, KR
AF Baenziger, Tanja
   Patel, Sona
   Scherer, Klaus R.
TI The Role of Perceived Voice and Speech Characteristics in Vocal Emotion
   Communication
SO JOURNAL OF NONVERBAL BEHAVIOR
LA English
DT Article
DE Perception; Emotional expression; Actor portrayals; Prosody; Voice
   quality
ID MULTIMODAL EXPRESSION; AFFECT PROGRAMS; MUSIC
AB Aiming at a more comprehensive assessment of nonverbal vocal emotion communication, this article presents the development and validation of a new rating instrument for the assessment of perceived voice and speech features. In two studies, using two different sets of emotion portrayals by German and French actors, ratings of perceived voice and speech characteristics (loudness, pitch, intonation, sharpness, articulation, roughness, instability, and speech rate) were obtained from non-expert (untrained) listeners. In addition, standard acoustic parameters were extracted from the voice samples. Overall, highly similar patterns of results were found in both studies. Rater agreement (reliability) reached highly satisfactory levels for most features. Multiple discriminant analysis results reveal that both perceived vocal features and acoustic parameters allow a high degree of differentiation of the actor-portrayed emotions. Positive emotions can be classified with a higher hit rate on the basis of perceived vocal features, confirming suggestions in the literature that it is difficult to find acoustic valence indicators. The results show that the suggested scales (Geneva Voice Perception Scales) can be reliably measured and make a substantial contribution to a more comprehensive assessment of the process of emotion inferences from vocal expression.
C1 [Baenziger, Tanja; Patel, Sona; Scherer, Klaus R.] Univ Geneva, Swiss Ctr Affect Sci, CH-1205 Geneva, Switzerland.
C3 University of Geneva
RP Scherer, KR (corresponding author), Univ Geneva, Swiss Ctr Affect Sci, Rue Battoirs 7, CH-1205 Geneva, Switzerland.
EM Klaus.Scherer@unige.ch
RI Patel, Sona/AAP-9641-2020
OI Patel, Sona/0000-0002-0973-9528
CR [Anonymous], 1980, The Phonetic Description of Voice Quality
   Bänziger T, 2012, EMOTION, V12, P1161, DOI 10.1037/a0025827
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Banziger T., 2003, P VOQ 2003 VOIC QUAL, P169
   Banziger T., 2004, THESIS U GENEVA
   Beck J. M., 1999, 14 P 14 INT C PHON S, P219
   Biemans M. A. J., 2000, THESIS U NIJMEGEN
   Davitz J. R., 1964, COMMUNICATION EMOTIO
   Granqvist S., 1996, SPEECH MUSIC HEARING, V4, P61
   Hall J. A., 2013, Nonverbal communication
   Harrigan J. A., 2005, NEW HDB METHODS NONV, P65, DOI DOI 10.1093/ACPROF:OSO/9780198529620.003.0003
   Henrich N., 2008, J INT DISCIPL MUSIC, V2, P71
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kreiman J, 1998, J ACOUST SOC AM, V104, P1598, DOI 10.1121/1.424372
   Patel S, 2013, HANDB COMMUN SCI, V2, P167
   Roesch E. B., 2010, BLUEPRINT AFFECTIVE, P271, DOI DOI 10.1037/A0025827
   Rosenthal R., 1987, JUDGMENT STUDIES
   Sangsue J., 1997, GENEVA STUDIES EMOTI, V11
   Scherer KR, 2007, EMOTION, V7, P158, DOI 10.1037/1528-3542.7.1.158
   Scherer KR, 2007, EMOTION, V7, P113, DOI 10.1037/1528-3542.7.1.113
   Scherer KR, 2013, STRUNGMANN FORUM REP, P107
   Scherer KR, 2011, INT J PSYCHOL, V46, P401, DOI 10.1080/00207594.2011.626049
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   SCHERER KR, 1978, EUR J SOC PSYCHOL, V8, P467, DOI 10.1002/ejsp.2420080405
   Sundberg J, 2011, IEEE T AFFECT COMPUT, V2, P162, DOI 10.1109/T-AFFC.2011.14
   TARTTER VC, 1994, J ACOUST SOC AM, V96, P2101, DOI 10.1121/1.410151
   TOLKMITT FJ, 1986, J EXP PSYCHOL HUMAN, V12, P302, DOI 10.1037/0096-1523.12.3.302
   van Bezooijen R, 1986, LINGUISTICS NETHERLA, P1
   van Bezooijen R. A., 1984, THESIS
   Weenink D., 2012, PRAAT DOING PHONETIC
NR 31
TC 43
Z9 47
U1 7
U2 71
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0191-5886
EI 1573-3653
J9 J NONVERBAL BEHAV
JI J. Nonverbal Behav.
PD MAR
PY 2014
VL 38
IS 1
BP 31
EP 52
DI 10.1007/s10919-013-0165-x
PG 22
WC Psychology, Social
WE Social Science Citation Index (SSCI)
SC Psychology
GA AA1AC
UT WOS:000330827500003
OA Green Submitted
DA 2024-01-09
ER

PT J
AU Frühholz, S
   Trost, W
   Grandjean, D
AF Fruehholz, Sascha
   Trost, Wiebke
   Grandjean, Didier
TI The role of the medial temporal limbic system in processing emotions in
   voice and music
SO PROGRESS IN NEUROBIOLOGY
LA English
DT Review
DE Amygdala; Hippocampus; Emotion; Music; Voice; Neuroimaging
ID AUDITORY-CORTEX; VOCAL EXPRESSIONS; HUMAN AMYGDALA; NEURAL RESPONSES;
   FUNCTIONAL MRI; IMPAIRED RECOGNITION; SPATIAL-ORGANIZATION; ACOUSTIC
   PARAMETERS; INTACT RECOGNITION; BRAIN ACTIVATION
AB Subcortical brain structures of the limbic system, such as the amygdala, are thought to decode the emotional value of sensory information. Recent neuroimaging studies, as well as lesion studies in patients, have shown that the amygdala is sensitive to emotions in voice and music. Similarly, the hippocampus, another part of the temporal limbic system (TLS), is responsive to vocal and musical emotions, but its specific roles in emotional processing from music and especially from voices have been largely neglected. Here we review recent research on vocal and musical emotions, and outline commonalities and differences in the neural processing of emotions in the TLS in terms of emotional valence, emotional intensity and arousal, as well as in terms of acoustic and structural features of voices and music. We summarize the findings in a neural framework including several subcortical and cortical functional pathways between the auditory system and the TLS. This framework proposes that some vocal expressions might already receive a fast emotional evaluation via a subcortical pathway to the amygdala, whereas cortical pathways to the TLS are thought to be equally used for vocal and musical emotions. While the amygdala might be specifically involved in a coarse decoding of the emotional value of voices and music, the hippocampus might process more complex vocal and musical emotions, and might have an important role especially for the decoding of musical emotions by providing memory-based and contextual associations. (C) 2014 Elsevier Ltd. All rights reserved.
C1 [Fruehholz, Sascha; Trost, Wiebke; Grandjean, Didier] Univ Geneva, Dept Psychol, Neurosci Emot & Affect Dynam Lab, CH-1211 Geneva 20, Switzerland.
   [Fruehholz, Sascha; Trost, Wiebke; Grandjean, Didier] Univ Geneva, Swiss Ctr Affect Sci, CH-1211 Geneva 20, Switzerland.
C3 University of Geneva; University of Geneva
RP Frühholz, S (corresponding author), Univ Geneva, Swiss Ctr Affect Sci, 9 Chemin Mines,POB 60, CH-1211 Geneva 20, Switzerland.
EM sascha.fruehholz@unige.ch
RI Frühholz, Sascha/E-9194-2013
OI Grandjean, Didier/0000-0001-6125-4520; Fruhholz,
   Sascha/0000-0002-6485-3817
FU Swiss National Science Foundation (SNSF) [105314_146559/1]; NCCR in
   Affective Sciences [51NF40-104897]
FX S.F. was supported by a grant from the Swiss National Science Foundation
   (SNSF 105314_146559/1). DG was supported by the NCCR in Affective
   Sciences (51NF40-104897). The authors thank Alessia Pannese for helpful
   comments on the manuscript.
CR Adolphs R, 1999, NEUROPSYCHOLOGIA, V37, P1285, DOI 10.1016/S0028-3932(99)00023-8
   AITKIN LM, 1978, J NEUROPHYSIOL, V41, P837, DOI 10.1152/jn.1978.41.4.837
   Alba-Ferrara L, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0028701
   Alluri V, 2013, NEUROIMAGE, V83, P627, DOI 10.1016/j.neuroimage.2013.06.064
   Alluri V, 2012, NEUROIMAGE, V59, P3677, DOI 10.1016/j.neuroimage.2011.11.019
   Alonso I, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00111
   Amunts K, 2005, ANAT EMBRYOL, V210, P343, DOI 10.1007/s00429-005-0025-5
   Anderson AK, 1998, NEUROREPORT, V9, P3607
   [Anonymous], 2009, Int. J. Speech Lang. Pathol
   Bach DR, 2008, NEUROIMAGE, V42, P919, DOI 10.1016/j.neuroimage.2008.05.034
   Bach DR, 2008, CEREB CORTEX, V18, P145, DOI 10.1093/cercor/bhm040
   Bach DR, 2013, NEUROPSYCHOLOGIA, V51, P2070, DOI 10.1016/j.neuropsychologia.2013.07.005
   Ball T, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000307
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Baumann S, 2011, NAT NEUROSCI, V14, P423, DOI 10.1038/nn.2771
   Baumgartner T, 2006, BRAIN RES, V1075, P151, DOI 10.1016/j.brainres.2005.12.065
   Beaucousin V, 2007, CEREB CORTEX, V17, P339, DOI 10.1093/cercor/bhj151
   Belin P, 2004, TRENDS COGN SCI, V8, P129, DOI 10.1016/j.tics.2004.01.008
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Belin P, 2008, P ROY SOC B-BIOL SCI, V275, P473, DOI 10.1098/rspb.2007.1460
   Bendor D, 2005, NATURE, V436, P1161, DOI 10.1038/nature03867
   Bestelmeyer PEG, 2010, COGNITION, V117, P217, DOI 10.1016/j.cognition.2010.08.008
   Blood AJ, 1999, NAT NEUROSCI, V2, P382, DOI 10.1038/7299
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   BORDI F, 1992, J NEUROSCI, V12, P2493
   Brattico E, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00308
   Brown S, 2004, NEUROREPORT, V15, P2033, DOI 10.1097/00001756-200409150-00008
   Buchanan TW, 2000, COGNITIVE BRAIN RES, V9, P227, DOI 10.1016/S0926-6410(99)00060-9
   Büchel C, 1999, J NEUROSCI, V19, P10869
   Cenquizca LA, 2007, BRAIN RES REV, V56, P1, DOI 10.1016/j.brainresrev.2007.05.002
   Chandrasekaran B, 2010, PSYCHOPHYSIOLOGY, V47, P236, DOI 10.1111/j.1469-8986.2009.00928.x
   Chapin H, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0013812
   Conard NJ, 2009, NATURE, V460, P737, DOI 10.1038/nature08169
   Coutinho E, 2013, COGNITION EMOTION, V27, P658, DOI 10.1080/02699931.2012.732559
   Da Costa S, 2011, J NEUROSCI, V31, P14067, DOI 10.1523/JNEUROSCI.2000-11.2011
   Dellacherie D, 2011, CORTEX, V47, P1107, DOI 10.1016/j.cortex.2011.05.007
   Dellacherie D, 2008, MUSIC PERCEPT, V25, P285, DOI 10.1525/MP.2008.25.4.285
   Dellacherie D, 2009, ANN NY ACAD SCI, V1169, P336, DOI 10.1111/j.1749-6632.2009.04870.x
   Dietrich S, 2007, NEUROREPORT, V18, P1891, DOI 10.1097/WNR.0b013e3282f290df
   Dyck M, 2011, NEUROIMAGE, V54, P2503, DOI 10.1016/j.neuroimage.2010.10.013
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Eldar E, 2007, CEREB CORTEX, V17, P2828, DOI 10.1093/cercor/bhm011
   Engel A, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00083
   Escoffier N, 2013, HUM BRAIN MAPP, V34, P1796, DOI 10.1002/hbm.22029
   Ethofer T, 2006, NEUROIMAGE, V30, P580, DOI 10.1016/j.neuroimage.2005.09.059
   Ethofer T, 2006, NEUROREPORT, V17, P249, DOI 10.1097/01.wnr.0000199466.32036.5d
   Ethofer T, 2006, HUM BRAIN MAPP, V27, P707, DOI 10.1002/hbm.20212
   Ethofer T, 2009, J COGNITIVE NEUROSCI, V21, P1255, DOI 10.1162/jocn.2009.21099
   EVERITT BJ, 1990, NEUROSCI BIOBEHAV R, V14, P217, DOI 10.1016/S0149-7634(05)80222-2
   Fairhurst MT, 2013, CEREB CORTEX, V23, P2592, DOI 10.1093/cercor/bhs243
   Fanselow MS, 2010, NEURON, V65, P7, DOI 10.1016/j.neuron.2009.11.031
   Fecteau S, 2007, NEUROIMAGE, V36, P480, DOI 10.1016/j.neuroimage.2007.02.043
   Fletcher PD, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00347
   Fontaine JRJ, 2007, PSYCHOL SCI, V18, P1050, DOI 10.1111/j.1467-9280.2007.02024.x
   Fruehholz S, 2013, NEUROSCI BIOBEHAV R, V37, P2847, DOI 10.1016/j.neubiorev.2013.10.007
   Frühholz S, 2013, CORTEX, V49, P1394, DOI 10.1016/j.cortex.2012.08.003
   Frühholz S, 2013, NEUROSCI BIOBEHAV R, V37, P24, DOI 10.1016/j.neubiorev.2012.11.002
   Frühholz S, 2012, CEREB CORTEX, V22, P1107, DOI 10.1093/cercor/bhr184
   Fruhholz S., 2014, CEREB CORTEX
   Fusar-Poli P, 2009, J PSYCHIATR NEUROSCI, V34, P418
   Gabrielsson A, 2003, SER AFFECTIVE SCI, P503
   Gomez P, 2007, EMOTION, V7, P377, DOI 10.1037/1528-3542.7.2.377
   Gosselin N, 2005, BRAIN, V128, P628, DOI 10.1093/brain/awh420
   Gosselin N, 2007, NEUROPSYCHOLOGIA, V45, P236, DOI 10.1016/j.neuropsychologia.2006.07.012
   Gosselin N, 2006, BRAIN, V129, P2585, DOI 10.1093/brain/awl240
   Gosselin N, 2011, CORTEX, V47, P1116, DOI 10.1016/j.cortex.2011.05.012
   Goudbeek M, 2010, J ACOUST SOC AM, V128, P1322, DOI 10.1121/1.3466853
   Grandjean D, 2005, NAT NEUROSCI, V8, P145, DOI 10.1038/nn1392
   Grandjean D, 2006, PROG BRAIN RES, V156, P235, DOI 10.1016/S0079-6123(06)56012-1
   Green AC, 2008, NEUROREPORT, V19, P711, DOI 10.1097/WNR.0b013e3282fd0dd8
   Grewe O, 2007, EMOTION, V7, P774, DOI 10.1037/1528-3542.7.4.774
   Guhn M, 2007, MUSIC PERCEPT, V24, P473, DOI 10.1525/MP.2007.24.5.473
   Hackett TA, 2011, HEARING RES, V271, P133, DOI 10.1016/j.heares.2010.01.011
   Harnmerschmidt K, 2007, J VOICE, V21, P531, DOI 10.1016/j.jvoice.2006.03.002
   Hasselmo ME, 2005, NEURAL NETWORKS, V18, P1172, DOI 10.1016/j.neunet.2005.08.007
   Henke K, 1997, HIPPOCAMPUS, V7, P249, DOI 10.1002/(SICI)1098-1063(1997)7:3<249::AID-HIPO1>3.0.CO;2-G
   Herry C, 2007, J NEUROSCI, V27, P5958, DOI 10.1523/JNEUROSCI.5218-06.2007
   Hove MJ, 2009, SOC COGNITION, V27, P949, DOI 10.1521/soco.2009.27.6.949
   Hsieh S, 2012, NEUROPSYCHOLOGIA, V50, P1814, DOI 10.1016/j.neuropsychologia.2012.04.006
   Hurt CP, 1998, J MUSIC THER, V35, P228, DOI 10.1093/jmt/35.4.228
   Immordino-Yang MH, 2013, HUM BRAIN MAPP, V34, P945, DOI 10.1002/hbm.21485
   Ising H, 2004, Noise Health, V6, P5
   James CE, 2008, NEUROIMAGE, V42, P1597, DOI 10.1016/j.neuroimage.2008.06.025
   JARRELL TW, 1987, BRAIN RES, V412, P285, DOI 10.1016/0006-8993(87)91135-8
   Jones E, 2007, THALAMUS, V2
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kensinger EA, 2007, CURR DIR PSYCHOL SCI, V16, P213, DOI 10.1111/j.1467-8721.2007.00506.x
   Khalfa S, 2008, NEUROPSYCHOLOGIA, V46, P2485, DOI 10.1016/j.neuropsychologia.2008.04.009
   Kissler J., 2013, The Cambridge handbook of human affective neuroscience, P304
   Kleber B, 2007, NEUROIMAGE, V36, P889, DOI 10.1016/j.neuroimage.2007.02.053
   Koelsch S, 2006, HUM BRAIN MAPP, V27, P239, DOI 10.1002/hbm.20180
   Koelsch S, 2003, ANN NY ACAD SCI, V999, P15, DOI 10.1196/annals.1284.002
   Koelsch S, 2014, NAT REV NEUROSCI, V15, P170, DOI 10.1038/nrn3666
   Koelsch S, 2013, NEUROIMAGE, V81, P49, DOI 10.1016/j.neuroimage.2013.05.008
   Koelsch S, 2010, TRENDS COGN SCI, V14, P131, DOI 10.1016/j.tics.2010.01.002
   Koelsch S, 2008, NEUROREPORT, V19, P1815, DOI 10.1097/WNR.0b013e32831a8722
   Kotz SA, 2003, BRAIN LANG, V86, P366, DOI 10.1016/S0093-934X(02)00532-1
   Kotz SA, 2013, HUM BRAIN MAPP, V34, P1971, DOI 10.1002/hbm.22041
   Kreifelts B, 2010, HUM BRAIN MAPP, V31, P979, DOI 10.1002/hbm.20913
   Kreifelts B, 2009, NEUROPSYCHOLOGIA, V47, P3059, DOI 10.1016/j.neuropsychologia.2009.07.001
   LeDoux JE, 2000, ANNU REV NEUROSCI, V23, P155, DOI 10.1146/annurev.neuro.23.1.155
   LeDoux J, 2007, CURR BIOL, V17, pR868, DOI 10.1016/j.cub.2007.08.005
   LeDoux J, 2012, NEURON, V73, P653, DOI 10.1016/j.neuron.2012.02.004
   Lehne M, 2014, SOC COGN AFFECT NEUR, V9, P1515, DOI 10.1093/scan/nst141
   Leitman DI, 2011, FRONT HUM NEUROSCI, V5, DOI [10.3389/fnhum.2011.00096, 10.3389/fnhum.2010.00019]
   Leitman DI, 2011, BIOL PSYCHIAT, V70, P611, DOI 10.1016/j.biopsych.2011.05.032
   Leitman DI, 2010, SCHIZOPHRENIA BULL, V36, P545, DOI 10.1093/schbul/sbn115
   Lerner Y, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0006230
   Levitin DJ, 2003, NEUROIMAGE, V18, P74, DOI 10.1006/nimg.2002.1297
   Liem F, 2014, HUM BRAIN MAPP, V35, P1779, DOI 10.1002/hbm.22291
   Liu SY, 2012, SCI REP-UK, V2, DOI 10.1038/srep00834
   Maguire EA, 2001, REV NEUROL-FRANCE, V157, P791
   Malone BJ, 2007, J NEUROPHYSIOL, V98, P1451, DOI 10.1152/jn.01203.2006
   McDermott JH, 2010, CURR BIOL, V20, P1035, DOI 10.1016/j.cub.2010.04.019
   Meyer LB., 1956, Emotion and meaning in music
   Milesi V, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00275
   Mitchell RLC, 2006, EUR J NEUROSCI, V24, P3611, DOI 10.1111/j.1460-9568.2006.05231.x
   Mitchell RLC, 2003, NEUROPSYCHOLOGIA, V41, P1410, DOI 10.1016/S0028-3932(03)00017-4
   Mitterschiffthaler MT, 2007, HUM BRAIN MAPP, V28, P1150, DOI 10.1002/hbm.20337
   Mohedano-Moriano A, 2007, J ANAT, V211, P250, DOI 10.1111/j.1469-7580.2007.00764.x
   Morris JS, 1999, NEUROPSYCHOLOGIA, V37, P1155, DOI 10.1016/S0028-3932(99)00015-9
   Mothes-Lasch M, 2011, J NEUROSCI, V31, P9594, DOI 10.1523/JNEUROSCI.6665-10.2011
   Mueller K, 2011, NEUROIMAGE, V54, P337, DOI 10.1016/j.neuroimage.2010.08.029
   Mutschler I, 2010, CEREB CORTEX, V20, P2531, DOI 10.1093/cercor/bhq001
   Nakamura K, 2001, NEUROPSYCHOLOGIA, V39, P1047, DOI 10.1016/S0028-3932(01)00037-9
   Nieuwenhuys R, 1996, PROG BRAIN RES, V107, P551
   Öhman A, 2001, PSYCHOL REV, V108, P483, DOI 10.1037//0033-295X.108.3.483
   Omar R, 2011, NEUROIMAGE, V56, P1814, DOI 10.1016/j.neuroimage.2011.03.002
   Pallesen KJ, 2005, ANN NY ACAD SCI, V1060, P450, DOI 10.1196/annals.1360.047
   Pallesen KJ, 2009, J COGNITIVE NEUROSCI, V21, P1065, DOI 10.1162/jocn.2009.21086
   Panksepp J, 2002, BEHAV PROCESS, V60, P133, DOI 10.1016/S0376-6357(02)00080-3
   Panksepp J, 1995, MUSIC PERCEPT, V13, P171
   Park M, 2013, BRAIN RES, V1523, P68, DOI 10.1016/j.brainres.2013.05.042
   Patel S, 2011, BIOL PSYCHOL, V87, P93, DOI 10.1016/j.biopsycho.2011.02.010
   Pell MD, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027256
   Pereira CS, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027241
   Phelps EA, 2005, NEURON, V48, P175, DOI 10.1016/j.neuron.2005.09.025
   Phillips ML, 1998, P ROY SOC B-BIOL SCI, V265, P1809, DOI 10.1098/rspb.1998.0506
   Pitkänen A, 2000, ANN NY ACAD SCI, V911, P369
   Plailly J, 2007, CEREB CORTEX, V17, P2650, DOI 10.1093/cercor/bhl173
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Polston JE, 2011, PHARMACOL BIOCHEM BE, V98, P54, DOI 10.1016/j.pbb.2010.11.024
   PREUSS A, 1990, EXP BRAIN RES, V79, P207
   Quadflieg S, 2008, BIOL PSYCHOL, V78, P129, DOI 10.1016/j.biopsycho.2008.01.014
   Rauch SL, 1999, PSYCHIAT RES-NEUROIM, V91, P1, DOI 10.1016/S0925-4927(99)00020-7
   Reser DH, 2009, EUR J NEUROSCI, V30, P578, DOI 10.1111/j.1460-9568.2009.06846.x
   Richardson MP, 2004, NAT NEUROSCI, V7, P278, DOI 10.1038/nn1190
   Rivier F, 1997, NEUROIMAGE, V6, P288, DOI 10.1006/nimg.1997.0304
   Romanski LM, 2009, ANNU REV NEUROSCI, V32, P315, DOI 10.1146/annurev.neuro.051508.135431
   Rota G, 2011, BRAIN LANG, V117, P123, DOI 10.1016/j.bandl.2010.07.008
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Russell JA, 2003, PSYCHOL REV, V110, P145, DOI 10.1037/0033-295X.110.1.145
   Salimpoor VN, 2013, SCIENCE, V340, P216, DOI 10.1126/science.1231059
   Salimpoor VN, 2011, NAT NEUROSCI, V14, P257, DOI 10.1038/nn.2726
   SAMSON S, 1991, J EXP PSYCHOL LEARN, V17, P793, DOI 10.1037/0278-7393.17.4.793
   Sander D, 2005, NEUROIMAGE, V28, P848, DOI 10.1016/j.neuroimage.2005.06.023
   Sander D, 2003, REV NEUROSCIENCE, V14, P303, DOI 10.1515/REVNEURO.2003.14.4.303
   Sander K, 2005, J COGNITIVE NEUROSCI, V17, P1519, DOI 10.1162/089892905774597227
   Sander K, 2003, BRAIN RES PROTOC, V11, P81, DOI 10.1016/S1385-299X(03)00018-7
   Sander K, 2007, HUM BRAIN MAPP, V28, P1007, DOI 10.1002/hbm.20333
   Sauter DA, 2010, Q J EXP PSYCHOL, V63, P2251, DOI 10.1080/17470211003721642
   Scherer K. R., 1984, APPROACHES EMOTION, DOI 10.4324/9781315798806
   Scherer KR, 2004, J NEW MUSIC RES, V33, P239, DOI 10.1080/0929821042000317822
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   SCHERER KR, 1994, EMOTIONS: ESSAYS ON EMOTION THEORY, P161
   Schirmer A, 2008, NEUROIMAGE, V40, P1402, DOI 10.1016/j.neuroimage.2008.01.018
   Schirmer A, 2012, NEUROIMAGE, V63, P137, DOI 10.1016/j.neuroimage.2012.06.025
   Schlaug G, 2010, MUSIC PERCEPT, V27, P249, DOI 10.1525/MP.2010.27.4.249
   Schröber M, 2003, SPEECH COMMUN, V40, P99, DOI 10.1016/S0167-6393(02)00078-X
   Scott SK, 1997, NATURE, V385, P254, DOI 10.1038/385254a0
   Sprengelmeyer R, 1999, P ROY SOC B-BIOL SCI, V266, P2451, DOI 10.1098/rspb.1999.0945
   Stienen BMC, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025517
   Sundberg J, 2011, IEEE T AFFECT COMPUT, V2, P162, DOI 10.1109/T-AFFC.2011.14
   Szameitat DP, 2010, NEUROIMAGE, V53, P1264, DOI 10.1016/j.neuroimage.2010.06.028
   Thayer RE., 1990, The Biopsychology of Mood and Activation
   Trost W., 2013, EMOTIONAL POWER MUSI
   Trost W, 2012, CEREB CORTEX, V22, P2769, DOI 10.1093/cercor/bhr353
   von Kriegstein K, 2008, CURR BIOL, V18, P1855, DOI 10.1016/j.cub.2008.10.052
   Vuilleumier P, 2005, TRENDS COGN SCI, V9, P585, DOI 10.1016/j.tics.2005.10.011
   Warren JE, 2006, J NEUROSCI, V26, P13067, DOI 10.1523/JNEUROSCI.3907-06.2006
   Warrier CM, 2011, HEARING RES, V282, P108, DOI 10.1016/j.heares.2011.09.001
   Watanabe T, 2008, NEUROIMAGE, V39, P483, DOI 10.1016/j.neuroimage.2007.08.024
   Wattendorf E, 2013, CEREB CORTEX, V23, P1280, DOI 10.1093/cercor/bhs094
   Weninger F, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00292
   WIESER HG, 1986, NEUROPSYCHOLOGIA, V24, P805, DOI 10.1016/0028-3932(86)90079-5
   Wiethoff S, 2008, NEUROIMAGE, V39, P885, DOI 10.1016/j.neuroimage.2007.09.028
   Wiethoff S, 2009, NEUROREPORT, V20, P1356, DOI 10.1097/WNR.0b013e328330eb83
   Wildgruber D, 2005, NEUROIMAGE, V24, P1233, DOI 10.1016/j.neuroimage.2004.10.034
   Wildgruber D, 2004, CEREB CORTEX, V14, P1384, DOI 10.1093/cercor/bhh099
   Wildgruber D, 2002, NEUROIMAGE, V15, P856, DOI 10.1006/nimg.2001.0998
   Williams H, 2004, ANN NY ACAD SCI, V1016, P1, DOI 10.1196/annals.1298.029
   Wittfoth M, 2010, CEREB CORTEX, V20, P383, DOI 10.1093/cercor/bhp106
   Zald DH, 2003, BRAIN RES REV, V41, P88, DOI 10.1016/S0165-0173(02)00248-5
   Zatorre RJ, 2013, P NATL ACAD SCI USA, V110, P10430, DOI 10.1073/pnas.1301228110
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
   Zentner M, 2010, MUSIC ANAL, V29, P102, DOI 10.1111/j.1468-2249.2011.00322.x
NR 198
TC 91
Z9 94
U1 3
U2 77
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0301-0082
EI 1873-5118
J9 PROG NEUROBIOL
JI Prog. Neurobiol.
PD DEC
PY 2014
VL 123
BP 1
EP 17
DI 10.1016/j.pneurobio.2014.09.003
PG 17
WC Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Neurosciences & Neurology
GA AZ1PL
UT WOS:000348010500001
PM 25291405
DA 2024-01-09
ER

PT J
AU Nussbaum, C
   Schirmer, A
   Schweinberger, SR
AF Nussbaum, Christine
   Schirmer, Annett
   Schweinberger, Stefan R.
TI Musicality - Tuned to the melody of vocal emotions
SO BRITISH JOURNAL OF PSYCHOLOGY
LA English
DT Article; Early Access
DE fundamental frequency (F0); musicality; parameter-specific voice
   morphing; timbre; vocal emotion perception
ID SPECTRUM QUOTIENT AQ; CONGENITAL AMUSIA; SPEECH PROSODY; VOICE QUALITY;
   AUTISM; PERCEPTION; EXPRESSION; BRAIN; COMMUNICATION; RECOGNITION
AB Musicians outperform non-musicians in vocal emotion perception, likely because of increased sensitivity to acoustic cues, such as fundamental frequency (F0) and timbre. Yet, how musicians make use of these acoustic cues to perceive emotions, and how they might differ from non-musicians, is unclear. To address these points, we created vocal stimuli that conveyed happiness, fear, pleasure or sadness, either in all acoustic cues, or selectively in either F0 or timbre only. We then compared vocal emotion perception performance between professional/semi-professional musicians (N = 39) and non-musicians (N = 38), all socialized in Western music culture. Compared to non-musicians, musicians classified vocal emotions more accurately. This advantage was seen in the full and F0-modulated conditions, but was absent in the timbre-modulated condition indicating that musicians excel at perceiving the melody (F0), but not the timbre of vocal emotions. Further, F0 seemed more important than timbre for the recognition of all emotional categories. Additional exploratory analyses revealed a link between time-varying F0 perception in music and voices that was independent of musical training. Together, these findings suggest that musicians are particularly tuned to the melody of vocal emotions, presumably due to a natural predisposition to exploit melodic patterns.
C1 [Nussbaum, Christine; Schirmer, Annett; Schweinberger, Stefan R.] Friedrich Schiller Univ, Inst Psychol, Dept Gen Psychol & Cognit Neurosci, Jena, Germany.
   [Nussbaum, Christine; Schweinberger, Stefan R.] Friedrich Schiller Univ, Voice Res Unit, Jena, Germany.
   [Schirmer, Annett] Univ Innsbruck, Inst Psychol, Innsbruck, Austria.
   [Schweinberger, Stefan R.] Univ Geneva, Swiss Ctr Affect Sci, Geneva, Switzerland.
   [Nussbaum, Christine] Friedrich Schiller Univ Jena, Dept Gen Psychol & Cognit Neurosci, Steiger 3-1, D-07743 Jena, Germany.
C3 Friedrich Schiller University of Jena; Friedrich Schiller University of
   Jena; University of Innsbruck; University of Geneva; Friedrich Schiller
   University of Jena
RP Nussbaum, C (corresponding author), Friedrich Schiller Univ Jena, Dept Gen Psychol & Cognit Neurosci, Steiger 3-1, D-07743 Jena, Germany.
EM christine.nussbaum@uni-jena.de
OI Nussbaum, Christine/0000-0003-2718-2898
FU German National Academic Foundation ('Studienstiftung des Deutschen
   Volkes')
FX C.N. has been supported by the German National Academic Foundation
   ('Studienstiftung des Deutschen Volkes').
CR Anikin A, 2020, PHONETICA, V77, P327, DOI 10.1159/000504855
   Arias P, 2021, EMOT REV, V13, P12, DOI 10.1177/1754073920934544
   Aubé W, 2015, SOC COGN AFFECT NEUR, V10, P399, DOI 10.1093/scan/nsu067
   Ayotte J, 2002, BRAIN, V125, P238, DOI 10.1093/brain/awf028
   BACHOROWSKI JA, 1995, PSYCHOL SCI, V6, P219, DOI 10.1111/j.1467-9280.1995.tb00596.x
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Bänziger T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0136675
   Baron-Cohen S, 2001, J AUTISM DEV DISORD, V31, P5, DOI 10.1023/A:1005653411471
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Boersma P., 2021, Glot International
   Bonnel A, 2003, J COGNITIVE NEUROSCI, V15, P226, DOI 10.1162/089892903321208169
   Breyer B., 2016, Zusammenstellung sozialwissenschaftlicher Items und Skalen, DOI DOI 10.6102/ZIS242
   Chartrand JP, 2006, NEUROSCI LETT, V405, P164, DOI 10.1016/j.neulet.2006.06.053
   Clark CN, 2015, SOC COGN AFFECT NEUR, V10, P444, DOI 10.1093/scan/nsu079
   Correia AI, 2022, EMOTION, V22, P894, DOI 10.1037/emo0000770
   Elmer S., 2018, The Oxford handbook of voice perception, P209
   Escoffier N, 2013, HUM BRAIN MAPP, V34, P1796, DOI 10.1002/hbm.22029
   Farmer E, 2020, MUSIC PERCEPT, V37, P323, DOI 10.1525/MP.2020.37.4.323
   Freitag C. M., 2007, Zeitschrift fur Klinische Psychologie und Psychotherapie, V36, P280, DOI [10.1026/1616-3443.36.4.280, DOI 10.1026/1616-3443.36.4.280]
   Frühholz S, 2015, CEREB CORTEX, V25, P2752, DOI 10.1093/cercor/bhu074
   Frühholz S, 2016, NEUROSCI BIOBEHAV R, V68, P96, DOI 10.1016/j.neubiorev.2016.05.002
   Fuller CD, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518765379
   Globerson E, 2013, ATTEN PERCEPT PSYCHO, V75, P1799, DOI 10.3758/s13414-013-0518-x
   Good A, 2017, EAR HEARING, V38, P455, DOI 10.1097/AUD.0000000000000402
   Grichkovtsova I, 2012, SPEECH COMMUN, V54, P414, DOI 10.1016/j.specom.2011.10.005
   Hallam S, 2017, LOND REV EDUC, V15, P388, DOI 10.18546/LRE.15.3.05
   Heaton P, 1998, MUSIC PERCEPT, V15, P291
   Hoekstra RA, 2008, J AUTISM DEV DISORD, V38, P1555, DOI 10.1007/s10803-008-0538-x
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kawahara H, 2008, INT CONF ACOUST SPEE, P3933, DOI 10.1109/ICASSP.2008.4518514
   Kawahara H., 2018, The Oxford Handbook of Voice Perception, P684
   Kawahara H., 2019, The Oxford Handbook of Voice Perception, P685
   Kawahara H, 2013, ASIAPAC SIGN INFO PR
   Kim S, 2015, COMMUN STAT APPL MET, V22, P665, DOI 10.5351/CSAM.2015.22.6.665
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Lagrois MÉ, 2019, CORTEX, V113, P229, DOI 10.1016/j.cortex.2018.11.036
   Lakens D., 2019, Simulation-based power-analysis for factorial ANOVA designs, DOI DOI 10.31234/OSF.IO/BAXSF
   Law LNC, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0052508
   Lima CF, 2016, SCI REP-UK, V6, DOI 10.1038/srep34911
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Lolli SL, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01340
   Martins I, 2022, COGN AFFECT BEHAV NE, V22, P1044, DOI 10.3758/s13415-022-01007-x
   Martins M, 2021, EMOT REV, V13, P199, DOI 10.1177/17540739211022035
   Morrison SJ, 2009, PROG BRAIN RES, V178, P67, DOI 10.1016/S0079-6123(09)17805-6
   Müllensiefan D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089642
   Nussbaum C, 2023, COGNITION EMOTION, V37, P731, DOI 10.1080/02699931.2023.2200920
   Nussbaum C, 2022, SOC COGN AFFECT NEUR, V17, P1145, DOI 10.1093/scan/nsac033
   Nussbaum C, 2022, COGNITION, V219, DOI 10.1016/j.cognition.2021.104967
   Nussbaum C, 2021, EMOT REV, V13, P211, DOI 10.1177/17540739211022803
   Peretz I, 2015, PHILOS T R SOC B, V370, P68, DOI 10.1098/rstb.2014.0090
   Piazza EA, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32018-9
   Pinheiro AP, 2015, BRAIN LANG, V140, P24, DOI 10.1016/j.bandl.2014.10.009
   Pralus A, 2019, NEUROPSYCHOLOGIA, V134, DOI [10.1016/j.neuropsychologia.2010.107234, 10.1016/j.neuropsychologia.2019.107234]
   R Core Team, 2018, R: A Language and Environment for Statistical Computing
   Rammstedt B, 2020, EUR J PSYCHOL ASSESS, V36, P149, DOI 10.1027/1015-5759/a000481
   Rigoulot S, 2015, NEUROSCIENCE, V290, P175, DOI 10.1016/j.neuroscience.2015.01.033
   Sauter DA, 2017, EMOT REV, V9, P222, DOI 10.1177/1754073916667236
   Schellenberg E. G., 2016, The Oxford handbook of music psychology, V2, P415
   Schellenberg EG, 2001, ANN NY ACAD SCI, V930, P355, DOI 10.1111/j.1749-6632.2001.tb05744.x
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Schirmer A, 2002, COGNITIVE BRAIN RES, V14, P228, DOI 10.1016/S0926-6410(02)00108-8
   Schirmer A, 2022, CURR OPIN BEHAV SCI, V44, DOI 10.1016/j.cobeha.2021.101100
   Schutz M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01402
   Shariff AF, 2011, CURR DIR PSYCHOL SCI, V20, P395, DOI 10.1177/0963721411424739
   Sivathasan S, 2022, MUSIC SCI, V26, P538, DOI 10.1177/1029864920988160
   Skuk VG, 2019, J AUTISM DEV DISORD, V49, P2747, DOI 10.1007/s10803-017-3039-y
   SMITH JC, 1978, SCIENCE, V201, P639, DOI 10.1126/science.675250
   Spackman MP, 2009, COGNITION EMOTION, V23, P1565, DOI 10.1080/02699930802536268
   Steinbeis N, 2011, J COGNITIVE NEUROSCI, V23, P604, DOI 10.1162/jocn.2009.21383
   Stewart L, 2006, BRAIN, V129, P2533, DOI 10.1093/brain/awl171
   Stoet G, 2017, TEACH PSYCHOL, V44, P24, DOI 10.1177/0098628316677643
   Stoet G, 2010, BEHAV RES METHODS, V42, P1096, DOI 10.3758/BRM.42.4.1096
   Strait DL, 2009, EUR J NEUROSCI, V29, P661, DOI 10.1111/j.1460-9568.2009.06617.x
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Thompson WF, 2012, P NATL ACAD SCI USA, V109, P19027, DOI 10.1073/pnas.1210344109
   Trimmer CG, 2008, EMOTION, V8, P838, DOI 10.1037/a0014080
   Twaite J. T., 2016, Examining relationships between basic emotion perception and musical training in the prosodic, facial, and lexical channels of communication and in music
   von Eiff CI, 2022, EAR HEARING, V43, P1178, DOI 10.1097/AUD.0000000000001181
   WAGNER HL, 1993, J NONVERBAL BEHAV, V17, P3, DOI 10.1007/BF00987006
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Weijkamp J, 2017, PSYCHOL MUSIC, V45, P204, DOI 10.1177/0305735616654216
   Wenhart T, 2019, MOL AUTISM, V10, DOI 10.1186/s13229-019-0272-6
   Wenhart T, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00031
   Yang D, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.746192
   Zentner M, 2017, ANN NY ACAD SCI, V1400, P33, DOI 10.1111/nyas.13410
NR 85
TC 1
Z9 1
U1 8
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0007-1269
EI 2044-8295
J9 BRIT J PSYCHOL
JI Br. J. Psychol.
PD 2023 OCT 18
PY 2023
DI 10.1111/bjop.12684
EA OCT 2023
PG 20
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA U6EP6
UT WOS:001085716900001
PM 37851369
OA hybrid
DA 2024-01-09
ER

PT J
AU Bhatara, A
   Laukka, P
   Levitin, DJ
AF Bhatara, Anjali
   Laukka, Petri
   Levitin, Daniel J.
TI Expression of emotion in music and vocal communication: Introduction to
   the research topic
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Editorial Material
DE music; speech; emotion; voice; cross-domain cognition
C1 [Bhatara, Anjali] Univ Paris 05, Sorbonne Paris Cite, Paris, France.
   [Bhatara, Anjali] CNRS, Lab Psychol Percept, UMR 8242, Paris, France.
   [Laukka, Petri] Stockholm Univ, Dept Psychol, S-10691 Stockholm, Sweden.
   [Levitin, Daniel J.] McGill Univ, Dept Psychol, Montreal, PQ, Canada.
C3 Universite Paris Cite; Centre National de la Recherche Scientifique
   (CNRS); CNRS - National Institute for Biology (INSB); Universite Paris
   Cite; Stockholm University; McGill University
RP Bhatara, A (corresponding author), Univ Paris 05, Sorbonne Paris Cite, Paris, France.
EM bhatara@gmail.com
RI Laukka, Petri/B-5259-2008; Levitin, Daniel/ACN-8897-2022
OI Laukka, Petri/0000-0001-8771-6818; Bhatara, Anjali/0000-0003-4856-9098
CR Allen R, 2013, FRONT PSYCHOL, V4, DOI [10.3389/fpsyg.2013.00156, 10.3389/fpsyg.2013.00890]
   Altenmüller E, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00114
   Bowling DL, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00464
   Bryant Gregory A, 2013, Front Psychol, V4, P990, DOI 10.3389/fpsyg.2013.00990
   Corbeil M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00372
   Droit-Volet S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00417
   Eerola T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00487
   Fitch WT, 2006, COGNITION, V100, P173, DOI 10.1016/j.cognition.2005.11.009
   Flaig NK, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00072
   Gabrielsson A, 2001, MUSIC SCI, V5, P123, DOI 10.1177/10298649020050S105
   Jürgens R, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00111
   Juslin PN, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00596
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Koeda M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00105
   Laukka P, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00353
   Loui P, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00675
   Margulis EH, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00167
   Paquette S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00509
   Paulmann S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00345
   Quinto L, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00184
   Rigoulot S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00367
   Russo FA, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00468
   Sauter DA, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00814
   Schellenberg EG, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00574
   Schubert E, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00837
   Spreckelmeyer KN, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00656
   Vieillard S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00711
   Waaramaa T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00344
   Wang DJ, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00351
   Weninger F, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00292
   Weusthoff S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00439
   Yanushevskaya I, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00335
NR 32
TC 8
Z9 8
U1 0
U2 36
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD MAY 5
PY 2014
VL 5
AR 399
DI 10.3389/fpsyg.2014.00399
PG 2
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA AH2UD
UT WOS:000335975900001
PM 24829557
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Weisgerber, A
   Vermeulen, N
   Peretz, I
   Samson, S
   Philippot, P
   Maurage, P
   D'Aoust, CD
   De Jaegere, A
   Delatte, B
   Gillain, B
   De Longueville, X
   Constant, E
AF Weisgerber, Anne
   Vermeulen, Nicolas
   Peretz, Isabelle
   Samson, Severine
   Philippot, Pierre
   Maurage, Pierre
   D'Aoust, Catherine De Graeuwe
   De Jaegere, Aline
   Delatte, Benoit
   Gillain, Benoit
   De Longueville, Xavier
   Constant, Eric
TI Facial, vocal and musical emotion recognition is altered in paranoid
   schizophrenic patients
SO PSYCHIATRY RESEARCH
LA English
DT Article
DE Schizophrenia; Emotion; Music; Face; Voice
ID SOCIAL COGNITION; IMPAIRMENTS; EXPRESSION; DEFICITS; PROSODY; VOICES;
   PEOPLE; AMUSIA; HAPPY
AB Disturbed processing of emotional faces and voices is typically observed in schizophrenia. This deficit leads to impaired social cognition and interactions. In this study, we investigated whether impaired processing of emotions also affects musical stimuli, which are widely present in daily life and known for their emotional impact. Thirty schizophrenic patients and 30 matched healthy controls evaluated the emotional content of musical, vocal and facial stimuli. Schizophrenic patients are less accurate than healthy controls in recognizing emotion in music, voices and faces. Our results confirm impaired recognition of emotion in voice and face stimuli in schizophrenic patients and extend this observation to the recognition of emotion in musical stimuli. (C) 2015 Elsevier Ireland Ltd. All rights reserved.
C1 [Weisgerber, Anne; Vermeulen, Nicolas; Philippot, Pierre; Maurage, Pierre; D'Aoust, Catherine De Graeuwe] Univ Catholique Louvain UCLouvain, Psychol Sci Res Inst IPSY, Louvain, Belgium.
   [Weisgerber, Anne] Natl Res Fund FNR, Luxembourg, Luxembourg.
   [Vermeulen, Nicolas; Maurage, Pierre] Fund Sci Res FRS FNRS, Brussels, Belgium.
   [Peretz, Isabelle] Univ Montreal, Int Lab Brain Mus & Sound Res BRAMS, Montreal, PQ H3C 3J7, Canada.
   [Samson, Severine] Univ Lille Nord France, Neuropsychol & Auditory Cognit, Lille, France.
   [De Jaegere, Aline] Univ Catholique Louvain UCLouvain, Dept Adult Psychiat, Inst Neurosci IoNS, B-1200 Brussels, Belgium.
   [Delatte, Benoit; De Longueville, Xavier] Psychiat Hosp Beau Vallon, Namur, Belgium.
   [Gillain, Benoit] Clin St Pierre, Ottignies, Belgium.
C3 Luxembourg National Research Fund; Fonds de la Recherche Scientifique -
   FNRS; Universite de Montreal; Universite de Lille - ISITE; Universite de
   Lille
RP Weisgerber, A (corresponding author), Catholic Univ Louvain, Psychol Sci Res Inst, Louvain, Belgium.
EM Anne.Weisgerber@uclouvain.be; Eric.Constant@uclouvain.be
RI Samson, Séverine/P-7417-2019
OI Samson, Séverine/0000-0002-4507-9440; Maurage,
   Pierre/0000-0003-0197-0810; /0000-0001-8966-6148
FU Special Research Fund of Catholic University of Louvain [FSR 1058.2011];
   Luxembourg National Research Fund [FNRL 5761586]
FX This work was supported by grants from the Special Research Fund of the
   Catholic University of Louvain (FSR 1058.2011) to Nicolas Vermeulen and
   the Luxembourg National Research Fund (FNRL 5761586) to Anne Weisgerber.
CR Andreasen NC, 1984, SCALE ASSESSMENT NEG
   [Anonymous], 1987, POSITIVE NEGATIVE SY
   BECK AT, 1961, ARCH GEN PSYCHIAT, V4, P561, DOI 10.1001/archpsyc.1961.01710120031004
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Brickenkamp R., 1969, MANUEL TEST D2 EDITE
   Brüne M, 2005, PSYCHIAT RES, V133, P135, DOI 10.1016/j.psychres.2004.10.007
   BRUNER GC, 1990, J MARKETING, V54, P94, DOI 10.1177/002224299005400408
   Bull M., 2007, Sound Moves: iPod Culture and Urban Experience
   Comparelli A, 2013, SCHIZOPHR RES, V143, P65, DOI 10.1016/j.schres.2012.11.005
   Constant EL, 2011, PSYCHIAT RES, V185, P315, DOI 10.1016/j.psychres.2009.08.026
   Couture SM, 2006, SCHIZOPHRENIA BULL, V32, pS44, DOI 10.1093/schbul/sbl029
   Dewhurst SA, 2000, EUR J COGN PSYCHOL, V12, P541, DOI 10.1080/095414400750050222
   Edwards Jane, 2001, Schizophrenia Research, V48, P235, DOI 10.1016/S0920-9964(00)00099-2
   Escoffier N, 2013, HUM BRAIN MAPP, V34, P1796, DOI 10.1002/hbm.22029
   Farhall J, 2007, CLIN PSYCHOL REV, V27, P476, DOI 10.1016/j.cpr.2006.12.002
   Gold C, 2005, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD004025.pub2
   Green MF, 2008, SCHIZOPHRENIA BULL, V34, P1211, DOI 10.1093/schbul/sbm145
   Hatada S, 2014, J PSYCHIATR NEUROSCI, V39, P118, DOI 10.1503/jpn.120207
   Hayashi N, 2002, PSYCHIAT CLIN NEUROS, V56, P187, DOI 10.1046/j.1440-1819.2002.00953.x
   Hoekert M, 2007, SCHIZOPHR RES, V96, P135, DOI 10.1016/j.schres.2007.07.023
   Hooker C, 2002, PSYCHIAT RES, V112, P41, DOI 10.1016/S0165-1781(02)00177-4
   Juslin PN, 2008, EMOTION, V8, P668, DOI 10.1037/a0013505
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kantrowitz JT, 2014, PSYCHOL MED, V44, P2739, DOI 10.1017/S0033291714000373
   KIRITA T, 1995, ACTA PSYCHOL, V89, P149, DOI 10.1016/0001-6918(94)00021-8
   Kornreich C, 2013, ADDICTION, V108, P80, DOI 10.1111/j.1360-0443.2012.03995.x
   Kring AM, 2013, ANNU REV CLIN PSYCHO, V9, P409, DOI 10.1146/annurev-clinpsy-050212-185538
   Kucharska-Pietura K, 2005, BRIT J PSYCHIAT, V187, P523, DOI 10.1192/bjp.187.6.523
   Leitman DI, 2007, AM J PSYCHIAT, V164, P474, DOI 10.1176/appi.ajp.164.3.474
   Leitman DI, 2010, SCHIZOPHRENIA BULL, V36, P545, DOI 10.1093/schbul/sbn115
   Leitman DI, 2005, BIOL PSYCHIAT, V58, P56, DOI 10.1016/j.biopsych.2005.02.034
   Maurage P, 2007, CLIN NEUROPHYSIOL, V118, P633, DOI 10.1016/j.clinph.2006.11.007
   Mermillod M, 2009, COGNITION, V110, P346, DOI 10.1016/j.cognition.2008.11.009
   Mier D, 2014, PSYCHIAT RES-NEUROIM, V221, P195, DOI 10.1016/j.pscychresns.2013.12.001
   Minato Miyuki, 2004, Occup Ther Int, V11, P177, DOI 10.1002/oti.205
   Miranda D., 2013, MUSIC HLTH WELLBEING, P513
   Miranda D, 2007, INT J ADOLESC YOUTH, V13, P285, DOI 10.1080/02673843.2007.9747981
   Morris RW, 2009, CURR OPIN PSYCHIATR, V22, P140, DOI 10.1097/YCO.0b013e328324f895
   Naranjo C, 2011, J AFFECT DISORDERS, V128, P243, DOI 10.1016/j.jad.2010.06.039
   North AC, 2004, MUSIC PERCEPT, V22, P41, DOI 10.1525/mp.2004.22.1.41
   North AC, 2006, SUICIDE LIFE-THREAT, V36, P582, DOI 10.1521/suli.2006.36.5.582
   Pinkham AE, 2003, AM J PSYCHIAT, V160, P815, DOI 10.1176/appi.ajp.160.5.815
   Pinkham AE, 2006, PSYCHIAT RES, V143, P167, DOI 10.1016/j.psychres.2005.09.005
   Putnam KM, 2007, PSYCHIAT RES, V151, P67, DOI 10.1016/j.psychres.2006.09.010
   Rossell SL, 2005, SCHIZOPHR RES, V78, P95, DOI 10.1016/j.schres.2005.06.002
   Saarikallio S, 2011, PSYCHOL MUSIC, V39, P307, DOI 10.1177/0305735610374894
   Skånland MS, 2013, INT J QUAL STUD HEAL, V8, DOI 10.3402/qhw.v8i0.20595
   Spielberger C. D., 1983, MANUAL FIR STATE TRA
   Thompson W., 2009, Music, thought, and feeling: Understanding the psychology of music
   van Goethem A, 2011, MUSIC SCI, V15, P208, DOI 10.1177/1029864911401174
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   Weisgerber A., 2013, MUSIC SOCIAL IMPACTS, P131
   Weiss MW, 2012, PSYCHOL SCI, V23, P1074, DOI 10.1177/0956797612442552
   Wen Y, 2014, SCHIZOPHR RES, V157, P60, DOI 10.1016/j.schres.2014.05.029
NR 54
TC 18
Z9 20
U1 0
U2 18
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0165-1781
J9 PSYCHIAT RES
JI Psychiatry Res.
PD SEP 30
PY 2015
VL 229
IS 1-2
BP 188
EP 193
DI 10.1016/j.psychres.2015.07.042
PG 6
WC Psychiatry
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Psychiatry
GA CQ7HC
UT WOS:000360772600026
PM 26210647
DA 2024-01-09
ER

PT J
AU Bänziger, T
   Hosoya, G
   Scherer, KR
AF Banziger, Tanja
   Hosoya, Georg
   Scherer, Klaus R.
TI Path Models of Vocal Emotion Communication
SO PLOS ONE
LA English
DT Article
ID MUSIC PERFORMANCE; LENS MODEL; CUE UTILIZATION; EXPRESSION; VOICE;
   ACCURACY; SPEECH; PERSPECTIVE; INFERENCES; INTENSITY
AB We propose to use a comprehensive path model of vocal emotion communication, encompassing encoding, transmission, and decoding processes, to empirically model data sets on emotion expression and recognition. The utility of the approach is demonstrated for two data sets from two different cultures and languages, based on corpora of vocal emotion enactment by professional actors and emotion inference by naive listeners. Lens model equations, hierarchical regression, and multivariate path analysis are used to compare the relative contributions of objectively measured acoustic cues in the enacted expressions and subjective voice cues as perceived by listeners to the variance in emotion inference from vocal expressions for four emotion families (fear, anger, happiness, and sadness). While the results confirm the central role of arousal in vocal emotion communication, the utility of applying an extended path modeling framework is demonstrated by the identification of unique combinations of distal cues and proximal percepts carrying information about specific emotion families, independent of arousal. The statistical models generated show that more sophisticated acoustic parameters need to be developed to explain the distal underpinnings of subjective voice quality percepts that account for much of the variance in emotion inference, in particular voice instability and roughness. The general approach advocated here, as well as the specific results, open up new research strategies for work in psychology (specifically emotion and social perception research) and engineering and computer science (specifically research and development in the domain of affective computing, particularly on automatic emotion detection and synthetic emotion expression in avatars).
C1 [Banziger, Tanja] Mid Sweden Univ, Dept Psychol, Ostersund, Sweden.
   [Hosoya, Georg] Free Univ Berlin, Dept Educ Sci & Psychol, Berlin, Germany.
   [Scherer, Klaus R.] Univ Geneva, Swiss Ctr Affect Sci, Geneva, Switzerland.
C3 Mid-Sweden University; Free University of Berlin; University of Geneva
RP Scherer, KR (corresponding author), Univ Geneva, Swiss Ctr Affect Sci, Geneva, Switzerland.
EM Klaus.Scherer@unige.ch
RI Hosoya, Georg/AAY-2498-2020
OI Hosoya, Georg/0000-0002-8130-2259
FU Swiss National Science Foundation [100014-122491]; European Research
   Council Advanced grant [230331]; European Research Council (ERC)
   [230331] Funding Source: European Research Council (ERC)
FX The research program as a whole was supported by funds from Swiss
   National Science Foundation grant (100014-122491) and European Research
   Council Advanced grant (no. 230331). The funders had no role in study
   design, data collection and analysis, decision to publish, or
   preparation of the manuscript.
CR Anderson C, 2012, J PERS SOC PSYCHOL, V103, P718, DOI 10.1037/a0029395
   Anolli L, 2008, J CROSS CULT PSYCHOL, V39, P565, DOI 10.1177/0022022108321178
   [Anonymous], 1988, ACTOR PREPARES
   BACHOROWSKI JA, 1995, PSYCHOL SCI, V6, P219, DOI 10.1111/j.1467-9280.1995.tb00596.x
   Bänziger T, 2014, J NONVERBAL BEHAV, V38, P31, DOI 10.1007/s10919-013-0165-x
   Bänziger T, 2012, EMOTION, V12, P1161, DOI 10.1037/a0025827
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Bernieri FJ, 2001, LEA SER PER CLIN PSY, P67
   Boersma P., 2021, Glot International
   Brunswik E., 1956, Perception and the representative design of psychological experiments, V2nd
   Cartei V, 2014, HORM BEHAV, V66, P569, DOI 10.1016/j.yhbeh.2014.08.006
   Chuenwattanapranithi S, 2008, PHONETICA, V65, P210, DOI 10.1159/000192793
   DUNCAN OD, 1966, AM J SOCIOL, V72, P1, DOI 10.1086/224256
   Eyben F, IEEE TRANSACTIONS ON
   GIFFORD R, 1994, J PERS SOC PSYCHOL, V66, P398, DOI 10.1037/0022-3514.66.2.398
   Goudbeek M, 2010, J ACOUST SOC AM, V128, P1322, DOI 10.1121/1.3466853
   HAMMOND KR, 1964, PSYCHOL REV, V71, P438, DOI 10.1037/h0040736
   Hawk ST, 2009, EMOTION, V9, P293, DOI 10.1037/a0015178
   Hirschmüller S, 2013, J PERS SOC PSYCHOL, V104, P335, DOI 10.1037/a0030383
   HURSCH CJ, 1964, PSYCHOL REV, V71, P42, DOI 10.1037/h0041729
   Juslin PN, 2006, J EXP PSYCHOL-APPL, V12, P79, DOI 10.1037/1076-898X.12.2.79
   Juslin PN, 2001, EMOTION, V1, P381, DOI 10.1037//1528-3542.1.4.381
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Juslin PN, 1997, MUSIC PERCEPT, V14, P383
   Juslin PN., 1998, FUNCTIONALIST PERSPE
   Kappas A, 1991, Fundamentals of nonverbal behavior, P200
   Karelaia N, 2008, PSYCHOL BULL, V134, P404, DOI 10.1037/0033-2909.134.3.404
   Ko SJ, 2015, PSYCHOL SCI, V26, P3, DOI 10.1177/0956797614553009
   Lei P.W., 2007, Educational Measurement: issues and practice, V26, P33, DOI DOI 10.1111/J.1745-3992.2007.00099.X
   Min CS, 2011, COGNITION EMOTION, V25, P1376, DOI 10.1080/02699931.2010.544865
   Muthen L. K., 1998, Mplus User's Guide, DOI 10.001316447803800111
   Nestler S, 2012, J PERS SOC PSYCHOL, V103, P689, DOI 10.1037/a0029461
   OHALA JJ, 1984, PHONETICA, V41, P1, DOI 10.1159/000261706
   Patel S, 2013, HANDB COMMUN SCI, V2, P167
   Patel S, 2011, BIOL PSYCHOL, V87, P93, DOI 10.1016/j.biopsycho.2011.02.010
   Reynolds DJ, 2001, PERS SOC PSYCHOL B, V27, P187, DOI 10.1177/0146167201272005
   Roesch E. B., 2010, BLUEPRINT AFFECTIVE, P271, DOI DOI 10.1037/A0025827
   Rule NO, 2013, J PERS SOC PSYCHOL, V104, P409, DOI 10.1037/a0031050
   Sauter DA, 2010, Q J EXP PSYCHOL, V63, P2251, DOI 10.1080/17470211003721642
   Scherer KR, 2013, STRUNGMANN FORUM REP, P107
   Scherer KR, 2011, INT J PSYCHOL, V46, P401, DOI 10.1080/00207594.2011.626049
   Scherer KR, 2009, COGNITION EMOTION, V23, P1307, DOI 10.1080/02699930902928969
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Scherer KR, 2003, SER AFFECTIVE SCI, P433
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   SCHERER KR, 1978, EUR J SOC PSYCHOL, V8, P467, DOI 10.1002/ejsp.2420080405
   Shuman V, 2013, FRONT PSYCHOL, V4, DOI [10.3389/fpsyg.2013.00261, 10.3389/fpsyg.2013.00922]
   Spackman MP, 2009, COGNITION EMOTION, V23, P1565, DOI 10.1080/02699930802536268
   TARTTER VC, 1980, PERCEPT PSYCHOPHYS, V27, P24, DOI 10.3758/BF03199901
   Thayer RE, 1978, Motivation and Emotion, V2, P1, DOI [10.1007/BF00992729, DOI 10.1007/BF00992729]
   TUCKER LR, 1964, PSYCHOL REV, V71, P528, DOI 10.1037/h0047061
   van Bezooijen R. A., 1984, THESIS
NR 54
TC 39
Z9 42
U1 1
U2 30
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD SEP 1
PY 2015
VL 10
IS 9
AR e0136675
DI 10.1371/journal.pone.0136675
PG 29
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Science & Technology - Other Topics
GA CQ2NK
UT WOS:000360437700055
PM 26325076
OA Green Submitted, Green Published, gold
DA 2024-01-09
ER

PT J
AU Juslin, PN
   Laukka, P
   Harmat, L
   Ovsiannikow, M
AF Juslin, Patrik N.
   Laukka, Petri
   Harmat, Laszlo
   Ovsiannikow, Melissa
TI Spontaneous Vocal Expressions From Everyday Life Convey Discrete
   Emotions to Listeners
SO EMOTION
LA English
DT Article
DE emotion; everyday life; nonverbal communication; speech; vocal
   expression
ID FACIAL EXPRESSIONS; SPEECH; COMMUNICATION; RECOGNITION; EXPERIENCE;
   INTENSITY; MUSIC; CUES; PERFORMANCE; STATES
AB Emotional expression is crucial for social interaction. Yet researchers disagree about whether nonverbal expressions truly reflect felt emotions and whether they convey discrete emotions to perceivers in everyday life. In the present study, 384 clips of vocal expression recorded in a field setting were rated by the speakers themselves and by naive listeners with regard to their emotional contents. Results suggested that most expressions in everyday life are reflective of felt emotions in speakers. Seventy-three percent of the voice clips involved moderate to high emotion intensity. Speaker-listener agreement concerning expressed emotions was 5 times higher than would be expected from chance alone, and agreement was significantly higher for voice clips with high emotion intensity than for clips with low intensity. Acoustic analysis of the clips revealed emotion-specific patterns of voice cues. "Mixed emotions" occurred in 41% of the clips. Such expressions were typically interpreted by listeners as conveying one or the other of the two felt emotions. Mixed emotions were rarely recognized as such. The results are discussed regarding their implications for the domain of emotional expression in general, and vocal expression in particular.
C1 [Juslin, Patrik N.; Ovsiannikow, Melissa] Uppsala Univ, Dept Psychol, Box 1225, SE-75142 Uppsala, Sweden.
   [Laukka, Petri] Stockholm Univ, Dept Psychol, Stockholm, Sweden.
   [Harmat, Laszlo] Linnaeus Univ, Dept Psychol, Vaxjo, Sweden.
C3 Uppsala University; Stockholm University; Linnaeus University
RP Juslin, PN (corresponding author), Uppsala Univ, Dept Psychol, Box 1225, SE-75142 Uppsala, Sweden.
EM patrik.juslin@psyk.uu.se
RI Laukka, Petri/B-5259-2008
OI Laukka, Petri/0000-0001-8771-6818; Harmat, Laszlo/0000-0002-9977-9506
FU Bank of Sweden Tercentenary Foundation [P12-0771:1]; Swedish Foundation
   for Humanities and Social Sciences [P12-0771:1] Funding Source: Swedish
   Foundation for Humanities and Social Sciences
FX The present research was supported by a grant from the Bank of Sweden
   Tercentenary Foundation to Patrik N. Juslin (P12-0771:1). We thank
   Goncalo Barradas for technical assistance with software programming.
CR Anikin A, 2017, BEHAV RES METHODS, V49, P758, DOI 10.3758/s13428-016-0736-y
   [Anonymous], 2006, SAGE HDB NONVERBAL C, DOI DOI 10.4135/9781412976152.N9
   [Anonymous], 2005, NEW HDB METHODS NONV
   [Anonymous], 1984, CHARACTERISTICS RECO, DOI DOI 10.1515/9783110850390
   Audibert N., 2010, SPEECH PROSODY
   BACHOROWSKI JA, 1995, PSYCHOL SCI, V6, P219, DOI 10.1111/j.1467-9280.1995.tb00596.x
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Barrett LF, 2001, SOC SCI COMPUT REV, V19, P175, DOI 10.1177/089443930101900204
   Barrett LF., 2017, How Emotions Are Made
   Barrett LF, 2019, PSYCHOL SCI PUBL INT, V20, P1, DOI 10.1177/1529100619832930
   Barrett LF, 2011, CURR DIR PSYCHOL SCI, V20, P400, DOI 10.1177/0963721411429125
   Berrios R, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00428
   Buck R, 2014, STUD EMO SO, P1, DOI 10.1017/CBO9781139049825
   Burkhardt F, 2018, LECT NOTES ARTIF INT, V11096, P76, DOI 10.1007/978-3-319-99579-3_9
   Carlson R., 1993, FONETIK 93, P65
   Cohen J, 1988, STAT POWER ANAL BEHA
   Cowie R, 2003, SPEECH COMMUN, V40, P5, DOI 10.1016/S0167-6393(02)00071-7
   COWIE R, 1999, ESCA TUT RES WORKSH, P41
   Darwin C., 1955, EXPRESS EMOT MAN
   Delacre M, 2019, INT REV SOC PSYCHOL, V32, DOI 10.5334/irsp.198
   Douglas-Cowie E, 2003, SPEECH COMMUN, V40, P33, DOI 10.1016/S0167-6393(02)00070-5
   Du SC, 2014, P NATL ACAD SCI USA, V111, pE1454, DOI 10.1073/pnas.1322355111
   Eibl-Eibesfeldt I., 1989, Human Ethology
   Ekman P., 1997, INNOVATIONS SOCIAL S, V10, P333, DOI [10.1080/13511610.1997.9968538, DOI 10.1080/13511610.1997.9968538]
   Ekman P., 1969, Semiotica, V1, P49, DOI [10.1515/semi.1969.1.1.49, DOI 10.1515/SEMI.1969.1.1.49]
   Ekman Pal, 1976, Semiotica, V16, P23, DOI [DOI 10.1515/SEMI.1976.16.1.23, 10.1515/semi.1976.16.1.23]
   ELDRED SH, 1958, PSYCHIATR, V21, P115
   Elfenbein HA, 2006, J NONVERBAL BEHAV, V30, P21, DOI 10.1007/s10919-005-0002-y
   Elfenbein HA, 2002, PSYCHOL BULL, V128, P203, DOI 10.1037//0033-2909.128.2.203
   Eyben F., 2013, P 21 ACM INT C MULT, P835, DOI 10.1145/2502081.2502224
   Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417
   Fox A.S., 2018, The Nature of Emotion: Fundamental Questions
   Frank MG, 2001, J PERS SOC PSYCHOL, V80, P75, DOI 10.1037/0022-3514.80.1.75
   Frank MG, 2005, NEW HDB METHODS NONV, P449
   FRIDLUND AJ, 1991, J PERS SOC PSYCHOL, V60, P229, DOI 10.1037/0022-3514.60.2.229
   Greasley P, 2000, LANG SPEECH, V43, P355, DOI 10.1177/00238309000430040201
   Grimm M, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P865, DOI 10.1109/ICME.2008.4607572
   Hair J. F., 1998, MULTIVARIATE DATA AN
   Harrigan J. A., 2005, NEW HDB METHODS NONV, P65, DOI DOI 10.1093/ACPROF:OSO/9780198529620.003.0003
   Hess U, 1997, J NONVERBAL BEHAV, V21, P241, DOI 10.1023/A:1024952730333
   Hevner K, 1935, PSYCHOL REV, V42, P186, DOI 10.1037/h0054832
   Jürgens R, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00180
   Jürgens U, 2002, NEUROSCI BIOBEHAV R, V26, P235, DOI 10.1016/S0149-7634(01)00068-9
   Juslin P. N., 2013, EVOLUTION EMOTIONAL, P252, DOI DOI 10.1093/ACPROF:OSO/9780199583560.003.0016
   Juslin Patrick N., 2019, Musical emotions explained: Unlocking the secrets of musical affect, DOI DOI 10.1093/OSO/9780198753421.001.0001
   Juslin PN, 2008, EMOTION, V8, P668, DOI 10.1037/a0013505
   Juslin PN, 2018, SCAND J PSYCHOL, V59, P105, DOI 10.1111/sjop.12429
   Juslin PN, 2018, J NONVERBAL BEHAV, V42, P1, DOI 10.1007/s10919-017-0268-x
   Juslin PN, 2001, EMOTION, V1, P381, DOI 10.1037//1528-3542.1.4.381
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   KRAUT RE, 1979, J PERS SOC PSYCHOL, V37, P1539, DOI 10.1037/0022-3514.37.9.1539
   Krebs J. R., 1984, BEHAV ECOLOGY EVOLUT, V2, P380, DOI DOI 10.1002/9780470015902.A0003217.PUB2
   KURODA I, 1976, AVIAT SPACE ENVIR MD, V47, P528
   Larsen JT, 2014, SOC PERSONAL PSYCHOL, V8, P263, DOI 10.1111/spc3.12108
   Larsen JT, 2001, J PERS SOC PSYCHOL, V81, P684, DOI 10.1037//0022-3514.81.4.684
   Laukka P, 2007, MOTIV EMOTION, V31, P182, DOI 10.1007/s11031-007-9063-z
   Little W., 2016, Introduction to sociology, V2nd Canadian Edition
   Marler P., 1977, ANIMALS COMMUNICATE, P45
   Mesquita B., 2015, INT ENCY SOCIAL BEHA, P542, DOI DOI 10.1016/B978-0-08-097086-8.24012-9
   Metsala JL, 2017, CHILD NEUROPSYCHOL, V23, P609, DOI 10.1080/09297049.2016.1205012
   Motley MT., 1988, Western Journal of Speech Communication, V52, P1, DOI [10.1080/10570318809389622, DOI 10.1080/10570318809389622]
   OATLEY K, 1994, COGNITION EMOTION, V8, P369, DOI 10.1080/02699939408408947
   Patel S, 2011, BIOL PSYCHOL, V87, P93, DOI 10.1016/j.biopsycho.2011.02.010
   Planalp S, 1996, COGNITION EMOTION, V10, P137, DOI 10.1080/026999396380303
   Plutchik R., 1980, EMOTION PSYCHOEVOLUT
   Plutchik Robert, 1994, The psychology and biology of emotion
   Reisberg D., 2004, MEMORY EMOTION, DOI [DOI 10.1093/ACPROF:OSO/9780195158564.003.0001, 10.1093/acprof:oso/9780195158564.003.0001, DOI 10.1093/ACPR0F:0S0/9780195158564.003.0001]
   ROESSLER R, 1976, J NERV MENT DIS, V163, P166, DOI 10.1097/00005053-197609000-00004
   RUSSELL JA, 1994, PSYCHOL BULL, V115, P102, DOI 10.1037/0033-2909.115.1.102
   Russell JA, 2003, ANNU REV PSYCHOL, V54, P329, DOI 10.1146/annurev.psych.54.101601.145102
   Sauter DA, 2018, COGNITION EMOTION, V32, P504, DOI 10.1080/02699931.2017.1320978
   Sauter DA, 2010, Q J EXP PSYCHOL, V63, P2251, DOI 10.1080/17470211003721642
   Scherer K. R., 2010, BLUEPRINT AFFECTIVE
   Scherer K. R., 2005, The new handbook of methods in nonverbal behavior research, P471
   Scherer K.R., 1999, HDB COGNITION EMOTIO, P637, DOI DOI 10.1002/0470013494.CH30
   Scherer KR, 2013, COMPUT SPEECH LANG, V27, P40, DOI 10.1016/j.csl.2011.11.003
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   SCHERER KR, 1972, J PSYCHOLINGUIST RES, V1, P269, DOI 10.1007/BF01074443
   SCHERER KR, 1985, ADV STUD BEHAV, V15, P189, DOI 10.1016/S0065-3454(08)60490-8
   Shariff AF, 2011, CURR DIR PSYCHOL SCI, V20, P395, DOI 10.1177/0963721411424739
   SPENCER H, 1857, FRASERS MAGAZINE, V56, P396, DOI DOI 10.1017/S0140525X08005293
   Teasdale JD, 1999, HDB COGNITION EMOTIO, P665
   WAGNER HL, 1993, J NONVERBAL BEHAV, V17, P3, DOI 10.1007/BF00987006
   WILLIAMS CE, 1972, J ACOUST SOC AM, V52, P1238, DOI 10.1121/1.1913238
   ZUCKERMAN M, 1979, J PERS, V47, P712, DOI 10.1111/j.1467-6494.1979.tb00217.x
NR 85
TC 3
Z9 3
U1 3
U2 14
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 1528-3542
EI 1931-1516
J9 EMOTION
JI Emotion
PD SEP
PY 2021
VL 21
IS 6
BP 1281
EP 1301
DI 10.1037/emo0000762
PG 21
WC Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA XL4ZP
UT WOS:000728153900019
PM 32940485
DA 2024-01-09
ER

PT J
AU Waaramaa, T
AF Waaramaa, Teija
TI Perception of emotional nonsense sentences in China, Egypt, Estonia,
   Finland, Russia, Sweden, and the USA
SO LOGOPEDICS PHONIATRICS VOCOLOGY
LA English
DT Article
DE Cross-cultural; emotion identification; gender; musical interests;
   nonsense text; voice quality
ID VOCAL EXPRESSION; SPEECH; VOCALIZATIONS; LISTENERS; VOICE
AB The present study focused on the identification of emotions in cross-cultural conditions on different continents and among subjects with divergent language backgrounds. The aim was to investigate whether the perception of the basic emotions from nonsense vocal samples was universal, dependent on voice quality, musicality, and/or gender. Listening tests for 350 participants were conducted on location in a variety of cultures: China, Egypt, Estonia, Finland, Russia, Sweden, and the USA. The results suggested that the voice quality parameters played a role in the identification of emotions without the linguistic content. Cultural background may affect the interpretation of the emotions more than the presumed universality. Musical interest tended to facilitate emotion identification. No gender differences were found.
C1 [Waaramaa, Teija] Univ Tampere, Sch Commun Media & Theatre, Kalevantie 4, Tampere 33014, Finland.
C3 Tampere University
RP Waaramaa, T (corresponding author), Univ Tampere, Sch Commun Media & Theatre, Kalevantie 4, Tampere 33014, Finland.
EM teija.waaramaa@uta.fi
FU Academy of Finland [139321]; Academy of Finland (AKA) [139321] Funding
   Source: Academy of Finland (AKA)
FX The author reports no conflicts of interest. Funding was been received
   from the Academy of Finland [grant no 139321].
CR [Anonymous], 1973, BRUEL KJAER TECH REV
   [Anonymous], 1984, DANCE LIFE OTHER DIM
   Damasio A, 2007, BRAIN MIND MED SOC C
   FONAGY I, 1981, RES ASPECTS SINGING, V33, P51
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Koeda M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00105
   Lallh AK, 2000, J SPEECH LANG HEAR R, V43, P782, DOI 10.1044/jslhr.4303.782
   Laukka P, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00353
   Laukkanen A. M., 1997, LOGOP PHONIATR VOCO, V22, P157, DOI DOI 10.3109/14015439709075330
   Leisio T, 2013, FRONTIERS EMOTION SC, DOI DOI 10.3389/FPSYG.2013.00344/FULL
   Nordenberg M, 2003, J TMH QPSR, V45, P93, DOI DOI 10.1080/14015430410004689
   Sauter DA, 2010, P NATL ACAD SCI USA, V107, P2408, DOI 10.1073/pnas.0908239106
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   Smith D, 2012, J ACOUST SOC AM, V131, P1480, DOI 10.1121/1.3672703
   Strait DL, 2009, EUR J NEUROSCI, V29, P661, DOI 10.1111/j.1460-9568.2009.06617.x
   Sundberg J, 2006, J ACOUST SOC AM, V120, P453, DOI 10.1121/1.2208451
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Trehub SE, 2003, NAT NEUROSCI, V6, P669, DOI 10.1038/nn1084
   Waaramaa Teija, 2006, Logoped Phoniatr Vocol, V31, P153, DOI 10.1080/14015430500456739
   Yanushevskaya I, 2005, P INT LISB PORT, P1849
   Yanushevskaya I, 2010, THESIS TRINITY COLL
   Yanushevskaya I, 2006, P SPEECH PROS 2 5 MA
   Yanushevskaya I, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00335
   zard C. E., 2007, PERSPECT PSYCHOL SCI, V2, P260
NR 24
TC 6
Z9 6
U1 0
U2 8
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1401-5439
EI 1651-2022
J9 LOGOP PHONIATR VOCO
JI Logop. Phoniatr. Vocology.
PD JUL 3
PY 2015
VL 40
IS 3
BP 129
EP 135
DI 10.3109/14015439.2014.915982
PG 7
WC Audiology & Speech-Language Pathology; Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Audiology & Speech-Language Pathology; Otorhinolaryngology
GA DD2PS
UT WOS:000369765300005
PM 24861103
DA 2024-01-09
ER

PT J
AU Nussbaum, C
   Schweinberger, SR
AF Nussbaum, Christine
   Schweinberger, Stefan R.
TI Links Between Musicality and Vocal Emotion Perception
SO EMOTION REVIEW
LA English
DT Article
DE amusia; musicality; musical training; vocal emotion perception
ID CONGENITAL AMUSIA; SPEECH PROSODY; BRAIN; RECOGNITION; EXPERTISE; VOICE;
   EXPRESSION; MUSICIANS; COMMUNICATION; PLASTICITY
AB Links between musicality and vocal emotion perception skills have only recently emerged as a focus of study. Here we review current evidence for or against such links. Based on a systematic literature search, we identified 33 studies that addressed either (a) vocal emotion perception in musicians and nonmusicians, (b) vocal emotion perception in individuals with congenital amusia, (c) the role of individual differences (e.g., musical interests, psychoacoustic abilities), or (d) effects of musical training interventions on both the normal hearing population and cochlear implant users. Overall, the evidence supports a link between musicality and vocal emotion perception abilities. We discuss potential factors moderating the link between emotions and music, and possible directions for future research.
C1 [Nussbaum, Christine; Schweinberger, Stefan R.] Friedrich Schiller Univ Jena, Dept Gen Psychol & Cognit Neurosci, Leutragraben 1, D-07743 Jena, Germany.
C3 Friedrich Schiller University of Jena
RP Nussbaum, C (corresponding author), Friedrich Schiller Univ Jena, Dept Gen Psychol & Cognit Neurosci, Leutragraben 1, D-07743 Jena, Germany.
EM christine.nussbaum@uni-jena.de
RI Schweinberger, Stefan/A-1860-2009; Nussbaum, Christine/AAV-3561-2021
OI Schweinberger, Stefan/0000-0001-5762-0188; Nussbaum,
   Christine/0000-0003-2718-2898
CR Aubé W, 2015, SOC COGN AFFECT NEUR, V10, P399, DOI 10.1093/scan/nsu067
   Ayotte J, 2002, BRAIN, V125, P238, DOI 10.1093/brain/awf028
   Baskent D, 2018, J ACOUST SOC AM, V143, pEL311, DOI 10.1121/1.5034489
   Bigand E, 2006, COGNITION, V100, P100, DOI 10.1016/j.cognition.2005.11.007
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Bodner E, 2012, J PSYCHOPATHOL BEHAV, V34, P458, DOI 10.1007/s10862-012-9304-7
   Chari DA, 2020, OTOL NEUROTOL, V41, pE422, DOI 10.1097/MAO.0000000000002525
   Chartrand JP, 2008, BRAIN RES, V1220, P191, DOI 10.1016/j.brainres.2008.01.014
   Cheung YL, 2021, CLIN LINGUIST PHONET, V35, P101, DOI 10.1080/02699206.2020.1719209
   Darwin G., 1871, P423
   Dibben N, 2018, FRONT BEHAV NEUROSCI, V12, DOI 10.3389/fnbeh.2018.00184
   Dmitrieva E S, 2006, Neurosci Behav Physiol, V36, P53, DOI 10.1007/s11055-005-0162-6
   ELBERT T, 1995, SCIENCE, V270, P305, DOI 10.1126/science.270.5234.305
   Elmer S., 2018, The Oxford handbook of voice perception, P209
   Escoffier N, 2013, HUM BRAIN MAPP, V34, P1796, DOI 10.1002/hbm.22029
   Fitch WT, 2013, BIRDSONG, SPEECH, AND LANGUAGE: EXPLORING THE EVOLUTION OF MIND AND BRAIN, P489
   Frühholz S, 2014, PROG NEUROBIOL, V123, P1, DOI 10.1016/j.pneurobio.2014.09.003
   Frühholz S, 2021, PROG NEUROBIOL, V199, DOI 10.1016/j.pneurobio.2020.101948
   Frühholz S, 2016, NEUROSCI BIOBEHAV R, V68, P96, DOI 10.1016/j.neubiorev.2016.05.002
   Fuller CD, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518765379
   Fuller CD, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00179
   Globerson E, 2013, ATTEN PERCEPT PSYCHO, V75, P1799, DOI 10.3758/s13414-013-0518-x
   Good A, 2017, EAR HEARING, V38, P455, DOI 10.1097/AUD.0000000000000402
   Grandjean D, 2021, EMOT REV, V13, P34, DOI 10.1177/1754073919898522
   Jiam NT, 2017, HEARING RES, V352, P30, DOI 10.1016/j.heares.2017.01.006
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kraus N, 2017, NEUROSCIENTIST, V23, P287, DOI 10.1177/1073858416653593
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Lagrois MÉ, 2019, CORTEX, V113, P229, DOI 10.1016/j.cortex.2018.11.036
   Lappe C, 2008, J NEUROSCI, V28, P9632, DOI 10.1523/JNEUROSCI.2254-08.2008
   Lehmann A, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00343
   Lima CF, 2016, SCI REP-UK, V6, DOI 10.1038/srep34911
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Lolli SL, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01340
   Merrete DL, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00606
   Mill A, 2009, EMOTION, V9, P619, DOI 10.1037/a0016562
   Mualem O, 2015, INT J MUSIC EDUC, V33, P413, DOI 10.1177/0255761415584292
   Nashkoff K., 2007, THESIS WALDEN U
   NILSONNE A, 1985, MUSIC PERCEPT, V2, P507
   Nolden S, 2017, NEUROPSYCHOLOGIA, V103, P96, DOI 10.1016/j.neuropsychologia.2017.07.014
   Palomar-García MA, 2017, CEREB CORTEX, V27, P2768, DOI 10.1093/cercor/bhw120
   Pantev C, 2011, NEUROSCI BIOBEHAV R, V35, P2140, DOI 10.1016/j.neubiorev.2011.06.010
   Paquette S, 2018, HEARING RES, V370, P272, DOI 10.1016/j.heares.2018.08.009
   Park M, 2015, FRONT HUM NEUROSCI, V8, DOI [10.3389/fnhurn.2014.01049, 10.3389/fnhum.2014.01049]
   Parsons CE, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01440
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Peretz I, 2003, ANN NY ACAD SCI, V999, P58, DOI 10.1196/annals.1284.006
   Petersen B., 2012, Psychomusicol Music Mind Brain, V22, P134, DOI DOI 10.1037/A0031140
   Phillips LH, 2010, PSYCHOL AGING, V25, P38, DOI 10.1037/a0017369
   Pinheiro AP, 2015, BRAIN LANG, V140, P24, DOI 10.1016/j.bandl.2014.10.009
   Pralus A, 2019, NEUROPSYCHOLOGIA, V134, DOI [10.1016/j.neuropsychologia.2010.107234, 10.1016/j.neuropsychologia.2019.107234]
   Rigoulot S, 2015, NEUROSCIENCE, V290, P175, DOI 10.1016/j.neuroscience.2015.01.033
   Sauter DA, 2017, EMOT REV, V9, P222, DOI 10.1177/1754073916667236
   Schäfer T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00511
   Schellenberg E. G., 2016, The Oxford handbook of music psychology, V2, P415
   Schellenberg EG, 2012, EMOTION, V12, P887, DOI 10.1037/a0027971
   Schellenberg EG, 2001, ANN NY ACAD SCI, V930, P355, DOI 10.1111/j.1749-6632.2001.tb05744.x
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   Schirmer A, 2005, NEUROREPORT, V16, P635, DOI 10.1097/00001756-200504250-00024
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   Schirmer A, 2012, NEUROIMAGE, V63, P137, DOI 10.1016/j.neuroimage.2012.06.025
   Schorr EA, 2009, J SPEECH LANG HEAR R, V52, P141, DOI 10.1044/1092-4388(2008/07-0213)
   Stewart L, 2006, BRAIN, V129, P2533, DOI 10.1093/brain/awl171
   Strait DL, 2009, EUR J NEUROSCI, V29, P661, DOI 10.1111/j.1460-9568.2009.06617.x
   Sun LJ, 2020, PSYCHOPHYSIOLOGY, V57, DOI 10.1111/psyp.13598
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Thompson WF, 2012, P NATL ACAD SCI USA, V109, P19027, DOI 10.1073/pnas.1210344109
   Trimmer CG, 2008, EMOTION, V8, P838, DOI 10.1037/a0014080
   Twaite J., 2016, THESIS CITY U NEW YO
   Waaramaa T, 2018, J SPEECH LANG HEAR R, V61, P973, DOI 10.1044/2017_JSLHR-H-17-0054
   Waaramaa T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00344
   Weijkamp J, 2017, PSYCHOL MUSIC, V45, P204, DOI 10.1177/0305735616654216
   Young AW, 2020, TRENDS COGN SCI, V24, P398, DOI 10.1016/j.tics.2020.02.001
   Young KS, 2012, EMOTION, V12, P1200, DOI 10.1037/a0028705
   Zhang YX, 2018, INTERSPEECH, P2196, DOI 10.21437/Interspeech.2018-91
NR 77
TC 8
Z9 8
U1 5
U2 25
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1754-0739
EI 1754-0747
J9 EMOT REV
JI Emot. Rev.
PD JUL
PY 2021
VL 13
IS 3
BP 211
EP 224
DI 10.1177/17540739211022803
PG 14
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA TG4NS
UT WOS:000671384100004
OA hybrid, Green Submitted
DA 2024-01-09
ER

PT J
AU Bowman, C
   Yamauchi, T
AF Bowman, Casady
   Yamauchi, Takashi
TI Processing emotions in sounds: cross-domain aftereffects of vocal
   utterances and musical sounds
SO COGNITION & EMOTION
LA English
DT Article
DE Auditory adaptation; music; speech; emotion; musical affect
ID FACIAL EXPRESSIONS; SPEECH PROSODY; PERCEPTION; LANGUAGE; VOICES; FACES;
   ANGRY; INTEGRATION; ADAPTATION; DIMENSIONS
AB Nonlinguistic signals in the voice and musical instruments play a critical role in communicating emotion. Although previous research suggests a common mechanism for emotion processing in music and speech, the precise relationship between the two domains is unclear due to the paucity of direct evidence. By applying the adaptation paradigm developed by Bestelmeyer, Rouger, DeBruine, and Belin [2010. Auditory adaptation in vocal affect perception. Cognition, 117(2), 217-223. doi: 10.1016/j.cognition.2010.08.008], this study shows cross-domain aftereffects from vocal to musical sounds. Participants heard an angry or fearful sound four times, followed by a test sound and judged whether the test sound was angry or fearful. Results show cross-domain aftereffects in one direction - vocal utterances to musical sounds, not vice-versa. This effect occurred primarily for angry vocal sounds. It is argued that there is a unidirectional relationship between vocal and musical sounds where emotion processing of vocal sounds encompasses musical sounds but not vice-versa.
C1 [Bowman, Casady; Yamauchi, Takashi] Texas A&M Univ, Dept Psychol, College Stn, TX 77843 USA.
C3 Texas A&M University System; Texas A&M University College Station
RP Yamauchi, T (corresponding author), Texas A&M Univ, Dept Psychol, College Stn, TX 77843 USA.
EM takashi-yamauchi@tamu.edu
RI Yamauchi, Takashi/GXM-8197-2022
OI Yamauchi, Takashi/0000-0002-6372-1118
CR [Anonymous], 1986, On the Origin of Language
   Aubé W, 2015, SOC COGN AFFECT NEUR, V10, P399, DOI 10.1093/scan/nsu067
   Ayotte J, 2002, BRAIN, V125, P238, DOI 10.1093/brain/awf028
   Bachorowski J.A., 2008, Handbook of Emotions, V3rd ed., P196
   Bachorowski JA, 2001, J ACOUST SOC AM, V110, P1581, DOI 10.1121/1.1391244
   Belin P, 2004, TRENDS COGN SCI, V8, P129, DOI 10.1016/j.tics.2004.01.008
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Bestelmeyer PEG, 2014, J NEUROSCI, V34, P8098, DOI 10.1523/JNEUROSCI.4820-13.2014
   Bestelmeyer PEG, 2010, COGNITION, V117, P217, DOI 10.1016/j.cognition.2010.08.008
   Bowman C., 2015, PSYCHOMUSICOLOGY MUS, V26, P15
   Bowman C, 2015, INT CONF AFFECT, P670, DOI 10.1109/ACII.2015.7344641
   Byrd M., 2012, P 34 ANN C COGN SCI, P1392
   Carver CS, 2000, PERS SOC PSYCHOL B, V26, P741, DOI 10.1177/0146167200268008
   Coutinho E, 2013, COGNITION EMOTION, V27, P658, DOI 10.1080/02699931.2012.732559
   Eder AB, 2013, EMOT REV, V5, P227, DOI 10.1177/1754073913477990
   Eerola T, 2013, MUSIC PERCEPT, V30, P307, DOI [10.1525/mp.2012.30.3.307, 10.1525/MP.2012.30.1.49]
   Fedorenko E, 2009, MEM COGNITION, V37, P1, DOI 10.3758/MC.37.1.1
   Frühholz S, 2014, PROG NEUROBIOL, V123, P1, DOI 10.1016/j.pneurobio.2014.09.003
   Frühholz S, 2013, CORTEX, V49, P1394, DOI 10.1016/j.cortex.2012.08.003
   Helmholtz Hermann von, 1885, On the sensations of tone as a physiological basis for the theory of music
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kandel E., 2001, PRINCIPLES NEURAL SC
   Kawahara H, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P256
   Klinge C, 2010, BRAIN, V133, P1729, DOI 10.1093/brain/awq102
   Levy DA, 2001, NEUROREPORT, V12, P2653, DOI 10.1097/00001756-200108280-00013
   Levy DA, 2003, PSYCHOPHYSIOLOGY, V40, P291, DOI 10.1111/1469-8986.00031
   Patel A.D., 2009, OXFORD HDB MUSIC PSY
   Patel AD, 2003, NAT NEUROSCI, V6, P674, DOI 10.1038/nn1082
   Peretz I., 2012, LANGUAGE MUSIC COGNI, P254
   Peretz Isabelle, 2015, PHILOS T R SOC B, V370, DOI DOI 10.3389/FNHUM.2015.00330
   Pollak SD, 2000, DEV PSYCHOL, V36, P679, DOI 10.1037//0012-1649.36.5.679
   Rogalsky C, 2011, J NEUROSCI, V31, P3843, DOI 10.1523/JNEUROSCI.4515-10.2011
   Schachner A, 2011, DEV PSYCHOL, V47, P19, DOI 10.1037/a0020740
   Springer US, 2007, EMOTION, V7, P516, DOI 10.1037/1528-3542.7.3.516
   Strauss MM, 2005, NEUROIMAGE, V26, P389, DOI 10.1016/j.neuroimage.2005.01.053
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Vaish A, 2008, PSYCHOL BULL, V134, P383, DOI 10.1037/0033-2909.134.3.383
   Wang XH, 2016, INT J CHEM ENG, V2016, DOI 10.1155/2016/5217802
   Wilkowski BM, 2010, J PERS SOC PSYCHOL, V98, P201, DOI 10.1037/a0017992
NR 40
TC 3
Z9 3
U1 0
U2 12
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 0269-9931
EI 1464-0600
J9 COGNITION EMOTION
JI Cogn. Emot.
PY 2017
VL 31
IS 8
BP 1610
EP 1626
DI 10.1080/02699931.2016.1255588
PG 17
WC Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA FO2KB
UT WOS:000416604600008
PM 27848281
DA 2024-01-09
ER

PT J
AU Lim, A
   Okuno, HG
AF Lim, Angelica
   Okuno, Hiroshi G.
TI The MEI Robot: Towards Using Motherese to Develop Multimodal Emotional
   Intelligence
SO IEEE TRANSACTIONS ON AUTONOMOUS MENTAL DEVELOPMENT
LA English
DT Article
DE Cross-modal recognition; emotion recognition; gait; gaussian mixture;
   gesture; motherese; SIRE; voice
ID EXPRESSIVE BEHAVIORS; FACIAL EXPRESSION; VOCAL EXPRESSIONS; BODY
   MOVEMENT; PERCEPTION; RECOGNITION; SPEECH; LANGUAGE; INFANTS; MUSIC
AB We introduce the first steps in a developmental robot called MEI (multimodal emotional intelligence), a robot that can understand and express emotions in voice, gesture and gait using a controller trained only on voice. Whereas it is known that humans can perceive affect in voice, movement, music and even as little as point light displays, it is not clear how humans develop this skill. Is it innate? If not, how does this emotional intelligence develop in infants? The MEI robot develops these skills through vocal input and perceptual mapping of vocal features to other modalities. We base MEI's development on the idea that motherese is used as a way to associate dynamic vocal contours to facial emotion from an early age. MEI uses these dynamic contours to both understand and express multimodal emotions using a unified model called SIRE (Speed, Intensity, irRegularity, and Extent). Offline experiments with MEI support its cross-modal generalization ability: a model trained with voice data can recognize happiness, sadness, and fear in a completely different modality-human gait. User evaluations of the MEI robot speaking, gesturing and walking show that it can reliably express multimodal happiness and sadness using only the voice-trained model as a basis.
C1 [Lim, Angelica; Okuno, Hiroshi G.] Kyoto Univ, Grad Sch Informat, Kyoto 6068501, Japan.
C3 Kyoto University
RP Lim, A (corresponding author), Kyoto Univ, Grad Sch Informat, Kyoto 6068501, Japan.
EM angelica@kuis.kyoto-u.ac.jp; okuno@kuis.kyoto-u.ac.jp
RI Okuno, Hiroshi G./S-3130-2018
OI Okuno, Hiroshi G./0000-0002-8704-4318
FU KAKENHI [24220006]; Honda Research Institute Japan
FX This work was supported by KAKENHI (S) 24220006 and the Honda Research
   Institute Japan.
CR Amaya K, 1996, PROC GRAPH INTERF, P222
   [Anonymous], 2000, Handbook of Emotions
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Beck Aryel, 2010, P 3 INT WORKSH AFF I, P37
   Bernhardt D, 2009, LECT NOTES COMPUT SC, V5857, P1, DOI 10.1007/978-3-642-05036-7_1
   Bhaykar M., 2013, 2013 NAT C COMM NCC, P1, DOI [DOI 10.1109/NCC.2013.6487998, 10.1109/NCC.2013.6487998]
   Bishop C.M., 2006, J. Electron. Imaging, V4, P738
   Boucenna S, 2010, IEEE INT C INT ROBOT, P5323, DOI 10.1109/IROS.2010.5650357
   Breazeal C., 2004, Designing sociable robots
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Burkhardt F, 2005, 9 EUR C SPEECH COMM, V5, P1517, DOI [10.21437/Interspeech.2005-446, DOI 10.21437/INTERSPEECH.2005-446]
   Campos JJ, 2000, INFANCY, V1, P149, DOI 10.1207/S15327078IN0102_1
   Camurri A, 2005, IEEE MULTIMEDIA, V12, P43, DOI 10.1109/MMUL.2005.2
   Castellano G, 2007, LECT NOTES COMPUT SC, V4738, P71
   Choi JJ, 2013, ACMIEEE INT CONF HUM, P105, DOI 10.1109/HRI.2013.6483523
   Clarke TJ, 2005, PERCEPTION, V34, P1171, DOI 10.1068/p5203
   Clynes M, 1977, SENTICS TOUCH EMOTIO
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   FERNALD A, 1989, CHILD DEV, V60, P1497, DOI 10.2307/1130938
   FERNALD A, 1993, CHILD DEV, V64, P657, DOI 10.1111/j.1467-8624.1993.tb02934.x
   FERNALD A, 1989, J CHILD LANG, V16, P477, DOI 10.1017/S0305000900010679
   Fernandez Raul, 2005, INTERSPEECH, P473
   Flom R, 2008, INFANT BEHAV DEV, V31, P716, DOI 10.1016/j.infbeh.2008.04.004
   GALLAHER PE, 1992, J PERS SOC PSYCHOL, V63, P133, DOI 10.1037/0022-3514.63.1.133
   Grossmann T, 2006, DEVELOPMENTAL SCI, V9, P309, DOI 10.1111/j.1467-7687.2006.00494.x
   Grossmann T, 2010, RESTOR NEUROL NEUROS, V28, P219, DOI 10.3233/RNN-2010-0499
   Gunes Hatice, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P827, DOI 10.1109/FG.2011.5771357
   Janssen D, 2008, J NONVERBAL BEHAV, V32, P79, DOI 10.1007/s10919-007-0045-3
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Karg M., 2009, P MLDM, P51
   Karg M, 2010, IEEE T SYST MAN CY B, V40, P1050, DOI 10.1109/TSMCB.2010.2044040
   Kim Youngmoo E, 2010, P ISMIR, P255
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Kuji K., 2009, ADV CONSUMER STUDIES, V15, P57
   Lewis M. M., 1936, INFANT SPEECH STUDY
   Lim Angelica, 2012, Human Behavior Understanding. Proceedings of the Third International Workshop, HBU 2012, P52, DOI 10.1007/978-3-642-34014-7_5
   Lim Angelica, 2011, 2011 11th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2011), P472, DOI 10.1109/Humanoids.2011.6100891
   Lim A, 2012, EURASIP J AUDIO SPEE, P1, DOI 10.1186/1687-4722-2012-3
   Lim HO, 2004, ROBOTICA, V22, P577, DOI 10.1017/S0263574704000372
   Littlewort G., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P298, DOI 10.1109/FG.2011.5771414
   Livingstone SR, 2010, COMPUT MUSIC J, V34, P41, DOI 10.1162/comj.2010.34.1.41
   Ma YL, 2006, BEHAV RES METHODS, V38, P134, DOI 10.3758/BF03192758
   Mancini M., 2007, P DOCT CONS INT C AF
   MEHRABIAN A, 1995, GENET SOC GEN PSYCH, V121, P339
   Mion L, 2008, IEEE T AUDIO SPEECH, V16, P458, DOI 10.1109/TASL.2007.913743
   Montepare J, 1999, J NONVERBAL BEHAV, V23, P133, DOI 10.1023/A:1021435526134
   MONTEPARE JM, 1987, J NONVERBAL BEHAV, V11, P33, DOI 10.1007/BF00999605
   Nakadai K, 2010, ADV ROBOTICS, V24, P739, DOI 10.1163/016918610X493561
   NELSON DGK, 1989, J CHILD LANG, V16, P55, DOI 10.1017/S030500090001343X
   Ortony A., 1990, The Cognitive Structure of Emotions
   Oudeyer P, 2002, SPEECH PROS 2002 INT
   Peipei Shen, 2011, 2011 International Conference on Electronic & Mechanical Engineering and Information Technology (EMEIT 2011), P621, DOI 10.1109/EMEIT.2011.6023178
   Pelachaud C, 2009, SPEECH COMMUN, V51, P630, DOI 10.1016/j.specom.2008.04.009
   PETERSON LR, 1959, J EXP PSYCHOL, V58, P193, DOI 10.1037/h0049234
   Pollick FE, 2001, COGNITION, V82, pB51, DOI 10.1016/S0010-0277(01)00147-0
   Polzehl T., 2010, P SPEECH PROS
   Roether CL, 2009, J VISION, V9, DOI 10.1167/9.6.15
   Rolls ET, 2000, BEHAV BRAIN SCI, V23, P177, DOI 10.1017/S0140525X00002429
   Russell JA, 2003, ANNU REV PSYCHOL, V54, P329, DOI 10.1146/annurev.psych.54.101601.145102
   Saint-Georges Catherine, 2013, PLoS One, V8, pe78103, DOI 10.1371/journal.pone.0078103
   Scheiner E, 2002, J VOICE, V16, P509, DOI 10.1016/S0892-1997(02)00127-3
   Scherer K., 2000, INTERSPEECH, V2, P379
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Sievers B, 2013, P NATL ACAD SCI USA, V110, P70, DOI 10.1073/pnas.1209023110
   Snowdon CT, 2003, SER AFFECTIVE SCI, P457
   SOKEN NH, 1992, CHILD DEV, V63, P787
   Somervuo P, 1999, NEURAL PROCESS LETT, V10, P151, DOI 10.1023/A:1018741720065
   Spector F, 2009, DEV PSYCHOL, V45, P175, DOI 10.1037/a0014171
   SPENCER H, 1857, FRASERS MAGAZINE, V56, P396, DOI DOI 10.1017/S0140525X08005293
   Trainor LJ, 2000, PSYCHOL SCI, V11, P188, DOI 10.1111/1467-9280.00240
   Unuma M., 1995, P ANN C COMP GRAPH I, P91
   VANBEZOOIJEN R, 1983, J CROSS CULT PSYCHOL, V14, P387, DOI 10.1177/0022002183014004001
   WalkerAndrews AS, 1997, PSYCHOL BULL, V121, P437, DOI 10.1037/0033-2909.121.3.437
   Watanabe A, 2007, J ROBOT MECHATRON, V19, P315, DOI 10.20965/jrm.2007.p0315
   Zecca Massimiliano, 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P381, DOI 10.1109/ROMAN.2009.5326184
NR 79
TC 23
Z9 25
U1 1
U2 28
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1943-0604
EI 1943-0612
J9 IEEE T AUTON MENT DE
JI IEEE Trans. Auton. Ment. Dev.
PD JUN
PY 2014
VL 6
IS 2
SI SI
BP 126
EP 138
DI 10.1109/TAMD.2014.2317513
PG 13
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Robotics; Neurosciences & Neurology
GA AJ7SX
UT WOS:000337898500005
DA 2024-01-09
ER

PT J
AU Loui, P
   Bachorik, JP
   Li, HC
   Schlaug, G
AF Loui, Psyche
   Bachorik, Justin P.
   Li, H. Charles
   Schlaug, Gottfried
TI Effects of voice on emotional arousal
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE emotion; music; arousal; perception; gender; aging
ID VOCAL EXPRESSION; MUSIC PREFERENCES; TIME-COURSE; SPEECH; RECOGNITION;
   DIMENSIONS; PERCEPTION; RESPONSES; BRAIN; PITCH
AB Music is a powerful medium capable of eliciting a broad range of emotions. Although the relationship between language and music is well documented, relatively little is known about the effects of lyrics and the voice on the emotional processing of music and on listeners' preferences. In the present study, we investigated the effects of vocals in music on participants' perceived valence and arousal in songs. Participants (N = 50) made valence and arousal ratings for familiar songs that were presented with and without the voice. We observed robust effects of vocal content on perceived arousal. Furthermore, we found that the effect of the voice on enhancing arousal ratings is independent of familiarity of the song and differs across genders and age: females were more influenced by vocals than males; furthermore these gender effects were enhanced among older adults. Results highlight the effects of gender and aging in emotion perception and are discussed in terms of the social roles of music.
C1 [Loui, Psyche; Bachorik, Justin P.; Li, H. Charles; Schlaug, Gottfried] Beth Israel Deaconess Med Ctr, Dept Neurol, Boston, MA 02215 USA.
   [Loui, Psyche; Bachorik, Justin P.; Li, H. Charles; Schlaug, Gottfried] Harvard Univ, Sch Med, Boston, MA USA.
   [Loui, Psyche] Wesleyan Univ, Dept Psychol, Middletown, CT 06459 USA.
C3 Harvard University; Beth Israel Deaconess Medical Center; Harvard
   University; Harvard Medical School; Wesleyan University
RP Loui, P (corresponding author), Wesleyan Univ, Dept Psychol, Judd Hall 104,207 High St, Middletown, CT 06459 USA.
EM ploui@wesleyan.edu
OI Loui, Psyche/0000-0001-7664-6092
CR Bachorik JP, 2009, MUSIC PERCEPT, V26, P355, DOI 10.1525/MP.2009.26.4.355
   BACHOROWSKI JA, 1995, PSYCHOL SCI, V6, P219, DOI 10.1111/j.1467-9280.1995.tb00596.x
   Bagley AD, 2009, J ABNORM PSYCHOL, V118, P388, DOI 10.1037/a0015372
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Besson M, 1998, PSYCHOL SCI, V9, P494, DOI 10.1111/1467-9280.00091
   Bigand E, 2005, ANN NY ACAD SCI, V1060, P429, DOI 10.1196/annals.1360.036
   Bryant GA, 2008, J COGN CULT, V8, P135, DOI 10.1163/156770908X289242
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Fairbanks G, 1938, SCIENCE, V88, P382, DOI 10.1126/science.88.2286.382
   Gosselin N, 2007, NEUROPSYCHOLOGIA, V45, P236, DOI 10.1016/j.neuropsychologia.2006.07.012
   Grewe O, 2007, EMOTION, V7, P774, DOI 10.1037/1528-3542.7.4.774
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Krumhansl CL, 1997, CAN J EXP PSYCHOL, V51, P336, DOI 10.1037/1196-1961.51.4.336
   Laukka P, 2005, COGNITION EMOTION, V19, P633, DOI 10.1080/02699930441000445
   Nagel F, 2007, BEHAV RES METHODS, V39, P283, DOI 10.3758/BF03193159
   Panksepp J, 2002, BEHAV PROCESS, V60, P133, DOI 10.1016/S0376-6357(02)00080-3
   PERROT D, 1999, P 1999 SOC MUS PERC
   Rentfrow PJ, 2006, PSYCHOL SCI, V17, P236, DOI 10.1111/j.1467-9280.2006.01691.x
   Rentfrow PJ, 2003, J PERS SOC PSYCHOL, V84, P1236, DOI 10.1037/0022-3514.84.6.1236
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Sammler D, 2007, PSYCHOPHYSIOLOGY, V44, P293, DOI 10.1111/j.1469-8986.2007.00497.x
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Schirmer A, 2008, PSYCHONEUROENDOCRINO, V33, P718, DOI 10.1016/j.psyneuen.2008.02.010
   Schubert E, 2004, MUSIC PERCEPT, V21, P561, DOI 10.1525/mp.2004.21.4.561
   Schubert E, 1999, AUST J PSYCHOL, V51, P154, DOI 10.1080/00049539908255353
   Serafine M. L., 1982, J ACOUST SOC AM, V72, pS45, DOI [10.1121/1.2019896, DOI 10.1121/1.2019896]
   Shipley WC, 1940, J PSYCHOL, V9, P371, DOI 10.1080/00223980.1940.9917704
   Skinner ER, 1935, SPEECH MONOGR, V2, P81, DOI 10.1080/03637753509374833
   Sloboda J. A., 1991, Psychology of Music, V19, P110, DOI [10.1177/0305735691192002, DOI 10.1177/0305735691192002]
   Steinbeis N, 2006, J COGNITIVE NEUROSCI, V18, P1380, DOI 10.1162/jocn.2006.18.8.1380
   Terwogt M. M., 1991, PSYCHOL MUSIC, V19, P99, DOI DOI 10.1177/0305735691192001
   Trainor LJ, 2000, PSYCHOL SCI, V11, P188, DOI 10.1111/1467-9280.00240
   Vines BW, 2005, ANN NY ACAD SCI, V1060, P462, DOI 10.1196/annals.1360.052
   Weiss MW, 2012, PSYCHOL SCI, V23, P1074, DOI 10.1177/0956797612442552
NR 34
TC 19
Z9 26
U1 1
U2 28
PU FRONTIERS RESEARCH FOUNDATION
PI LAUSANNE
PA PO BOX 110, LAUSANNE, 1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD OCT 1
PY 2013
VL 4
AR 675
DI 10.3389/fpsyg.2013.00675
PG 6
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA AA6UR
UT WOS:000331234200001
PM 24101908
OA gold, Green Published
DA 2024-01-09
ER

PT J
AU Bedoya, D
   Arias, P
   Rachman, L
   Liuni, M
   Canonne, C
   Goupil, L
   Aucouturier, JJ
AF Bedoya, D.
   Arias, P.
   Rachman, L.
   Liuni, M.
   Canonne, C.
   Goupil, L.
   Aucouturier, J-J
TI Even violins can cry: specifically vocal emotional behaviours also drive
   the perception of emotions in non-vocal music
SO PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY B-BIOLOGICAL SCIENCES
LA English
DT Article
DE voice; music; emotions
ID NONLINEAR PHENOMENA; SPEECH PROSODY; EXPRESSION; CUES; REPRESENTATIONS;
   COMMUNICATION; RECOGNITION; SPEAKING; CONTEXT; SOUND
AB A wealth of theoretical and empirical arguments have suggested that music triggers emotional responses by resembling the inflections of expressive vocalizations, but have done so using low-level acoustic parameters (pitch, loudness, speed) that, in fact, may not be processed by the listener in reference to human voice. Here, we take the opportunity of the recent availability of computational models that allow the simulation of three specifically vocal emotional behaviours: smiling, vocal tremor and vocal roughness. When applied to musical material, we find that these three acoustic manipulations trigger emotional perceptions that are remarkably similar to those observed on speech and scream sounds, and identical across musician and non-musician listeners. Strikingly, this not only applied to singing voice with and without musical background, but also to purely instrumental material. This article is part of the theme issue 'Voice modulation: from origin and mechanism to social impact (Part I)'.
C1 [Bedoya, D.; Arias, P.; Canonne, C.] Sorbonne Univ, Sci & Technol Mus & Sound, CNRS, IRCAM, Paris, France.
   [Arias, P.] Lund Univ, Dept Cognit Sci, Lund, Sweden.
   [Rachman, L.] Univ Groningen, Fac Med Sci, Groningen, Netherlands.
   [Liuni, M.] Alta Voce SAS, Houilles, France.
   [Goupil, L.] Univ East London, BabyDevLab, London, England.
   [Aucouturier, J-J] Univ Bourgogne Franche Comte, FEMTO ST Inst, CNRS, Besancon, France.
C3 Sorbonne Universite; Centre National de la Recherche Scientifique
   (CNRS); Lund University; University of Groningen; University of East
   London; Universite de Franche-Comte; Universite de Technologie de
   Belfort-Montbeliard (UTBM); Centre National de la Recherche Scientifique
   (CNRS)
RP Aucouturier, JJ (corresponding author), Univ Bourgogne Franche Comte, FEMTO ST Inst, CNRS, Besancon, France.
EM aucouturier@gmail.com
RI Bedoya, Daniel/IVV-2933-2023
OI Goupil, Louise/0000-0003-4342-9408; Arias Sarah,
   Pablo/0000-0002-4868-120X
FU European Research Council [335634]; Agence Nationale de la Recherche
   grant; Fondation Pour l'Audition (FPA) [RD-2018-2]
FX This study was funded by a European Research Council Starting Grant
   (CREAM 335634), an Agence Nationale de la Recherche grant (REFLETS,
   SEPIA), and Fondation Pour l'Audition (FPA RD-2018-2).
CR Anikin A, 2020, ROY SOC OPEN SCI, V7, DOI 10.1098/rsos.201306
   Anikin A, 2020, PHONETICA, V77, P327, DOI 10.1159/000504855
   Anikin A, 2020, BIOACOUSTICS, V29, P226, DOI 10.1080/09524622.2019.1581839
   Anikin A, 2019, ATTEN PERCEPT PSYCHO, V81, P764, DOI 10.3758/s13414-018-01639-7
   Anikin A, 2019, BEHAV RES METHODS, V51, P778, DOI 10.3758/s13428-018-1095-7
   [Anonymous], 1874, DESCENT MAN SELECTIO
   [Anonymous], 2001, GLOT INT
   Arias P, 2021, EMOT REV, V13, P12, DOI 10.1177/1754073920934544
   Arias P, 2020, IEEE T AFFECT COMPUT, V11, P507, DOI 10.1109/TAFFC.2018.2811465
   Arias P, 2018, CURR BIOL, V28, pR782, DOI 10.1016/j.cub.2018.05.084
   Arnal LH, 2015, CURR BIOL, V25, P2051, DOI 10.1016/j.cub.2015.06.043
   Aucouturier JJ, 2016, P NATL ACAD SCI USA, V113, P948, DOI 10.1073/pnas.1506552113
   Barrett LF, 2007, TRENDS COGN SCI, V11, P327, DOI 10.1016/j.tics.2007.06.003
   Belz A., 2010, Proceedings of the Sixth International Natural Language Generation Conference, P7
   Bestelmeyer PEG, 2010, COGNITION, V117, P217, DOI 10.1016/j.cognition.2010.08.008
   Blumstein DT, 2012, BIOL LETTERS, V8, P744, DOI 10.1098/rsbl.2012.0374
   Bowman C, 2017, COGNITION EMOTION, V31, P1610, DOI 10.1080/02699931.2016.1255588
   Castro SL, 2014, MUSIC PERCEPT, V32, P125, DOI 10.1525/MP.2014.32.2.125
   Chong CS, 2018, SPEECH COMMUN, V98, P68, DOI 10.1016/j.specom.2017.12.007
   Coutinho E, 2013, COGNITION EMOTION, V27, P658, DOI 10.1080/02699931.2012.732559
   Davies JQ, 2014, ROMANTIC ANATOMIES OF PERFORMANCE, P1
   Duan ZY, 2013, ASIAPAC SIGN INFO PR
   Ekkekakis P., 2013, The Measurement of Affect, Mood, and Emotion: A Guide for Health-Behavioral Research
   Escoffier N, 2013, HUM BRAIN MAPP, V34, P1796, DOI 10.1002/hbm.22029
   Farmer E, 2020, MUSIC PERCEPT, V37, P323, DOI 10.1525/MP.2020.37.4.323
   Fernández-Prieto I, 2015, INFANT BEHAV DEV, V38, P77, DOI 10.1016/j.infbeh.2014.12.008
   Fitch WT, 2013, BIRDSONG, SPEECH, AND LANGUAGE: EXPLORING THE EVOLUTION OF MIND AND BRAIN, P489
   Fitch WT, 2002, ANIM BEHAV, V63, P407, DOI 10.1006/anbe.2001.1912
   GERINGER JM, 1996, B COUN RES MUSIC ED, P80
   Giddens CL, 2013, J VOICE, V27, DOI 10.1016/j.jvoice.2012.12.010
   Giordano BL, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0115587
   Hailstone JC, 2009, Q J EXP PSYCHOL, V62, P2141, DOI 10.1080/17470210902765957
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kivy P., 1989, Sound Sentiment: An Essay on the Musical Emotions
   Laukkanen AM, 2008, J VOICE, V22, P283, DOI 10.1016/j.jvoice.2006.10.001
   Leech-Wilkinson Daniel, 2009, The Changing Sound of Music: Approaches to Studying Recorded Musical Performances
   Leslie DJ., 1952, US Patent, Patent No. [2,622,692, 2622692]
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Liuni M., 2020, 11241V1 ARXIV
   Liuni M, 2020, BEHAV PROCESS, V172, DOI 10.1016/j.beproc.2020.104042
   Ma WY, 2015, P NATL ACAD SCI USA, V112, P14563, DOI 10.1073/pnas.1515087112
   Mehr SA, 2021, BEHAV BRAIN SCI, V44, DOI 10.1017/S0140525X20000345
   Milsom David, 2003, Theory and Practice in Late Nineteenth-Century Violin Performance: an Examination of Style in Performance, 1850-1900
   Moreno S, 2009, CEREB CORTEX, V19, P712, DOI 10.1093/cercor/bhn120
   Moshona CC., 2018, THESIS TU BERLIN
   Neuhoff JG, 2001, ECOL PSYCHOL, V13, P87, DOI 10.1207/S15326969ECO1302_2
   Norman L, 2010, ACTA ACUST UNITED AC, V96, P614, DOI 10.3813/AAA.918316
   Ohala J. J., 1980, J ACOUST SOC AM, V68, pS33
   Patel AD, 2010, MUSIC LANGUAGE BRAIN
   Peelen MV, 2010, J NEUROSCI, V30, P10127, DOI 10.1523/JNEUROSCI.2161-10.2010
   Ponsot E, 2018, J ACOUST SOC AM, V143, pEL19, DOI 10.1121/1.5020989
   Proust Marcel, 1913, SWANNS WAY SEARCH LO, V1
   Rachman L, 2018, BEHAV RES METHODS, V50, P323, DOI 10.3758/s13428-017-0873-y
   Ramig LA, 1987, J Voice, V1, P162, DOI [10.1016/S0892-1997(87)80040-1, DOI 10.1016/S0892-1997(87)80040-1]
   Ross D, 2007, P NATL ACAD SCI USA, V104, P9852, DOI 10.1073/pnas.0703140104
   Rychlowska M, 2017, PSYCHOL SCI, V28, P1259, DOI 10.1177/0956797617706082
   Sandys W., 1864, HIST VIOLIN OTHER IN
   SCHELLENG JC, 1973, J ACOUST SOC AM, V53, P26, DOI 10.1121/1.1913322
   Scherer KR, 2015, COMPUT SPEECH LANG, V29, P218, DOI 10.1016/j.csl.2013.10.002
   Schlenker P, 2017, MUSIC PERCEPT, V35, P3, DOI 10.1525/MP.2017.35.1.3
   Strange P., 2003, CONT VIOLIN EXTENDED, V7
   Tai HC, 2018, P NATL ACAD SCI USA, V115, P5926, DOI 10.1073/pnas.1800666115
   Tajadura-Jimenez A., 2008, J ACOUST SOC AM, V123, P3245, DOI [10.1121/1.2933507, DOI 10.1121/1.2933507]
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Thompson WF, 2012, P NATL ACAD SCI USA, V109, P19027, DOI 10.1073/pnas.1210344109
   Watkins Holly, 2015, Women & Music, V19, P160, DOI [10.1353/wam.2015.0006, DOI 10.1353/WAM.2015.0006]
   Zatorre RJ, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001372
NR 69
TC 6
Z9 7
U1 1
U2 8
PU ROYAL SOC
PI LONDON
PA 6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND
SN 0962-8436
EI 1471-2970
J9 PHILOS T R SOC B
JI Philos. Trans. R. Soc. B-Biol. Sci.
PD DEC 20
PY 2021
VL 376
IS 1840
AR 20200396
DI 10.1098/rstb.2020.0396
PG 12
WC Biology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Life Sciences & Biomedicine - Other Topics
GA WP4VY
UT WOS:000713132600006
PM 34719254
OA Green Published, hybrid
DA 2024-01-09
ER

PT J
AU Jiam, NT
   Caldwell, M
   Deroche, ML
   Chatterjee, M
   Limb, CJ
AF Jiam, N. T.
   Caldwell, M.
   Deroche, M. L.
   Chatterjee, M.
   Limb, C. J.
TI Voice emotion perception and production in cochlear implant users
SO HEARING RESEARCH
LA English
DT Article
DE Voice emotion; Cochlear implant; Speech prosody; Voice emotion
   production; Voice emotion perception
ID PRELINGUALLY-DEAFENED CHILDREN; SPEECH INTONATION; PROSODY PERCEPTION;
   VOCAL EXPRESSION; TONE RECOGNITION; TEMPORAL CUES; PITCH; HEARING;
   MUSIC; DISCRIMINATION
AB Voice emotion is a fundamental component of human social interaction and social development. Unfortunately, cochlear implant users are often forced to interface with highly degraded prosodic cues as a result of device constraints in extraction, processing, and transmission. As such, individuals with cochlear implants frequently demonstrate significant difficulty in recognizing voice emotions in comparison to their normal hearing counterparts. Cochlear implant-mediated perception and production of voice emotion is an important but relatively understudied area of research. However, a rich understanding of the voice emotion auditory processing offers opportunities to improve upon CI biomedical design and to develop training programs benefiting CI performance. In this review, we will address the issues, current literature, and future directions for improved voice emotion processing in cochlear implant users. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Jiam, N. T.; Caldwell, M.; Limb, C. J.] Univ Calif San Francisco, Dept Otolaryngol Head & Neck Surg, Sch Med, San Francisco, CA 94115 USA.
   [Deroche, M. L.] McGill Univ, Ctr Res Brain Language & Mus, Montreal, PQ, Canada.
   [Chatterjee, M.] Boys Town Natl Res Hosp, Auditory Prostheses & Percept Lab, Omaha, NE 68131 USA.
C3 University of California System; University of California San Francisco;
   McGill University; Boys Town National Research Hospital
RP Limb, CJ (corresponding author), UCSF, Dept Otolaryngol Head & Neck Surg, 2380 Sutter St,1st Floor, San Francisco, CA 94115 USA.
EM charles.limb@ucsf.edu
RI Deroche, Mickael L. D./I-7516-2019
OI Deroche, Mickael L. D./0000-0002-8698-2249; Tahir,
   Peggy/0000-0002-3458-664X; Chatterjee, Monita/0000-0002-8286-2557
FU NIDCD NIH HHS [R01 DC014233] Funding Source: Medline
CR Agrawal D, 2013, NEUROIMAGE-CLIN, V2, P229, DOI 10.1016/j.nicl.2013.01.001
   Agrawal D., 2012, BMC NEUROAD, V13, P1
   ANDREWS FM, 1970, J RES MUSIC EDUC, V18, P214, DOI 10.2307/3344460
   [Anonymous], 2003, J DEAF STUD DEAF EDU, DOI DOI 10.1093/DEAFED/ENG019
   [Anonymous], P SPEECH PROS C
   APPLE W, 1979, J PERS SOC PSYCHOL, V37, P715, DOI 10.1037/0022-3514.37.5.715
   Artières F, 2009, OTOL NEUROTOL, V30, P736, DOI 10.1097/MAO.0b013e3181b2367b
   Bachorowski JA, 1999, CURR DIR PSYCHOL SCI, V8, P53, DOI 10.1111/1467-8721.00013
   Boons T, 2012, EAR HEARING, V33, P627, DOI 10.1097/AUD.0b013e3182503e47
   Breitenstein C, 2001, BRAIN COGNITION, V45, P277, DOI 10.1006/brcg.2000.1246
   Bryant GA, 2008, J COGN CULT, V8, P135, DOI 10.1163/156770908X289242
   Caldwell Meredith, 2015, Cochlear Implants Int, V16 Suppl 3, pS114, DOI 10.1179/1467010015Z.000000000265
   Chatterjee M, 2016, ASS RES OT 2016 39 A
   Chatterjee M, 2008, HEARING RES, V235, P143, DOI 10.1016/j.heares.2007.11.004
   Chatterjee M, 2015, HEARING RES, V322, P151, DOI 10.1016/j.heares.2014.10.003
   Chen JKC, 2010, PEDIATRICS, V125, pE793, DOI 10.1542/peds.2008-3620
   Chin SB, 2012, J COMMUN DISORD, V45, P355, DOI 10.1016/j.jcomdis.2012.05.003
   Ciocca V, 2002, J ACOUST SOC AM, V111, P2250, DOI 10.1121/1.1471897
   CostaGiomi E, 1996, J RES MUSIC EDUC, V44, P204, DOI 10.2307/3345594
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Davitz J. R., 1964, COMMUNICATION EMOTIO
   Degé F, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00124
   Deroche MLD, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00073
   Deroche MLD, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00282
   Deroche MLD, 2012, J ACOUST SOC AM, V131, P2938, DOI 10.1121/1.3692230
   EKMAN P, 1992, PSYCHOL REV, V99, P550, DOI 10.1037/0033-295X.99.3.550
   Galvin JJ, 2007, EAR HEARING, V28, P302, DOI 10.1097/01.aud.0000261689.35445.20
   Geurts L, 2001, J ACOUST SOC AM, V109, P713, DOI 10.1121/1.1340650
   Giannantonio S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0136685
   Gilbers S, 2015, I-PERCEPTION, V6, DOI 10.1177/0301006615599139
   Gordon KA, 2011, BRAIN TOPOGR, V24, P204, DOI 10.1007/s10548-011-0181-2
   Gosselin N, 2007, NEUROPSYCHOLOGIA, V45, P236, DOI 10.1016/j.neuropsychologia.2006.07.012
   Green T, 2004, J ACOUST SOC AM, V116, P2298, DOI 10.1121/1.1785611
   HAIR HI, 1981, J RES MUSIC EDUC, V29, P11, DOI 10.2307/3344675
   Hausen M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00566
   He A, 2016, OTOL NEUROTOL, V37, P324, DOI 10.1097/MAO.0000000000000980
   Hegarty Lauren, 2013, Cochlear Implants Int, V14 Suppl 4, pS35, DOI 10.1179/1467010013Z.000000000132
   Holt CM, 2013, INT J AUDIOL, V52, P808, DOI 10.3109/14992027.2013.832416
   Hopyan T, 2011, Cochlear Implants Int, V12, P21, DOI 10.1179/146701010X12677899497399
   Hopyan-Misakyan TM, 2009, CHILD NEUROPSYCHOL, V15, P136, DOI 10.1080/09297040802403682
   HUTTAR GL, 1968, J SPEECH HEAR RES, V11, P481, DOI 10.1044/jshr.1103.481
   Isshiki I., 1964, JSLHR, V7, P17
   Juslin PN, 2001, EMOTION, V1, P381, DOI 10.1037//1528-3542.1.4.381
   Kalathottukaren RT, 2015, INT J AUDIOL, V54, P444, DOI 10.3109/14992027.2014.997314
   Kang SY, 2010, JARO-J ASSOC RES OTO, V11, P245, DOI 10.1007/s10162-009-0194-7
   Ketelaar L, 2013, LARYNGOSCOPE, V123, P518, DOI 10.1002/lary.23544
   Kong YY, 2011, J SPEECH LANG HEAR R, V54, P981, DOI 10.1044/1092-4388(2010/10-0196)
   Kong YY, 2004, EAR HEARING, V25, P173, DOI 10.1097/01.AUD.0000120365.97792.2F
   Krumhansl CL, 1997, CAN J EXP PSYCHOL, V51, P336, DOI 10.1037/1196-1961.51.4.336
   LANE H, 1971, J SPEECH HEAR RES, V14, P677, DOI 10.1044/jshr.1404.677
   LEVIN H, 1975, IEEE T SYST MAN CYB, VSMC5, P259, DOI 10.1109/TSMC.1975.5408480
   Lo C.Y., 2015, HEHAV NEUROL, V2015, P1
   Lopez HAG, 2013, J VOICE, V27, DOI 10.1016/j.jvoice.2013.03.005
   Meister H, 2009, INT J AUDIOL, V48, P38, DOI 10.1080/14992020802293539
   Morgan S.D., 2014, J ACOUST SOC AM, V135, P2224
   Most T, 2007, J DEAF STUD DEAF EDU, V12, P350, DOI 10.1093/deafed/enm012
   Nakata T, 2012, J ACOUST SOC AM, V131, P1307, DOI 10.1121/1.3672697
   Osgood C. E., 1957, Themeasurement ofmeaning
   Patel AD, 2014, HEARING RES, V308, P98, DOI 10.1016/j.heares.2013.08.011
   Peng SC, 2004, EAR HEARING, V25, P251, DOI 10.1097/01.AUD.0000130797.73809.40
   Peng SC, 2004, INT CONGR SER, V1273, P336, DOI 10.1016/j.ics.2004.08.046
   Peng SC, 2008, EAR HEARING, V29, P336, DOI 10.1097/AUD.0b013e318168d94d
   Peng SC, 2007, J SPEECH LANG HEAR R, V50, P1210, DOI 10.1044/1092-4388(2007/085)
   Peng SC, 2012, TRENDS AMPLIF, V16, P67, DOI 10.1177/1084713812451159
   Pereira C., 2000, THESIS
   Planalp S, 1996, COGNITION EMOTION, V10, P137, DOI 10.1080/026999396380303
   Ponton CW, 2000, AUDIOL NEURO-OTOL, V5, P167, DOI 10.1159/000013878
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   RUSSELL JA, 1977, J RES PERS, V11, P273, DOI 10.1016/0092-6566(77)90037-X
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Sammler D, 2007, PSYCHOPHYSIOLOGY, V44, P293, DOI 10.1111/j.1469-8986.2007.00497.x
   Scherer K., 1977, MOTIV EMOTION, V1, P331, DOI [DOI 10.1007/BF00992539, 10.1007/bf00992539]
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   Schorr EA, 2009, J SPEECH LANG HEAR R, V52, P141, DOI 10.1044/1092-4388(2008/07-0213)
   Schroder Marc, 2001, INTERSPEECH, P87
   Schubert E, 1999, AUST J PSYCHOL, V51, P154, DOI 10.1080/00049539908255353
   See RL, 2013, OTOL NEUROTOL, V34, P490, DOI 10.1097/MAO.0b013e318287c985
   SHANNON RV, 1983, HEARING RES, V11, P157, DOI 10.1016/0378-5955(83)90077-1
   Shirvani S, 2016, ANN OTO RHINOL LARYN, V125, P470, DOI 10.1177/0003489415619943
   Skinner ER, 1935, SPEECH MONOGR, V2, P81, DOI 10.1080/03637753509374833
   SMITH CA, 1985, J PERS SOC PSYCHOL, V48, P813, DOI 10.1037/0022-3514.48.4.813
   Soderstrom M, 2003, J MEM LANG, V49, P249, DOI 10.1016/S0749-596X(03)00024-X
   Straatman LV, 2010, J ACOUST SOC AM, V128, P1884, DOI 10.1121/1.3474236
   Torppa R, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01389
   Trainor LJ, 2000, PSYCHOL SCI, V11, P188, DOI 10.1111/1467-9280.00240
   ULDALL E, 1960, LANG SPEECH, V3, P223, DOI 10.1177/002383096000300403
   Van Zyl M, 2013, J COMMUN DISORD, V46, P449, DOI 10.1016/j.jcomdis.2013.09.002
   VANZEE N, 1976, J RES MUSIC EDUC, V24, P14, DOI 10.2307/3345062
   Volkova Anna, 2013, Cochlear Implants Int, V14, P80, DOI 10.1179/1754762812Y.0000000004
   WALLBOTT HG, 1986, J PERS SOC PSYCHOL, V51, P690, DOI 10.1037/0022-3514.51.4.690
   Wang DJ, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00351
   Wang WQ, 2011, INT J AUDIOL, V50, P270, DOI 10.3109/14992027.2010.542490
   Wei CG, 2004, HEARING RES, V197, P87, DOI 10.1016/j.heares.2004.06.002
   Wei WI, 2000, ACTA OTO-LARYNGOL, V120, P218
   Wiefferink CH, 2013, J DEAF STUD DEAF EDU, V18, P175, DOI 10.1093/deafed/ens042
   Wong AOC, 2004, OTOLARYNG HEAD NECK, V130, P751, DOI 10.1016/j.otohns.2003.09.037
   Wouters J, 2015, IEEE SIGNAL PROC MAG, V32, P67, DOI 10.1109/MSP.2014.2371671
   Xin L, 2004, J ACOUST SOC AM, V116, P3659, DOI 10.1121/1.1783352
   Xin Luo, 2007, Trends Amplif, V11, P301
   Xu L, 2009, HEARING RES, V255, P129, DOI 10.1016/j.heares.2009.06.011
   ZAJONC RB, 1980, AM PSYCHOL, V35, P151, DOI 10.1037/0003-066X.35.2.151
   Zeng FG, 2002, HEARING RES, V174, P101, DOI 10.1016/S0378-5955(02)00644-5
   Zhang T, 2012, EAR HEARING, V33, pE70, DOI 10.1097/AUD.0b013e318259e5dd
NR 103
TC 46
Z9 49
U1 1
U2 62
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0378-5955
EI 1878-5891
J9 HEARING RES
JI Hear. Res.
PD SEP
PY 2017
VL 352
BP 30
EP 39
DI 10.1016/j.heares.2017.01.006
PG 10
WC Audiology & Speech-Language Pathology; Neurosciences;
   Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Audiology & Speech-Language Pathology; Neurosciences & Neurology;
   Otorhinolaryngology
GA FE6CV
UT WOS:000408298500004
PM 28088500
OA Green Accepted, Green Submitted
DA 2024-01-09
ER

PT J
AU Nussbaum, C
   Schirmer, A
   Schweinberger, SR
AF Nussbaum, Christine
   Schirmer, Annett
   Schweinberger, Stefan R.
TI Electrophysiological Correlates of Vocal Emotional Processing in
   Musicians and Non-Musicians
SO BRAIN SCIENCES
LA English
DT Article
DE vocal emotion perception; musicality; fundamental frequency (F0);
   timbre; parameter-specific voice morphing; electrophysiological
   correlates
ID MUSICAL EXPERTISE; SEX-DIFFERENCES; TIME-COURSE; PROSODY; SPEECH;
   ENHANCEMENT; RECOGNITION; VALIDATION; LANGUAGE; SOUND
AB Musicians outperform non-musicians in vocal emotion recognition, but the underlying mechanisms are still debated. Behavioral measures highlight the importance of auditory sensitivity towards emotional voice cues. However, it remains unclear whether and how this group difference is reflected at the brain level. Here, we compared event-related potentials (ERPs) to acoustically manipulated voices between musicians (n = 39) and non-musicians (n = 39). We used parameter-specific voice morphing to create and present vocal stimuli that conveyed happiness, fear, pleasure, or sadness, either in all acoustic cues or selectively in either pitch contour (F0) or timbre. Although the fronto-central P200 (150-250 ms) and N400 (300-500 ms) components were modulated by pitch and timbre, differences between musicians and non-musicians appeared only for a centro-parietal late positive potential (500-1000 ms). Thus, this study does not support an early auditory specialization in musicians but suggests instead that musicality affects the manner in which listeners use acoustic voice cues during later, controlled aspects of emotion evaluation.
C1 [Nussbaum, Christine; Schirmer, Annett; Schweinberger, Stefan R.] Friedrich Schiller Univ, Dept Gen Psychol & Cognit Neurosci, D-07743 Jena, Germany.
   [Nussbaum, Christine; Schweinberger, Stefan R.] Friedrich Schiller Univ, Voice Res Unit, D-07743 Jena, Germany.
   [Schirmer, Annett] Univ Innsbruck, Inst Psychol, A-6020 Innsbruck, Austria.
   [Schweinberger, Stefan R.] Univ Geneva, Swiss Ctr Affect Sci, CH-1202 Geneva, Switzerland.
C3 Friedrich Schiller University of Jena; Friedrich Schiller University of
   Jena; University of Innsbruck; University of Geneva
RP Nussbaum, C; Schweinberger, SR (corresponding author), Friedrich Schiller Univ, Dept Gen Psychol & Cognit Neurosci, D-07743 Jena, Germany.; Nussbaum, C; Schweinberger, SR (corresponding author), Friedrich Schiller Univ, Voice Res Unit, D-07743 Jena, Germany.; Schweinberger, SR (corresponding author), Univ Geneva, Swiss Ctr Affect Sci, CH-1202 Geneva, Switzerland.
EM christine.nussbaum@uni-jena.de; annett.schirmer@uibk.ac.at;
   stefan.schweinberger@uni-jena.de
OI Nussbaum, Christine/0000-0003-2718-2898; Schweinberger,
   Stefan/0000-0001-5762-0188
FU German National Academic Foundation; Research Fellowship of the Jena
   Excellence Fellowship Programme of the Friedrich Schiller University of
   Jena
FX C.N. has been supported by the German National Academic Foundation
   ("Studienstiftungdes Deutschen Volkes"). A.S. has been partially
   supported by a Research Fellowship of the Jena Excellence Fellowship
   Programme of the Friedrich Schiller University of Jena
CR [Anonymous], 2020, MATLAB
   Arias P, 2021, EMOT REV, V13, P12, DOI 10.1177/1754073920934544
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Baron-Cohen S, 2001, J AUTISM DEV DISORD, V31, P5, DOI 10.1023/A:1005653411471
   Besson M, 2007, RESTOR NEUROL NEUROS, V25, P399
   Boersma P., 2021, Glot International
   Breyer B., 2016, Zusammenstellung Sozialwissenschaftlicher Items und Skalen (ZIS), DOI [DOI 10.6102/ZIS242, 10.6102/zis242]
   Chartrand JP, 2008, BRAIN RES, V1220, P191, DOI 10.1016/j.brainres.2008.01.014
   Correia AI, 2022, EMOTION, V22, P894, DOI 10.1037/emo0000770
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Elmer S., 2018, The Oxford Handbook of Voice Perception, P208
   FREEDEN W, 1984, J COMPUT APPL MATH, V11, P367, DOI 10.1016/0377-0427(84)90011-6
   Freitag C.M., 2007, Z. Fur Klin. Psychol. Und Psychother, V36, P280, DOI [10.1026/1616-3443.36.4.280, DOI 10.1026/1616-3443.36.4.280]
   Fritz CO, 2012, J EXP PSYCHOL GEN, V141, P2, DOI 10.1037/a0024338
   Frühholz S, 2015, CEREB CORTEX, V25, P2752, DOI 10.1093/cercor/bhu074
   Frühholz S, 2016, NEUROSCI BIOBEHAV R, V68, P96, DOI 10.1016/j.neubiorev.2016.05.002
   Globerson E, 2013, ATTEN PERCEPT PSYCHO, V75, P1799, DOI 10.3758/s13414-013-0518-x
   Hajcak G, 2020, PSYCHOPHYSIOLOGY, V57, DOI 10.1111/psyp.13570
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kaganovich N, 2013, EUR J NEUROSCI, V37, P1295, DOI 10.1111/ejn.12110
   Kang K, 2018, SOC COGN AFFECT NEUR, V13, P933, DOI 10.1093/scan/nsy061
   Kawahara H., 2018, The Oxford Handbook of Voice Perception, P684
   Kawahara H., 2008, PROC IEEE INT CONF A
   Kayser J., 2009, Current Source Density (CSD) Interpolation Using Spherical Splines-Csd Toolbox
   Kayser J, 2015, INT J PSYCHOPHYSIOL, V97, P171, DOI 10.1016/j.ijpsycho.2015.06.001
   Koelsch S, 1999, NEUROREPORT, V10, P1309, DOI 10.1097/00001756-199904260-00029
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Kroes ADA, 2023, PSYCHOL METHODS, DOI 10.1037/met0000581
   Law LNC, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0052508
   Lima CF, 2016, SCI REP-UK, V6, DOI 10.1038/srep34911
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Liu TS, 2012, NEUROREPORT, V23, P108, DOI 10.1097/WNR.0b013e32834ea757
   Lolli SL, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01340
   Lütkenhöner B, 2006, NEUROIMAGE, V30, P927, DOI 10.1016/j.neuroimage.2005.10.034
   Martins I, 2022, COGN AFFECT BEHAV NE, V22, P1044, DOI 10.3758/s13415-022-01007-x
   Martins M, 2021, EMOT REV, V13, P199, DOI 10.1177/17540739211022035
   Milovanov R, 2009, NEUROSCI LETT, V460, P161, DOI 10.1016/j.neulet.2009.05.063
   Müllensiefan D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089642
   Nolden S, 2017, NEUROPSYCHOLOGIA, V103, P96, DOI 10.1016/j.neuropsychologia.2017.07.014
   Nussbaum C, 2023, BRIT J PSYCHOL, DOI 10.1111/bjop.12684
   Nussbaum C, 2023, COGNITION EMOTION, V37, P731, DOI 10.1080/02699931.2023.2200920
   Nussbaum C, 2022, SOC COGN AFFECT NEUR, V17, P1145, DOI 10.1093/scan/nsac033
   Nussbaum C, 2021, EMOT REV, V13, P211, DOI 10.1177/17540739211022803
   Pantev C, 1998, NATURE, V392, P811, DOI 10.1038/33918
   Pantev C, 2011, NEUROSCI BIOBEHAV R, V35, P2140, DOI 10.1016/j.neubiorev.2011.06.010
   Park M, 2015, FRONT HUM NEUROSCI, V8, DOI [10.3389/fnhurn.2014.01049, 10.3389/fnhum.2014.01049]
   Partanen E, 2022, NEUROPSYCHOLOGIA, V169, DOI 10.1016/j.neuropsychologia.2022.108189
   Paulmann S., 2018, The Oxford Handbook of Voice Perception, P458
   Paulmann S, 2008, NEUROREPORT, V19, P209, DOI 10.1097/WNR.0b013e3282f454db
   Paulmann S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00345
   Petit S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-67407-6
   Pinheiro AP, 2013, PSYCHOL MED, V43, P603, DOI 10.1017/S003329171200133X
   Pinheiro AP, 2015, BRAIN LANG, V140, P24, DOI 10.1016/j.bandl.2014.10.009
   Psychology Software Tools, 2016, [E-Prime 3.0
   R Core Team, 2018, R: A Language and Environment for Statistical Computing
   Rammstedt B, 2020, EUR J PSYCHOL ASSESS, V36, P149, DOI 10.1027/1015-5759/a000481
   Rigoulot S, 2015, NEUROSCIENCE, V290, P175, DOI 10.1016/j.neuroscience.2015.01.033
   Santoyo AE, 2023, J NEUROPHYSIOL, V130, P291, DOI 10.1152/jn.00042.2023
   Scherer K.R., 2018, The Oxford Handbook of Voice Perception, P60
   Schirmer A, 2005, COGNITIVE BRAIN RES, V24, P442, DOI 10.1016/j.cogbrainres.2005.02.022
   Schirmer A, 2005, NEUROREPORT, V16, P635, DOI 10.1097/00001756-200504250-00024
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   Schirmer A, 2003, J COGNITIVE NEUROSCI, V15, P1135, DOI 10.1162/089892903322598102
   Schirmer A, 2022, CURR OPIN BEHAV SCI, V44, DOI 10.1016/j.cobeha.2021.101100
   Schirmer A, 2013, COGN AFFECT BEHAV NE, V13, P80, DOI 10.3758/s13415-012-0132-8
   Schirmer A, 2010, CLIN NEUROPHYSIOL, V121, P53, DOI 10.1016/j.clinph.2009.09.029
   Schön D, 2004, PSYCHOPHYSIOLOGY, V41, P341, DOI 10.1111/1469-8986.00172.x
   Shahin A, 2003, J NEUROSCI, V23, P5545
   Shahin A, 2005, NEUROREPORT, V16, P1781, DOI 10.1097/01.wnr.0000185017.29316.63
   Shahin AJ, 2008, NEUROIMAGE, V41, P113, DOI 10.1016/j.neuroimage.2008.01.067
   Strait DL, 2009, EUR J NEUROSCI, V29, P661, DOI 10.1111/j.1460-9568.2009.06617.x
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Thompson WF, 2012, P NATL ACAD SCI USA, V109, P19027, DOI 10.1073/pnas.1210344109
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Zäske R, 2014, J NEUROSCI, V34, P10821, DOI 10.1523/JNEUROSCI.0581-14.2014
   Zentner M, 2017, ANN NY ACAD SCI, V1400, P33, DOI 10.1111/nyas.13410
NR 76
TC 0
Z9 0
U1 1
U2 1
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3425
J9 BRAIN SCI
JI Brain Sci.
PD NOV
PY 2023
VL 13
IS 11
AR 1563
DI 10.3390/brainsci13111563
PG 16
WC Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Neurosciences & Neurology
GA Y8OY7
UT WOS:001107812000001
PM 38002523
OA gold, Green Published
DA 2024-01-09
ER

PT J
AU Lehmann, A
   Paquette, S
AF Lehmann, Alexandre
   Paquette, Sebastien
TI Cross-domain processing of musical and vocal emotions in cochlear
   implant users
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Editorial Material
DE cross-domain processing; emotion; music; voice; cochlear implant; brain
   plasticity; neural overlap
ID MODAL PLASTICITY; AUDITORY-CORTEX; PERCEPTION; SPEECH; MUSICIANS;
   CHILDREN; DEAFNESS; SPECTROSCOPY; ACTIVATION; EXPRESSION
C1 [Lehmann, Alexandre] McGill Univ, Dept Otolaryngol Head & Neck Surg, Montreal, PQ, Canada.
   [Lehmann, Alexandre; Paquette, Sebastien] Ctr Res Brain Language & Mus, Int Lab Brain Mus & Sound Res, Montreal, PQ, Canada.
   [Lehmann, Alexandre; Paquette, Sebastien] Univ Montreal, Dept Psychol, Montreal, PQ H3C 3J7, Canada.
C3 McGill University; Universite de Montreal; Universite de Montreal
RP Lehmann, A (corresponding author), McGill Univ, Dept Otolaryngol Head & Neck Surg, Montreal, PQ, Canada.
EM alexandre.lehmann@mcgill.ca
CR Agrawal D, 2013, NEUROIMAGE-CLIN, V2, P229, DOI 10.1016/j.nicl.2013.01.001
   Alain C, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00089
   Ambert-Dahan E, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00181
   Bavelier D, 2010, NAT NEUROSCI, V13, P1309, DOI 10.1038/nn1110-1309
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Bestelmeyer PEG, 2010, COGNITION, V117, P217, DOI 10.1016/j.cognition.2010.08.008
   Bidelman GM, 2014, EUR J NEUROSCI, V40, P2662, DOI 10.1111/ejn.12627
   Bidelman GM, 2011, J COGNITIVE NEUROSCI, V23, P425, DOI 10.1162/jocn.2009.21362
   Collignon O, 2011, P NATL ACAD SCI USA, V108, P4435, DOI 10.1073/pnas.1013928108
   Gabrielsson A., 2010, HDB MUSIC EMOTION TH, P367, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0014
   Gfeller K, 2007, EAR HEARING, V28, P412, DOI 10.1097/AUD.0b013e3180479318
   Gilley PM, 2010, RESTOR NEUROL NEUROS, V28, P207, DOI 10.3233/RNN-2010-0525
   Gosselin N, 2015, CORTEX, V71, P171, DOI 10.1016/j.cortex.2015.06.022
   Herrmann MJ, 2003, BIOL PSYCHOL, V64, P255, DOI 10.1016/S0301-0511(03)00095-4
   Honing H, 2015, PHILOS T R SOC B, V370, P5, DOI 10.1098/rstb.2014.0088
   Hopyan T, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00425
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Köchel A, 2011, INT J PSYCHOPHYSIOL, V80, P192, DOI 10.1016/j.ijpsycho.2011.03.006
   Kong YY, 2004, EAR HEARING, V25, P173, DOI 10.1097/01.AUD.0000120365.97792.2F
   Lazard DS, 2010, NEUROIMAGE, V49, P3443, DOI 10.1016/j.neuroimage.2009.11.013
   Lazard DS, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048739
   Lazzouni L, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00340
   Lee DS, 2001, NATURE, V409, P149, DOI 10.1038/35051653
   Limb CJ, 2010, JARO-J ASSOC RES OTO, V11, P133, DOI 10.1007/s10162-009-0184-9
   Looi Valerie, 2012, Seminars in Hearing, V33, P307, DOI 10.1055/s-0032-1329222
   Nakata T, 2012, J ACOUST SOC AM, V131, P1307, DOI 10.1121/1.3672697
   Okazawa H, 1996, BRAIN, V119, P1297, DOI 10.1093/brain/119.4.1297
   Paquette S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00509
   Parbery-Clark A, 2012, NEUROSCIENCE, V219, P111, DOI 10.1016/j.neuroscience.2012.05.042
   Patel AD, 2014, HEARING RES, V308, P98, DOI 10.1016/j.heares.2013.08.011
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Pell MD, 2015, BIOL PSYCHOL, V111, P14, DOI 10.1016/j.biopsycho.2015.08.008
   Peretz I, 2015, PHILOS T R SOC B, V370, P68, DOI 10.1098/rstb.2014.0090
   Peretz I, 2013, PSYCHOLOGY OF MUSIC, THIRD EDITION, P551, DOI 10.1016/B978-0-12-381460-9.00013-4
   Peretz Isabelle, 2011, HDB MUSIC EMOTION TH, P99, DOI DOI 10.1093/ACPROF:O-SO/9780199230143.003.0005
   Plichta MM, 2011, NEUROIMAGE, V55, P1200, DOI 10.1016/j.neuroimage.2011.01.011
   Sandmann P, 2012, BRAIN, V135, P555, DOI 10.1093/brain/awr329
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   Sevy ABG, 2010, HEARING RES, V270, P39, DOI 10.1016/j.heares.2010.09.010
   Sharma A, 2015, INT J PSYCHOPHYSIOL, V95, P135, DOI 10.1016/j.ijpsycho.2014.04.007
   Strait DL, 2014, CEREB CORTEX, V24, P2512, DOI 10.1093/cercor/bht103
   Strait DL, 2014, HEARING RES, V308, P109, DOI 10.1016/j.heares.2013.08.004
   Timm L, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00181
   Villringer A, 1997, TRENDS NEUROSCI, V20, P435, DOI 10.1016/S0166-2236(97)01132-6
   Volkova Anna, 2013, Cochlear Implants Int, V14, P80, DOI 10.1179/1754762812Y.0000000004
   Wang DJ, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00351
   White-Schwoch T, 2013, J NEUROSCI, V33, P17667, DOI 10.1523/JNEUROSCI.2560-13.2013
   Zhang FW, 2011, HEARING RES, V275, P17, DOI 10.1016/j.heares.2010.11.007
NR 48
TC 4
Z9 4
U1 0
U2 18
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD SEP 24
PY 2015
VL 9
AR 343
DI 10.3389/fnins.2015.00343
PG 5
WC Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Neurosciences & Neurology
GA CS6TW
UT WOS:000362216500001
PM 26441512
OA gold, Green Published
DA 2024-01-09
ER

PT J
AU Belyk, M
   Brown, S
AF Belyk, Michel
   Brown, Steven
TI The Acoustic Correlates of Valence Depend on Emotion Family
SO JOURNAL OF VOICE
LA English
DT Article
DE Prosody; Speech; Acoustics; Vocalization; Valence; Pitch; Cognitive
   appraisal; Emotion
ID VOCAL EXPRESSION; FUNDAMENTAL-FREQUENCY; AFFECT BURSTS; SPEECH; VOICE;
   CUES; INTENSITY; MUSIC; COMMUNICATION; VOCALIZATIONS
AB The voice expresses a wide range of emotions through modulations of acoustic parameters such as frequency and amplitude. Although the acoustics of individual emotions are well understood, attempts to describe the acoustic correlates of broad emotional categories such as valence have yielded mixed results. In the present study, we analyzed the acoustics of emotional valence for different families of emotion. We divided emotional vocalizations into "motivational,'' "moral,'' and "aesthetic'' families as defined by the OCC (Ortony, Clore, and Collins) model of emotion. Subjects viewed emotional scenarios and were cued to vocalize congruent exclamations in response to them, for example, "Yay!'' and "Damn!''. Positive valence was weakly associated with high-pitched and loud vocalizations. However, valence interacted with emotion family for both pitch and amplitude. A general acoustic code for valence does not hold across families of emotion, whereas family-specific codes provide a more accurate description of vocal emotions. These findings are consolidated into a set of "rules of expression'' relating vocal dimensions to emotion dimensions.
C1 [Belyk, Michel; Brown, Steven] McMaster Univ, Dept Psychol Neurosci & Behav, Hamilton, ON L8S 4K1, Canada.
C3 McMaster University
RP Belyk, M (corresponding author), McMaster Univ, Dept Psychol Neurosci & Behav, 1280 Main St West, Hamilton, ON L8S 4K1, Canada.
EM belykm@mcmaster.ca
RI Brown, Steven/IWD-6669-2023
OI Brown, Steven/0000-0002-2457-7942; Belyk, Michel/0000-0002-3270-8666
FU Natural Sciences and Engineering Research Council (NSERC) of Canada
FX This work was funded by a grant from the Natural Sciences and
   Engineering Research Council (NSERC) of Canada to S.B.
CR BACHOROWSKI JA, 1995, PSYCHOL SCI, V6, P219, DOI 10.1111/j.1467-9280.1995.tb00596.x
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Bastian A, 2008, J ACOUST SOC AM, V124, P598, DOI 10.1121/1.2924123
   Bates D. M., 2010, lme4: Mixed-effects modeling with R.
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Boersma P., 2021, Glot International
   Curtis V, 2004, P ROY SOC B-BIOL SCI, V271, pS131, DOI 10.1098/rsbl.2003.0144
   Darwin C., 1872, The Expression of the Emotions in Man and Animals
   DOTY RW, 1956, J NEUROPHYSIOL, V19, P44, DOI 10.1152/jn.1956.19.1.44
   EKMAN P, 1969, SCIENCE, V164, P86, DOI 10.1126/science.164.3875.86
   Evans S, 2006, BIOL PSYCHOL, V72, P160, DOI 10.1016/j.biopsycho.2005.09.003
   Fairbanks G, 1938, SCIENCE, V88, P382, DOI 10.1126/science.88.2286.382
   Feinberg DR, 2005, ANIM BEHAV, V69, P561, DOI 10.1016/j.anbehav.2004.06.012
   FERNALD A, 1985, INFANT BEHAV DEV, V8, P181, DOI 10.1016/S0163-6383(85)80005-9
   FERNALD A, 1984, DEV PSYCHOL, V20, P104, DOI 10.1037/0012-1649.20.1.104
   FONAGY I, 1978, LANG SPEECH, V21, P34, DOI 10.1177/002383097802100102
   Friberg A., 2006, ADV COGN PSYCHOL, V2, P145, DOI [DOI 10.2478/V10053-008-0052-X, 10.2478/v10053-008-0052-x]
   Gobl C, 2003, SPEECH COMMUN, V40, P189, DOI 10.1016/S0167-6393(02)00082-1
   Goudbeek M, 2010, J ACOUST SOC AM, V128, P1322, DOI 10.1121/1.3466853
   Gramming P., 1988, J. Voice, V2, P118, DOI [10.1016/S0892-1997(88)80067-5, DOI 10.1016/S0892-1997(88)80067-5]
   Grandjean D, 2008, SOC SCI INFORM, V47, P187, DOI 10.1177/0539018408089078
   Green JA, 2011, EMOTION, V11, P1124, DOI 10.1037/a0024173
   Hoffmann R, 2003, 3 INT SPEECH PROS C
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Jürgens R, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00180
   Juslin PN, 2001, EMOTION, V1, P381, DOI 10.1037//1528-3542.1.4.381
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Keltner D, 2003, COGNITION EMOTION, V17, P297, DOI 10.1080/02699930302297
   Knutson B, 2002, PSYCHOL BULL, V128, P961, DOI 10.1037//0033-2909.128.6.961
   Lang IM, 2002, AM J PHYSIOL-GASTR L, V283, pG529, DOI 10.1152/ajpgi.00062.2002
   LASS NJ, 1978, J ACOUST SOC AM, V63, P1218, DOI 10.1121/1.381808
   Laukka P, 2005, COGNITION EMOTION, V19, P633, DOI 10.1080/02699930441000445
   Laukka P, 2012, SOC PSYCHOL PERS SCI, V3, P529, DOI 10.1177/1948550611428011
   LIEBERMAN P, 1962, J ACOUST SOC AM, V34, P922, DOI 10.1121/1.1918222
   MORTON ES, 1977, AM NAT, V111, P855, DOI 10.1086/283219
   Oaten M, 2009, PSYCHOL BULL, V135, P303, DOI 10.1037/a0014823
   OHALA JJ, 1984, PHONETICA, V41, P1, DOI 10.1159/000261706
   Ortony A, 1988, The cognitive structure of emotions
   Owings D. H., 1998, Animal vocal communication: A new approach
   R Core Development Team, 2011, R LANG ENV STAT COMP
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Russell JA, 2003, PSYCHOL REV, V110, P145, DOI 10.1037/0033-295X.110.1.145
   Sauter DA, 2010, Q J EXP PSYCHOL, V63, P2251, DOI 10.1080/17470211003721642
   Scherer K. R., 2001, Series in Affective Science, P92, DOI DOI 10.1016/S0166-4115(08)62387-0
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   SCHERER KR, 1991, MOTIV EMOTION, V15, P123, DOI 10.1007/BF00995674
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   SCHERER KR, 1994, J PERS SOC PSYCHOL, V66, P310, DOI 10.1037/0022-3514.66.2.310
   Schröber M, 2003, SPEECH COMMUN, V40, P99, DOI 10.1016/S0167-6393(02)00078-X
   Simon-Thomas ER, 2009, EMOTION, V9, P838, DOI 10.1037/a0017810
   SMITH CA, 1985, J PERS SOC PSYCHOL, V48, P813, DOI 10.1037/0022-3514.48.4.813
   Szameitat DP, 2009, J ACOUST SOC AM, V126, P354, DOI 10.1121/1.3139899
   Thexton AJ, 2007, J APPL PHYSIOL, V102, P587, DOI 10.1152/japplphysiol.00456.2006
   Thompson WF, 2006, SEMIOTICA, V158, P407, DOI 10.1515/SEM.2006.017
   TITZE IR, 1989, J ACOUST SOC AM, V85, P901, DOI 10.1121/1.397562
   WHALEN DH, 1995, J PHONETICS, V23, P349, DOI 10.1016/S0095-4470(95)80165-0
   WIER CC, 1977, J ACOUST SOC AM, V61, P178, DOI 10.1121/1.381251
NR 58
TC 13
Z9 17
U1 0
U2 27
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0892-1997
EI 1873-4588
J9 J VOICE
JI J. Voice
PD JUL
PY 2014
VL 28
IS 4
AR 523.e9
DI 10.1016/j.jvoice.2013.12.007
PG 10
WC Audiology & Speech-Language Pathology; Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Audiology & Speech-Language Pathology; Otorhinolaryngology
GA AK2CO
UT WOS:000338226800002
PM 24495430
DA 2024-01-09
ER

PT J
AU Spreadborough, K
AF Spreadborough, Kristal
TI Emotional Tones and Emotional Texts: A New Approach to Analyzing the
   Voice in Popular Vocal Song
SO MUSIC THEORY ONLINE
LA English
DT Article
DE Voice quality; tone quality; emotion; song; popular music; music
   psychology; social semiotics; analysis
ID DIMENSIONAL MODELS; MUSIC
AB Vocal tone quality is a highly emotive musical resource in popular vocal songs. However, it isalso one of the most difficult aspects to analyze due to the complexity and variety of the voice. This articlepresents a novel analytical approach to the sung voice by considering how emotion is conveyed through tonequality and text. The aim of the approach is to provide a system for annotating vocal tone quality and foranalyzing its emotive content. The approach is informed by findings from psychology, music studies, and thesocial semiotics of sound-taking into consideration how our everyday experience of voice in communicationcontributes to our emotional perception of singing. Different modes of annotation, from static annotation torealtime annotation, are demonstrated and two new analytical parameters are introduced: the Affect Map andCohesiveness. This paper first presents the theoretical underpinnings of the approach, followed by an outline ofthe approach itself, and finally demonstrates the approach through an analysis of the voice in KrisKristofferson's 1970 song "Casey's Last Ride."
C1 [Spreadborough, Kristal] Univ Melbourne, Melbourne Connect, Bldg 290,Level 8,700 Swanston St, Carlton, Vic 3053, Australia.
C3 University of Melbourne
RP Spreadborough, K (corresponding author), Univ Melbourne, Melbourne Connect, Bldg 290,Level 8,700 Swanston St, Carlton, Vic 3053, Australia.
EM kristal.spreadborough@unimelb.edu.au
CR [Anonymous], 1968, FOLK SONG STYLE CULT
   [Anonymous], 2011, THESIS CLEVELAND STA
   [Anonymous], 1980, The Phonetic Description of Voice Quality
   Campbell Murray, 2001, GROVE MUSIC ONLINE, DOI [10.1093/gmo/9781561592630.article.17030, DOI 10.1093/GMO/9781561592630.ARTICLE.17030]
   Carter Tim, 2001, WORD PAINTING
   Eerola T, 2013, MUSIC PERCEPT, V30, P307, DOI [10.1525/mp.2012.30.3.307, 10.1525/MP.2012.30.1.49]
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   Erickson Robert, 1975, SOUND STRUCTURE MUSI
   Evans P, 2008, MUSIC SCI, V12, P75, DOI 10.1177/102986490801200105
   Fairclough N., 2001, DISCOURSE DATA GUIDE, P229
   Frith S., 1998, PERFORMING RITES VAL
   Haynes Bruce, 2001, GROVE MUSIC ONLINE, DOI DOI 10.1093/GMO/9781561592630.ARTICLE.40883
   Heidemann K, 2016, MUSIC THEORY ONLINE, V22
   Hunter PG, 2010, SPRINGER HANDB AUDIT, V36, P129, DOI 10.1007/978-1-4419-6114-3_5
   Huron David, 2015, MUSIC ANAL EXPERIENC, P185, DOI [10.2307/j.ctt180r0s2.17, DOI 10.2307/J.CTT180R0S2.17]
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Lacasse S, 2010, ASHG POP FOLK MUSIC, P141
   Lavan N, 2019, PSYCHON B REV, V26, P90, DOI 10.3758/s13423-018-1497-7
   McDonald Klimek M, 2005, ESTILL VOICE TRAININ
   Middleton Richard, 2000, CAMBRIDGE COMPANION, P28
   Moylan William, 2015, Understanding and Crafting the Mix: The Art of Recording
   Ngo T, 2022, RES STUD MUSIC EDUC, V44, P451, DOI 10.1177/1321103X211034694
   Paul B, 2010, EMPIR MUSICOL REV, V5, P27, DOI 10.18061/1811/46747
   Plazak J.S, 2011, THESIS OHIO STATE U
   Poyatos Fernando., 1993, PARALANGUAGE LINGUIS, DOI [10.1075/cilt.92, DOI 10.1075/CILT.92]
   Poyatos Fernando, 1992, ADV NONVERBAL COMMUN, P41, DOI [10.1075/z.60.08poy, DOI 10.1075/Z.60.08POY]
   Poyatos Fernando, 2002, VOLUME 2 PARALANGUAG, V2, DOI [10.1075/z.ncad2, DOI 10.1075/Z.NCAD2]
   Rossing T. D, 2002, ECHOES, V12
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Schimmack U, 2000, EUR J PERSONALITY, V14, P325, DOI 10.1002/1099-0984(200007/08)14:4<325::AID-PER380>3.0.CO;2-I
   Smalley D, 1986, The Language of Electroacoustic Music
   Smalley D., 1997, ORGAN SOUND, V2, P107, DOI [10.1017/S1355771897009059, DOI 10.1017/S1355771897009059]
   Spreadborough K., 2018, THESIS U NEW ENGLAND, DOI [10.6084/m9.figshare.7636886.v1, DOI 10.6084/M9.FIGSHARE.7636886.V1]
   Spreadborough KL, 2019, PSYCHOL MUSIC, V47, P407, DOI 10.1177/0305735617753996
   Tellegen A, 1999, PSYCHOL SCI, V10, P297, DOI 10.1111/1467-9280.00157
   TITZE IR, 1989, J ACOUST SOC AM, V85, P1699, DOI 10.1121/1.397959
   van Leeuwen T., 1999, Speech, music, sound
   Wescott Roger W., 1992, ADVANCESIN NONVERBAL, P25
   Wishart Trevor, 1996, NEW REV, DOI [10.4324/9781315077895, DOI 10.4324/9781315077895]
NR 39
TC 2
Z9 2
U1 0
U2 5
PU SOC FOR MUSIC THEORY
PI CHICAGO
PA UNIV, CHICAGO, EPT MUSIC, 1010 EAST 59TH STREET, CHICAGO, IL 60637-1512
   USA
SN 1067-3040
J9 MUSIC THEORY ONLINE
JI Music Theory Online
PD JUN
PY 2022
VL 28
IS 2
DI 10.30535/mto.28.2.7
PG 14
WC Music
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music
GA 2J0BQ
UT WOS:000815334500003
OA gold
DA 2024-01-09
ER

PT J
AU Paquette, S
   Takerkart, S
   Saget, S
   Peretz, I
   Belin, P
AF Paquette, Sebastien
   Takerkart, Sylvain
   Saget, Shinji
   Peretz, Isabelle
   Belin, Pascal
TI Cross-classification of musical and vocal emotions in the auditory
   cortex
SO ANNALS OF THE NEW YORK ACADEMY OF SCIENCES
LA English
DT Article; Proceedings Paper
CT 6th International Conference on Neurosciences and Music
CY JUN 15-18, 2017
CL Mariani Fdn Paediat Neurol, Boston, MA
HO Mariani Fdn Paediat Neurol
DE music; voice; emotion; multivoxel pattern analysis;
   cross-classification; auditory cortex
ID RESPONSES; AREAS; RECOGNITION; SPEECH; FEAR
AB Whether emotions carried by voice and music are processed by the brain using similar mechanisms has long been investigated. Yet neuroimaging studies do not provide a clear picture, mainly due to lack of control over stimuli. Here, we report a functional magnetic resonance imaging (fMRI) study using comparable stimulus material in the voice and music domains-the Montreal Affective Voices and the Musical Emotional Bursts-which include nonverbal short bursts of happiness, fear, sadness, and neutral expressions. We use a multivariate emotion-classification fMRI analysis involving cross-timbre classification as a means of comparing the neural mechanisms involved in processing emotional information in the two domains. We find, for affective stimuli in the violin, clarinet, or voice timbres, that local fMRI patterns in the bilateral auditory cortex and upper premotor regions support above-chance emotion classification when training and testing sets are performed within the same timbre category. More importantly, classifier performance generalized well across timbre in cross-classifying schemes, albeit with a slight accuracy drop when crossing the voice-music boundary, providing evidence for a shared neural code for processing musical and vocal emotions, with possibly a cost for the voice due to its evolutionary significance.
C1 [Paquette, Sebastien; Peretz, Isabelle; Belin, Pascal] Univ Montreal, Int Lab Brain Music & Sound Res, Dept Psychol, Montreal, PQ, Canada.
   [Paquette, Sebastien] Harvard Med Sch, Beth Israel Deaconess Med Ctr, Dept Neurol, Boston, MA USA.
   [Takerkart, Sylvain; Saget, Shinji; Belin, Pascal] CNRS, Inst Neurosci La Timone, Marseille, France.
   [Takerkart, Sylvain; Saget, Shinji; Belin, Pascal] Aix Marseille Univ, Marseille, France.
   [Belin, Pascal] Univ Glasgow, Inst Neurosci & Psychol, Glasgow, Lanark, Scotland.
C3 Universite de Montreal; Harvard University; Harvard Medical School; Beth
   Israel Deaconess Medical Center; Aix-Marseille Universite; Assistance
   Publique-Hopitaux de Marseille; Centre National de la Recherche
   Scientifique (CNRS); Aix-Marseille Universite; University of Glasgow
RP Belin, P (corresponding author), CNRS, Inst Neurosci La Timone, Marseille, France.; Belin, P (corresponding author), Aix Marseille Univ, Marseille, France.; Paquette, S (corresponding author), Beth Israel Deaconess Med Ctr, Dept Neurol, 330 Brookline Ave Palmer 127, Boston, MA 02215 USA.
EM spaquet1@bidmc.harvard.edu; pascal.belin@univ-amu.fr
OI Takerkart, Sylvain/0000-0001-8410-0962
FU European Union Erasmus Mundus mobility fellowship in Auditory Cognitive
   Neuroscience; Canadian Institutes of Health Research; British
   Biotechnology and Biological Sciences Research Council, [BBJ003654/1,
   BB/1006494/1]; French Fondation pour la Recherche Medicale [AJE201214];
   Excellence Initiative of Aix-Marseille University (A*MIDEX); 
   [ANR-16-CONV-0002];  [ANR-11-LABX-0036]
FX We thank Frances Crabbe and Marc Becirspahic for their help with data
   collection. S.P. was supported by a European Union Erasmus Mundus
   mobility fellowship in Auditory Cognitive Neuroscience and a fellowship
   from the Canadian Institutes of Health Research. P.B. was supported by
   Grants BBJ003654/1 and BB/1006494/1 from the British Biotechnology and
   Biological Sciences Research Council, Grant AJE201214 from the French
   Fondation pour la Recherche Medicale, and Grants ANR-16-CONV-0002
   (Institute for Language, Communication and the Brain) and
   ANR-11-LABX-0036 (Brain and Language Research Institute) and the
   Excellence Initiative of Aix-Marseille University (A*MIDEX). S.P., P.B.,
   and I.P. developed the project. S.P. collected the data. S.P., S.T., and
   S.S. analyzed the data. S.T. and S.S. prepared the figures. All authors
   were involved in writing, editing, and reviewing the manuscript.
CR Agus T.R., 2017, SCI REP, V7, P1
   Armony JL, 2015, NEUROSCI LETT, V593, P35, DOI 10.1016/j.neulet.2015.03.011
   Aubé W, 2015, SOC COGN AFFECT NEUR, V10, P399, DOI 10.1093/scan/nsu067
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Bigand E, 2005, ANN NY ACAD SCI, V1060, P429, DOI 10.1196/annals.1360.036
   Bowling DL, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0031942
   Coutinho E, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179289
   Curtis ME, 2010, EMOTION, V10, P335, DOI 10.1037/a0017928
   Dehaene S, 2007, NEURON, V56, P384, DOI 10.1016/j.neuron.2007.10.004
   Dellacherie D, 2011, NEUROPSYCHOLOGIA, V49, P618, DOI 10.1016/j.neuropsychologia.2010.11.008
   Escoffier N, 2013, HUM BRAIN MAPP, V34, P1796, DOI 10.1002/hbm.22029
   Ethofer T, 2012, CEREB CORTEX, V22, P191, DOI 10.1093/cercor/bhr113
   Ethofer T, 2009, CURR BIOL, V19, P1028, DOI 10.1016/j.cub.2009.04.054
   Gosselin N, 2007, NEUROPSYCHOLOGIA, V45, P236, DOI 10.1016/j.neuropsychologia.2006.07.012
   Haxby JV, 2014, ANNU REV NEUROSCI, V37, P435, DOI 10.1146/annurev-neuro-062012-170325
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kotz SA, 2013, HUM BRAIN MAPP, V34, P1971, DOI 10.1002/hbm.22041
   Ma WY, 2015, P NATL ACAD SCI USA, V112, P14563, DOI 10.1073/pnas.1515087112
   Norman-Haignere S, 2015, NEURON, V88, P1281, DOI 10.1016/j.neuron.2015.11.035
   PAQUETTE S, 2013, FRONT PSYCHOL, V4
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   Peretz I, 2015, PHILOS T R SOC B, V370, P68, DOI 10.1098/rstb.2014.0090
   Pernet CR, 2015, NEUROIMAGE, V119, P164, DOI 10.1016/j.neuroimage.2015.06.050
   SCHERER KR, 1994, EMOTIONS: ESSAYS ON EMOTION THEORY, P161
   Scott SK, 1997, NATURE, V385, P254, DOI 10.1038/385254a0
   SPENCER H, 1857, FRASERS MAGAZINE, V56, P396, DOI DOI 10.1017/S0140525X08005293
   Sprengelmeyer R, 1999, P ROY SOC B-BIOL SCI, V266, P2451, DOI 10.1098/rspb.1999.0945
   Warren JE, 2006, J NEUROSCI, V26, P13067, DOI 10.1523/JNEUROSCI.3907-06.2006
NR 29
TC 30
Z9 33
U1 1
U2 23
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0077-8923
EI 1749-6632
J9 ANN NY ACAD SCI
JI Ann. N.Y. Acad. Sci.
PD JUL
PY 2018
VL 1423
IS 1
SI SI
BP 329
EP 337
DI 10.1111/nyas.13666
PG 9
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Science & Technology - Other Topics
GA GN3FY
UT WOS:000438890800033
PM 29741242
DA 2024-01-09
ER

PT J
AU Scherer, KR
   Sundberg, J
   Tamarit, L
   Salomao, GL
AF Scherer, Klaus R.
   Sundberg, Johan
   Tamarit, Lucas
   Salomao, Glaucia L.
TI Comparing the acoustic expression of emotion in the speaking and the
   singing voice
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Vocal expression; Emotional interpretation in singing; Comparison
   between emotion expression in speech and singing; Acoustic analyses of
   emotion
ID VOCAL EXPRESSION; RECOGNITION; COMMUNICATION; PERFORMANCE; PERCEPTION;
   MUSIC
AB We examine the similarities and differences in the expression of emotion in the singing and the speaking voice. Three internationally renowned opera singers produced "vocalises" (using a schwa vowel) and short nonsense phrases in different interpretations for 10 emotions. Acoustic analyses of emotional expression in the singing samples show significant differences between the emotions. In addition to the obvious effects of loudness and tempo, spectral balance and perturbation make significant contributions (high effect sizes) to this differentiation. A comparison of the emotion-specific patterns produced by the singers in this study with published data for professional actors portraying different emotions in speech generally show a very high degree of similarity. However, singers tend to rely more than actors on the use of voice perturbation, specifically vibrato, in particular in the case of high arousal emotions. It is suggested that this may be due to by the restrictions and constraints imposed by the musical structure. (C) 2013 Elsevier Ltd. All rights reserved.
C1 [Scherer, Klaus R.; Tamarit, Lucas] Univ Geneva, Swiss Ctr Affect Sci, CH-1205 Geneva, Switzerland.
   [Sundberg, Johan; Salomao, Glaucia L.] Royal Inst Technol, Sch Comp Sci & Commun, Dept Speech Mus & Hearing, SE-10044 Stockholm, Sweden.
C3 University of Geneva; Royal Institute of Technology
RP Scherer, KR (corresponding author), Univ Geneva, Swiss Ctr Affect Sci, 7 Rue Battoirs, CH-1205 Geneva, Switzerland.
EM klaus.scherer@unige.ch; jsu@csc.kth.se; Lucas.Tamarit@unige.ch;
   gsalomao@kth.se
CR [Anonymous], IEEE TAC
   [Anonymous], 2013, EMOTIONAL POWER MUSI
   [Anonymous], MUSIC LANGUAGE SPEEC
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Boersma P., 2010, PRAAT DOING PHONETIC
   Bryant GA, 2008, J COGN CULT, V8, P135, DOI 10.1163/156770908X289242
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155
   Fonseca N., 2011, THESIS U PORTO PORTU
   Goto M, 2012, INT CONF ACOUST SPEE, P5393, DOI 10.1109/ICASSP.2012.6289140
   Goudbeek M, 2010, J ACOUST SOC AM, V128, P1322, DOI 10.1121/1.3466853
   Howes P, 2004, J VOICE, V18, P216, DOI 10.1016/j.jvoice.2003.09.003
   Jansens S., 1997, P 5 EUR C SPEECH COM, P2155
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kenmochi H., 2007, P 8 ANN C INT SPEECH
   KOTLYAR GM, 1976, SOV PHYS ACOUST+, V22, P208
   Laukka P, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00353
   Laukka P, 2013, EMOTION, V13, P434, DOI 10.1037/a0031388
   Maynard Smith J. M., 2003, Animal signals
   Mortillaro M., 2013, EVOLUTION EMOTIONAL, P3, DOI DOI 10.1093/ACPROF:OSO/9780199583560.003.0001
   Patel S, 2011, BIOL PSYCHOL, V87, P93, DOI 10.1016/j.biopsycho.2011.02.010
   Pell MD, 2009, J PHONETICS, V37, P417, DOI 10.1016/j.wocn.2009.07.005
   RISSET JC, 1991, MUSIC LANGUAGE SPEEC, P368
   Roesch E. B., 2010, BLUEPRINT AFFECTIVE, P271, DOI DOI 10.1037/A0025827
   Sauter DA, 2010, P NATL ACAD SCI USA, V107, P2408, DOI 10.1073/pnas.0908239106
   Scherer K., 1977, MOTIV EMOTION, V1, P331, DOI [DOI 10.1007/BF00992539, 10.1007/bf00992539]
   Scherer K. R., 2013, COMPONENTS EMOTIONAL, P186, DOI DOI 10.1093/ACPROF:OSO/9780199592746.003.0013
   Scherer KR, 2013, STRUNGMANN FORUM REP, P107
   Scherer KR, 2011, INT J PSYCHOL, V46, P401, DOI 10.1080/00207594.2011.626049
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   SIEGWART H, 1995, J VOICE, V9, P249, DOI 10.1016/S0892-1997(05)80232-2
   Sundberg J, 1995, VOCAL FOLD, P217
   Sundberg J., 1978, SWED J MUSICOL, P107
   Sundberg J., 1989, The Science of the Singing Voice
   Sundberg J, 2006, J ACOUST SOC AM, V120, P453, DOI 10.1121/1.2208451
   Weninger F, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00292
NR 38
TC 46
Z9 49
U1 1
U2 38
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD JAN
PY 2015
VL 29
IS 1
SI SI
BP 218
EP 235
DI 10.1016/j.csl.2013.10.002
PG 18
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA AT7HI
UT WOS:000345106900014
DA 2024-01-09
ER

PT J
AU Leongómez, JD
   Pisanski, K
   Reby, D
   Sauter, D
   Lavan, N
   Perlman, M
   Valentova, JV
AF Leongomez, Juan David
   Pisanski, Katarzyna
   Reby, David
   Sauter, Disa
   Lavan, Nadine
   Perlman, Marcus
   Varella Valentova, Jaroslava
TI Voice modulation: from origin and mechanism to social impact
SO PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY B-BIOLOGICAL SCIENCES
LA English
DT Editorial Material
DE vocal control; voice perception; acoustic communication; evolution of
   speech; emotions; music
AB Research on within-individual modulation of vocal cues is surprisingly scarce outside of human speech. Yet, voice modulation serves diverse functions in human and nonhuman nonverbal communication, from dynamically signalling motivation and emotion, to exaggerating physical traits such as body size and masculinity, to enabling song and musicality. The diversity of anatomical, neural, cognitive and behavioural adaptations necessary for the production and perception of voice modulation make it a critical target for research on the origins and functions of acoustic communication. This diversity also implicates voice modulation in numerous disciplines and technological applications. In this two-part theme issue comprising 21 articles from leading and emerging international researchers, we highlight the multidisciplinary nature of the voice sciences. Every article addresses at least two, if not several, critical topics: (i) development and mechanisms driving vocal control and modulation; (ii) cultural and other environmental factors affecting voice modulation; (iii) evolutionary origins and adaptive functions of vocal control including cross-species comparisons; (iv) social functions and real-world consequences of voice modulation; and (v) state-of-the-art in multidisciplinary methodologies and technologies in voice modulation research. With this collection of works, we aim to facilitate cross-talk across disciplines to further stimulate the burgeoning field of voice modulation.
   This article is part of the theme issue 'Voice modulation: from origin and mechanism to social impact (Part I)'.
C1 [Leongomez, Juan David] Univ El Bosque, Fac Psychol, Human Behav Lab LACH, Bogota 110121, DC, Colombia.
   [Pisanski, Katarzyna; Reby, David] Jean Monnet Univ St Etienne, Sensory Neuroethol Lab ENES, Neurosci Res Ctr Lyon CRNL, St Etienne, France.
   [Pisanski, Katarzyna] Univ Lyon 2, CNRS Ctr Natl Rech Sci, Lab Dynam Langage, Lyon, France.
   [Sauter, Disa] Univ Amsterdam, Dept Psychol, Amsterdam, Netherlands.
   [Lavan, Nadine] Queen Mary Univ London, Dept Biol & Expt Psychol, London, England.
   [Perlman, Marcus] Univ Birmingham, Dept English Language & Linguist, Birmingham, W Midlands, England.
   [Varella Valentova, Jaroslava] Univ Sao Paulo, Inst Psychol, Dept Expt Psychol, BR-05508030 Sao Paulo, Brazil.
C3 Universidad El Bosque; Institut National de la Sante et de la Recherche
   Medicale (Inserm); Universite Lyon 2; University of Amsterdam;
   University of London; Queen Mary University London; University of
   Birmingham; Universidade de Sao Paulo
RP Leongómez, JD (corresponding author), Univ El Bosque, Fac Psychol, Human Behav Lab LACH, Bogota 110121, DC, Colombia.; Pisanski, K (corresponding author), Jean Monnet Univ St Etienne, Sensory Neuroethol Lab ENES, Neurosci Res Ctr Lyon CRNL, St Etienne, France.; Pisanski, K (corresponding author), Univ Lyon 2, CNRS Ctr Natl Rech Sci, Lab Dynam Langage, Lyon, France.
EM jleongomez@unbosque.edu.co; katarzyna.pisanski@cnrs.fr
RI Sauter, Disa/AAF-9557-2022; Leongómez, Juan David/D-2885-2011; Sauter,
   Disa/AFK-2268-2022; Lavan, Nadine/W-7566-2019; Perlman,
   Marcus/K-6972-2018; Valentova, Jaroslava Varella/K-8765-2012; reby,
   david/A-4227-2013; Pisanski, Katarzyna/F-7291-2019
OI Leongómez, Juan David/0000-0002-0092-6298; Lavan,
   Nadine/0000-0001-7569-0817; Perlman, Marcus/0000-0002-1269-3882;
   Valentova, Jaroslava Varella/0000-0002-2113-3385; Pisanski,
   Katarzyna/0000-0003-0992-2477; Reby, David/0000-0001-9261-1711
FU Universidad El Bosque, Vice-rectory of Research [PCI.2015-8207];
   University of Lyon IDEXLYON project [ANR-16-IDEX-0005]; ERC [714977];
   Sir Henry Wellcome Fellowship [220448/Z/20/Z]; European Research Council
   (ERC) [714977] Funding Source: European Research Council (ERC)
FX J.D.L. was supported by Universidad El Bosque, Vice-rectory of Research
   (grant no. PCI.2015-8207). K.P. and D.R. were supported by the
   University of Lyon IDEXLYON project as part of the `Programme
   Investissements d'Avenir' (ANR-16-IDEX-0005) to D.R. D.S. is supported
   by the ERC Starting (grant no. 714977). N.L. is supported by a Sir Henry
   Wellcome Fellowship (grant no. 220448/Z/20/Z).
CR Bedoya D, 2021, PHILOS T R SOC B, V376, DOI 10.1098/rstb.2020.0396
   Belyk M, 2021, PHILOS T R SOC B, V376, DOI 10.1098/rstb.2020.0392
   Borda LT, 2021, PHILOS T R SOC B, V376, DOI 10.1098/rstb.2020.0456
   Bryant GA, 2022, PHILOS T R SOC B, V377, DOI 10.1098/rstb.2020.0387
   Cartei V., 2021, PHIL T R SOC B, V376, DOI [10.1098/rstb.2020.0397, DOI 10.1098/RSTB.2020.0397]
   Cwiek A, 2022, PHILOS T R SOC B, V377, DOI 10.1098/rstb.2020.0390
   Grawunder S, 2022, PHILOS T R SOC B, V377, DOI 10.1098/rstb.2020.0455
   Guerouaou Nadia, 2022, Philos Trans R Soc Lond B Biol Sci, V377, P20210083, DOI 10.1098/rstb.2021.0083
   Hughes SM, 2021, PHILOS T R SOC B, V376, DOI 10.1098/rstb.2020.0388
   Kamiloglu RG., 2021, PHIL T R SOC B, V376, DOI [10.1098/rstb.2020.0404, DOI 10.1098/RSTB.2020.0404]
   Kleisner K, 2021, PHILOS T R SOC B, V376, DOI 10.1098/rstb.2020.0403
   Leongomez JD., 2021, PHIL T R SOC B, V376, DOI [10.1098/rstb.2020.0391, DOI 10.1098/RSTB.2020.0391]
   Matzinger T, 2021, PHILOS T R SOC B, V376, DOI 10.1098/rstb.2020.0393
   Pinheiro AP, 2021, PHILOS T R SOC B, V376, DOI 10.1098/rstb.2020.0402
   Pisanski K, 2022, PHILOS T R SOC B, V377, DOI 10.1098/rstb.2020.0401
   Ravignani Andrea, 2022, Philos Trans R Soc Lond B Biol Sci, V377, P20200394, DOI 10.1098/rstb.2020.0394
   Scott Sophie K, 2022, Philos Trans R Soc Lond B Biol Sci, V377, P20200395, DOI 10.1098/rstb.2020.0395
   Tuomainen O., 2021, PHIL T R SOC B, V376, DOI [10.1098/rstb.2020.0398, DOI 10.1098/RSTB.2020.0398]
   Waters S, 2021, PHILOS T R SOC B, V376, DOI 10.1098/rstb.2020.0399
   Winter B, 2021, PHILOS T R SOC B, V376, DOI 10.1098/rstb.2020.0400
   Yan R, 2021, PHILOS T R SOC B, V376, DOI 10.1098/rstb.2021.0089
NR 21
TC 6
Z9 6
U1 5
U2 16
PU ROYAL SOC
PI LONDON
PA 6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND
SN 0962-8436
EI 1471-2970
J9 PHILOS T R SOC B
JI Philos. Trans. R. Soc. B-Biol. Sci.
PD DEC 20
PY 2021
VL 376
IS 1840
AR 20200386
DI 10.1098/rstb.2020.0386
PG 7
WC Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics
GA WP4VY
UT WOS:000713132600002
PM 34719255
OA Green Published, Green Submitted
DA 2024-01-09
ER

PT J
AU Naranjo, C
   Kornreich, C
   Campanella, S
   Noël, X
   Vandriette, Y
   Gillain, B
   de Longueville, X
   Delatte, B
   Verbanck, P
   Constant, E
AF Naranjo, C.
   Kornreich, C.
   Campanella, S.
   Noel, X.
   Vandriette, Y.
   Gillain, B.
   de Longueville, X.
   Delatte, B.
   Verbanck, P.
   Constant, E.
TI Major depression is associated with impaired processing of emotion in
   music as well as in facial and vocal stimuli
SO JOURNAL OF AFFECTIVE DISORDERS
LA English
DT Article
DE Depression; Emotion; Music; Face; Voice; Facial expression
ID NEURAL RESPONSES; RECOGNITION; PERCEPTION; EXPRESSIONS; MOOD; FEAR;
   AMYGDALA; SCHIZOPHRENIA; HAPPY; SAD
AB Background: The processing of emotional stimuli is thought to be negatively biased in major depression. This study investigates this issue using musical, vocal and facial affective stimuli. Methods: 23 depressed in-patients and 23 matched healthy controls were recruited. Affective information processing was assessed through musical, vocal and facial emotion recognition tasks. Depression, anxiety level and attention capacity were controlled.
   Results: The depressed participants demonstrated less accurate identification of emotions than the control group in all three sorts of emotion-recognition tasks. The depressed group also gave higher intensity ratings than the controls when scoring negative emotions, and they were more likely to attribute negative emotions to neutral voices and faces.
   Limitations: Our in-patient group might differ from the more general population of depressed adults. They were all taking anti-depressant medication, which may have had an influence on their emotional information processing.
   Conclusions: Major depression is associated with a general negative bias in the processing of emotional stimuli. Emotional processing impairment in depression is not confined to interpersonal stimuli (faces and voices), being also present in the ability to feel music accurately. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Kornreich, C.] Univ Libre Bruxelles, CHU Brugmann, Lab Psychol Med, B-1020 Brussels, Belgium.
   [Constant, E.] Catholic Univ Louvain, Dept Psychiat, Louvain, Belgium.
   [de Longueville, X.; Delatte, B.] Hop Beau Vallon, Beau Vallon, Belgium.
   [Gillain, B.] Clin St Pierre, Ottignies, Belgium.
C3 Universite Libre de Bruxelles; Universite Catholique Louvain
RP Kornreich, C (corresponding author), Univ Libre Bruxelles, CHU Brugmann, Lab Psychol Med, Pl A Van Gehuchten 4, B-1020 Brussels, Belgium.
EM ckornrei@ulb.ac.be
OI Kornreich, Charles/0000-0002-4898-5588
FU Laboratoire de Psychologie Medicale Universite Libre de Bruxelles
FX The research was supported by the Laboratoire de Psychologie Medicale
   Universite Libre de Bruxelles.
CR Adolphs R, 1999, NEUROPSYCHOLOGIA, V37, P1111, DOI 10.1016/S0028-3932(99)00039-1
   Adolphs R, 2001, NEUROPSYCHOLOGY, V15, P396, DOI 10.1037//0894-4105.15.3.396
   Anderson AK, 1998, NEUROREPORT, V9, P3607
   [Anonymous], 2005, SINGING NEANDERTHALS
   ARCHER J, 1992, BRIT J CLIN PSYCHOL, V31, P45, DOI 10.1111/j.2044-8260.1992.tb00967.x
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Bhagwagar Z, 2004, AM J PSYCHIAT, V161, P166, DOI 10.1176/appi.ajp.161.1.166
   Blair RJR, 1999, BRAIN, V122, P883, DOI 10.1093/brain/122.5.883
   Bodner E, 2007, ART PSYCHOTHER, V34, P142, DOI 10.1016/j.aip.2006.12.002
   Bouhuys AL, 1999, PSYCHIAT RES, V85, P247, DOI 10.1016/S0165-1781(99)00003-7
   Bouhuys AL, 1996, PSYCHIAT RES, V64, P193, DOI 10.1016/S0165-1781(96)02930-7
   BOUHUYS AL, 1995, J AFFECT DISORDERS, V33, P215, DOI 10.1016/0165-0327(94)00092-N
   Bouhuys AL, 1997, J AFFECT DISORDERS, V43, P213, DOI 10.1016/S0165-0327(97)01432-8
   BOWER GH, 1981, AM PSYCHOL, V36, P129, DOI 10.1037/0003-066X.36.2.129
   BOYATZIS CJ, 1994, J NONVERBAL BEHAV, V18, P37, DOI 10.1007/BF02169078
   Bradley BP, 1997, COGNITION EMOTION, V11, P25, DOI 10.1080/026999397380014
   Breiter HC, 1996, NEURON, V17, P875, DOI 10.1016/S0896-6273(00)80219-6
   Brickenkamp R., 1998, The d2 Test of Attention
   Carton JS, 1999, J NONVERBAL BEHAV, V23, P91, DOI 10.1023/A:1021339410262
   Caspi A, 2003, SCIENCE, V301, P386, DOI 10.1126/science.1083968
   Chabris CF, 1999, NATURE, V400, P826, DOI 10.1038/23608
   COLLET L, 1986, Encephale, V12, P77
   COOLEY E L, 1989, Genetic Social and General Psychology Monographs, V115, P451
   Drevets WC, 2001, CURR OPIN NEUROBIOL, V11, P240, DOI 10.1016/S0959-4388(00)00203-8
   Emerson CS, 1999, NEUROPSY NEUROPSY BE, V12, P102
   FEINBERG TE, 1986, ARCH GEN PSYCHIAT, V43, P276
   Feyereisen P., 1986, ASPECTS FACE PROCESS, P349, DOI DOI 10.1007/978-94-009-4420-6_37
   Fu CHY, 2004, ARCH GEN PSYCHIAT, V61, P877, DOI 10.1001/archpsyc.61.9.877
   Furlanetto LM, 2005, J AFFECT DISORDERS, V86, P87, DOI 10.1016/j.jad.2004.12.011
   GAEBEL W, 1992, EUR ARCH PSY CLIN N, V242, P46, DOI 10.1007/BF02190342
   Gilet AL, 2008, ENCEPHALE, V34, P233, DOI 10.1016/j.encep.2006.08.003
   Gold C., 2005, COCHRANE DATABASE SY, V18
   Gollan JK, 2008, PSYCHIAT RES, V159, P18, DOI 10.1016/j.psychres.2007.06.011
   Gosselin N, 2005, BRAIN, V128, P628, DOI 10.1093/brain/awh420
   Gosselin N, 2007, NEUROPSYCHOLOGIA, V45, P236, DOI 10.1016/j.neuropsychologia.2006.07.012
   Gotlib IH, 2004, J ABNORM PSYCHOL, V113, P127, DOI 10.1037/0021-843X.113.1.121
   Gross J. J., 1998, Review of General Psychology, V2, P271, DOI [DOI 10.1037/1089-2680.2.3.271, https://doi.org/10.1037/1089-2680.2.3.271]
   GUR RC, 1992, PSYCHIAT RES, V42, P241, DOI 10.1016/0165-1781(92)90116-K
   Hale WW, 1998, J AFFECT DISORDERS, V47, P63, DOI 10.1016/S0165-0327(97)00112-2
   Harmer CJ, 2009, BRIT J PSYCHIAT, V195, P102, DOI 10.1192/bjp.bp.108.051193
   Harmer CJ, 2004, AM J PSYCHIAT, V161, P1256, DOI 10.1176/appi.ajp.161.7.1256
   Harmer CJ, 2003, AM J PSYCHIAT, V160, P990, DOI 10.1176/appi.ajp.160.5.990
   Harmer CJ, 2003, NEUROPSYCHOPHARMACOL, V28, P148, DOI 10.1038/sj.npp.1300004
   Harmer CJ, 2002, BIOL PSYCHIAT, V51, P298, DOI 10.1016/S0006-3223(01)01249-5
   Hetland L, 2000, J AESTHET EDUC, V34, P179, DOI 10.2307/3333643
   KIRITA T, 1995, ACTA PSYCHOL, V89, P149, DOI 10.1016/0001-6918(94)00021-8
   Krumhansl CL, 1997, CAN J EXP PSYCHOL, V51, P336, DOI 10.1037/1196-1961.51.4.336
   Leppänen JM, 2004, PSYCHIAT RES, V128, P123, DOI 10.1016/j.psychres.2004.05.020
   Levkovitz Y, 2003, J AFFECT DISORDERS, V75, P19, DOI 10.1016/S0165-0327(02)00024-1
   Maratos A.S., 2008, COCHRANE DATABASE SY, V23
   Marazziti D, 2010, EUR J PHARMACOL, V626, P83, DOI 10.1016/j.ejphar.2009.08.046
   Maurage P, 2007, NEUROPSYCHOL TRENDS, P63, DOI 10.7358/neur-2007-002-maur
   Mikhailova ES, 1996, BIOL PSYCHIAT, V40, P697, DOI 10.1016/0006-3223(96)00032-7
   Moffitt TE, 2007, ARCH GEN PSYCHIAT, V64, P651, DOI 10.1001/archpsyc.64.6.651
   Morris JS, 1999, NEUROPSYCHOLOGIA, V37, P1155, DOI 10.1016/S0028-3932(99)00015-9
   Morris JS, 1996, NATURE, V383, P812, DOI 10.1038/383812a0
   Nakayama H, 2009, J MUSIC THER, V46, P160, DOI 10.1093/jmt/46.2.160
   PERSAD SM, 1993, J ABNORM PSYCHOL, V102, P358, DOI 10.1037/0021-843X.102.3.358
   PHILIPPOT P, 1990, BRIT J SOC PSYCHOL, V29, P43, DOI 10.1111/j.2044-8309.1990.tb00885.x
   Phillips ML, 1998, P ROY SOC B-BIOL SCI, V265, P1809, DOI 10.1098/rspb.1998.0506
   RAUSCHER FH, 1995, NEUROSCI LETT, V185, P44, DOI 10.1016/0304-3940(94)11221-4
   RAUSCHER FH, 1993, NATURE, V365, P611, DOI 10.1038/365611a0
   Rauscher FH, 1997, NEUROL RES, V19, P2
   Royet JP, 2000, J NEUROSCI, V20, P7752
   Scott SK, 1997, NATURE, V385, P254, DOI 10.1038/385254a0
   Spielberger, 1983, MAN STAT TRAIT ANX I
   Surguladze SA, 2004, NEUROPSYCHOLOGY, V18, P212, DOI 10.1037/0894-4105.18.2.212
   Uekermann J, 2008, J INT NEUROPSYCH SOC, V14, P552, DOI 10.1017/S1355617708080740
   Västfjäll D, 2002, J PSYCHOL, V136, P357
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   Waterhouse L, 2006, EDUC PSYCHOL-US, V41, P207, DOI 10.1207/s15326985ep4104_1
   Weniger G, 2004, PSYCHIAT RES, V128, P135, DOI 10.1016/j.psychres.2003.12.027
   Whalen PJ, 1998, CURR DIR PSYCHOL SCI, V7, P177, DOI 10.1111/1467-8721.ep10836912
   ZUROFF DC, 1986, J CLIN PSYCHOL, V42, P411, DOI 10.1002/1097-4679(198605)42:3<411::AID-JCLP2270420302>3.0.CO;2-T
NR 74
TC 75
Z9 90
U1 3
U2 46
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0165-0327
EI 1573-2517
J9 J AFFECT DISORDERS
JI J. Affect. Disord.
PD FEB
PY 2011
VL 128
IS 3
BP 243
EP 251
DI 10.1016/j.jad.2010.06.039
PG 9
WC Clinical Neurology; Psychiatry
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Neurosciences & Neurology; Psychiatry
GA 743JG
UT WOS:000289014000007
PM 20663569
DA 2024-01-09
ER

PT J
AU Cowen, AS
   Elfenbein, HA
   Laukka, P
   Keltner, D
AF Cowen, Alan S.
   Elfenbein, Hillary Anger
   Laukka, Petri
   Keltner, Dacher
TI Mapping 24 Emotions Conveyed by Brief Human Vocalization
SO AMERICAN PSYCHOLOGIST
LA English
DT Article
DE emotion; voice; affect; computational methods; semantic space
ID FACIAL EXPRESSIONS; VOCAL EXPRESSION; RECOGNITION; MODEL; VOICE;
   COMMUNICATION; UNIVERSALITY; PATTERNS; LAUGHTER; SHAME
AB Emotional vocalizations are central to human social life. Recent studies have documented that people recognize at least 13 emotions in brief vocalizations. This capacity emerges early in development, is preserved in some form across cultures, and informs how people respond emotionally to music. What is poorly understood is how emotion recognition from vocalization is structured within what we call a semantic space, the study of which addresses questions critical to the field: How many distinct kinds of emotions can be expressed? Do expressions convey emotion categories or affective appraisals (e.g., valence, arousal)? Is the recognition of emotion expressions discrete or continuous? Guided by a new theoretical approach to emotion taxonomies, we apply large-scale data collection and analysis techniques to judgments of 2,032 emotional vocal bursts produced in laboratory settings (Study 1) and 48 found in the real world (Study 2) by U.S. English speakers (N = 1,105). We find that vocal bursts convey at least 24 distinct kinds of emotion. Emotion categories (sympathy. awe), more so than affective appraisals (including valence and arousal), organize emotion recognition. In contrast to discrete emotion theories, the emotion categories conveyed by vocal bursts are bridged by smooth gradients with continuously varying meaning. We visualize the complex, high-dimensional space of emotion conveyed by brief human vocalization within an online interactive map.
C1 [Cowen, Alan S.; Keltner, Dacher] Univ Calif Berkeley, Dept Psychol, 2121 Berkeley Way, Berkeley, CA 94720 USA.
   [Elfenbein, Hillary Anger] Washington Univ, Olin Sch Business, St Louis, MO 63110 USA.
   [Laukka, Petri] Stockholm Univ, Dept Psychol, Stockholm, Sweden.
C3 University of California System; University of California Berkeley;
   Washington University (WUSTL); Stockholm University
RP Cowen, AS (corresponding author), Univ Calif Berkeley, Dept Psychol, 2121 Berkeley Way, Berkeley, CA 94720 USA.
EM alan.cowen@berkeley.edu
RI Cowen, Alan Samuel/S-3367-2019; Laukka, Petri/B-5259-2008
OI Cowen, Alan Samuel/0000-0002-8381-5883; Laukka,
   Petri/0000-0001-8771-6818
CR Anikin A, 2018, Q J EXP PSYCHOL, V71, P622, DOI 10.1080/17470218.2016.1270976
   Arnal LH, 2015, CURR BIOL, V25, P2051, DOI 10.1016/j.cub.2015.06.043
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Barrett LF, 2006, PERSPECT PSYCHOL SCI, V1, P28, DOI 10.1111/j.1745-6916.2006.00003.x
   Bryant GA, 2016, P NATL ACAD SCI USA, V113, P4682, DOI 10.1073/pnas.1524993113
   Cordaro DT, 2016, EMOTION, V16, P117, DOI 10.1037/emo0000100
   Cowen AS, 2018, TRENDS COGN SCI, V22, P274, DOI 10.1016/j.tics.2018.02.003
   Cowen AS, 2017, P NATL ACAD SCI USA, V114, pE7900, DOI 10.1073/pnas.1702247114
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DiGirolamo MA, 2017, EMOTION, V17, P538, DOI 10.1037/emo0000247
   Du SC, 2014, P NATL ACAD SCI USA, V111, pE1454, DOI 10.1073/pnas.1322355111
   Egner T, 2011, NAT NEUROSCI, V14, P1219, DOI 10.1038/nn.2932
   Ekman P, 2011, EMOT REV, V3, P364, DOI 10.1177/1754073911410740
   Elfenbein HA, 2002, PSYCHOL BULL, V128, P203, DOI 10.1037//0033-2909.128.2.203
   Fernández-Dols JM, 2013, EMOT REV, V5, P24, DOI 10.1177/1754073912457229
   Frühholz S, 2016, NEUROSCI BIOBEHAV R, V68, P96, DOI 10.1016/j.neubiorev.2016.05.002
   Gendron M, 2014, EMOTION, V14, P251, DOI 10.1037/a0036052
   Gonzaga GC, 2001, J PERS SOC PSYCHOL, V81, P247, DOI 10.1037//0022-3514.81.2.247
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Harris RJ, 2012, P NATL ACAD SCI USA, V109, P21164, DOI 10.1073/pnas.1212207110
   Hawk ST, 2009, EMOTION, V9, P293, DOI 10.1037/a0015178
   Hertenstein MJ, 2004, CHILD DEV, V75, P595, DOI 10.1111/j.1467-8624.2004.00695.x
   Jack RE, 2016, J EXP PSYCHOL GEN, V145, P708, DOI 10.1037/xge0000162
   Johnson G, 2014, HUM RELAT, V67, P1265, DOI 10.1177/0018726714532856
   Juslin PN, 2018, J NONVERBAL BEHAV, V42, P1, DOI 10.1007/s10919-017-0268-x
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Keltner D, 1996, COGNITION EMOTION, V10, P155, DOI 10.1080/026999396380312
   Keltner D., 1998, Review of General Psychology, V2, P320, DOI 10.1037/1089-2680.2.3.320
   Keltner D.T., 2010, HDB SOCIAL PSYCHOL, V1, P317, DOI [DOI 10.1002/9780470561119.SOCPSY001009, 10.1002/9780470561119.socpsy001009]
   Keltner Dacher, 2016, Handbook of emotions, V4, P467
   Kraus MW, 2017, AM PSYCHOL, V72, P644, DOI 10.1037/amp0000147
   Laukka P, 2007, MOTIV EMOTION, V31, P182, DOI 10.1007/s11031-007-9063-z
   Laukka P, 2016, J PERS SOC PSYCHOL, V111, P686, DOI 10.1037/pspi0000066
   Laukka P, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00353
   LAZARUS RS, 1991, AM PSYCHOL, V46, P819, DOI 10.1037/0003-066X.46.8.819
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lima CF, 2014, EMOTION, V14, P145, DOI 10.1037/a0034287
   Matsumoto D., 2008, Handbook of Emotions, P211, DOI DOI 10.1016/J.BRAT.2006.05.004
   Mehrabian A., 1974, APPROACH ENV PSYCHOL
   Mitchell RLC, 2013, NEUROSCI BIOBEHAV R, V37, P471, DOI 10.1016/j.neubiorev.2013.01.027
   Nordström H, 2017, ROY SOC OPEN SCI, V4, DOI 10.1098/rsos.170912
   Oveis C, 2016, J EXP SOC PSYCHOL, V65, P109, DOI 10.1016/j.jesp.2016.04.005
   Parsons CE, 2014, SOC COGN AFFECT NEUR, V9, P977, DOI 10.1093/scan/nst076
   PROVINE RR, 1989, ETHOLOGY, V83, P295
   REISS S, 1991, CLIN PSYCHOL REV, V11, P141, DOI 10.1016/0272-7358(91)90092-9
   Rozin P, 1999, J PERS SOC PSYCHOL, V76, P574, DOI 10.1037/0022-3514.66.5.870
   Rozin P, 2003, EMOTION, V3, P68, DOI 10.1037/1528-3542.3.1.68
   RUSSELL JA, 1994, PSYCHOL BULL, V115, P102, DOI 10.1037/0033-2909.115.1.102
   Russell JA, 2003, PSYCHOL REV, V110, P145, DOI 10.1037/0033-295X.110.1.145
   RUSSELL JA, 1991, PSYCHOL BULL, V110, P426, DOI 10.1037/0033-2909.110.3.426
   Sauter DA, 2018, COGNITION EMOTION, V32, P504, DOI 10.1080/02699931.2017.1320978
   Sauter DA, 2013, BRIT J DEV PSYCHOL, V31, P97, DOI 10.1111/j.2044-835X.2012.02081.x
   Sauter DA, 2010, P NATL ACAD SCI USA, V107, P2408, DOI 10.1073/pnas.0908239106
   Scherer K. R., 2004, PROC SPEECH PROSODY, P359
   Scherer KR, 2013, COMPUT SPEECH LANG, V27, P40, DOI 10.1016/j.csl.2011.11.003
   Scherer KR, 2009, COGNITION EMOTION, V23, P1307, DOI 10.1080/02699930902928969
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   Scherer KR, 2003, SER AFFECTIVE SCI, P433
   SCHERER KR, 1994, J PERS SOC PSYCHOL, V66, P310, DOI 10.1037/0022-3514.66.2.310
   Schuller B, 2017, SOCIAL SIGNAL PROCES, P56
   Scott SK, 2014, TRENDS COGN SCI, V18, P618, DOI 10.1016/j.tics.2014.09.002
   Shiota MN, 2017, AM PSYCHOL, V72, P617, DOI 10.1037/a0040456
   Shuman V, 2017, COGNITION EMOTION, V31, P47, DOI 10.1080/02699931.2015.1075964
   Simon-Thomas ER, 2009, EMOTION, V9, P838, DOI 10.1037/a0017810
   SMITH CA, 1985, J PERS SOC PSYCHOL, V48, P813, DOI 10.1037/0022-3514.48.4.813
   Smoski MJ, 2003, COGNITION EMOTION, V17, P327, DOI 10.1080/02699930302296
   Snowdon C. T., 2002, HDB AFFECTIVE SCI, P457
   Story BH, 1998, J ACOUST SOC AM, V104, P471, DOI 10.1121/1.423298
   Tracy JL, 2008, P NATL ACAD SCI USA, V105, P11655, DOI 10.1073/pnas.0802686105
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Van Kleef GA, 2010, SOC PERSONAL PSYCHOL, V4, P331, DOI 10.1111/j.1751-9004.2010.00262.x
   Vidrascu L, 2005, LECT NOTES COMPUT SC, V3784, P739
   Watson D, 2017, EMOT REV, V9, P99, DOI 10.1177/1754073916639659
   Wu Y, 2017, P NATL ACAD SCI USA, V114, P11896, DOI 10.1073/pnas.1707715114
NR 74
TC 68
Z9 74
U1 5
U2 47
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0003-066X
EI 1935-990X
J9 AM PSYCHOL
JI Am. Psychol.
PD SEP
PY 2019
VL 74
IS 6
BP 698
EP 712
DI 10.1037/amp0000399
PG 15
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA IZ4ZY
UT WOS:000487093100006
PM 30570267
OA Green Accepted
DA 2024-01-09
ER

PT J
AU Martins, M
   Pinheiro, AP
   Lima, CF
AF Martins, Marta
   Pinheiro, Ana P.
   Lima, Cesar F.
TI Does Music Training Improve Emotion Recognition Abilities? A Critical
   Review
SO EMOTION REVIEW
LA English
DT Review
DE emotion recognition; music training; socioemotional processes; transfer
ID VOCAL EMOTION; FACIAL EXPRESSIONS; SPEECH PROSODY; PERCEPTION; CHILDREN;
   VOICE; LESSONS; VOCALIZATIONS; INTELLIGENCE; PLASTICITY
AB There is widespread interest in the possibility that music training enhances nonmusical abilities. This possibility has been examined primarily for speech perception and domain-general abilities such as IQ. Although social and emotional processes are central to many musical activities, transfer from music training to socioemotional skills remains underexplored. Here we synthesize results from studies examining associations between music training and emotion recognition in voices and faces. Enhancements are typically observed for vocal emotions but not for faces, although most evidence is cross-sectional. These findings are discussed considering the design features of the studies. Future research could explore further the neurocognitive mechanisms underlying musician-related differences in emotion recognition, the role of predispositions, and the implications for broader aspects of socioemotional functioning.
C1 [Martins, Marta; Lima, Cesar F.] Inst Univ Lisboa ISCTE IUL, Ave Forcas Armadas, P-1649026 Lisbon, Portugal.
   [Pinheiro, Ana P.] Univ Lisbon, Fac Psychol, Lisbon, Portugal.
   [Lima, Cesar F.] UCL, Inst Cognit Neurosci, London, England.
C3 Instituto Universitario de Lisboa; Universidade de Lisboa; University of
   London; University College London
RP Lima, CF (corresponding author), Inst Univ Lisboa ISCTE IUL, Ave Forcas Armadas, P-1649026 Lisbon, Portugal.
EM cesar.lima@iscte-iul.pt
RI Lima, Cesar F./HSF-6972-2023
OI Lima, Cesar F./0000-0003-3058-7204; Martins, Marta/0000-0002-4872-0539
FU Portuguese Foundation for Science and Technology (FCT)
   [PTDC/PSI-GER/28274/2017, IF/00172/2015]; Fundação para a Ciência e a
   Tecnologia [PTDC/PSI-GER/28274/2017] Funding Source: FCT
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: Funded by
   grants from the Portuguese Foundation for Science and Technology (FCT)
   awarded to C. F. L. (PTDC/PSI-GER/28274/2017 and IF/00172/2015).
CR Amorim M, 2021, EMOTION, V21, P315, DOI 10.1037/emo0000692
   Bänziger T, 2012, EMOTION, V12, P1161, DOI 10.1037/a0025827
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Barnett SM, 2002, PSYCHOL BULL, V128, P612, DOI 10.1037//0033-2909.128.4.612
   Baskent D, 2018, J ACOUST SOC AM, V143, pEL311, DOI 10.1121/1.5034489
   Besson M, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00094
   Bhatara A, 2011, J EXP PSYCHOL HUMAN, V37, P921, DOI 10.1037/a0021922
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Blair RJR, 2000, COGNITIVE DEV, V15, P421, DOI 10.1016/S0885-2014(01)00039-9
   Boebinger D, 2015, J ACOUST SOC AM, V137, P378, DOI 10.1121/1.4904537
   Bowen E, 2007, J NONVERBAL BEHAV, V31, P169, DOI 10.1007/s10919-007-0030-x
   Bugos JA, 2017, PSYCHOL MUSIC, V45, P855, DOI 10.1177/0305735617692666
   Carton JS, 1999, J NONVERBAL BEHAV, V23, P91, DOI 10.1023/A:1021339410262
   Castro SL, 2014, MUSIC PERCEPT, V32, P125, DOI 10.1525/MP.2014.32.2.125
   Chari DA, 2020, OTOL NEUROTOL, V41, pE422, DOI 10.1097/MAO.0000000000002525
   Chobert J, 2014, CEREB CORTEX, V24, P956, DOI 10.1093/cercor/bhs377
   Chronaki G, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-26889-1
   Clark CN, 2015, SOC COGN AFFECT NEUR, V10, P444, DOI 10.1093/scan/nsu079
   Clark CN, 2014, CURR BIOL, V24, pR234, DOI 10.1016/j.cub.2014.02.013
   Coffey EBJ, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00479
   Coffey EBJ, 2017, HEARING RES, V352, P49, DOI 10.1016/j.heares.2017.02.006
   Correia AI, 2022, EMOTION, V22, P894, DOI 10.1037/emo0000770
   Correia AI, 2019, NEUROIMAGE, V201, DOI 10.1016/j.neuroimage.2019.116052
   Costa-Giomi E., 2004, Psychology of Music, V32, P139, DOI [DOI 10.1177/0305735604041491, 10.1177/0305735604041491]
   Curtis ME, 2010, EMOTION, V10, P335, DOI 10.1037/a0017928
   Dawel A, 2012, NEUROSCI BIOBEHAV R, V36, P2288, DOI 10.1016/j.neubiorev.2012.08.006
   Degé F, 2018, MUSIC SCI, V22, P305, DOI 10.1177/1029864916688508
   Dibben N, 2018, FRONT BEHAV NEUROSCI, V12, DOI 10.3389/fnbeh.2018.00184
   Dmitrieva E S, 2006, Neurosci Behav Physiol, V36, P53, DOI 10.1007/s11055-005-0162-6
   Downey LE, 2013, CORTEX, V49, P1844, DOI 10.1016/j.cortex.2012.09.011
   Draganski B, 2004, NATURE, V427, P311, DOI 10.1038/427311a
   Dumont E, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01694
   Ethofer T, 2013, NEUROIMAGE, V76, P45, DOI 10.1016/j.neuroimage.2013.02.064
   Farmer E, 2020, MUSIC PERCEPT, V37, P323, DOI 10.1525/MP.2020.37.4.323
   FERNALD A, 1989, J CHILD LANG, V16, P477, DOI 10.1017/S0305000900010679
   Frey A, 2019, BRAIN SCI, V9, DOI 10.3390/brainsci9040091
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Frühholz S, 2016, NEUROSCI BIOBEHAV R, V68, P96, DOI 10.1016/j.neubiorev.2016.05.002
   Fuller CD, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518765379
   Fuller CD, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00179
   Gendron M, 2018, CURR DIR PSYCHOL SCI, V27, P211, DOI 10.1177/0963721417746794
   Gerry D, 2012, DEVELOPMENTAL SCI, V15, P398, DOI 10.1111/j.1467-7687.2012.01142.x
   Gery I, 2009, PSYCHIAT RES, V165, P252, DOI 10.1016/j.psychres.2007.11.006
   Gobet, 2020, PSYARXIV, DOI [10.31234/osf.io/7s8wr, DOI 10.31234/OSF.IO/7S8WR]
   Golan O, 2010, J AUTISM DEV DISORD, V40, P269, DOI 10.1007/s10803-009-0862-9
   Good A, 2017, EAR HEARING, V38, P455, DOI 10.1097/AUD.0000000000000402
   Grandjean D, 2021, EMOT REV, V13, P34, DOI 10.1177/1754073919898522
   Grau-Sánchez J, 2020, NEUROSCI BIOBEHAV R, V112, P585, DOI 10.1016/j.neubiorev.2020.02.027
   Habib M, 2009, MUSIC PERCEPT, V26, P279, DOI 10.1525/MP.2009.26.3.279
   Habibi A, 2016, DEV COGN NEUROS-NETH, V21, P1, DOI 10.1016/j.dcn.2016.04.003
   Hall JA, 2009, J NONVERBAL BEHAV, V33, P149, DOI 10.1007/s10919-009-0070-5
   Herholz SC, 2012, NEURON, V76, P486, DOI 10.1016/j.neuron.2012.10.011
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Johnston P, 2013, CORTEX, V49, P2462, DOI 10.1016/j.cortex.2013.01.002
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kim HS, 2018, PSYCHOL MUSIC, V46, P440, DOI 10.1177/0305735617729028
   Koelsch S., 2013, MUSIC MED, V5, P204, DOI [DOI 10.1177/1943862113508588, 10.1177/1943862113508588]
   Koelsch S, 2014, NAT REV NEUROSCI, V15, P170, DOI 10.1038/nrn3666
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Kreifelts B, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00648
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Laukka P, 2021, EMOT REV, V13, P3, DOI 10.1177/1754073919897295
   Lima CF, 2019, EMOTION, V19, P219, DOI 10.1037/emo0000429
   Lima CF, 2016, SCI REP-UK, V6, DOI 10.1038/srep34911
   Lima CF, 2016, TRENDS NEUROSCI, V39, P527, DOI 10.1016/j.tins.2016.06.003
   Lima CF, 2014, EMOTION, V14, P145, DOI 10.1037/a0034287
   Lima CF, 2013, BEHAV RES METHODS, V45, P1234, DOI 10.3758/s13428-013-0324-3
   Lima CF, 2011, COGNITION EMOTION, V25, P585, DOI 10.1080/02699931.2010.502449
   Lonsdale AJ, 2011, BRIT J PSYCHOL, V102, P108, DOI 10.1348/000712610X506831
   Mankel K, 2018, P NATL ACAD SCI USA, V115, P13129, DOI 10.1073/pnas.1811793115
   Marques C, 2007, J COGNITIVE NEUROSCI, V19, P1453, DOI 10.1162/jocn.2007.19.9.1453
   Mayer JD, 2003, EMOTION, V3, P97, DOI 10.1037/1528-3542.3.1.97
   McGettigan C, 2015, CEREB CORTEX, V25, P246, DOI 10.1093/cercor/bht227
   Moreno S, 2014, HEARING RES, V308, P84, DOI 10.1016/j.heares.2013.09.012
   Moreno S, 2011, PSYCHOL SCI, V22, P1425, DOI 10.1177/0956797611416999
   Moreno S, 2009, CEREB CORTEX, V19, P712, DOI 10.1093/cercor/bhn120
   Mosing M.A., 2016, MUSICAL PRODIGIES IN, P156
   Mosing MA, 2016, DEVELOPMENTAL SCI, V19, P504, DOI 10.1111/desc.12306
   Mosing MA, 2014, PSYCHOL SCI, V25, P1795, DOI 10.1177/0956797614541990
   Mualem O, 2015, INT J MUSIC EDUC, V33, P413, DOI 10.1177/0255761415584292
   Müllensiefan D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089642
   Nakata T, 2004, INFANT BEHAV DEV, V27, P455, DOI 10.1016/j.infbeh.2004.03.002
   NILSONNE A, 1985, MUSIC PERCEPT, V2, P507
   North AC, 2000, BRIT J EDUC PSYCHOL, V70, P255, DOI 10.1348/000709900158083
   O'Nions E, 2017, CURR BIOL, V27, P3049, DOI 10.1016/j.cub.2017.08.062
   Pantev C, 2011, NEUROSCI BIOBEHAV R, V35, P2140, DOI 10.1016/j.neubiorev.2011.06.010
   Park M, 2015, FRONT HUM NEUROSCI, V8, DOI [10.3389/fnhurn.2014.01049, 10.3389/fnhum.2014.01049]
   Parsons CE, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01440
   Patel AD, 2014, HEARING RES, V308, P98, DOI 10.1016/j.heares.2013.08.011
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Peelen MV, 2010, J NEUROSCI, V30, P10127, DOI 10.1523/JNEUROSCI.2161-10.2010
   Pell MD, 2015, BIOL PSYCHOL, V111, P14, DOI 10.1016/j.biopsycho.2015.08.008
   Pinheiro AP, 2015, BRAIN LANG, V140, P24, DOI 10.1016/j.bandl.2014.10.009
   Putkinen V, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-47467-z
   Rabinowitch TC, 2013, PSYCHOL MUSIC, V41, P484, DOI 10.1177/0305735612440609
   Rickard NS, 2013, INT J MUSIC EDUC, V31, P292, DOI 10.1177/0255761411434824
   Rickard NS, 2012, INT J MUSIC EDUC, V30, P57, DOI 10.1177/0255761411431399
   Rochas V, 2013, CEREB CORTEX, V23, P1517, DOI 10.1093/cercor/bhs133
   Roden I, 2014, PSYCHOL MUSIC, V42, P284, DOI 10.1177/0305735612471239
   Rose D, 2019, PSYCHOL MUSIC, V47, P284, DOI 10.1177/0305735617744887
   Ruffman T, 2008, NEUROSCI BIOBEHAV R, V32, P863, DOI 10.1016/j.neubiorev.2008.01.001
   Sala G, 2017, CURR DIR PSYCHOL SCI, V26, P515, DOI 10.1177/0963721417712760
   Sala G, 2017, EDUC RES REV-NETH, V20, P55, DOI 10.1016/j.edurev.2016.11.005
   Sauter DA, 2015, PSYCHOL SCI, V26, P354, DOI 10.1177/0956797614560771
   Sauter DA, 2010, P NATL ACAD SCI USA, V107, P2408, DOI 10.1073/pnas.0908239106
   Schellenberg E.G., 2020, ED NEUROSCIENCE DEV, Vfirst, P413, DOI 10.4324/9781003016830
   Schellenberg EG, 2006, J EDUC PSYCHOL, V98, P457, DOI 10.1037/0022-0663.98.2.457
   Schellenberg EG, 2020, PSYCHOL AESTHET CREA, V14, P475, DOI 10.1037/aca0000263
   Schellenberg EG, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0141449
   Schellenberg EG, 2011, BRIT J PSYCHOL, V102, P283, DOI 10.1111/j.2044-8295.2010.02000.x
   Schellenberg EG, 2004, PSYCHOL SCI, V15, P511, DOI 10.1111/j.0956-7976.2004.00711.x
   Scherer KR, 2011, J NONVERBAL BEHAV, V35, P305, DOI 10.1007/s10919-011-0115-4
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Schirmer A, 2018, SOC COGN AFFECT NEUR, V13, P1, DOI 10.1093/scan/nsx142
   Schirmer A, 2017, TRENDS COGN SCI, V21, P216, DOI 10.1016/j.tics.2017.01.001
   Schlegel K, 2017, MOTIV EMOTION, V41, P646, DOI 10.1007/s11031-017-9631-9
   Scott SK, 2010, HBK BEHAV NEUROSCI, V19, P187, DOI 10.1016/B978-0-12-374593-4.00019-X
   Stevens D, 2001, J GENET PSYCHOL, V162, P201, DOI 10.1080/00221320109597961
   Strait DL, 2009, EUR J NEUROSCI, V29, P661, DOI 10.1111/j.1460-9568.2009.06617.x
   Swaminathan S, 2020, J EXP PSYCHOL LEARN, V46, P2340, DOI 10.1037/xlm0000798
   Swaminathan S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-27571-2
   Swaminathan S, 2017, PSYCHON B REV, V24, P1929, DOI 10.3758/s13423-017-1244-5
   Swaminathan S, 2017, INTELLIGENCE, V62, P119, DOI 10.1016/j.intell.2017.03.005
   Swaminathan S, 2015, EMOT REV, V7, P189, DOI 10.1177/1754073914558282
   Tarr B, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01096
   Thompson W., 2009, Music, thought, and feeling: Understanding the psychology of music
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Tracy JL, 2008, EMOTION, V8, P81, DOI 10.1037/1528-3542.8.1.81
   Trehub SE, 2003, NAT NEUROSCI, V6, P669, DOI 10.1038/nn1084
   Trimmer CG, 2008, EMOTION, V8, P838, DOI 10.1037/a0014080
   Trost WJ, 2017, NEUROPSYCHOLOGIA, V96, P96, DOI 10.1016/j.neuropsychologia.2017.01.004
   Vilaverde RF, 2020, ROY SOC OPEN SCI, V7, DOI 10.1098/rsos.192077
   Weijkamp J, 2017, PSYCHOL MUSIC, V45, P204, DOI 10.1177/0305735616654216
   Welch GF, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00803
   Woollett K, 2009, PHILOS T R SOC B, V364, P1407, DOI 10.1098/rstb.2008.0288
   Young AW, 2020, TRENDS COGN SCI, V24, P398, DOI 10.1016/j.tics.2020.02.001
   Young KS, 2012, EMOTION, V12, P1200, DOI 10.1037/a0028705
   Zhang JD, 2020, PSYCHOL MUSIC, V48, P389, DOI 10.1177/0305735618804038
NR 139
TC 10
Z9 10
U1 9
U2 61
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1754-0739
EI 1754-0747
J9 EMOT REV
JI Emot. Rev.
PD JUL
PY 2021
VL 13
IS 3
BP 199
EP 210
AR 17540739211022035
DI 10.1177/17540739211022035
EA JUN 2021
PG 12
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA TG4NS
UT WOS:000665219300001
OA Green Accepted, Green Submitted
DA 2024-01-09
ER

PT J
AU Livingstone, SR
   Thompson, WF
   Wanderley, MM
   Palmer, C
AF Livingstone, Steven R.
   Thompson, William F.
   Wanderley, Marcelo M.
   Palmer, Caroline
TI Common cues to emotion in the dynamic facial expressions of speech and
   song
SO QUARTERLY JOURNAL OF EXPERIMENTAL PSYCHOLOGY
LA English
DT Article
DE Vocal communication; Singing; Dynamic information; Emotion; Facial
   expressions; Speech
ID FALSE DISCOVERY RATE; PERCEPTION; MUSIC; PERFORMANCE; MOVEMENT;
   RECOGNITION; JAW; COMMUNICATION; INTENSITY; SINGERS
AB Speech and song are universal forms of vocalization that may share aspects of emotional expression. Research has focused on parallels in acoustic features, overlooking facial cues to emotion. In three experiments, we compared moving facial expressions in speech and song. In Experiment 1, vocalists spoke and sang statements each with five emotions. Vocalists exhibited emotion-dependent movements of the eyebrows and lip corners that transcended speech-song differences. Vocalists' jaw movements were coupled to their acoustic intensity, exhibiting differences across emotion and speech-song. Vocalists' emotional movements extended beyond vocal sound to include large sustained expressions, suggesting a communicative function. In Experiment 2, viewers judged silent videos of vocalists' facial expressions prior to, during, and following vocalization. Emotional intentions were identified accurately for movements during and after vocalization, suggesting that these movements support the acoustic message. Experiment 3 compared emotional identification in voice-only, face-only, and face-and-voice recordings. Emotion judgements for voice-only singing were poorly identified, yet were accurate for all other conditions, confirming that facial expressions conveyed emotion more accurately than the voice in song, yet were equivalent in speech. Collectively, these findings highlight broad commonalities in the facial cues to emotion in speech and song, yet highlight differences in perception and acoustic-motor production.
C1 [Livingstone, Steven R.; Palmer, Caroline] McGill Univ, Dept Psychol, Montreal, PQ H3A 1B1, Canada.
   [Thompson, William F.] Macquarie Univ, Dept Psychol, Sydney, NSW 2109, Australia.
   [Wanderley, Marcelo M.] McGill Univ, CIRMMT, Dept Mus Res, Montreal, PQ, Canada.
C3 McGill University; Macquarie University; McGill University
RP Livingstone, SR (corresponding author), Ryerson Univ, Dept Psychol, 350 Victoria St, Toronto, ON M5B 2K3, Canada.
EM steven.livingstone@ryerson.ca
RI Livingstone, Steven R./H-5695-2019
OI Livingstone, Steven R./0000-0002-6364-6410; Thompson,
   William/0000-0002-4256-1338; Palmer, Caroline/0000-0003-4816-8067
FU ACN-Create NSERC Fellowship; Australian Research Council [DP0987182];
   NSERC [288230, 298173]; Canada Research Chair; Australian Research
   Council [DP0987182] Funding Source: Australian Research Council
FX This research was funded in part by an ACN-Create NSERC Fellowship
   awarded to the first author, an Australian Research Council Discovery
   Grant [grant number DP0987182] awarded to the second and fourth authors,
   an NSERC Grant [grant number 288230] awarded to the third author, and by
   a Canada Research Chair and NSERC Discovery Grant [grant number 298173]
   awarded to the fourth author.
CR Ambadar Z, 2009, J NONVERBAL BEHAV, V33, P17, DOI 10.1007/s10919-008-0059-5
   [Anonymous], EMPIRICAL STUDIES AR, DOI DOI 10.2190/NBNY-AKDK-GW58-MTEL
   [Anonymous], 2001, Music and Emotion, DOI DOI 10.1525/MP.2004.21.4.561
   Atkinson AP, 2004, PERCEPTION, V33, P717, DOI 10.1068/p5096
   Bänziger T, 2012, EMOTION, V12, P1161, DOI 10.1037/a0025827
   BASSILI JN, 1979, J PERS SOC PSYCHOL, V37, P2049, DOI 10.1037/0022-3514.37.11.2049
   BASSILI JN, 1978, J EXP PSYCHOL HUMAN, V4, P373, DOI 10.1037/0096-1523.4.3.373
   Benjamini Y, 2001, ANN STAT, V29, P1165
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   BUGENTAL DB, 1986, PERS SOC PSYCHOL B, V12, P7, DOI 10.1177/0146167286121001
   Carlo N. S., 2004, SEMIOTICA, V2004, P37, DOI [10.1515/semi.2004.036, DOI 10.1515/SEMI.2004.036]
   COLTHEART M, 1981, Q J EXP PSYCHOL-A, V33, P497, DOI 10.1080/14640748108400805
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Craig MS, 2008, J ACOUST SOC AM, V124, P3183, DOI 10.1121/1.2982369
   Cunningham DW, 2009, J VISION, V9, DOI 10.1167/9.13.7
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Davidson JW., 1993, PSYCHOL MUSIC, V21, P103, DOI [10.1177/030573569302100201, DOI 10.1177/030573569302100201]
   EDWARDS J, 1990, J SPEECH HEAR RES, V33, P550, DOI 10.1044/jshr.3303.550
   Ekman P., 1978, MANUAL FACIAL ACTION, DOI [DOI 10.1037/T27734-000, 10.1037/t27734-000]
   Elfenbein HA, 2002, PSYCHOL BULL, V128, P203, DOI 10.1037//0033-2909.128.2.203
   FERNALD A, 1989, CHILD DEV, V60, P1497, DOI 10.2307/1130938
   Hevner K, 1935, AM J PSYCHOL, V47, P103, DOI 10.2307/1416710
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   ISSHIKI N, 1965, FOLIA PHONIATR, V17, P92, DOI 10.1159/000263031
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN., 2001, Music and Emotion, P309, DOI 10.1093/oso/9780192631886.003.0014
   Kamachi M, 2001, PERCEPTION, V30, P875, DOI 10.1068/p3131
   Kohler CG, 2004, PSYCHIAT RES, V128, P235, DOI 10.1016/j.psychres.2004.07.003
   KOTLYAR GM, 1976, SOV PHYS ACOUST+, V22, P208
   Krumhuber E, 2005, J NONVERBAL BEHAV, V29, P3, DOI 10.1007/s10919-004-0887-x
   LINDBLOM BE, 1971, J ACOUST SOC AM, V50, P1166, DOI 10.1121/1.1912750
   Livingstone S. R., 2013, P M AC, P1, DOI [10.1121/1.4799460, DOI 10.1121/1.4799460]
   Livingstone SR, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00156
   Livingstone SR, 2012, EMOTION, V12, P552, DOI 10.1037/a0023747
   Livingstone SR, 2010, COMPUT MUSIC J, V34, P41, DOI 10.1162/comj.2010.34.1.41
   Livingstone SR, 2009, MUSIC PERCEPT, V26, P475, DOI 10.1525/MP.2009.26.5.475
   McClean MD, 2003, J SPEECH LANG HEAR R, V46, P1387, DOI 10.1044/1092-4388(2003/108)
   O'Toole AJ, 2002, TRENDS COGN SCI, V6, P261, DOI 10.1016/S1364-6613(02)01908-3
   Ramsay J. O., 2005, Functional Data Analysis
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   SPENCER H, 1857, FRASERS MAGAZINE, V56, P396, DOI DOI 10.1017/S0140525X08005293
   Stamou L., 2002, INT J MUSIC EDUC, V39, P3, DOI DOI 10.1177/025576140203900102
   Sundberg J, 1997, J VOICE, V11, P301, DOI 10.1016/S0892-1997(97)80008-2
   Sundberg J, 1995, VOCAL FOLD, P217
   Tasko SM, 2004, J SPEECH LANG HEAR R, V47, P85, DOI 10.1044/1092-4388(2004/008)
   Thompson WF, 2008, COGNITION EMOTION, V22, P1457, DOI 10.1080/02699930701813974
   Vines BW, 2011, COGNITION, V118, P157, DOI 10.1016/j.cognition.2010.11.010
   WAGNER HL, 1993, J NONVERBAL BEHAV, V17, P3, DOI 10.1007/BF00987006
NR 50
TC 28
Z9 31
U1 1
U2 35
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXFORDSHIRE, ENGLAND
SN 1747-0218
EI 1747-0226
J9 Q J EXP PSYCHOL
JI Q. J. Exp. Psychol.
PD MAY 4
PY 2015
VL 68
IS 5
BP 952
EP 970
DI 10.1080/17470218.2014.971034
PG 19
WC Psychology, Biological; Physiology; Psychology; Psychology, Experimental
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Psychology; Physiology
GA CH0KI
UT WOS:000353708000009
PM 25424388
OA Green Published, hybrid
DA 2024-01-09
ER

PT J
AU Ahmed, DG
   Paquette, S
   Zeitouni, A
   Lehmann, A
AF Ahmed, Duha G.
   Paquette, Sebastian
   Zeitouni, Anthony
   Lehmann, Alexandre
TI Neural Processing of Musical and Vocal Emotions Through Cochlear
   Implants Simulation
SO CLINICAL EEG AND NEUROSCIENCE
LA English
DT Article
DE cochlear implants; emotional acoustical cues; cross-domain comparison;
   music; voice; event-related potentials
ID SPEECH RECOGNITION; EVOKED-POTENTIALS; NORMAL-HEARING; PERCEPTION;
   PROSODY; MECHANISMS; EXPRESSION; RESPONSES; CHILDREN; VOICES
AB Cochlear implants (CIs) partially restore the sense of hearing in the deaf. However, the ability to recognize emotions in speech and music is reduced due to the implant's electrical signal limitations and the patient's altered neural pathways. Electrophysiological correlations of these limitations are not yet well established. Here we aimed to characterize the effect of CIs on auditory emotion processing and, for the first time, directly compare vocal and musical emotion processing through a CI-simulator. We recorded 16 normal hearing participants' electroencephalographic activity while listening to vocal and musical emotional bursts in their original form and in a degraded (CI-simulated) condition. We found prolonged P50 latency and reduced N100-P200 complex amplitude in the CI-simulated condition. This points to a limitation in encoding sound signals processed through CI simulation. When comparing the processing of vocal and musical bursts, we found a delay in latency with the musical bursts compared to the vocal bursts in both conditions (original and CI-simulated). This suggests that despite the cochlear implants' limitations, the auditory cortex can distinguish between vocal and musical stimuli. In addition, it adds to the literature supporting the complexity of musical emotion. Replicating this study with actual CI users might lead to characterizing emotional processing in CI users and could ultimately help develop optimal rehabilitation programs or device processing strategies to improve CI users' quality of life.
C1 [Ahmed, Duha G.; Paquette, Sebastian; Lehmann, Alexandre] Univ Montreal, Dept Psychol, Ctr Res Brain Language & Mus, Int Lab Brain Mus & Sound Res, Montreal, PQ, Canada.
   [Ahmed, Duha G.; Zeitouni, Anthony; Lehmann, Alexandre] McGill Univ, Dept Otolaryngol Head & Neck Surg, BRAMS Pavillon 1420 Blvd Mt Royal, Montreal, PQ H2V 4P3, Canada.
   [Ahmed, Duha G.] King Abdulaziz Univ, Dept Otolaryngol Head & Neck Surg, Rabigh Med Coll, Jeddah, Saudi Arabia.
   [Paquette, Sebastian] Harvard Med Sch, Dept Neurol, Beth Israel Deaconess Med Ctr, Boston, MA USA.
C3 Universite de Montreal; McGill University; King Abdulaziz University;
   Harvard University; Harvard Medical School; Beth Israel Deaconess
   Medical Center
RP Ahmed, DG (corresponding author), McGill Univ, Dept Otolaryngol Head & Neck Surg, BRAMS Pavillon 1420 Blvd Mt Royal, Montreal, PQ H2V 4P3, Canada.
EM duha.ahmed@mail.mcgill.ca
FU Centre for Research on Brain, Language and Music
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: The
   project described was supported by a Research Incubator Award from the
   Centre for Research on Brain, Language and Music to Alexandre Lehmann
   and Isabelle Peretz.
CR Agrawal D, 2013, NEUROIMAGE-CLIN, V2, P229, DOI 10.1016/j.nicl.2013.01.001
   Agrawal D, 2012, BMC NEUROSCI, V13, DOI 10.1186/1471-2202-13-113
   Ambert-Dahan E, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00181
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Bestelmeyer PEG, 2010, COGNITION, V117, P217, DOI 10.1016/j.cognition.2010.08.008
   Beynon A J, 2005, J Am Acad Audiol, V16, P42, DOI 10.3766/jaaa.16.1.5
   Burkholder RA, 2005, INT J AUDIOL, V44, P551, DOI 10.1080/14992020500243893
   Cousineau M, 2010, HEARING RES, V269, P34, DOI 10.1016/j.heares.2010.07.007
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Eggermont JJ, 1997, ACTA OTO-LARYNGOL, V117, P161, DOI 10.3109/00016489709117760
   Eggermont JJ, 2003, ACTA OTO-LARYNGOL, V123, P249, DOI 10.1080/0036554021000028098
   Fu QJ, 2005, JARO-J ASSOC RES OTO, V6, P180, DOI 10.1007/s10162-005-5061-6
   Groenen PAP, 2001, SCAND AUDIOL, V30, P31, DOI 10.1080/010503901750069554
   HEGERL U, 1993, BIOL PSYCHIAT, V33, P173, DOI 10.1016/0006-3223(93)90137-3
   HILLYARD SA, 1973, SCIENCE, V182, P177, DOI 10.1126/science.182.4108.177
   Hillyard SA., 1987, HDB PHYSL 1, P519
   Hopyan T, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00425
   Iredale JM, 2013, INT J PSYCHOPHYSIOL, V89, P483, DOI 10.1016/j.ijpsycho.2013.06.025
   Jung TP, 2000, PSYCHOPHYSIOLOGY, V37, P163, DOI 10.1111/1469-8986.3720163
   Juslin P. N., 2011, HDB MUSIC EMOTION TH
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kaganovich N, 2013, EUR J NEUROSCI, V37, P1295, DOI 10.1111/ejn.12110
   Key APF, 2005, DEV NEUROPSYCHOL, V27, P183, DOI 10.1207/s15326942dn2702_1
   KNIGHT RT, 1981, ELECTROEN CLIN NEURO, V52, P571, DOI 10.1016/0013-4694(81)91431-0
   Lakshminarayanan K, 2003, BRAIN LANG, V84, P250, DOI 10.1016/S0093-934X(02)00516-3
   Lehmann A, 2015, 4 INT C MUS EM OCT 1
   Lehmann A, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00343
   Levy DA, 2001, NEUROREPORT, V12, P2653, DOI 10.1097/00001756-200108280-00013
   Levy DA, 2003, PSYCHOPHYSIOLOGY, V40, P291, DOI 10.1111/1469-8986.00031
   Liu TS, 2012, NEUROREPORT, V23, P108, DOI 10.1097/WNR.0b013e32834ea757
   Lopez-Calderon J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00213
   MANGUN GR, 1995, PSYCHOPHYSIOLOGY, V32, P4, DOI 10.1111/j.1469-8986.1995.tb03400.x
   Meyer M, 2007, RESTOR NEUROL NEUROS, V25, P411
   Moore BCJ, 2003, J ACOUST SOC AM, V114, P408, DOI 10.1121/1.1577552
   Nakata T, 2012, J ACOUST SOC AM, V131, P1307, DOI 10.1121/1.3672697
   NOVAK G, 1992, PSYCHOPHYSIOLOGY, V29, P398, DOI 10.1111/j.1469-8986.1992.tb01713.x
   Paquette S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00509
   Pell MD, 2015, BIOL PSYCHOL, V111, P14, DOI 10.1016/j.biopsycho.2015.08.008
   Pinheiro AP, 2011, RES DEV DISABIL, V32, P133, DOI 10.1016/j.ridd.2010.09.011
   Poissant SF, 2006, J ACOUST SOC AM, V119, P1606, DOI 10.1121/1.2168428
   Qin MK, 2003, J ACOUST SOC AM, V114, P446, DOI 10.1121/1.1579009
   Rigoulot S, 2015, NEUROSCIENCE, V290, P175, DOI 10.1016/j.neuroscience.2015.01.033
   RITTER W, 1988, ELECTROEN CLIN NEURO, V69, P244, DOI 10.1016/0013-4694(88)90133-2
   Sandmann P, 2010, CLIN NEUROPHYSIOL, V121, P2070, DOI 10.1016/j.clinph.2010.04.032
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Stabej KK, 2012, INT J PEDIATR OTORHI, V76, P1392, DOI 10.1016/j.ijporl.2012.07.004
   Volkova Anna, 2013, Cochlear Implants Int, V14, P80, DOI 10.1179/1754762812Y.0000000004
   Wang DJ, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00351
NR 50
TC 4
Z9 4
U1 0
U2 16
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1550-0594
EI 2169-5202
J9 CLIN EEG NEUROSCI
JI Clin. EEG Neurosci.
PD MAY
PY 2018
VL 49
IS 3
BP 143
EP 151
DI 10.1177/1550059417733386
PG 9
WC Clinical Neurology; Neurosciences; Neuroimaging; Psychiatry; Psychology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Neurosciences & Neurology; Psychiatry; Psychology
GA GD0NX
UT WOS:000430198600001
PM 28958161
DA 2024-01-09
ER

PT J
AU Lévêque, Y
   Schön, D
AF Leveque, Yohana
   Schoen, Daniele
TI Modulation of the motor cortex during singing-voice perception
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE fMRI-singing; Voice perception; Dorsal auditory path; Poor singers; PPI
   connectivity
ID MIRROR NEURON SYSTEM; BIOLOGICAL MOTION; PREMOTOR CORTEX; SPEECH; BRAIN;
   EMOTIONS; LANGUAGE; STREAMS; MEMORY; MUSIC
AB Several studies on action observation have shown that the biological dimension of movement modulates sensorimotor interactions in perception. In the present fMRI study, we tested the hypothesis that the biological dimension of sound modulates the involvement of the motor system in human auditory perception, using musical tasks. We first localized the vocal motor cortex in each participant. Then we compared the BOLD response to vocal, semi-vocal and non-vocal melody perception, and found greater activity for voice perception in the right sensorimotor cortex. We additionally ran a psychophysiological interaction analysis with the right sensorimotor as a seed, showing that the vocal dimension of the stimuli enhanced the connectivity between the seed region and other important nodes of the auditory dorsal stream. Finally, the participants' vocal ability was negatively correlated to the voice effect in the Inferior Parietal Lobule. These results suggest that the biological dimension of singing-voice impacts the activity within the auditory dorsal stream, probably via a facilitated matching between the perceived sound and the participant motor representations. (C) 2015 Elsevier Ltd. All rights reserved.
C1 [Leveque, Yohana] Aix Marseille Univ, CNRS, Lab Parole & Langage, F-13604 Aix En Provence, France.
   [Schoen, Daniele] Aix Marseille Univ, INSERM, UMR S 1106, F-13005 Marseille, France.
C3 Aix-Marseille Universite; Centre National de la Recherche Scientifique
   (CNRS); Aix-Marseille Universite; Institut National de la Sante et de la
   Recherche Medicale (Inserm)
RP Lévêque, Y (corresponding author), CAP DYCOG, Ctr Rech Neurosci Lyon, CNRS UMR5292, 50 Ave Tony Garnier, F-69633 Lyon 07, France.
EM yohana.leveque@inserm.fr; daniele.schon@univ-amu.fr
RI Schön, Daniele/B-2484-2013
OI Schön, Daniele/0000-0003-4472-4150; Leveque, Yohana/0000-0003-2210-2182
FU "Agence Nationale pour la Recherche" of the French Ministry of Research
   (DMBB) [14.00 72 544x376 ANR-07-NEUR0-033-01]; AIRS (Advanced
   Interdisciplinary Research in Singing) network
FX We wish to express our sincere gratitude to Thierry Voinier (Laboratoire
   de Mecanique et d'Acoustique, Marseille) for his generous and
   indispensable help in stimuli preparation. We are also grateful to Bruno
   Nazarian, Muriel Roth and Jean-Luc Anton for their helpful assistance in
   acquiring the data. This study was supported by the Grant from "Agence
   Nationale pour la Recherche" of the French Ministry of Research (DMBB)
   (Grant no. 14.00 72 544x376 ANR-07-NEUR0-033-01) and by a Grant from
   AIRS (Advanced Interdisciplinary Research in Singing) network.
CR Agus TR, 2010, IEEE INT SYMP CIRC S, P509, DOI 10.1109/ISCAS.2010.5537589
   Banissy MJ, 2010, J NEUROSCI, V30, P13552, DOI 10.1523/JNEUROSCI.0786-10.2010
   Belin P, 2004, TRENDS COGN SCI, V8, P129, DOI 10.1016/j.tics.2004.01.008
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Brown S, 2008, CEREB CORTEX, V18, P837, DOI 10.1093/cercor/bhm131
   Caetano G, 2007, P NATL ACAD SCI USA, V104, P9058, DOI 10.1073/pnas.0702453104
   Callan DE, 2006, NEUROIMAGE, V31, P1327, DOI 10.1016/j.neuroimage.2006.01.036
   Callan DE, 2004, NEUROIMAGE, V22, P1182, DOI 10.1016/j.neuroimage.2004.03.006
   Champoux F, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0022829
   D'Ausillo A, 2009, CURR BIOL, V19, P381, DOI 10.1016/j.cub.2009.01.017
   Dushanova J, 2010, EUR J NEUROSCI, V31, P386, DOI 10.1111/j.1460-9568.2009.07067.x
   Friederici AD, 2009, TRENDS COGN SCI, V13, P175, DOI 10.1016/j.tics.2009.01.001
   Grabski K, 2013, J NEUROLINGUIST, V26, P384, DOI 10.1016/j.jneuroling.2012.11.003
   Grezes J, 1998, COGN NEUROPSYCHOL, V15, P553, DOI 10.1080/026432998381023
   Guenther FH, 2006, J COMMUN DISORD, V39, P350, DOI 10.1016/j.jcomdis.2006.06.013
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2003, J COGNITIVE NEUROSCI, V15, P673, DOI 10.1162/089892903322307393
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019
   Ito T, 2012, J NEUROPHYSIOL, V107, P442, DOI 10.1152/jn.00029.2011
   Kessler K, 2006, NEUROIMAGE, V33, P227, DOI 10.1016/j.neuroimage.2006.06.014
   Kilner JM, 2007, P NATL ACAD SCI USA, V104, P8683, DOI 10.1073/pnas.0702937104
   Kilner JM, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004925
   Kleber B, 2007, NEUROIMAGE, V36, P889, DOI 10.1016/j.neuroimage.2007.02.053
   Kleber B, 2010, CEREB CORTEX, V20, P1144, DOI 10.1093/cercor/bhp177
   Lévêque Y, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0080659
   Lévêque Y, 2012, J VOICE, V26, P293, DOI 10.1016/j.jvoice.2011.04.001
   Mattingly IG., 1988, AUDITORY FUNCTION NE, P775
   Möttönen R, 2014, J NEUROSCI, V34, P4064, DOI 10.1523/JNEUROSCI.2214-13.2014
   Osnes B, 2011, NEUROIMAGE, V54, P2437, DOI 10.1016/j.neuroimage.2010.09.078
   Pineda JA, 2008, BEHAV BRAIN FUNCT, V4, DOI 10.1186/1744-9081-4-47
   Pulvermüller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rizzolatti G, 2004, ANNU REV NEUROSCI, V27, P169, DOI 10.1146/annurev.neuro.27.070203.144230
   Sammler D, 2010, J NEUROSCI, V30, P3572, DOI 10.1523/JNEUROSCI.2751-09.2010
   Schön D, 2010, NEUROIMAGE, V51, P450, DOI 10.1016/j.neuroimage.2010.02.023
   Schwartz JL, 2012, J NEUROLINGUIST, V25, P336, DOI 10.1016/j.jneuroling.2009.12.004
   SELTZER B, 1978, BRAIN RES, V149, P1, DOI 10.1016/0006-8993(78)90584-X
   Tai YF, 2004, CURR BIOL, V14, P117, DOI 10.1016/j.cub.2004.01.005
   Ulloa ER, 2007, BEHAV BRAIN RES, V183, P188, DOI 10.1016/j.bbr.2007.06.007
   Vercoe B., 2005, CANONICAL CSOUND REF
   Warren JE, 2006, J NEUROSCI, V26, P13067, DOI 10.1523/JNEUROSCI.3907-06.2006
   Watts CR, 2008, LOGOP PHONIATR VOCO, V33, P74, DOI 10.1080/14015430802028434
   Weiss MW, 2012, PSYCHOL SCI, V23, P1074, DOI 10.1177/0956797612442552
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Wilson SM, 2006, NEUROIMAGE, V33, P316, DOI 10.1016/j.neuroimage.2006.05.032
NR 46
TC 13
Z9 15
U1 0
U2 19
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD APR
PY 2015
VL 70
BP 58
EP 63
DI 10.1016/j.neuropsychologia.2015.02.012
PG 6
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA CI2SI
UT WOS:000354596900006
PM 25676678
DA 2024-01-09
ER

PT J
AU Paquette, S
   Ahmed, GD
   Goffi-Gomez, MV
   Hoshino, ACH
   Peretz, I
   Lehmann, A
AF Paquette, S.
   Ahmed, G. D.
   Goffi-Gomez, M. V.
   Hoshino, A. C. H.
   Peretz, I.
   Lehmann, A.
TI Musical and vocal emotion perception for cochlear implants users
SO HEARING RESEARCH
LA English
DT Article
DE Cochlear implants; Emotional acoustic cues; Cross-domain comparison;
   Music; Voice; Timbre
ID SPEECH RECOGNITION; NORMAL-HEARING; DEAF-CHILDREN; COMMUNICATION;
   EXPRESSION; PERFORMANCE; RECEPTION
AB Cochlear implants can successfully restore hearing in profoundly deaf individuals and enable speech comprehension. However, the acoustic signal provided is severely degraded and, as a result, many important acoustic cues for perceiving emotion in voices and music are unavailable. The deficit of cochlear implant users in auditory emotion processing has been clearly established. Yet, the extent to which this deficit and the specific cues that remain available to cochlear implant users are unknown due to several confounding factors.
   Here we assessed the recognition of the most basic forms of auditory emotion and aimed to identify which acoustic cues are most relevant to recognize emotions through cochlear implants. To do so, we used stimuli that allowed vocal and musical auditory emotions to be comparatively assessed while controlling for confounding factors. These stimuli were used to evaluate emotion perception in cochlear implant users (Experiment 1) and to investigate emotion perception in natural versus cochlear implant hearing in the same participants with a validated cochlear implant simulation approach (Experiment 2).
   Our results showed that vocal and musical fear was not accurately recognized by cochlear implant users. Interestingly, both experiments found that timbral acoustic cues (energy and roughness) correlate with participant ratings for both vocal and musical emotion bursts in the cochlear implant simulation condition. This suggests that specific attention should be given to these cues in the design of cochlear implant processors and rehabilitation protocols (especially energy, and roughness). For instance, music based interventions focused on timbre could improve emotion perception and regulation, and thus improve social functioning, in children with cochlear implants during development. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Paquette, S.; Peretz, I.; Lehmann, A.] Univ Montreal, Dept Psychol, Ctr Res Brain Language & Mus, Int Lab Brain Mus & Sound Res, Montreal, PQ, Canada.
   [Paquette, S.] Harvard Med Sch, Beth Israel Deaconess Med Ctr, Neurol Dept, Boston, MA 02115 USA.
   [Ahmed, G. D.; Lehmann, A.] McGill Univ, Dept Otolaryngol Head & Neck Surg, Montreal, PQ, Canada.
   [Ahmed, G. D.] King Abdulaziz Univ, Rabigh Med Coll, Dept Otolaryngol Head & Neck Surg, Jeddah, Saudi Arabia.
   [Goffi-Gomez, M. V.; Hoshino, A. C. H.] Univ Sao Paulo, Hosp Clin, Sch Med, Cochlear Implant Grp, Sao Paulo, SP, Brazil.
   [Paquette, S.; Ahmed, G. D.; Goffi-Gomez, M. V.; Hoshino, A. C. H.; Peretz, I.; Lehmann, A.] Univ Montreal FAS, BRAMS, Psychol Dept, CP 6128,Succ Ctr Ville, Montreal, PQ H3C 3J7, Canada.
C3 Universite de Montreal; Harvard University; Beth Israel Deaconess
   Medical Center; Harvard Medical School; McGill University; King
   Abdulaziz University; Universidade de Sao Paulo
RP Paquette, S (corresponding author), Beth Israel Deaconess Med Ctr, Neurol, Palmer 127,330 Brookline Ave, Boston, MA 02215 USA.
EM spaquet1@bidmc.harvard.edu
OI Goffi, Valeria/0000-0002-4440-7692
FU Centre for Research on Brain, Language and Music; Canadian Institutes of
   Health Research
FX The project described was supported by a Research Incubator Award from
   the Centre for Research on Brain, Language and Music to AL and IP and by
   Doctoral and Postdoctoral Awards from the Canadian Institutes of Health
   Research to SP. We would like to thank Marion Cousineau, Mickael
   Deroche, Olivier Dussault and Gabrielle Laufer for their helpful
   comments and implication in data collection.
CR Ahmed DG, 2018, CLIN EEG NEUROSCI, V49, P143, DOI 10.1177/1550059417733386
   Ambert-Dahan E, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00181
   [Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225
   [Anonymous], 2007, P 10 INT C DIG AUD E
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Bestelmeyer PEG, 2010, COGNITION, V117, P217, DOI 10.1016/j.cognition.2010.08.008
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Boersma P., 2021, Glot International
   Cousineau M, 2010, HEARING RES, V269, P34, DOI 10.1016/j.heares.2010.07.007
   Cullington HE, 2010, EAR HEARING, V31, P70, DOI 10.1097/AUD.0b013e3181bc7722
   Driscoll VD, 2009, J AM ACAD AUDIOL, V20, P71, DOI 10.3766/jaaa.20.1.7
   DUNLAP WP, 1994, MULTIVAR BEHAV RES, V29, P115, DOI 10.1207/s15327906mbr2901_4
   Frank MG, 2001, J PERS SOC PSYCHOL, V80, P75, DOI 10.1037/0022-3514.80.1.75
   Fu QJ, 2005, JARO-J ASSOC RES OTO, V6, P180, DOI 10.1007/s10162-005-5061-6
   Gabrielsson A., 2001, INFLUENCE MUSICAL ST
   GFELLER K, 1991, J SPEECH HEAR RES, V34, P916, DOI 10.1044/jshr.3404.916
   GFELLER K, 1992, J MUSIC THER, V29, P18, DOI 10.1093/jmt/29.1.18
   Gfeller Kate, 2002, J Am Acad Audiol, V13, P132
   Gfeller Kate, 2002, Cochlear Implants Int, V3, P29, DOI 10.1179/cim.2002.3.1.29
   Gilbers S, 2015, I-PERCEPTION, V6, DOI 10.1177/0301006615599139
   Gosselin N, 2007, NEUROPSYCHOLOGIA, V45, P236, DOI 10.1016/j.neuropsychologia.2006.07.012
   Gosselin N, 2015, CORTEX, V71, P171, DOI 10.1016/j.cortex.2015.06.022
   Hopyan T, 2016, CHILD NEUROPSYCHOL, V22, P366, DOI 10.1080/09297049.2014.992400
   Hopyan T, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00425
   Hyde KL, 2004, PSYCHOL SCI, V15, P356, DOI 10.1111/j.0956-7976.2004.00683.x
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Kleiner M, 2007, PERCEPTION, V36, P14
   Kong YY, 2004, EAR HEARING, V25, P173, DOI 10.1097/01.AUD.0000120365.97792.2F
   Laneau J, 2004, J ACOUST SOC AM, V116, P3606, DOI 10.1121/1.1823311
   Language T, 2004, COMPONENTS, V3, P750, DOI [DOI 10.1007/S10766-008-0082-5, 10.1007/s10766-008-0082-5.]
   Lehmann A, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00343
   Limb Charles J, 2006, Curr Opin Otolaryngol Head Neck Surg, V14, P337, DOI 10.1097/01.moo.0000244192.59184.bd
   Looi Valerie, 2012, Seminars in Hearing, V33, P307, DOI 10.1055/s-0032-1329222
   Moore BCJ, 2003, J ACOUST SOC AM, V114, P408, DOI 10.1121/1.1577552
   Nakata T, 2012, J ACOUST SOC AM, V131, P1307, DOI 10.1121/1.3672697
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469
   Nogaki G, 2007, EAR HEARING, V28, P132, DOI 10.1097/AUD.0b013e3180312669
   Paquette S, 2018, ANN NY ACAD SCI, V1423, P329, DOI 10.1111/nyas.13666
   Paquette S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00509
   Poissant SF, 2006, J ACOUST SOC AM, V119, P1606, DOI 10.1121/1.2168428
   Qin MK, 2003, J ACOUST SOC AM, V114, P446, DOI 10.1121/1.1579009
   Quarto T, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0103278
   Rogalsky C, 2011, J NEUROSCI, V31, P3843, DOI 10.1523/JNEUROSCI.4515-10.2011
   Rubinstein JT, 2003, ANN OTO RHINOL LARYN, V112, P14
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   SHANNON RV, 1992, J ACOUST SOC AM, V91, P2156, DOI 10.1121/1.403807
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Sharda M, 2015, AUTISM RES, V8, P174, DOI 10.1002/aur.1437
   Stabej KK, 2012, INT J PEDIATR OTORHI, V76, P1392, DOI 10.1016/j.ijporl.2012.07.004
   Turgeon C, 2014, CLIN NEUROPHYSIOL, V125, P827, DOI 10.1016/j.clinph.2013.09.035
   Volkova A., 2013, CHILDREN BILATERAL C, P80, DOI [10.1179/1754762812Y.000000000414, DOI 10.1179/1754762812Y.000000000414]
   Vuvan D T, 2018, Behav Res Methods, V50, P662, DOI 10.3758/s13428-017-0892-8
   Wang DJ, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00351
   Wang YF, 2011, RES DEV DISABIL, V32, P2583, DOI 10.1016/j.ridd.2011.06.019
   Whipple CM, 2015, J MUSIC THER, V52, P78, DOI 10.1093/jmt/thu039
   Wiefferink CH, 2013, J DEAF STUD DEAF EDU, V18, P175, DOI 10.1093/deafed/ens042
   Wiefferink CH, 2012, INT J PEDIATR OTORHI, V76, P883, DOI 10.1016/j.ijporl.2012.02.065
   Witt S, 2002, ANN OTO RHINOL LARYN, V111, P349, DOI 10.1177/000348940211100412
   Zeng Fan-Gang, 2004, Trends Amplif, V8, P1, DOI 10.1177/108471380400800102
NR 60
TC 31
Z9 32
U1 2
U2 39
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0378-5955
EI 1878-5891
J9 HEARING RES
JI Hear. Res.
PD DEC
PY 2018
VL 370
BP 272
EP 282
DI 10.1016/j.heares.2018.08.009
PG 11
WC Audiology & Speech-Language Pathology; Neurosciences;
   Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Audiology & Speech-Language Pathology; Neurosciences & Neurology;
   Otorhinolaryngology
GA HE2NG
UT WOS:000453114200027
PM 30181063
DA 2024-01-09
ER

PT J
AU Merrill, J
   Ackermann, TI
AF Merrill, Julia
   Ackermann, Taren-Ida
TI "Like Static Noise in a Beautiful Landscape": A Mixed-Methods Approach
   to Rationales and Features of Disliked Voices in Popular Music
SO PSYCHOLOGY OF AESTHETICS CREATIVITY AND THE ARTS
LA English
DT Article
DE voices; vocal features; singing; expression; aesthetics
ID PREFERENCES; SPEECH; ADULTS
AB The use of the voice in everyday communication is vital for our understanding of human interaction. The singing of popular music often amplifies vocal features from speech, which can provide insights into vocal activity in the context of the intense emotional impact of music. Three studies with a mixed-methods approach aimed at evaluating rationales and features of disliked voices in the context of popular music. In an interview study (n = 20), rationales and features for disliked voices were identified using self-selected voices. In a group testing session (n = 48) and an online survey (n = 216), these disliked voices were presented to new participants, and the vocal features and evoked emotions by the singers were investigated, assuming that the participants did not have strong opinions about the voices. The results showed that participants justified their dislikes based on object-related/sound and emotional reasons, similar to findings from studies on musical taste. Specific features of disliked voices were confirmed in the following studies, including a specific feature of popular singing styles, the twang, perceived as a squeaky and nasal sound. Further disliked features include a pressed sound, imprecise and ordinary articulation, and a uniform expression. Notably, a rough voice was no predictor of aesthetic judgments. Evoked feelings relate to vocal features with similar tension levels. The measures created in the current study will also be informative for studying voice perception and evaluation more generally, which is a tool to evaluate vocal expression and items to evaluate reasons for disliked voices.
C1 [Merrill, Julia; Ackermann, Taren-Ida] Max Planck Inst Empir Aesthet, Dept Mus, Frankfurt, Germany.
   [Merrill, Julia] Univ Kassel, Inst Mus, Kassel, Germany.
   [Merrill, Julia] Max Planck Inst Empir Aesthet, Gruneburgweg 14, D-60322 Frankfurt, Germany.
C3 Universitat Kassel
RP Merrill, J (corresponding author), Max Planck Inst Empir Aesthet, Gruneburgweg 14, D-60322 Frankfurt, Germany.
EM julia.merrill@ae.mpg.de
CR Ackermann T.-I., 2019, Disliked Music: Features, rationales and functions of rejected music, DOI [10.17170/kobra-202007161459, DOI 10.17170/KOBRA-202007161459]
   ANDERS LC, 1988, FOLIA PHONIATR, V40, P91, DOI 10.1159/000265889
   [Anonymous], 1994, Sprache, Stimme, Gehor
   Bänziger T, 2014, J NONVERBAL BEHAV, V38, P31, DOI 10.1007/s10919-013-0165-x
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Baumeister R. F., 2001, Rev. Gen. Psychol, V5, P323, DOI [DOI 10.1037/1089-2680.5.4.323, 10.1037/1089-2680.5.4.323]
   Behne K. E., 1987, Psychologische Grundlagen des Musiklebens, V4, P221
   Behne K. E., 1986, Perspektiven zur Musikpadagogik und Musikwissenschaft, V10
   Berli O., 2014, Kultur und soziale Praxis, DOI [10.14361/transcript.9783839427361, DOI 10.14361/TRANSCRIPT.9783839427361]
   Bethe, 1900, POLLUCIS ONOMASTICON
   Bigand E, 2006, COGNITION, V100, P100, DOI 10.1016/j.cognition.2005.11.007
   Bose I., 2010, Sprache intermedial. Stimme und Schrift, Bild und Ton, P29, DOI [10.1515/9783110223613.29, DOI 10.1515/9783110223613.29]
   Bose I., 2001, Gesprachsforschung: Online-Zeitschrift zur Verbalen Interaktion, V2, P262
   Bourdieu Pierre., 1984, HDB THEORY RES SOCIO, DOI DOI 10.1002/9780470755679.CH15
   Buhler K., 1933, Theory of expression
   Buttner M., 2008, Das Phanomen Stimme: Naturliche Veranlagung oder kulturelle Formung. 6. Internationale Stuttgarter Stimmtage 2006
   Cleveland TE, 2001, J VOICE, V15, P54, DOI 10.1016/S0892-1997(01)00006-6
   Cohen J, 1988, STAT POWER ANAL BEHA
   Coutinho E, 2017, PSYCHOL MUSIC, V45, P550, DOI 10.1177/0305735616670496
   DeNora Tia, 2000, Music in Everyday Life
   Edmondson Jerold A., 2006, Phonology, V23, P157, DOI DOI 10.1017/S095267570600087X
   Ekholm E, 1998, J VOICE, V12, P182, DOI 10.1016/S0892-1997(98)80038-6
   Fox J., 2011, An R Companion to Applied Regression
   Gabrielsson A, 2001, MUSIC SCI, V5, P123, DOI 10.1177/10298649020050S105
   Goy H, 2016, J ACOUST SOC AM, V139, P1648, DOI 10.1121/1.4945094
   Greasley A, 2013, QUAL RES PSYCHOL, V10, P402, DOI 10.1080/14780887.2011.647259
   Gunermann H., 2012, Reclams Universal-Bibliothek, V18825
   Hahnel T., 2015, Texte zur popularen Musik, V8, P53
   Henrich N., 2008, J INT DISCIPL MUSIC, V2, P71
   Himonides E, 2009, J MUSIC TECHNOL EDUC, V2, P25, DOI 10.1386/jmte.2.1.25/1
   Hirano M., 1981, Clinical examination of voice. Disorders of human communication, V5
   HOLLIEN H, 1991, J COMMUN DISORD, V24, P157, DOI 10.1016/0021-9924(91)90019-F
   Hollien H., 2000, Voice quality measurement, P13
   Kroger C, 2017, PSYCHOL MUSIC, V45, P49, DOI 10.1177/0305735616642543
   Kunz A., 1998, Aspects of the development of personal musical taste
   Larrouy-Maestri P., 2018, Music Science, V1, DOI DOI 10.1177/2059204318784582
   Laver J., 1980, Cambridge studies in linguistics, V31
   Mathieson L., 2001, Greene and Mathieson's The Voice and Its Disorders
   Mayring P., 2014, A Companion To Qual Res
   Mayring P, 2010, Qualitative Inhaltsanalyse: Grundlagen Und Techniken (Qualitative Content Analysis: Basics and Techniques), V11
   Mayring P., 2012, Qualitative Forschung: Ein Handbuch, V55628, P468
   Merrill J., 2019, Sprechen Zeitschrift fur Sprechwissenschaft, Sprechpadagogik, Sprechtherapie, Sprechkunst, V68, P42
   Merrill J, 2017, ACTA MUSICOLOGICA, V89, P95
   Merrill J, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01108
   Merton R.K., 1990, The focused interview: A manual of problems and procedures, V2nd ed.
   MONTEPARE JM, 1987, J EXP SOC PSYCHOL, V23, P331, DOI 10.1016/0022-1031(87)90045-X
   Nakagawa S, 2013, METHODS ECOL EVOL, V4, P133, DOI 10.1111/j.2041-210x.2012.00261.x
   Oates JM, 2006, J VOICE, V20, P71, DOI 10.1016/j.jvoice.2005.01.006
   Ohara Y., 1999, Wahrnehmung und Herstellung von Geschlecht: Perceiving and Performing Gender, P105, DOI [10.1007/978-3-322-89014-6_8, DOI 10.1007/978-3-322-89014-6_8]
   Popper R., 2005, ChemoSense, V7, P4
   Re DE, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0032719
   Rozin P, 2001, PERS SOC PSYCHOL REV, V5, P296, DOI 10.1207/S15327957PSPR0504_2
   Sadolin C., 2009, Complete vocal technique
   Salimpoor VN, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0007487
   Schäfer T, 2009, PSYCHOL MUSIC, V37, P279, DOI 10.1177/0305735608097247
   Scherer K. R., 2001, MUSIC EMOTION THEORY, P361, DOI DOI 10.1080/0929821042000317822
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   Schindler I, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0178899
   Seidner W., 1998, AUSDRUCKSWELT STIMME, P72
   Stone RE, 2003, J VOICE, V17, P283, DOI 10.1067/S0892-1997(03)00074-2
   Sundberg J., 2006, Adv. Cognit. Psychol., V2, P131
   Sundberg J, 2010, J VOICE, V24, P654, DOI 10.1016/j.jvoice.2009.03.003
   Thalen M, 2001, Logoped Phoniatr Vocol, V26, P82
   vanBezooijen R, 1995, LANG SPEECH, V38, P253, DOI 10.1177/002383099503800303
   Von Appen R., 2007, The value of music: On the aesthetics of the popular, V4, DOI [10.14361/9783839407349, DOI 10.14361/9783839407349]
   Wilk R. R., 1997, CONSUMP MARK CULT, V1, P175, DOI DOI 10.1080/10253866.1997.9670297
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 68
TC 0
Z9 0
U1 2
U2 2
PU EDUCATIONAL PUBLISHING FOUNDATION-AMERICAN PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST, NE, WASHINGTON, DC 20002-4242 USA
SN 1931-3896
EI 1931-390X
J9 PSYCHOL AESTHET CREA
JI Psychol. Aesthet. Creat. Arts.
PD OCT
PY 2023
VL 17
IS 5
BP 562
EP 580
DI 10.1037/aca0000376
PG 19
WC Humanities, Multidisciplinary; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Arts & Humanities - Other Topics; Psychology
GA U3PC7
UT WOS:001083941100004
OA Green Submitted
DA 2024-01-09
ER

PT J
AU Sweet, B
   Parker, EC
AF Sweet, Bridget
   Parker, Elizabeth Cassidy
TI Female Vocal Identity Development: A Phenomenology
SO JOURNAL OF RESEARCH IN MUSIC EDUCATION
LA English
DT Article
DE vocal identity; female singers; choral research
ID EMERGING ADULTHOOD; VOICE
AB The purpose of our phenomenology was to investigate the lived experiences of emerging female vocal identity development (ages 19-35 years) and how participants' lived experiences shaped their future as musicians and music educators. Thirty-nine participants, freshmen through graduate students, enrolled in vocal music education or vocal performance programs within two large universities in the United States completed written responses to an open set of questions that were then discussed during a corresponding in-depth interview. Our analysis revealed four themes: (a) others as powerful influences, (b) voice classification, (c) omnipresent emotion, and (d) perceptions of future involvement. Time underwrote each theme as participants shared lived experiences that took place from age 11 into their 20s and some into the mid-30s. Therefore, consideration of chronological age within each of the themes provided deeper insight on the evolution of female vocal identity development. We found that intrapersonal and interpersonal interactions, both past and present, fostered emotional responses that influenced female vocalists' perceptions of their voice. These, in combination with encounters with voice classifications and tensions between vocal and choral teachers, influenced their ever-evolving relationship with their instrument. In addition, participants actively used lived experiences to build futures for themselves and their vocal students.
C1 [Sweet, Bridget] Univ Illinois, Mus Educ, Urbana, IL USA.
   [Parker, Elizabeth Cassidy] Temple Univ, Mus Educ, Boyer Coll Mus & Dance, Philadelphia, PA 19122 USA.
C3 University of Illinois System; University of Illinois Urbana-Champaign;
   Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple
   University
RP Sweet, B (corresponding author), Univ Illinois, Sch Mus, 1114 West Nevada St,MC-056, Urbana, IL 61801 USA.
EM bsweet@illinois.edu
FU University of Illinois College of Fine and Applied Arts Creative
   Research Award
FX The authors disclosed receipt of the following financial support for the
   research, authorship, and/or publication of this article: This study was
   supported by University of Illinois College of Fine and Applied Arts
   Creative Research Award.
CR Allsup RE, 2008, PHILOS MUSIC EDUC RE, V16, P156, DOI 10.2979/PME.2008.16.2.156
   Allsup RE, 2012, THEOR PRACT, V51, P179, DOI 10.1080/00405841.2012.690288
   Allsup RE, 2003, J RES MUSIC EDUC, V51, P24, DOI 10.2307/3345646
   [Anonymous], CHORAL J
   [Anonymous], Q J MUSIC TEACHING L
   [Anonymous], 1993, CARTESIAN MEDITATION
   [Anonymous], MUSIC ED RES, DOI DOI 10.1080/14613800220119813
   [Anonymous], THESIS
   Bandura A, 2001, ANNU REV PSYCHOL, V52, P1, DOI 10.1146/annurev.psych.52.1.1
   Bates V., 2009, ACTION CRITICISM THE, V8, P12
   Bates V. C., 2004, ACTION CRITICISM THE, V3, P1
   Brown L.M., 1992, M CROSSROADS WOMENS
   Davinson J. W., 1997, SOCIAL PSYCHOL MUSIC, P188
   Edgar S.N., 2014, ACTION CRITICISM THE, V13, P112
   Gackle L., 1991, CHORAL J, V31, P17
   Gackle L., 2011, FINDING OPHELIAS VOI
   Gackle Lynne, 2006, CHORAL J, V47, P28
   Gaunt H, 2010, PSYCHOL MUSIC, V38, P178, DOI 10.1177/0305735609339467
   Gilligan C., 1993, DIFFERENT VOICE PSYC
   Harter S., 1999, CONSTRUCTION SELF DE, pxv
   Hourigan R.M., 2014, OXFORD HDB QUALITATI, P148
   Josselson R., 1996, REVISING HERSELF STO
   Kemp AE., 1996, The Musical Temperament
   King Nigel, 2010, Interviews in Qualitative Research
   Klem AM, 2004, J SCHOOL HEALTH, V74, P262, DOI 10.1111/j.1746-1561.2004.tb08283.x
   Levinson D.J., 1996, SEASONS WOMANS LIFE
   Lincoln YS., 1985, Naturalistic inquiry, DOI DOI 10.1016/0147-1767(85)90062-8
   Manturzewska M., 1990, PSYCHOL MUSIC, V18, P112, DOI DOI 10.1177/0305735690182002
   Moustakas C., 1994, Phenomenological Research Methods, DOI [10.4135/9781412995658, DOI 10.4135/9781412995658]
   Noddings N., 2005, The Challenge to Care in Schools: An Alternative Approach to Education, V2nd ed.
   O'Bryan J., 2010, PERSPECTIVES TEACHIN, P47
   O'Bryan J, 2015, RES STUD MUSIC EDUC, V37, P123, DOI 10.1177/1321103X15592831
   O'Toole P., 2005, VISIONS RES MUSIC ED, V6
   Parker EC, 2016, J RES MUSIC EDUC, V64, P220, DOI 10.1177/0022429416648292
   Parker EC, 2015, ADV MUSIC EDUC RES, P127
   Parker EC, 2014, J RES MUSIC EDUC, V62, P18, DOI 10.1177/0022429413520009
   Patton M. Q., 2002, Qualitative Research & Evaluation Methods, V3rd ed.
   Saldana J., 2018, Qualitative research: Analyzing life
   Sameroff A., 2009, The transactional model of development: How children and contexts shape each other, P3, DOI [DOI 10.1037/11877-001, 10.1037/11877-001]
   Sameroff A, 2010, CHILD DEV, V81, P6, DOI 10.1111/j.1467-8624.2009.01378.x
   Schwartz SJ, 2005, YOUTH SOC, V37, P201, DOI 10.1177/0044118X05275965
   Serra-Dawa S., 2015, TEACHING SINGING 21, P201
   Shulman S, 2005, J ADOLESCENT RES, V20, P577, DOI 10.1177/0743558405274913
   Silverman M., 2012, ACTION CRITICISM THE, V11, P96
   Spinazzola J., 2002, CHARTING NEW COURSE, P111
   Sweet B. M., 2008, THESIS
   Sweet B, 2018, J RES MUSIC EDUC, V66, P133, DOI 10.1177/0022429418763790
   Sweet B, 2015, J RES MUSIC EDUC, V63, P70, DOI 10.1177/0022429415570755
   TANNER JL, 2006, EMERGING ADULTS AM C
   Thurman L, 2000, Bodymind and voice: Foundations of voice education, V2nd
   Van Manen M, 2016, Researching lived experience: Human science for an action sensitive pedagogy
   Welch G.F., 2005, MUSICAL COMMUNICATIO, P239, DOI DOI 10.1093/ACPROF:OSO/9780198529361.001.0001
NR 52
TC 7
Z9 17
U1 0
U2 8
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0022-4294
EI 1945-0095
J9 J RES MUSIC EDUC
JI J. Res. Music Educ.
PD APR
PY 2019
VL 67
IS 1
BP 62
EP 82
DI 10.1177/0022429418809981
PG 21
WC Education & Educational Research; Music
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Education & Educational Research; Music
GA HN0JX
UT WOS:000459875200005
OA Bronze
DA 2024-01-09
ER

PT J
AU Waaramaa, T
   Kukkonen, T
   Mykkänen, S
   Geneid, A
AF Waaramaa, Teija
   Kukkonen, Tarja
   Mykkanen, Sari
   Geneid, Ahmed
TI Vocal Emotion Identification by Children Using Cochlear Implants,
   Relations to Voice Quality, and Musical Interests
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID NORMAL-HEARING; NORMALLY-HEARING; YOUNG-CHILDREN; DEAF-CHILDREN;
   PERCEPTION; RECOGNITION; LOCALIZATION; EXPRESSION; INTONATION; AGE
AB Purpose: Listening tests for emotion identification were conducted with 8-17-year-old children with hearing impairment (HI; N = 25) using cochlear implants, and their 12-year-old peers with normal hearing (N = 18). The study examined the impact of musical interests and acoustics of the stimuli on correct emotion identification.
   Method: The children completed a questionnaire with their background information and noting musical interests. They then listened to vocal stimuli produced by actors (N = 5) and consisting of nonsense sentences and prolonged vowels ([a:], [i:], and [u:]; N = 32) expressing excitement, anger, contentment, and fear. The children's task was to identify the emotions they heard in the sample by choosing from the provided options. Acoustics of the samples were studied using Praat software, and statistics were examined using SPSS 24 software.
   Results: The children with HI identified the emotions with 57% accuracy and the normal hearing children with 75% accuracy. Female listeners were more accurate than male listeners in both groups. Those who were implanted before age of 3 years identified emotions more accurately than others (p < .05). No connection between the child's audiogram and correct identification was observed. Musical interests and voice quality parameters were found to be related to correct identification.
   Conclusions: Implantation age, musical interests, and voice quality tended to have an impact on correct emotion identification. Thus, in developing the cochlear implants, it may be worth paying attention to the acoustic structures of vocal emotional expressions, especially the formant frequency of F3. Supporting the musical interests of children with HI may help their emotional development and improve their social lives.
C1 [Waaramaa, Teija] Univ Tampere, Fac Commun Sci, Tampere Res Ctr Journalism Media & Commun COMET, Tampere, Finland.
   [Kukkonen, Tarja] Univ Tampere, Fac Social Sci Logoped, Tampere, Finland.
   [Mykkanen, Sari] Tampere Univ Hosp, Hearing Ctr, Tampere, Finland.
   [Geneid, Ahmed] Univ Helsinki, Dept Otorhinolaryngol & Phoniatr Head & Neck Surg, Helsinki, Finland.
   [Geneid, Ahmed] Helsinki Univ Hosp, Helsinki, Finland.
C3 Tampere University; Tampere University; Tampere University; Tampere
   University Hospital; University of Helsinki; University of Helsinki;
   Helsinki University Central Hospital
RP Waaramaa, T (corresponding author), Univ Tampere, Fac Commun Sci, Tampere Res Ctr Journalism Media & Commun COMET, Tampere, Finland.
EM teija.waaramaa@uta.fi
RI Geneid, Ahmed/L-7974-2015
OI Geneid, Ahmed/0000-0003-1617-1181
FU Emil Aaltonen Foundation; Finnish Cultural Foundation
FX This study was supported by the Emil Aaltonen Foundation and the Finnish
   Cultural Foundation. The authors extend their gratitude to the study
   participants, their parents and caretakers, and to Tampere University
   Hospital for their cooperation. Special thanks also go to the volunteer
   actors for providing the samples, to Tiina Syrja, D.A., for recruiting
   the actors, and to Nuutti Vapaavuori, M.A., for recording and editing
   the samples.
CR Addington DW., 1968, SPEECH MONOGR, V35, P429, DOI DOI 10.1080/03637756809375599
   Anmyr L, 2015, INT J PEDIATR OTORHI, V79, P610, DOI 10.1016/j.ijporl.2015.02.009
   [Anonymous], 2013, Neuroscience Discovery, DOI [DOI 10.7243/2052-6946-1-9, 10.7243/2052-6946-1-9]
   [Anonymous], HDB EMOTIONS
   [Anonymous], 2013, J ED AUDIOLOGY
   Boersma P., 2010, PRAAT DOWNLOADING PR
   Brown JR, 1996, CHILD DEV, V67, P789, DOI 10.1111/j.1467-8624.1996.tb01764.x
   Chao WC, 2015, INT J PEDIATR OTORHI, V79, P648, DOI 10.1016/j.ijporl.2015.02.006
   Chatterjee M, 2015, HEARING RES, V322, P151, DOI 10.1016/j.heares.2014.10.003
   Damasio A., 2005, SPAIN
   De Giacomo A, 2013, INT J PEDIATR OTORHI, V77, P1975, DOI 10.1016/j.ijporl.2013.09.015
   Dunn CC, 2008, EAR HEARING, V29, P352, DOI 10.1097/AUD.0b013e318167b870
   Dyck MJ, 2004, J CHILD PSYCHOL PSYC, V45, P789, DOI 10.1111/j.1469-7610.2004.00272.x
   Eisenberg N, 2010, ANNU REV CLIN PSYCHO, V6, P495, DOI 10.1146/annurev.clinpsy.121208.131208
   Fant G., 1970, Acoustic theory of speech production: with calculations based on Xray studies of Russian articulations
   Flavell JH, 2004, MERRILL PALMER QUART, V50, P274, DOI 10.1353/mpq.2004.0018
   FONAGY I, 1981, RES ASPECTS SINGING, V33, P51
   GAUFFIN J, 1989, J SPEECH HEAR RES, V32, P556, DOI 10.1044/jshr.3203.556
   Giannantonio S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0136685
   Gray C, 2007, J DEV PHYS DISABIL, V19, P145, DOI 10.1007/s10882-006-9029-1
   Hopyan T, 2016, CHILD NEUROPSYCHOL, V22, P366, DOI 10.1080/09297049.2014.992400
   Hopyan-Misakyan TM, 2009, CHILD NEUROPSYCHOL, V15, P136, DOI 10.1080/09297040802403682
   Hosie JA, 1998, MOTIV EMOTION, V22, P293, DOI 10.1023/A:1021352323157
   Izard CE, 2007, PERSPECT PSYCHOL SCI, V2, P260, DOI [10.1111/j.1745-6916.2007.00044.x, 10.1111/j.1745-6916.2007.00053.x]
   Jiam NT, 2017, HEARING RES, V352, P30, DOI 10.1016/j.heares.2017.01.006
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Ketelaar L, 2015, EUR CHILD ADOLES PSY, V24, P1369, DOI 10.1007/s00787-015-0688-2
   Lasak JM, 2014, PRIMARY CARE, V41, P19, DOI 10.1016/j.pop.2013.10.003
   Laukkanen A. M., 1997, LOGOP PHONIATR VOCO, V22, P157, DOI DOI 10.3109/14015439709075330
   Laukkanen A. -M., 2008, EMOTIONS HUMAN VOICE, VI, P171
   Lawrence K, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00761
   Litovsky RY, 2006, EAR HEARING, V27, P43, DOI 10.1097/01.aud.0000194515.28023.4b
   Lovett RES, 2010, ARCH DIS CHILD, V95, P107, DOI 10.1136/adc.2009.160325
   Ludlow A, 2010, J CLIN EXP NEUROPSYC, V32, P923, DOI 10.1080/13803391003596447
   Lukkarila P, 2012, LOGOP PHONIATR VOCO, V37, P158, DOI 10.3109/14015439.2012.687762
   Luo X, 2016, J ACOUST SOC AM, V140, pEL497, DOI 10.1121/1.4971758
   Mildner V, 2014, CLIN LINGUIST PHONET, V28, P543, DOI 10.3109/02699206.2014.927000
   Most T, 2012, J SPEECH LANG HEAR R, V55, P1148, DOI 10.1044/1092-4388(2011/11-0060)
   Most T, 2009, J DEAF STUD DEAF EDU, V14, P449, DOI 10.1093/deafed/enp007
   Nakata T, 2012, J ACOUST SOC AM, V131, P1307, DOI 10.1121/1.3672697
   Netten AP, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124102
   Neuman AC, 2007, EAR HEARING, V28, P73, DOI 10.1097/01.aud.0000249910.80803.b9
   PAKOSZ M, 1982, LINGUA, V56, P153, DOI 10.1016/0024-3841(82)90028-6
   PAKOSZ M, 1983, J PSYCHOLINGUIST RES, V12, P311
   Peng SC, 2008, EAR HEARING, V29, P336, DOI 10.1097/AUD.0b013e318168d94d
   Saarni C., 1999, The development of emotional competence
   Scheiner E, 2006, J VOICE, V20, P585, DOI 10.1016/j.jvoice.2005.09.001
   Schorr EA, 2009, J SPEECH LANG HEAR R, V52, P141, DOI 10.1044/1092-4388(2008/07-0213)
   Stone MA, 2008, EAR HEARING, V29, P601, DOI 10.1097/AUD.0b013e3181734ef2
   Taumoepeau M, 2008, CHILD DEV, V79, P284, DOI 10.1111/j.1467-8624.2007.01126.x
   Toivanen Juhani, 2006, Logoped Phoniatr Vocol, V31, P43, DOI 10.1080/14015430500293926
   van Hoesel RJM, 2003, J ACOUST SOC AM, V113, P1617, DOI 10.1121/1.1539520
   Voelkle MC, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00635
   Waaramaa T., 2018, INT J LISTEN, V32, P150, DOI [10.1080/10904018.2016.1250633, DOI 10.1080/10904018.2016.1250633]
   Waaramaa Teija, 2006, Logoped Phoniatr Vocol, V31, P153, DOI 10.1080/14015430500456739
   Waaramaa T, 2008, FOLIA PHONIATR LOGO, V60, P249, DOI 10.1159/000151762
   Waaramaa T, 2017, LOGOP PHONIATR VOCO, V42, P160, DOI 10.1080/14015439.2016.1243725
   Waaramaa T, 2015, LOGOP PHONIATR VOCO, V40, P156, DOI 10.3109/14015439.2014.934277
   Waaramaa T, 2015, LOGOP PHONIATR VOCO, V40, P129, DOI 10.3109/14015439.2014.915982
   Waaramaa T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00344
   Waaramaa T, 2010, J VOICE, V24, P30, DOI 10.1016/j.jvoice.2008.04.004
   Waaramaa-Maki-Kulmala T, 2009, EMOTIONS VOICE ACOUS
   Wake M, 2004, EAR HEARING, V25, P1, DOI 10.1097/01.AUD.0000111262.12219.2F
   Wei CG, 2004, HEARING RES, V197, P87, DOI 10.1016/j.heares.2004.06.002
   Wiefferink CH, 2013, J DEAF STUD DEAF EDU, V18, P175, DOI 10.1093/deafed/ens042
   Wiefferink CH, 2012, INT J PEDIATR OTORHI, V76, P883, DOI 10.1016/j.ijporl.2012.02.065
   Xin Luo, 2007, Trends Amplif, V11, P301
NR 68
TC 11
Z9 11
U1 1
U2 11
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD APR
PY 2018
VL 61
IS 4
BP 973
EP 985
DI 10.1044/2017_JSLHR-H-17-0054
PG 13
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GD4BL
UT WOS:000430447400015
PM 29587304
OA Green Accepted
DA 2024-01-09
ER

PT J
AU Franco, F
   Chew, M
   Swaine, JS
AF Franco, Fabia
   Chew, Marcia
   Swaine, Joel Simon
TI Preschoolers' attribution of affect to music: A comparison between vocal
   and instrumental performance
SO PSYCHOLOGY OF MUSIC
LA English
DT Article
DE child development; emotion; perception; performance; voice
ID MAJOR MINOR DISTINCTION; FACIAL EXPRESSIONS; WORKING-MEMORY; EMOTIONAL
   EXPRESSION; SOCIAL COMPETENCE; PERCEPTION; INFANTS; CHILDREN; YOUNG;
   RECOGNITION
AB Research has shown inconsistent results concerning the ability of young children to identify musical emotion. This study explores the influence of the type of musical performance (vocal vs. instrumental) on children's affect identification. Using an independent-group design, novel child-directed music was presented in three conditions: instrumental, vocal-only, and song (instrumental plus vocals) to 3-to 6-year-olds previously screened for language development (N = 76). A forced-choice task was used in which children chose a face expressing the emotion matching each musical track. All performance conditions comprised " happy" (major mode/ fast tempo) and " sad" (minor mode/ slow tempo) tracks. Nonsense syllables rather than words were used in the vocals in order to avoid the influence of lyrics on children's decisions. The results showed that even the younger children were able to correctly identify the intended emotion in music, although " happy" music was more readily recognised and recognition appeared facilitated in the instrumental condition. Performance condition interacted with gender.
C1 [Franco, Fabia] Middlesex Univ, London NW4 4BT, England.
   [Chew, Marcia] Univ Melbourne, Melbourne, Vic, Australia.
   [Swaine, Joel Simon] Univ Hull, Kingston Upon Hull, N Humberside, England.
C3 Middlesex University; University of Melbourne; University of Hull
RP Franco, F (corresponding author), Middlesex Univ, London NW4 4BT, England.
EM fabia1@mdx.ac.uk
FU British Academy [SG101096]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This
   research has been carried out with the support of British Academy grant
   n. SG101096.
CR Adachi M, 2004, JPN PSYCHOL RES, V46, P322, DOI 10.1111/j.1468-5584.2004.00264.x
   Allen, 2005, COMMUNICATION DISORD, V26, P131, DOI DOI 10.1177/15257401050260030201
   [Anonymous], 2008, HDB EMOTIONS
   [Anonymous], PYSCHOL MUSIC, DOI DOI 10.1177/0305735603031001325
   [Anonymous], 1997, BRIT PICTURE VOCABUL
   [Anonymous], 2011, PSYCHOMUSICOLOGY MUS, DOI [DOI 10.1037/H0094005, 10.1037/h0094005]
   Arsalidou M, 2011, BRAIN TOPOGR, V24, P149, DOI 10.1007/s10548-011-0171-4
   Balkwill LL, 2004, JPN PSYCHOL RES, V46, P337, DOI 10.1111/j.1468-5584.2004.00265.x
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Baruch C, 2004, PERCEPT MOTOR SKILL, V98, P325
   Blasi A, 2011, CURR BIOL, V21, P1220, DOI 10.1016/j.cub.2011.06.009
   Boone R. T., 2001, J NONVERBAL BEHAV, V18, P37
   Brattico E, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00308
   Bryant GA, 2008, J COGN CULT, V8, P135, DOI 10.1163/156770908X289242
   BULLOCK M, 1986, MEASURING EMOTIONS I, V2, P203
   Calvo MG, 2010, VIS COGN, V18, P1274, DOI 10.1080/13506285.2010.481867
   Camras LA, 1998, DEV PSYCHOL, V34, P616, DOI 10.1037/0012-1649.34.4.616
   Cowan N, 2003, J EXP PSYCHOL GEN, V132, P113, DOI 10.1037/0096-3445.132.1.113
   CROWDER RG, 1991, B PSYCHONOMIC SOC, V29, P187
   CUNNINGHAM JG, 1986, CHILD DEV, V57, P136, DOI 10.2307/1130645
   CUNNINGHAM JG, 1988, MOTIV EMOTION, V12, P399, DOI 10.1007/BF00992362
   CUSTRINI RJ, 1989, J CLIN CHILD PSYCHOL, V18, P336, DOI 10.1207/s15374424jccp1804_7
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   DAVIDSON L, 1985, MUSIC PERCEPT, V2, P361
   DENHAM SA, 1990, CHILD STUDY J, V20, P171
   Doherty CP, 1999, EUR J NEUROL, V6, P221, DOI 10.1111/j.1468-1331.1999.tb00016.x
   Dolgin KG., 1990, Psychol. Music, V18, P87, DOI DOI 10.1177/0305735690181007
   Drake C, 2000, COGNITION, V77, P251, DOI 10.1016/S0010-0277(00)00106-2
   Egan GJ, 1998, ARCH CLIN NEUROPSYCH, V13, P383, DOI 10.1016/S0887-6177(97)00019-X
   Ekman P., 1972, NEBRASKA S MOTIVATIO, P207, DOI DOI 10.1037/0022-3514.53.4.712
   Elfenbein HA, 2002, PSYCHOL BULL, V128, P203, DOI 10.1037//0033-2909.128.2.203
   Falk S., 2011, Psychomusicology: Music, Mind and Brain, V21, P54, DOI DOI 10.1037/H0094004
   Falk S, 2011, LANG SPEECH, V54, P167, DOI 10.1177/0023830910397490
   Feldman HM, 2000, CHILD DEV, V71, P310, DOI 10.1111/1467-8624.00146
   FERNALD A, 1987, INFANT BEHAV DEV, V10, P279, DOI 10.1016/0163-6383(87)90017-8
   FERNALD A, 1989, CHILD DEV, V60, P1497, DOI 10.2307/1130938
   Flom R, 2008, INFANT BEHAV DEV, V31, P716, DOI 10.1016/j.infbeh.2008.04.004
   Franco F, 2014, PSYCHOL MUSIC, V42, P869, DOI 10.1177/0305735614548500
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Gabrielsson A, 2003, SER AFFECTIVE SCI, P503
   Gabrielsson A., 2010, HDB MUSIC EMOTION TH, P367, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0014
   Gagnon L, 2003, COGNITION EMOTION, V17, P25, DOI 10.1080/02699930302279
   Gaillard V, 2011, J EXP CHILD PSYCHOL, V110, P469, DOI 10.1016/j.jecp.2011.05.004
   Gao XQ, 2009, J EXP CHILD PSYCHOL, V102, P503, DOI 10.1016/j.jecp.2008.11.002
   Gathercole SE, 2004, DEV PSYCHOL, V40, P177, DOI 10.1037/0012-1649.40.2.177
   GERARDI GM, 1995, MUSIC PERCEPT, V12, P279
   GIOMO CJ, 1993, PSYCHOL MUSIC, V21, P141, DOI DOI 10.1177/030573569302100204
   Goshen, 2006, BRIT J MUSIC EDUC, V23, P303, DOI [DOI 10.1017/S0265051706007078, 10.1017/S0265051706007078]
   Gregory AH, 1996, MOTIV EMOTION, V20, P341, DOI 10.1007/BF02856522
   GROSS AL, 1991, DEV REV, V11, P368, DOI 10.1016/0273-2297(91)90019-K
   Grossman JB, 2000, J CHILD PSYCHOL PSYC, V41, P369, DOI 10.1017/S0021963099005466
   Heaton P, 2008, BRIT J DEV PSYCHOL, V26, P171, DOI 10.1348/026151007X206776
   Hosie JA, 1998, MOTIV EMOTION, V22, P293, DOI 10.1023/A:1021352323157
   Hunter PG, 2011, J EXP CHILD PSYCHOL, V110, P80, DOI 10.1016/j.jecp.2011.04.001
   Hunter PG, 2010, SPRINGER HANDB AUDIT, V36, P129, DOI 10.1007/978-1-4419-6114-3_5
   IZARD CE, 1995, DEV PSYCHOL, V31, P997, DOI 10.1037/0012-1649.31.6.997
   Juslin P. N., 1996, PSYCHOL MUSIC, V24, P68, DOI [10.1177/0305735696241007, DOI 10.1177/0305735696241007]
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   KASTNER MP, 1990, MUSIC PERCEPT, V8, P189
   Kitamura G., 1998, ADV INFANCY RES, V12, P43
   Koelsch S, 2010, TRENDS COGN SCI, V14, P131, DOI 10.1016/j.tics.2010.01.002
   LaBar KS, 2003, CEREB CORTEX, V13, P1023, DOI 10.1093/cercor/13.10.1023
   Laukka P, 2013, EMOTION, V13, P434, DOI 10.1037/a0031388
   Malloch S., 1999, Musicae Scientiae, P29, DOI [10.1177/10298649000030-104, DOI 10.1177/10298649000030S104]
   MANSTEAD ASR, 1993, SYSTEMS REPRESENTATI, P185
   Mastropieri D, 1999, DEV PSYCHOBIOL, V35, P204, DOI 10.1002/(SICI)1098-2302(199911)35:3<204::AID-DEV5>3.0.CO;2-V
   McAuley JD, 2006, J EXP PSYCHOL GEN, V135, P348, DOI 10.1037/0096-3445.135.3.348
   McClure EB, 2000, PSYCHOL BULL, V126, P424, DOI 10.1037/0033-2909.126.3.424
   Molnar-Szakacs I, 2006, SOC COGN AFFECT NEUR, V1, P235, DOI 10.1093/scan/nsl029
   Morton J.B., 2007, PSYCHOL MUSIC, V35, P629, DOI [DOI 10.1177/0305735607076445, 10.1177/0305735607076445]
   Morton JB, 2001, CHILD DEV, V72, P834, DOI 10.1111/1467-8624.00318
   Mote J, 2011, EMOTION, V11, P618, DOI 10.1037/a0022573
   Nakata T, 2004, INFANT BEHAV DEV, V27, P455, DOI 10.1016/j.infbeh.2004.03.002
   Nawrot ES., 2003, Psychol. Music, V31, P75, DOI DOI 10.1177/0305735603031001325
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   PHILIPPOT P, 1990, BRIT J SOC PSYCHOL, V29, P43, DOI 10.1111/j.2044-8309.1990.tb00885.x
   Plantinga J, 2014, J EXP PSYCHOL HUMAN, V40, P40, DOI 10.1037/a0033471
   Provasi JL, 2003, INT J BEHAV DEV, V27, P220, DOI 10.1080/01650250244000290
   REICHENBACH L, 1983, CHILD DEV, V54, P993, DOI 10.1111/j.1467-8624.1983.tb00520.x
   Sambeth A, 2008, CLIN NEUROPHYSIOL, V119, P332, DOI 10.1016/j.clinph.2007.09.144
   Sauter DA, 2010, P NATL ACAD SCI USA, V107, P2408, DOI 10.1073/pnas.0908239106
   Schellenberg E. G., 2007, Psychology of Music, V35, P5, DOI [DOI 10.1177/0305735607068885, 10.1177/0305735607068885]
   Scherer K.R., 1988, COGNITIVE PERSPECTIV, P89, DOI DOI 10.1007/978-94-009-2792-6_4
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   SCHERER KR, 1985, ADV STUD BEHAV, V15, P189, DOI 10.1016/S0065-3454(08)60490-8
   Shenfield T., 2003, Psychol. Music, V31, P365, DOI DOI 10.1177/03057356030314002
   Stachó L, 2013, MUSIC SCI, V17, P495, DOI 10.1177/1029864913497617
   Terwogt M. M., 1991, PSYCHOL MUSIC, V19, P99, DOI DOI 10.1177/0305735691192001
   Tottenham N, 2009, PSYCHIAT RES, V168, P242, DOI 10.1016/j.psychres.2008.05.006
   Trainor LJ, 2007, EMPIR MUSICOL REV, V2, P17, DOI 10.18061/1811/24480
   Trainor LJ, 1998, INFANT BEHAV DEV, V21, P77, DOI 10.1016/S0163-6383(98)90055-8
   Trainor LJ, 2002, MUSIC PERCEPT, V20, P187, DOI 10.1525/mp.2002.20.2.187
   Trainor LJ, 2000, PSYCHOL SCI, V11, P188, DOI 10.1111/1467-9280.00240
   Trehub S. E., 1998, Advances in Infancy Research, V12, P43
   Trehub SE, 2001, MUSIC SCI, V5, P37, DOI 10.1177/10298649020050S103
   Trehub SE, 2003, NAT NEUROSCI, V6, P669, DOI 10.1038/nn1084
   TREHUB SE, 1993, INFANT BEHAV DEV, V16, P193, DOI 10.1016/0163-6383(93)80017-3
   van Noorden L, 2014, PROCD SOC BEHV, V126, P117, DOI 10.1016/j.sbspro.2014.02.336
   Van Puyvelde M, 2010, INFANT BEHAV DEV, V33, P387, DOI 10.1016/j.infbeh.2010.04.003
   Vanneste S, 2001, EXP AGING RES, V27, P83, DOI 10.1080/03610730125798
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   Vuontela V, 2003, LEARN MEMORY, V10, P74, DOI 10.1101/lm.53503
   Wehrle T, 2000, J PERS SOC PSYCHOL, V78, P105, DOI 10.1037/0022-3514.78.1.105
   Welch G.F., 2005, MUSICAL COMMUNICATIO, P239, DOI DOI 10.1093/ACPROF:OSO/9780198529361.001.0001
   Young S, 2002, B COUN RES MUSIC ED, P43
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
   Zentner MR, 1998, INFANT BEHAV DEV, V21, P483, DOI 10.1016/S0163-6383(98)90021-2
NR 107
TC 8
Z9 11
U1 0
U2 23
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0305-7356
EI 1741-3087
J9 PSYCHOL MUSIC
JI Psychol. Music
PD JAN
PY 2017
VL 45
IS 1
BP 131
EP 149
DI 10.1177/0305735616652954
PG 19
WC Psychology, Educational; Psychology, Applied; Music; Psychology,
   Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Psychology; Music
GA EP2QD
UT WOS:000397227300010
OA Green Accepted
DA 2024-01-09
ER

PT J
AU Scherer, KR
   Sundberg, J
   Fantini, B
   Trznadel, S
   Eyben, F
AF Scherer, Klaus R.
   Sundberg, Johan
   Fantini, Bernardino
   Trznadel, Stephanie
   Eyben, Florian
TI The expression of emotion in the singing voice: Acoustic patterns in
   vocal performance
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID PERCEPTION; COMMUNICATION
AB There has been little research on the acoustic correlates of emotional expression in the singing voice. In this study, two pertinent questions are addressed: How does a singer's emotional interpretation of a musical piece affect acoustic parameters in the sung vocalizations? Are these patterns specific enough to allow statistical discrimination of the intended expressive targets? Eight professional opera singers were asked to sing the musical scale upwards and downwards (using meaningless content) to express different emotions, as if on stage. The studio recordings were acoustically analyzed with a standard set of parameters. The results show robust vocal signatures for the emotions studied. Overall, there is a major contrast between sadness and tenderness on the one hand, and anger, joy, and pride on the other. This is based on low vs high levels on the components of loudness, vocal dynamics, high perturbation variation, and a tendency for high low-frequency energy. This pattern can be explained by the high power and arousal characteristics of the emotions with high levels on these components. A multiple discriminant analysis yields classification accuracy greatly exceeding chance level, confirming the reliability of the acoustic patterns. (C) 2017 Author(s).
C1 [Scherer, Klaus R.] Univ Geneva, Dept Psychol, Blvd Pont dArve, 40, CH-1211 Geneva, Switzerland.
   [Sundberg, Johan] KTH Royal Inst Technol, Sch Comp Sci & Commun, Dept Speech Mus Hearing, SE-10044 Stockholm, Sweden.
   [Fantini, Bernardino] Univ Geneva, 24 Rue Gen Dufour, CH-1211 Geneva, Switzerland.
   [Trznadel, Stephanie] Univ Geneva, Swiss Ctr Affect Sci, Campus Biotech 9,Chemin Mines, CH-1202 Geneva, Switzerland.
   [Eyben, Florian] audEERING GmbH, Landsbergerstr 46 D, D-82205 Gilching, Germany.
C3 University of Geneva; Royal Institute of Technology; University of
   Geneva; University of Geneva
RP Scherer, KR (corresponding author), Univ Geneva, Dept Psychol, Blvd Pont dArve, 40, CH-1211 Geneva, Switzerland.
EM Klaus.Scherer@unige.ch
FU ERC in the European Community [230331-PROPEREMO]; National Center of
   Competence in Research (NCCR) Affective Sciences - Swiss National
   Science Foundation [51NF40-104897]
FX The work reported here was conducted by members of the Music and Emotion
   Focus of the Swiss Center for Affective Sciences (K.R.S., B.F., Eduardo
   Coutinho, and their collaborators). The research was funded by an ERC
   Advanced Grant in the European Community's 7th Framework Programme under
   grant agreement 230331-PROPEREMO (Production and perception of emotion:
   an affective sciences approach) to K.R.S and by the National Center of
   Competence in Research (NCCR) Affective Sciences financed by the Swiss
   National Science Foundation (51NF40-104897) and hosted by the University
   of Geneva. The authors thank the opera singers for their collaboration
   and Lucas Tamarit for supervising the recordings.
CR [Anonymous], P INTERSPEECH 2013 A
   [Anonymous], 2013, EMOTIONAL POWER MUSI
   [Anonymous], 2014, OXFORD HDB SINGING
   [Anonymous], PSYCHOACOUSTICS FACT
   [Anonymous], 3523 STLQPSR
   Bachorowski JA, 2003, ANN NY ACAD SCI, V1000, P244, DOI 10.1196/annals.1280.012
   Bachorowski JA, 1999, CURR DIR PSYCHOL SCI, V8, P53, DOI 10.1111/1467-8721.00013
   Bänziger T, 2012, EMOTION, V12, P1161, DOI 10.1037/a0025827
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Bänziger T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0136675
   Cochrane T., 2013, The Emotional Power of Music: Multidisciplinary Perspectives on Musical Arousal, Expression, and Social Control
   Darwin C., 1872, The Expression of the Emotions in Man and Animals
   Dromey C, 2015, J VOICE, V29, P170, DOI 10.1016/j.jvoice.2014.06.007
   Ekman Paul, 1997, What the face reveals: Basic and applied studies of spontaneous expression using the Facial Action Coding System (FACS), DOI DOI 10.1093/ACPROF:OSO/9780195179644.003.0002
   Eyben F, 2016, SPRINGER THESES-RECO, P1, DOI 10.1007/978-3-319-27299-3
   Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417
   Eyben F, 2015, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-015-0057-6
   Fontaine Johnny R. J., 2013, Components of Emotional Meaning: A Sourcebook
   Gobl C, 2003, SPEECH COMMUN, V40, P189, DOI 10.1016/S0167-6393(02)00082-1
   Goudbeek M, 2010, J ACOUST SOC AM, V128, P1322, DOI 10.1121/1.3466853
   Guzman M, 2013, J VOICE, V27, DOI 10.1016/j.jvoice.2012.08.008
   HAMMARBERG B, 1980, ACTA OTO-LARYNGOL, V90, P441, DOI 10.3109/00016488009131746
   Harnmerschmidt K, 2007, J VOICE, V21, P531, DOI 10.1016/j.jvoice.2006.03.002
   Harrigan J. A., 2005, NEW HDB METHODS NONV, P65, DOI DOI 10.1093/ACPROF:OSO/9780198529620.003.0003
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423
   Howes P, 2004, J VOICE, V18, P216, DOI 10.1016/j.jvoice.2003.09.003
   Jansens S., 1997, P 5 EUR C SPEECH COM, P2155
   Juslin P. N., 1996, PSYCHOL MUSIC, V24, P68, DOI [10.1177/0305735696241007, DOI 10.1177/0305735696241007]
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   KOTLYAR GM, 1976, SOV PHYS ACOUST+, V22, P208
   Owren M. J., 2007, HDB EMOTION ELICITAT, P239
   Patel S, 2011, BIOL PSYCHOL, V87, P93, DOI 10.1016/j.biopsycho.2011.02.010
   Prame E, 1997, J ACOUST SOC AM, V102, P616, DOI 10.1121/1.419735
   Reddy AA, 2015, J VOICE, V29, P603, DOI 10.1016/j.jvoice.2014.09.022
   Russell JA, 2003, ANNU REV PSYCHOL, V54, P329, DOI 10.1146/annurev.psych.54.101601.145102
   Scherer K. R., 2013, COMPONENTS EMOTIONAL, P186, DOI DOI 10.1093/ACPROF:OSO/9780199592746.003.0013
   Scherer KR, 2015, COMPUT SPEECH LANG, V29, P218, DOI 10.1016/j.csl.2013.10.002
   Scherer KR, 2011, INT J PSYCHOL, V46, P401, DOI 10.1080/00207594.2011.626049
   Scherer KR, 2006, COGNITION EMOTION, V20, P92, DOI 10.1080/02699930500305016
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Scherer KR, 2003, SER AFFECTIVE SCI, P433
   Sherman M, 1928, J EXP PSYCHOL, V11, P495, DOI 10.1037/h0075703
   Sundberg J, 2000, PHONETICA, V57, P95, DOI 10.1159/000028465
   Sundberg J, 1995, VOCAL FOLD, P217
   Sundberg J, 2011, IEEE T AFFECT COMPUT, V2, P162, DOI 10.1109/T-AFFC.2011.14
   Ververidis D, 2006, SPEECH COMMUN, V48, P1162, DOI 10.1016/j.specom.2006.04.003
   Weninger F, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00292
NR 49
TC 29
Z9 36
U1 3
U2 22
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD OCT
PY 2017
VL 142
IS 4
BP 1805
EP 1815
DI 10.1121/1.5002886
PG 11
WC Acoustics; Audiology & Speech-Language Pathology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Acoustics; Audiology & Speech-Language Pathology
GA FK5HP
UT WOS:000413528900021
PM 29092548
OA hybrid
DA 2024-01-09
ER

PT J
AU Merrill, J
AF Merrill, Julia
TI Auditory perceptual assessment of voices: Examining perceptual ratings
   as a function of voice experience
SO CURRENT PSYCHOLOGY
LA English
DT Article
DE Voices; Vocal features; Singing; Expression; Phonetics; Speech
   perception
ID EMOTION; SPEECH; LISTENERS; QUALITY; SINGERS
AB Understanding voice usage is vital to our understanding of human interaction. What is known about the auditory perceptual evaluation of voices comes mainly from studies of voice professionals, who evaluate operatic/lyrical singing in specific contexts. This is surprising as recordings of singing voices from different musical styles are an omnipresent phenomenon, evoking reactions in listeners with various levels of expertise. Understanding how untrained listeners perceive and describe voices will open up new research possibilities and enhance vocal communication between listeners. Here three studies with a mixed-methods approach aimed at: (1) evaluating the ability of untrained listeners to describe voices, and (2) determining what auditory features were most salient in participants' discrimination of voices. In an interview (N = 20) and a questionnaire study (N = 48), free voice descriptions by untrained listeners of 23 singing voices primarily from popular music were compared with terms used by voice professionals, revealing that participants were able to describe voices using vocal characteristics from essential categories indicating sound quality, pitch changes, articulation, and variability in expression. Nine items were derived and used in an online survey for the evaluation of six voices by trained and untrained listeners in a German (N = 216) and an English (N = 50) sample, revealing that neither language nor expertise affected the assessment of the singers. A discriminant analysis showed that roughness and tension were important features for voice discrimination. The measurement of vocal expression created in the current study will be informative for studying voice perception and evaluation more generally.
C1 [Merrill, Julia] Max Planck Inst Empir Aesthet, Grtineburgweg 14, D-60322 Frankfurt, Germany.
   [Merrill, Julia] Univ Kassel, Inst Mus, Kassel, Germany.
C3 Universitat Kassel
RP Merrill, J (corresponding author), Max Planck Inst Empir Aesthet, Grtineburgweg 14, D-60322 Frankfurt, Germany.; Merrill, J (corresponding author), Univ Kassel, Inst Mus, Kassel, Germany.
EM julia.merrill@ae.mpg.de
FU Projekt DEAL
FX Open Access funding enabled and organized by Projekt DEAL.
CR Ackermann T.-I., 2021, RATIONALES FUNCTIONS, DOI [10.31234/osf.io/5zuwp, DOI 10.31234/OSF.IO/5ZUWP]
   Ackermann T.-I., 2019, Disliked Music: Features, rationales and functions of rejected music, DOI [10.17170/kobra-202007161459, DOI 10.17170/KOBRA-202007161459]
   ANDERS LC, 1988, FOLIA PHONIATR, V40, P91, DOI 10.1159/000265889
   [Anonymous], 1994, Sprache, Stimme, Gehor
   Babel M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0088616
   Bänziger T, 2014, J NONVERBAL BEHAV, V38, P31, DOI 10.1007/s10919-013-0165-x
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Baumeister R. F., 2001, Rev. Gen. Psychol, V5, P323, DOI [DOI 10.1037/1089-2680.5.4.323, 10.1037/1089-2680.5.4.323]
   Bigand E, 2006, COGNITION, V100, P100, DOI 10.1016/j.cognition.2005.11.007
   Bose I., 2001, Gesprachsforschung: Online-Zeitschrift zur Verbalen Interaktion, V2, P262
   Cleveland TE, 2001, J VOICE, V15, P54, DOI 10.1016/S0892-1997(01)00006-6
   Colton R. H., 1987, J VOICE, V1, P240, DOI [10.1016/S0892-1997(87)80006-1, DOI 10.1016/S0892-1997(87)80006-1]
   Ekholm E, 1998, J VOICE, V12, P182, DOI 10.1016/S0892-1997(98)80038-6
   Garnier M, 2007, J INTERDISCIP MUSIC, V1, P62
   Greasley A, 2013, QUAL RES PSYCHOL, V10, P402, DOI 10.1080/14780887.2011.647259
   H?hnel T., 2015, TEXTE POPULAREN MUSI, V8, P53, DOI [10.1515/9783839430866-002, DOI 10.1515/9783839430866-002]
   Hellbernd N, 2016, J MEM LANG, V88, P70, DOI 10.1016/j.jml.2016.01.001
   Henrich N., 2008, J INT DISCIPL MUSIC, V2, P71
   HIRANO M, 1989, FOLIA PHONIATR, V41, P89, DOI 10.1159/000265950
   Hirano M, 1981, CLIN EXAMINATION VOI
   Hollien H., 2000, Voice quality measurement, P13
   Kreiman J, 1998, J ACOUST SOC AM, V104, P1598, DOI 10.1121/1.424372
   Kreiman J, 2007, J ACOUST SOC AM, V122, P2354, DOI 10.1121/1.2770547
   Larrouy-Maestri P., 2018, Music Science, V1, DOI DOI 10.1177/2059204318784582
   Laver J., 1980, Cambridge studies in linguistics, V31
   Mathieson L., 2001, Greene and Mathieson's The Voice and Its Disorders
   Merrill J., 2020, MIXED METHODS APPROA, DOI [10.1037/aca0000376, DOI 10.1037/ACA0000376]
   Merrill J., 2019, Z SPRECHWISSENSCHAFT, V68, P42
   Merrill J, 2017, ACTA MUSICOLOGICA, V89, P95
   Merrill J, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01108
   Mitchell HF., 2014, TEACHING SINGING 21, P187, DOI DOI 10.1007/978-94-017-8851-9_12
   Oates JM, 2006, J VOICE, V20, P71, DOI 10.1016/j.jvoice.2005.01.006
   Reddy AA, 2015, J VOICE, V29, P603, DOI 10.1016/j.jvoice.2014.09.022
   Rozin P, 2001, PERS SOC PSYCHOL REV, V5, P296, DOI 10.1207/S15327957PSPR0504_2
   Sadolin C., 2009, Complete vocal technique
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Stone RE, 2003, J VOICE, V17, P283, DOI 10.1067/S0892-1997(03)00074-2
   SUNDBERG J, 1975, ACUSTICA, V32, P89
   Sundberg J, 2010, J VOICE, V24, P654, DOI 10.1016/j.jvoice.2009.03.003
   Thalen M, 2001, Logoped Phoniatr Vocol, V26, P82
   Wapnick J, 1997, J VOICE, V11, P429, DOI 10.1016/S0892-1997(97)80039-2
   Webb AL, 2004, EUR ARCH OTO-RHINO-L, V261, P429, DOI 10.1007/s00405-003-0707-7
   ZUCKERMAN M, 1993, J NONVERBAL BEHAV, V17, P119, DOI 10.1007/BF01001960
NR 43
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1046-1310
EI 1936-4733
J9 CURR PSYCHOL
JI Curr. Psychol.
PD JUN
PY 2023
VL 42
IS 17
BP 14334
EP 14349
DI 10.1007/s12144-022-02734-7
EA JAN 2022
PG 16
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA L4AL7
UT WOS:000749122600003
OA hybrid, Green Submitted
DA 2024-01-09
ER

PT J
AU Punamäki, RL
   Vänskä, M
   Quota, SR
   Perko, K
   Diab, SY
AF Punamaki, Raija-Leena
   Vanska, Mervi
   Quota, Samir R.
   Perko, Kaisa
   Diab, Safwat Y.
TI Vocal emotion expressions in infant-directed singing: The impact of war
   trauma and maternal mental health and the consequences on infant
   development
SO INFANT AND CHILD DEVELOPMENT
LA English
DT Article
DE infant development; infant-directed singing; maternal depression;
   maternal PTSD; vocal emotion expression
ID POSTTRAUMATIC-STRESS-DISORDER; POSTNATAL DEPRESSION;
   CULTURAL-DIFFERENCES; CHILD-DEVELOPMENT; MOTHERS; SPEECH; VOICE; MUSIC;
   QUESTIONNAIRE; BEHAVIOR
AB Maternal singing is considered vital to infant well-being. This study focuses on vocal emotion expressions in infant-directed singing among mothers in war conditions. It examines the questions: (a) how traumatic war events and mental health problems are associated with the content and valence of vocal emotion expressions and (b) how these emotion expressions are associated with infant development. The vocal material consists of songs sung by 50 Palestinian mothers who participated at delivery (T1) as well as when their infants were 6 (T2) and 18 (T3) months of age. These mothers reported traumatic war events (T1); depressive and post-traumatic stress disorder (PTSD) symptoms (T2-T3); and infants' emotional, sensorimotor, and cognitive development (T2-T3). Student judges evaluated the valence and content of vocal emotion expressions in maternal infant-directed singing (playfulness-vivacity, fear, joy, sadness, love-tenderness, anger, and tension). Severe traumatic war events and depressive symptoms were associated with low positive and high negative vocal emotion expressions. High levels of playfulness and joy, as well as low levels of fear and tension, were associated with infant positive affectivity, while low levels of fear, anger, and tension were associated with advanced infant language skills. Discussion focuses on the vocal markers of maternal mental health and infant development.
   Highlights
   How are maternal war trauma and mental health problems (symptoms of depression and post-traumatic stress disorder [PTSD]) associated with the valence and content of mothers' vocal emotion expressions when they sing to their infants?
   How are the maternal vocal emotion expressions associated with infant emotional and sensorimotor development?
   Methodologically, the study involved cultural in- and out-group judges to evaluate maternal vocal emotion expressions. The vocal material consisted of song excerpts of 50 Palestinian women from the Gaza strip, which is sung in Arabic. War trauma was photodocumented; mothers reported their symptoms of depression and PTSD; and infant emotion development by the Infant Behavior Questionnaire (IBQ), sensorimotor development, is based on the Bayley test.
   Maternal vocal emotion expression in infant-directed singing can provide a marker for her mental health in transition to parenthood. Further, valence and content of infant-directed singing are vital for infant emotional and sensorimotor development.
C1 [Punamaki, Raija-Leena; Vanska, Mervi; Perko, Kaisa; Diab, Safwat Y.] Tampere Univ, Fac Social Sci, Psychol, Tampere 33014, Finland.
   [Quota, Samir R.] IUG, Dept Educ & Psychol, Gaza, Palestine.
   [Quota, Samir R.] Doha Inst Grad Students, Sch Social & Humanitarian Studies, Doha, Qatar.
C3 Tampere University; Doha Institute for Graduate Studies
RP Punamäki, RL (corresponding author), Tampere Univ, Fac Social Sci, Psychol, Tampere 33014, Finland.
EM raija-leena.punamaki-gitai@tuni.fi
OI Punamaki, Raija-Leena/0000-0003-4385-3073; Diab,
   Safwat/0000-0001-6483-7182
FU Academy of Finland [25012751971]; Jacobs Foundation [25021024]
FX Academy of Finland, Grant/Award Number: 25012751971; Jacobs Foundation,
   Grant/Award Number: 25021024
CR [Anonymous], 2009, INT J CULTURE MENTAL, DOI DOI 10.1080/17542860802456620
   [Anonymous], 2009, EXPRESS EMOT MAN
   [Anonymous], INFANT MENTAL HLTH J
   [Anonymous], 2 STAGE LEAST SQUARE
   [Anonymous], UN IND COMM INQ 2014
   [Anonymous], PRENATAL PERIOD MIDD
   Arnon S, 2014, ACTA PAEDIATR, V103, P1039, DOI 10.1111/apa.12744
   Baherie A, 2013, BAYLEY SENSORY MOTOR
   Bergeson TR, 1999, INFANT BEHAV DEV, V22, P51, DOI 10.1016/S0163-6383(99)80005-8
   BETTES BA, 1988, CHILD DEV, V59, P1089, DOI 10.2307/1130275
   Bieleninik L, 2016, PEDIATRICS, V138, DOI 10.1542/peds.2016-0971
   Biringen Z, 2012, DEV PSYCHOPATHOL, V24, P1, DOI 10.1017/S0954579411000617
   Braun S, 2014, PSYCHOPATHOLOGY, V47, P327, DOI 10.1159/000363247
   Brummelte S, 2016, HORM BEHAV, V77, P153, DOI 10.1016/j.yhbeh.2015.08.008
   Calkins S. D., 2007, HDB EMOTION REGULATI, P229
   Carolan M, 2012, MIDWIFERY, V28, P321, DOI 10.1016/j.midw.2011.04.009
   Corbeil M, 2016, INFANCY, V21, P373, DOI 10.1111/infa.12114
   Corbeil M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00372
   COX JL, 1987, BRIT J PSYCHIAT, V150, P782, DOI 10.1007/978-94-007-1694-0_2
   Dalgleish T, 2015, COGNITION EMOTION OR
   Diab SY, 2018, INFANT BEHAV DEV, V50, P284, DOI 10.1016/j.infbeh.2017.05.008
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Elfenbein HA, 2002, PSYCHOL BULL, V128, P203, DOI 10.1037//0033-2909.128.2.203
   Field Tiffany, 2017, J Pregnancy Child Health, V4, DOI 10.4172/2376-127X.1000301
   Field T, 2009, INFANT BEHAV DEV, V32, P10, DOI 10.1016/j.infbeh.2008.09.005
   Filippa M, 2017, ACTA PAEDIATR, V106, P1220, DOI 10.1111/apa.13832
   Filippa M, 2013, ACTA PAEDIATR, V102, P1017, DOI 10.1111/apa.12356
   Flykt M, 2010, INFANT CHILD DEV, V19, P530, DOI 10.1002/icd.679
   Frijda N. H., 1994, EMOTION CULTURE EMPI, P51, DOI DOI 10.1037/10152-002
   Greenland S, 2003, EPIDEMIOLOGY, V14, P300, DOI 10.1097/00001648-200305000-00009
   JAMES LR, 1978, PSYCHOL BULL, V85, P1104, DOI 10.1037/0033-2909.85.5.1104
   Jardri R, 2012, INT J DEV NEUROSCI, V30, P159, DOI 10.1016/j.ijdevneu.2011.11.002
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kaitz M, 2009, INFANT MENT HEALTH J, V30, P158, DOI 10.1002/imhj.20209
   Kaplan PS, 1999, CHILD DEV, V70, P560, DOI 10.1111/1467-8624.00041
   Kivijärvi M, 2001, INFANT MENT HEALTH J, V22, P627, DOI 10.1002/imhj.1023
   KOPPARTHI R, 1991, J DEV BEHAV PEDIATR, V12, P217
   Kraus MW, 2017, AM PSYCHOL, V72, P644, DOI 10.1037/amp0000147
   Larsen R. J., 1992, Emotion: Review of Personality and Social Psychology, P25, DOI DOI 10.1177/0004867420943943
   Laukka P, 2014, EMOTION, V14, P445, DOI 10.1037/a0036048
   Laukka P, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00353
   LeBeau R, 2014, PSYCHIAT RES, V218, P143, DOI 10.1016/j.psychres.2014.03.032
   LeBreton JM, 2008, ORGAN RES METHODS, V11, P815, DOI 10.1177/1094428106296642
   Leerkes EM, 2017, J PERS ASSESS, V99, P94, DOI 10.1080/00223891.2016.1185612
   Lefkovics E, 2014, INFANT MENT HEALTH J, V35, P354, DOI 10.1002/imhj.21450
   Leventhal AM, 2008, BEHAV MODIF, V32, P759, DOI 10.1177/0145445508317167
   Lyytinen P., 2000, Assessment of vocal and motoric development in infancy
   Malarbi S, 2017, NEUROSCI BIOBEHAV R, V72, P68, DOI 10.1016/j.neubiorev.2016.11.004
   Matsumoto D, 2002, COGNITION EMOTION, V16, P721, DOI 10.1080/02699930143000608
   Matthey S, 2006, ARCH WOMEN MENT HLTH, V9, P309, DOI 10.1007/s00737-006-0152-x
   MOLLICA RF, 1992, J NERV MENT DIS, V180, P111, DOI 10.1097/00005053-199202000-00008
   Nakata T, 2004, INFANT BEHAV DEV, V27, P455, DOI 10.1016/j.infbeh.2004.03.002
   Parkinson B., 2005, EMOTION SOCIAL RELAT
   Parsons CE, 2012, BRIT MED BULL, V101, P57, DOI 10.1093/bmb/ldr047
   Pearson RM, 2012, INFANT BEHAV DEV, V35, P613, DOI 10.1016/j.infbeh.2012.07.020
   Persico G, 2017, WOMEN BIRTH, V30, pE214, DOI 10.1016/j.wombi.2017.01.007
   Putnam SP, 2014, J PERS ASSESS, V96, P445, DOI 10.1080/00223891.2013.841171
   Puura K, 2013, EUR CHILD ADOLES PSY, V22, pS279
   Qureshi SU, 2011, J NEUROPSYCH CLIN N, V23, P16, DOI 10.1176/appi.neuropsych.23.1.16
   Raikes H, 2006, CHILD DEV, V77, P924, DOI 10.1111/j.1467-8624.2006.00911.x
   Reck C, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194763
   Reddy V, 2019, DEV PSYCHOL, V55, P2020, DOI 10.1037/dev0000773
   Reissland N, 2003, J CHILD PSYCHOL PSYC, V44, P255, DOI 10.1111/1469-7610.00118
   Rock AML, 1999, DEV PSYCHOL, V35, P527, DOI 10.1037/0012-1649.35.2.527
   Saxton M., 2017, Child Language: Acquisition and Development
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   Shenfield T., 2003, Psychol. Music, V31, P365, DOI DOI 10.1177/03057356030314002
   Tanaka A, 2010, PSYCHOL SCI, V21, P1259, DOI 10.1177/0956797610380698
   Trainor LJ, 1996, INFANT BEHAV DEV, V19, P83, DOI 10.1016/S0163-6383(96)90046-6
   Trainor LJ, 1997, INFANT BEHAV DEV, V20, P383, DOI 10.1016/S0163-6383(97)90009-6
   Trehub S. E., 1998, Advances in Infancy Research, V12, P43
   Trehub SE, 2016, SOC DEV, V25, P665, DOI 10.1111/sode.12164
   Trehub SE, 1997, CAN J EXP PSYCHOL, V51, P385, DOI 10.1037/1196-1961.51.4.385
   TREHUB SE, 1993, INFANT BEHAV DEV, V16, P193, DOI 10.1016/0163-6383(93)80017-3
   Ullsten A., 2017, Music and Medicine, V9, P73, DOI [10.47513/mmd, DOI 10.47513/MMD]
   Ullsten A, 2017, NORD J MUSIC THER, V26, P142, DOI 10.1080/08098131.2015.1131187
   Ullsten A, 2017, ACTA PAEDIATR, V106, P361, DOI 10.1111/apa.13731
   Vally Z, 2015, J CHILD PSYCHOL PSYC, V56, P865, DOI 10.1111/jcpp.12352
   van der Hart O, 2005, J TRAUMA STRESS, V18, P413, DOI 10.1002/jts.20049
   van Ee E, 2012, INFANT MENT HEALTH J, V33, P459, DOI 10.1002/imhj.21324
   Virtala P, 2018, ANN NY ACAD SCI, V1423, P92, DOI 10.1111/nyas.13646
NR 81
TC 2
Z9 3
U1 1
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1522-7227
EI 1522-7219
J9 INFANT CHILD DEV
JI Infant Child Dev.
PD MAY
PY 2020
VL 29
IS 3
DI 10.1002/icd.2176
EA FEB 2020
PG 23
WC Psychology, Developmental
WE Social Science Citation Index (SSCI)
SC Psychology
GA LY5HR
UT WOS:000512450200001
OA Green Accepted
DA 2024-01-09
ER

PT J
AU Sivathasan, S
   Dahary, H
   Burack, JA
   Quintin, EM
AF Sivathasan, Shalini
   Dahary, Hadas
   Burack, Jacob A.
   Quintin, Eve-Marie
TI Basic emotion recognition of children on the autism spectrum is enhanced
   in music and typical for faces and voices
SO PLOS ONE
LA English
DT Article
ID PERVASIVE DEVELOPMENTAL DISORDERS; CIRCUMPLEX MODEL; PITCH
   DISCRIMINATION; FACIAL EXPRESSIONS; COMPLEX EMOTION; BRAIN; MIND;
   ADULTS; INDIVIDUALS; MONTREAL
AB In contrast with findings of reduced facial and vocal emotional recognition (ER) accuracy, children on the autism spectrum (AS) demonstrate comparable ER skills to those of typically-developing (TD) children using music. To understand the specificity of purported ER differences, the goal of this study was to examine ER from music compared with faces and voices among children on the AS and TD children. Twenty-five children on the AS and 23 TD children (6-13 years) completed an ER task, using categorical (happy, sad, fear) and dimensional (valence, arousal) ratings, of emotions presented via music, faces, or voices. Compared to the TD group, the AS group showed a relative ER strength from music, and comparable performance from faces and voices. Although both groups demonstrated greater vocal ER accuracy, the children on the AS performed equally well with music and faces, whereas the TD children performed better with faces than with music. Both groups performed comparably with dimensional ratings, except for greater variability by the children on the AS in valence ratings for happy emotions. These findings highlight a need to re-examine ER of children on the AS, and to consider how facilitating strengths-based approaches can re-shape our thinking about and support for persons on the AS.
C1 [Sivathasan, Shalini; Dahary, Hadas; Burack, Jacob A.; Quintin, Eve-Marie] McGill Univ, Dept Educ & Counselling Psychol, Montreal, PQ, Canada.
   [Sivathasan, Shalini; Dahary, Hadas; Burack, Jacob A.; Quintin, Eve-Marie] McGill Univ, Montreal Neurol Inst, Azrieli Ctr Autism Res, Montreal, PQ, Canada.
   [Sivathasan, Shalini; Dahary, Hadas; Quintin, Eve-Marie] McGill Univ, Ctr Res Mus Brain & Language, Montreal, PQ, Canada.
C3 McGill University; McGill University; McGill University
RP Quintin, EM (corresponding author), McGill Univ, Dept Educ & Counselling Psychol, Montreal, PQ, Canada.; Quintin, EM (corresponding author), McGill Univ, Montreal Neurol Inst, Azrieli Ctr Autism Res, Montreal, PQ, Canada.; Quintin, EM (corresponding author), McGill Univ, Ctr Res Mus Brain & Language, Montreal, PQ, Canada.
EM eve-marie.quintin@mcgill.ca
OI Sivathasan, Shalini/0000-0002-7324-5039; Quintin,
   Eve-Marie/0000-0001-8671-7480
FU Social Sciences and Humanities Research Council of Canada; Fonds de
   Recherche du Quebec Sante; Organization for Autism Research
FX Support for this research was provided by the Social Sciences and
   Humanities Research Council of Canada (https://www.sshrc-crsh.gc.ca/) to
   SS and EMQ, Fonds de Recherche du Quebec Sante
   (https://frq.gouv.qc.ca/en/health/) to EMQ, and the Organization for
   Autism Research (https://researchautism.org/) to SS. The funders had no
   role in study design, data collection and analysis, decision to publish,
   or preparation of the manuscript.
CR Allen R, 2009, AUTISM, V13, P21, DOI 10.1177/1362361307098511
   [Anonymous], 2013, Psychomusicology: Music, Mind, and Brain, DOI [DOI 10.1037/A0033754, 10.1037/a0033754]
   Baron-Cohen S, 1999, EUR J NEUROSCI, V11, P1891, DOI 10.1046/j.1460-9568.1999.00621.x
   Baron-Cohen S, 2002, TRENDS COGN SCI, V6, P248, DOI 10.1016/S1364-6613(02)01904-6
   BARONCOHEN S, 1988, J AUTISM DEV DISORD, V18, P379, DOI 10.1007/BF02212194
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Belmonte MK, 2004, MOL PSYCHIATR, V9, P646, DOI 10.1038/sj.mp.4001499
   Bonnel A, 2003, J COGNITIVE NEUROSCI, V15, P226, DOI 10.1162/089892903321208169
   Bonnel A, 2010, NEUROPSYCHOLOGIA, V48, P2465, DOI 10.1016/j.neuropsychologia.2010.04.020
   BRAVERMAN M, 1989, J AUTISM DEV DISORD, V19, P301, DOI 10.1007/BF02211848
   Buitelaar JK, 1999, J CHILD PSYCHOL PSYC, V40, P869, DOI 10.1017/S0021963099004321
   Burack JA, 2016, J COGN DEV, V17, P553, DOI 10.1080/15248372.2016.1197226
   Caria A, 2011, CEREB CORTEX, V21, P2838, DOI 10.1093/cercor/bhr084
   Castelli F, 2005, AUTISM, V9, P428, DOI 10.1177/1362361305056082
   Chenausky K, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0164930
   Cicchetti D, 1996, DEV PSYCHOPATHOL, V8, P597, DOI 10.1017/S0954579400007318
   Conner CM, 2019, AUTISM, V23, P1273, DOI 10.1177/1362361318810709
   Constantino J. N., 2005, Social responsiveness scale: SRS-2
   Constantino JN, 2017, NATURE, V547, P340, DOI 10.1038/nature22999
   Durlak JA, 2011, CHILD DEV, V82, P405, DOI 10.1111/j.1467-8624.2010.01564.x
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Ekman P., 1969, Semiotica, V1, P49, DOI [10.1515/semi.1969.1.1.49, DOI 10.1515/SEMI.1969.1.1.49]
   Elfenbein HA, 2002, PSYCHOL BULL, V128, P203, DOI 10.1037//0033-2909.128.2.203
   Fombonne E, 2006, PEDIATRICS, V118, pE139, DOI 10.1542/peds.2005-2993
   Golan O, 2008, J AUTISM DEV DISORD, V38, P1534, DOI 10.1007/s10803-007-0533-7
   Golan O, 2007, J AUTISM DEV DISORD, V37, P1096, DOI 10.1007/s10803-006-0252-5
   Griffin C, 2016, AUTISM RES, V9, P773, DOI 10.1002/aur.1569
   Harms MB, 2010, NEUROPSYCHOL REV, V20, P290, DOI 10.1007/s11065-010-9138-6
   Heaton P, 2005, J AUTISM DEV DISORD, V35, P787, DOI 10.1007/s10803-005-0024-7
   Heaton P, 1998, MUSIC PERCEPT, V15, P291
   Heaton P, 1999, PSYCHOL MED, V29, P1405, DOI 10.1017/S0033291799001221
   Heaton P, 2003, J CHILD PSYCHOL PSYC, V44, P543, DOI 10.1111/1469-7610.00143
   Heaton P, 2008, BRIT J DEV PSYCHOL, V26, P171, DOI 10.1348/026151007X206776
   Heaton P, 2008, AUTISM, V12, P203, DOI 10.1177/1362361307085270
   Heaton P, 2009, PHILOS T R SOC B, V364, P1443, DOI 10.1098/rstb.2008.0327
   HOBSON RP, 1986, J CHILD PSYCHOL PSYC, V27, P321, DOI 10.1111/j.1469-7610.1986.tb01836.x
   HOBSON RP, 1986, J CHILD PSYCHOL PSYC, V27, P671, DOI 10.1111/j.1469-7610.1986.tb00191.x
   Hubl D, 2003, NEUROLOGY, V61, P1232, DOI 10.1212/01.WNL.0000091862.22033.1A
   Järvinen-Pasley A, 2008, DEVELOPMENTAL SCI, V11, P109, DOI 10.1111/j.1467-7687.2007.00644.x
   Johnson MH, 2017, DEV COGN NEUROS-NETH, V25, P5, DOI 10.1016/j.dcn.2017.02.004
   Johnson MH, 2015, DEV PSYCHOPATHOL, V27, P425, DOI 10.1017/S0954579415000073
   Jones CRG, 2011, J CHILD PSYCHOL PSYC, V52, P275, DOI 10.1111/j.1469-7610.2010.02328.x
   Jones W, 2008, ARCH GEN PSYCHIAT, V65, P946, DOI 10.1001/archpsyc.65.8.946
   Kim J, 2008, J AUTISM DEV DISORD, V38, P1758, DOI 10.1007/s10803-008-0566-6
   Klin A, 2003, PHILOS T R SOC B, V358, P345, DOI 10.1098/rstb.2002.1202
   Klin A, 2009, NATURE, V459, P257, DOI 10.1038/nature07868
   LaGasse AB, 2017, PATIENT-RELAT OUTCOM, V8, P23, DOI 10.2147/PROM.S106267
   Laugeson EA, 2012, J AUTISM DEV DISORD, V42, P1025, DOI 10.1007/s10803-011-1339-1
   Lazoff T, 2010, CAN J PSYCHIAT, V55, P715, DOI 10.1177/070674371005501105
   Lense Miriam D, 2020, Music Sci (Lond), V3, DOI 10.1177/2059204320933080
   Lewis JD, 2008, DEVELOPMENTAL SCI, V11, P135, DOI 10.1111/j.1467-7687.2007.00634.x
   Lim HA, 2011, J MUSIC THER, V48, P532, DOI 10.1093/jmt/48.4.532
   Lim HA, 2010, J MUSIC THER, V47, P2, DOI 10.1093/jmt/47.1.2
   Lozier LM, 2014, DEV PSYCHOPATHOL, V26, P933, DOI 10.1017/S0954579414000479
   Molnar-Szakacs I, 2012, ANN NY ACAD SCI, V1252, P318, DOI 10.1111/j.1749-6632.2012.06465.x
   Mottron L, 2000, J CHILD PSYCHOL PSYC, V41, P1057, DOI 10.1111/1469-7610.00693
   Mottron L, 2006, J AUTISM DEV DISORD, V36, P27, DOI 10.1007/s10803-005-0040-7
   Mottron L, 2001, DEVELOPMENT OF AUTISM: PERSPECTIVES FROM THEORY AND RESEARCH, P131
   Mottron L, 2013, NEUROSCI BIOBEHAV R, V37, P209, DOI 10.1016/j.neubiorev.2012.11.016
   Nuske HJ, 2013, COGNITION EMOTION, V27, P1042, DOI 10.1080/02699931.2012.762900
   Ouimet T, 2012, ANN NY ACAD SCI, V1252, P325, DOI 10.1111/j.1749-6632.2012.06453.x
   OZONOFF S, 1990, J CHILD PSYCHOL PSYC, V31, P343, DOI 10.1111/j.1469-7610.1990.tb01574.x
   Paquette S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00509
   Pelphrey KA, 2002, J AUTISM DEV DISORD, V32, P249, DOI 10.1023/A:1016374617369
   Posner J, 2005, DEV PSYCHOPATHOL, V17, P715, DOI 10.1017/S0954579405050340
   Prizant BM, 2003, INFANT YOUNG CHILD, V16, P296, DOI 10.1097/00001163-200310000-00004
   Quintin EM, 2019, FRONT NEURAL CIRCUIT, V13, DOI 10.3389/fncir.2019.00049
   Quintin EM, 2011, J AUTISM DEV DISORD, V41, P1240, DOI 10.1007/s10803-010-1146-0
   Reaven Judy, 2012, Autism Res Treat, V2012, P423905, DOI 10.1155/2012/423905
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Russo N, 2021, DEV PSYCHOPATHOL, V33, P727, DOI 10.1017/S0954579420001480
   Samson F, 2012, HUM BRAIN MAPP, V33, P1553, DOI 10.1002/hbm.21307
   Sharda M, 2018, TRANSL PSYCHIAT, V8, DOI 10.1038/s41398-018-0287-3
   Sivathasan S, 2020, RES AUTISM SPECT DIS, V77, DOI 10.1016/j.rasd.2020.101608
   Stanutz S, 2014, AUTISM, V18, P137, DOI 10.1177/1362361312462905
   Stephenson KG, 2016, J AUTISM DEV DISORD, V46, P1142, DOI 10.1007/s10803-015-2624-1
   Swaminathan S, 2015, EMOT REV, V7, P189, DOI 10.1177/1754073914558282
   Tottenham N, 2009, PSYCHIAT RES, V168, P242, DOI 10.1016/j.psychres.2008.05.006
   Tracy JL, 2011, J AUTISM DEV DISORD, V41, P102, DOI 10.1007/s10803-010-1030-y
   Trevisan DA, 2016, RES AUTISM SPECT DIS, V32, P24, DOI 10.1016/j.rasd.2016.08.004
   Tseng A, 2014, J AUTISM DEV DISORD, V44, P1332, DOI 10.1007/s10803-013-1993-6
   Uljarevic M, 2013, J AUTISM DEV DISORD, V43, P1517, DOI 10.1007/s10803-012-1695-5
   Velikonja T, 2019, JAMA PSYCHIAT, V76, P135, DOI 10.1001/jamapsychiatry.2018.3645
   Wechsler D., 2014, WISC 5 ADM SCORING M
   Wechsler D., 2011, Wechsler Abbreviated Scale of Intelligence-Second Edition [jeu de donnees], VSecond, DOI DOI 10.1037/T15171-000
   Williams D, 2010, AUTISM, V14, P285, DOI 10.1177/1362361309344849
   Zelazo PD, 1996, J CHILD PSYCHOL PSYC, V37, P479, DOI 10.1111/j.1469-7610.1996.tb01429.x
NR 87
TC 1
Z9 1
U1 7
U2 8
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD JAN 11
PY 2023
VL 18
IS 1
AR e0279002
DI 10.1371/journal.pone.0279002
PG 19
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA N3LV7
UT WOS:001036077600026
PM 36630376
OA gold, Green Published
DA 2024-01-09
ER

PT J
AU Zuccarini, C
AF Zuccarini, Carlo
TI Hearing Voices: Neuropsychoanalysis and Opera
SO INTERDISCIPLINARY SCIENCE REVIEWS
LA English
DT Article
DE Opera; Neuropsychoanalysis; Voice; Gaze; Synaesthesia
ID MUSIC; SCIENCE
AB Opera essentially combines three layers - drama, music and singing that have one thing in common: language. As neuroscience continues to explore how music is processed in the brain, similarities with language processing are becoming increasingly apparent. Listening to music involves the activation of numerous brain regions, including the so-called reward and pleasure centres, as well as some of the same areas associated with language processing. However, these findings do not explain why some people experience intense emotion, feel choked up or tearful, upon hearing an operatic voice. With language as a common denominator, Lacanian theory may provide some insight into this particular relationship between operatic vocal music and emotion. Therefore, a neuropsychoanalytic approach, combining current neuroscientific knowledge and psychoanalytic theory, may contribute to a deeper understanding of how and why the operatic voice is capable of evoking such powerful emotion.
C1 Brunel Univ, London, England.
C3 Brunel University
RP Zuccarini, C (corresponding author), Brunel Univ, London, England.
EM Carlo.Zuccarini@brunel.ac.uk
CR Abel Sam, 1996, OPERA FLESH SEXUALIT
   Ali SO., 2006, Psychology of Music, V34, P511, DOI DOI 10.1177/0305735606067168
   [Anonymous], SEM J LAC BOOK 7 ETH
   [Anonymous], OXFORD DICT MUSIC
   Ball P, 2008, NATURE, V453, P160, DOI 10.1038/453160a
   HURON D, 2008, MUS SCI BRAIN S 27 S
   HURON DAVID, 2006, SWEET ANTICIPATION M, P148, DOI DOI 10.7551/MITPRESS/6575.001.0001
   Jourdain R., 2002, MUSIC BRAIN ECSTASY
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Kerman Joseph., 1988, Opera as Drama
   KESENNE J, DR H HEYRMAN MUSEUMS
   Konecni VJ, 2003, MUSIC PERCEPT, V20, P332
   LAMARQUE L, 1988, NUOVA ENCICLOPEDIA
   Levitin D.J., 2007, This is your brain on music: The science of a human obsession
   Levitin DJ, 2009, ANN NY ACAD SCI, V1156, P211, DOI 10.1111/j.1749-6632.2009.04417.x
   LEVITIN DJ, 2008, NEWSWEEK        0922
   Menon V, 2005, NEUROIMAGE, V28, P175, DOI 10.1016/j.neuroimage.2005.05.053
   MITERSCHIFFTHAL.MT, 2006, HUMAN BRAIN MAPPING, V28, P1150
   Patel A. D., 2008, Music, Language, and the Brain
   Patel AD, 2008, NATURE, V453, P726, DOI 10.1038/453726a
   Peciña S, 2006, NEUROSCIENTIST, V12, P500, DOI 10.1177/1073858406293154
   Poizat M., 1992, The Angel's Cry: Beyond the Pleasure Principle in Opera
   Purves D., 2008, Principles of Cognitive Neuroscience
   Sloboda J. A., 2007, MUSICAL MIND COGNITI
   STEIBEIS N, 2008, PLOS ONE, V3
   Trainor L, 2008, NATURE, V453, P598, DOI 10.1038/453598a
   Zizek Slavoj, 1996, GAZE VOICE LOVE OBJE
   ZUCCARINI C, 2009, PERSONS SEXUALITY PR
   ZUCCARINI C, 2010, EROTIC EXPLORING CRI
NR 29
TC 0
Z9 0
U1 0
U2 6
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 0308-0188
EI 1743-2790
J9 INTERDISCIPL SCI REV
JI Interdiscip. Sci. Rev.
PD JUN
PY 2010
VL 35
IS 2
SI SI
BP 154
EP 165
DI 10.1179/030801810X12723585301156
PG 12
WC Multidisciplinary Sciences; Social Sciences, Interdisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Science & Technology - Other Topics; Social Sciences - Other Topics
GA 619SD
UT WOS:000279449700005
DA 2024-01-09
ER

PT J
AU Cheng, LK
   Chiu, YH
   Lin, YC
   Li, WC
   Hong, TY
   Yang, CJ
   Shih, CH
   Yeh, TC
   Tseng, WYI
   Yu, HY
   Hsieh, JC
   Chen, LF
AF Cheng, Li-Kai
   Chiu, Yu-Hsien
   Lin, Ying-Chia
   Li, Wei-Chi
   Hong, Tzu-Yi
   Yang, Ching-Ju
   Shih, Chung-Heng
   Yeh, Tzu-Chen
   Tseng, Wen-Yih Isaac
   Yu, Hsin-Yen
   Hsieh, Jen-Chuen
   Chen, Li-Fen
TI Long-term musical training induces white matter plasticity in emotion
   and language networks
SO HUMAN BRAIN MAPPING
LA English
DT Article
DE brain asymmetry; emotion; graph theory; language; structural
   connectivity; vocal training
ID SPECTRUM IMAGING TEMPLATE; STRUCTURAL PLASTICITY; BRAIN NETWORKS;
   WHOLE-BRAIN; CONNECTIVITY; EXPERTISE; MUSICIANS; COMMUNICATION;
   PARCELLATION; ARCHITECTURE
AB Numerous studies have reported that long-term musical training can affect brain functionality and induce structural alterations in the brain. Singing is a form of vocal musical expression with an unparalleled capacity for communicating emotion; however, there has been relatively little research on neuroplasticity at the network level in vocalists (i.e., noninstrumental musicians). Our objective in this study was to elucidate changes in the neural network architecture following long-term training in the musical arts. We employed a framework based on graph theory to depict the connectivity and efficiency of structural networks in the brain, based on diffusion-weighted images obtained from 35 vocalists, 27 pianists, and 33 nonmusicians. Our results revealed that musical training (both voice and piano) could enhance connectivity among emotion-related regions of the brain, such as the amygdala. We also discovered that voice training reshaped the architecture of experience-dependent networks, such as those involved in vocal motor control, sensory feedback, and language processing. It appears that vocal-related changes in areas such as the insula, paracentral lobule, supramarginal gyrus, and putamen are associated with functional segregation, multisensory integration, and enhanced network interconnectivity. These results suggest that long-term musical training can strengthen or prune white matter connectivity networks in an experience-dependent manner.
C1 [Cheng, Li-Kai; Chiu, Yu-Hsien; Li, Wei-Chi; Hong, Tzu-Yi; Yang, Ching-Ju; Shih, Chung-Heng; Yeh, Tzu-Chen; Hsieh, Jen-Chuen; Chen, Li-Fen] Natl Yang Ming Chiao Tung Univ, Inst Brain Sci, Taipei, Taiwan.
   [Cheng, Li-Kai; Chiu, Yu-Hsien; Li, Wei-Chi; Hong, Tzu-Yi; Yang, Ching-Ju; Shih, Chung-Heng; Hsieh, Jen-Chuen; Chen, Li-Fen] Taipei Vet Gen Hosp, Dept Med Res, Integrated Brain Res Unit, Taipei, Taiwan.
   [Lin, Ying-Chia] NYU, Grossman Sch Med, Ctr Adv Imaging Innovat & Res CAI2R, New York, NY USA.
   [Lin, Ying-Chia] NYU, Grossman Sch Med, Ctr Biomed Imaging, Dept Radiol, New York, NY USA.
   [Yeh, Tzu-Chen] Taipei Vet Gen Hosp, Dept Radiol, Taipei, Taiwan.
   [Tseng, Wen-Yih Isaac] Natl Taiwan Univ, Coll Med, Inst Med Device & Imaging, Taipei, Taiwan.
   [Yu, Hsin-Yen] Taipei Natl Univ Arts, Grad Inst Arts & Humanities Educ, Taipei, Taiwan.
   [Hsieh, Jen-Chuen; Chen, Li-Fen] Natl Yang Ming Chiao Tung Univ, Brain Res Ctr, Taipei, Taiwan.
   [Hsieh, Jen-Chuen] Natl Yang Ming Chiao Tung Univ, Coll Biol Sci & Technol, Dept Biol Sci & Technol, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University; Taipei Veterans General
   Hospital; New York University; New York University; Taipei Veterans
   General Hospital; National Taiwan University; National Yang Ming Chiao
   Tung University; National Yang Ming Chiao Tung University
RP Hsieh, JC; Chen, LF (corresponding author), Natl Yang Ming Chiao Tung Univ, Inst Brain Sci, Taipei, Taiwan.; Hsieh, JC (corresponding author), Natl Yang Ming Chiao Tung Univ, Coll Biol Sci & Technol, Dept Biol Sci & Technol, Hsinchu, Taiwan.
EM jchsiehibru@nycu.edu.tw; lfchen@nycu.edu.tw
RI Lin, Ying-Chia/GQB-1175-2022
OI Lin, Ying-Chia/0000-0001-7243-0980; Cheng, Li-Kai/0000-0001-9568-0704;
   Li, Wei-Chi/0000-0002-4537-9291; Tseng, Wen-Yih
   Isaac/0000-0002-2314-6868; Chiu, Yu-Hsien/0000-0002-8233-4631; Hsieh,
   Jen-Chuen/0000-0002-7568-000X; Yang, Ching-Ju/0000-0001-5324-8112; Chen,
   Li-Fen/0000-0002-3819-853X
FU Ministry of Science and Technology, Taiwan [MOST 106-2420-H-009-001,
   MOST 106-2420-H-010-005, MOST 106-2420-H-010-006-MY2, MOST
   110-2314-B-A49A-529, NSC 102-2420-H-010-004-MY3, NSC
   102-2420-H010-005-MY3, NSC 102-2420-H075-001-MY3]; Aim for the Top
   University Plan of the Ministry of Education for National Yang Ming
   Chiao Tung University; Brain Research Center, National Yang Ming Chiao
   Tung University from The Featured Areas Research Center Program within
   Ministry of Education in Taiwan
FX Ministry of Science and Technology, Taiwan, Grant/Award Numbers: MOST
   106-2420-H-009-001, MOST 106-2420-H-010-005, MOST
   106-2420-H-010-006-MY2, MOST 110-2314-B-A49A-529, NSC
   102-2420-H-010-004-MY3, NSC 102-2420-H010-005-MY3, NSC
   102-2420-H075-001-MY3; The Aim for the Top University Plan of the
   Ministry of Education for National Yang Ming Chiao Tung University;
   Brain Research Center, National Yang Ming Chiao Tung University from The
   Featured Areas Research Center Program within the framework of the
   Higher Education Sprout Project by the Ministry of Education in Taiwan
CR Abutalebi J, 2013, BRAIN LANG, V125, P307, DOI 10.1016/j.bandl.2012.03.009
   Achard S, 2007, PLOS COMPUT BIOL, V3, P174, DOI 10.1371/journal.pcbi.0030017
   Asavasopon S, 2014, J NEUROSCI, V34, P13811, DOI 10.1523/JNEUROSCI.2073-14.2014
   Ashtari M, 2007, NEUROIMAGE, V35, P501, DOI 10.1016/j.neuroimage.2006.10.047
   Bangert M, 2006, EUR J NEUROSCI, V24, P1832, DOI 10.1111/j.1460-9568.2006.05031.x
   Barrett KC, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00713
   Bassett DS, 2006, NEUROSCIENTIST, V12, P512, DOI 10.1177/1073858406293182
   Bilodeau-Mercure M, 2015, BRAIN STRUCT FUNCT, V220, P979, DOI 10.1007/s00429-013-0695-3
   BLAIR RC, 1993, PSYCHOPHYSIOLOGY, V30, P518, DOI 10.1111/j.1469-8986.1993.tb02075.x
   Brandes U, 2001, J MATH SOCIOL, V25, P163, DOI 10.1080/0022250X.2001.9990249
   Brown S, 2006, EUR J NEUROSCI, V23, P2791, DOI 10.1111/j.1460-9568.2006.04785.x
   Catani M, 2007, P NATL ACAD SCI USA, V104, P17163, DOI 10.1073/pnas.0702116104
   Chen YJ, 2015, HUM BRAIN MAPP, V36, P3441, DOI 10.1002/hbm.22854
   Cohen JR, 2016, J NEUROSCI, V36, P12083, DOI 10.1523/JNEUROSCI.2965-15.2016
   Dhakal K, 2021, BRAIN SCI, V11, DOI 10.3390/brainsci11040506
   Elmer S, 2016, BRAIN STRUCT FUNCT, V221, P331, DOI 10.1007/s00429-014-0910-x
   Estrada E, 2008, PHYS REV E, V77, DOI 10.1103/PhysRevE.77.036111
   Fernández-Miranda J, 2015, BRAIN STRUCT FUNCT, V220, P1665, DOI 10.1007/s00429-014-0751-7
   Foster NEV, 2010, NEUROIMAGE, V53, P26, DOI 10.1016/j.neuroimage.2010.06.042
   Frühholz S, 2014, PROG NEUROBIOL, V123, P1, DOI 10.1016/j.pneurobio.2014.09.003
   Gackle L., 2019, OXFORD HDB SINGING, P551
   Gordon KE, 2020, J VOICE, V34, P243, DOI 10.1016/j.jvoice.2018.09.024
   Groussard M, 2014, BRAIN COGNITION, V90, P174, DOI 10.1016/j.bandc.2014.06.013
   Habibi A, 2018, CEREB CORTEX, V28, P4336, DOI 10.1093/cercor/bhx286
   Halwani GF, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00156
   Heun R, 2004, PSYCHIAT RES-NEUROIM, V132, P19, DOI 10.1016/j.pscychresns.2004.01.007
   Hsu YC, 2015, HUM BRAIN MAPP, V36, P3528, DOI 10.1002/hbm.22860
   Huang H, 2015, CEREB CORTEX, V25, P1389, DOI 10.1093/cercor/bht335
   Hyde KL, 2009, J NEUROSCI, V29, P3019, DOI 10.1523/JNEUROSCI.5118-08.2009
   Jäncke L, 2012, J COGNITIVE NEUROSCI, V24, P1447, DOI 10.1162/jocn_a_00227
   Jansens S., 1997, P 5 EUR C SPEECH COM, P2155
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kintali S., 2008, BETWEENNESS CENTRALI
   Kleber B, 2007, NEUROIMAGE, V36, P889, DOI 10.1016/j.neuroimage.2007.02.053
   Kleber B, 2017, NEUROIMAGE, V147, P97, DOI 10.1016/j.neuroimage.2016.11.059
   Knecht S, 2000, BRAIN, V123, P74, DOI 10.1093/brain/123.1.74
   Knight S., 1999, PHENOMENON SINGING, P144
   Kolinsky R, 2009, MUSIC PERCEPT, V26, P235, DOI 10.1525/MP.2009.26.3.235
   Kort NS, 2016, HUM BRAIN MAPP, V37, P1474, DOI 10.1002/hbm.23114
   Kuo LW, 2008, NEUROIMAGE, V41, P7, DOI 10.1016/j.neuroimage.2008.02.016
   Landau SM, 2006, COGN AFFECT BEHAV NE, V6, P246, DOI 10.3758/CABN.6.3.246
   Larrouy-Maestri P, 2013, MUSIC SCI, V17, P217, DOI 10.1177/1029864912473470
   Latora V, 2001, PHYS REV LETT, V87, DOI 10.1103/PhysRevLett.87.198701
   Leipold S, 2021, J NEUROSCI, V41, P2496, DOI 10.1523/JNEUROSCI.1985-20.2020
   Li J, 2014, PLOS ONE, V9, DOI [10.1371/journal.pone.0096185, 10.1371/journal.pone.0090225]
   Lomax A., 2017, FOLK SONG STYLE CULT
   Loui P, 2011, J COGNITIVE NEUROSCI, V23, P1015, DOI 10.1162/jocn.2010.21500
   Marie C, 2011, J COGNITIVE NEUROSCI, V23, P2701, DOI 10.1162/jocn.2010.21585
   Miendlarzewska EA, 2014, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00279
   Nettl Bruno, 1983, The study of ethnomusicology: Thirty-three discussions
   Pantev C, 2001, ANN NY ACAD SCI, V930, P300, DOI 10.1111/j.1749-6632.2001.tb05740.x
   Patra Apurba, 2021, Asian J Neurosurg, V16, P349, DOI 10.4103/ajns.AJNS_505_20
   Rubinov M, 2010, NEUROIMAGE, V52, P1059, DOI 10.1016/j.neuroimage.2009.10.003
   Scherer KR, 2017, J ACOUST SOC AM, V142, P1805, DOI 10.1121/1.5002886
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Schlaug G, 2005, ANN NY ACAD SCI, V1060, P219, DOI 10.1196/annals.1360.015
   Schmithorst VJ, 2002, NEUROSCI LETT, V321, P57, DOI 10.1016/S0304-3940(02)00054-X
   Shenker JJ, 2022, BRAIN STRUCT FUNCT, V227, P407, DOI 10.1007/s00429-021-02409-2
   Slater J, 2017, EUR J NEUROSCI, V45, P952, DOI 10.1111/ejn.13535
   Sporns O., 2010, Networks of the Brain
   Sporns O, 2014, NAT NEUROSCI, V17, P652, DOI 10.1038/nn.3690
   Sporns O, 2013, CURR OPIN NEUROBIOL, V23, P162, DOI 10.1016/j.conb.2012.11.015
   Tanaka S, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00606
   Tremblay P, 2016, BRAIN STRUCT FUNCT, V221, P3275, DOI 10.1007/s00429-015-1100-1
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Vaquero L, 2016, NEUROIMAGE, V126, P106, DOI 10.1016/j.neuroimage.2015.11.008
   Veraart J, 2016, MAGN RESON MED, V76, P1582, DOI 10.1002/mrm.26059
   Wang L, 2011, P NATL ACAD SCI USA, V108, P2545, DOI 10.1073/pnas.1014335108
   Wang WD, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00815
   Wedeen VJ, 2005, MAGN RESON MED, V54, P1377, DOI 10.1002/mrm.20642
   Westfall P.H., 1993, Resampling-based multiple testing: Examples and methods for p-value adjustment
   Wiethoff S, 2009, NEUROREPORT, V20, P1356, DOI 10.1097/WNR.0b013e328330eb83
   Williams J., 2019, OXFORD HDB SINGING, P533
   Xia MR, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068910
   Yeh FC, 2018, NEUROIMAGE, V178, P57, DOI 10.1016/j.neuroimage.2018.05.027
   Yeh FC, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0080713
   Yeh FC, 2010, IEEE T MED IMAGING, V29, P1626, DOI 10.1109/TMI.2010.2045126
   Zalesky A, 2010, NEUROIMAGE, V53, P1197, DOI 10.1016/j.neuroimage.2010.06.041
   Zarate JM, 2008, NEUROIMAGE, V40, P1871, DOI 10.1016/j.neuroimage.2008.01.026
   Zarate JM, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00237
NR 80
TC 2
Z9 2
U1 2
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1065-9471
EI 1097-0193
J9 HUM BRAIN MAPP
JI Hum. Brain Mapp.
PD JAN
PY 2023
VL 44
IS 1
BP 5
EP 17
DI 10.1002/hbm.26054
EA AUG 2022
PG 13
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA 9D5NO
UT WOS:000844169500001
PM 36005832
OA Green Published
DA 2024-01-09
ER

PT J
AU Liuni, M
   Ponsot, E
   Bryant, GA
   Aucouturier, JJ
AF Liuni, Marco
   Ponsot, Emmanuel
   Bryant, Gregory A.
   Aucouturier, J. J.
TI Sound context modulates perceived vocal emotion
SO BEHAVIOURAL PROCESSES
LA English
DT Article
DE Vocal arousal; Vocalization; Sound context; Emotional judgments
ID NONLINEAR PHENOMENA; COMMUNICATION; AROUSAL; MUSIC
AB Many animal vocalizations contain nonlinear acoustic phenomena as a consequence of physiological arousal. In humans, nonlinear features are processed early in the auditory system, and are used to efficiently detect alarm calls and other urgent signals. Yet, high-level emotional and semantic contextual factors likely guide the perception and evaluation of roughness features in vocal sounds. Here we examined the relationship between perceived vocal arousal and auditory context. We presented listeners with nonverbal vocalizations (yells of a single vowel) at varying levels of portrayed vocal arousal, in two musical contexts (clean guitar, distorted guitar) and one non-musical context (modulated noise). As predicted, vocalizations with higher levels of portrayed vocal arousal were judged as more negative and more emotionally aroused than the same voices produced with low vocal arousal. Moreover, both the perceived valence and emotional arousal of vocalizations were significantly affected by both musical and non-musical contexts. These results show the importance of auditory context in judging emotional arousal and valence in voices and music, and suggest that nonlinear features in music are processed similarly to communicative vocal signals.
C1 [Liuni, Marco; Ponsot, Emmanuel; Aucouturier, J. J.] Sorbonne Univ, IRCAM, CNRS, STMS Lab, Paris, France.
   [Ponsot, Emmanuel] Univ PSL, Dept Etud Cognit, Lab Syst Perceptifs, CNRS,Ecole Normale Super, Paris, France.
   [Bryant, Gregory A.] Univ Calif Los Angeles, Dept Commun, Los Angeles, CA 90024 USA.
   [Bryant, Gregory A.] Univ Calif Los Angeles, Ctr Behav Evolut & Culture, Los Angeles, CA 90024 USA.
C3 Centre National de la Recherche Scientifique (CNRS); Sorbonne
   Universite; Universite PSL; Ecole Normale Superieure (ENS); Centre
   National de la Recherche Scientifique (CNRS); University of California
   System; University of California Los Angeles; University of California
   System; University of California Los Angeles
RP Liuni, M (corresponding author), IRCAM, 1 Pl Igor Stravinsky, F-75004 Paris, France.
EM marco.liuni@ircam.fr
RI Bryant, Gregory/AAR-9118-2020
OI Bryant, Gregory/0000-0002-7240-4026
FU ERC Grant [StG 335536 CREAM]; Fulbright Visiting Scholar Fellowship
FX This study was supported by ERC Grant StG 335536 CREAM to JJA, and by a
   Fulbright Visiting Scholar Fellowship to ML.
CR Abitbol R, 2015, J NEUROSCI, V35, P2308, DOI 10.1523/JNEUROSCI.1878-14.2015
   Arnal LH, 2015, CURR BIOL, V25, P2051, DOI 10.1016/j.cub.2015.06.043
   Begault D.R., 2008, AUD ENG SOC C 33 INT
   Belin P, 2015, CURR BIOL, V25, pR805, DOI 10.1016/j.cub.2015.07.027
   Blumstein DT, 2017, ETHOLOGY, V123, P966, DOI 10.1111/eth.12702
   Blumstein DT, 2012, BIOL LETTERS, V8, P744, DOI 10.1098/rsbl.2012.0374
   Blumstein DT, 2009, ETHOLOGY, V115, P1074, DOI 10.1111/j.1439-0310.2009.01691.x
   Boersma P., 2014, PRAAT DOING PHONETIC
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Briefer EF, 2012, J ZOOL, V288, P1, DOI 10.1111/j.1469-7998.2012.00920.x
   Bryant Gregory A, 2013, Front Psychol, V4, P990, DOI 10.3389/fpsyg.2013.00990
   de Gelder B, 2000, COGNITION EMOTION, V14, P289, DOI 10.1080/026999300378824
   Driver J, 2008, NEURON, V57, P11, DOI 10.1016/j.neuron.2007.12.013
   Fitch WT, 2002, ANIM BEHAV, V63, P407, DOI 10.1006/anbe.2001.1912
   Glasberg BR, 2002, J AUDIO ENG SOC, V50, P331
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Mothes-Lasch M, 2012, NEUROIMAGE, V63, P485, DOI 10.1016/j.neuroimage.2012.07.005
   Neubauer J, 2004, J VOICE, V18, P1, DOI 10.1016/S0892-1997(03)00073-0
   R Core Team, 2018, R: A Language and Environment for Statistical Computing
   Sakakibara K.I., 2004, LEONARDO, V1, P2
   Thompson W.F., 2018, PSYCHOL POP MEDIA CU
   Vannier M, 2018, J ACOUST SOC AM, V143, P575, DOI 10.1121/1.5021551
   Wilden I., 1998, Bioacoustics, V9, P171
NR 23
TC 6
Z9 7
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0376-6357
EI 1872-8308
J9 BEHAV PROCESS
JI Behav. Processes
PD MAR
PY 2020
VL 172
AR 104042
DI 10.1016/j.beproc.2020.104042
PG 5
WC Psychology, Biological; Behavioral Sciences; Zoology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Psychology; Behavioral Sciences; Zoology
GA LG2NQ
UT WOS:000527944500006
PM 31926279
OA Green Submitted
DA 2024-01-09
ER

PT J
AU Hailstone, JC
   Crutch, SJ
   Vestergaard, MD
   Patterson, RD
   Warren, JD
AF Hailstone, Julia C.
   Crutch, Sebastian J.
   Vestergaard, Martin D.
   Patterson, Roy D.
   Warren, Jason D.
TI Progressive associative phonagnosia: A neuropsychological analysis
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE Voice; Face; Person knowledge; Prosopagnosia; Frontotemporal lobar
   degeneration; Dementia
ID RIGHT TEMPORAL-LOBE; VOICE RECOGNITION; HUMAN BRAIN; DEFECTIVE
   RECOGNITION; FACE PERCEPTION; FAMILIAR PEOPLE; FAMOUS FACES;
   PROSOPAGNOSIA; ORGANIZATION; DISORDERS
AB There are few detailed studies of impaired voice recognition, or phonagnosia. Here we describe two patients with progressive phonagnosia in the context of frontotemporal lobar degeneration. Patient QR presented with behavioural decline and increasing difficulty recognising familiar voices, while patient KL presented with progressive prosopagnosia. In a series of neuro psychological experiments we assessed the ability of QR and KL to recognise and judge the familiarity of voices, faces and proper names, to recognise vocal emotions, to perceive and discriminate voices, and to recognise environmental sounds and musical instruments. The patients were assessed in relation to a group of healthy age-matched control subjects. QR exhibited severe impairments of voice identification and familiarity judgments with relatively preserved recognition of difficulty-matched faces and environmental sounds; recognition of musical instruments was impaired, though better than recognition of voices. In contrast, patient KL exhibited severe impairments of both voice and face recognition, with relatively preserved recognition of musical instruments and environmental sounds. Both patients demonstrated preserved ability to analyse perceptual properties of voices and to recognise vocal emotions. The voice processing deficit in both patients could be characterised as associative phonagnosia: in the case of QR, this was relatively selective for voices, while in the case of KL, there was evidence for a multimodal impairment of person knowledge. The findings have implications for current cognitive models of voice recognition. (C) 2009 Elsevier Ltd. All rights reserved.
C1 [Hailstone, Julia C.; Crutch, Sebastian J.; Warren, Jason D.] UCL, Inst Neurol, Dementia Res Ctr, London WC1N 3BG, England.
   [Vestergaard, Martin D.; Patterson, Roy D.] Univ Cambridge, Ctr Neural Basis Hearing, Dept Physiol, Cambridge, England.
C3 University of London; University College London; University of Cambridge
RP Warren, JD (corresponding author), UCL, Inst Neurol, Dementia Res Ctr, Queen Sq, London WC1N 3BG, England.
EM jwarren@drc.ion.ucl.ac.uk
OI Crutch, Sebastian/0000-0002-4160-0139; Warren,
   Jason/0000-0002-5405-0826; Vestergaard, Martin/0000-0003-0000-8566
FU Department of Health's NIHR Biomedical Research Centres; Wellcome Trust;
   UK Medical Research Council; Alzheimer's Research Trust; Medical
   Research Council [G0500221, G0801306] Funding Source: researchfish; MRC
   [G0500221, G0801306] Funding Source: UKRI
FX We are grateful to all the subjects for their participation. We thank
   Dr. Doris-Eva Barniou for assistance with audiometric assessments,
   Jonathan Bartlett MSc for statistical advice and Prof. Sophie Scott and
   Dr. Disa Sauter for making available the vocal emotion stimuli. We thank
   Prof. EK Warrington for helpful discussion. This work was undertaken at
   UCLH/UCL who received a proportion of funding from the Department of
   Health's NIHR Biomedical Research Centres funding scheme. The Dementia
   Research Centre is an Alzheimer's Research Trust Co-ordinating Centre.
   This work was funded by the Wellcome Trust and by the UK Medical
   Research Council. SJC is supported by an Alzheimer's Research Trust
   Fellowship. JDW is supported by a Wellcome Trust Intermediate Clinical
   Fellowship.
CR Barton JJS, 2003, NEUROL CLIN, V21, P521, DOI 10.1016/S0733-8619(02)00106-8
   Belin P, 2004, TRENDS COGN SCI, V8, P129, DOI 10.1016/j.tics.2004.01.008
   Belin P, 2002, COGNITIVE BRAIN RES, V13, P17, DOI 10.1016/S0926-6410(01)00084-2
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   BENTON AL, 1989, CONTRIBUTIONS NEUROP
   Benzagmout M, 2008, ACTA NEUROCHIR, V150, P589, DOI 10.1007/s00701-008-1495-4
   BRUCE V, 1986, BRIT J PSYCHOL, V77, P305, DOI 10.1111/j.2044-8295.1986.tb02199.x
   Burton A M, 1993, Memory, V1, P457, DOI 10.1080/09658219308258248
   BURTON AM, 1990, BRIT J PSYCHOL, V81, P361, DOI 10.1111/j.2044-8295.1990.tb02367.x
   Chan D, 2009, BRAIN, V132, P1287, DOI 10.1093/brain/awp037
   Crawford JR, 1998, CLIN NEUROPSYCHOL, V12, P482, DOI 10.1076/clin.12.4.482.7241
   Crutch SJ, 2004, NEUROPSYCHOLOGIA, V42, P584, DOI 10.1016/j.neuropsychologia.2003.10.009
   Damjanovic L, 2007, MEM COGNITION, V35, P1205, DOI 10.3758/BF03193594
   Delis D. C., 2001, DelisKaplan executive function system (D-KEFS)
   DERENZI E, 1991, CORTEX, V27, P213, DOI 10.1016/S0010-9452(13)80125-6
   Duchaine BC, 2006, CURR OPIN NEUROBIOL, V16, P166, DOI 10.1016/j.conb.2006.03.003
   ELLIS AW, 1989, BRAIN, V112, P1469, DOI 10.1093/brain/112.6.1469
   Ellis HD, 1997, BRIT J PSYCHOL, V88, P143, DOI 10.1111/j.2044-8295.1997.tb02625.x
   EVANS JJ, 1995, BRAIN, V118, P1, DOI 10.1093/brain/118.1.1
   Gainotti G, 2003, BRAIN, V126, P792, DOI 10.1093/brain/awg092
   Gainotti G, 2008, CORTEX, V44, P238, DOI 10.1016/j.cortex.2006.09.001
   Gainotti G, 2007, BRAIN RES REV, V56, P214, DOI 10.1016/j.brainresrev.2007.07.009
   Gainotti G, 2007, NEUROPSYCHOLOGIA, V45, P1591, DOI 10.1016/j.neuropsychologia.2006.12.013
   Garrido L, 2009, NEUROPSYCHOLOGIA, V47, P123, DOI 10.1016/j.neuropsychologia.2008.08.003
   Gentileschi V, 2001, COGN NEUROPSYCHOL, V18, P439, DOI 10.1080/02643290125835
   Gentileschi V, 1999, NEUROCASE, V5, P407, DOI 10.1093/neucas/5.5.407
   Griffiths TD, 2004, NAT REV NEUROSCI, V5, P887, DOI 10.1038/nrn1538
   HALPERN AR, 1995, PSYCHOL AGING, V10, P325, DOI 10.1037/0882-7974.10.3.325
   Hanley JR, 1998, Q J EXP PSYCHOL-A, V51, P179, DOI 10.1080/713755751
   HANLEY JR, 1989, COGNITIVE NEUROPSYCH, V6, P179, DOI 10.1080/02643298908253418
   Imaizumi S, 1997, NEUROREPORT, V8, P2809, DOI 10.1097/00001756-199708180-00031
   Ives DT, 2005, J ACOUST SOC AM, V118, P3816, DOI 10.1121/1.2118427
   Josephs KA, 2008, NEUROLOGY, V71, P1628, DOI 10.1212/01.wnl.0000334756.18558.92
   Joubert S, 2004, NEUROLOGY, V63, P1962, DOI 10.1212/01.WNL.0000144347.40132.6A
   Joubert S, 2003, BRAIN, V126, P2537, DOI 10.1093/brain/awg259
   Kawahara H, 2005, SPEECH SEPARATION BY HUMANS AND MACHINES, P167, DOI 10.1007/0-387-22794-6_11
   Keane J, 2002, NEUROPSYCHOLOGIA, V40, P655, DOI 10.1016/S0028-3932(01)00156-7
   Lang CJG, 2009, J NEUROL, V256, P1303, DOI 10.1007/s00415-009-5118-2
   Lucchelli F, 2008, CORTEX, V44, P230, DOI 10.1016/j.cortex.2006.11.001
   Lyons F, 2006, NEUROPSYCHOLOGIA, V44, P2887, DOI 10.1016/j.neuropsychologia.2006.06.005
   Mahon BZ, 2009, NEURON, V63, P397, DOI 10.1016/j.neuron.2009.07.012
   Nakamura K, 2001, NEUROPSYCHOLOGIA, V39, P1047, DOI 10.1016/S0028-3932(01)00037-9
   Nelson H. E., 1982, National Adult Reading Test (NART): For the Assessment of Premorbid Intelligence in Patients with Dementia: Test Manual
   Neuner F, 2000, BRAIN COGNITION, V44, P342, DOI 10.1006/brcg.1999.1196
   PERETZ I, 1994, BRAIN, V117, P1283, DOI 10.1093/brain/117.6.1283
   Perrachione TK, 2007, NEUROPSYCHOLOGIA, V45, P1899, DOI 10.1016/j.neuropsychologia.2006.11.015
   Remez RE, 1997, J EXP PSYCHOL HUMAN, V23, P651, DOI 10.1037/0096-1523.23.3.651
   SAUTER DA, Q J EXPT PS IN PRESS
   Sauter DA, 2007, MOTIV EMOTION, V31, P192, DOI 10.1007/s11031-007-9065-x
   Schweinberger SR, 2001, NEUROPSYCHOLOGIA, V39, P921, DOI 10.1016/S0028-3932(01)00023-9
   Snowden JS, 2008, NEUROPSYCHOLOGIA, V46, P2638, DOI 10.1016/j.neuropsychologia.2008.04.018
   Snowden JS, 2004, BRAIN, V127, P860, DOI 10.1093/brain/awh099
   Thompson SA, 2004, NEUROPSYCHOLOGIA, V42, P359, DOI 10.1016/j.neuropsychologia.2003.08.004
   TYRRELL PJ, 1990, J NEUROL NEUROSUR PS, V53, P1046, DOI 10.1136/jnnp.53.12.1046
   Van Lancker D R, 1982, Brain Cogn, V1, P185, DOI 10.1016/0278-2626(82)90016-1
   VANLANCKER D, 1987, NEUROPSYCHOLOGIA, V25, P829, DOI 10.1016/0028-3932(87)90120-5
   VANLANCKER D, 1985, J PHONETICS, V13, P19, DOI 10.1016/S0095-4470(19)30723-5
   VANLANCKER DR, 1989, J CLIN EXP NEUROPSYC, V11, P665, DOI 10.1080/01688638908400923
   VANLANCKER DR, 1988, CORTEX, V24, P195, DOI 10.1016/S0010-9452(88)80029-7
   von Kriegstein K, 2005, J COGNITIVE NEUROSCI, V17, P367, DOI 10.1162/0898929053279577
   von Kriegstein K, 2003, COGNITIVE BRAIN RES, V17, P48, DOI 10.1016/S0926-6410(03)00079-X
   von Kriegstein K, 2006, CEREB CORTEX, V16, P1314, DOI 10.1093/cercor/bhj073
   Warren JD, 2006, NEUROIMAGE, V31, P1389, DOI 10.1016/j.neuroimage.2006.01.034
   Warrington E K, 1979, Ciba Found Symp, P153
   Warrington EK, 1998, NEUROPSYCHOL REHABIL, V8, P143
   Warrington EK, 1997, NEUROPSYCHOL REHABIL, V7, P143, DOI 10.1080/713755528
   WARRINGTON EK, 1967, CORTEX, V3, P317, DOI DOI 10.1016/S0010-9452(67)80020-0
   WHITELEY AM, 1978, J NEUROL NEUROSUR PS, V41, P575, DOI 10.1136/jnnp.41.6.575
   YOUNG AW, 1993, BRAIN, V116, P941, DOI 10.1093/brain/116.4.941
NR 69
TC 71
Z9 79
U1 0
U2 14
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD MAR
PY 2010
VL 48
IS 4
BP 1104
EP 1114
DI 10.1016/j.neuropsychologia.2009.12.011
PG 11
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA 573RY
UT WOS:000275933500030
PM 20006628
OA Green Published, hybrid, Green Accepted
DA 2024-01-09
ER

PT J
AU Waaramaa, T
   Leisiö, T
AF Waaramaa, Teija
   Leisio, Timo
TI Perception of emotionally loaded vocal expressions and its connection to
   responses to music. A cross-cultural investigation: Estonia, Finland,
   Sweden, Russia, and the USA
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE voice quality; expression; perception of emotions; valence; musical
   interests; cross-cultural
ID SPEECH; RECOGNITION; VOICE; PROSODY; VOCALIZATIONS
AB The present study focused on voice quality and the perception of the basic emotions from speech samples in cross-cultural conditions. It was examined whether voice quality, cultural, or language background, age, or gender were related to the identification of the emotions. Professional actors (n2) and actresses (n2) produced non sense sentences (n32) and protracted vowels (n8) expressing the six basic emotions, interest, and a neutral emotional state. The impact of musical interests on the ability to distinguish between emotions or valence (on an axis positivity neutrality negativity) from voice samples was studied. Listening tests were conducted on location in five countries: Estonia, Finland, Russia, Sweden, and the USA with 50 randomly chosen participants (25 males and 25 females) in each country. The participants (total N = 250) completed a questionnaire eliciting their background information and musical interests. The responses in the listening test and the questionnaires were statistically analyzed. Voice quality parameters and the share of the emotions and valence identified correlated significantly with each other for both genders. The percentage of emotions and valence identified was clearly above the chance level in each of the five countries studied, however, the countries differed significantly from each other for the identified emotions and the gender of the speaker. The samples produced by females were identified significantly better than those produced by males. Listener's age was a significant variable. Only minor gender differences were found for the identification. Perceptual confusion in the listening test between emotions seemed to be dependent on their similar voice production types. Musical interests tended to have a positive effect on the identification of the emotions. The results also suggest that identifying emotions from speech samples may be easier for those listeners who share a similar language or cultural background with the speaker.
C1 [Waaramaa, Teija] Univ Tampere, Sch Commun Media & Theatre, Tampere 33014, Finland.
   [Leisio, Timo] Univ Tampere, Sch Social Sci & Humanities, Tampere 33014, Finland.
C3 Tampere University; Tampere University
RP Waaramaa, T (corresponding author), Univ Tampere, Sch Commun Media & Theatre, Kalevantie 4, Tampere 33014, Finland.
EM teija.waaramaa@uta.fi
CR Abelin A., 2000, ISCA ITRW WORKSH SPE
   Abelin A., 2008, P SPEECH PROS 2008 C, P713
   ABELIN A., 2008, EMOTIONS HUMAN VOICE, V1, P65
   Abelin A, 2004, P SPEECH PROS ISCA M
   [Anonymous], 1973, BRUEL KJAER TECH REV
   [Anonymous], SAGE ENCY PERCEPTION
   [Anonymous], 2006, SINGING NEANDERTHALS
   [Anonymous], 1980, The Phonetic Description of Voice Quality
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Belin P, 2011, BRIT J PSYCHOL, V102, P711, DOI 10.1111/j.2044-8295.2011.02041.x
   Besson M, 2002, TRENDS COGN SCI, V6, P405, DOI 10.1016/S1364-6613(02)01975-7
   Cross I, 2001, ANN NY ACAD SCI, V930, P28, DOI 10.1111/j.1749-6632.2001.tb05723.x
   Ekman P., 2004, Emotions Revealed: Understanding Faces and Feelings
   Falk D, 2000, ORIGINS OF MUSIC, P197
   Fant G., 1970, Acoustic theory of speech production: with calculations based on Xray studies of Russian articulations
   Fecteau S, 2005, APPL NEUROPSYCHOL, V12, P40, DOI 10.1207/s15324826an1201_7
   FONAGY I, 1981, RES ASPECTS SINGING, V33, P51
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   GAUFFIN J, 1989, J SPEECH HEAR RES, V32, P556, DOI 10.1044/jshr.3203.556
   Gentilucci M, 2006, NEUROSCI BIOBEHAV R, V30, P949, DOI 10.1016/j.neubiorev.2006.02.004
   Hannon EE, 2005, PSYCHOL SCI, V16, P48, DOI 10.1111/j.0956-7976.2005.00779.x
   Higgins MB, 2002, J ACOUST SOC AM, V111, P1865, DOI 10.1121/1.1456517
   Imaizumi S., 2004, ISCA SPEECH PROS MAR
   Iversen JR, 2008, J ACOUST SOC AM, V124, P2263, DOI 10.1121/1.2973189
   Izard CE, 2007, PERSPECT PSYCHOL SCI, V2, P260, DOI [10.1111/j.1745-6916.2007.00044.x, 10.1111/j.1745-6916.2007.00053.x]
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2003, ANN NY ACAD SCI, V1000, P279, DOI 10.1196/annals.1280.025
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Koeda M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00105
   KOTLYAR GM, 1976, SOV PHYS ACOUST+, V22, P208
   LADD DR, 1985, J ACOUST SOC AM, V78, P435, DOI 10.1121/1.392466
   Laukka P, 2007, MOTIV EMOTION, V31, P182, DOI 10.1007/s11031-007-9063-z
   Laukkanen A. M., 1997, LOGOP PHONIATR VOCO, V22, P157, DOI DOI 10.3109/14015439709075330
   Laukkanen A. -M., 2008, EMOTIONS HUMAN VOICE, VI, P171
   Leisio T, 2010, MUSIIKKI, V2, P60
   Levitin DJ, 2009, ANN NY ACAD SCI, V1156, P211, DOI 10.1111/j.1749-6632.2009.04417.x
   Liberman A. M., 1981, SR6768, p[67, 68]
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Matsumoto D., 2002, HDB INT INTERCULTURA, P107
   Morrison SJ, 2009, PROG BRAIN RES, V178, P67, DOI 10.1016/S0079-6123(09)17805-6
   MURRAY IR, 1993, J ACOUST SOC AM, V93, P1097, DOI 10.1121/1.405558
   Nordenberg M, 2003, J TMH QPSR, V45, P93, DOI DOI 10.1080/14015430410004689
   Panksepp J, 2009, MUSIC SCI, P229, DOI 10.1177/1029864909013002111
   Richman B, 2000, ORIGINS OF MUSIC, P301
   Rizzolatti G, 1996, COGNITIVE BRAIN RES, V3, P131, DOI 10.1016/0926-6410(95)00038-0
   Sauter DA, 2010, P NATL ACAD SCI USA, V107, P2408, DOI 10.1073/pnas.0908239106
   Scherer KR, 2007, EMOTION, V7, P158, DOI 10.1037/1528-3542.7.1.158
   SCHERER KR, 1991, MOTIV EMOTION, V15, P123, DOI 10.1007/BF00995674
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   Schirmer A, 2002, COGNITIVE BRAIN RES, V14, P228, DOI 10.1016/S0926-6410(02)00108-8
   Schirmer A, 2008, EMOTIONS HUMAN VOICE, P75
   Schirmer A, 2002, P 1 SPEECH PROS C FR, P631
   Strait DL, 2009, EUR J NEUROSCI, V29, P661, DOI 10.1111/j.1460-9568.2009.06617.x
   Sundberg J, 2006, J ACOUST SOC AM, V120, P453, DOI 10.1121/1.2208451
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Trehub SE, 2003, NAT NEUROSCI, V6, P669, DOI 10.1038/nn1084
   Trimmer CG, 2008, EMOTION, V8, P838, DOI 10.1037/a0014080
   Waaramaa Teija, 2006, Logoped Phoniatr Vocol, V31, P153, DOI 10.1080/14015430500456739
   Waaramaa T, 2008, FOLIA PHONIATR LOGO, V60, P249, DOI 10.1159/000151762
   Waaramaa T, 2013, LOGOP PHONIATR VOCO, V38, P11, DOI 10.3109/14015439.2012.679966
   Waaramaa T, 2010, J VOICE, V24, P30, DOI 10.1016/j.jvoice.2008.04.004
   Waaramaa-Maki-Kulmala T., 2009, THESIS
NR 65
TC 11
Z9 12
U1 1
U2 14
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD JUN 21
PY 2013
VL 4
AR 344
DI 10.3389/fpsyg.2013.00344
PG 13
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA AA4DQ
UT WOS:000331045600001
PM 23801972
OA gold, Green Published
DA 2024-01-09
ER

PT J
AU Frühholz, S
   Grandjean, D
AF Fruehholz, Sascha
   Grandjean, Didier
TI Towards a fronto-temporal neural network for the decoding of angry vocal
   expressions
SO NEUROIMAGE
LA English
DT Article
DE Vocal expressions; Angry prosody; fMRI; Fronto-temporal network; Voice
ID EMOTIONAL PROSODY; AUDITORY-CORTEX; MEANINGLESS SPEECH; BRAIN; LANGUAGE;
   PATHWAYS; LATERALIZATION; PERCEPTION; INTONATION; MUSIC
AB Vocal expressions commonly elicit activity in superior temporal and inferior frontal cortices, indicating a distributed network to decode vocally expressed emotions. We examined the involvement of this frontotemporal network for the decoding of angry voices during attention towards (explicit attention) or away from emotional cues in voices (implicit attention) based on a reanalysis of previous data (Fruhholz, S., Ceravolo, L., Grandjean, D., 2012. Cerebral Cortex 22, 1107-1117). The general network revealed high interconnectivity of bilateral inferior frontal gyrus (IFG) to different bilateral voice-sensitive regions in mid and posterior superior temporal gyri. Right superior temporal gyrus (STG) regions showed connectivity to the left primary auditory cortex and secondary auditory cortex (AC) as well as to high-level auditory regions. This general network revealed differences in connectivity depending on the attentional focus. Explicit attention to angry voices revealed a specific right-left STG network connecting higher-level AC. During attention to a nonemotional vocal feature we also found a left-right STG network implicitly elicited by angry voices that also included low-level left AC. Furthermore, only during this implicit processing there was widespread interconnectivity between bilateral IFG and bilateral STG. This indicates that while implicit attention to angry voices recruits extended bilateral STG and IFG networks for the sensory and evaluative decoding of voices, explicit attention to angry voices solely involves a network of bilateral STG regions probably for the integrative recognition of emotional cues from voices. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Fruehholz, Sascha] Univ Geneva, Dept Psychol, Neurosci Emot & Affect Dynam NEAD Lab, CH-1205 Geneva, Switzerland.
   Univ Geneva, Swiss Ctr Affect Sci, Geneva, Switzerland.
C3 University of Geneva; University of Geneva
RP Frühholz, S (corresponding author), Univ Geneva, Dept Psychol, Neurosci Emot & Affect Dynam NEAD Lab, 40 Bd Pont Arve, CH-1205 Geneva, Switzerland.
EM sascha.fruehholz@unige.ch
RI Frühholz, Sascha/E-9194-2013
OI Grandjean, Didier/0000-0001-6125-4520; Fruhholz,
   Sascha/0000-0002-6485-3817
FU Swiss National Science Foundation [SNSF 105314_124572/1]; NCCR in
   Affective Sciences at the University of Geneva [51NF40-104897]
FX This study was supported by the Swiss National Science Foundation (SNSF
   105314_124572/1) and by the NCCR in Affective Sciences at the University
   of Geneva (51NF40-104897).
CR [Anonymous], 2009, Int. J. Speech Lang. Pathol
   Bach DR, 2008, NEUROIMAGE, V42, P919, DOI 10.1016/j.neuroimage.2008.05.034
   Bamiou DE, 2007, BRAIN RES REV, V56, P170, DOI 10.1016/j.brainresrev.2007.07.003
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Buchanan TW, 2000, COGNITIVE BRAIN RES, V9, P227, DOI 10.1016/S0926-6410(99)00060-9
   CIPOLLONI PB, 1985, EXP BRAIN RES, V57, P381
   Ethofer T, 2006, NEUROIMAGE, V30, P580, DOI 10.1016/j.neuroimage.2005.09.059
   Ethofer T, 2012, CEREB CORTEX, V22, P191, DOI 10.1093/cercor/bhr113
   Ethofer T, 2009, J COGNITIVE NEUROSCI, V21, P1255, DOI 10.1162/jocn.2009.21099
   Formisano E, 2003, NEURON, V40, P859, DOI 10.1016/S0896-6273(03)00669-X
   Friston KJ, 2005, NEUROIMAGE, V25, P661, DOI 10.1016/j.neuroimage.2005.01.013
   Friston KJ, 1997, NEUROIMAGE, V6, P218, DOI 10.1006/nimg.1997.0291
   Frühholz S, 2012, CEREB CORTEX, V22, P1107, DOI 10.1093/cercor/bhr184
   Gandour J, 2004, NEUROIMAGE, V23, P344, DOI 10.1016/j.neuroimage.2004.06.004
   Glasser MF, 2008, CEREB CORTEX, V18, P2471, DOI 10.1093/cercor/bhn011
   Grandjean D, 2005, NAT NEUROSCI, V8, P145, DOI 10.1038/nn1392
   Grandjean D, 2006, PROG BRAIN RES, V156, P235, DOI 10.1016/S0079-6123(06)56012-1
   Griffiths TD, 1999, NEUROREPORT, V10, P3825, DOI 10.1097/00001756-199912160-00019
   Griffiths TD, 2002, TRENDS NEUROSCI, V25, P348, DOI 10.1016/S0166-2236(02)02191-4
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kotz SA, 2003, BRAIN LANG, V86, P366, DOI 10.1016/S0093-934X(02)00532-1
   Leitman D.I., 2010, FRONT HUM NEUROSCI, V4, P1, DOI [10.3389/fnhum.2010.00019, DOI 10.3389/FNHUM.2010.00019]
   Leitman DI, 2010, SCHIZOPHRENIA BULL, V36, P545, DOI 10.1093/schbul/sbn115
   Lewis JW, 2009, J NEUROSCI, V29, P2283, DOI 10.1523/JNEUROSCI.4145-08.2009
   Nichols T, 2005, NEUROIMAGE, V25, P653, DOI 10.1016/j.neuroimage.2004.12.005
   Patel S, 2011, BIOL PSYCHOL, V87, P93, DOI 10.1016/j.biopsycho.2011.02.010
   Roesch E. B., 2010, BLUEPRINT AFFECTIVE, P271, DOI DOI 10.1037/A0025827
   Ross ED, 1997, BRAIN LANG, V56, P27, DOI 10.1006/brln.1997.1731
   Sander D, 2005, NEUROIMAGE, V28, P848, DOI 10.1016/j.neuroimage.2005.06.023
   Saur D, 2008, P NATL ACAD SCI USA, V105, P18035, DOI 10.1073/pnas.0805234105
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   Schönwiesner M, 2005, EUR J NEUROSCI, V22, P1521, DOI 10.1111/j.1460-9568.2005.04315.x
   Wiethoff S, 2008, NEUROIMAGE, V39, P885, DOI 10.1016/j.neuroimage.2007.09.028
   Wildgruber D, 2005, NEUROIMAGE, V24, P1233, DOI 10.1016/j.neuroimage.2004.10.034
   ZATORRE RJ, 1994, J NEUROSCI, V14, P1908, DOI 10.1523/jneurosci.14-04-01908.1994
   Zatorre RJ, 2002, TRENDS COGN SCI, V6, P37, DOI 10.1016/S1364-6613(00)01816-7
NR 37
TC 49
Z9 51
U1 0
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
J9 NEUROIMAGE
JI Neuroimage
PD SEP
PY 2012
VL 62
IS 3
BP 1658
EP 1666
DI 10.1016/j.neuroimage.2012.06.015
PG 9
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA 986TR
UT WOS:000307369000033
PM 22721630
DA 2024-01-09
ER

PT J
AU Correia, AI
   Castro, SL
   MacGregor, C
   Müllensiefen, D
   Schellenberg, EG
   Lima, CF
AF Correia, Ana Isabel
   Castro, Sao Luis
   MacGregor, Chloe
   Mullensiefen, Daniel
   Schellenberg, E. Glenn
   Lima, Cesar F.
TI Enhanced Recognition of Vocal Emotions in Individuals With Naturally
   Good Musical Abilities
SO EMOTION
LA English
DT Article
DE emotion; music; training; aptitude; voice
ID SPEECH PROSODY; AUDITORY IMAGERY; NON-MUSICIANS; PERCEPTION; CHILDREN;
   DISCRIMINATION; PERFORMANCE; LANGUAGE; LESSONS; VOCALIZATIONS
AB Music training is widely assumed to enhance several nonmusical abilities, including speech perception, executive functions, reading, and emotion recognition. This assumption is based primarily on cross-sectional comparisons between musicians and nonmusicians. It remains unclear, however, whether training itself is necessary to explain the musician advantages, or whether factors such as innate predispositions and informal musical experience could produce similar effects. Here, we sought to clarify this issue by examining the association between music training, music perception abilities and vocal emotion recognition. The sample (N = 169) comprised musically trained and untrained listeners who varied widely in their musical skills, as assessed through self-report and performance-based measures. The emotion recognition tasks required listeners to categorize emotions in nonverbal vocalizations (e.g., laughter, crying) and in speech prosody. Music training was associated positively with emotion recognition across tasks, but the effect was small. We also found a positive association between music perception abilities and emotion recognition in the entire sample, even with music training held constant. In fact, untrained participants with good musical abilities were as good as highly trained musicians at recognizing vocal emotions. Moreover, the association between music training and emotion recognition was fully mediated by auditory and music perception skills. Thus, in the absence of formal music training, individuals who were "naturally" musical showed musician-like performance at recognizing vocal emotions. These findings highlight an important role for factors other than music training (e.g., predispositions and informal musical experience) in associations between musical and nonmusical domains.
C1 [Correia, Ana Isabel; Lima, Cesar F.] Inst Univ Lisboa ISCTE IUL, Dept Social & Org Psychol, Ave Forcas Armadas, P-1649026 Lisbon, Portugal.
   [Castro, Sao Luis] Univ Porto, Fac Psychol & Educ Sci, Porto, Portugal.
   [MacGregor, Chloe; Mullensiefen, Daniel] Goldsmiths Univ London, Dept Psychol, London, England.
   [Schellenberg, E. Glenn] Univ Toronto Mississauga, Dept Psychol, Mississauga, ON, Canada.
   [Lima, Cesar F.] UCL, Inst Cognit Neurosci, London, England.
C3 Instituto Universitario de Lisboa; Universidade do Porto; University of
   London; Goldsmiths University London; University of Toronto; University
   Toronto Mississauga; University of London; University College London
RP Lima, CF (corresponding author), Inst Univ Lisboa ISCTE IUL, Dept Social & Org Psychol, Ave Forcas Armadas, P-1649026 Lisbon, Portugal.
EM cesar.lima@iscte-iul.pt
RI Castro, Sao Luis/ISV-1010-2023; Stacey MacGregor, Chloe/HTM-6386-2023;
   Lima, Cesar F./HSF-6972-2023; Castro, Sao Luis/E-5518-2017
OI Castro, Sao Luis/0000-0002-1487-3596; Lima, Cesar
   F./0000-0003-3058-7204; Castro, Sao Luis/0000-0002-1487-3596;
   Mullensiefen, Daniel/0000-0001-7297-1760; Schellenberg,
   Glenn/0000-0003-3681-6020; MacGregor, Chloe/0000-0001-8169-5454;
   Correia, Ana Isabel/0000-0002-2493-0195
FU Portuguese Foundation for Science and Technology (FCT)
   [PTDC/PSI-GER/28274/2017, IF/00172/2015, UID/PSI/00050/2013]; Fundação
   para a Ciência e a Tecnologia [PTDC/PSI-GER/28274/2017] Funding Source:
   FCT
FX Funded by grants from Portuguese Foundation for Science and Technology
   (FCT) awarded to Cesar F. Lima (PTDC/PSI-GER/28274/2017 and
   IF/00172/2015) and to the Center for Psychology at University of Porto
   (tUID/PSI/00050/2013 and PTDC/PSI-GER/28274/2017).
CR [Anonymous], PSYCHOMUSICOLOGY, DOI DOI 10.1037/H0094283
   Bangert M, 2003, BMC NEUROSCI, V4, DOI 10.1186/1471-2202-4-26
   BARTLETT JC, 1980, J EXP PSYCHOL HUMAN, V6, P501, DOI 10.1037/0096-1523.6.3.501
   Bigand E, 2006, COGNITION, V100, P100, DOI 10.1016/j.cognition.2005.11.007
   Boebinger D, 2015, J ACOUST SOC AM, V137, P378, DOI 10.1121/1.4904537
   Brück C, 2011, PHYS LIFE REV, V8, P383, DOI 10.1016/j.plrev.2011.10.002
   Castro SL, 2010, BEHAV RES METHODS, V42, P74, DOI 10.3758/BRM.42.1.74
   Chobert J, 2014, CEREB CORTEX, V24, P956, DOI 10.1093/cercor/bhs377
   Clark CN, 2015, SOC COGN AFFECT NEUR, V10, P444, DOI 10.1093/scan/nsu079
   Coffey EBJ, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00479
   Correia AI, 2019, NEUROIMAGE, V201, DOI 10.1016/j.neuroimage.2019.116052
   Dawson C, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00213
   Degé F, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00124
   Eisenbarth H, 2011, EMOTION, V11, P860, DOI 10.1037/a0022758
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   François C, 2013, CEREB CORTEX, V23, P2038, DOI 10.1093/cercor/bhs180
   Frey A, 2019, BRAIN SCI, V9, DOI 10.3390/brainsci9040091
   Goeleven E, 2008, COGNITION EMOTION, V22, P1094, DOI 10.1080/02699930701626582
   Good A, 2017, EAR HEARING, V38, P455, DOI 10.1097/AUD.0000000000000402
   Habibi A, 2016, DEV COGN NEUROS-NETH, V21, P1, DOI 10.1016/j.dcn.2016.04.003
   Harrison PMC, 2016, J NEW MUSIC RES, V45, P265, DOI 10.1080/09298215.2016.1197953
   Hayes AF., 2018, INTRO MEDIATION MODE
   Herholz SC, 2012, NEURON, V76, P486, DOI 10.1016/j.neuron.2012.10.011
   Honing H, 2019, EVOLVING ANIMAL ORCHESTRA: IN SEARCH OF WHAT MAKES US MUSICAL, P1
   Isaacowitz DM, 2007, PSYCHOL AGING, V22, P147, DOI 10.1037/0882-7974.22.1.147
   Iversen J. R., 2008, P 10 INT C MUSIC PER, P465, DOI DOI 10.1016/J.HEARES.2007.10.007
   Jarosz AF, 2014, J PROBL SOLVING, V7, P2, DOI 10.7771/1932-6246.1167
   JASP Team, 2018, JASP VERS 0 9 2
   Jeffreys H., 1998, Theory of Probability
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Koelsch S, 2015, ANN NY ACAD SCI, V1337, P193, DOI 10.1111/nyas.12684
   Koelsch S, 2014, NAT REV NEUROSCI, V15, P170, DOI 10.1038/nrn3666
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Krishnan S, 2018, CEREB CORTEX, V28, P4063, DOI 10.1093/cercor/bhy208
   Lima CF, 2020, PSYCHOL MUSIC, V48, P376, DOI 10.1177/0305735618801997
   Lima CF, 2016, SCI REP-UK, V6, DOI 10.1038/srep34911
   Lima CF, 2016, TRENDS NEUROSCI, V39, P527, DOI 10.1016/j.tins.2016.06.003
   Lima CF, 2015, CEREB CORTEX, V25, P4638, DOI 10.1093/cercor/bhv134
   Lima CF, 2013, BEHAV RES METHODS, V45, P1234, DOI 10.3758/s13428-013-0324-3
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Lundqvist D., 1998, KAROLINSKA DIRECTED
   MacGregor C, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01955
   Madsen SMK, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46728-1
   Mankel K, 2018, P NATL ACAD SCI USA, V115, P13129, DOI 10.1073/pnas.1811793115
   Marques C, 2007, J COGNITIVE NEUROSCI, V19, P1453, DOI 10.1162/jocn.2007.19.9.1453
   McGettigan C, 2015, CEREB CORTEX, V25, P246, DOI 10.1093/cercor/bht227
   Moreno S, 2014, HEARING RES, V308, P84, DOI 10.1016/j.heares.2013.09.012
   Moreno S, 2011, PSYCHOL SCI, V22, P1425, DOI 10.1177/0956797611416999
   Moreno S, 2009, CEREB CORTEX, V19, P712, DOI 10.1093/cercor/bhn120
   Moritz C, 2013, READ WRIT, V26, P739, DOI 10.1007/s11145-012-9389-0
   Mosing MA, 2014, PSYCHOL SCI, V25, P1795, DOI 10.1177/0956797614541990
   Mualem O, 2015, INT J MUSIC EDUC, V33, P413, DOI 10.1177/0255761415584292
   Müllensiefan D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089642
   Park M, 2015, FRONT HUM NEUROSCI, V8, DOI [10.3389/fnhurn.2014.01049, 10.3389/fnhum.2014.01049]
   Patel AD, 2014, HEARING RES, V308, P98, DOI 10.1016/j.heares.2013.08.011
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Pell MD, 2015, BIOL PSYCHOL, V111, P14, DOI 10.1016/j.biopsycho.2015.08.008
   Peretz I, 2003, NAT NEUROSCI, V6, P688, DOI 10.1038/nn1083
   Pfordresher PQ, 2013, PSYCHON B REV, V20, P747, DOI 10.3758/s13423-013-0401-8
   Pinheiro AP, 2015, BRAIN LANG, V140, P24, DOI 10.1016/j.bandl.2014.10.009
   Roden I, 2014, PSYCHOL MUSIC, V42, P284, DOI 10.1177/0305735612471239
   Rouder JN, 2012, J MATH PSYCHOL, V56, P356, DOI 10.1016/j.jmp.2012.08.001
   Sala G, 2017, CURR DIR PSYCHOL SCI, V26, P515, DOI 10.1177/0963721417712760
   Sala G, 2017, EDUC RES REV-NETH, V20, P55, DOI 10.1016/j.edurev.2016.11.005
   Schellenberg EG, 2020, PSYCHOL AESTHET CREA, V14, P475, DOI 10.1037/aca0000263
   Schellenberg EG, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0141449
   Schellenberg EG, 2011, BRIT J PSYCHOL, V102, P283, DOI 10.1111/j.2044-8295.2010.02000.x
   Schellenberg EG, 2004, PSYCHOL SCI, V15, P511, DOI 10.1111/j.0956-7976.2004.00711.x
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   Schön D, 2004, PSYCHOPHYSIOLOGY, V41, P341, DOI 10.1111/1469-8986.00172.x
   Scott SK, 2010, HBK BEHAV NEUROSCI, V19, P187, DOI 10.1016/B978-0-12-374593-4.00019-X
   Slevc LR, 2016, COGNITION, V152, P199, DOI 10.1016/j.cognition.2016.03.017
   Soranzo A, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00712
   Strachan JWA, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0219185
   Strait DL, 2009, ANN NY ACAD SCI, V1169, P209, DOI 10.1111/j.1749-6632.2009.04864.x
   Swaminathan S, 2020, J EXP PSYCHOL LEARN, V46, P2340, DOI 10.1037/xlm0000798
   Swaminathan S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-27571-2
   Swaminathan S, 2018, J EXP PSYCHOL LEARN, V44, P992, DOI 10.1037/xlm0000493
   Swaminathan S, 2017, PSYCHON B REV, V24, P1929, DOI 10.3758/s13423-017-1244-5
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Trimmer CG, 2008, EMOTION, V8, P838, DOI 10.1037/a0014080
   Wagenmakers EJ, 2018, PSYCHON B REV, V25, P58, DOI [10.3758/s13423-017-1323-7, 10.3758/s13423-017-1343-3]
   Wagenmakers EJ, 2016, BEHAV RES METHODS, V48, P413, DOI 10.3758/s13428-015-0593-0
   WAGNER HL, 1993, J NONVERBAL BEHAV, V17, P3, DOI 10.1007/BF00987006
   Warren JE, 2006, J NEUROSCI, V26, P13067, DOI 10.1523/JNEUROSCI.3907-06.2006
   Wechsler David., 1999, Escala de Inteligencia Wechsler para Adultos (WAIS-III). [Wechsler Intelligence Scale for Adults]
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   Zhang JD, 2020, PSYCHOL MUSIC, V48, P389, DOI 10.1177/0305735618804038
NR 88
TC 15
Z9 15
U1 10
U2 97
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 1528-3542
EI 1931-1516
J9 EMOTION
JI Emotion
PD AUG
PY 2022
VL 22
IS 5
BP 894
EP 906
DI 10.1037/emo0000770
PG 13
WC Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA 3B2WS
UT WOS:000827806900016
PM 32718172
OA Green Accepted
DA 2024-01-09
ER

PT J
AU Naranjo, B
AF Naranjo, Beatriz
TI The role of emotions in the perception of natural vs. play-acted
   dubbing: an approach to angry and sad vocal performances
SO META
LA English
DT Article
DE dubbing; naturalness; dubbese; emotions; vocal performance
AB This study examines the perception and preferences of Spanish viewers for natural vs. play-acted dubbing styles in different emotionally-loaded scenes. Two scenes portraying high-intensity emotions (anger and sadness) were selected from an American independent romantic comedy. For each scene, two different dubbed versions (natural and playacted) were recorded. While the natural version tried to capture the paralinguistic attitudes of native conversation, the play-acted version attempted to preserve the features of dubbese with calques, formulaic routines and other vocal and paralinguistic traits identified in play-acted and dubbed speech by previous studies. In an in-situ experiment, a group of 59 viewers with the same generational profile watched the dubbed scenes and assessed whether and how both versions differed. Then, they were asked to indicate their potential preferences. Results reveal that differences in terms of naturalness between the two versions were more perceptible in the anger scene than in the sad scene. The different emotions portrayed in the scenes also seem to have played a relevant part in viewers' preferences. Whereas participants showed a stronger preference towards natural voices in the anger scene, the play-acted version was more likable in the sad scene. The presence of visual and vocal expressions of emotion (e.g. sobbing) and background music are discussed as potential influential factors.
C1 [Naranjo, Beatriz] Univ Murcia, Murcia, Spain.
C3 University of Murcia
RP Naranjo, B (corresponding author), Univ Murcia, Murcia, Spain.
EM beatriz.naranjo@um.es
FU FEDER/UE funds [FFI2017-84187-P]; Spanish Ministerio de Ciencia,
   Innovacion y Universidades, Agencia Estatal de Investigacion
FX This work was supported by the Spanish Ministerio de Ciencia, Innovacion
   y Universidades, Agencia Estatal de Investigacion and FEDER/UE funds
   (grant number FFI2017-84187-P) This funding source played no role in the
   collection, analysis and interpretation of data, or the decision to
   submit the article for publication.
CR [Anonymous], 1997, TEXT TYPOLOGY TRANSL
   [Anonymous], 1969, ACTA LINGUISTICA ACA
   [Anonymous], 1973, FILMMAKERS NEWSLETTE
   Antonini R, 2008, AUDIOVISUAL TRANSLATION: LANGUAGE TRANSFER ON SCREEN, P97
   Audibert Nicolas, 2010, P SPEECH PROS CHIC
   Banos Pinero Rocio, 2014, META, V59, P406
   Banos Pinero Rocio, 2009, PREFABRICATED ORALIT
   BERRY Cicely, 1973, Voice and the Actor
   Bosseaux C, 2019, PERSPECT STUD TRANSL, V27, P218, DOI 10.1080/0907676X.2018.1452275
   Bosseaux Charlotte, 2008, QUAD FILOL-ESTUD LIT, V13, P85
   Chaume F, 2004, META, V49, P843, DOI 10.7202/009785ar
   CHAUME Frederic, 2001, La traduccion en los medios audiovisuales, P77
   Diaz Cintas Jorge., 2010, HDB TRANSLATION STUD
   Fodor Itsvan, 1969, ACTA LINGUISTICA, V19, P69
   Freddi Maria, 2008, ECOLINGUA ROLE E COR, P52
   Fresco PR, 2009, META, V54, P49, DOI 10.7202/029793ar
   Giampieri P, 2018, ALTRE MOD-RIV STUD L, V19, P175, DOI 10.13130/2035-7680/10120
   Giampieri Patrizia, 2017, LINGUE CULTURE MEDIA, V2
   Gobl C, 2003, SPEECH COMMUN, V40, P189, DOI 10.1016/S0167-6393(02)00082-1
   Gonzalez Villa R.E., 2002, THESIS
   Avila-Cabrera JJ, 2015, SENDEBAR, P37
   Johnstone T, 2006, SOC COGN AFFECT NEUR, V1, P242, DOI 10.1093/scan/nsl027
   Jürgens R, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00180
   Juslin PN, 2018, J NONVERBAL BEHAV, V42, P1, DOI 10.1007/s10919-017-0268-x
   Keen Suzanne, 2007, EMPATHY NOVEL
   Marza Ibanez Anna, 2018, LLENGUA PERIFERICA D
   Marza Ibanez Anna, 2016, THESIS
   Naranjo Beatriz, 2018, TRANSLATION COGNITIO, V1, P319
   Sánchez BN, 2019, BABEL-AMSTERDAM, V65, P264, DOI 10.1075/babel.00091.nar
   Sánchez BN, 2015, REV ESP LINGUIST APL, V28, P416, DOI 10.1075/resla.28.2.03nar
   OLIVER MB, 1993, HUM COMMUN RES, V19, P315, DOI 10.1111/j.1468-2958.1993.tb00304.x
   Pavesi M, 1996, CINEMA E TRADUZIONE, P117
   Pavesi M, 2018, ROUTL ADV TRANSL INT, V32, P11
   Pavesi M, 2016, ACROSS LANG CULT, V17, P99, DOI 10.1556/084.2016.17.1.5
   Pavesi Maria., 2008, Between Text and Image. Updating Research in Screen Translation
   Pavesi Maria, 2012, MEDIA ALL 3, V3, P335
   Pérez-González L, 2007, TRANSLATOR, V13, P1
   Pietrowicz M, 2017, J ACOUST SOC AM, V142, P792, DOI 10.1121/1.4997189
   Quaglio P, 2009, STUD CORPUS LINGUIST, V36, P1
   Ranzato Irene, 2009, TRANSLATING REGIONAL, P43
   Fresco PR, 2012, MONTI, V4, P181, DOI 10.6035/MonTI.2012.4.8
   Romero Fresco Pablo, 2007, LING ANTVERP NEW SER, V6, P185
   Sanchez-Mompean S, 2020, PALGR STUD TRANSL, P1, DOI 10.1007/978-3-030-35521-0
   Sanchez-Mompeán S, 2020, PERSPECT STUD TRANSL, V28, P284, DOI 10.1080/0907676X.2019.1616788
   Sanchez-Mompean Sofia, 2017, THESIS
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Schingler Martin, 2006, SCOPE, V5, P1
   SMITH S, 2007, CLOSE UP, V2, P159
   Sobin C, 1999, J PSYCHOLINGUIST RES, V28, P347, DOI 10.1023/A:1023237014909
   Soler Pardo Betlem, 2013, J SPEC TRANSL, V20, P1
   SpiteriMiggiani Giselle., 2019, Dialogue writing for dubbing. An insider's perspective
   Thomas Herbst, 1994, LINGUISTISCHE ASPEKT
   Wassiliwizky E, 2015, PSYCHOL AESTHET CREA, V9, P405, DOI 10.1037/aca0000023
   Whitman-Linsen Candace, 1992, DUBBING GLASS
   Whittaker T, 2012, J SPAN CULT STUD, V13, P292, DOI 10.1080/14636204.2013.788915
   Whittaker Tom, 2012, LOCATING VOICE FILM
   Wright Jean Annand, 2013, VOICE ANIMATION BURL
   Muñoz PZ, 2016, HERMENEUS, P315
   Zanotti S, 2012, META, V57, P351
   Zanotti Serenella, 2014, OBSERVING NORMS OBSE, P351
NR 60
TC 0
Z9 0
U1 0
U2 0
PU PRESSES UNIV MONTREAL
PI MONTREAL
PA PO BOX 6128, SUCCURSALE A, 3744 RUE JEAN-BRILLANT, MONTREAL, QUEBEC H3T
   1P1, CANADA
SN 0026-0452
J9 META
JI Meta
PD DEC
PY 2021
VL 66
IS 3
BP 580
EP 600
PG 21
WC Language & Linguistics
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Linguistics
GA VM2EH
UT WOS:000976767100005
DA 2024-01-09
ER

PT J
AU Guzman, M
   Correa, S
   Muñoz, D
   Mayerhoff, R
AF Guzman, Marco
   Correa, Soledad
   Munoz, Daniel
   Mayerhoff, Ross
TI Influence on Spectral Energy Distribution of Emotional Expression
SO JOURNAL OF VOICE
LA English
DT Article
DE Emotions; Actor; Spectral energy; LTAS; Voice quality; Timbre
ID TERM AVERAGE SPECTRUM; VOICE QUALITY; FUNDAMENTAL-FREQUENCY; MUSIC
   PERFORMANCE; SYNTHETIC SPEECH; VOCAL EMOTION; COMMUNICATION;
   RECOGNITION; PREVALENCE; PERCEPTION
AB Purpose. The aim of this study was to determine the influence of emotional expression in spectral energy distribution in professional theater actors.
   Study Design. The study design is a quasi-experimental study.
   Method. Thirty-seven actors, native Spanish speakers, were included. All subjects had at least 3 years of professional experience as a theater actor and no history of vocal pathology for the last 5 years. Participants were recorded during a read-aloud task of a 230-word passage, expressing six different emotions (happiness, sadness, fear, anger, tenderness, and eroticism) and without emotion (neutral state). Acoustical analysis with long-term average spectrum included three variables: the energy level difference between the F-1 and fundamental frequency (F-0) regions, ratio between 1-5 kHz and 5-8 kHz, and alpha ratio.
   Results. All the different emotions differ significantly from the neutral state for alpha ratio and 1-5/5-8 kHz ratio. Only significant differences between "joy," "anger," and "eroticism" were found for L1-L0 ratio. Statistically significant differences between genders for the three acoustical variables were also found.
   Conclusion. The expression of emotion impacts the spectral energy distribution. On the one hand emotional states characterized by a breathy voice quality such as tenderness, sadness, and eroticism present a low harmonic energy above 1 kHz, high glottal noise energy, and more energy on F-0 than overtones. On the other hand, emotional states such as joy, anger, and fear are characterized by high harmonic energy greater than 1 kHz (less steep spectral slope declination), low glottal noise energy, and more energy on the F-1 than F-0 region.
C1 [Guzman, Marco] Univ Chile, Sch Commun Sci, Santiago, Chile.
   [Correa, Soledad] Univ Valparaiso, Sch Commun Sci, Valparaiso, Chile.
   [Munoz, Daniel] Univ Chile, Fac Med, Santiago 7, Chile.
   [Mayerhoff, Ross] Wayne State Univ, Dept Otolaryngol, Detroit, MI 48201 USA.
C3 Universidad de Chile; Universidad de Valparaiso; Universidad de Chile;
   Wayne State University
RP Guzman, M (corresponding author), Univ Chile, Sch Commun Sci, Ave Independencia 1029, Santiago, Chile.
EM guzmanvoz@gmail.com
RI Munoz, Daniel/IXD-6516-2023
CR [Anonymous], 1986, The structure of singing
   [Anonymous], 1964, COMMUNICATION EMOTIO
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   BLOOTHOOFT G, 1986, J ACOUST SOC AM, V79, P2028, DOI 10.1121/1.393211
   Boersma P, 2008, PRAAT MANUAL DOING P
   BORDEN GJ, 1984, SPEECH SCI PRIMER PH
   Chapman JL, 2006, SINGING TEACHING SIN
   Douglas-Cowie E, 2003, SPEECH COMMUN, V40, P33, DOI 10.1016/S0167-6393(02)00070-5
   Douglas-Cowie E., 2003, 15 INT C PHON SCI BA
   Foulds-Elliott S D, 2000, Logoped Phoniatr Vocol, V25, P151, DOI 10.1080/140154300750067539
   GAUFFIN J, 1989, J SPEECH HEAR RES, V32, P556, DOI 10.1044/jshr.3203.556
   HAMMARBERG B, 1980, ACTA OTO-LARYNGOL, V90, P441, DOI 10.3109/00016488009131746
   HILLENBRAND J, 1994, J SPEECH HEAR RES, V37, P769, DOI 10.1044/jshr.3704.769
   Hurme P, 1985, PAPERS SPEECH RES
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Juslin PN, 1999, MUSIC PERCEPT, V17, P197
   Juslin PN, 1997, MUSIC SCI, V1, P225, DOI DOI 10.1177/102986499700100205
   Kienast M, 2000, ACOUSTICAL ANAL SPEC, P145
   KITZING P, 1986, J PHONETICS, V14, P477, DOI 10.1016/S0095-4470(19)30693-X
   KLATT DH, 1990, J ACOUST SOC AM, V87, P820, DOI 10.1121/1.398894
   Laukkanen A-M, 1997, SCAND J LOG PHON VOC, V22, P157
   LIEBERMAN P, 1962, J ACOUST SOC AM, V34, P922, DOI 10.1121/1.1918222
   Linville SE, 2001, J VOICE, V15, P323, DOI 10.1016/S0892-1997(01)00034-0
   Master S, 2008, J VOICE, V22, P146, DOI 10.1016/j.jvoice.2006.09.006
   Master S, 2012, J VOICE, V26, pE117, DOI 10.1016/j.jvoice.2010.10.011
   Mendoza E, 1996, J VOICE, V10, P59, DOI 10.1016/S0892-1997(96)80019-1
   Miralles A, 1984, MONOLOGOS EJERCICIO, P56
   Murray IR, 2008, COMPUT SPEECH LANG, V22, P107, DOI 10.1016/j.csl.2007.06.001
   MURRAY IR, 1993, J ACOUST SOC AM, V93, P1097, DOI 10.1121/1.405558
   Nordemberg M, 2003, TMH Q PROGR STATUS R, V45, P87
   Nwe TL, 2003, SPEECH COMMUN, V41, P603, DOI 10.1016/S0167-6393(03)00099-2
   Pettersen V, 2009, J VOICE, V23, P295, DOI 10.1016/j.jvoice.2007.08.006
   Pittarn J., 1993, HDB EMOTIONS, P185
   Roy N, 2004, J SPEECH LANG HEAR R, V47, P281, DOI 10.1044/1092-4388(2004/023)
   Russell A, 1998, J VOICE, V12, P467, DOI 10.1016/S0892-1997(98)80056-8
   Scherer K. R., 1984, APPROACHES EMOTION, DOI 10.4324/9781315798806
   Scherer K. R, 1993, INTERPERSONAL EXPECT, P316
   Scherer K.R., 1988, Journal of Language Social Psychology, V7, P79, DOI [DOI 10.1177/0261927X8800700201, 10.1177/0261927x8800700201]
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   SCHERER KR, 1991, MOTIV EMOTION, V15, P123, DOI 10.1007/BF00995674
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   SCHLOSBERG H, 1954, PSYCHOL REV, V61, P81, DOI 10.1037/h0054570
   Schroder M, 2001, ACOUSTIC CORRELATES, V1
   Sherer K. R., 1989, Handbook of social psychophysiology, P165
   Stemple JC., 2014, CLIN VOICE PATHOLOGY
   SUNDBERG J, 1993, J VOICE, V7, P15, DOI 10.1016/S0892-1997(05)80108-0
   Ternstrom S, 2003, J ACOUST SOC AM, V13, P2296
   Van Borsel J, 2009, J VOICE, V23, P291, DOI 10.1016/j.jvoice.2007.08.002
   Verdolini K, 1998, J VOICE, V12, P315, DOI 10.1016/S0892-1997(98)80021-0
   VERVERIDIS D., 2004, P 12 EUR SIGN PROC C, P341
   Waaramaa Teija, 2006, Logoped Phoniatr Vocol, V31, P153, DOI 10.1080/14015430500456739
   White P., 1998, LOGOPED PHONIATR VOC, V23, P111
   White P, 2000, TMH Q PROGR STATUS R, V4, P29
   WILLIAMS CE, 1972, J ACOUST SOC AM, V52, P1238, DOI 10.1121/1.1913238
   Xu Y, 2005, SPEECH COMMUN, V46, P220, DOI 10.1016/j.specom.2005.02.014
   YANAGIHARA N, 1967, J SPEECH HEAR RES, V10, P531, DOI 10.1044/jshr.1003.531
   YILDIRIM S, 2004, P INT C SPOK LANG PR, P2193
NR 59
TC 16
Z9 21
U1 0
U2 19
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0892-1997
J9 J VOICE
JI J. Voice
PD JAN
PY 2013
VL 27
IS 1
AR 129.e1
DI 10.1016/j.jvoice.2012.08.008
PG 10
WC Audiology & Speech-Language Pathology; Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Audiology & Speech-Language Pathology; Otorhinolaryngology
GA 066CK
UT WOS:000313197300022
PM 23159031
DA 2024-01-09
ER

PT J
AU Martins, I
   Lima, CF
   Pinheiro, AP
AF Martins, Ines
   Lima, Cesar F.
   Pinheiro, Ana P.
TI Enhanced salience of musical sounds in singers and instrumentalists
SO COGNITIVE AFFECTIVE & BEHAVIORAL NEUROSCIENCE
LA English
DT Article
DE Emotion; Music; Voice; Music expertise; Event-related potential
ID EMOTIONAL PROSODY; PITCH DISCRIMINATION; TEMPORAL DYNAMICS; VOCAL
   EMOTION; SPEECH; MUSICIANS; PERCEPTION; BRAIN; EXPERTISE; VOICE
AB Music training has been linked to facilitated processing of emotional sounds. However, most studies have focused on speech, and less is known about musicians' brain responses to other emotional sounds and in relation to instrument-specific experience. The current study combined behavioral and EEG methods to address two novel questions related to the perception of auditory emotional cues: whether and how long-term music training relates to a distinct emotional processing of nonverbal vocalizations and music; and whether distinct training profiles (vocal vs. instrumental) modulate brain responses to emotional sounds from early to late processing stages. Fifty-eight participants completed an EEG implicit emotional processing task, in which musical and vocal sounds differing in valence were presented as nontarget stimuli. After this task, participants explicitly evaluated the same sounds regarding the emotion being expressed, their valence, and arousal. Compared with nonmusicians, musicians displayed enhanced salience detection (P2), attention orienting (P3), and elaborative processing (Late Positive Potential) of musical (vs. vocal) sounds in event-related potential (ERP) data. The explicit evaluation of musical sounds also was distinct in musicians: accuracy in the emotional recognition of musical sounds was similar across valence types in musicians, who also judged musical sounds to be more pleasant and more arousing than nonmusicians. Specific profiles of music training (singers vs. instrumentalists) did not relate to differences in the processing of vocal vs. musical sounds. Together, these findings reveal that music has a privileged status in the auditory system of long-term musically trained listeners, irrespective of their instrument-specific experience.
C1 [Martins, Ines; Pinheiro, Ana P.] Univ Lisbon, Fac Psicol, CICPSI, P-1649013 Lisbon, Portugal.
   [Lima, Cesar F.] Inst Univ Lisboa ISCTE IUL, Lisbon, Portugal.
C3 Universidade de Lisboa; Instituto Universitario de Lisboa
RP Pinheiro, AP (corresponding author), Univ Lisbon, Fac Psicol, CICPSI, P-1649013 Lisbon, Portugal.
EM appinheiro@psicologia.ulisboa.pt
RI Lima, Cesar F./HSF-6972-2023
OI Lima, Cesar F./0000-0003-3058-7204
FU Portuguese Science Foundation (Fundacao para a Ciencia e a Tecnologia
   [FCT]) [PTDC/MHC-PCN/0101/2014, PTDC/PSI-GER/28274/2017]; Fundação para
   a Ciência e a Tecnologia [PTDC/PSI-GER/28274/2017] Funding Source: FCT
FX This work was supported by the Portuguese Science Foundation (Fundacao
   para a Ciencia e a Tecnologia [FCT]; grant number PTDC/MHC-PCN/0101/2014
   awarded to APP and grant numbers PTDC/PSI-GER/28274/2017 awarded to CL
   and APP). The authors thank the participants who collaborated in the
   study, as well as Marta Pereira for assistance with data analyses.
CR Baskent D, 2018, J ACOUST SOC AM, V143, pEL311, DOI 10.1121/1.5034489
   Belin P, 2004, TRENDS COGN SCI, V8, P129, DOI 10.1016/j.tics.2004.01.008
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Bestelmeyer PEG, 2017, SOC COGN AFFECT NEUR, V12, P1351, DOI 10.1093/scan/nsx059
   Bestelmeyer PEG, 2014, J NEUROSCI, V34, P8098, DOI 10.1523/JNEUROSCI.4820-13.2014
   Bidelman GM, 2014, EUR J NEUROSCI, V40, P2662, DOI 10.1111/ejn.12627
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Canavarro MC., 1999, BSI TESTES PROVAS PS, P87
   Castiajo P, 2021, COGN AFFECT BEHAV NE, V21, P412, DOI 10.3758/s13415-021-00864-2
   Castiajo P, 2019, MOTIV EMOTION, V43, P803, DOI 10.1007/s11031-019-09783-9
   Castro SL, 2014, MUSIC PERCEPT, V32, P125, DOI 10.1525/MP.2014.32.2.125
   Chartrand JP, 2006, NEUROSCI LETT, V405, P164, DOI 10.1016/j.neulet.2006.06.053
   Chobert J, 2014, CEREB CORTEX, V24, P956, DOI 10.1093/cercor/bhs377
   Christiner M, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00482
   Correia AI, 2022, EMOTION, V22, P894, DOI 10.1037/emo0000770
   Crowley KE, 2004, CLIN NEUROPHYSIOL, V115, P732, DOI 10.1016/j.clinph.2003.11.021
   Curtis ME, 2010, EMOTION, V10, P335, DOI 10.1037/a0017928
   Delaney-Busch N, 2016, COGN AFFECT BEHAV NE, V16, P415, DOI 10.3758/s13415-016-0402-y
   Delplanque S, 2006, INT J PSYCHOPHYSIOL, V60, P315, DOI 10.1016/j.ijpsycho.2005.06.006
   Denham SL, 2020, EUR J NEUROSCI, V51, P1151, DOI 10.1111/ejn.13802
   Dibben N, 2018, FRONT BEHAV NEUROSCI, V12, DOI 10.3389/fnbeh.2018.00184
   Dick F, 2011, CEREB CORTEX, V21, P938, DOI 10.1093/cercor/bhq166
   Dumont E, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01694
   ELBERT T, 1995, SCIENCE, V270, P305, DOI 10.1126/science.270.5234.305
   Espírito-Santo H, 2017, APPL NEUROPSYCH-ADUL, V24, P275, DOI 10.1080/23279095.2017.1290636
   Farmer E, 2020, MUSIC PERCEPT, V37, P323, DOI 10.1525/MP.2020.37.4.323
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Frühholz S, 2016, SOC COGN AFFECT NEUR, V11, P1638, DOI 10.1093/scan/nsw066
   Frühholz S, 2016, NEUROSCI BIOBEHAV R, V68, P96, DOI 10.1016/j.neubiorev.2016.05.002
   Fujioka T, 2006, BRAIN, V129, P2593, DOI 10.1093/brain/awl247
   Fuller CD, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00179
   Galinha Iolanda Costa, 2005, Aná. Psicológica, V23, P219
   Giordano BL, 2021, NAT HUM BEHAV, V5, P1203, DOI 10.1038/s41562-021-01073-0
   GRATTON G, 1983, ELECTROEN CLIN NEURO, V55, P468, DOI 10.1016/0013-4694(83)90135-9
   Grau-Sánchez J, 2020, NEUROSCI BIOBEHAV R, V112, P585, DOI 10.1016/j.neubiorev.2020.02.027
   Halwani GF, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00156
   Herholz SC, 2012, NEURON, V76, P486, DOI 10.1016/j.neuron.2012.10.011
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Jeon J., 1997, PSYCHOL MUSIC, V25, P70, DOI [10.1177/0305735697251006, DOI 10.1177/0305735697251006]
   Jessen S, 2011, NEUROIMAGE, V58, P665, DOI 10.1016/j.neuroimage.2011.06.035
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kishon-Rabin Liat, 2001, Journal of Basic and Clinical Physiology and Pharmacology, V12, P125
   Kleber B, 2010, CEREB CORTEX, V20, P1144, DOI 10.1093/cercor/bhp177
   Krishnan S, 2018, CEREB CORTEX, V28, P4063, DOI 10.1093/cercor/bhy208
   Lappe C, 2008, J NEUROSCI, V28, P9632, DOI 10.1523/JNEUROSCI.2254-08.2008
   Lima CF, 2020, PSYCHOL MUSIC, V48, P376, DOI 10.1177/0305735618801997
   Lima CF, 2019, EMOTION, V19, P219, DOI 10.1037/emo0000429
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Liu TS, 2012, NEUROREPORT, V23, P108, DOI 10.1097/WNR.0b013e32834ea757
   Liu YL, 2012, J NEUROSCI, V32, P14563, DOI 10.1523/JNEUROSCI.3109-12.2012
   Margulis EH, 2009, HUM BRAIN MAPP, V30, P267, DOI 10.1002/hbm.20503
   Martins M, 2021, EMOT REV, V13, P199, DOI 10.1177/17540739211022035
   Micheyl C, 2006, HEARING RES, V219, P36, DOI 10.1016/j.heares.2006.05.004
   Moran TP, 2013, BRAIN RES, V1516, P66, DOI 10.1016/j.brainres.2013.04.018
   Mualem O, 2015, INT J MUSIC EDUC, V33, P413, DOI 10.1177/0255761415584292
   Munzer S., 2002, Psychologische Beitrage, V44, P187
   Musacchia G, 2007, P NATL ACAD SCI USA, V104, P15894, DOI 10.1073/pnas.0701498104
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Nikjeh DA, 2008, PSYCHOPHYSIOLOGY, V45, P994, DOI 10.1111/j.1469-8986.2008.00689.x
   Nolden S, 2017, NEUROPSYCHOLOGIA, V103, P96, DOI 10.1016/j.neuropsychologia.2017.07.014
   Pantev C, 2001, ANN NY ACAD SCI, V930, P300, DOI 10.1111/j.1749-6632.2001.tb05740.x
   Pantev C, 2001, NEUROREPORT, V12, P169, DOI 10.1097/00001756-200101220-00041
   Pantev C, 2011, NEUROSCI BIOBEHAV R, V35, P2140, DOI 10.1016/j.neubiorev.2011.06.010
   Paquette S, 2020, BRAIN RES, V1741, DOI 10.1016/j.brainres.2020.146887
   Paquette S, 2018, ANN NY ACAD SCI, V1423, P329, DOI 10.1111/nyas.13666
   Paquette S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00509
   Park M, 2015, FRONT HUM NEUROSCI, V8, DOI [10.3389/fnhurn.2014.01049, 10.3389/fnhum.2014.01049]
   Parsons CE, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01440
   Patel AD, 2014, HEARING RES, V308, P98, DOI 10.1016/j.heares.2013.08.011
   Paulmann S, 2008, NEUROREPORT, V19, P209, DOI 10.1097/WNR.0b013e3282f454db
   Paulmann S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00345
   Paulmann S, 2012, NEUROPSYCHOLOGIA, V50, P1609, DOI 10.1016/j.neuropsychologia.2012.03.014
   Pinheiro AP, 2013, PSYCHOL MED, V43, P603, DOI 10.1017/S003329171200133X
   Pinheiro AP, 2017, BIOL PSYCHOL, V130, P11, DOI 10.1016/j.biopsycho.2017.09.012
   Pinheiro AP, 2017, CORTEX, V92, P233, DOI 10.1016/j.cortex.2017.03.018
   Pinheiro AP, 2016, BRAIN LANG, V153, P38, DOI 10.1016/j.bandl.2015.12.003
   Pinheiro AP, 2016, SOC COGN AFFECT NEUR, V11, P127, DOI 10.1093/scan/nsv103
   Pinheiro AP, 2015, BRAIN LANG, V140, P24, DOI 10.1016/j.bandl.2014.10.009
   PITT MA, 1994, J EXP PSYCHOL HUMAN, V20, P976, DOI 10.1037/0096-1523.20.5.976
   Polich J, 2007, CLIN NEUROPHYSIOL, V118, P2128, DOI 10.1016/j.clinph.2007.04.019
   Proverbio AM, 2020, EUR J NEUROSCI, V51, P1987, DOI 10.1111/ejn.14650
   Rammsayer T, 2006, MUSIC PERCEPT, V24, P37, DOI 10.1525/mp.2006.24.1.37
   Rigoulot S, 2015, NEUROSCIENCE, V290, P175, DOI 10.1016/j.neuroscience.2015.01.033
   Rüsseler J, 2001, NEUROSCI LETT, V308, P33, DOI 10.1016/S0304-3940(01)01977-2
   Sauter DA, 2010, J COGNITIVE NEUROSCI, V22, P474, DOI 10.1162/jocn.2009.21215
   Schellenberg EG, 2020, PSYCHOL AESTHET CREA, V14, P475, DOI 10.1037/aca0000263
   Schirmer A, 2005, NEUROREPORT, V16, P635, DOI 10.1097/00001756-200504250-00024
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   Schirmer A, 2018, SOC COGN AFFECT NEUR, V13, P1, DOI 10.1093/scan/nsx142
   Shahin AJ, 2008, NEUROIMAGE, V41, P113, DOI 10.1016/j.neuroimage.2008.01.067
   Sharp A, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01976
   SPIEGEL MF, 1984, J ACOUST SOC AM, V76, P1690, DOI 10.1121/1.391605
   Strong Jessica V, 2019, Neuropsychol Dev Cogn B Aging Neuropsychol Cogn, V26, P367, DOI 10.1080/13825585.2018.1448356
   Tervaniemi M, 2005, EXP BRAIN RES, V161, P1, DOI 10.1007/s00221-004-2044-5
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Trimmer CG, 2008, EMOTION, V8, P838, DOI 10.1037/a0014080
   Vasconcelos M, 2017, J NONVERBAL BEHAV, V41, P239, DOI 10.1007/s10919-017-0253-4
   WAGNER HL, 1993, J NONVERBAL BEHAV, V17, P3, DOI 10.1007/BF00987006
   Weijkamp J, 2017, PSYCHOL MUSIC, V45, P204, DOI 10.1177/0305735616654216
   Wildgruber D, 2006, PROG BRAIN RES, V156, P249, DOI 10.1016/S0079-6123(06)56013-3
   Zarate JM, 2008, NEUROIMAGE, V40, P1871, DOI 10.1016/j.neuroimage.2008.01.026
NR 102
TC 3
Z9 3
U1 3
U2 18
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1530-7026
EI 1531-135X
J9 COGN AFFECT BEHAV NE
JI Cogn. Affect. Behav. Neurosci.
PD OCT
PY 2022
VL 22
IS 5
BP 1044
EP 1062
DI 10.3758/s13415-022-01007-x
EA MAY 2022
PG 19
WC Behavioral Sciences; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Behavioral Sciences; Neurosciences & Neurology
GA 4L1RE
UT WOS:000789727200001
PM 35501427
OA Bronze
DA 2024-01-09
ER

PT J
AU Schehka, S
   Zimmermann, E
AF Schehka, Simone
   Zimmermann, Elke
TI Affect Intensity in Voice Recognized by Tree Shrews (<i>Tupaia
   belangeri</i>)
SO EMOTION
LA English
DT Article
DE acoustic communication; emotion; perception; tree shrew; evolution
ID YELLOW-BELLIED MARMOTS; VOCAL EXPRESSION; ALARM CALLS; PSYCHOSOCIAL
   STRESS; EMOTION; AROUSAL; COMMUNICATION; VOCALIZATIONS; PERCEPTION;
   PHYSIOLOGY
AB Shared acoustic cues in speech, music, and nonverbal emotional expressions were postulated to code for emotion quality and intensity favoring the hypothesis of a prehuman origin of affective prosody in human emotional communication. To explore this hypothesis, we examined in playback experiments using a habituation-dishabituation paradigm whether a solitary foraging, highly vocal mammal, the tree shrew, is able to discriminate two behaviorally defined states of affect intensity (low vs. high) from the voice of conspecifics. Playback experiments with communication calls of two different types (chatter call and scream call) given in the state of low affect intensity revealed that habituated tree shrews dishabituated to one call type (the chatter call) and showed a tendency to do so for the other one (the scream call), both given in the state of high affect intensity. Findings suggest that listeners perceive the acoustic variation linked to defined states of affect intensity as different within the same call type. Our findings in tree shrews provide first evidence that acoustically conveyed affect intensity is biologically relevant without any other sensory cue, even for solitary foragers. Thus, the perception of affect intensity in voice conveyed in stressful contexts represents a shared trait of mammals, independent of the complexity of social systems. Findings support the hypothesis that affective prosody in human emotional communication has deep-reaching phylogenetic roots, deriving from precursors already present and relevant in the vocal communication system of early mammals.
C1 [Zimmermann, Elke] Univ Vet Med, Ctr Syst Neurosci, D-30559 Hannover, Germany.
   [Schehka, Simone; Zimmermann, Elke] Univ Vet Med, Inst Zool, D-30559 Hannover, Germany.
C3 University of Veterinary Medicine Hannover; University of Veterinary
   Medicine Hannover
RP Zimmermann, E (corresponding author), Univ Vet Med, Ctr Syst Neurosci, Buenteweg 17, D-30559 Hannover, Germany.
EM elke.zimmermann@tiho-hannover.de
CR Bachorowski JA, 1999, CURR DIR PSYCHOL SCI, V8, P53, DOI 10.1111/1467-8721.00013
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Bastian A, 2008, J ACOUST SOC AM, V124, P598, DOI 10.1121/1.2924123
   BINZ H, 1989, BEHAVIOUR, V109, P142, DOI 10.1163/156853989X00196
   Blanchard RJ, 2001, PHYSIOL BEHAV, V73, P261, DOI 10.1016/S0031-9384(01)00449-8
   Blumstein DT, 2004, ANIM BEHAV, V68, P1257, DOI 10.1016/j.anbehav.2003.12.024
   Blumstein DT, 1997, ANIM BEHAV, V53, P143, DOI 10.1006/anbe.1996.0285
   Cheney D. L., 1988, ANIM BEHAV, V49, P739
   Darwin C., 1872, EXPRESS EMOT MAN, DOI DOI 10.1037/10001-000
   Ehret Guenter, 2006, P85
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   Elfenbein HA, 2002, PSYCHOL BULL, V128, P203, DOI 10.1037//0033-2909.128.2.203
   Emmons L., 2000, Tupai: A Field Study of Bornean Treeshrews, VVolume 2
   Fichtel C, 2002, ETHOLOGY, V108, P763, DOI 10.1046/j.1439-0310.2002.00816.x
   FISCHER J, 1995, ETHOLOGY, V101, P51, DOI 10.1111/j.1439-0310.1995.tb00345.x
   FITCH WT, 1995, AM J PRIMATOL, V37, P191, DOI 10.1002/ajp.1350370303
   Fitch WT, 2003, SPR HDB AUD, V16, P65
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Gould E, 1997, J NEUROSCI, V17, P2492
   HAUSER MD, 1993, BEHAV ECOL, V4, P194, DOI 10.1093/beheco/4.3.194
   Janecka JE, 2007, SCIENCE, V318, P792, DOI 10.1126/science.1147555
   Johnstone T, 2000, PSYCHOPHYSIOLOGY, V37, pS52
   Juslin PN, 2001, EMOTION, V1, P381, DOI 10.1037//1528-3542.1.4.381
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Konerding WS, 2011, ANIM COGN, V14, P787, DOI 10.1007/s10071-011-0411-8
   Kriegs JO, 2007, TRENDS GENET, V23, P158, DOI 10.1016/j.tig.2007.02.002
   Lewis PA, 2007, CEREB CORTEX, V17, P742, DOI 10.1093/cercor/bhk024
   Manser MB, 2001, P ROY SOC B-BIOL SCI, V268, P2485, DOI 10.1098/rspb.2001.1772
   Manser MB, 2001, P ROY SOC B-BIOL SCI, V268, P2315, DOI 10.1098/rspb.2001.1773
   Michael-Titus AT, 2008, EUR J PHARMACOL, V598, P43, DOI 10.1016/j.ejphar.2008.09.006
   Monticelli PE, 2004, AN ACAD BRAS CIENC, V76, P368, DOI 10.1590/S0001-37652004000200027
   MORTON ES, 1977, AM NAT, V111, P855, DOI 10.1086/283219
   Mundry R, 1998, ANIM BEHAV, V56, P256, DOI 10.1006/anbe.1998.0756
   MURRAY IR, 1993, J ACOUST SOC AM, V93, P1097, DOI 10.1121/1.405558
   Owings D. H., 1998, Animal vocal communication: A new approach
   Owren MJ, 1997, PERSP ETHOL, V12, P299
   Rendall D, 2003, J ACOUST SOC AM, V113, P3390, DOI 10.1121/1.1568942
   Sauter DA, 2010, P NATL ACAD SCI USA, V107, P2408, DOI 10.1073/pnas.0908239106
   Schehka S, 2007, J COMP PHYSIOL A, V193, P845, DOI 10.1007/s00359-007-0236-8
   Schehka S, 2009, BEHAV BRAIN RES, V203, P223, DOI 10.1016/j.bbr.2009.05.007
   SCHERER KR, 1991, MOTIV EMOTION, V15, P123, DOI 10.1007/BF00995674
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   Slocombe KE, 2007, P NATL ACAD SCI USA, V104, P17228, DOI 10.1073/pnas.0706741104
   Slocombe KE, 2009, ANIM COGN, V12, P441, DOI 10.1007/s10071-008-0204-x
   Spelke ES., 1985, MEASUREMENT AUDITION, P85
   Uher J, 2011, DEV PSYCHOBIOL, V53, P521, DOI 10.1002/dev.20544
   von Holst D, 1998, ADV STUD BEHAV, V27, P1
   Weary DM, 1996, ANIM BEHAV, V52, P1247, DOI 10.1006/anbe.1996.0272
   WEARY DM, 1995, ANIM BEHAV, V50, P1047, DOI 10.1016/0003-3472(95)80105-7
   Zambello E, 2010, PROG NEURO-PSYCHOPH, V34, P122, DOI 10.1016/j.pnpbp.2009.10.011
   Zimmermann E., 2011, EVOLUTION EMOT UNPUB
   Zimmermann E, 2009, HDB MAMMALIAN VOCALI, P215
NR 54
TC 10
Z9 10
U1 0
U2 18
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 1528-3542
EI 1931-1516
J9 EMOTION
JI Emotion
PD JUN
PY 2012
VL 12
IS 3
BP 632
EP 639
DI 10.1037/a0026893
PG 8
WC Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA 948OO
UT WOS:000304512700021
PM 22309729
DA 2024-01-09
ER

PT J
AU Bodner, E
   Aharoni, R
   Iancu, I
AF Bodner, Ehud
   Aharoni, Ronit
   Iancu, Iulian
TI The Effect of Training with Music on Happiness Recognition in Social
   Anxiety Disorder
SO JOURNAL OF PSYCHOPATHOLOGY AND BEHAVIORAL ASSESSMENT
LA English
DT Article
DE Social anxiety; Emotion; Voice; Music improvisation; Vocal expression
ID SELF-REPORT VERSION; PSYCHOMETRIC PROPERTIES; EMOTIONS; COMMUNICATION;
   PERCEPTION; EXPRESSION; PHOBIA; BIAS
AB The process of emotion recognition is thought to be negatively biased in social anxiety disorder (SAD). Ways to change this bias are needed. Forty one individuals afflicted with moderate SAD and 39 healthy controls were recruited to participate in this study. All subjects performed a vocal improvisation recognition task and half of them underwent training in happiness recognition in musical improvisations. The four groups (trained SAD, untrained SAD, trained controls and untrained controls) were then compared in terms of the extent of precise identification of one of five basic emotions (happiness, fear, anger, sadness and surprise) in spoken language. Subjects with SAD demonstrated less accurate identification of happiness in spoken language as compared to the healthy controls. However, subjects with SAD trained to recognize happiness demonstrated an improved ability to identify happiness in spoken language (in a female's voice), similarly to that of the healthy controls. Our findings demonstrate that a brief training in happiness recognition improves the ability of individuals with SAD to recognize happiness in spoken language. Additional studies are needed to support and refine our intervention and to examine its impact on individuals with SAD over longer periods of time.
C1 [Iancu, Iulian] Yavne Mental Hlth Clin, IL-81000 Yavne, Israel.
   [Bodner, Ehud; Aharoni, Ronit] Bar Ilan Univ, Dept Mus, IL-52900 Ramat Gan, Israel.
   [Bodner, Ehud] Bar Ilan Univ, Interdisciplinary Dept Social Sci, IL-52900 Ramat Gan, Israel.
   [Iancu, Iulian] Beer Yaakov Hosp, Yavne Mental Hlth Ctr, Beer Yaagov, Israel.
   [Iancu, Iulian] Tel Aviv Univ, Sackler Sch Med, IL-69978 Tel Aviv, Israel.
C3 Bar Ilan University; Bar Ilan University; Tel Aviv University; Sackler
   Faculty of Medicine
RP Iancu, I (corresponding author), Yavne Mental Hlth Clin, 4 Dekel St, IL-81000 Yavne, Israel.
EM iulian1@bezeqint.net
CR Alden LE, 2004, CLIN PSYCHOL REV, V24, P857, DOI 10.1016/j.cpr.2004.07.006
   Amin N, 1998, BEHAV RES THER, V36, P945, DOI 10.1016/S0005-7967(98)00060-6
   [Anonymous], MUSIC EMOTION THEORY
   Baker F., 2007, MICROANALYSIS MUSIC, P107
   Balkwill LL, 2004, JPN PSYCHOL RES, V46, P337, DOI 10.1111/j.1468-5584.2004.00265.x
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   BECK AT, 1961, ARCH GEN PSYCHIAT, V4, P561, DOI 10.1001/archpsyc.1961.01710120031004
   Berger Y., 2002, THESIS LIAN U RAMAT
   Bodner E., 2006, NORD J MUSIC THER, V15, P3, DOI [10.1080/08098130609478147, DOI 10.1080/08098130609478147]
   Bunt L., 2001, MUSIC EMOTION THEORY, P181
   Clark D. M., 2002, SOCIAL PHOBIA DIAGNO, P69
   Coles ME, 1998, BEHAV COGN PSYCHOTH, V26, P3
   Dingemans AE, 2001, J AFFECT DISORDERS, V65, P123, DOI 10.1016/S0165-0327(00)00238-X
   FOA EB, 1986, PSYCHOL BULL, V99, P20, DOI 10.1037/0033-2909.99.1.20
   Gfeller K. E., 2002, MUSIC THERAPY TREATM, P68
   Gilboa A, 2006, J MUSIC THER, V43, P198, DOI 10.1093/jmt/43.3.198
   Hanser S., 2010, HDB MUSIC EMOTION TH, P49
   Heimberg RG, 1999, PSYCHOL MED, V29, P199, DOI 10.1017/S0033291798007879
   Heinrichs N, 2001, CLIN PSYCHOL REV, V21, P751, DOI 10.1016/S0272-7358(00)00067-2
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kashdan TB, 2011, CLIN PSYCHOL REV, V31, P786, DOI 10.1016/j.cpr.2011.03.012
   Landau G, 2004, HEALTH SOC WORK, V29, P116, DOI 10.1093/hsw/29.2.116
   Levin JB, 2002, DEPRESS ANXIETY, V16, P143, DOI 10.1002/da.10064
   Li SW, 2008, BEHAV RES THER, V46, P905, DOI 10.1016/j.brat.2008.04.005
   Liang CW, 2011, J BEHAV THER EXP PSY, V42, P204, DOI 10.1016/j.jbtep.2010.12.002
   Liebowitz M R, 1987, Mod Probl Pharmacopsychiatry, V22, P141
   Mogg K, 2004, J ABNORM PSYCHOL, V113, P160, DOI 10.1037/0021-843X.113.1.160
   Murphy R, 2007, BEHAV RES THER, V45, P1517, DOI 10.1016/j.brat.2007.01.007
   Naranjo C, 2011, J AFFECT DISORDERS, V128, P243, DOI 10.1016/j.jad.2010.06.039
   Patel AD, 2003, NAT NEUROSCI, V6, P674, DOI 10.1038/nn1082
   Pavlicevic M, 2000, J MUSIC THER, V37, P269, DOI 10.1093/jmt/37.4.269
   Quadflieg S, 2007, BEHAV RES THER, V45, P3096, DOI 10.1016/j.brat.2007.08.003
   Rudd E, 1998, MUSIC THERAPY IMPROV
   Rytwinski NK, 2009, DEPRESS ANXIETY, V26, P34, DOI 10.1002/da.20503
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Stein MB, 2008, LANCET, V371, P1115, DOI 10.1016/S0140-6736(08)60488-2
   Taylor CT, 2010, J ANXIETY DISORD, V24, P403, DOI 10.1016/j.janxdis.2010.02.004
   Thaut M., 1999, INTRO MUSIC THERAPY, P330
   Tracy JL, 2008, EMOTION, V8, P81, DOI 10.1037/1528-3542.8.1.81
   Varcin KJ, 2010, J INT NEUROPSYCH SOC, V16, P621, DOI 10.1017/S1355617710000329
   Vassilopoulos SP, 2010, BEHAV COGN PSYCHOTH, V38, P597, DOI 10.1017/S1352465810000433
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 44
TC 7
Z9 7
U1 1
U2 24
PU SPRINGER/PLENUM PUBLISHERS
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0882-2689
EI 1573-3505
J9 J PSYCHOPATHOL BEHAV
JI J. Psychopathol. Behav. Assess.
PD DEC
PY 2012
VL 34
IS 4
BP 458
EP 466
DI 10.1007/s10862-012-9304-7
PG 9
WC Psychology, Clinical
WE Social Science Citation Index (SSCI)
SC Psychology
GA 035OU
UT WOS:000310957600004
DA 2024-01-09
ER

PT J
AU Escoffier, N
   Zhong, JD
   Schirmer, A
   Qiu, AQ
AF Escoffier, Nicolas
   Zhong, Jidan
   Schirmer, Annett
   Qiu, Anqi
TI Emotional expressions in voice and music: Same code, same effect?
SO HUMAN BRAIN MAPPING
LA English
DT Article
DE prosody; theory of mind; ACC; MPFC; fMRI
ID TEMPORAL-LOBE EXCISION; HUMAN CEREBRAL-CORTEX; HUMAN AUDITORY-CORTEX;
   IMPAIRED RECOGNITION; FACIAL EXPRESSIONS; MEANINGLESS SPEECH; VOCAL
   EXPRESSIONS; HUMAN BRAIN; ACTIVATION; RESPONSES
AB Scholars have documented similarities in the way voice and music convey emotions. By using functional magnetic resonance imaging (fMRI) we explored whether these similarities imply overlapping processing substrates. We asked participants to trace changes in either the emotion or pitch of vocalizations and music using a joystick. Compared to music, vocalizations more strongly activated superior and middle temporal cortex, cuneus, and precuneus. However, despite these differences, overlapping rather than differing regions emerged when comparing emotion with pitch tracing for music and vocalizations, respectively. Relative to pitch tracing, emotion tracing activated medial superior frontal and anterior cingulate cortex regardless of stimulus type. Additionally, we observed emotion specific effects in primary and secondary auditory cortex as well as in medial frontal cortex that were comparable for voice and music. Together these results indicate that similar mechanisms support emotional inferences from vocalizations and music and that these mechanisms tap on a general system involved in social cognition. Hum Brain Mapp, 2013. (c) 2012 Wiley Periodicals, Inc.
C1 [Escoffier, Nicolas; Schirmer, Annett] Natl Univ Singapore, Dept Psychol, Singapore 117576, Singapore.
   [Zhong, Jidan] Natl Univ Singapore, NUS Grad Sch Integrat Sci & Engn, Singapore 117576, Singapore.
   [Schirmer, Annett] Duke NUS Grad Med Sch, Singapore, Singapore.
   [Qiu, Anqi] Natl Univ Singapore, Dept Bioengn, Singapore 117576, Singapore.
   [Qiu, Anqi] Natl Univ Singapore, Clin Imaging Res Ctr, Singapore 117576, Singapore.
   [Qiu, Anqi] Agcy Sci Technol & Res, Singapore Inst Clin Sci, Singapore, Singapore.
C3 National University of Singapore; National University of Singapore;
   National University of Singapore; National University of Singapore;
   National University of Singapore; Agency for Science Technology &
   Research (A*STAR); A*STAR - Singapore Institute for Clinical Sciences
   (SICS)
RP Qiu, AQ (corresponding author), Natl Univ Singapore, Dept Bioengn, 9 Engn Dr 1,Block EA 03-12, Singapore 117576, Singapore.
EM bieqa@nus.edu.sg
RI Schirmer, Annett/A-5257-2012; Qiu, Anqi/H-2267-2011
OI Qiu, Anqi/0000-0002-0215-6338; Schirmer, Annett/0000-0003-1474-2788;
   Escoffier, Nicolas/0000-0002-3734-0303
FU NUS [R-581-000-066-101]; A*STAR SERC [0921570130, 082-101-0025]; A*STAR
   [SICS-09/1/1/001]; National University of Singapore [NUSYIA FY10 P07];
   National University of Singapore MOE AcRF
FX The authors thank Pierce Hale and Amerie Baeg for their help with
   stimulus selection, editing, and rating. This research was supported by
   the NUS young investigator award R-581-000-066-101 (AS), A*STAR SERC
   0921570130 (AS), A*STAR SERC 082-101-0025 (AQ), A*STAR SICS-09/1/1/001
   (AQ), the Young Investigator Award at National University of Singapore
   (NUSYIA FY10 P07) (AQ), and National University of Singapore MOE AcRF
   Tier 1 (AQ).
CR Andrade A, 2001, HUM BRAIN MAPP, V12, P79, DOI 10.1002/1097-0193(200102)12:2<79::AID-HBM1005>3.0.CO;2-I
   Anticevic A, 2008, NEUROIMAGE, V41, P835, DOI 10.1016/j.neuroimage.2008.02.052
   Bach DR, 2008, NEUROIMAGE, V42, P919, DOI 10.1016/j.neuroimage.2008.05.034
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Belin P, 2002, COGNITIVE BRAIN RES, V13, P17, DOI 10.1016/S0926-6410(01)00084-2
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Binder JR, 2000, CEREB CORTEX, V10, P512, DOI 10.1093/cercor/10.5.512
   Brosch T, 2008, PSYCHOL SCI, V19, P362, DOI 10.1111/j.1467-9280.2008.02094.x
   Brosch T, 2009, J COGNITIVE NEUROSCI, V21, P1670, DOI 10.1162/jocn.2009.21110
   Carrington SJ, 2009, HUM BRAIN MAPP, V30, P2313, DOI 10.1002/hbm.20671
   Chua SM, 2011, COG EMOTION, V25, P1376
   Chung MK, 2005, NEUROIMAGE, V25, P1256, DOI 10.1016/j.neuroimage.2004.12.052
   CONFAVREUX C, 1992, ARCH NEUROL-CHICAGO, V49, P971, DOI 10.1001/archneur.1992.00530330095023
   Critchley H, 2000, HUM BRAIN MAPP, V9, P93, DOI 10.1002/(SICI)1097-0193(200002)9:2<93::AID-HBM4>3.0.CO;2-Z
   Curtis ME, 2010, EMOTION, V10, P335, DOI 10.1037/a0017928
   Dale AM, 1999, NEUROIMAGE, V9, P179, DOI 10.1006/nimg.1998.0395
   Deike S, 2004, NEUROREPORT, V15, P1511, DOI 10.1097/01.wnr.0000132919.12990.34
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021
   Ellis RJ, 2010, MUSIC PERCEPT, V27, P317, DOI 10.1525/MP.2010.27.4.317
   Ethofer T, 2006, NEUROREPORT, V17, P249, DOI 10.1097/01.wnr.0000199466.32036.5d
   Fecteau S, 2007, NEUROIMAGE, V36, P480, DOI 10.1016/j.neuroimage.2007.02.043
   Fischl B, 2004, CEREB CORTEX, V14, P11, DOI 10.1093/cercor/bhg087
   Fischl B, 2002, NEURON, V33, P341, DOI 10.1016/S0896-6273(02)00569-X
   FLETCHER PC, 1995, COGNITION, V57, P109, DOI 10.1016/0010-0277(95)00692-R
   Friston K.J., 1994, Hum Brain Mapp, V2, P189, DOI [10.1002/hbm.460020402, DOI 10.1002/HBM.460020402]
   Friston KJ, 1998, NEUROIMAGE, V7, P30, DOI 10.1006/nimg.1997.0306
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Gallagher HL, 2000, NEUROPSYCHOLOGIA, V38, P11, DOI 10.1016/S0028-3932(99)00053-6
   Gandour J, 2003, HUM BRAIN MAPP, V18, P149, DOI 10.1002/hbm.10088
   Gobbini MI, 2007, J COGNITIVE NEUROSCI, V19, P1803, DOI 10.1162/jocn.2007.19.11.1803
   Gosselin N, 2005, BRAIN, V128, P628, DOI 10.1093/brain/awh420
   Gosselin N, 2007, NEUROPSYCHOLOGIA, V45, P236, DOI 10.1016/j.neuropsychologia.2006.07.012
   Gosselin N, 2006, BRAIN, V129, P2585, DOI 10.1093/brain/awl240
   Gosselin N, 2011, CORTEX, V47, P1116, DOI 10.1016/j.cortex.2011.05.012
   Grandjean D, 2005, NAT NEUROSCI, V8, P145, DOI 10.1038/nn1392
   Green AC, 2008, NEUROREPORT, V19, P711, DOI 10.1097/WNR.0b013e3282fd0dd8
   Hariri AR, 2003, BIOL PSYCHIAT, V53, P494, DOI 10.1016/S0006-3223(02)01786-9
   Hariri AR, 2000, NEUROREPORT, V11, P43, DOI 10.1097/00001756-200001170-00009
   Holmes A. P., 1998, NEUROIMAGE, V7, pS754, DOI DOI 10.1016/S1053-8119(18)31587-8
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Imaizumi S, 1998, NEUROREPORT, V9, P899, DOI 10.1097/00001756-199803300-00025
   Janata P, 2005, ANN NY ACAD SCI, V1060, P111, DOI 10.1196/annals.1360.008
   Janata P, 2009, MUSIC THAT WORKS, P131, DOI 10.1007/978-3-211-75121-3_8
   Janata P, 2009, CEREB CORTEX, V19, P2579, DOI 10.1093/cercor/bhp008
   Jenkinson M, 2002, NEUROIMAGE, V17, P825, DOI 10.1006/nimg.2002.1132
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Kawase T, 2005, NEUROSCI LETT, V382, P254, DOI 10.1016/j.neulet.2005.03.050
   Khalfa S, 2005, NEUROREPORT, V16, P1981, DOI 10.1097/00001756-200512190-00002
   Leitman DI, 2010, FRONT HUM NEUROSCI, V26, P4
   Levitin DJ, 2009, ANN NY ACAD SCI, V1156, P211, DOI 10.1111/j.1749-6632.2009.04417.x
   Livingstone SR, 2009, MUSIC SCI, P83, DOI 10.1177/1029864909013002061
   LOFTUS GR, 1994, PSYCHON B REV, V1, P476, DOI 10.3758/BF03210951
   Micheyl C, 2007, HEARING RES, V229, P116, DOI 10.1016/j.heares.2007.01.007
   Mitterschiffthaler MT, 2007, HUM BRAIN MAPP, V28, P1150, DOI 10.1002/hbm.20337
   Nichols T, 2005, NEUROIMAGE, V25, P653, DOI 10.1016/j.neuroimage.2004.12.005
   Peelen MV, 2010, J NEUROSCI, V30, P10127, DOI 10.1523/JNEUROSCI.2161-10.2010
   Pell MD, 2008, SPEECH COMMUN, V50, P519, DOI 10.1016/j.specom.2008.03.006
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   Peretz I, 2005, ANNU REV PSYCHOL, V56, P89, DOI 10.1146/annurev.psych.56.091103.070225
   Phillips ML, 1998, P ROY SOC B-BIOL SCI, V265, P1809, DOI 10.1098/rspb.1998.0506
   Pittam Jeff, 1994, Voice in social interaction
   Plailly J, 2007, CEREB CORTEX, V17, P2650, DOI 10.1093/cercor/bhl173
   Qiu AQ, 2006, IEEE T MED IMAGING, V25, P1296, DOI 10.1109/TMI.2006.882143
   Qiu AQ, 2006, NEUROIMAGE, V31, P125, DOI 10.1016/j.neuroimage.2005.11.049
   Ratnanather JT, 2003, NEUROIMAGE, V20, P359, DOI 10.1016/S1053-8119(03)00238-6
   Rousseau JJ, 1992, ESSAY ORIGIN LANGUAG
   Sander D, 2005, NEUROIMAGE, V28, P848, DOI 10.1016/j.neuroimage.2005.06.023
   Saxe R, 2006, NEUROIMAGE, V30, P1088, DOI 10.1016/j.neuroimage.2005.12.062
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   Schirmer A, 2004, NEUROIMAGE, V21, P1114, DOI 10.1016/j.neuroimage.2003.10.048
   Schirmer A, 2008, NEUROIMAGE, V40, P1402, DOI 10.1016/j.neuroimage.2008.01.018
   Schirmer A, 2010, CLIN NEUROPHYSIOL, V121, P53, DOI 10.1016/j.clinph.2009.09.029
   Schönwiesner M, 2005, EUR J NEUROSCI, V22, P1521, DOI 10.1111/j.1460-9568.2005.04315.x
   SCHROEDER MR, 1968, J ACOUST SOC AM, V43, P829, DOI 10.1121/1.1910902
   Shtyrov Y, 2005, NEUROIMAGE, V27, P37, DOI 10.1016/j.neuroimage.2005.02.003
   SPENCER H, 1857, FRASERS MAGAZINE, V56, P396, DOI DOI 10.1017/S0140525X08005293
   Strait DL, 2009, EUR J NEUROSCI, V29, P661, DOI 10.1111/j.1460-9568.2009.06617.x
   Tervaniemi M, 2006, J NEUROSCI, V26, P8647, DOI 10.1523/JNEUROSCI.0995-06.2006
   von Kriegstein K, 2008, CURR BIOL, V18, P1855, DOI 10.1016/j.cub.2008.10.052
   Warren J, 2008, CLIN MED, V8, P32, DOI 10.7861/clinmedicine.8-1-32
   Wildgruber D, 2006, PROG BRAIN RES, V156, P249, DOI 10.1016/S0079-6123(06)56013-3
   Wildgruber D, 2002, NEUROIMAGE, V15, P856, DOI 10.1006/nimg.2001.0998
   Worsley KJ, 1996, HUM BRAIN MAPP, V4, P58, DOI 10.1002/(SICI)1097-0193(1996)4:1<58::AID-HBM4>3.0.CO;2-O
   Zaki J, 2009, P NATL ACAD SCI USA, V106, P11382, DOI 10.1073/pnas.0902666106
   Zatorre RJ, 2001, CEREB CORTEX, V11, P946, DOI 10.1093/cercor/11.10.946
   Zatorre RJ, 2002, TRENDS COGN SCI, V6, P37, DOI 10.1016/S1364-6613(00)01816-7
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
   Zhong JD, 2010, NEUROIMAGE, V52, P131, DOI 10.1016/j.neuroimage.2010.03.085
   Zhong JD, 2010, NEUROIMAGE, V49, P355, DOI 10.1016/j.neuroimage.2009.08.026
NR 92
TC 53
Z9 55
U1 1
U2 58
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1065-9471
J9 HUM BRAIN MAPP
JI Hum. Brain Mapp.
PD AUG
PY 2013
VL 34
IS 8
BP 1796
EP 1810
DI 10.1002/hbm.22029
PG 15
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA 178GX
UT WOS:000321435100005
PM 22505222
OA Green Published
DA 2024-01-09
ER

PT J
AU Hakanpää, T
   Waaramaa, T
   Laukkanen, AM
AF Hakanpaa, Tua
   Waaramaa, Teija
   Laukkanen, Anne-Maria
TI Emotion Recognition From Singing Voices Using Contemporary Commercial
   Music and Classical Styles
SO JOURNAL OF VOICE
LA English
DT Article
DE Voice quality; Emotion expression; Perception; Song genre; Singing style
ID VOCAL EXPRESSION; SPEECH; COMMUNICATION; THEATER
AB Objectives: This study examines the recognition of emotion in contemporary commercial music (CCM) and classical styles of singing. This information may be useful in improving the training of interpretation in singing.
   Study design: This is an experimental comparative study.
   Methods: Thirteen singers (11 female, 2 male) with a minimum of 3 years' professional-level singing studies (in CCM or classical technique or both) participated. They sang at three pitches (females: a, e1, a1, males: one octave lower) expressing anger, sadness, joy, tenderness, and a neutral state. Twenty-nine listeners listened to 312 short (0.63- to 4.8-second) voice samples, 135 of which were sung using a classical singing technique and 165 of which were sung in a CCM style. The listeners were asked which emotion they heard. Activity and valence were derived from the chosen emotions.
   Results: The percentage of correct recognitions out of all the answers in the listening test (N = 9048) was 30.2%. The recognition percentage for the CCM-style singing technique was higher (34.5%) than for the classical-style technique (24.5%). Valence and activation were better perceived than the emotions themselves, and activity was better recognized than valence. A higher pitch was more likely to be perceived as joy or anger, and a lower pitch as sorrow. Both valence and activation were better recognized in the female CCM samples than in the other samples.
   Conclusions: There are statistically significant differences in the recognition of emotions between classical and CCM styles of singing. Furthermore, in the singing voice, pitch affects the perception of emotions, and valence and activity are more easily recognized than emotions.
C1 [Hakanpaa, Tua; Waaramaa, Teija; Laukkanen, Anne-Maria] Univ Tampere, Fac Educ, Speech & Voice Res Lab, Tampere, Finland.
   [Waaramaa, Teija] Univ Tampere, Fac Commun Sci, Tampere, Finland.
C3 Tampere University; Tampere University
RP Hakanpää, T (corresponding author), Univ Tampere, Fac Educ, Speech & Voice Res Lab, Vanhan Mankkaan Tie 16 E 14, Espoo 02180, Finland.
EM Hakanpaa.tua.s@student.uta.fi
RI Laukkanen, Anne-Maria/GRS-5359-2022; Hakanpaa, Tua/AAH-5041-2021;
   Hakanpää, Tua/GZM-1298-2022
OI Laukkanen, Anne-Maria/0000-0003-4836-2513; Hakanpää,
   Tua/0000-0001-8573-5855
FU Eemil Aaltonen Foundation [160036 N1]; Oskar Oflunds Stiftelse
   Foundation
FX This research was supported by the Eemil Aaltonen Foundation through a
   grant (160036 N1) and by the Oskar Oflunds Stiftelse Foundation through
   a grant to Tua Hakanpaa. The authors would like to thank Antti Poteri,
   D.Sc. (Tech), for help with the statistical analysis.
CR Airas M, 2006, PHONETICA, V63, P26, DOI 10.1159/000091405
   [Anonymous], 1980, The Phonetic Description of Voice Quality
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Barlow C, 2010, J VOICE, V24, P314, DOI 10.1016/j.jvoice.2008.10.003
   Björkner E, 2008, J VOICE, V22, P533, DOI 10.1016/j.jvoice.2006.12.007
   Boersma P, 2014, PRAAT
   Borch D Zangger, 2004, Logoped Phoniatr Vocol, V29, P147
   Chua G, P 2015 INT C AS LANG, DOI 10.1109/IALP.2015.7451541.
   EKMAN P, 1992, PSYCHOL REV, V99, P550, DOI 10.1037/0033-295X.99.3.550
   Eyben F, 2015, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-015-0057-6
   Hallqvist H, 2017, J VOICE, V31, P229, DOI 10.1016/j.jvoice.2016.05.020
   Iida A, 2003, SPEECH COMMUN, V40, P161, DOI 10.1016/S0167-6393(02)00081-X
   IZARD CE, 1992, PSYCHOL REV, V99, P561, DOI 10.1037/0033-295X.99.3.561
   Jansens S., 1997, P 5 EUR C SPEECH COM, P2155
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Laukkanen A. M., 1997, LOGOP PHONIATR VOCO, V22, P157, DOI DOI 10.3109/14015439709075330
   Manfredi C, 2015, J VOICE, V29, DOI 10.1016/j.jvoice.2014.09.014
   Mazo M, 1995, VOCAL FOLD, P173
   PETERSON KL, 1994, ANN OTO RHINOL LARYN, V103, P335, DOI 10.1177/000348949410300501
   Richard M, 1996, STRUCTURE SINGING SY
   Scherer KR, 2015, COMPUT SPEECH LANG, V29, P218, DOI 10.1016/j.csl.2013.10.002
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   Schloneger MJ, 2017, J VOICE, V31, DOI 10.1016/j.jvoice.2015.12.018
   SIEGWART H, 1995, J VOICE, V9, P249, DOI 10.1016/S0892-1997(05)80232-2
   Story BH, 1998, J ACOUST SOC AM, V104, P471, DOI 10.1121/1.423298
   Sundberg J, 2000, PHONETICA, V57, P95, DOI 10.1159/000028465
   Sundberg J, 2013, J VOICE, V27, P278, DOI 10.1016/j.jvoice.2012.12.002
   SUNDBERG Johan, 1987, The science of singing voice
   Sundberg Johan, 1998, LOGOP PHONIATR VOCO, V23, P121, DOI DOI 10.1080/140154398434130
   TARTTER VC, 1980, PERCEPT PSYCHOPHYS, V27, P24, DOI 10.3758/BF03199901
   Titze I., 1994, Principles of Voice Production
   Waaramaa T, 2008, FOLIA PHONIATR LOGO, V60, P249, DOI 10.1159/000151762
   WILLIAMS CE, 1972, J ACOUST SOC AM, V52, P1238, DOI 10.1121/1.1913238
NR 36
TC 10
Z9 10
U1 1
U2 15
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0892-1997
EI 1873-4588
J9 J VOICE
JI J. Voice
PD JUL
PY 2019
VL 33
IS 4
BP 501
EP 509
DI 10.1016/j.jvoice.2018.01.012
PG 9
WC Audiology & Speech-Language Pathology; Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Audiology & Speech-Language Pathology; Otorhinolaryngology
GA IK3LE
UT WOS:000476489700015
PM 29478708
OA Green Accepted
DA 2024-01-09
ER

PT J
AU Mualem, O
   Lavidor, M
AF Mualem, Orit
   Lavidor, Michal
TI Music education intervention improves vocal emotion recognition
SO INTERNATIONAL JOURNAL OF MUSIC EDUCATION
LA English
DT Article
DE Emotion; intervention; language; music; prosody; visual art
ID EXPRESSION; LANGUAGE; SPEECH; PROSODY; ABILITY; STRESS; SYNTAX; SKILLS
AB The current study is an interdisciplinary examination of the interplay among music, language, and emotions. It consisted of two experiments designed to investigate the relationship between musical abilities and vocal emotional recognition. In experiment 1 (N = 24), we compared the influence of two short-term intervention programs - music and art - on vocal emotion recognition. In experiment 2 (N = 47), we compared musicians, who had undergone long-term music training, to non-musicians regarding their vocal emotion recognition. The results from experiment 1 revealed that short-term music intervention, which focused on ways music conveys emotions, significantly improved the vocal emotion recognition of the participants., In experiment 2, which examined the long-term effects of music training, there were no significant differences between musicians and non-musicians in vocal emotion recognition. The uniqueness of the short-term intervention and the inconsistency between the two experiments' findings are discussed, and possible directions for future studies are proposed.
C1 [Mualem, Orit] Levinsky Coll Educ, Tel Aviv, Israel.
   [Lavidor, Michal] Univ Hull, Kingston Upon Hull HU6 7RX, N Humberside, England.
   [Lavidor, Michal] Bar Ilan Univ, Ramat Gan, Israel.
C3 University of Hull; Bar Ilan University
RP Mualem, O (corresponding author), Levinsky Coll Educ, Dept Early Childhood Educ, 15 Shoshana Persitz St, Tel Aviv, Israel.
EM orit.mualem@gmail.com
CR [Anonymous], 2012, Fundamental Frequency in Sentence Production
   [Anonymous], 1982, U SHAPED BEHAV GROWT
   [Anonymous], 1993, Educational Psychology
   Anvari SH, 2002, J EXP CHILD PSYCHOL, V83, P111, DOI 10.1016/S0022-0965(02)00124-8
   BARWICK J, 1989, BRIT J EDUC PSYCHOL, V59, P253, DOI 10.1111/j.2044-8279.1989.tb03097.x
   Chan AS, 1998, NATURE, V396, P128, DOI 10.1038/24075
   COOPER WE, 1985, J ACOUST SOC AM, V77, P2142, DOI 10.1121/1.392372
   Dankovicová J, 2007, LANG SPEECH, V50, P177, DOI 10.1177/00238309070500020201
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   Forgeard M, 2008, MUSIC PERCEPT, V25, P383, DOI 10.1525/MP.2008.25.4.383
   Foxton JM, 2003, NAT NEUROSCI, V6, P343, DOI 10.1038/nn1035
   Globerson E., 2010, SPEECH PROS C CHIC I
   Gordon E., 1989, Advanced measures of music audiation
   Hetland L., 2002, J AESTHET EDUC, V34, P179
   Husain G, 2002, MUSIC PERCEPT, V20, P151, DOI 10.1525/mp.2002.20.2.151
   Johnstone T., 2000, Handbook of Emotions, V2nd ed., P220
   Juslin P. N., 2011, HDB MUSIC EMOTION TH
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Koelsch S, 2005, TRENDS COGN SCI, V9, P578, DOI 10.1016/j.tics.2005.10.001
   Koelsch S, 2002, NEUROIMAGE, V17, P956, DOI 10.1016/S1053-8119(02)91154-7
   Kolinsky R, 2009, MUSIC PERCEPT, V26, P235, DOI 10.1525/MP.2009.26.3.235
   Maess B, 2001, NAT NEUROSCI, V4, P540, DOI 10.1038/87502
   McCann J, 2003, INT J LANG COMM DIS, V38, P325, DOI 10.1080/1368282031000154204
   McMullen E, 2004, MUSIC PERCEPT, V21, P289, DOI 10.1525/mp.2004.21.3.289
   MURPHY D, 1990, J NEUROL NEUROSUR PS, V53, P727, DOI 10.1136/jnnp.53.9.727
   NILSONNE A, 1985, MUSIC PERCEPT, V2, P507
   Overy K, 2003, ANN NY ACAD SCI, V999, P497, DOI 10.1196/annals.1284.060
   Patel AD, 2003, NAT NEUROSCI, V6, P674, DOI 10.1038/nn1082
   Patel AD, 2005, BRAIN COGNITION, V59, P310, DOI 10.1016/j.bandc.2004.10.003
   Schellenberg EG, 2005, CURR DIR PSYCHOL SCI, V14, P317, DOI 10.1111/j.0963-7214.2005.00389.x
   Schellenberg EG, 2001, ANN NY ACAD SCI, V930, P355, DOI 10.1111/j.1749-6632.2001.tb05744.x
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   Schön D, 2004, PSYCHOPHYSIOLOGY, V41, P341, DOI 10.1111/1469-8986.00172.x
   Schön D, 2008, COGNITION, V106, P975, DOI 10.1016/j.cognition.2007.03.005
   Tervaniemi M, 2000, HUM BRAIN MAPP, V10, P74, DOI 10.1002/(SICI)1097-0193(200006)10:2<74::AID-HBM30>3.3.CO;2-U
   Thompson W., 2009, Music, thought, and feeling: Understanding the psychology of music
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Trimmer CG, 2008, EMOTION, V8, P838, DOI 10.1037/a0014080
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   Zatorre RJ, 2002, TRENDS COGN SCI, V6, P37, DOI 10.1016/S1364-6613(00)01816-7
NR 41
TC 13
Z9 15
U1 2
U2 41
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0255-7614
EI 1744-795X
J9 INT J MUSIC EDUC
JI Int. J. Music Educ.
PD NOV
PY 2015
VL 33
IS 4
BP 413
EP 425
DI 10.1177/0255761415584292
PG 13
WC Education & Educational Research; Music
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Education & Educational Research; Music
GA CW5KG
UT WOS:000365033700003
DA 2024-01-09
ER

PT J
AU Guzman, MA
   Dowdall, J
   Rubin, AD
   Maki, A
   Levin, S
   Mayerhoff, R
   Jackson-Menaldi, MC
AF Guzman, Marco A.
   Dowdall, Jayme
   Rubin, Adam D.
   Maki, Ahmed
   Levin, Samuel
   Mayerhoff, Ross
   Jackson-Menaldi, Maria Cristina
TI Influence of Emotional Expression, Loudness, and Gender on the Acoustic
   Parameters of Vibrato in Classical Singers
SO JOURNAL OF VOICE
LA English
DT Article
DE Vibrato; Emotion; Singing voice; Acoustical analysis
ID CRESCENDO
AB Objectives. Vibrato is considered one of the most essential characteristics of the classical singing voice. Vibrato can be acoustically described by the rate, extent, onset, and regularity. The aim of this study was to determine the influence of emotional expression on acoustic parameters of vibrato in classically trained singers.
   Study Design. A prospective cohort study was performed.
   Methods. Thirty healthy classical singers were recruited for this study, 29 singers met inclusion criteria. Inclusion criteria for this study were as follow: 1) no history of vocal pathology in the past year, 2) to have at least 5 years of classical singing training. Each subject was asked to sing the phrase "I Love You," while expressing four different emotions ( tenderness, anger, happiness, and sadness) and without emotion ( neutral state). The musical tonality of the phrase was adapted to each singer's vocal classification. Subjects were also recorded at three levels of loudness ( pianissimo, mezzo forte, and fortissimo), while expressing each emotion. Acoustical analysis was performed during the vowel /o/ of the word "Love" to determine rate of vibrato, the extent of vibrato, and vibrato jitter.
   Results. Vibrato parameters did not vary significantly when different emotions were expressed. However, vibrato jitter and extent did vary significantly between different levels of loudness. Significant differences were also noted in both rate and extent of vibrato when compared between sexes.
   Conclusions. Expression of emotions does not affect the acoustic parameters of vibrato, although some parameters are affected by loudness and gender.
C1 [Guzman, Marco A.] Univ Chile, Fac Med, Sch Commun Sci, Ave Independencia 1027, Santiago 7, Chile.
   [Guzman, Marco A.; Rubin, Adam D.; Jackson-Menaldi, Maria Cristina] Lakeshore Ear Nose & Throat Ctr, Lakeshore Profess Voice Ctr, St Clair Shores, MI USA.
   [Dowdall, Jayme; Mayerhoff, Ross; Jackson-Menaldi, Maria Cristina] Wayne State Univ, Sch Med, Dept Otolaryngol, Detroit, MI 48201 USA.
   [Rubin, Adam D.] Univ Michigan, Med Ctr, Dept Otolaryngol HNS, Ann Arbor, MI USA.
   [Maki, Ahmed] Michigan State Univ, POH Reg Med Ctr, E Lansing, MI 48824 USA.
   [Levin, Samuel] Wayne State Univ, Sch Med, Detroit, MI USA.
C3 Universidad de Chile; Wayne State University; University of Michigan
   System; University of Michigan; Michigan State University; Wayne State
   University
RP Guzman, MA (corresponding author), Univ Chile, Fac Med, Sch Commun Sci, Ave Independencia 1027, Santiago 7, Chile.
EM guzmanvoz@gmail.com
OI Guzman, Marco/0000-0003-2088-4870; Mayerhoff, Ross/0000-0002-3262-4737
CR [Anonymous], 1986, The structure of singing
   Arroabarren I, 2001, P IEEE INSTR MEAS TE
   BJORKLUND A, 1961, J ACOUST SOC AM, V33, P575, DOI 10.1121/1.1908728
   Bretos J, 2003, J VOICE, V17, P343, DOI 10.1067/S0892-1997(03)00006-7
   Cecconello C, 2010, REV ARETE, V10, P17
   Cecconello L, 2009, 19 ENT WORLD C IFOS
   Chapman JL, 2006, SINGING TEACHING SIN
   Diaz JA, 2003, J VOICE, V17, P179, DOI 10.1016/S0892-1997(03)00002-X
   Foulds-Elliott S D, 2000, Logoped Phoniatr Vocol, V25, P151, DOI 10.1080/140154300750067539
   Gabrielsson A, 1993, STOCKH MUS AC C STOC
   Grant KW, 1996, J SPEECH HEAR RES, V39, P228, DOI 10.1044/jshr.3902.228
   HORII Y, 1989, Journal of Voice, V3, P36, DOI 10.1016/S0892-1997(89)80120-1
   Howes P, 2004, J VOICE, V18, P216, DOI 10.1016/j.jvoice.2003.09.003
   Jacob L, 1968, THESIS
   Johnstone T, 1995, P 13 INT C PHON SCI, V1
   Johnstone T, 2003, HDB EMOTIONS
   KOTLYAR GM, 1976, SOV PHYS ACOUST+, V22, P208
   MICHEL JF, 1991, J VOICE, V5, P292, DOI 10.1016/S0892-1997(05)80058-X
   Miller D, 2008, VOCE VISTA MANUAL V
   MURRAY IR, 1993, J ACOUST SOC AM, V93, P1097, DOI 10.1121/1.405558
   ORLIKOFF RF, 1991, J VOICE, V5, P113, DOI 10.1016/S0892-1997(05)80175-4
   Pettersen V, 2009, J VOICE, V23, P295, DOI 10.1016/j.jvoice.2007.08.006
   Pittarn J., 1993, HDB EMOTIONS, P185
   Prame E, 1997, J ACOUST SOC AM, V102, P616, DOI 10.1121/1.419735
   Protopapas A, 1997, J ACOUST SOC AM, V101, P2267, DOI 10.1121/1.418247
   ROBISON CW, 1994, NATS J, V51, P19
   Scherer K., 1977, MOTIV EMOTION, V1, P331, DOI [DOI 10.1007/BF00992539, 10.1007/bf00992539]
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   Seashore C.E., 1967, PSYCHOL MUSIC
   Seashore CE, 1932, VIBRATO U IOWA STUDI, V1
   Shipp T, 1980, J RES SING, V4, P18
   SIEGWART H, 1995, J VOICE, V9, P249, DOI 10.1016/S0892-1997(05)80232-2
   Sundberg J, 1995, VIBRATO, P35
   Sundberg J., 1994, STL QPSR, V35, P45
   Sundberg J, 2000, CAMBRIDGE COMPANION
   SUNDBERG Johan, 1987, The science of singing voice
   TARTTER VC, 1994, J ACOUST SOC AM, V96, P2101, DOI 10.1121/1.410151
   Tischer B, 1994, VOCAL COMMUNICATION
   Vennard W, 1967, MECH TECHNIC
   Wilson D, 2006, J PRAGMATICS, V38, P1559, DOI 10.1016/j.pragma.2005.04.012
   Winckel F, 1953, FOLIA PHONIATR, V5, P232, DOI 10.1159/000262652
NR 43
TC 7
Z9 10
U1 0
U2 9
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0892-1997
EI 1873-4588
J9 J VOICE
JI J. Voice
PD SEP
PY 2012
VL 26
IS 5
AR 675.e5
DI 10.1016/j.jvoice.2012.02.006
PG 7
WC Audiology & Speech-Language Pathology; Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Audiology & Speech-Language Pathology; Otorhinolaryngology
GA 004HO
UT WOS:000308672400057
PM 22727122
DA 2024-01-09
ER

PT J
AU Paquette, S
   Peretz, I
   Belin, P
AF Paquette, Sebastien
   Peretz, Isabelle
   Belin, Pascal
TI The "Musical Emotional Bursts": a validated set of musical affect bursts
   to investigate auditory affective processing
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE music; emotion; auditory stimuli; voices
ID IMPAIRED RECOGNITION; FACIAL EXPRESSIONS; CONGENITAL AMUSIA; PROSODY;
   SPEECH; PERCEPTION; RESPONSES; EXPERTISE; JAPANESE; MEMORY
AB The Musical Emotional Bursts (MEB) consist of 80 brief musical executions expressing basic emotional states (happiness, sadness and fear) and neutrality. These musical bursts were designed to be the musical analog of the Montreal Affective Voices (MAV) a set of brief non-verbal affective vocalizations portraying different basic emotions. The MEB consist of short (mean duration: 1.6s) improvisations on a given emotion or of imitations of a given MAV stimulus, played on a violin (10 stimuli x 4 [3 emotions + neutral]), or a clarinet (10 stimuli x 4 [3 emotions + neutral]). The MEB arguably represent a primitive form of music emotional expression, just like the MAV represent a primitive form of vocal, non-linguistic emotional expression. To create the MEB, stimuli were recorded from 10 violinists and 10 clarinetists, and then evaluated by 60 participants. Participants evaluated 240 stimuli [30 stimuli x 4 (3 emotions + neutral) x 2 instruments] by performing either a forced-choice emotion categorization task, a valence rating task or an arousal rating task (20 subjects per task); 40 MAVs were also used in the same session with similar task instructions. Recognition accuracy of emotional categories expressed by the MEB (n:80) was lower than for the MAVs but still very high with an average percent correct recognition score of 80.4%. Highest recognition accuracies were obtained for happy clarinet (92.0%) and fearful or sad violin (88.0% each) MEB stimuli. The MEB can be used to compare the cerebral processing of emotional expressions in music and vocal communication, or used for testing affective perception in patients with communication problems.
C1 [Paquette, Sebastien; Peretz, Isabelle; Belin, Pascal] Univ Montreal, Dept Psychol, Int Lab Brain Mus & Sound Res, Ctr Res Brain Language & Mus, Montreal, PQ H3C 3J7, Canada.
   [Belin, Pascal] Univ Glasgow, Inst Neurosci & Psychol, Voice Neurocognit Lab, Glasgow, Lanark, Scotland.
   [Belin, Pascal] Aix Marseille Univ, Inst Neurosci La Timone, Marseille, France.
C3 Universite de Montreal; University of Glasgow; Aix-Marseille Universite;
   Assistance Publique-Hopitaux de Marseille
RP Paquette, S (corresponding author), Int Lab Brain Mus & Sound Res, Pavillon 1430 Blvd Mt Royal, Montreal, PQ H2V 4P3, Canada.
EM sebastien.paquette.1@umontreal.ca; isabelle.peretz@umontreal.ca
RI Belin, Pascal/C-6247-2009
OI Belin, Pascal/0000-0002-7578-6365
CR ADOLPHS R, 1994, NATURE, V372, P669, DOI 10.1038/372669a0
   Aubé W, 2013, MEMORY, V21, P981, DOI 10.1080/09658211.2013.770871
   Balkwill LL, 2004, JPN PSYCHOL RES, V46, P337, DOI 10.1111/j.1468-5584.2004.00265.x
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Behrens Gene Ann, 1993, Psychology of Music, V21, P20, DOI DOI 10.1177/030573569302100102
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Bestelmeyer PEG, 2010, COGNITION, V117, P217, DOI 10.1016/j.cognition.2010.08.008
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Buchanan TW, 2000, COGNITIVE BRAIN RES, V9, P227, DOI 10.1016/S0926-6410(99)00060-9
   Charlesworth W., 1973, DARWIN FACIAL EXPRES, P91
   CORNWELL JM, 1994, J OCCUP ORGAN PSYCH, V67, P89, DOI 10.1111/j.2044-8325.1994.tb00553.x
   Dailey M., 2001, California facial expressions
   Dalla Bella S, 2003, PERCEPT PSYCHOPHYS, V65, P1019
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Dellacherie D, 2011, NEUROPSYCHOLOGIA, V49, P618, DOI 10.1016/j.neuropsychologia.2010.11.008
   Ekman P., 1978, Manual for the facial action coding system
   Ekman P., 1982, Emotion in the Human Face, V2nd ed.
   Ekman Paul, 2002, A HUMAN FACE, V2, P3
   Eschrich S, 2008, BMC NEUROSCI, V9, DOI 10.1186/1471-2202-9-48
   Fecteau S, 2007, NEUROIMAGE, V36, P480, DOI 10.1016/j.neuroimage.2007.02.043
   Filipic S, 2010, PSYCHON B REV, V17, P335, DOI 10.3758/PBR.17.3.335
   Flom R, 2008, INFANT BEHAV DEV, V31, P716, DOI 10.1016/j.infbeh.2008.04.004
   Frank MG, 2001, J PERS SOC PSYCHOL, V80, P75, DOI 10.1037/0022-3514.80.1.75
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Gabrielsson A, 2003, SER AFFECTIVE SCI, P503
   Gosselin N, 2005, BRAIN, V128, P628, DOI 10.1093/brain/awh420
   Gosselin N, 2007, NEUROPSYCHOLOGIA, V45, P236, DOI 10.1016/j.neuropsychologia.2006.07.012
   Hailstone JC, 2009, Q J EXP PSYCHOL, V62, P2141, DOI 10.1080/17470210902765957
   Heaton R., 2006, VERSATILE CLARINET, P31
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Juslin P. N., 1996, PSYCHOL MUSIC, V24, P68, DOI [10.1177/0305735696241007, DOI 10.1177/0305735696241007]
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kantrowitz JT, 2013, SCHIZOPHRENIA BULL, V39, P86, DOI 10.1093/schbul/sbr060
   Koeda M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00105
   Kotz SA, 2003, BRAIN LANG, V86, P366, DOI 10.1016/S0093-934X(02)00532-1
   Lang PJ., 1988, The international affective picture system (slides)
   Lima CF, 2013, J CLIN EXP NEUROPSYC, V35, P373, DOI 10.1080/13803395.2013.776518
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Mitchell RLC, 2003, NEUROPSYCHOLOGIA, V41, P1410, DOI 10.1016/S0028-3932(03)00017-4
   Monrad-Krohn G.H., 1963, Problems in Dynamic Neurology, P101
   Omar R, 2011, NEUROIMAGE, V56, P1814, DOI 10.1016/j.neuroimage.2011.03.002
   Pell MD, 2006, BRAIN LANG, V96, P221, DOI 10.1016/j.bandl.2005.04.007
   Peretz I, 2003, NAT NEUROSCI, V6, P688, DOI 10.1038/nn1083
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   Peretz I, 2005, ANNU REV PSYCHOL, V56, P89, DOI 10.1146/annurev.psych.56.091103.070225
   Peretz I, 2002, NEURON, V33, P185, DOI 10.1016/S0896-6273(01)00580-3
   Roy M, 2009, INT J PSYCHOPHYSIOL, V71, P37, DOI 10.1016/j.ijpsycho.2008.07.010
   Salimpoor VN, 2011, NAT NEUROSCI, V14, P257, DOI 10.1038/nn.2726
   Sauter DA, 2010, P NATL ACAD SCI USA, V107, P2408, DOI 10.1073/pnas.0908239106
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   SCHERER KR, 1994, EMOTIONS: ESSAYS ON EMOTION THEORY, P161
   Schirmer A, 2005, COGNITIVE BRAIN RES, V24, P442, DOI 10.1016/j.cogbrainres.2005.02.022
   Schröber M, 2003, SPEECH COMMUN, V40, P99, DOI 10.1016/S0167-6393(02)00078-X
   Terwogt M. M., 1991, PSYCHOL MUSIC, V19, P99, DOI DOI 10.1177/0305735691192001
   Thompson WF, 2012, P NATL ACAD SCI USA, V109, P19027, DOI 10.1073/pnas.1210344109
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 59
TC 46
Z9 49
U1 0
U2 16
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD AUG 13
PY 2013
VL 4
AR 509
DI 10.3389/fpsyg.2013.00509
PG 7
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA AA6FN
UT WOS:000331194300001
PM 23964255
OA gold, Green Published
DA 2024-01-09
ER

PT J
AU Xu, YZ
   Wang, WQ
   Cui, HH
   Xu, MY
   Li, M
AF Xu, Yanze
   Wang, Weiqing
   Cui, Huahua
   Xu, Mingyang
   Li, Ming
TI Paralinguistic singing attribute recognition using supervised machine
   learning for describing the classical tenor solo singing voice in vocal
   pedagogy
SO EURASIP JOURNAL ON AUDIO SPEECH AND MUSIC PROCESSING
LA English
DT Article
DE Paralinguistic singing attribtue recognition; Vocal pedagogy; Music
   perception
ID EMOTION RECOGNITION; LOW TONE; K-NN; SPEECH; TIMBRE; FEATURES;
   CLASSIFICATION; DIMENSIONS; SCALE; MFCC
AB Humans can recognize someone's identity through their voice and describe the timbral phenomena of voices. Likewise, the singing voice also has timbral phenomena. In vocal pedagogy, vocal teachers listen and then describe the timbral phenomena of their student's singing voice. In this study, in order to enable machines to describe the singing voice from the vocal pedagogy point of view, we perform a task called paralinguistic singing attribute recognition. To achieve this goal, we first construct and publish an open source dataset named Singing Voice Quality and Technique Database (SVQTD) for supervised learning. All the audio clips in SVQTD are downloaded from YouTube and processed by music source separation and silence detection. For annotation, seven paralinguistic singing attributes commonly used in vocal pedagogy are adopted as the labels. Furthermore, to explore the different supervised machine learning algorithm for classifying each paralinguistic singing attribute, we adopt three main frameworks, namely openSMILE features with support vector machine (SF-SVM), end-to-end deep learning (E2EDL), and deep embedding with support vector machine (DE-SVM). Our methods are based on existing frameworks commonly employed in other paralinguistic speech attribute recognition tasks. In SF-SVM, we separately use the feature set of the INTERSPEECH 2009 Challenge and that of the INTERSPEECH 2016 Challenge as the SVM classifier's input. In E2EDL, the end-to-end framework separately utilizes the ResNet and transformer encoder as feature extractors. In particular, to handle two-dimensional spectrogram input for a transformer, we adopt a sliced multi-head self-attention (SMSA) mechanism. In the DE-SVM, we use the representation extracted from the E2EDL model as the input of the SVM classifier. Experimental results on SVQTD show no absolute winner between E2EDL and the DE-SVM, which means that the back-end SVM classifier with the representation learned by E2E as input does not necessarily improve the performance. However, the DE-SVM that utilizes the ResNet as the feature extractor achieves the best average UAR, with an average 16% improvement over that of the SF-SVM with INTERSPEECH's hand-crafted feature set.
C1 [Xu, Yanze; Wang, Weiqing; Li, Ming] Duke Kunshan Univ, Data Sci Res Ctr, Kunshan, Peoples R China.
   [Cui, Huahua; Xu, Mingyang] Adv Comp East China SubCtr, Suzhou, Peoples R China.
C3 Duke Kunshan University
RP Li, M (corresponding author), Duke Kunshan Univ, Data Sci Res Ctr, Kunshan, Peoples R China.
EM ming.li369@dukekunshan.edu.cn
FU National Natural Science Foundation of China [62171207]; Fundamental
   Research Funds for the Central Universities [2042021kf0039]; Science and
   Technology Program of Guangzhou City [201903010040,202007030011]
FX This research is funded in part by the National Natural Science
   Foundation of China (62171207), the Fundamental Research Funds for the
   Central Universities (2042021kf0039), and the Science and Technology
   Program of Guangzhou City (201903010040,202007030011).
CR Amiriparian S, 2017, INTERSPEECH, P3512, DOI 10.21437/Interspeech.2017-434
   [Anonymous], 1999, METAPHORIC LOGIC MUS
   [Anonymous], 1984, New Images of Musical Sound
   APPELMAN DR, 1967, SCI VOCAL PEDAGOGY T
   Aura M, 2022, J VOICE, V36, P83, DOI 10.1016/j.jvoice.2020.04.013
   Austin SF, 1997, J VOICE, V11, P212, DOI 10.1016/S0892-1997(97)80080-X
   Ba JL., 2016, ARXIV160706450, V1050, P21, DOI DOI 10.48550/ARXIV.1607.06450
   Ball Martin J., 1995, J INT PHON ASSOC, V25, P71, DOI [DOI 10.1017/S0025100300005181, 10.1017/S0025100300005181.]
   Barsties B, 2015, AURIS NASUS LARYNX, V42, P183, DOI 10.1016/j.anl.2014.11.001
   Blake David K., 2012, MTO J SOC MUSIC THEO, V18, P1, DOI DOI 10.30535/MTO.18.2.1
   Boersma P., 2014, PRAAT DOING PHONETIC
   Bourne T., 2011, Journal of Singing, V67, P437
   Caclin A, 2005, J ACOUST SOC AM, V118, P471, DOI 10.1121/1.1929229
   Cai Han, 2019, INT C LEARN REPR ICL, DOI DOI 10.48550/ARXIV.1812.00332
   Chee LS, 2009, 2009 INTERNATIONAL CONFERENCE FOR TECHNICAL POSTGRADUATES (TECHPOS 2009), P15
   Chee LS, 2009, IEEE ST CONF RES DEV, P146, DOI 10.1109/SCORED.2009.5443210
   Debertin P. L., 1979, THESIS U MONTANA
   DeBodt MS, 1997, J VOICE, V11, P74, DOI 10.1016/S0892-1997(97)80026-4
   Defossez Alexandre, 2019, ARXIV PREPRINT ARXIV
   Dosovitskiy A., 2021, P ICLR 2021 IM REC S
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Elliott TM, 2013, J ACOUST SOC AM, V133, P389, DOI 10.1121/1.4770244
   Eyben F., 2010, P 18 ACM INT C MULT, P1459, DOI [DOI 10.1145/1873951.1874246, 10.1145/1873951.1874246]
   Fernandez R, 2011, SPEECH COMMUN, V53, P1088, DOI 10.1016/j.specom.2011.05.003
   Fletcher H, 1934, J ACOUST SOC AM, V6, P59, DOI 10.1121/1.1915704
   Goto M., 2005, IPSJ SIG NOTES, V2005, P7
   Grove G., 1980, NEW GROVE DICT MUSIC, V1
   Hariharan M., 2012, 2012 IEEE 8th International Colloquium on Signal Processing & its Applications, P240, DOI 10.1109/CSPA.2012.6194726
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heidemann K, 2016, MUSIC THEORY ONLINE, V22
   Hennequin Romain, 2020, Journal of Open Source Software, V5, P2154, DOI [10.21105/joss.02154, DOI 10.21105/JOSS.02154]
   Khine SZK, 2008, LECT NOTES COMPUT SC, V4969, P159
   Kishore KVK, 2013, IEEE INT ADV COMPUT, P842
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Koike T, 2020, INTERSPEECH, P2047, DOI 10.21437/Interspeech.2020-1552
   Krajinovic S., 2006, THESIS HOGSKOLEN AGD
   Kreiman, 2003, ISCA TUT RES WORKSH, P115
   Lanjewar RB, 2015, PROCEDIA COMPUT SCI, V49, P50, DOI 10.1016/j.procs.2015.04.226
   Large J, 1972, NATS B, V28, P18
   Lavengood M., 2017, THESIS CITY U NEW YO
   Lazoryszczak M., 2013, ELEKT KONSTRUKCJE TE, V54, P92
   Lee G, 2003, CHINESE J PHYSIOL, V46, P123
   Lee GS, 2009, CLEFT PALATE-CRAN J, V46, P47, DOI 10.1597/07-184.1
   Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin YL, 2005, PROCEEDINGS OF 2005 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-9, P4898
   Ling He, 2009, Proceedings of the 2009 Fifth International Conference on Natural Computation (ICNC 2009), P260, DOI 10.1109/ICNC.2009.59
   LoVetri J.L., 2003, JOS, V60, P161
   McKinney James C., 2005, DIAGNOSIS CORRECTION
   Nakano T, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1706
   Nwe TL, 2007, IEEE T AUDIO SPEECH, V15, P519, DOI 10.1109/TASL.2006.876756
   Nwe TL, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P1619
   Nwe TL, 2003, SPEECH COMMUN, V41, P603, DOI 10.1016/S0167-6393(03)00099-2
   O'Connor B., 2020, P 2020 JOINT C AI MU, DOI [10.30746/978-91-519-5560-5, DOI 10.30746/978-91-519-5560-5]
   Paszke A, 2019, ADV NEUR IN, V32
   PRATT RL, 1976, J SOUND VIB, V45, P317, DOI 10.1016/0022-460X(76)90391-6
   Rosenberg A, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P2239
   Rothman H.B., 1987, J VOICE, V1, P123, DOI [10.1016/S0892-1997(87)80036-X, DOI 10.1016/S0892-1997(87)80036-X]
   Sataloff R T, 1981, Am J Otolaryngol, V2, P251, DOI 10.1016/S0196-0709(81)80022-1
   Schuller B, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P865
   Schuller B, 2016, INTERSPEECH, P2001, DOI 10.21437/Interspeech.2016-129
   Schuller B, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P336
   Slawson W., 1985, Sound Color
   Stark James A., 1999, Bel Canto: A History of Vocal Pedagogy
   STOER VL, 1978, MUSIC EDUC J, V65, P47, DOI 10.2307/3395549
   Stoter F.-R., 2019, J OPEN SOURCE SOFTWA, DOI DOI 10.21105/JOSS.01667
   Sundberg J., 1990, J ACOUST SOC AM, V87, P462, DOI [DOI 10.1121/1.399243, 10.1121/1.399243]
   Titze I.R., 2012, J SINGING, V69, P177
   TRAGER G. L., 1958, Studies in Linguistics, Scilit, V13, P1
   Trigeorgis G, 2016, INT CONF ACOUST SPEE, P5200, DOI 10.1109/ICASSP.2016.7472669
   Vaswani A, 2017, ADV NEUR IN, V30
   Vurma A, 2002, J VOICE, V16, P383, DOI 10.1016/S0892-1997(02)00109-1
   Vurma Allan, 2003, Logoped Phoniatr Vocol, V28, P19, DOI 10.1080/14015430310010854
   Wagner J, 2018, INTERSPEECH, P147
   Weninger F, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00292
   Wilkins J., 2018, P ISMIR, P468
   Wooldridge W.B, 1956, BULLETIN, V13, P128
   Wu HW, 2019, INTERSPEECH, P2433, DOI 10.21437/Interspeech.2019-1386
   Wyllys K., 2013, THESIS W MICHIGAN U
   Zhou GJ, 1999, INT CONF ACOUST SPEE, P2087, DOI 10.1109/ICASSP.1999.758344
   Zwan, 2006, AUDIO ENG SOC CONVEN
NR 80
TC 5
Z9 5
U1 1
U2 6
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1687-4722
J9 EURASIP J AUDIO SPEE
JI EURASIP J. Audio Speech Music Process.
PD APR 15
PY 2022
VL 2022
IS 1
AR 8
DI 10.1186/s13636-022-00240-z
PG 16
WC Acoustics; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Acoustics; Engineering
GA 0N3RA
UT WOS:000782757900001
PM 35440938
OA gold, Green Published
DA 2024-01-09
ER

PT J
AU Trevor, C
   Frühholz, S
AF Trevor, Caitlyn
   Fruhholz, Sascha
TI The evolutionary benefit of less-credible affective musical signals for
   emotion induction during storytelling
SO BEHAVIORAL AND BRAIN SCIENCES
LA English
DT Editorial Material
ID COMMUNICATION; EXPRESSION; VOICE
AB The credible signaling theory underexplains the evolutionary added value of less-credible affective musical signals compared to vocal signals. The theory might be extended to account for the motivation for, and consequences of, culturally decontextualizing a biologically contextualized signal. Musical signals are twofold, communicating "emotional fiction" alongside biological meaning, and could have filled an adaptive need for affect induction during storytelling.
C1 [Trevor, Caitlyn; Fruhholz, Sascha] Univ Zurich, Cognit & Affect Neurosci Unit, Dept Psychol, Binzmuehlestr 14, CH-8050 Zurich, Switzerland.
   [Fruhholz, Sascha] Univ Oslo, Dept Psychol, N-0317 Oslo, Norway.
C3 University of Zurich; University of Oslo
RP Trevor, C (corresponding author), Univ Zurich, Cognit & Affect Neurosci Unit, Dept Psychol, Binzmuehlestr 14, CH-8050 Zurich, Switzerland.
EM caitlyn.trevor@psychologie.uzh.ch; sascha.fruehholz@uzh.ch
OI Trevor, Caitlyn/0000-0002-8418-3443
FU European Union [835682]; Swiss National Science Foundation [SNSF
   PP00P1_157409/1, PP00P1_183711/1]; Marie Curie Actions (MSCA) [835682]
   Funding Source: Marie Curie Actions (MSCA)
FX C.T. received funding from the European Union's Horizon 2020 research
   and innovation program under the Marie Sklodowska-Curie Grant Agreement
   (No. 835682). S.F. received funding from Swiss National Science
   Foundation (Grants Nos. SNSF PP00P1_157409/1 and PP00P1_183711/1).
CR Arnal LH, 2015, CURR BIOL, V25, P2051, DOI 10.1016/j.cub.2015.06.043
   Bown J., 2016, EMOTIONS TECHNOLOGY, P3, DOI 10.1016/B978-0-12-801738-8.00001-4
   Bryant G.A., 2020, HDB COMMUNICATION SC, P63, DOI DOI 10.4324/9781351235587-7
   Engelberg JWM, 2019, Q J EXP PSYCHOL, V72, P1889, DOI 10.1177/1747021818816307
   Frühholz S, 2014, PROG NEUROBIOL, V123, P1, DOI 10.1016/j.pneurobio.2014.09.003
   Frühholz S, 2021, PROG NEUROBIOL, V199, DOI 10.1016/j.pneurobio.2020.101948
   Frühholz S, 2016, NEUROSCI BIOBEHAV R, V68, P96, DOI 10.1016/j.neubiorev.2016.05.002
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Li P, 2017, CURR BIOL, V27, pR88, DOI 10.1016/j.cub.2016.09.006
   Monelle Raymond., 2000, The Sense of Music: Semiotic Essays
   Paquette S, 2018, ANN NY ACAD SCI, V1423, P329, DOI 10.1111/nyas.13666
   Pellowski A., 1990, WORLD STORYTELLING
   Revonsuo A, 2000, BEHAV BRAIN SCI, V23, P877, DOI 10.1017/S0140525X00004015
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Schwartz J. W., 2019, J ACOUST SOC AM, V145, P1776, DOI [10.1121/1.5101500, DOI 10.1121/1.5101500]
   Scrivner C, 2021, PERS INDIV DIFFER, V168, DOI 10.1016/j.paid.2020.110397
   Smith D, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-02036-8
   Stanovich KE, 2000, BEHAV BRAIN SCI, V23, P645, DOI 10.1017/S0140525X00003435
   Teigen KH, 2008, SCAND J PSYCHOL, V49, P49, DOI 10.1111/j.1467-9450.2007.00599.x
   Trevor C, 2020, J ACOUST SOC AM, V147, pEL540, DOI 10.1121/10.0001459
   Trevor C, 2018, EMPIR MUSICOL REV, V13, P66
   Vassilakis PN, 2010, PROC SPIE, V7527, DOI 10.1117/12.845457
   Walton K. L., 1990, Mimesis as make-believe
NR 23
TC 1
Z9 1
U1 1
U2 5
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0140-525X
EI 1469-1825
J9 BEHAV BRAIN SCI
JI Behav. Brain Sci.
PD SEP 30
PY 2021
VL 44
AR e118
DI 10.1017/S0140525X20001004
PG 3
WC Psychology, Biological; Behavioral Sciences; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Psychology; Behavioral Sciences; Neurosciences & Neurology
GA UY4ZV
UT WOS:000701534900060
PM 34588032
OA Green Accepted
DA 2024-01-09
ER

PT J
AU Kim, KL
   Lee, J
   Kum, S
   Park, CL
   Nam, J
AF Kim, Keunhyoung Luke
   Lee, Jongpil
   Kum, Sangeun
   Park, Chae Lin
   Nam, Juhan
TI Semantic Tagging of Singing Voices in Popular Music Recordings
SO IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING
LA English
DT Article
DE Timbre; Instruments; Vocabulary; Tagging; Statistical analysis; Singing
   voice; vocal; semantic analysis; music tagging; convolutional neural
   networks; timbre; K-Pop
ID MELODY EXTRACTION; ACCOMPANIMENT; EMOTION; TIMBRE
AB Singing voice is a key sound source in popular music. As recent music streaming and entertainment services call for more intelligent solutions to retrieve songs or evaluate musical characteristics, automatic analysis of popular music targeted to singing voice has been a significant research subject. The majority of studies have focused on quantitative or objective information of singing voice such as pitch, lyrics or singer identity. However, singing voice has a wide variety of dimensions that are somewhat difficult to quantify and therefore we often describe by words. In this article, we address the qualitative analysis of singing voice as a music auto-tagging task that annotates songs with a set of tag words. To this end, we build a music tag dataset dedicated to singing voice. Specifically, we define a vocabulary that describes timbre and singing styles of K-pop vocalists and collect human annotations for individual tracks. We then conduct statistical analysis to understand the global and temporal characteristics of the tag words. Using the dataset, we train a deep neural network model to automatically predict the voice-specific tags from popular music recordings and evaluate the model in different conditions. We discuss the results by comparing them to the statistical analysis of tag words. Finally, we show potential applications of the vocal tagging system in music retrieval, music thumbnailing and singing evaluation.
C1 [Kim, Keunhyoung Luke; Lee, Jongpil; Kum, Sangeun; Park, Chae Lin; Nam, Juhan] Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, Daejeon 34141, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Nam, J (corresponding author), Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, Daejeon 34141, South Korea.
EM dilu@kaist.ac.kr; richter@kaist.ac.kr; keums@kaist.ac.kr;
   lynn08@kaist.ac.kr; juhannam@kaist.ac.kr
RI Nam, Juhan/N-3513-2014
OI Nam, Juhan/0000-0003-2664-2119; Kim, Keunhyoung/0000-0001-8167-5752
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [NRF-2015R1C1A1A02036962]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT) (No.
   NRF-2015R1C1A1A02036962). The associate editor coordinating the review
   of this manuscript and approving it for publication was Dr. Hsin-min
   Wang.
CR [Anonymous], 2014, FOUND TRENDS INF RET, V8, P128, DOI 10.1561/1500000042
   [Anonymous], 2010, ISMIR
   [Anonymous], 2010, INT SOC MUS INF RETR, DOI DOI 10.1109/ICMLA.2010.101
   [Anonymous], 2009, ISMIR
   [Anonymous], 2011, MODERN HIERARCHICAL
   [Anonymous], P 17 INT SOC MUS INF
   Bartsch MA, 2005, IEEE T MULTIMEDIA, V7, P96, DOI 10.1109/TMM.2004.840597
   Bertin-Mahieux T., 2011, P 12 INT C MUS INF R
   Choi K, 2018, IEEE TETCI, V2, P139, DOI 10.1109/TETCI.2017.2771298
   Choi W, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P805, DOI 10.1145/2971648.2971756
   Daido R, 2014, COMPUT SPEECH LANG, V28, P501, DOI 10.1016/j.csl.2012.07.007
   Donnadieu S, 2007, MOD ACOUST SIGN PROC, P272, DOI 10.1007/978-0-387-32576-7_8
   Durrieu JL, 2008, INT CONF ACOUST SPEE, P169, DOI 10.1109/ICASSP.2008.4517573
   Fan J., 2017, ISMIR, P368
   Flexer A, 2016, J NEW MUSIC RES, V45, P239, DOI 10.1080/09298215.2016.1200631
   Fujihara H, 2010, IEEE T AUDIO SPEECH, V18, P638, DOI 10.1109/TASL.2010.2041386
   Goto M., 2002, ISMIR, P287
   Goto M, 2014, INT CONF SIGN PROCES, P2431, DOI 10.1109/ICOSP.2014.7015431
   Ha J.-W., 2017, P 34 INT C MACH LEAR
   Hmpuhrey EJ, 2019, IEEE SIGNAL PROC MAG, V36, P82, DOI 10.1109/MSP.2018.2875133
   Hong J, 2018, PROCEEDINGS OF THE 9TH ACM SIGPLAN INTERNATIONAL SYMPOSIUM ON SCALA (SCALA '18), P35, DOI 10.1145/3241653.3241657
   Hosoya T., 2005, ISMIR, P532
   Huang Y.-S., 2018, T INT SOC MUSIC INF, V1, P68
   Jeni LA, 2013, INT CONF AFFECT, P245, DOI 10.1109/ACII.2013.47
   Kan MY, 2008, IEEE T AUDIO SPEECH, V16, P338, DOI 10.1109/TASL.2007.911559
   Kanato A., 2014, P ICMC SMC 2014, P1244
   Kim K. L., 2017, P LAT BREAK DEM 18 I
   Kim Y. E, 2002, P INT SOC MUS INF RE
   Koops HV, 2019, J NEW MUSIC RES, V48, P232, DOI 10.1080/09298215.2019.1613436
   Kriegeskorte N, 2008, FRONT SYST NEUROSCI, V2, DOI 10.3389/neuro.06.004.2008
   KRIPPEND.K, 1970, EDUC PSYCHOL MEAS, V30, P61, DOI 10.1177/001316447003000105
   Kum S, 2016, PROC ISMIR, P819
   Li HQ, 2018, INT REV FINANC, V18, P717, DOI 10.1111/irfi.12158
   Lichte WH, 1941, J EXP PSYCHOL, V28, P455, DOI 10.1037/h0053526
   Lippens S, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL IV, PROCEEDINGS, P233
   Mandel M, 2008, J NEW MUSIC RES, V37, P151, DOI 10.1080/09298210802479300
   McVicar Matt, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3117, DOI 10.1109/ICASSP.2014.6854174
   Moon G, 2017, J INFORM DISPLAY, V18, P145, DOI 10.1080/15980316.2017.1345800
   Nakano Tomoyasu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5202, DOI 10.1109/ICASSP.2014.6854595
   Nakano T, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1706
   Nam J, 2019, IEEE SIGNAL PROC MAG, V36, P41, DOI 10.1109/MSP.2018.2874383
   Prockup Matthew, 2015, P INT SOC MUS INF RE, P31
   Ramona M, 2008, INT CONF ACOUST SPEE, P1885, DOI 10.1109/ICASSP.2008.4518002
   Rao V, 2010, IEEE T AUDIO SPEECH, V18, P2145, DOI 10.1109/TASL.2010.2042124
   Salamon J, 2014, IEEE SIGNAL PROC MAG, V31, P118, DOI 10.1109/MSP.2013.2271648
   Scherer KR, 2017, J ACOUST SOC AM, V142, P1805, DOI 10.1121/1.5002886
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Schluter J., 2015, ISMIR
   Seyerlehner K., 2011, ADAPTIVE MULTIMEDIA, P118
   Soleymani M., 2017, P ACM C MULT, P1161
   Song J., 2002, P 3 C INT SOC MUS IN
   Stoller Daniel, 2018, P INT SOC MUS INF RE, V19, P334
   Stoter F.-R., 2019, J OPEN SOURCE SOFTWA, DOI DOI 10.21105/JOSS.01667
   Tsai WH, 2012, IEEE T AUDIO SPEECH, V20, P1233, DOI 10.1109/TASL.2011.2174224
   Turnbull D., 2018, IEEE-ACM T AUDIO SPE, V16, P467
   Turnbull D., 2008, P INT SOC MUS INF RE
   von Bismarck G., 1974, Acustica, V30, P159
   [王思洋 Wang Siyang], 2014, [北京师范大学学报. 自然科学版, Journal of Beijing Normal University. Natural Science], V50, P1
   Whitman B., 2004, P INT SOC MUS INF RE
NR 59
TC 6
Z9 6
U1 2
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2329-9290
EI 2329-9304
J9 IEEE-ACM T AUDIO SPE
JI IEEE-ACM Trans. Audio Speech Lang.
PY 2020
VL 28
BP 1656
EP 1668
DI 10.1109/TASLP.2020.2993893
PG 13
WC Acoustics; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Acoustics; Engineering
GA MC0HD
UT WOS:000542977800004
DA 2024-01-09
ER

PT J
AU Bowling, DL
   Sundararajan, J
   Han, S
   Purves, D
AF Bowling, Daniel Liu
   Sundararajan, Janani
   Han, Shui'er
   Purves, Dale
TI Expression of Emotion in Eastern and Western Music Mirrors Vocalization
SO PLOS ONE
LA English
DT Article
AB In Western music, the major mode is typically used to convey excited, happy, bright or martial emotions, whereas the minor mode typically conveys subdued, sad or dark emotions. Recent studies indicate that the differences between these modes parallel differences between the prosodic and spectral characteristics of voiced speech sounds uttered in corresponding emotional states. Here we ask whether tonality and emotion are similarly linked in an Eastern musical tradition. The results show that the tonal relationships used to express positive/excited and negative/subdued emotions in classical South Indian music are much the same as those used in Western music. Moreover, tonal variations in the prosody of English and Tamil speech uttered in different emotional states are parallel to the tonal trends in music. These results are consistent with the hypothesis that the association between musical tonality and emotion is based on universal vocal characteristics of different affective states.
C1 [Bowling, Daniel Liu; Sundararajan, Janani; Han, Shui'er; Purves, Dale] Duke Natl Univ Singapore, Neurosci & Behav Disorders Program, Grad Med Sch Singapore, Singapore, Singapore.
   [Bowling, Daniel Liu; Purves, Dale] Duke Univ, Med Ctr, Dept Neurobiol, Durham, NC 27710 USA.
   [Bowling, Daniel Liu; Purves, Dale] Duke Univ, Med Ctr, Ctr Cognit Neurosci, Levine Sci Res Ctr, Durham, NC 27710 USA.
C3 National University of Singapore; Duke University; Duke University
RP Bowling, DL (corresponding author), Duke Natl Univ Singapore, Neurosci & Behav Disorders Program, Grad Med Sch Singapore, Singapore, Singapore.
OI Bowling, Daniel/0000-0002-5303-5472
FU National Science Foundation [BCS-0924181]; Duke-National University of
   Singapore Graduate Medical School; Direct For Social, Behav & Economic
   Scie; Division Of Behavioral and Cognitive Sci [0924181] Funding Source:
   National Science Foundation
FX This work was supported by a grant from the National Science Foundation
   [BCS-0924181] and a block grant to DP from Duke-National University of
   Singapore Graduate Medical School. The funders had no role in study
   design, data collection and analysis, decision to publish, or
   preparation of the manuscript.
CR Aldwell E, 2003, HARMONY VOICE LEADIN, P19
   [Anonymous], NEW HARVARD DICT MUS
   [Anonymous], 1984, PSYCHOMUSICOLOGY, DOI DOI 10.1037/H0094207
   [Anonymous], 2001, Music and Emotion: Theory and Research
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Banumathy R, 2002, SRUTI MANJARI 2
   Banumathy R, 2002, SRUTI MANJARI 1
   Boersma P., 2014, PRAAT DOING PHONETIC
   Bowling DL, 2010, J ACOUST SOC AM, V127, P491, DOI 10.1121/1.3268504
   Chelladurai PT, 2010, SPLENDOUR S INDIAN M, P31
   Cooke D, 1959, LANGUAGE MUSIC, P89
   Curtis ME, 2010, EMOTION, V10, P335, DOI 10.1037/a0017928
   Danielou, 1980, RAGAS NO INDIAN MUSI, P40
   Darwin C, 2009, EXPRESSION EMOTIONS, P88
   Hevner K, 1935, AM J PSYCHOL, V47, P103, DOI 10.2307/1416710
   Jurgens U, 1979, Behaviour, V69, P88, DOI 10.1163/156853979X00412
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   MathWorks Inc, 2009, MATL VERS R2009A COM
   Miller TE, 2008, GARLAND HDB SE ASIAN, V256, P384
   Papousek M., 1992, NONVERBAL VOCAL COMM, P230
   Patel AD, 2008, MUSIC LANGUAGE BRAIN, P313
   PORTER FL, 1986, CHILD DEV, V57, P790, DOI 10.2307/1130355
   Ramanathan S, 1988, DIVYA NAMA KIRTANA 2
   Ramanathan S, 1988, DIVYA NAMA KIRTANA 1
   Ramanathan S, 1985, SHYAMA SASTRIGAL ARI
   Rowell, 1992, MUSIC MUSICAL THOUGH, P327
   Sambamurthy P, 1999, S INDIAN MUSIC, P160
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   SPENCER H, 1857, FRASERS MAGAZINE, V56, P396, DOI DOI 10.1017/S0140525X08005293
   Swift, 1990, J SOC ASIAN MUSIC, V21-2, P71
   Touma HH, 1996, MUSIC ARABS
   Varadan P, 2005, KRTIMANIMALAI SRI TY
   Varadan P, 2005, KRTIMANIMALAI SRI TY, VI
   Zarlino G, 1968, ART COUNTERPOINT, P21
NR 34
TC 66
Z9 70
U1 1
U2 18
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD MAR 14
PY 2012
VL 7
IS 3
AR e31942
DI 10.1371/journal.pone.0031942
PG 8
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Science & Technology - Other Topics
GA 931EO
UT WOS:000303198600013
PM 22431970
OA gold, Green Published, Green Submitted
DA 2024-01-09
ER

PT J
AU Järvinen, A
   Ng, R
   Crivelli, D
   Neumann, D
   Arnold, AJ
   Woo-VonHoogenstyn, N
   Lai, P
   Trauner, D
   Bellugi, U
AF Jaervinen, Anna
   Ng, Rowena
   Crivelli, Davide
   Neumann, Dirk
   Arnold, Andrew J.
   Woo-VonHoogenstyn, Nicholas
   Lai, Philip
   Trauner, Doris
   Bellugi, Ursula
TI Social Functioning and Autonomic Nervous System Sensitivity Across Vocal
   and Musical Emotion in Williams Syndrome and Autism Spectrum Disorder
SO DEVELOPMENTAL PSYCHOBIOLOGY
LA English
DT Article
DE auditory processing; autism spectrum disorder; autonomic nervous system;
   emotion; music; social behavior; vocalizations; Williams syndrome
ID HEART-RATE-VARIABILITY; COMPLEX SOUNDS; CHILDREN; PERCEPTION;
   INDIVIDUALS; RECOGNITION; ABILITIES; DEFICITS; HETEROGENEITY;
   INTERVENTION
AB Both Williams syndrome (WS) and autism spectrum disorders (ASD) are associated with unusual auditory phenotypes with respect to processing vocal and musical stimuli, which may be shaped by the atypical social profiles that characterize the syndromes. Autonomic nervous system (ANS) reactivity to vocal and musical emotional stimuli was examined in 12 children with WS, 17 children with ASD, and 20 typically developing (TD) children, and related to their level of social functioning. The results of this small-scale study showed that after controlling for between-group differences in cognitive ability, all groups showed similar emotion identification performance across conditions. Additionally, in ASD, lower autonomic reactivity to human voice, and in TD, to musical emotion, was related to more normal social functioning. Compared to TD, both clinical groups showed increased arousal to vocalizations. A further result highlighted uniquely increased arousal to music in WS, contrasted with a decrease in arousal in ASD and TD. The ASD and WS groups exhibited arousal patterns suggestive of diminished habituation to the auditory stimuli. The results are discussed in the context of the clinical presentation of WS and ASD. (C) 2015 Wiley Periodicals, Inc. Dev Psychobiol 58: 17-26, 2016.
C1 [Jaervinen, Anna; Ng, Rowena; Crivelli, Davide; Arnold, Andrew J.; Woo-VonHoogenstyn, Nicholas; Lai, Philip; Bellugi, Ursula] Salk Inst Biol Studies, Cognit Neurosci Lab, 10010 N Torrey Pines Rd, La Jolla, CA 92037 USA.
   [Ng, Rowena] Univ Minnesota, Twin Cities Inst Child Dev, Minneapolis, MN USA.
   [Crivelli, Davide] Univ Cattolica Sacro Cuore, Dept Psychol, I-20123 Milan, Italy.
   [Neumann, Dirk] CALTECH, Emot & Social Cognit Lab, Pasadena, CA 91125 USA.
   [Trauner, Doris] Univ Calif San Diego, Sch Med, Dept Neurosci, La Jolla, CA 92093 USA.
C3 Salk Institute; University of Minnesota System; University of Minnesota
   Twin Cities; Catholic University of the Sacred Heart; California
   Institute of Technology; University of California System; University of
   California San Diego
RP Järvinen, A (corresponding author), Salk Inst Biol Studies, Cognit Neurosci Lab, 10010 N Torrey Pines Rd, La Jolla, CA 92037 USA.
EM pasley@salk.edu
RI Arnold, Andrew/AGY-4802-2022; Neumann, Dirk/AAD-2150-2021; Crivelli,
   Davide/K-9123-2016
OI Neumann, Dirk/0000-0003-0818-4572; Crivelli, Davide/0000-0003-2221-2349;
   Ng, Rowena/0000-0001-7193-4300
CR American Psychiatric Association, 2013, DIAGNOSTIC STAT MANU, V5th edn., DOI [10.1176/appi.books.9780890425596, DOI 10.1176/APPI.BOOKS.9780890425596]
   Appelhans BM, 2006, REV GEN PSYCHOL, V10, P229, DOI 10.1037/1089-2680.10.3.229
   Baker KF, 2010, J AUTISM DEV DISORD, V40, P123, DOI 10.1007/s10803-009-0841-1
   Bal E, 2010, J AUTISM DEV DISORD, V40, P358, DOI 10.1007/s10803-009-0884-3
   Bellugi U, 2000, J COGNITIVE NEUROSCI, V12, P7, DOI 10.1162/089892900561959
   Bernston G. G., 1995, PSYCHOPHYSIOLOGY, V42, P246
   BLACKSTOCK EG, 1978, J AUTISM CHILD SCHIZ, V8, P339, DOI 10.1007/BF01539636
   Boddaert N, 2004, AM J PSYCHIAT, V161, P2117, DOI 10.1176/appi.ajp.161.11.2117
   Boddaert N, 2003, AM J PSYCHIAT, V160, P2057, DOI 10.1176/appi.ajp.160.11.2057
   Boucher J, 2000, J CHILD PSYCHOL PSYC, V41, P847, DOI 10.1111/1469-7610.00672
   BRAVERMAN M, 1989, J AUTISM DEV DISORD, V19, P301, DOI 10.1007/BF02211848
   Catterall C, 2006, CLIN LINGUIST PHONET, V20, P531, DOI 10.1080/02699200500266380
   Chang MC, 2012, AM J OCCUP THER, V66, P567, DOI 10.5014/ajot.2012.004242
   Cheshire WP, 2012, AUTON NEUROSCI-BASIC, V171, P4, DOI 10.1016/j.autneu.2012.08.003
   Cohen S, 2015, J CLIN CHILD ADOLESC, V44, P250, DOI 10.1080/15374416.2013.843462
   Constantino J. N., 2005, Social responsiveness scale: SRS-2
   DePape AMR, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0044084
   Dodd HF, 2010, COGN NEUROPSYCHIATRY, V15, P549, DOI 10.1080/13546801003737157
   Dykens EM, 2005, AM J MENT RETARD, V110, P346, DOI 10.1352/0895-8017(2005)110[346:MAAIWS]2.0.CO;2
   EWART AK, 1993, NAT GENET, V5, P11, DOI 10.1038/ng0993-11
   Gervais H, 2004, NAT NEUROSCI, V7, P801, DOI 10.1038/nn1291
   Heaton P, 1999, NEUROCASE, V5, P503, DOI 10.1093/neucas/5.6.503
   Heaton P, 2003, J CHILD PSYCHOL PSYC, V44, P543, DOI 10.1111/1469-7610.00143
   Hillier LW, 2003, NATURE, V424, P157, DOI 10.1038/nature01782
   Hirstein W, 2001, P ROY SOC B-BIOL SCI, V268, P1883, DOI 10.1098/rspb.2001.1724
   Hopyan T, 2001, CHILD NEUROPSYCHOL, V7, P42, DOI 10.1076/chin.7.1.42.3147
   Järvinen A, 2013, CURR OPIN NEUROBIOL, V23, P414, DOI 10.1016/j.conb.2012.12.006
   Järvinen AM, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00321
   Järvinen-Pasley A, 2010, NEUROPSYCHOLOGIA, V48, P2110, DOI 10.1016/j.neuropsychologia.2010.03.032
   Järvinen-Pasley A, 2010, NEUROPSYCHOLOGIA, V48, P1047, DOI 10.1016/j.neuropsychologia.2009.12.002
   Jarvinen A., 2015, J AUTISM DEV DISORDE
   Jarvinen Anna, 2012, Front Psychol, V3, P343, DOI 10.3389/fpsyg.2012.00343
   Järvinen-Pasley A, 2008, DEV PSYCHOPATHOL, V20, P1, DOI 10.1017/S0954579408000011
   Järvinen-Pasley A, 2008, J AUTISM DEV DISORD, V38, P1328, DOI 10.1007/s10803-007-0520-z
   Järvinen-Pasley A, 2010, NEUROPSYCHOLOGIA, V48, P456, DOI 10.1016/j.neuropsychologia.2009.10.003
   Jones CRG, 2011, J CHILD PSYCHOL PSYC, V52, P275, DOI 10.1111/j.1469-7610.2010.02328.x
   Klein-Tasman BP, 2007, CHILD NEUROPSYCHOL, V13, P444, DOI 10.1080/09297040601033680
   Klein-Tasman BP, 2011, J AUTISM DEV DISORD, V41, P341, DOI 10.1007/s10803-010-1060-5
   Kujala T, 2005, NEUROSCI LETT, V383, P260, DOI 10.1016/j.neulet.2005.04.048
   LaGasse AB, 2014, J MUSIC THER, V51, P250, DOI 10.1093/jmt/thu012
   Lang P. J., 1995, A4 U FLOR CTR RES PS
   Levitin DJ, 2004, CHILD NEUROPSYCHOL, V10, P223, DOI 10.1080/09297040490909288
   Little K, 2013, RES DEV DISABIL, V34, P959, DOI 10.1016/j.ridd.2012.11.020
   Lloyd-Fox S, 2013, P ROY SOC B-BIOL SCI, V280, DOI 10.1098/rspb.2012.3026
   Lord C, 2000, NEURON, V28, P355, DOI 10.1016/S0896-6273(00)00115-X
   LORD C, 1994, J AUTISM DEV DISORD, V24, P659, DOI 10.1007/BF02172145
   Lord C., 1999, Autism Diagnostic Observation Schedule
   Martens MA, 2008, J CHILD PSYCHOL PSYC, V49, P576, DOI 10.1111/j.1469-7610.2008.01887.x
   Mathersul D, 2013, INT J PSYCHOPHYSIOL, V89, P475, DOI 10.1016/j.ijpsycho.2013.04.014
   Mendes W. B., 2009, Methods in Social Neuroscience Series, P118
   O'Connor K, 2007, J AUTISM DEV DISORD, V37, P2008, DOI 10.1007/s10803-006-0345-1
   Peppe S., 2007, J SPEECH LANG HEAR R, V50, P1097
   Philip RCM, 2010, PSYCHOL MED, V40, P1919, DOI 10.1017/S0033291709992364
   Pinheiro J., 2020, R package version 3.1-153
   Pinheiro J. C., 2000, Mixed-effects models in S and A-PLUS, DOI [DOI 10.1007/978-1-4419-0318-1, DOI 10.1007/B98882]
   Plesa-Skwerer D, 2006, AM J MENT RETARD, V111, P15, DOI 10.1352/0895-8017(2006)111[15:PFAVEO]2.0.CO;2
   Porges SW, 2007, BIOL PSYCHOL, V74, P116, DOI 10.1016/j.biopsycho.2006.06.009
   Porges SW, 2013, INT J PSYCHOPHYSIOL, V88, P261, DOI 10.1016/j.ijpsycho.2012.11.009
   Porter MA, 2005, DEV NEUROPSYCHOL, V27, P275, DOI 10.1207/s15326942dn2702_5
   Quintana DS, 2012, INT J PSYCHOPHYSIOL, V86, P168, DOI 10.1016/j.ijpsycho.2012.08.012
   Quintin EM, 2011, J AUTISM DEV DISORD, V41, P1240, DOI 10.1007/s10803-010-1146-0
   R Core Team, 2018, R: A Language and Environment for Statistical Computing
   Riby DM, 2008, NEUROPSYCHOLOGIA, V46, P2855, DOI 10.1016/j.neuropsychologia.2008.05.003
   Riby DM, 2014, J AUTISM DEV DISORD, V44, P1220, DOI 10.1007/s10803-013-1984-7
   Riby DM, 2009, J AUTISM DEV DISORD, V39, P421, DOI 10.1007/s10803-008-0641-z
   Salimpoor VN, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0007487
   Stewart ME, 2013, AUTISM, V17, P6, DOI 10.1177/1362361311424572
   Tager-Flusberg H, 2000, COGNITION, V76, P59, DOI 10.1016/S0010-0277(00)00069-X
   van der Fluit F, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00197
   Wechsler D., 1991, The Wechsler Intelligence Scale for Children-Third edition, V3rd
   Whipple J, 2004, J MUSIC THER, V41, P90, DOI 10.1093/jmt/41.2.90
   Wigram T, 2006, CHILD CARE HLTH DEV, V32, P535, DOI 10.1111/j.1365-2214.2006.00615.x
NR 72
TC 19
Z9 22
U1 1
U2 48
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0012-1630
EI 1098-2302
J9 DEV PSYCHOBIOL
JI Dev. Psychobiol.
PD JAN
PY 2016
VL 58
IS 1
BP 17
EP 26
DI 10.1002/dev.21335
PG 10
WC Developmental Biology; Psychology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Developmental Biology; Psychology
GA DD7YQ
UT WOS:000370141300002
PM 26248474
OA Green Accepted
DA 2024-01-09
ER

PT J
AU Bowling, DL
AF Bowling, Daniel L.
TI A vocal basis for the affective character of musical mode in melody
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Review
DE music; emotion; voice; mode; interval-size
ID MAJOR MINOR DISTINCTION; EMOTIONAL RESPONSES; PERCEPTION; COMMUNICATION;
   RECOGNITION; EXPRESSION; TEMPO
AB Why does major music sound happy and minor music sound sad? The idea that different musical modes are best suited to the expression of different emotions has been prescribed by composers, music theorists, and natural philosophers for millennia. However, the reason we associate musical modes with emotions remains a matter of debate. On one side there is considerable evidence that mode-emotion associations arise through exposure to the conventions of a particular musical culture, suggesting a basis in lifetime learning. On the other, cross-cultural comparisons suggest that the particular associations we make are supported by musical similarities to the prosodic characteristics of the voice in different affective states, indicating a basis in the biology of emotional expression. Here, I review developmental and cross-cultural studies on the affective character of musical modes, concluding that while learning clearly plays a role, the emotional associations we make are (1) not arbitrary, and (2) best understood by also taking into account the physical characteristics and biological purposes of vocalization.
C1 Univ Vienna, Dept Cognit Biol, A-1090 Vienna, Austria.
C3 University of Vienna
RP Bowling, DL (corresponding author), Univ Vienna, Dept Cognit Biol, Alserstr 14, A-1090 Vienna, Austria.
EM dan.bowling@univie.edu
OI Bowling, Daniel/0000-0002-5303-5472
FU European Research Council (ERC) [230604] Funding Source: European
   Research Council (ERC); European Research Council [230604] Funding
   Source: Medline
CR [Anonymous], 1955, REPUBLIC
   [Anonymous], 1984, PSYCHOMUSICOLOGY, DOI DOI 10.1037/H0094207
   [Anonymous], 1899, EXPRESSION EMOTIONS
   [Anonymous], 1879, DESCENT MAN SELECTIO
   Balkwill LL, 2004, JPN PSYCHOL RES, V46, P337, DOI 10.1111/j.1468-5584.2004.00265.x
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Bowling DL, 2010, J ACOUST SOC AM, V127, P491, DOI 10.1121/1.3268504
   Bowling DL, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0031942
   Capwell C., 1986, NEW HARVARD DICT MUS, P779, DOI [10.1017/S0140525X08005293, DOI 10.1017/S0140525X08005293]
   Chomsky N., 2006, LANG MIND, DOI [10.1017/S0140525X08005293, DOI 10.1017/S0140525X08005293]
   Cook ND, 2007, MUSIC PERCEPT, V24, P315, DOI 10.1525/MP.2007.24.3.315
   Crowder R. G., 1985, PSYCHOMUSICOLOGY, V5, P3, DOI [DOI 10.1037/H0094203, 10.1037/h0094203]
   CROWDER RG, 1991, B PSYCHONOMIC SOC, V29, P187
   Curtis ME, 2010, EMOTION, V10, P335, DOI 10.1037/a0017928
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Davies S., 2001, MUSIC EMOTION THEORY, P23, DOI DOI 10.1017/S0140525X08005293
   Devy G. N., 2002, INDIAN LIT CRITICISM, DOI [10.1017/S0140525X08005293, DOI 10.1017/S0140525X08005293]
   Dolgin KG., 1990, Psychol. Music, V18, P87, DOI DOI 10.1177/0305735690181007
   Elfenbein HA, 2002, PSYCHOL BULL, V128, P203, DOI 10.1037//0033-2909.128.2.203
   Fitch WT, 2006, COGNITION, V100, P173, DOI 10.1016/j.cognition.2005.11.009
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Gagnon L, 2003, COGNITION EMOTION, V17, P25, DOI 10.1080/02699930302279
   Garcia J., 1966, PSYCHON SCI, V4, P123, DOI DOI 10.3758/BF03342209
   GERARDI GM, 1995, MUSIC PERCEPT, V12, P279
   GOULD JL, 1987, SCI AM, V256, P74, DOI 10.1038/scientificamerican0187-74
   Gregory AH, 1996, MOTIV EMOTION, V20, P341, DOI 10.1007/BF02856522
   Heinlein CP, 1928, J COMP PSYCHOL, V8, P101, DOI 10.1037/h0070573
   Helmholtz HLF., 1877, On the Sensations of Tone as a Physiological Basis for the Theory of Music
   Hevner K, 1935, AM J PSYCHOL, V47, P103, DOI 10.2307/1416710
   Hoshino E., 1996, PSYCHOL MUSIC, V24, P29, DOI [DOI 10.1177/0305735696241004, 10.1177/0305735696241004]
   Huron D, 2008, EMPIR MUSICOL REV, V3, P59, DOI 10.18061/1811/31940
   Jurgens U., 1992, NONVERBAL VOCAL COMM, P31, DOI DOI 10.1017/S0140525X08005293
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin Patrik N., 2008, BEHAV BRAIN SCI, V31, P559, DOI [10.1017/s0140525x08005293, DOI 10.1017/S0140525X08005293]
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   KASTNER MP, 1990, MUSIC PERCEPT, V8, P189
   Krumhansl C. L., 1990, COGNITIVE FDN MUSICA, DOI [10.1017/S0140525X08005293, DOI 10.1017/S0140525X08005293]
   Kunej D, 2000, ORIGINS OF MUSIC, P235
   Lobue V, 2008, PSYCHOL SCI, V19, P284, DOI 10.1111/j.1467-9280.2008.02081.x
   Lundin R. W., 1967, OBJECTIVE PSYCHOL MU, DOI [10.1017/S0140525X08005293, DOI 10.1017/S0140525X08005293]
   Marler P., 1991, EPIGENESIS MIND ESSA, P212, DOI [10.1017/S0140525X08005293, DOI 10.1017/S0140525X08005293]
   Nettl B., 1986, NEW HARVARD DICT MUS, P531, DOI [10.1017/S0140525X08005293, DOI 10.1017/S0140525X08005293]
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   Ploog Detlev W., 1992, P6
   Randel D. M., 1986, NEW HARVARD DICT MUS, P499, DOI [10.1017/S0140525X08005293, DOI 10.1017/S0140525X08005293]
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   SEYFARTH RM, 1980, SCIENCE, V210, P801, DOI 10.1126/science.7433999
   Spencer H., 1890, Mind, V15, P449, DOI [10.1093/mind/os-XV.60.449, DOI 10.1093/MIND/OS-XV.60.449]
   SPENCER H, 1857, FRASERS MAGAZINE, V56, P396, DOI DOI 10.1017/S0140525X08005293
   Tomasello M., 1999, CULTURAL ORIGINS HUM, DOI [10.1017/financialS0140525X08005293, DOI 10.1017/FINANCIALS0140525X08005293]
   Trainor LJ, 2010, SPRINGER HANDB AUDIT, V36, P89, DOI 10.1007/978-1-4419-6114-3_4
   Zacharopoulou K., 2009, J INTERDISCIP MUSIC, V3, P1
   Zarlino G., 1558, ART COUNTERPOINT 3
NR 54
TC 15
Z9 15
U1 0
U2 19
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD JUL 31
PY 2013
VL 4
AR 464
DI 10.3389/fpsyg.2013.00464
PG 6
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA AA5WQ
UT WOS:000331170700001
PM 23914179
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Mo, WW
   Yuan, Y
AF Mo, Wenwen
   Yuan, Yuan
TI Design of Interactive Vocal Guidance and Artistic Psychological
   Intervention System Based on Emotion Recognition
SO OCCUPATIONAL THERAPY INTERNATIONAL
LA English
DT Article
AB The research on artistic psychological intervention to judge emotional fluctuations by extracting emotional features from interactive vocal signals has become a research topic with great potential for development. Based on the interactive vocal music instruction theory of emotion recognition, this paper studies the design of artistic psychological intervention system. This paper uses the vocal music emotion recognition algorithm to first train the interactive recognition network, in which the input is a row vector composed of different vocal music characteristics, and finally recognizes the vocal music of different emotional categories, which solves the problem of low data coupling in the artistic psychological intervention system. Among them, the vocal music emotion recognition experiment based on the interactive recognition network is mainly carried out from six aspects: the number of iterative training, the vocal music instruction rate, the number of emotion recognition signal nodes in the artistic psychological intervention layer, the number of sample sets, different feature combinations, and the number of emotion types. The input data of the system is a training class learning video, and actions and expressions need to be recognized before scoring. In the simulation process, before the completion of the sample indicators is unbalanced, the R language statistical analysis tool is used to balance the existing unbalanced data based on the artificial data synthesis method, and 279 uniformly classified samples are obtained. The 279*7 dataset was used for statistical identification of the participants. The experimental results show that under the guidance of four different interactive vocal music, the vocal emotion recognition rate is between 65.85%-91.00%, which promotes the intervention of music therapy on artistic psychological intervention.
C1 [Mo, Wenwen] Sichuan Coll Tradit Chinese Med, Human Resources Off, Mianyang 621000, Sichuan, Peoples R China.
   [Yuan, Yuan] Northwestern Polytech Univ, Sch Marxism, Xian 71007Z, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University
RP Yuan, Y (corresponding author), Northwestern Polytech Univ, Sch Marxism, Xian 71007Z, Shaanxi, Peoples R China.
EM collegemh@nwpu.edu.cn
FU Human Resources Office, Sichuan College of Traditional Chinese Medicine
FX This work was supported by Human Resources Office, Sichuan College of
   Traditional Chinese Medicine.
CR Ayata D, 2020, J MED BIOL ENG, V40, P149, DOI 10.1007/s40846-019-00505-7
   DiPietro J, 2019, MEDICINA-LITHUANIA, V55, DOI 10.3390/medicina55080440
   Franzoni V, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185222
   Geraets CNW, 2021, CURR OPIN PSYCHOL, V41, P40, DOI 10.1016/j.copsyc.2021.02.004
   Haslbeck FB, 2020, JOVE-J VIS EXP, DOI 10.3791/60412
   Hasnul MA, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21155015
   He ZP, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10100687
   Hunnikin LM, 2020, EUR CHILD ADOLES PSY, V29, P363, DOI 10.1007/s00787-019-01358-w
   Imani M, 2019, J NETW COMPUT APPL, V147, DOI 10.1016/j.jnca.2019.102423
   Jiang YY, 2020, INFORM FUSION, V53, P209, DOI 10.1016/j.inffus.2019.06.019
   Johnston D, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10092996
   Lander K, 2018, COGN RES, V3, DOI 10.1186/s41235-018-0115-6
   Liao YH, 2018, THINK SKILLS CREAT, V29, P213, DOI 10.1016/j.tsc.2018.07.007
   Lim JZ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082384
   Lima Antonio Marcos Oliveira de, 2019, Rev. CEFAC, V21, pe12318, DOI 10.1590/1982-02162019/21112318
   Luna-Jiménez C, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12010327
   Marín-Morales J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185163
   McStay A, 2020, BIG DATA SOC, V7, DOI 10.1177/2053951720904386
   Nonis F, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9183904
   Park CY, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00630-y
   Ortega MGS, 2020, J AMB INTEL HUM COMP, V11, P3187, DOI 10.1007/s12652-019-01485-x
   Shu L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030718
   Shu L, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072074
   Yanxia Zhang, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3264960
   Zhang TY, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21010052
NR 25
TC 1
Z9 1
U1 1
U2 8
PU WILEY-HINDAWI
PI LONDON
PA ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND
SN 0966-7903
EI 1557-0703
J9 OCCUP THER INT
JI Occup. Ther. Int.
PD JUN 17
PY 2022
VL 2022
AR 1079097
DI 10.1155/2022/1079097
PG 9
WC Rehabilitation
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Rehabilitation
GA 2M4FN
UT WOS:000817657400002
PM 35821713
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Greenspon, EB
   Montanaro, V
AF Greenspon, Emma B.
   Montanaro, Victor
TI Singing ability is related to vocal emotion recognition: Evidence for
   shared sensorimotor processing across speech and music
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Singing accuracy; Music ability; Emotion recognition; Prosody
ID CONGENITAL AMUSIA; PROSODY; PERCEPTION; SPEAKING; INTELLIGENCE;
   PERFORMANCE; IMAGERY; ASSOCIATION; IMITATION; LESSONS
AB The ability to recognize emotion in speech is a critical skill for social communication. Motivated by previous work that has shown that vocal emotion recognition accuracy varies by musical ability, the current study addressed this relationship using a behavioral measure of musical ability (i.e., singing) that relies on the same effector system used for vocal prosody production. In the current study, participants completed a musical production task that involved singing four-note novel melodies. To measure pitch perception, we used a simple pitch discrimination task in which participants indicated whether a target pitch was higher or lower than a comparison pitch. We also used self-report measures to address language and musical background. We report that singing ability, but not self-reported musical experience nor pitch discrimination ability, was a unique predictor of vocal emotion recognition accuracy. These results support a relationship between processes involved in vocal production and vocal perception, and suggest that sensorimotor processing of the vocal system is recruited for processing vocal prosody.
C1 [Greenspon, Emma B.; Montanaro, Victor] Monmouth Univ, Dept Psychol, West Long Branch, NJ 07764 USA.
C3 Monmouth University
RP Greenspon, EB (corresponding author), Monmouth Univ, Dept Psychol, West Long Branch, NJ 07764 USA.
EM egreensp@monmouth.edu
CR Atkinson AL, 2021, J EXP PSYCHOL LEARN, V47, P747, DOI 10.1037/xlm0000979
   Aubé W, 2015, SOC COGN AFFECT NEUR, V10, P399, DOI 10.1093/scan/nsu067
   Ayotte J, 2002, BRAIN, V125, P238, DOI 10.1093/brain/awf028
   Aziz-Zadeh L, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0008759
   Banissy MJ, 2012, NEUROIMAGE, V62, P2034, DOI 10.1016/j.neuroimage.2012.05.081
   Banissy MJ, 2010, J NEUROSCI, V30, P13552, DOI 10.1523/JNEUROSCI.0786-10.2010
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Boersma P., 2021, Glot International
   Christiner M, 2022, LANGUAGES-BASEL, V7, DOI 10.3390/languages7020072
   Christiner M, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00482
   Christiner M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00874
   Correia AI, 2022, EMOTION, V22, P894, DOI 10.1037/emo0000770
   Correia AI, 2019, NEUROIMAGE, V201, DOI 10.1016/j.neuroimage.2019.116052
   Coutinho E, 2013, COGNITION EMOTION, V27, P658, DOI 10.1080/02699931.2012.732559
   Demorest SM, 2001, B COUN RES MUSIC ED, P63
   Demorest SM, 2007, J RES MUSIC EDUC, V55, P190, DOI 10.1177/002242940705500302
   Demorest SM, 2015, MUSIC PERCEPT, V32, P266, DOI 10.1525/MP.2015.32.3.266
   Dibben N, 2018, FRONT BEHAV NEUROSCI, V12, DOI 10.3389/fnbeh.2018.00184
   Dmitrieva E S, 2006, Neurosci Behav Physiol, V36, P53, DOI 10.1007/s11055-005-0162-6
   FFmpeg, 2021, FFMPEG TOOL
   FindingFive Team, 2019, FindingFive: A Web Platform for Creating, Running, and Managing your Studies in One Place. FindingFive Corporation (nonprofit), NJ
   FRICK RW, 1985, PSYCHOL BULL, V97, P412, DOI 10.1037/0033-2909.97.3.412
   Fuller CD, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00179
   Gerry D, 2012, DEVELOPMENTAL SCI, V15, P398, DOI 10.1111/j.1467-7687.2012.01142.x
   Globerson E, 2015, AUTISM RES, V8, P153, DOI 10.1002/aur.1432
   Globerson E, 2013, ATTEN PERCEPT PSYCHO, V75, P1799, DOI 10.3758/s13414-013-0518-x
   Good A, 2017, EAR HEARING, V38, P455, DOI 10.1097/AUD.0000000000000402
   Greenspon E. B., 2020, Auditory Perception Cognition, V3, P76, DOI [DOI 10.1080/25742442.2020.1866428, 10.1080/25742442.2020.1866428]
   Greenspon EB, 2019, ATTEN PERCEPT PSYCHO, V81, P2473, DOI 10.3758/s13414-019-01799-0
   Greenspon EB, 2017, MUSIC PERCEPT, V34, P585, DOI 10.1525/MP.2017.34.5.585
   Herholz SC, 2012, J COGNITIVE NEUROSCI, V24, P1382, DOI 10.1162/jocn_a_00216
   Honda, 2022, REMOTELY COLLE UNPUB
   Hutchins S, 2014, ATTEN PERCEPT PSYCHO, V76, P2522, DOI 10.3758/s13414-014-0732-1
   Hutchins S, 2012, J EXP PSYCHOL GEN, V141, P76, DOI 10.1037/a0025064
   James W., 1884, Mind, V9, P188, DOI DOI 10.1093/MIND/OS-IX.34.188
   Jiang J, 2015, J AUTISM DEV DISORD, V45, P2067, DOI 10.1007/s10803-015-2370-4
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Lima CF, 2016, TRENDS NEUROSCI, V39, P527, DOI 10.1016/j.tins.2016.06.003
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Liu F, 2013, ATTEN PERCEPT PSYCHO, V75, P1783, DOI 10.3758/s13414-013-0506-1
   Livingstone SR, 2009, MUSIC PERCEPT, V26, P475, DOI 10.1525/MP.2009.26.5.475
   Mantell JT, 2013, COGNITION, V127, P177, DOI 10.1016/j.cognition.2012.12.008
   Nussbaum C, 2021, EMOT REV, V13, P211, DOI 10.1177/17540739211022803
   Park M, 2015, FRONT HUM NEUROSCI, V8, DOI [10.3389/fnhurn.2014.01049, 10.3389/fnhum.2014.01049]
   Patel AD, 2014, HEARING RES, V308, P98, DOI 10.1016/j.heares.2013.08.011
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Pell MD, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027256
   Petrides KV, 2006, PSICOTHEMA, V18, P101
   Pfordresher P. Q., 2019, AUDITORY PERCEPTION, V2, P67, DOI DOI 10.1080/25742442.2019.1663716
   Pfordresher PQ, 2007, MUSIC PERCEPT, V25, P95, DOI 10.1525/MP.2007.25.2.95
   Pfordresher PQ, 2015, MUSIC PERCEPT, V32, P242, DOI 10.1525/MP.2015.32.3.242
   Pfordresher PQ, 2014, COGNITIVE PSYCHOL, V70, P31, DOI 10.1016/j.cogpsych.2013.12.005
   Pfordresher PQ, 2013, PSYCHON B REV, V20, P747, DOI 10.3758/s13423-013-0401-8
   Pichon S, 2013, J NEUROSCI, V33, P1640, DOI 10.1523/JNEUROSCI.3530-12.2013
   Saarimäki H, 2016, CEREB CORTEX, V26, P2563, DOI 10.1093/cercor/bhv086
   Sander D, 2005, NEUROIMAGE, V28, P848, DOI 10.1016/j.neuroimage.2005.06.023
   Schelinski S, 2019, J AUTISM DEV DISORD, V49, P68, DOI 10.1007/s10803-018-3681-z
   Schellenberg EG, 2011, MUSIC PERCEPT, V29, P185, DOI 10.1525/MP.2011.29.2.185
   Scherer KR, 2009, COGNITION EMOTION, V23, P1307, DOI 10.1080/02699930902928969
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Stel M, 2008, PSYCHOL SCI, V19, P984, DOI 10.1111/j.1467-9280.2008.02188.x
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Thompson WF, 2012, P NATL ACAD SCI USA, V109, P19027, DOI 10.1073/pnas.1210344109
   Trimmer CG, 2008, EMOTION, V8, P838, DOI 10.1037/a0014080
   WAGNER HL, 1993, J NONVERBAL BEHAV, V17, P3, DOI 10.1007/BF00987006
   Wang L, 2021, AUTISM RES, V14, P2355, DOI 10.1002/aur.2569
   Yang WX, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01024
   Yehia H, 1998, SPEECH COMMUN, V26, P23, DOI 10.1016/S0167-6393(98)00048-X
   Zhang YX, 2018, INTERSPEECH, P2196, DOI 10.21437/Interspeech.2018-91
NR 69
TC 0
Z9 0
U1 2
U2 8
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD JAN
PY 2023
VL 85
IS 1
BP 234
EP 243
DI 10.3758/s13414-022-02613-0
EA NOV 2022
PG 10
WC Psychology; Psychology, Experimental
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Psychology
GA 7Q7BM
UT WOS:000884191300002
PM 36380148
OA Bronze
DA 2024-01-09
ER

PT J
AU Juntunen, ML
   Arlin, EP
   Liira, K
AF Juntunen, Marja-Leena
   Arlin, Elina P. P.
   Liira, Katri
TI Expression in popular music singing as embodied and interpersonal
SO FRONTIERS IN EDUCATION
LA English
DT Article
DE expression; singing; popular music; voice pedagogy; embodiment;
   phenomenology; Merleau-Ponty
ID VOCAL EXPRESSION; PERFORMANCE; PERCEPTION; EMOTIONS; VOICE
AB This article presents theoretical viewpoints for considering and understanding expression in popular music singing and pedagogy from the perspective of embodiment as outlined in Merleau-Ponty's phenomenological philosophy. In our study, we apply his interpretations of such notions as intentionality, body schema, gesture, reversibility, and intersubjectivity to bring forth and discuss the holistic, embodied, and interpersonal nature of voice expression in singing. We argue that expression should be viewed as an intentional activity, based on the body's innate mindful functioning as a whole, and in singing guided by the lyrics and emotions to be communicated. We propose that this requires a "free voice", based on healthy vocal production, that also allows for the immediacy of expression as and through gestures that bring the meaning into existence. We further argue that expression is an interpersonal, interactive, and intersubjective process in which the performer and listener influence each other in many ways. The reversibility of perception in expression means that perception and the object perceived are intertwined and action and perception are interconnected. There is also a gap in reversibility, which implies that the perception of (one's own) expression is never complete. In addition to our theoretical arguments, we make pedagogical suggestions, such as that the body itself has a lot of understanding of how and should be trusted in singing, both in terms of voice production and expression. The expression should not be primarily approached as a technical issue but taught in connection with and through expression. The expression should be viewed from the inside out, not the opposite. This means that expression builds on one's personality and (emotional) experiences.
C1 [Juntunen, Marja-Leena; Arlin, Elina P. P.; Liira, Katri] Univ Arts Helsinki, Sibelius Acad, Dept Mus Educ, Helsinki, Finland.
C3 University of the Arts Helsinki
RP Juntunen, ML (corresponding author), Univ Arts Helsinki, Sibelius Acad, Dept Mus Educ, Helsinki, Finland.
EM marja-leena.juntunen@uniarts.fi
OI Juntunen, Marja-Leena/0000-0003-0036-3592
FU University of the Arts Helsinki (Taideyliopisto) [32000320,
   003725003056, 003703575029]
FX This work was supported by the University of the Arts Helsinki
   (Taideyliopisto) 32000320/Ollikainen Electronic invoice: University of
   the Arts Helsinki EDI ID: 003725003056 e-invoice operator: CGI Operator
   ID: 003703575029 Print or PDF invoice: University of the Arts Helsinki
   P.O. Box 775 00074 CGI.
CR [Anonymous], 1996, DISCOVER YOUR VOICE
   [Anonymous], 2010, The Solo Singer in the Choral Setting: A Handbook for Achieving Vocal Health
   [Anonymous], 2014, OXFORD HDB SINGING
   [Anonymous], 2007, Music Education Research, DOI DOI 10.1080/14613800701587761
   [Anonymous], 2003, Psychology of Music, DOI [DOI 10.1177/03057356030313003, 10.1177/03057356030313003]
   [Anonymous], 2011, Psychomusicology: Music, Mind Brain, DOI [10.1037/h0094011, DOI 10.1037/H0094011]
   [Anonymous], 1996, On the art of singing
   [Anonymous], 2001, Music and Emotion, DOI DOI 10.1525/MP.2004.21.4.561
   Anttila E., 2018, P BOD KNOWL EMB COGN
   Blin F, 2016, LANG STUD SCI ENGINE, V2, P41, DOI 10.1075/lsse.2.03bli
   Bohme G., 2014, DIALOG U, V24, P54, DOI [10.5840/du201424490, DOI 10.5840/DU201424490]
   Bowman W., 2007, INT HDB RES ARTS ED
   Brown N., 2006, CONTEMP MUSIC REV, V25, P37, DOI DOI 10.1080/07494460600647410
   Buccino G, 2004, BRAIN LANG, V89, P370, DOI 10.1016/S0093-934X(03)00356-0
   Bunch D. M., 2005, PERFORMERS VOICE REA
   Carter T., 2005, CHORAL CHARISMA SING
   Dillon M.C., 1997, Merleau-Ponty's Ontology
   Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417
   Flood VJ, 2020, ZDM-MATH EDUC, V52, P1307, DOI 10.1007/s11858-020-01165-7
   Ford B., 2013, MUSIC PERFORMANCE RE, V6, P152
   Gallagher S., 2008, The Phenomenological Mind
   Gallagher S., 2005, How the body shapes the mind
   Gilman M., 2018, OXFORD HDB MUSIC BOD
   Grape C, 2003, INTEGR PHYS BEH SCI, V38, P65
   Hakanpaa T., 2022, THESIS TAMPERE U
   Hakanpää T, 2019, J VOICE, V33, P501, DOI 10.1016/j.jvoice.2018.01.012
   HEUER H, 1984, PSYCHOL HUMAN MOVEME
   Hoffmann S., 2016, THESIS COLUMBIA U
   Holmgren C., 2022, THESIS LULEA U TECHN
   Hughes D., 2014, TEACHING SINGING 21
   Hughes D., 2017, ROUTLEDGE RES COMPAN
   Hughes D., 2014, AUST VOICE, V16, P25
   Hughes Diane., 2015, Journal of Singing, V71, P587
   Iacoboni M, 2005, PLOS BIOL, V3, P529, DOI 10.1371/journal.pbio.0030079
   Iacoboni M, 2002, BEHAV BRAIN SCI, V25, P39, DOI 10.1017/S0140525X02420018
   Johnson J., 2019, OXFORD HDB VOICE STU
   Johnson M, 2006, EURAMERICA, V36, P1
   Johnson Mark, 2007, The Meaning of the Body: Aesthetics of Human Understanding
   Johnson-Glenberg MC, 2014, J EDUC PSYCHOL, V106, P86, DOI 10.1037/a0034008
   Juntunen M.-L., 2017, FINNISH J MUSIC ED, V20, P117
   Juntunen M.-L., 2001, Music Education Research, V3, P203, DOI [DOI 10.1080/14613800120089250, 10.1080/14613800120089250]
   Juntunen ML, 2020, INT J EDUC ARTS, V21, P1, DOI 10.26209/ijea21n29
   JUNTUNEN Marja-Leena, 2020, International Journal of Music in Early Childhood, V15, P39
   Juslin P. N., 2011, HDB MUSIC EMOTION TH
   Juslin PN, 2018, J NONVERBAL BEHAV, V42, P1, DOI 10.1007/s10919-017-0268-x
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Jusslin S, 2022, EDUC RES REV-NETH, V37, DOI 10.1016/j.edurev.2022.100480
   Kobel M, 2020, J CULT RES, V24, P236, DOI 10.1080/14797585.2020.1806439
   Kronengold C., 2005, Popular Music, V24, P381, DOI DOI 10.1017/S0261143005000589
   Kross E., 2021, Chatter: The Voice in Our Head, Why it Matters, and How to Harness it
   Lakoff G., 1999, PHILOS FLESH
   Lakoff G., 1980, Metaphors We Live by, DOI DOI 10.7208/CHICAGO/9780226470993.001.0001
   Laukka P, 2005, COGNITION EMOTION, V19, P633, DOI 10.1080/02699930441000445
   Laukkanen A.-M., 2001, IHMEELLINEN IHMISAAN
   Leder Drew, 1990, The Absent Body
   Leech -Wilkinson Daniel, 2012, Music Theory Online, V18
   Leitan N. D., 2014, SENSORIA J MIND BRAI, V10, P3, DOI [DOI 10.7790/SA.V10I1.384, 10.7790/sa.v10i1.384]
   Leman M, 2014, EMPIR MUSICOL REV, V9, P236
   Levin K, 2016, CONT PHILOS REV, V49, P181, DOI 10.1007/s11007-016-9376-2
   LoVetri J. L., 2014, TEACHING SINGING 21, P53
   Lundqvist LO, 2009, PSYCHOL MUSIC, V37, P61, DOI 10.1177/0305735607086048
   Maturana Humberto R., 1980, Autopoiesis and cognition: The realization of the living
   McNeill D., 1992, Hand and mind: What gestures reveal about thought
   Merleau-Ponty M., 1965, STRUCTURE BEHAV
   Merleau-Ponty Maurice, 2007, Merleau-Ponty Reader
   MERLEAU-PONTY Maurice, 1968, The visible and the invisible
   Merleau-Ponty Maurice, 2002, Phenomenology of Perception
   Middleton Richard., 2000, CAMBRIDGE COMPANION
   Morris D., 2014, MERLEAU PONTY KEY CO
   Nielzen S., 1982, Psychology of Music, V10, P7, DOI [DOI 10.1177/0305735682102002, 10.1177/0305735682102002]
   Olkkonen S., 2013, ACTA SCENICA, V33
   Ostwald David F., 2005, Acting for Singers: Creating Believable Characters
   Paparo SA, 2016, INT J MUSIC EDUC, V34, P488, DOI 10.1177/0255761415569366
   Parviainen J., 1998, THESIS TAMPERE U TAM
   Pavese C, 2021, PHILOS PERSPECT, V35, P359, DOI 10.1111/phpe.12150
   PLAVSA D, 1981, INT REV AESTHET SOC, V12, P65, DOI 10.2307/836827
   Priest Stephen, 1998, Merleau-Ponty
   Reynaert P., 2009, PHENOMENOLOGY EXISTE
   Rodger MWM, 2012, HUM MOVEMENT SCI, V31, P1137, DOI 10.1016/j.humov.2012.02.012
   Rodrigues H. M., 2009, COMMUNICATIVE MUSICA
   Rouhiainen L., 2011, TAITEEN JALKI TAIDEP
   Sadolin C., 2000, Complete vocal technique
   Sanders M., 2014, MERLEAU PONTY KEY CO
   Scherer KR, 2017, J ACOUST SOC AM, V142, P1805, DOI 10.1121/1.5002886
   Schiavio A, 2014, EMPIR MUSICOL REV, V9, P254
   Schutz M, 2008, EMPIR MUSICOL REV, V3, P83, DOI 10.18061/1811/34098
   Sell K., 2003, THESIS MIDDLESEX U L
   Shapiro L, 2014, ROUTLEDGE HBK PHILOS, P1
   Skulmowski A, 2018, COGN RES, V3, DOI 10.1186/s41235-018-0092-9
   Soto-Morettini D., 2006, POPULAR SINGING PRAC
   Steinhauer K, 2017, The Estill voice model: theory & translation
   Stephens V, 2008, AM MUSIC, V26, P156, DOI 10.2307/40071702
   Stolz SA, 2015, EDUC PHILOS THEORY, V47, P474, DOI 10.1080/00131857.2013.879694
   Studer RK, 2014, APPL PSYCHOPHYS BIOF, V39, P45, DOI 10.1007/s10484-014-9240-2
   Symonds D, 2007, STUD MUSICAL THEATRE, V1, P167, DOI 10.1386/smt.1.2.167_1
   Tarvainen A., 2018, AESTHETIC EXPERIENCE
   Tarvainen A., 2008, MUSIIKKI, V1, P18
   Tarvainen A., 2019, The Journal of Somaesthetics, V5, P8
   Tarvainen A., 2018, PRAGMATISM TODAY, V9, P91, DOI [10.22381/PT91120189, DOI 10.22381/PT91120189]
   Thurman L., 2000, BODYMIND VOICE FDN V, V1
   Tiili M. L., 2011, ELORE, V18, P85, DOI [10.30666/elore.78958, DOI 10.30666/ELORE.78958]
   Tobolski E., 2002, VASTA, V16, P18
   Uniarts, 2022, STUD GUID POP JAZZ V
   Varela FJ, 2016, EMBODIED MIND: COGNITIVE SCIENCE AND HUMAN EXPERIENCE, P1
   Varto J., 2001, KAUNEUDEN TAITO ESTE
   Yang D., 2009, 2009 11 IEEE INT S M
   Zahavi D., 2004, PHENOMENOL COGN SCI, V3, P331, DOI DOI 10.1023/B:PHEN.0000048935.94012.4E
NR 108
TC 0
Z9 0
U1 5
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2504-284X
J9 FRONT EDUC
JI Front. Educ.
PD MAY 30
PY 2023
VL 8
AR 1092736
DI 10.3389/feduc.2023.1092736
PG 10
WC Education & Educational Research
WE Emerging Sources Citation Index (ESCI)
SC Education & Educational Research
GA J0CN2
UT WOS:001006370000001
OA gold
DA 2024-01-09
ER

PT J
AU de Freitas, EF
AF de Freitas, Eliane Faleiro
TI CONTRIBUTIONS OF THE MUSICTHERAPIC TREATMENT FOR THE PATIENT WITH VOCAL
   DISORDER
SO MUSICA HODIE
LA Portuguese
DT Article
DE Music therapy; Vocal disorder; Treatment
AB In this study it is considered emotional dimension of the dysphonic patient in music therapy dysphonic patient in the music therapy process, promoting the expression of the patient through the not-verbal canal. This qualitative research was developed with three patients of the feminine sex in voices therapy treatment during a period of four months. The main objective of the research was to investigate as the Music Therapy can contribute for the treatment of the person with vocal disorder. Specifically it was looked to observe which the possibilities of opening of the not-verbal communication channel through the music therapy treatment, as well as promoting the reflection on the involved aspects in the establishment of the modified vocal behavior. The Music Therapy shows as to proposal efficient that propitiates to the dysphonic the expression of its emotions and feelings in a intent context to its necessities, preventing the occurrence of vocal abuse.
C1 PUC Goias, Goiania, Go, Brazil.
RP de Freitas, EF (corresponding author), PUC Goias, Goiania, Go, Brazil.
EM elianefaleiro@globo.com
CR [Anonymous], DEFININDO MUSICOTERA
   Behlau M, 1995, AVALIACAO TRATAMENTO
   BLOCH Pedro, 1986, MELHORE SUA VOZ TEOR
   BLOCH Pedro, 1980, FALAR BEM VIVER MELH
   Brandi E., 1990, VOZ FALADA ESTUDO AV
   MACFARLANE Stephen C., 2003, VOZ TERAPIA VOCAL
   Souza OC, 2005, REV CEFAC, V7, P388
   Turato ER, 2003, Tratado da metodologia da pesquisa clinico-qualitativa
NR 8
TC 0
Z9 0
U1 0
U2 2
PU UNIV FEDERAL GOIAS
PI GOIANIA GO
PA ESCOLA MUSICA ARTES CIENCIAS, PROG POT-GRAD MUSICA, CAIXA POSTAL 131,
   CAMPUS II-SAMAMBAIA, GOIANIA GO, CEP74001-970, BRAZIL
SN 1676-3939
J9 MUSICA HODIE
JI Musica Hodie
PY 2011
VL 11
IS 1
BP 171
EP 181
PG 11
WC Music
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music
GA 858PL
UT WOS:000297813400010
DA 2024-01-09
ER

PT J
AU Vidas, D
   Calligeros, R
   Nelson, NL
   Dingle, GA
AF Vidas, Dianna
   Calligeros, Renee
   Nelson, Nicole L.
   Dingle, Genevieve A.
TI Development of emotion recognition in popular music and vocal bursts*
SO COGNITION & EMOTION
LA English
DT Article
DE Emotion recognition; development; music; lyrics; vocal bursts
ID CHILDRENS INTERPRETATION; SPEECH PROSODY; CUES; EXPRESSION;
   DIFFERENTIATION; PERFORMANCE; EXPERIENCE
AB Previous research on the development of emotion recognition in music has focused on classical, rather than popular music. Such research does not consider the impact of lyrics on judgements of emotion in music, impact that may differ throughout development. We had 172 children, adolescents, and adults (7- to 20-year-olds) judge emotions in popular music. In song excerpts, the melody of the music and the lyrics had either congruent valence (e.g. happy lyrics and melody), or incongruent valence (e.g. scared lyrics, happy melody). We also examined participants' judgements of vocal bursts, and whether emotion identification was linked to emotion lexicon. Recognition of emotions in congruent music increased with age. For incongruent music, age was positively associated with judging the emotion in music by the melody. For incongruent music with happy or sad lyrics, younger participants were more likely to answer with the emotion of the lyrics. For scared incongruent music, older adolescents were more likely to answer with the lyrics than older and younger participants. Age groups did not differ on their emotion lexicons, nor recognition of emotion in vocal bursts. Whether children use lyrics or melody to determine the emotion of popular music may depend on the emotion conveyed.
C1 [Vidas, Dianna; Calligeros, Renee; Nelson, Nicole L.; Dingle, Genevieve A.] Univ Queensland, Sch Psychol, St Lucia, Qld, Australia.
C3 University of Queensland
RP Vidas, D (corresponding author), Univ Queensland, Sch Psychol, St Lucia, Qld, Australia.
EM dianna.vidas@uq.net.au
RI Vidas, Dianna/AFH-1911-2022; Vidas, Dianna/AAF-2327-2022; Nelson,
   Nicole/P-1078-2014
OI Vidas, Dianna/0000-0003-0574-5610; Vidas, Dianna/0000-0003-0574-5610;
   Dingle, Genevieve/0000-0002-4915-169X; Nelson,
   Nicole/0000-0001-8299-4798
CR Adachi M., 1998, PSYCHOL MUSIC, V26, P133, DOI [DOI 10.1177/0305735698262003, 10.1177/0305735698262003]
   Aguert M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0083657
   Ali SO., 2006, Psychology of Music, V34, P511, DOI DOI 10.1177/0305735606067168
   Anderson CA, 2003, J PERS SOC PSYCHOL, V84, P960, DOI 10.1037/0022-3514.84.5.960
   [Anonymous], MUSIC EMOTION THEORY
   [Anonymous], PYSCHOL MUSIC, DOI DOI 10.1177/0305735603031001325
   Baron-Cohen Simon, 2010, Front Evol Neurosci, V2, P109, DOI 10.3389/fnevo.2010.00109
   Belfi AM, 2018, J EXP PSYCHOL GEN, V147, P1531, DOI 10.1037/xge0000474
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Ciarrochi J, 2008, J ADOLESCENCE, V31, P565, DOI 10.1016/j.adolescence.2007.10.004
   Coutinho E, 2013, COGNITION EMOTION, V27, P658, DOI 10.1080/02699931.2012.732559
   CUNNINGHAM JG, 1988, MOTIV EMOTION, V12, P399, DOI 10.1007/BF00992362
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Dingle G. A., 2019, HDB MUSIC ADOLESCENC, P25, DOI DOI 10.1093/OSO/9780198808992.003.0003
   Dingle GA, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00859
   Dolgin KG., 1990, Psychol. Music, V18, P87, DOI DOI 10.1177/0305735690181007
   Eerola T, 2013, MUSIC PERCEPT, V30, P307, DOI [10.1525/mp.2012.30.3.307, 10.1525/MP.2012.30.1.49]
   Franco F, 2017, PSYCHOL MUSIC, V45, P131, DOI 10.1177/0305735616652954
   Gil S, 2016, DEV PSYCHOL, V52, P1064, DOI 10.1037/dev0000121
   Greasley AE, 2011, MUSIC SCI, V15, P45, DOI 10.1177/1029864910393417
   Grosbras MH, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32868-3
   Hawk ST, 2009, EMOTION, V9, P293, DOI 10.1037/a0015178
   Hunter PG, 2011, EMOTION, V11, P1068, DOI 10.1037/a0023749
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Juslin PN, 2013, PHYS LIFE REV, V10, P235, DOI 10.1016/j.plrev.2013.05.008
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Laukka P, 2007, MOTIV EMOTION, V31, P182, DOI 10.1007/s11031-007-9063-z
   McFerran KS, 2015, NORD J MUSIC THER, V24, P187, DOI 10.1080/08098131.2014.908942
   Morton J.B., 2007, PSYCHOL MUSIC, V35, P629, DOI [DOI 10.1177/0305735607076445, 10.1177/0305735607076445]
   Morton JB, 2001, CHILD DEV, V72, P834, DOI 10.1111/1467-8624.00318
   Nelson NL, 2011, J EXP CHILD PSYCHOL, V110, P52, DOI 10.1016/j.jecp.2011.03.014
   Nook EC, 2018, PSYCHOL SCI, V29, P1346, DOI 10.1177/0956797618773357
   Nook EC, 2017, NAT HUM BEHAV, V1, P881, DOI 10.1038/s41562-017-0238-7
   North AC, 2000, BRIT J EDUC PSYCHOL, V70, P255, DOI 10.1348/000709900158083
   Papinczak ZE, 2015, J YOUTH STUD, V18, P1119, DOI 10.1080/13676261.2015.1020935
   Quam C, 2012, CHILD DEV, V83, P236, DOI 10.1111/j.1467-8624.2011.01700.x
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Russell JA, 2002, SOC DEV, V11, P30, DOI 10.1111/1467-9507.00185
   Saarikallio S., 2007, Psychol. Music, V35, P88, DOI [10.1177/0305735607068889, DOI 10.1177/0305735607068889]
   Saarikallio S, 2015, CHILD ADOL MENT H-UK, V20, P210, DOI 10.1111/camh.12109
   Sauter DA, 2013, BRIT J DEV PSYCHOL, V31, P97, DOI 10.1111/j.2044-835X.2012.02081.x
   Schellenberg EG, 2012, PSYCHOL AESTHET CREA, V6, P196, DOI 10.1037/a0028024
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Sharman L, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00272
   Spackman MP, 2006, INT J LANG COMM DIS, V41, P173, DOI 10.1080/13682820500224091
   *SPOT, 2019, GET AUD FEAT TRACK
   Stachó L, 2013, MUSIC SCI, V17, P495, DOI 10.1177/1029864913497617
   Stack S, 2012, SUICIDE LIFE-THREAT, V42, P654, DOI 10.1111/j.1943-278X.2012.00120.x
   Thompson W. F., 2018, PSYCHOL POPULAR MEDI, DOI 10.1037/ppm0000184
   Trainor LJ, 2000, PSYCHOL SCI, V11, P188, DOI 10.1111/1467-9280.00240
   Vidas D., 2018, Music & Science, V1, DOI [10.1177/2059204318762650, DOI 10.1177/2059204318762650, 10.1177/]
   WAGNER HL, 1993, J NONVERBAL BEHAV, V17, P3, DOI 10.1007/BF00987006
   Widen SC, 2013, EMOT REV, V5, P72, DOI 10.1177/1754073912451492
   Widen SC, 2010, EMOTION, V10, P651, DOI 10.1037/a0019005
NR 54
TC 5
Z9 5
U1 3
U2 48
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 0269-9931
EI 1464-0600
J9 COGNITION EMOTION
JI Cogn. Emot.
PD JUL 3
PY 2020
VL 34
IS 5
BP 906
EP 919
DI 10.1080/02699931.2019.1700482
EA DEC 2019
PG 14
WC Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA MO1XU
UT WOS:000501059200001
PM 31805815
DA 2024-01-09
ER

PT J
AU Spreadborough, KL
   Anton-Mendez, I
AF Spreadborough, Kristal L.
   Anton-Mendez, Ines
TI It's not what you sing, it's how you sing it: How the emotional valence
   of vocal timbre influences listeners' emotional perception of words
SO PSYCHOLOGY OF MUSIC
LA English
DT Article
DE analysis; emotional perception; lexical processing; popular music; vocal
   timbre
ID INTERFERENCE; VOICE; TONE
AB Here we present an investigation into whether vocal timbre impacts on emotional perception of sung words, and whether this effect is intersubjective. That is, does vocal timbre influence the processing of emotion in words, and does it do so in a similar way across listeners? If so, this could help overcome the lack of appropriate analytical techniques for vocal timbre analysis in popular music by approaching such analysis from the perspective of vocal timbres emotive content and how this emotive content impacts emotional perception of sung words (lyrics), specifically in popular, lyric-based, vocal songs. The results of a reception test on emotional word perception according to timbre valence show that participants are significantly less accurate in identifying the emotional valence of words when they are sung with a vocal timbre that has an incongruent emotional valence and, for sad words, they are also slower in arriving at a correct identification of the word's emotional valence when sung with an emotionally incongruent timbre. This supports the hypothesis that timbre conveys emotional meaning and that the experience of vocal timbre may be intersubjective.
C1 [Spreadborough, Kristal L.; Anton-Mendez, Ines] Univ New England, Armidale, NSW, Australia.
C3 University of New England
RP Spreadborough, KL (corresponding author), Univ New England, Fac Humanities Arts Social Sci & Educ, Bldg E11,Room 181, Armidale, NSW 2351, Australia.
EM kspread2@une.edu.au
OI Anton-Mendez, Ines/0000-0003-1237-8126; Spreadborough,
   Kristal/0000-0002-7022-3213
FU Australian Postgraduate Award; Faculty of Humanities, Arts, Social
   Sciences and Education, University of New England (Australia)
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This work
   was supported by the Australian Postgraduate Award, the Faculty of
   Humanities, Arts, Social Sciences and Education, University of New
   England (Australia).
CR [Anonymous], 2011, HDB MUSIC EMOTION TH
   [Anonymous], 1999, Psychology
   [Anonymous], 1977, STUDIES MUSICOLOGY 1
   Baumeister R. F., 2001, Rev. Gen. Psychol, V5, P323, DOI [DOI 10.1037/1089-2680.5.4.323, 10.1037/1089-2680.5.4.323]
   Bregman A.S., 1990, AUDITORY SCENE ANAL, DOI DOI 10.7551/MITPRESS/1486.001.0001
   Foster J., 2015, DMDX 5 1 3 4
   Grimshaw GM, 1998, BRAIN COGNITION, V36, P108, DOI 10.1006/brcg.1997.0949
   Hajda J. M., 2004, PERCEPTION COGNITION, P253
   HANSEN CH, 1988, J PERS SOC PSYCHOL, V54, P917, DOI 10.1037/0022-3514.54.6.917
   Houtsma AJM, 1997, J NEW MUSIC RES, V26, P104, DOI 10.1080/09298219708570720
   Ihde D., 2007, Listening and Voice: Phenomenologies of Sound
   Juslin P.N., 2001, SERIES AFFECTIVE SCI, P309
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Kitayama S, 2002, COGNITION EMOTION, V16, P29, DOI 10.1080/0269993943000121
   Krestar ML, 2013, Q J EXP PSYCHOL, V66, P1793, DOI 10.1080/17470218.2013.766897
   LEWICKA M, 1992, EUR J SOC PSYCHOL, V22, P425, DOI 10.1002/ejsp.2420220502
   LIMA SD, 1991, PSYCHOL AGING, V6, P416, DOI 10.1037/0882-7974.6.3.416
   MACLEOD CM, 1991, PSYCHOL BULL, V109, P163, DOI 10.1037/0033-2909.109.2.163
   Nygaard LC, 2002, MEM COGNITION, V30, P583, DOI 10.3758/BF03194959
   Nygaard LC, 2008, J EXP PSYCHOL HUMAN, V34, P1017, DOI 10.1037/0096-1523.34.4.1017
   Rinkenauer G, 2004, J EXP PSYCHOL GEN, V133, P261, DOI 10.1037/0096-3445.133.2.261
   Rozin P, 2001, PERS SOC PSYCHOL REV, V5, P296, DOI 10.1207/S15327957PSPR0504_2
   Schirmer A, 2003, J COGNITIVE NEUROSCI, V15, P1135, DOI 10.1162/089892903322598102
   Stroop JR, 1935, J EXP PSYCHOL, V18, P643, DOI 10.1037/h0054651
   WICKELGREN WA, 1977, ACTA PSYCHOL, V41, P67, DOI 10.1016/0001-6918(77)90012-9
   Wurm LH, 2004, PSYCHOL AGING, V19, P523, DOI 10.1037/0882-7974.19.3.523
NR 26
TC 4
Z9 5
U1 2
U2 25
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0305-7356
EI 1741-3087
J9 PSYCHOL MUSIC
JI Psychol. Music
PD MAY
PY 2019
VL 47
IS 3
BP 407
EP 419
DI 10.1177/0305735617753996
PG 13
WC Psychology, Educational; Psychology, Applied; Music; Psychology,
   Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Psychology; Music
GA HP6NR
UT WOS:000461802200007
DA 2024-01-09
ER

PT J
AU Baskent, D
   Fuller, CD
   Galvin, JJ
   Schepel, L
   Gaudrain, E
   Free, RH
AF Baskent, Deniz
   Fuller, Christina D.
   Galvin, John J., III
   Schepel, Like
   Gaudrain, Etienne
   Free, Rolien H.
TI Musician effect on perception of spectro-temporally degraded speech,
   vocal emotion, and music in young adolescents
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID COCHLEAR; CHILDREN; SENTENCES
AB In adult normal-hearing musicians, perception of music, vocal emotion, and speech in noise has been previously shown to be better than non-musicians, sometimes even with spectro-temporally degraded stimuli. In this study, melodic contour identification, vocal emotion identification, and speech understanding in noise were measured in young adolescent normal-hearing musicians and non-musicians listening to unprocessed or degraded signals. Different from adults, there was no musician effect for vocal emotion identification or speech in noise. Melodic contour identification with degraded signals was significantly better in musicians, suggesting potential benefits from music training for young cochlear-implant users, who experience similar spectro-temporal signal degradations. (C) 2018 Acoustical Society of America
C1 [Baskent, Deniz; Fuller, Christina D.; Schepel, Like; Gaudrain, Etienne; Free, Rolien H.] Univ Groningen, Univ Med Ctr Groningen, Dept Otorhinolaryngol Head & Neck Surg, Groningen, Netherlands.
   [Galvin, John J., III] House Ear Res Inst, Los Angeles, CA 90057 USA.
   [Baskent, Deniz; Fuller, Christina D.; Free, Rolien H.] Univ Groningen, Res Sch Behav & Cognit Neurosci, Grad Sch Med Sci, Groningen, Netherlands.
   [Gaudrain, Etienne] Univ Lyon, Lyon Neurosci Res, CNRS, UMR 5292,Ctr Auditory Cognit & Psychoacoust, Lyon, France.
C3 University of Groningen; House Research Institute; University of
   Groningen; Centre National de la Recherche Scientifique (CNRS); CNRS -
   National Institute for Biology (INSB); Institut National de la Sante et
   de la Recherche Medicale (Inserm); Universite Claude Bernard Lyon 1;
   Universite Jean Monnet
RP Baskent, D (corresponding author), Univ Groningen, Univ Med Ctr Groningen, Dept Otorhinolaryngol Head & Neck Surg, Groningen, Netherlands.
EM d.baskent@umcg.nl; c.d.fuller@umcg.nl; jgalvin@hei.org;
   l.schepel@franciscus.nl; etienne.gaudrain@cnrs.fr; r.h.free@umcg.nl
RI Gaudrain, Etienne/C-6713-2013
OI Gaudrain, Etienne/0000-0003-0490-0295; Baskent,
   Deniz/0000-0002-6560-1451
FU VICI from Netherlands Organization for Scientific Research (NWO)
   [918.17.603]; Netherlands Organization for Health Research and
   Development (ZonMw); Heinsius Houbolt Foundation; University Medical
   Center Groningen; VIDI from Netherlands Organization for Scientific
   Research (NWO) [016.096.397]
FX We thank Dr. Qian-jie Fu and the Emily Shannon Fu Foundation for
   providing the experimental software. We also thank three anonymous
   reviewers for helpful comments. This study was supported by VIDI Grant
   No. 016.096.397 and VICI Grant No. 918.17.603 from the Netherlands
   Organization for Scientific Research (NWO) and the Netherlands
   Organization for Health Research and Development (ZonMw), funds from
   Heinsius Houbolt Foundation, and the Rosalind Franklin Fellowship from
   University Medical Center Groningen. E.G.'s contribution was conducted
   in the framework of the LabEx CeLyA ("Centre Lyonnais d'Acoustique,"
   ANR-10-LABX-0060/ANR-11-IDEX-0007) operated by the French National
   Research Agency. This research is part of the Healthy Aging and
   Communication research program of the Otorhinolaryngology Department of
   University Medical Center Groningen.
CR Baskent D, 2016, J ACOUST SOC AM, V139, pEL51, DOI 10.1121/1.4942628
   Bosman AJ, 1995, AUDIOLOGY, V34, P260
   Chatterjee M, 2008, HEARING RES, V235, P143, DOI 10.1016/j.heares.2007.11.004
   Chen JKC, 2010, PEDIATRICS, V125, pE793, DOI 10.1542/peds.2008-3620
   Deroche MLD, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00073
   Fuller CD, 2014, JARO-J ASSOC RES OTO, V15, P1037, DOI 10.1007/s10162-014-0483-7
   Fuller CD, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00179
   Galvin JJ, 2007, EAR HEARING, V28, P302, DOI 10.1097/01.aud.0000261689.35445.20
   Gfeller K, 2016, EUR ANN OTORHINOLARY, V133, pS50, DOI 10.1016/j.anorl.2016.01.010
   Good A, 2017, EAR HEARING, V38, P455, DOI 10.1097/AUD.0000000000000402
   Goorhuis-Brouwer SM, 2000, HDB LANGUAGE DEV LAN
   Goudbeek M, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2026
   GREENWOOD DD, 1990, J ACOUST SOC AM, V87, P2592, DOI 10.1121/1.399052
   Leibold LJ, 2017, J SPEECH LANG HEAR R, V60, P3001, DOI 10.1044/2017_JSLHR-H-17-0070
   Magne C, 2006, J COGNITIVE NEUROSCI, V18, P199, DOI 10.1162/089892906775783660
   Micheyl C, 2006, HEARING RES, V219, P36, DOI 10.1016/j.heares.2006.05.004
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   PLOMP R, 1979, J ACOUST SOC AM, V66, P1333, DOI 10.1121/1.383554
   Swaminathan J, 2015, SCI REP-UK, V5, DOI 10.1038/srep11628
   Xin Luo, 2007, Trends Amplif, V11, P301
NR 20
TC 10
Z9 11
U1 1
U2 10
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD MAY
PY 2018
VL 143
IS 5
BP EL311
EP EL316
DI 10.1121/1.5034489
PG 6
WC Acoustics; Audiology & Speech-Language Pathology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Acoustics; Audiology & Speech-Language Pathology
GA GG9WB
UT WOS:000433050700001
PM 29857757
OA Green Published, Bronze
DA 2024-01-09
ER

PT J
AU Pedregal, CR
   Heaton, P
AF Pedregal, Celia Redondo
   Heaton, Pamela
TI Autism, music and Alexithymia: A musical intervention to enhance emotion
   recognition in adolescents with ASD
SO RESEARCH IN DEVELOPMENTAL DISABILITIES
LA English
DT Article
DE Autism Spectrum Disorder; Emotion recognition; Music; Alexithymia;
   Language
ID SPECTRUM DISORDERS; CHILDREN; QUESTIONNAIRE; PERCEPTION; ABILITIES;
   AWARENESS; RESPONSES; LANGUAGE; SCALE; SELF
AB Background: Difficulties identifying and describing emotions in Autism Spectrum Disorder (ASD) have been linked with an increased prevalence of Type 2 Alexithymia. Alexithymia is associated with difficulties in interpreting and verbally labelling physiological arousal. Children and adults with ASD show typical patterns of physiological arousal to music and can attribute verbal labels to musical emotions. Aim: This pilot study aimed to develop a music-based intervention to improve facial and vocal emotion recognition (ER) and Alexithymia in adolescents with ASD. Methods and procedures: Adolescents with ASD completed 5 music sessions and pre and post-tests of Alexithymia, ER and language. Each intervention began with a researcher-led group analysis of the emotions expressed in a series of musical excerpts, followed by a group-led discussion of the participants' experiences of these emotions and the ways they may be communicated. Finally, the likely causes and outward expression of these emotions were discussed. Outcome and results: Results showed that at pre-test, chronological age (CA) and receptive vocabulary were significantly associated with recognition of facial and verbal emotions and Not hiding emotions. At post-test, older children showed a greater increase in recognition of voices and in emotional bodily awareness. Correlations suggested a trend towards increased ER in voices and faces in children with lower language scores. Conclusions and implications: Music-based interventions may enhance ER in adolescents with ASD and Alexithymia. Limitations and recommendations for future investigations are discussed.
C1 [Pedregal, Celia Redondo; Heaton, Pamela] Goldsmiths Univ London, Dept Psychol, London SE14 6NW, England.
C3 University of London; Goldsmiths University London
RP Pedregal, CR (corresponding author), Goldsmiths Univ London, Dept Psychol, London SE14 6NW, England.
EM credo001@gold.ac.uk; p.heaton@gold.ac.uk
OI Redondo Pedregal, Celia/0000-0003-2104-067X
FU British Spanish Society [1080250]
FX This work was supported by the British Spanish Society (registered
   charity number 1080250).
CR Allen R, 2013, J AUTISM DEV DISORD, V43, P432, DOI 10.1007/s10803-012-1587-8
   Allen R, 2009, ANN NY ACAD SCI, V1169, P326, DOI 10.1111/j.1749-6632.2009.04772.x
   Allgood R, 2015, BRIT J DEV PSYCHOL, V33, P398, DOI 10.1111/bjdp.12097
   [Anonymous], 1997, BRIT PICTURE VOCABUL
   BAGBY RM, 1994, J PSYCHOSOM RES, V38, P23, DOI 10.1016/0022-3999(94)90005-1
   Berthoz S, 2005, EUR PSYCHIAT, V20, P291, DOI 10.1016/j.eurpsy.2004.06.013
   Bird G, 2013, TRANSL PSYCHIAT, V3, DOI 10.1038/tp.2013.61
   Bird G, 2010, BRAIN, V133, P1515, DOI 10.1093/brain/awq060
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Brennand R, 2011, RES AUTISM SPECT DIS, V5, P1567, DOI 10.1016/j.rasd.2011.03.002
   DuBois D, 2016, INT J DEV NEUROSCI, V52, P104, DOI 10.1016/j.ijdevneu.2016.05.001
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   Gebauer L, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00192
   Griffin C, 2016, AUTISM RES, V9, P773, DOI 10.1002/aur.1569
   Harms MB, 2010, NEUROPSYCHOL REV, V20, P290, DOI 10.1007/s11065-010-9138-6
   Heaton P, 1999, PSYCHOL MED, V29, P1405, DOI 10.1017/S0033291799001221
   Heaton P., 2008, BRIT J DEV PSYCHOL
   Hemming L, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00203
   Hill E, 2004, J AUTISM DEV DISORD, V34, P229, DOI 10.1023/B:JADD.0000022613.41399.14
   Hillier A, 2016, PSYCHOL MUSIC, V44, P481, DOI 10.1177/0305735615576264
   Hudac CM, 2020, AUTISM RES, V13, P1300, DOI 10.1002/aur.2332
   Järvinen-Pasley A, 2008, J AUTISM DEV DISORD, V38, P1328, DOI 10.1007/s10803-007-0520-z
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Kinnaird E, 2019, EUR PSYCHIAT, V55, P80, DOI 10.1016/j.eurpsy.2018.09.004
   Koelsch S, 2004, NAT NEUROSCI, V7, P302, DOI 10.1038/nn1197
   Laukka P, 2007, MOTIV EMOTION, V31, P182, DOI 10.1007/s11031-007-9063-z
   Lindström R, 2016, NEUROSCI LETT, V628, P47, DOI 10.1016/j.neulet.2016.06.016
   Lombardo MV, 2015, NEURON, V86, P567, DOI 10.1016/j.neuron.2015.03.023
   Milosavljevic B, 2016, J AUTISM DEV DISORD, V46, P1354, DOI 10.1007/s10803-015-2670-8
   Moseley RL, 2015, NEUROIMAGE, V104, P413, DOI 10.1016/j.neuroimage.2014.09.046
   Parker JDA, 2010, PSYCHOL ASSESSMENT, V22, P798, DOI 10.1037/a0020256
   Patel A. D., 2008, Music, Language, and the Brain
   Quintin EM, 2011, J AUTISM DEV DISORD, V41, P1240, DOI 10.1007/s10803-010-1146-0
   Rieffe C, 2008, PERS INDIV DIFFER, V45, P756, DOI 10.1016/j.paid.2008.08.001
   Shah P, 2016, CORTEX, V81, P215, DOI 10.1016/j.cortex.2016.03.021
   Silani G, 2008, SOC NEUROSCI-UK, V3, P97, DOI 10.1080/17470910701577020
   Simpson K, 2011, J AUTISM DEV DISORD, V41, P1507, DOI 10.1007/s10803-010-1172-y
   Uljarevic M, 2013, J AUTISM DEV DISORD, V43, P1517, DOI 10.1007/s10803-012-1695-5
   Williams D, 2010, AUTISM, V14, P285, DOI 10.1177/1362361309344849
   Yum YN, 2020, BMC PEDIATR, V20, DOI 10.1186/s12887-020-02454-6
NR 40
TC 2
Z9 5
U1 9
U2 37
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0891-4222
EI 1873-3379
J9 RES DEV DISABIL
JI Res. Dev. Disabil.
PD SEP
PY 2021
VL 116
AR 104040
DI 10.1016/j.ridd.2021.104040
EA JUL 2021
PG 10
WC Education, Special; Rehabilitation
WE Social Science Citation Index (SSCI)
SC Education & Educational Research; Rehabilitation
GA UD0LD
UT WOS:000686908000005
PM 34329821
DA 2024-01-09
ER

PT J
AU Chen, HH
   Liu, C
AF Chen, Huihui
   Liu, Chang
TI The perception of vocal aesthetics in digital art
SO MUSICA HODIE
LA English
DT Article
DE Aesthetics; Digital art; Music; Vocal; Voice
ID JUDGMENTS; CREATION
AB The active use of new digital technologies in the art of music is becoming the basis of a new aesthetic perception that has relevance nowadays. The possibilities of digital technology to transform the voices of performers make it relevant to consider the role of vocal aesthetics in digital music art. This study aims to investigate the features of vocal aesthetics perception in digital art. The perception of musical works as pleasant or unpleasant correlates with the psycho-emotional state of the listener; thus, to study the psycho-emotional impact of synthesized vocal without instrumental accompaniment, the authors used Kunin projective physiognomic test (1977), the WAM (Well-being, Activity, Mood) technique (1973), and the Wessman-Ricks self-assessment of mental state technique (2004). The study involved 182 students and teachers of Conservatory of Music, Communication University of Zhejiang, China. The study of the psycho-emotional state of respondents before and after listening to synthesized vocal compositions allowed the authors to indirectly evaluate the aesthetic perception of digital music art. After listening to the vocal digital fragment, which included both major and minor fragments of different tempo and rhythm, the overall mood in the group of respondents significantly improved: good mood was detected in 26.9% of cases, and very good -in 11.5%. The positive impact of listening to a vocal digital song on the well-being, activity, and mood of the respondents correlates with its positive aesthetic impact. The research confirms that aesthetic properties are directly dependent on the listener's point of view, aesthetic experience is a matter of value and emotion, and aesthetic feeling arises as a result of an unconscious process and is associated with the normalizing effect of digital vocal composition on the psycho-emotional state of the respondents. The practical significance can be presented by the further development of digital music art, considering its psycho-emotional impact on the listeners and the corresponding aesthetic perception. In further research it seems important to study the vocal component of digital music compositions, in comparison with the live voice and in combination with it. It seems promising to identify the psychological factors in the emergence of aesthetic feeling when listening to live and digital music, which will create digital music works that evoke a deeper emotional response from listeners.
C1 [Chen, Huihui] Commun Univ Zhejiang, Conservatory Musk, Hangzhou, Peoples R China.
   [Liu, Chang] Ningbo Univ, Conservatory Mus, Ningbo, Peoples R China.
C3 Communication University of Zhejiang; Ningbo University
RP Liu, C (corresponding author), Ningbo Univ, Conservatory Mus, Ningbo, Peoples R China.
EM 41010215@qq.com; 615298842@qq.com
CR Alexander J, 2015, BODY SOC, V21, P127, DOI 10.1177/1357034X13510055
   [Anonymous], 2021, PSYCHOL TESTS TRAINI
   Archer A, 2017, INQUIRY, V60, P656, DOI 10.1080/0020174X.2016.1272487
   Aschliman L, 2016, INQUIRY, V59, P632, DOI 10.1080/0020174X.2016.1208926
   Babel M, 2015, COGNITIVE SCI, V39, P766, DOI 10.1111/cogs.12179
   Bastani H, 2020, ETHNOMUSICOL FORUM, V29, P379, DOI 10.1080/17411912.2021.1896371
   Benedikter R., 2021, CHALLENGE, V64, P75, DOI [10.1080/05775132.2020.1842021, DOI 10.1080/05775132.2020.1842021]
   Calderón-Garrido D, 2020, INT J MUSIC EDUC, V38, P613, DOI 10.1177/0255761420954303
   Canazza S, 2019, COMPUT MUSIC J, V43, P58, DOI [10.1162/COMJ_a_00537, 10.1162/comj_a_00537]
   Chadabe J, 2014, MUSICA HODIE, V14, P8
   Debruyne F, 2021, RETHINKING MUSIC THROUGH SCIENCE AND TECHNOLOGY STUDIES, P256
   Elsen H, 2021, LANG SCI, V85, DOI 10.1016/j.langsci.2021.101360
   EMMERSON Simon, 2017, LIVING ELECT MUSIC
   Fornari J, 2012, MUSICA HODIE, V12, P120
   GELTEC, 2021, IMPACT ICTS EVENT MA, P123
   GUBINA, 2013, PSYCHOLOGIST, V3, P186
   Halpern MK., 2021, ROUTLEDGE HDB PUBLIC, P214
   Hanelt A, 2021, EUR J INFORM SYST, V30, P3, DOI 10.1080/0960085X.2020.1747365
   JIANG, 2016, WORLD SCI CULTURE ED, V7, P60
   JIANG, 2016, WORLD SCI CULTURE ED, V7, P48
   Kidd E, 2021, CULTIVATING ENTREPRE, P122
   Kirwan J, 2019, J AESTHET PHENOMENOL, V6, P153, DOI 10.1080/20539320.2019.1672304
   KREMER, 2021, ESPES, V9, P66
   LOU, 2018, THESIS VORONEZH STAT
   Magnusson T, 2021, J NEW MUSIC RES, V50, P175, DOI 10.1080/09298215.2021.1907420
   MELNIKOVA Yulia V., 2005, HIST MYTH CREATIVE L
   Mudd T, 2019, COMPUT MUSIC J, V43, P25, DOI 10.1162/comj_a_00535
   NATHANIEL Steven Andrew, 2021, THESIS INDIANA U
   OLENSKAYA, 2015, HLTH ALL, V2, P15
   Otterbeck J, 2020, POP MUSIC SOC, V43, P1, DOI 10.1080/03007766.2019.1581335
   Scarani S, 2019, COMPUT MUSIC J, V43, P12, DOI 10.1162/comj_a_00534
   Singh H, 2021, 2021 THIRD SOUTH AMERICAN COLLOQUIUM ON VISIBLE LIGHT COMMUNICATIONS (SACVLC 2021), P43, DOI [10.1109/SACVLC53127.2021.9652327, 10.1109/ECTIDAMTNCON51128.2021.9425707, 10.1109/CAPS52117.2021.9730658]
   Sterne J, 2021, CULT STUD, V35, P750, DOI 10.1080/09502386.2021.1895247
   Szubielska M, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0250924
   Tahiroglu K, 2021, J NEW MUSIC RES, V50, P155, DOI 10.1080/09298215.2021.1900275
   TRUBNIKOVA Nina, 2021, SHS WEB C, V114
   VINCENT Caitlin Claire, 2018, THESIS DEAKIN U
   Wilson N, 2020, J CRIT REALISM, V19, P398, DOI 10.1080/14767430.2020.1771014
   WINBORN Mark Douglas, 2015, INT J JUNGIAN STUDIE, V7, P94, DOI DOI 10.1080/19409052.2014.924424
NR 39
TC 1
Z9 1
U1 2
U2 15
PU UNIV FEDERAL GOIAS
PI GOIANIA
PA ESCOLA DE AGRONOMIA, CAMPUS SAMAMBAIA, GOIANIA, GO, BRAZIL
SN 1676-3939
J9 MUSICA HODIE
JI Musica Hodie
PY 2022
VL 22
AR e68883
DI 10.5216/mh.v22.68883
PG 23
WC Music
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music
GA ZC4YL
UT WOS:000757527600001
OA gold
DA 2024-01-09
ER

PT J
AU Broze, Y
   Paul, BT
   Allen, ET
   Guarna, KM
AF Broze, Yuri
   Paul, Brandon T.
   Allen, Erin T.
   Guarna, Kathleen M.
TI POLYPHONIC VOICE MULTIPLICITY, NUMEROSITY, AND MUSICAL EMOTION
   PERCEPTION
SO MUSIC PERCEPTION
LA English
DT Article
DE musical emotion; musical voices; multiplicity; numerosity;
   denumerability; loneliness; Well-Tempered Clavier
ID TEMPORAL NUMEROSITY; YOUNG-CHILDREN; SOCIAL-EMOTION; EXPRESSION;
   CATEGORIES; RESPONSES; EXPOSURE; STREAM; NUMBER
AB THREE EXPERIMENTAL STUDIES SUGGEST THAT music with more musical voices (higher voice multiplicity) tends to be perceived more positively. In the first experiment, participants heard brief extracts from polyphonic keyboard works representing conditions of one, two, three, or four concurrent musical voices. Two basic emotions (happiness and sadness) and two social emotions (pride and loneliness) were rated on a continuous scale. Listeners rated excerpts with higher voice multiplicity as sounding more happy, less sad, less lonely, and more proud. Results from a second experiment indicate that this effect might extend to positive and negative emotions more generally. In a third experiment, participants were asked to count (denumerate) the number of musical voices in the same stimuli. Denumeration responses corresponded closely with ratings for both positive and negative emotions, suggesting that a single musical feature or percept might play a role in both. Possible roles for both symbolic and psychoacoustic musical features are discussed.
C1 [Broze, Yuri; Paul, Brandon T.; Allen, Erin T.; Guarna, Kathleen M.] Ohio State Univ, Columbus, OH 43210 USA.
C3 University System of Ohio; Ohio State University
RP Broze, Y (corresponding author), Ohio State Univ, Sch Mus, 1866 Coll Rd, Columbus, OH 43210 USA.
EM broze.3@osu.edu
RI Paul, Brandon T./ABE-4579-2020
OI Paul, Brandon T./0000-0002-2353-7631
CR Albrecht Joshua., 2012, AFFECTIVE ANAL MUSIC
   [Anonymous], 1863, Die Lehre von den Tonempfindungen als Physiologische Grundlage fur die Theorie der Musik
   [Anonymous], 1975, LONELINESS EXPERIENC
   [Anonymous], 1966, SERIAL COMPOSITION
   [Anonymous], DARWIN FACIAL EXPRES
   [Anonymous], THE CORDED SHELL
   [Anonymous], 1993, CONTEMP MUSIC REV
   BACH J. S., 1722, WELL TEMPERED CLAVIE, V1
   Berry W., 1976, STRUCTURAL FUNCTIONS
   Blacking J., 1973, How Musical is Man
   BORNSTEIN RF, 1989, PSYCHOL BULL, V106, P265, DOI 10.1037/0033-2909.106.2.265
   Bregman A.S., 1990, AUDITORY SCENE ANAL, DOI DOI 10.7551/MITPRESS/1486.001.0001
   BREGMAN AS, 1971, J EXP PSYCHOL, V89, P244, DOI 10.1037/h0031163
   BREGMAN AS, 1978, J EXP PSYCHOL HUMAN, V4, P380, DOI 10.1037/0096-1523.4.3.380
   Burnett S, 2009, J COGNITIVE NEUROSCI, V21, P1736, DOI 10.1162/jocn.2009.21121
   Cacioppo J. T., 2008, Loneliness: Human nature and the need for social connection, DOI DOI 10.1007/S11126-022-10006-7
   Cambouropoulos E, 2008, MUSIC PERCEPT, V26, P75, DOI 10.1525/MP.2008.26.1.75
   CHEATHAM PG, 1954, J EXP PSYCHOL, V47, P425, DOI 10.1037/h0054287
   Clendinning Jane Piper, 2005, MUSICIANS GUIDE THEO
   COOPER P, 1981, PERSPECTIVES MUSIC T
   Davies M., 2020, CORPUS CONT AM ENGLI
   Davis S, 2006, MUSIC PERCEPT, V23, P423, DOI 10.1525/mp.2006.23.5.423
   Davison LL, 2003, MUSIC PERCEPT, V21, P3, DOI 10.1525/mp.2003.21.1.3
   Dehaene S, 2011, NUMBER SENSE MIND CR
   DESCOEUDRES A, 1921, DEV ENFANT 2 7 ANS
   Eisenberg N, 2000, ANNU REV PSYCHOL, V51, P665, DOI 10.1146/annurev.psych.51.1.665
   Fujioka T, 2005, J COGNITIVE NEUROSCI, V17, P1578, DOI 10.1162/089892905774597263
   Gabrielsson A, 2003, SER AFFECTIVE SCI, P503
   Gabrielsson A., 2010, HDB MUSIC EMOTION TH, P367, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0014
   Gregory AH, 1996, MOTIV EMOTION, V20, P341, DOI 10.1007/BF02856522
   HURON D, 1989, MUSIC PERCEPT, V6, P361
   HURON D, 1993, MUSIC PERCEPT, V10, P435
   HURON D, 1989, PROCEEDINGS : 1989 INTERNATIONAL COMPUTER MUSIC CONFERENCE, NOVEMBER 2-5, P131
   Huron D, 2001, MUSIC PERCEPT, V19, P1, DOI 10.1525/mp.2001.19.1.1
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Jevons W.S., 1871, NATURE, V3, P281, DOI [10.1038/003281a0, DOI 10.1038/003281A0, 10.1038/003405b0]
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kagan J., 1981, The second year: The emergence of self-awareness
   KASTNER MP, 1990, MUSIC PERCEPT, V8, P189
   KAUFMAN EL, 1949, AM J PSYCHOL, V62, P498, DOI 10.2307/1418556
   Laitz S. G., 2012, COMPLETE MUSICIAN IN
   Lakoff G, 1987, Women, fire
   LEWIS M, 1989, CHILD DEV, V60, P146, DOI 10.1111/j.1467-8624.1989.tb02704.x
   Lewis M., 1983, Children's emotions and moods
   MCCULLOCH R, 1999, MODALITY CHILDRENS A
   Merriam Alan P., 1964, The Anthropology of Music
   Minzenberg MJ, 2006, COMPR PSYCHIAT, V47, P468, DOI 10.1016/j.comppsych.2006.03.005
   Nettl B., 2005, The Study of Ethnomusicology: Thirty-one Issues and Concepts
   Ollen J. E., 2006, doctoral dissertation
   RASCH R. A., 1981, THESIS ELINKWIJK UTR
   ROSCH E, 1975, J EXP PSYCHOL GEN, V104, P192, DOI 10.1037/0096-3445.104.3.192
   ROSCH EH, 1973, COGNITIVE PSYCHOL, V4, P328, DOI 10.1016/0010-0285(73)90017-0
   ROUSSEAU J. J., 1782, COLLECTION COMPLETE, V8, P355
   Rowell L. E., 1983, Thinking About Music: An Introduction to the Philosophy of Music
   SHAVER P, 1987, J PERS SOC PSYCHOL, V52, P1061, DOI 10.1037/0022-3514.52.6.1061
   SPENCER H, 1857, FRASERS MAGAZINE, V56, P396, DOI DOI 10.1017/S0140525X08005293
   STIPEK DJ, 1990, DEV PSYCHOL, V26, P972, DOI 10.1037/0012-1649.26.6.972
   Tangney JP, 2007, ANNU REV PSYCHOL, V58, P345, DOI 10.1146/annurev.psych.56.091103.070145
   ten Hoopen G, 1979, Percept Psychophys, V26, P374
   Teroni F, 2008, CONSCIOUS COGN, V17, P725, DOI 10.1016/j.concog.2008.02.002
   Thompson WF, 2012, P NATL ACAD SCI USA, V109, P19027, DOI 10.1073/pnas.1210344109
   Tracy Jessica L., 2007, SELF CONSCIOUS EMOTI, P209
   TVERSKY A, 1974, SCIENCE, V185, P1124, DOI 10.1126/science.185.4157.1124
   VERLET B., 1993, WELL TEMPERED CLAVIE
   Webster GD, 2005, MOTIV EMOTION, V29, P19, DOI 10.1007/s11031-005-4414-0
   WHITE CT, 1963, PSYCHOL MONOGR, V77, P1, DOI 10.1037/h0093860
   Williams LA, 2008, J PERS SOC PSYCHOL, V94, P1007, DOI 10.1037/0022-3514.94.6.1007
   ZAJONC RB, 1968, J PERS SOC PSYCHOL, V9, P1, DOI 10.1037/h0025848
NR 68
TC 3
Z9 3
U1 0
U2 9
PU UNIV CALIFORNIA PRESS
PI OAKLAND
PA 155 GRAND AVE, SUITE 400, OAKLAND, CA 94612-3758 USA
SN 0730-7829
J9 MUSIC PERCEPT
JI Music Percept.
PD DEC
PY 2014
VL 32
IS 2
BP 143
EP 159
DI 10.1525/MP.2014.32.2.143
PG 17
WC Music; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music; Psychology
GA AX4BT
UT WOS:000346879800003
DA 2024-01-09
ER

PT J
AU Allgood, R
   Heaton, P
AF Allgood, Rebecca
   Heaton, Pamela
TI Developmental change and cross-domain links in vocal and musical emotion
   recognition performance in childhood
SO BRITISH JOURNAL OF DEVELOPMENTAL PSYCHOLOGY
LA English
DT Article
DE music; vocalisations; age; gender
ID PERCEPTION; EXPRESSION; SPEECH
AB Although the configurations of psychoacoustic cues signalling emotions in human vocalizations and instrumental music are very similar, cross-domain links in recognition performance have yet to be studied developmentally. Two hundred and twenty 5- to 10-year-old children were asked to identify musical excerpts and vocalizations as happy, sad, or fearful. The results revealed age-related increases in overall recognition performance with significant correlations across vocal and musical conditions at all developmental stages. Recognition scores were greater for musical than vocal stimuli and were superior in females compared with males. These results confirm that recognition of emotions in vocal and musical stimuli is linked by 5years and that sensitivity to emotions in auditory stimuli is influenced by age and gender.
C1 [Allgood, Rebecca; Heaton, Pamela] Univ London, Dept Psychol, Goldsmiths Coll, London SE14 6NW, England.
C3 University of London; Goldsmiths University London
RP Heaton, P (corresponding author), Univ London, Dept Psychol, Goldsmiths Coll, London SE14 6NW, England.
EM p.heaton@gold.ac.uk
CR Bonebright TL, 1996, SEX ROLES, V34, P429, DOI 10.1007/BF01547811
   Heaton P, 2008, BRIT J DEV PSYCHOL, V26, P171, DOI 10.1348/026151007X206776
   Juslin P., 2001, MUSIC EMOTION THEORY, V14, P309
   Juslin P. N., 2000, INT SOC RES EM ISRE
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Laukka P, 2007, MOTIV EMOTION, V31, P182, DOI 10.1007/s11031-007-9063-z
   Mohn C, 2011, PSYCHOL MUSIC, V39, P503, DOI 10.1177/0305735610378183
   Palmer C, 1997, ANNU REV PSYCHOL, V48, P115, DOI 10.1146/annurev.psych.48.1.115
   Quintin EM, 2011, J AUTISM DEV DISORD, V41, P1240, DOI 10.1007/s10803-010-1146-0
   SAUTER DA, 2006, THESIS U LONDON
   Sauter DA, 2013, BRIT J DEV PSYCHOL, V31, P97, DOI 10.1111/j.2044-835X.2012.02081.x
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
NR 12
TC 21
Z9 25
U1 3
U2 27
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0261-510X
EI 2044-835X
J9 BRIT J DEV PSYCHOL
JI Br. J. Dev. Psychol.
PD SEP
PY 2015
VL 33
IS 3
BP 398
EP 403
DI 10.1111/bjdp.12097
PG 6
WC Psychology, Developmental
WE Social Science Citation Index (SSCI)
SC Psychology
GA CO7PE
UT WOS:000359352000012
PM 26080754
DA 2024-01-09
ER

PT J
AU Kostyuk, AA
   Alekseeva, GV
AF Kostyuk, Aleksei A.
   Alekseeva, Galina, V
TI Emotions as a Phenomenon of Vocal and Opera Music
SO PROBLEMY MUZYKALNOI NAUKI-MUSIC SCHOLARSHIP
LA English
DT Article
DE emotions; phenomenon of vocal art; functions of emotions; emotional
   score of imagery; psychophysiology of vocal performance; Tchaikovsky?s
   The Queen of Spades
ID TEXT
AB The article examines the phenomenon of emotions as one of the leading patterns of creation of the vocal score of the singer-actor, the communicative intermediary between the composer, the librettist, the singer-actor and the listener-viewer. Opera as a synthetic art unites together music, poetry, production, scenography, the art of face-paint and costumes. By means of melody, its rhythmical and intonational texture builds up and ciphers those emotions which the singer must arouse from the listener-viewer. Frequently composers in the piano-vocal scores of their operas have provided descriptions of the stage settings, as well as nuances of stage motion and plastic, in order to bring out emotional colors to a greater degree by means of pantomime. In such situations it is important to research the means of operatic expression not merely from the point of view of musicology or theater studies. The phenomenon of opera requires study in a direct connection with psychology, physiology and sociology of culture. The authors of the article update the concept of the emotional score of the vocal parts of the operatic composition presenting a completed form from the positions of psycho-physiology of emotions and emphasizing the importance of its examination. The vocal part of Herman from Tchaikovsky's The Queen of Spades is chosen as the object of studies.
C1 [Kostyuk, Aleksei A.; Alekseeva, Galina, V] Far Eastern State Inst Arts, Vladivostok, Russia.
RP Kostyuk, AA (corresponding author), Far Eastern State Inst Arts, Vladivostok, Russia.
EM vocalekos@bk.ru; alexglas@mail.ru
OI Kostuk, Aleksei/0000-0002-0314-4267; Alekseeva,
   Galina/0000-0001-6733-9429
CR Fleischer M, 2022, FRONT PHYSIOL, V13, DOI 10.3389/fphys.2022.1081622
   Kiseyeva EV, 2021, PROBL MUZYKALNOI NAU, P170, DOI 10.33779/2782-3598.2021.4.170-180
   Shaymukhametova LN, 2021, PROBL MUZYKALNOI NAU, P86, DOI 10.33779/2587-6341.2021.3.086-096
   Ternström S, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122211353
   Volkova PS, 2022, PROBL MUZYKALNOI NAU, P171, DOI 10.56620/2782-3598.2022.3.171-183
   Wang W., 2022, MODERN PATHOL, P126, DOI [10.17513/snt.39245, DOI 10.17513/SNT.39245]
NR 6
TC 0
Z9 0
U1 0
U2 0
PU Gnesin Russian Acad Music
PI Moscow
PA 30-36, Povarskaya Street, Moscow, RUSSIA
SN 2782-358X
EI 2782-3598
J9 PROBL MUZYKALNOI NAU
JI Probl. Muzykalnoi Nauk.
PY 2023
IS 1
BP 168
EP 177
DI 10.56620/2782-3598.2023.1.168-177
PG 10
WC Music
WE Emerging Sources Citation Index (ESCI)
SC Music
GA E9KO5
UT WOS:000978646900013
OA gold
DA 2024-01-09
ER

PT J
AU Hakanpää, T
   Waaramaa, T
   Laukkanen, AM
AF Hakanpaa, Tua
   Waaramaa, Teija
   Laukkanen, Anne-Maria
TI Comparing Contemporary Commercial and Classical Styles: Emotion
   Expression in Singing
SO JOURNAL OF VOICE
LA English
DT Article
DE Emotion expression; Singing voice; Voice quality; Song genre; Acoustic
   analyses
ID SPEECH; VOICE
AB Objective. This study examines the acoustic correlates of the vocal expression of emotions in contemporary commercial music (CCM) and classical styles of singing. This information may be useful in improving the training of interpretation in singing.
   Study Design. This is an experimental comparative study.
   Methods. Eleven female singers with a minimum of 3 years of professional-level singing training in CCM, classical, or both styles participated. They sang the vowel [a:] at three pitches (A(3) 220Hz, E-4 330Hz, and A(4) 440Hz) expressing anger, sadness, joy, tenderness, and a neutral voice. Vowel samples were analyzed for fundamental frequency (fo) formant frequencies (F1-F5), sound pressure level (SPL), spectral structure (alpha ratio = SPL 1500-5000 Hz-SPL 50-1500 Hz), harmonics-to-noise ratio (HNR), perturbation (jitter, shimmer), onset and offset duration, sustain time, rate and extent of fo variation in vibrato, and rate and extent of amplitude vibrato.
   Results. The parameters that were statistically significantly (RM-ANOVA, P <= 0.05) related to emotion expression in both genres were SPL, alpha ratio, F1, and HNR. Additionally, for CCM, significance was found in sustain time, jitter, shimmer, F2, and F4. When fo and SPL were set as covariates in the variance analysis, jitter, HNR, and F4 did not show pure dependence on expression. The alpha ratio, F1, F2, shimmer apq5, amplitude vibrato rate, and sustain time of vocalizations had emotion-related variation also independent of fo and SPL in the CCM style, while these parameters were related to fo and SPL in the classical style.
   Conclusions. The results differed somewhat for the CCM and classical styles. The alpha ratio showed less variation in the classical style, most likely reflecting the demand for a more stable voice source quality. The alpha ratio, F1, F2, shimmer, amplitude vibrato rate, and the sustain time of the vocalizations were related to fo and SPL control in the classical style. The only common independent sound parameter indicating emotional expression for both styles was SPL. The CCM style offers more freedom for expression-related changes in voice quality.
C1 [Hakanpaa, Tua; Waaramaa, Teija; Laukkanen, Anne-Maria] Tampere Univ, Fac Social Sci, Speech & Voice Res Lab, Tampere, Finland.
C3 Tampere University
RP Hakanpää, T (corresponding author), Tampere Univ, Speech & Voice Res Lab, Akerlundinkatu 5, Tampere 33014, Finland.
EM Tua.Hakanpaa@tuni.fi
RI Laukkanen, Anne-Maria/GRS-5359-2022; Hakanpää, Tua/GZM-1298-2022
OI Laukkanen, Anne-Maria/0000-0003-4836-2513; Hakanpää,
   Tua/0000-0001-8573-5855
FU Eemil Aaltonen Foundation [170036 N1]
FX This research was supported by the Eemil Aaltonen Foundation through a
   grant (170036 N1) to Tua Hakanpaa.
CR Airas M, 2006, PHONETICA, V63, P26, DOI 10.1159/000091405
   [Anonymous], 1980, The Phonetic Description of Voice Quality
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Bunch M, 2000, J VOICE, V14, P363, DOI 10.1016/S0892-1997(00)80081-8
   Cespedes-Guevara J, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00215
   Darwin C., 1872, P374
   Eyben F, 2015, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-015-0057-6
   Guzman MA, 2012, J VOICE, V26, DOI 10.1016/j.jvoice.2012.02.006
   Hakanpää T, 2019, J VOICE, V33, P501, DOI 10.1016/j.jvoice.2018.01.012
   Harrigan J. A., 2005, NEW HDB METHODS NONV, P65, DOI DOI 10.1093/ACPROF:OSO/9780198529620.003.0003
   Jansens S, 1997, P 5 EUR C SPEECH COM, V0, P0
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN., 2010, HDB MUSIC EMOTION TH, DOI [10.1093/acprof, DOI 10.1093/ACPROF]
   Laukkanen A. M., 1997, LOGOP PHONIATR VOCO, V22, P157, DOI DOI 10.3109/14015439709075330
   Leppanen JM, 2006, MIELI JA AIVOT KOGNI, P311
   Livingstone SR, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00156
   Mayor O., 2006, P AES 121 CONV
   MURRAY IR, 1993, J ACOUST SOC AM, V93, P1097, DOI 10.1121/1.405558
   Niedenthal P. M., 2017, PSYCHOL EMOT, DOI DOI 10.4324/9781315276229
   Patel S, 2011, BIOL PSYCHOL, V87, P93, DOI 10.1016/j.biopsycho.2011.02.010
   Pervin LA, 2003, The Science of Personality
   Quinto LR, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00262
   Scherer K.R., 2017, PSYCHOMUSICOL MUSIC, V27, P244, DOI DOI 10.1037/PMU0000193
   Scherer KR, 2017, J ACOUST SOC AM, V142, P1805, DOI 10.1121/1.5002886
   Scherer KR, 2015, COMPUT SPEECH LANG, V29, P218, DOI 10.1016/j.csl.2013.10.002
   Scherer KR, 2013, COMPUT SPEECH LANG, V27, P40, DOI 10.1016/j.csl.2011.11.003
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Seikel J, 2009, ANATOMY PHYSL SPEECH, DOI [10.1002/cbdv.200490137/abstract%5Cnhttp://books.google.com/books?hl=en&lr=&id=LFBOhaD1JHwC&oi=, DOI 10.1002/CBDV.200490137/ABSTRACT%5CNHTTP://BOOKS.GOOGLE.COM/BOOKS?HL=EN&LR=&ID=LFBOHAD1JHWC&OI=]
   SIEGWART H, 1995, J VOICE, V9, P249, DOI 10.1016/S0892-1997(05)80232-2
   Sundberg J, 2000, PHONETICA, V57, P95, DOI 10.1159/000028465
   Sundberg J, 1995, VOCAL FOLD, P217
   Sundberg J, 2017, J VOICE, V31, P528, DOI 10.1016/j.jvoice.2017.02.009
   Sundberg J, 2013, PSYCHOLOGY OF MUSIC, THIRD EDITION, P69, DOI 10.1016/B978-0-12-381460-9.00003-1
   Sundberg J, 2013, J VOICE, V27, P278, DOI 10.1016/j.jvoice.2012.12.002
   Sundberg J, 2009, J VOICE, V23, P546, DOI 10.1016/j.jvoice.2008.02.003
   Sundberg Johan, 1998, LOGOP PHONIATR VOCO, V23, P121, DOI DOI 10.1080/140154398434130
   TARTTER VC, 1980, PERCEPT PSYCHOPHYS, V27, P24, DOI 10.3758/BF03199901
   Teixeira JP., 2013, Proc. Technol, V9, P1112, DOI DOI 10.1016/J.PROTCY.2013.12.124
   Titze I., 1994, Principles of Voice Production
   Titze IR, 2011, J SINGING, V67, P561
   Waaramaa T, 2008, FOLIA PHONIATR LOGO, V60, P249, DOI 10.1159/000151762
   Waaramaa T, 2010, J VOICE, V24, P30, DOI 10.1016/j.jvoice.2008.04.004
NR 43
TC 0
Z9 0
U1 1
U2 3
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0892-1997
EI 1873-4588
J9 J VOICE
JI J. Voice
PD JUL
PY 2021
VL 35
IS 4
BP 570
EP 580
DI 10.1016/j.jvoice.2019.10.002
EA AUG 2021
PG 11
WC Audiology & Speech-Language Pathology; Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Audiology & Speech-Language Pathology; Otorhinolaryngology
GA YO3UK
UT WOS:000747868300011
DA 2024-01-09
ER

PT J
AU Nordström, H
   Laukka, P
AF Nordstrom, Henrik
   Laukka, Petri
TI The time course of emotion recognition in speech and music
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID VOCAL EXPRESSION; CULTURAL SPECIFICITY; FACIAL EXPRESSIONS; VOICE
   QUALITY; COMMUNICATION; PERCEPTION; PERFORMANCE; PROSODY; CUES;
   UNIVERSALITY
AB The auditory gating paradigm was adopted to study how much acoustic information is needed to recognize emotions from speech prosody and music performances. In Study 1, brief utterances conveying ten emotions were segmented into temporally fine-grained gates and presented to listeners, whereas Study 2 instead used musically expressed emotions. Emotion recognition accuracy increased with increasing gate duration and generally stabilized after a certain duration, with different trajectories for different emotions. Above-chance accuracy was observed for <= 100 ms stimuli for anger, happiness, neutral, and sadness, and for <= 250 ms stimuli for most other emotions, for both speech and music. This suggests that emotion recognition is a fast process that allows discrimination of several emotions based on low-level physical characteristics. The emotion identification points, which reflect the amount of information required for stable recognition, were shortest for anger and happiness for both speech and music, but recognition took longer to stabilize for music vs speech. This, in turn, suggests that acoustic cues that develop over time also play a role for emotion inferences (especially for music). Finally, acoustic cue patterns were positively correlated between speech and music, suggesting a shared acoustic code for expressing emotions. (C) 2019 Acoustical Society of America.
C1 [Nordstrom, Henrik; Laukka, Petri] Stockholm Univ, Dept Psychol, S-10691 Stockholm, Sweden.
C3 Stockholm University
RP Nordström, H (corresponding author), Stockholm Univ, Dept Psychol, S-10691 Stockholm, Sweden.
EM henrik.nordstrom@psychology.su.se
RI Laukka, Petri/B-5259-2008
OI Laukka, Petri/0000-0001-8771-6818
FU Swedish Research Council [2012-801]; Marianne and Marcus Wallenberg
   Foundation [2018-0059]
FX The research was funded by the Swedish Research Council (Grant No.
   2012-801) and the Marianne and Marcus Wallenberg Foundation (Grant No.
   2018-0059). Data and analysis code are available at the Open Science
   Framework (http://osf.io/a8de7).
CR Askenfelt A., 1991, MUSIC LANGUAGE SPEEC, P243
   Audibert N, 2007, P ICPHS, P2137
   Bänziger T, 2012, EMOTION, V12, P1161, DOI 10.1037/a0025827
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Barrett LF, 2017, SOC COGN AFFECT NEUR, V12, P1, DOI 10.1093/scan/nsw154
   Baumeister R. F., 2001, Rev. Gen. Psychol, V5, P323, DOI [DOI 10.1037/1089-2680.5.4.323, 10.1037/1089-2680.5.4.323]
   Bigand E, 2005, ANN NY ACAD SCI, V1060, P429, DOI 10.1196/annals.1360.036
   Birkholz P, 2015, J ACOUST SOC AM, V137, P1503, DOI 10.1121/1.4906836
   Bowling DL, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0031942
   Chen XH, 2011, BIOL PSYCHOL, V86, P158, DOI 10.1016/j.biopsycho.2010.11.004
   Cordaro DT, 2016, EMOTION, V16, P117, DOI 10.1037/emo0000100
   Cornew L, 2010, COGNITION EMOTION, V24, P1133, DOI 10.1080/02699930903247492
   Coutinho E, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179289
   Cowen A. S., 2018, AM PSYCHOL
   Dalla Bella S, 2003, PERCEPT PSYCHOPHYS, V65, P1019
   Dinno A, 2009, MULTIVAR BEHAV RES, V44, P362, DOI 10.1080/00273170902938969
   Eerola T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00487
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Elfenbein HA, 2002, PSYCHOL BULL, V128, P203, DOI 10.1037//0033-2909.128.2.203
   Ellsworth PC, 2003, SER AFFECTIVE SCI, P572
   Eyben F., 2013, P 21 ACM INT C MULT, P835, DOI 10.1145/2502081.2502224
   Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417
   Filipic S, 2010, PSYCHON B REV, V17, P335, DOI 10.3758/PBR.17.3.335
   Fitch WT, 2006, COGNITION, V100, P173, DOI 10.1016/j.cognition.2005.11.009
   Frank MG, 2001, J PERS SOC PSYCHOL, V80, P75, DOI 10.1037/0022-3514.80.1.75
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Ghosh J., 2015, ARXIV150707170STAT
   Gobl C., 2010, HDB PHONETIC SCI, P387
   Goudbeek M, 2010, J ACOUST SOC AM, V128, P1322, DOI 10.1121/1.3466853
   GROSJEAN F, 1980, PERCEPT PSYCHOPHYS, V28, P267, DOI 10.3758/BF03204386
   Harajda H., 1993, Archives of Acoustics, V18, P17
   Harnmerschmidt K, 2007, J VOICE, V21, P531, DOI 10.1016/j.jvoice.2006.03.002
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Jiang XM, 2015, J EXP PSYCHOL HUMAN, V41, P597, DOI 10.1037/xhp0000043
   Juslin PN, 2018, J NONVERBAL BEHAV, V42, P1, DOI 10.1007/s10919-017-0268-x
   Juslin PN, 2001, EMOTION, V1, P381, DOI 10.1037//1528-3542.1.4.381
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 1997, MUSIC PERCEPT, V14, P383
   Keltner D, 1999, COGNITION EMOTION, V13, P505, DOI 10.1080/026999399379168
   Krumhansl CL, 2010, MUSIC PERCEPT, V27, P337, DOI 10.1525/mp.2010.27.5.337
   Lacheret A., 2007, 16 INT C PHON SCI IC, V1539, P805
   LADD DR, 1985, J ACOUST SOC AM, V78, P435, DOI 10.1121/1.392466
   Laukka P, 2005, COGNITION EMOTION, V19, P633, DOI 10.1080/02699930441000445
   Laukka P, 2016, J PERS SOC PSYCHOL, V111, P686, DOI 10.1037/pspi0000066
   Laukka P, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00353
   Laukka P, 2013, EMOTION, V13, P434, DOI 10.1037/a0031388
   Laukka P, 2012, SOC PSYCHOL PERS SCI, V3, P529, DOI 10.1177/1948550611428011
   Lazarus R. S., 1991, STRESS APPRAISAL COP
   Lima CF, 2019, EMOTION, V19, P219, DOI 10.1037/emo0000429
   Liu TS, 2012, NEUROREPORT, V23, P108, DOI 10.1097/WNR.0b013e32834ea757
   Moors A, 2017, PSYCHOL INQ, V28, P1, DOI 10.1080/1047840X.2017.1235900
   Mores R, 2017, CURR RES SYST MUSIC, V4, P223, DOI 10.1007/978-3-319-47292-8_8
   MUELLENSIEFAN D, 2014, PLOS ONE, V9, DOI DOI 10.1371/JOURNAL.PONE.0089642
   Nordström H, 2017, ROY SOC OPEN SCI, V4, DOI 10.1098/rsos.170912
   Nummenmaa L, 2015, EMOTION, V15, P243, DOI 10.1037/emo0000042
   Ortony A, 1988, The cognitive structure of emotions
   Parncutt R, 2014, MUSIC SCI, V18, P324, DOI 10.1177/1029864914542842
   Paulmann S, 2008, NEUROREPORT, V19, P209, DOI 10.1097/WNR.0b013e3282f454db
   Paulmann S, 2010, COGN AFFECT BEHAV NE, V10, P230, DOI 10.3758/CABN.10.2.230
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Pell MD, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027256
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   Piironen J., 2018, ARXIV 1810 02406
   POLLACK I, 1960, LANG SPEECH, V3, P121, DOI 10.1177/002383096000300301
   Rigoulot S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00367
   Sauter DA, 2017, EMOT REV, V9, P222, DOI 10.1177/1754073916667236
   Sauter DA, 2010, Q J EXP PSYCHOL, V63, P2251, DOI 10.1080/17470211003721642
   Sauter DA, 2010, J COGNITIVE NEUROSCI, V22, P474, DOI 10.1162/jocn.2009.21215
   Scherer KR, 2017, J ACOUST SOC AM, V142, P1805, DOI 10.1121/1.5002886
   Scherer KR, 2015, COMPUT SPEECH LANG, V29, P218, DOI 10.1016/j.csl.2013.10.002
   Scherer KR, 2011, INT J PSYCHOL, V46, P401, DOI 10.1080/00207594.2011.626049
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Scherer KR, 2019, OXFORD HDB VOICE PER, P61, DOI DOI 10.1093/OXFORDHB/9780198743187.013.4
   Schoonderwaldt E, 2009, ACTA ACUST UNITED AC, V95, P901, DOI 10.3813/AAA.918221
   Schuller B, 2011, SPEECH COMMUN, V53, P1062, DOI 10.1016/j.specom.2011.01.011
   Simon-Thomas ER, 2009, EMOTION, V9, P838, DOI 10.1037/a0017810
   Spreckelmeyer KN, 2009, BRAIN COGNITION, V69, P121, DOI 10.1016/j.bandc.2008.06.003
   Stan Development Team, 2018, RSTANARM BAYES APPL
   Stan Development Team, 2021, RStan: the R interface to Stan. R package version 2.21.2
   Tangney J.P., 2012, Handbook of self and identity, P446, DOI DOI 10.4135/9781446263402
   Thompson WF, 2012, P NATL ACAD SCI USA, V109, P19027, DOI 10.1073/pnas.1210344109
   Tracy JL, 2011, EMOT REV, V3, P397, DOI 10.1177/1754073911410747
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   WAGNER HL, 1993, J NONVERBAL BEHAV, V17, P3, DOI 10.1007/BF00987006
   Weninger F, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00292
   Yanushevskaya I, 2018, J ACOUST SOC AM, V144, P2730, DOI 10.1121/1.5066448
NR 89
TC 24
Z9 25
U1 2
U2 29
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD MAY
PY 2019
VL 145
IS 5
BP 3058
EP 3074
DI 10.1121/1.5108601
PG 17
WC Acoustics; Audiology & Speech-Language Pathology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Acoustics; Audiology & Speech-Language Pathology
GA IV0MP
UT WOS:000483973600041
PM 31153307
DA 2024-01-09
ER

PT J
AU Goudbeek, M
   Scherer, K
AF Goudbeek, Martijn
   Scherer, Klaus
TI Beyond arousal: Valence and potency/control cues in the vocal expression
   of emotion
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID SPEECH; COMMUNICATION; INTENSITY; EVOLUTION; MUSIC
AB The important role of arousal in determining vocal parameters in the expression of emotion is well established. There is less evidence for the contribution of emotion dimensions such as valence and potency/control to vocal emotion expression. Here, an acoustic analysis of the newly developed Geneva Multimodal Emotional Portrayals corpus, is presented to examine the role of dimensions other than arousal. This corpus contains twelve emotions that systematically vary with respect to valence, arousal, and potency/control. The emotions were portrayed by professional actors coached by a stage director. The extracted acoustic parameters were first compared with those obtained from a similar corpus [Banse and Scherer (1996). J. Pers. Soc. Psychol. 70, 614-636] and shown to largely replicate the earlier findings. Based on a principal component analysis, seven composite scores were calculated and were used to determine the relative contribution of the respective vocal parameters to the emotional dimensions arousal, valence, and potency/control. The results show that although arousal dominates for many vocal parameters, it is possible to identify parameters, in particular spectral balance and spectral noise, that are specifically related to valence and potency/control. (C) 2010 Acoustical Society of America. [DOI: 10.1121/1.3466853]
C1 [Goudbeek, Martijn] Tilburg Univ, Fac Humanities, NL-5000 LE Tilburg, Netherlands.
   [Scherer, Klaus] Swiss Ctr Affect Sci, CH-1205 Geneva, Switzerland.
C3 Tilburg University
RP Goudbeek, M (corresponding author), Tilburg Univ, Fac Humanities, POB 90153, NL-5000 LE Tilburg, Netherlands.
EM m.b.goudbeek@uvt.nl
RI Goudbeek, Martijn/J-4442-2019
OI Goudbeek, Martijn/0000-0002-7787-4123
FU SNFS [101411-100367]; SNFS National Competence Center in Affective
   Sciences
FX We thank Tanja Banziger for the work done on construction and rating of
   the corpus, Marcello Mortillaro for the construction of the core set
   based on the lay ratings, and Sona Patel for careful reading of the
   revised manuscript. This research has been funded by SNFS grant
   101411-100367 and the SNFS National Competence Center in Affective
   Sciences. The manuscript of this paper benefited from the excellent
   comments of two anonymous reviewers and the comments and suggestions of
   the action editor, Michael Owren.
CR [Anonymous], 2006, P LREC
   BACHOROWSKI JA, 1995, PSYCHOL SCI, V6, P219, DOI 10.1111/j.1467-9280.1995.tb00596.x
   Bänziger T, 2007, LECT NOTES COMPUT SC, V4738, P476
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Bänziger T, 2005, SPEECH COMMUN, V46, P252, DOI 10.1016/j.specom.2005.02.016
   Banziger T., 2005, ISRE 2005 BAR IT
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Boersma P., 2014, PRAAT DOING PHONETIC
   BURKHARDT R, 2005, P INT 2005 EUR LISB
   Douglas-Cowie E, 2003, SPEECH COMMUN, V40, P33, DOI 10.1016/S0167-6393(02)00070-5
   DRIOLI C, 2003, ISCA TUT RES WORKSH, P127
   Elfenbein HA, 2002, PSYCHOL BULL, V128, P203, DOI 10.1037//0033-2909.128.2.203
   Ellsworth PC, 2003, SER AFFECTIVE SCI, P572
   Fitch WT, 2000, TRENDS COGN SCI, V4, P258, DOI 10.1016/S1364-6613(00)01494-7
   Fontaine JRJ, 2007, PSYCHOL SCI, V18, P1050, DOI 10.1111/j.1467-9280.2007.02024.x
   Frijda N. H, 1986, The Emotions
   Gobl C, 2003, SPEECH COMMUN, V40, P189, DOI 10.1016/S0167-6393(02)00082-1
   GOUDBEEK M, 2008, ISCA TUT RES WORKSH
   HAMMARBERG B, 1980, ACTA OTO-LARYNGOL, V90, P441, DOI 10.3109/00016488009131746
   Harrigan J. A., 2005, NEW HDB METHODS NONV, P65, DOI DOI 10.1093/ACPROF:OSO/9780198529620.003.0003
   JOHNSTONE T, 2001, APPRAISAL PROCESSES, P271
   Juslin PN, 2001, EMOTION, V1, P381, DOI 10.1037//1528-3542.1.4.381
   Juslin PN, 2003, ANN NY ACAD SCI, V1000, P279, DOI 10.1196/annals.1280.025
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Laukka P, 2005, COGNITION EMOTION, V19, P633, DOI 10.1080/02699930441000445
   LAUKKA P, 2004, THESIS UPPSALA U UPP
   MOZZICONACCI S, 2002, P SPEECH PROS AIX EN
   Osgood Charles E., 1975, Cross-Cultural Universals of Affective Meaning
   Owren M. J., 2007, HDB EMOTION ELICITAT, P239
   Owren MJ, 2003, J NONVERBAL BEHAV, V27, P183, DOI 10.1023/A:1025394015198
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Russell JA, 2003, PSYCHOL REV, V110, P145, DOI 10.1037/0033-295X.110.1.145
   Sander D, 2005, NEURAL NETWORKS, V18, P317, DOI 10.1016/j.neunet.2005.03.001
   Scherer K. R., 2001, Series in Affective Science, P92, DOI DOI 10.1016/S0166-4115(08)62387-0
   Scherer KR, 2003, SER AFFECTIVE SCI, P433
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   SCHERER KR, 1994, EMOTIONS: ESSAYS ON EMOTION THEORY, P161
   SCHERER KR, 2004, P SPEECH PROS NAR JA
   Schröber M, 2003, SPEECH COMMUN, V40, P99, DOI 10.1016/S0167-6393(02)00078-X
   Stanislavski C., 1936, ACTOR PREPARES
   TAMARIT L, 2008, ISCA TUT RES WORKSH
   vBezooijen R., 1984, CHARACTERISTICS RECO
   WUNDT W, 2009, GRUNDRISS PSYCHOL AC
   XIAO Z, 2009, INT C AFF COMP INT I
   Yanushevskaya I, 2007, LECT NOTES COMPUT SC, V4738, P159
NR 45
TC 105
Z9 116
U1 1
U2 29
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD SEP
PY 2010
VL 128
IS 3
BP 1322
EP 1336
DI 10.1121/1.3466853
PG 15
WC Acoustics; Audiology & Speech-Language Pathology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Acoustics; Audiology & Speech-Language Pathology
GA 649UP
UT WOS:000281799800043
PM 20815467
DA 2024-01-09
ER

PT J
AU Nolden, S
   Rigoulot, S
   Jolicoeur, P
   Armony, JL
AF Nolden, Sophie
   Rigoulot, Simon
   Jolicoeur, Pierre
   Armony, Jorge L.
TI Effects of musical expertise on oscillatory brain activity in response
   to emotional sounds
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE Sound processing; Emotion; Speech; Music; Vocal expression; Musical
   expertise; EEG; Oscillations
ID HUMAN AUDITORY-CORTEX; UNPLEASANT MUSIC; SPEECH PROSODY; BAND ACTIVITY;
   LANGUAGE; VOCALIZATIONS; RECOGNITION; PERCEPTION; PLASTICITY; AMYGDALA
AB Emotions can be conveyed through a variety of channels in the auditory domain, be it via music, non-linguistic vocalizations, or speech prosody. Moreover, recent studies suggest that expertise in one sound category can impact the processing of emotional sounds in other sound categories as they found that musicians process more efficiently emotional musical and vocal sounds than non-musicians. However, the neural correlates of these modulations, especially their time course, are not very well understood. Consequently, we focused here on how the neural processing of emotional information varies as a function of sound category and expertise of participants. Electroencephalogram (EEG) of 20 non-musicians and 17 musicians was recorded while they listened to vocal (speech and vocalizations) and musical sounds. The amplitude of EEG-oscillatory activity in the theta, alpha, beta, and gamma band was quantified and Independent Component Analysis (ICA) was used to identify underlying components of brain activity in each band. Category differences were found in theta and alpha bands, due to larger responses to music and speech than to vocalizations, and in posterior beta, mainly due to differential processing of speech. In addition, we observed greater activation in frontal theta and alpha for musicians than for non-musicians, as well as an interaction between expertise and emotional content of sounds in frontal alpha. The results reflect musicians' expertise in recognition of emotion-conveying music, which seems to also generalize to emotional expressions conveyed by the human voice, in line with previous accounts of effects of expertise on musical and vocal sounds processing.
C1 [Nolden, Sophie; Rigoulot, Simon; Jolicoeur, Pierre; Armony, Jorge L.] CRBLM, Montreal, PQ, Canada.
   [Nolden, Sophie; Jolicoeur, Pierre] Univ Montreal, Ctr Rech Neuropsychol & Cognit CERNEC, Montreal, PQ, Canada.
   [Nolden, Sophie; Jolicoeur, Pierre; Armony, Jorge L.] Univ Montreal, Dept Psychol, Montreal, PQ, Canada.
   [Rigoulot, Simon; Armony, Jorge L.] McGill Univ, Dept Psychiat, Montreal, PQ, Canada.
   [Rigoulot, Simon; Armony, Jorge L.] Douglas Mental Hlth Univ Inst, Montreal, PQ, Canada.
   [Nolden, Sophie; Rigoulot, Simon; Jolicoeur, Pierre; Armony, Jorge L.] Int Lab Brain Mus & Sound Res BRAMS, Montreal, PQ, Canada.
   [Jolicoeur, Pierre] CRIUGM, Montreal, PQ, Canada.
   [Nolden, Sophie] Rhein Westfal TH Aachen, Inst Psychol, Aachen, Germany.
C3 Universite de Montreal; Universite de Montreal; McGill University;
   Universite de Montreal; Universite de Montreal; RWTH Aachen University
RP Nolden, S (corresponding author), Rhein Westfal TH Aachen, Inst Psychol, Aachen, Germany.
EM sophie.nolden@psych.rwth-aachen.de
RI Rigoulot, Simon/ABF-5776-2020
OI Nolden, Sophie/0000-0003-1352-5060
FU Natural Science and Engineering Research Council of Canada (NSERC)
   [262439-2009, 795-2010]; Canadian Institutes of Health Research (CIHR)
   [MOP-130516]; Canada Research Chairs Program; Deutsche Akademische
   Austausch-Dienst (DAAD); NSERC Auditory Cognitive Neuroscience (ACN)
   CREATE
FX We thank our participants for their participation and Pia Amping for
   programming. This study was supported by the Natural Science and
   Engineering Research Council of Canada (NSERC, 262439-2009 to JLA and
   795-2010 to PJ), the Canadian Institutes of Health Research (CIHR,
   MOP-130516) to JLA, and the Canada Research Chairs Program to PJ. SN was
   supported by fellowships from the Deutsche Akademische Austausch-Dienst
   (DAAD) and the NSERC Auditory Cognitive Neuroscience (ACN) CREATE
   program.
CR Abrams DA, 2011, CEREB CORTEX, V21, P1507, DOI 10.1093/cercor/bhq198
   Angulo-Perkins A, 2014, CORTEX, V59, P126, DOI 10.1016/j.cortex.2014.07.013
   [Anonymous], 2009, Int. J. Speech Lang. Pathol
   [Anonymous], 1993, Educational Psychology
   Armony JL, 2015, NEUROSCI LETT, V593, P35, DOI 10.1016/j.neulet.2015.03.011
   Aubé W, 2015, SOC COGN AFFECT NEUR, V10, P399, DOI 10.1093/scan/nsu067
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Belin P, 2004, TRENDS COGN SCI, V8, P129, DOI 10.1016/j.tics.2004.01.008
   Bermudez P, 2009, CEREB CORTEX, V19, P1583, DOI 10.1093/cercor/bhn196
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Blood AJ, 1999, NAT NEUROSCI, V2, P382, DOI 10.1038/7299
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Brattico E, 2006, BRAIN RES, V1117, P162, DOI 10.1016/j.brainres.2006.08.023
   Brown S, 2006, EUR J NEUROSCI, V23, P2791, DOI 10.1111/j.1460-9568.2006.04785.x
   Campanella S, 2007, TRENDS COGN SCI, V11, P535, DOI 10.1016/j.tics.2007.10.001
   Chartrand JP, 2006, NEUROSCI LETT, V405, P164, DOI 10.1016/j.neulet.2006.06.053
   Dell'Acqua R, 2015, J COGNITIVE NEUROSCI, V27, P720, DOI 10.1162/jocn_a_00752
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dien J., 2004, EVENT RELATED POTENT
   Drisdelle B., 2017, PSYCHOPHYSI IN PRESS
   EKMAN P, 1993, AM PSYCHOL, V48, P384, DOI 10.1037/0003-066X.48.4.384
   Fecteau S, 2007, NEUROIMAGE, V36, P480, DOI 10.1016/j.neuroimage.2007.02.043
   Gosselin N, 2007, NEUROPSYCHOLOGIA, V45, P236, DOI 10.1016/j.neuropsychologia.2006.07.012
   Güntekin B, 2014, NEUROPSYCHOLOGIA, V58, P33, DOI 10.1016/j.neuropsychologia.2014.03.014
   Habibi A, 2013, MUSIC PERCEPT, V30, P463, DOI 10.1525/MP.2013.30.5.463
   Hébert S, 2003, BRAIN, V126, P1838, DOI 10.1093/brain/awg186
   Herdener M, 2010, J NEUROSCI, V30, P1377, DOI 10.1523/JNEUROSCI.4513-09.2010
   Ho YC, 2003, NEUROPSYCHOLOGY, V17, P439, DOI 10.1037/0894-4105.17.3.439
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kaiser J, 2002, EUR J NEUROSCI, V15, P345, DOI 10.1046/j.0953-816x.2001.01857.x
   Kaiser J, 2002, CEREB CORTEX, V12, P212, DOI 10.1093/cercor/12.2.212
   Keil A, 2001, CLIN NEUROPHYSIOL, V112, P2057, DOI 10.1016/S1388-2457(01)00654-X
   Kilgour AR, 2000, MEM COGNITION, V28, P700, DOI 10.3758/BF03198404
   Kreiman J., 1997, TALKER VARIABILITY S
   Kühnis J, 2014, J COGNITIVE NEUROSCI, V26, P2750, DOI 10.1162/jocn_a_00674
   Lappe C, 2008, J NEUROSCI, V28, P9632, DOI 10.1523/JNEUROSCI.2254-08.2008
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Liu YL, 2012, J NEUROSCI, V32, P14563, DOI 10.1523/JNEUROSCI.3109-12.2012
   Lopez-Calderon J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00213
   Müller MM, 1999, CLIN NEUROPHYSIOL, V110, P1913, DOI 10.1016/S1388-2457(99)00151-0
   Öhman A, 2005, PSYCHONEUROENDOCRINO, V30, P953, DOI 10.1016/j.psyneuen.2005.03.019
   Onton J., 2006, PROGR BRAIN RES
   Oya H, 2002, J NEUROSCI, V22, P9502
   Pantev C, 2011, NEUROSCI BIOBEHAV R, V35, P2140, DOI 10.1016/j.neubiorev.2011.06.010
   Patel AD, 2003, NAT NEUROSCI, V6, P674, DOI 10.1038/nn1082
   Pell MD, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027256
   Pell MD, 2009, J NONVERBAL BEHAV, V33, P107, DOI 10.1007/s10919-008-0065-7
   Peretz I, 2004, MUSIC PERCEPT, V21, P373, DOI 10.1525/mp.2004.21.3.373
   Peretz I, 2003, NAT NEUROSCI, V6, P688, DOI 10.1038/nn1083
   PERETZ I, 1994, BRAIN, V117, P1283, DOI 10.1093/brain/117.6.1283
   Rigoulot S, 2015, NEUROSCIENCE, V290, P175, DOI 10.1016/j.neuroscience.2015.01.033
   Rigoulot S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00367
   Rigoulot S, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030740
   Rogalsky C, 2011, J NEUROSCI, V31, P3843, DOI 10.1523/JNEUROSCI.4515-10.2011
   Salimpoor VN, 2011, NAT NEUROSCI, V14, P257, DOI 10.1038/nn.2726
   Sammler D, 2007, PSYCHOPHYSIOLOGY, V44, P293, DOI 10.1111/j.1469-8986.2007.00497.x
   Sauter DA, 2010, J COGNITIVE NEUROSCI, V22, P474, DOI 10.1162/jocn.2009.21215
   Schirmer A, 2005, COGNITIVE BRAIN RES, V24, P442, DOI 10.1016/j.cogbrainres.2005.02.022
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   SCHLAUG G, 1995, NEUROPSYCHOLOGIA, V33, P1047, DOI 10.1016/0028-3932(95)00045-5
   Senkowski D, 2014, HUM BRAIN MAPP, V35, P3107, DOI 10.1002/hbm.22388
   Shahin AJ, 2009, BRAIN COGNITION, V70, P259, DOI 10.1016/j.bandc.2009.02.008
   Tallon-Baudry C, 1999, TRENDS COGN SCI, V3, P151, DOI 10.1016/S1364-6613(99)01299-1
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Tierney A, 2013, CEREB CORTEX, V23, P249, DOI 10.1093/cercor/bhs003
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   Vuilleumier P, 2001, NEURON, V30, P829, DOI 10.1016/S0896-6273(01)00328-2
   Weiss S, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00201
NR 68
TC 8
Z9 10
U1 0
U2 34
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD AUG
PY 2017
VL 103
BP 96
EP 105
DI 10.1016/j.neuropsychologia.2017.07.014
PG 10
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA FF3IR
UT WOS:000408789200012
PM 28720526
DA 2024-01-09
ER

PT J
AU Esposito, A
   Palumbo, D
   Troncone, A
AF Esposito, Anna
   Palumbo, Davide
   Troncone, Alda
TI The Influence of the Attachment Style on the Decoding Accuracy of
   Emotional Vocal Expressions
SO COGNITIVE COMPUTATION
LA English
DT Article
DE Emotional vocal stimuli; Emotion recognition; Attachment style; Mood
   induction
ID FACIAL EXPRESSION; ADULT ATTACHMENT; MOOD; PERCEPTION; MUSIC; STATE
AB This study aimed at examining the effects of attachment style on the ability of recognizing emotions, from acoustic stimuli, in subjects with induced emotional states. An adequate sample of 145 university students (71 females and 74 males; mean age = 23.37 +/- A 2.05) was recruited from the Second University of Naples (Italy). The subjects, classified for attachment style into Secure, Insecure Dismissing, Insecure Preoccupied and Insecure Fearful, were randomly assigned with one of three (sad, fearful or neutral) different elicited emotional conditions induced by viewing short movies. Immediately after the mood-induction procedure, subjects undertook a vocal emotion-decoding task. Secure subjects were more accurate in recognizing surprise and sadness than the Insecure group; Fearfully attached individuals were less accurate in identifying vocal stimuli conveying sadness than the Securely and Dismissively attached groups. The recognition of vocal stimuli was not affected by induced mood conditions. No mood-congruity effects were found. The study sheds light on some of the factors underlying the emotion-recognition process. Possible explanations of the contribution of attachment style on the ability to decode vocal stimuli were discussed.
C1 [Esposito, Anna; Palumbo, Davide; Troncone, Alda] Univ Naples 2, Dept Psychol, Caserta, Italy.
   [Esposito, Anna] IIASS, Salerno, Italy.
C3 Universita della Campania Vanvitelli
RP Troncone, A (corresponding author), Univ Naples 2, Dept Psychol, Viale Ellitt 31, Caserta, Italy.
EM alda.troncone@unina2.it
RI troncone, alda/N-6826-2016; Esposito, Anna/GWC-6719-2022; Troncone,
   Alda/HTR-8013-2023; troncone, alda/AAD-6609-2019; ESPOSITO,
   Anna/P-4018-2015
OI troncone, alda/0000-0002-4641-6314; Troncone, Alda/0000-0002-4641-6314;
   troncone, alda/0000-0002-4641-6314; ESPOSITO, Anna/0000-0002-7268-1795
CR [Anonymous], 1990, ATTACHMENT PRESCHOOL
   [Anonymous], P 1 INT WORKSH EM CO
   Astington J. W., 1988, Developing Theories of Mind
   Barratt W, 2006, BARRATT SIMPLI UNPUB
   BOUHUYS AL, 1995, J AFFECT DISORDERS, V33, P215, DOI 10.1016/0165-0327(94)00092-N
   Bowlby J., 1951, Maternal care and mental health
   Bowlby J., 1979, The making and breaking of affectional bonds
   Brennan K.A., 1998, ATTACHMENT THEORY CL, P46
   BULLERJAHN C., 1994, Psychomusicology-A Journal of Research in Music Cognition, V13, P99, DOI DOI 10.1037/H0094100
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Caro D. H., 2009, CANADIAN J ED, V32, P558
   Chepenik LG, 2007, EMOTION, V7, P802, DOI 10.1037/1528-3542.7.4.802
   Colle L, 2011, SOC DEV, V20, P51, DOI 10.1111/j.1467-9507.2010.00576.x
   Conklin CZ, 2006, J NERV MENT DIS, V194, P69, DOI 10.1097/01.nmd.0000198138.41709.4f
   Crittenden P, 1994, NUOVE PROSPETTIVE SU
   de Rosnay Marc, 2002, Attach Hum Dev, V4, P39, DOI 10.1080/14616730210123139
   Ekman P., 1978, Manual for the facial action coding system
   Esposito Anna, 2012, Cognitive Behavioural Systems (COST 2012). International Training School. Revised Selected Papers, P158, DOI 10.1007/978-3-642-34584-5_12
   Esposito A, 2009, FRONT ARTIF INTEL AP, V204, P51, DOI 10.3233/978-1-60750-072-8-51
   Esposito A, 2009, COGN COMPUT, V1, P268, DOI 10.1007/s12559-009-9017-8
   Esposito A, 2010, LECT NOTES COMPUT SC, V5967, P406
   Harris P L, 1999, Attach Hum Dev, V1, P307, DOI 10.1080/14616739900134171
   L'assessment Cionini L, 2004, NUOVO MANUALE PSICOT, VIII, P15
   Laible DJ, 1998, DEV PSYCHOL, V34, P1038, DOI 10.1037/0012-1649.34.5.1038
   Lay KL, 1995, MONOGR SOC RES CHILD, V60, P179, DOI 10.2307/1166178
   Liotti G, 2004, PSYCHOTHERAPY, V41, P472, DOI 10.1037/0033-3204.41.4.472
   Main M., 1991, Attachment across the life cycle, P127
   Main M., 1986, Affective development in infancy, P95
   McClure EB, 2000, PSYCHOL BULL, V126, P424, DOI 10.1037/0033-2909.126.3.424
   Niedenthal PM, 2001, COGNITION EMOTION, V15, P853, DOI 10.1080/02699930143000194
   Niedenthal PM, 2000, EUR J SOC PSYCHOL, V30, P211, DOI 10.1002/(SICI)1099-0992(200003/04)30:2<211::AID-EJSP988>3.0.CO;2-3
   Niedenthal PM, 2002, J PERS SOC PSYCHOL, V82, P419, DOI 10.1037//0022-3514.82.3.419
   Picardi A., 2002, ITALIAN J PSYCHOPATH, V8, P282
   Picardi A., 2000, RIV PSICHIATR, V35, P114
   Plutchik R., 1966, PSYCHOANAL REV, VLIII2, P105
   Russell JA, 2003, ANNU REV PSYCHOL, V54, P329, DOI 10.1146/annurev.psych.54.101601.145102
   SCHERER KR, 1991, MOTIV EMOTION, V15, P123, DOI 10.1007/BF00995674
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Schmid PC, 2010, MOTIV EMOTION, V34, P288, DOI 10.1007/s11031-010-9170-0
   Seppi D, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P601
   Sirin SR, 2005, REV EDUC RES, V75, P417, DOI 10.3102/00346543075003417
   Steele H, 2008, ATTACH HUM DEV, V10, P379, DOI 10.1080/14616730802461409
   Suslow T, 2010, AUST J PSYCHOL, V62, P181, DOI 10.1080/00049530903567203
   Tan SL, 2007, MUSIC PERCEPT, V25, P135, DOI 10.1525/MP.2007.25.2.135
   Thompson WF, 2006, SEMIOTICA, V158, P407, DOI 10.1515/SEM.2006.017
NR 45
TC 10
Z9 11
U1 0
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1866-9956
EI 1866-9964
J9 COGN COMPUT
JI Cogn. Comput.
PD DEC
PY 2014
VL 6
IS 4
SI SI
BP 699
EP 707
DI 10.1007/s12559-014-9292-x
PG 9
WC Computer Science, Artificial Intelligence; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Neurosciences & Neurology
GA AW0PJ
UT WOS:000345994900008
DA 2024-01-09
ER

PT J
AU Barnes, SJ
AF Barnes, Stuart J. J.
TI Smooth Talking and Fast Music: Understanding the Importance of Voice and
   Music in Travel and Tourism Ads via Acoustic Analytics
SO JOURNAL OF TRAVEL RESEARCH
LA English
DT Article; Early Access
DE audio analytics; video analytics; machine learning; voice quality; music
   tempo
ID BACKGROUND MUSIC; VOCAL EMOTIONS; SPEECH RATE; PITCH; TEMPO;
   COMMUNICATION; CUSTOMERS; RESPONSES; BEHAVIOR; IMPACT
AB Travel and tourism advertising is critical in developing positive associations to attract visitor patronage and build sustainable post-pandemic tourism. An important part of an advertising message is delivered through voice and other aspects of audio, for example, music. However, how audio features impact viewers of travel and tourism advertisements remains unexplored in the research. This study implements advanced audio analytics to test how various features impact upon viewers. The results show that voice quality is important in developing positive affect; advertisement viewers prefer speakers with quieter voices (less mean intensity) that have a higher level of clarity (higher harmonics-to-noise ratio). This can be explained via the heuristic route of the heuristic-systematic model. Music tempo was found to be important in stimulating reactions from advertisements, with faster music being associated with a higher level of positive affect. The paper concludes with practical and theoretical implications, limitations, and suggestions for future research.
C1 [Barnes, Stuart J. J.] Newcastle Univ, Newcastle Univ Business Sch, 5 Barrack Rd, Newcastle Upon Tyne NE1 4SE, England.
C3 Newcastle University - UK
RP Barnes, SJ (corresponding author), Newcastle Univ, Newcastle Univ Business Sch, 5 Barrack Rd, Newcastle Upon Tyne NE1 4SE, England.
EM stuart.barnes@newcastle.ac.uk
CR Anikin A, 2019, BEHAV RES METHODS, V51, P778, DOI 10.3758/s13428-018-1095-7
   [Anonymous], 1985, OBJECTIVE PSYCHOL MU
   APPLE W, 1979, J PERS SOC PSYCHOL, V37, P715, DOI 10.1037/0022-3514.37.5.715
   Balducci B, 2018, J ACAD MARKET SCI, V46, P557, DOI 10.1007/s11747-018-0581-x
   Bandyopadhya C, 2019, J NONPROFIT PUBLIC S, V31, P164, DOI 10.1080/10495142.2018.1526738
   Bannister S., 2020, MUSIC AND SCI, V3, P1, DOI [DOI 10.1177/2059204320915654, 10.1177/ 2059204320915654]
   Barnett V., 1994, Outliers in statistical data
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Berger J, 2020, J MARKETING, V84, P1, DOI 10.1177/0022242919873106
   Bhattacharya C. B., 2016, GFK MARKETING INTELL, V8, P8
   Biswas D, 2019, J ACAD MARKET SCI, V47, P37, DOI 10.1007/s11747-018-0583-8
   BITNER MJ, 1992, J MARKETING, V56, P57, DOI 10.2307/1252042
   Breitenstein C, 2001, COGNITION EMOTION, V15, P57, DOI 10.1080/0269993004200114
   BURGOON JK, 1990, HUM COMMUN RES, V17, P140, DOI 10.1111/j.1468-2958.1990.tb00229.x
   Caldwell C, 2002, PSYCHOL MARKET, V19, P895, DOI 10.1002/mar.10043
   CHAIKEN S, 1980, J PERS SOC PSYCHOL, V39, P752, DOI 10.1037/0022-3514.39.5.752
   Chattopadhyay A, 2003, J CONSUM PSYCHOL, V13, P198, DOI 10.1207/S15327663JCP1303_02
   Dawar N, 2018, HARVARD BUS REV, V96, P80
   Dubey M., 2018, ADV ADVERTISING RES
   Feng S, 2014, PSYCHOL MARKET, V31, P489, DOI 10.1002/mar.20710
   Fernandes J, 2018, PROCEDIA COMPUT SCI, V138, P280, DOI 10.1016/j.procs.2018.10.040
   Fuchs M., 2022, Transitioning towards the future of tourism destinations, P45
   Fuchs M., 2022, Handbook of e-Tourism, P1109
   Garlin FV, 2006, J BUS RES, V59, P755, DOI 10.1016/j.jbusres.2006.01.013
   GelinasChebat C, 1996, PERCEPT MOTOR SKILL, V83, P243, DOI 10.2466/pms.1996.83.1.243
   Gretzel U, 2020, INF TECHNOL TOUR, V22, P187, DOI 10.1007/s40558-020-00181-3
   Grewal D, 2022, J RETAILING, V98, P224, DOI 10.1016/j.jretai.2021.01.007
   Guyer JJ, 2019, PERS SOC PSYCHOL B, V45, P389, DOI 10.1177/0146167218787805
   Hagtvedt H, 2016, J MARKETING RES, V53, P551, DOI 10.1509/jmr.14.0414
   Hair J. F., 2017, Multivariate data analysis, V2nd
   Handayani B., 2018, INT J COMPUTATIONAL, V2, P1, DOI [10.4018/IJCMHS.2018070101, DOI 10.4018/IJCMHS.2018070101]
   Harrington RJ, 2015, INT J HOSP TOUR ADM, V16, P99, DOI 10.1080/15256480.2015.1023133
   Hawkins DM, 2017, S AFR STAT J, V51, P317
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Herhausen D, 2020, J MARKETING RES, V57, P917, DOI 10.1177/0022243720934863
   Hevner K, 1935, AM J PSYCHOL, V47, P103, DOI 10.2307/1416710
   Higgins-Desbiolles F, 2020, TOURISM GEOGR, V22, P610, DOI 10.1080/14616688.2020.1757748
   Hildebrand C, 2020, J BUS RES, V121, P364, DOI 10.1016/j.jbusres.2020.09.020
   Huang X, 2020, J MARKETING, V84, P130, DOI 10.1177/0022242918813577
   Jamrozy U, 2007, INT J CULT TOUR HOSP, V1, P117, DOI 10.1108/17506180710751669
   Jiang XM, 2017, SPEECH COMMUN, V88, P106, DOI 10.1016/j.specom.2017.01.011
   Jiang XM, 2015, J EXP PSYCHOL HUMAN, V41, P597, DOI 10.1037/xhp0000043
   Johnstone T., 2000, Handbook of Emotions, V2nd ed., P220
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kamiloglu RG, 2020, PSYCHON B REV, V27, P237, DOI 10.3758/s13423-019-01701-x
   Kellaris JJ., 1992, Journal of Consumer Psychology, V1, P365, DOI DOI 10.1016/S1057-7408(08)80060-5
   Kim H. J., 2021, CUSTOMER NEEDS SOLUT, V8, P123
   Knoeferle KM, 2017, J RETAILING, V93, P541, DOI 10.1016/j.jretai.2017.06.004
   Latinus M, 2012, BRAIN TOPOGR, V25, P194, DOI 10.1007/s10548-011-0207-9
   Leongómez JD, 2021, PHILOS T R SOC B, V376, DOI 10.1098/rstb.2020.0386
   Li JJ, 2018, TOURISM MANAGE, V68, P301, DOI 10.1016/j.tourman.2018.03.009
   Li X, 2019, INT J RES MARK, V36, P216, DOI 10.1016/j.ijresmar.2019.02.004
   Liu X, 2018, J MARKETING, V82, P86, DOI 10.1509/jm.16.0048
   Magnini V.P., 2009, Journal of Vacation Marketing, V15, P53, DOI 10.1177/1356766708098171
   Mahalanobis P, 1936, National Instituto of Science of India, V2, P49, DOI DOI 10.1007/S13171-019-00164-5
   Martín-Santana JD, 2015, PSYCHOL MUSIC, V43, P763, DOI 10.1177/0305735614567701
   Martín-Santana JD, 2015, BRQ-BUS RES Q, V18, P143, DOI 10.1016/j.brq.2014.06.001
   Maryn Y, 2009, J ACOUST SOC AM, V126, P2619, DOI 10.1121/1.3224706
   Mehrabian A., 1974, APPROACH ENV PSYCHOL
   MILLIMAN RE, 1986, J CONSUM RES, V13, P286, DOI 10.1086/209068
   Moriyama T., 2001, Systems and Computers in Japan, V32, P59, DOI 10.1002/scj.1019
   Ngai EWT, 2022, J BUS RES, V145, P35, DOI 10.1016/j.jbusres.2022.02.049
   Nguyen D, 2021, CURR OPIN BEHAV SCI, V39, P72, DOI 10.1016/j.cobeha.2021.02.013
   North AC, 2004, J APPL SOC PSYCHOL, V34, P1675, DOI 10.1111/j.1559-1816.2004.tb02793.x
   North AC, 2003, ENVIRON BEHAV, V35, P712, DOI 10.1177/0013916503254749
   Novak CC, 2010, J CULIN SCI TECHNOL, V8, P191, DOI 10.1080/15428052.2010.535756
   Oakes S, 2003, SERV IND J, V23, P165, DOI 10.1080/714005121
   Oakes S., 2000, J SERV MARK, V14, P539, DOI DOI 10.1108/08876040010352673
   Oakes S, 2007, J ADVERTISING RES, V47, P38, DOI 10.2501/S0021849907070055
   Oakes S, 2006, APPL COGNITIVE PSYCH, V20, P505, DOI 10.1002/acp.1199
   Oakes S, 2008, J MARKET MANAG, V24, P589, DOI 10.1362/026725708X326002
   Oh H, 2016, J TRAVEL RES, V55, P205, DOI 10.1177/0047287514546228
   Oleszkiewicz A, 2017, PSYCHON B REV, V24, P856, DOI 10.3758/s13423-016-1146-y
   Ordenes FV, 2019, J CONSUM RES, V45, P988, DOI 10.1093/jcr/ucy032
   Pantoja F, 2021, J RETAIL CONSUM SERV, V63, DOI 10.1016/j.jretconser.2021.102730
   Pech-Pacheco JL, 2000, INT C PATT RECOG, P314, DOI 10.1109/ICPR.2000.903548
   Peng C. Y. J., 2006, Real data analysis, P31
   PETTY RE, 1983, J CONSUM RES, V10, P135, DOI 10.1086/208954
   Petty Richard E., 1986, Adv. Exp. Soc. Psychol, V19, P123, DOI [DOI 10.1016/S0065-2601(08)60214-2, 10.1016/S0065-2601(08)60214-2]
   Rodero E, 2017, HUM COMMUN RES, V43, P397, DOI 10.1111/hcre.12109
   Roschk H, 2017, J RETAILING, V93, P228, DOI 10.1016/j.jretai.2016.10.001
   Scherer K.R., 1979, Social markers in speech, VVolume 6
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Schwenzow J, 2021, J BUS RES, V123, P367, DOI 10.1016/j.jbusres.2020.09.059
   Spangenberg ER, 2005, J BUS RES, V58, P1583, DOI 10.1016/j.jbusres.2004.09.005
   Spence C, 2019, MULTISENS RES, V32, P275, DOI 10.1163/22134808-20191403
   Sueur J., 2018, Sound Analysis and Synthesis with R. Cham, DOI DOI 10.1007/978-3-319-77647-7
   Tabachnick B. G., 2007, Using multivariate statistics, V5
   Takahashi N., 2017, P 2017 IEEE WORKSH A
   Tellis GJ, 2019, J MARKETING, V83, P1, DOI 10.1177/0022242919841034
   Tigue CC, 2012, EVOL HUM BEHAV, V33, P210, DOI 10.1016/j.evolhumbehav.2011.09.004
   Tracy DK, 2011, BMC NEUROSCI, V12, DOI 10.1186/1471-2202-12-128
   Trompeta MA, 2022, J BUS RES, V138, P130, DOI 10.1016/j.jbusres.2021.08.067
   Truong VD, 2017, J SUSTAIN TOUR, V25, P884, DOI 10.1080/09669582.2016.1201093
   Turley LW, 2000, J BUS RES, V49, P193, DOI 10.1016/S0148-2963(99)00010-7
   Tusing KJ, 2000, HUM COMMUN RES, V26, P148, DOI 10.1111/j.1468-2958.2000.tb00754.x
   Van Zant AB, 2020, J PERS SOC PSYCHOL, V118, P661, DOI 10.1037/pspi0000193
   vBezooijen R., 1984, CHARACTERISTICS RECO
   Waaramaa T, 2010, J VOICE, V24, P30, DOI 10.1016/j.jvoice.2008.04.004
   Wang X, 2021, J CONSUM RES, V48, P189, DOI 10.1093/jcr/ucab012
   Weng LS, 2021, TOURISM MANAGE, V85, DOI 10.1016/j.tourman.2020.104278
   Whiteside SP, 1999, PERCEPT MOTOR SKILL, V88, P1219, DOI 10.2466/PMS.88.3.1219-1222
   Whiteside SP, 1999, PERCEPT MOTOR SKILL, V89, P1195, DOI 10.2466/PMS.89.7.1195-1208
   Wilson S., 2003, PSYCHOL MUSIC, V31, P93, DOI DOI 10.1177/0305735603031001327
   Zander M.F., 2006, PSYCHOL MUSIC, V34, P465, DOI [10.1177/0305735606067158, DOI 10.1177/0305735606067158]
   ZENITH Richard, 2021, Pessoa: A Biography
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhu R, 2005, J MARKETING RES, V42, P333, DOI 10.1509/jmkr.2005.42.3.333
   Zoghaib A, 2019, RECH APPL MARKET-ENG, V34, P83, DOI 10.1177/2051570719828687
   Zoghaib A, 2017, J PROD BRAND MANAG, V26, P492, DOI 10.1108/JPBM-06-2016-1230
NR 111
TC 0
Z9 0
U1 32
U2 32
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0047-2875
EI 1552-6763
J9 J TRAVEL RES
JI J. Travel Res.
PD 2023 JUL 17
PY 2023
DI 10.1177/00472875231185882
EA JUL 2023
PG 16
WC Hospitality, Leisure, Sport & Tourism
WE Social Science Citation Index (SSCI)
SC Social Sciences - Other Topics
GA M4LQ2
UT WOS:001029940600001
OA hybrid
DA 2024-01-09
ER

PT J
AU Wu, YY
   Chong, HJ
AF Wu, Yingyi
   Chong, Hyun-Ju
TI Affective responses to singing voice in different vocal registers and
   modes
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF KOREA
LA English
DT Article
DE Musical elements; Vocal register; Affective response; Valence; Arousal;
   Vocal music
ID MUSIC; EMOTIONS; EXPRESSION; PITCH
AB The purpose of this study was to investigate listener's affective responses to different vocal registers and modes in terms of valence (i.e., negative to positive affect) and arousal (i.e., low to high energy level). The data were collected from four different conditions (i.e., higher and lower registers paired with major and minor modes). A total of 188 female college students participated in the survey online and rated their perceived valence and arousal levels on a visual analogue scale after listening to each excerpt. The two-way analysis of variance (ANOVA) was administered for data analysis. The results revealed that there were significant differences in the affective responses to the two vocal registers, showing that the arousal was more affected by the register than the valence. Secondly, mode had statistically significant impact on both valence and arousal while weighing more on valence. Further, there was significant interaction effect of vocal register and mode on valence, but not on arousal. Results also displayed that listeners had the most negative valence when listening to the excerpt of minor mode in higher register, while having the lowest arousal when listening to the excerpt of minor mode in lower register. These findings imply that it is important to consider the vocal range as well as the musical mode when selecting music for appreciation.
C1 [Wu, Yingyi; Chong, Hyun-Ju] Ewha Womans Univ, Dept Mus Therapy, 52 Ewhayeodae Gil, Seoul 03760, South Korea.
C3 Ewha Womans University
RP Wu, YY (corresponding author), Ewha Womans Univ, Dept Mus Therapy, 52 Ewhayeodae Gil, Seoul 03760, South Korea.
EM yingyi.wu@ewhain.ney
OI Chong, Hyun Ju/0000-0001-9788-0320; WU, YINGYI/0009-0004-3145-1047
CR Aucouturier JJ, 2007, PATTERN RECOGN LETT, V28, P654, DOI 10.1016/j.patrec.2006.11.004
   Berg J., 2006, JSCI, V4, P65
   Bigand E, 1996, PERCEPT PSYCHOPHYS, V58, P125, DOI 10.3758/BF03205482
   Collier WG, 2004, MUSIC SCI, V8, P151, DOI 10.1177/102986490400800203
   Droit-Volet S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00417
   Gomez P, 2007, EMOTION, V7, P377, DOI 10.1037/1528-3542.7.2.377
   Hakanpää T, 2019, J VOICE, V33, P501, DOI 10.1016/j.jvoice.2018.01.012
   Hunter PG, 2010, PSYCHOL AESTHET CREA, V4, P47, DOI 10.1037/a0016873
   Husain G, 2002, MUSIC PERCEPT, V20, P151, DOI 10.1525/mp.2002.20.2.151
   Jaquet L, 2014, PSYCHOL MUSIC, V42, P51, DOI 10.1177/0305735612456583
   Juslin PN, 2010, MUSIC ANAL, V29, P334, DOI 10.1111/j.1468-2249.2011.00323.x
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kamenetsky S.B., 1997, PSYCHOL MUSIC, V25, P149
   Liu Y, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02118
   Loui P, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00675
   Morreale F., 2013, PROC ICME3, V16, P374
   Schubert E, 2004, MUSIC PERCEPT, V21, P561, DOI 10.1525/mp.2004.21.4.561
   Webster GD, 2005, MOTIV EMOTION, V29, P19, DOI 10.1007/s11031-005-4414-0
   Yeung AWK, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00086
NR 19
TC 0
Z9 0
U1 0
U2 2
PU ACOUSTICAL SOC KOREA
PI SEOUL
PA RM 1619, 280 GWANGPYEONG-RO, GANGNAM-GU, SEOUL, SOUTH KOREA
SN 1225-4428
EI 2287-3775
J9 J ACOUST SOC KOREA
JI J. Acoust. Soc. Korea
PY 2023
VL 42
IS 1
BP 75
EP 82
DI 10.7776/ASK.2023.42.1.075
PG 8
WC Acoustics
WE Emerging Sources Citation Index (ESCI)
SC Acoustics
GA I1VF2
UT WOS:001000723800010
DA 2024-01-09
ER

PT J
AU Eyben, F
   Scherer, KR
   Schuller, BW
   Sundberg, J
   André, E
   Busso, C
   Devillers, LY
   Epps, J
   Laukka, P
   Narayanan, SS
   Truong, KP
AF Eyben, Florian
   Scherer, Klaus R.
   Schuller, Bjoern W.
   Sundberg, Johan
   Andre, Elisabeth
   Busso, Carlos
   Devillers, Laurence Y.
   Epps, Julien
   Laukka, Petri
   Narayanan, Shrikanth S.
   Truong, Khiet P.
TI The Geneva Minimalistic Acoustic Parameter Set (GeMAPS) for Voice
   Research and Affective Computing
SO IEEE TRANSACTIONS ON AFFECTIVE COMPUTING
LA English
DT Article
DE Affective computing; acoustic features; standard; emotion recognition;
   speech analysis; geneva minimalistic parameter set
ID VOCAL EXPRESSION; EMOTION; FEATURES; COMMUNICATION; RECOGNITION; SPEECH;
   CORPUS; IMPACT; MUSIC; CUES
AB Work on voice sciences over recent decades has led to a proliferation of acoustic parameters that are used quite selectively and are not always extracted in a similar fashion. With many independent teams working in different research areas, shared standards become an essential safeguard to ensure compliance with state-of-the-art methods allowing appropriate comparison of results across studies and potential integration and combination of extraction and recognition systems. In this paper we propose a basic standard acoustic parameter set for various areas of automatic voice analysis, such as paralinguistic or clinical speech analysis. In contrast to a large brute-force parameter set, we present a minimalistic set of voice parameters here. These were selected based on a) their potential to index affective physiological changes in voice production, b) their proven value in former studies as well as their automatic extractability, and c) their theoretical significance. The set is intended to provide a common baseline for evaluation of future research and eliminate differences caused by varying parameter sets or even different implementations of the same parameters. Our implementation is publicly available with the openSMILE toolkit. Comparative evaluations of the proposed feature set and large baseline feature sets of INTERSPEECH challenges show a high performance of the proposed set in relation to its size.
C1 [Eyben, Florian; Schuller, Bjoern W.] audEERING UG, Gilching, Germany.
   [Eyben, Florian] Tech Univ Munich, Munich, Germany.
   [Eyben, Florian; Scherer, Klaus R.; Schuller, Bjoern W.] Swiss Ctr Affect Sci, Geneva, Switzerland.
   [Scherer, Klaus R.] Univ Geneva, Geneva, Switzerland.
   [Scherer, Klaus R.] Univ Munich, Munich, Germany.
   [Schuller, Bjoern W.] Univ Passau, Chair Complex & Intelligent Syst, Passau, Germany.
   [Schuller, Bjoern W.] Imperial Coll, Dept Comp, London, England.
   [Sundberg, Johan] KTH Royal Inst Technol, Stockholm, Sweden.
   [Andre, Elisabeth] Univ Augsburg, Fac Appl Comp Sci, Augsburg, Germany.
   [Busso, Carlos] Univ Texas Dallas, Dept Elect Engn, Richardson, TX 75083 USA.
   [Devillers, Laurence Y.] Univ Paris 04, Paris, France.
   [Devillers, Laurence Y.] CNRS, LIMSI, Paris, France.
   [Epps, Julien] Univ New South Wales, Sydney, NSW, Australia.
   [Epps, Julien] NICTA ATP Lab, Eveleigh, Australia.
   [Laukka, Petri] Stockholm Univ, Stockholm, Sweden.
   [Narayanan, Shrikanth S.] Univ Southern Calif, SAIL, Los Angeles, CA 90089 USA.
   [Truong, Khiet P.] Univ Twente, Dept Human Media Interact, Enschede, Netherlands.
C3 Technical University of Munich; University of Geneva; University of
   Munich; University of Passau; Imperial College London; Royal Institute
   of Technology; University of Augsburg; University of Texas System;
   University of Texas Dallas; Sorbonne Universite; Universite Paris
   Saclay; Centre National de la Recherche Scientifique (CNRS); University
   of New South Wales Sydney; Stockholm University; University of Southern
   California; University of Twente
RP Eyben, F; Schuller, BW (corresponding author), audEERING UG, Gilching, Germany.; Eyben, F (corresponding author), Tech Univ Munich, Munich, Germany.; Eyben, F; Scherer, KR; Schuller, BW (corresponding author), Swiss Ctr Affect Sci, Geneva, Switzerland.; Scherer, KR (corresponding author), Univ Geneva, Geneva, Switzerland.; Scherer, KR (corresponding author), Univ Munich, Munich, Germany.; Schuller, BW (corresponding author), Univ Passau, Chair Complex & Intelligent Syst, Passau, Germany.; Schuller, BW (corresponding author), Imperial Coll, Dept Comp, London, England.; Sundberg, J (corresponding author), KTH Royal Inst Technol, Stockholm, Sweden.; André, E (corresponding author), Univ Augsburg, Fac Appl Comp Sci, Augsburg, Germany.; Busso, C (corresponding author), Univ Texas Dallas, Dept Elect Engn, Richardson, TX 75083 USA.; Devillers, LY (corresponding author), Univ Paris 04, Paris, France.; Devillers, LY (corresponding author), CNRS, LIMSI, Paris, France.; Epps, J (corresponding author), Univ New South Wales, Sydney, NSW, Australia.; Epps, J (corresponding author), NICTA ATP Lab, Eveleigh, Australia.; Laukka, P (corresponding author), Stockholm Univ, Stockholm, Sweden.; Narayanan, SS (corresponding author), Univ Southern Calif, SAIL, Los Angeles, CA 90089 USA.; Truong, KP (corresponding author), Univ Twente, Dept Human Media Interact, Enschede, Netherlands.
EM fe@audeering.com; Klaus.Scherer@unige.ch; schuller@tum.de;
   pjohan@speech.kth.se; andre@informatik.uni-augsburg.de;
   busso@utdallas.edu; devil@limsi.fr; j.epps@unsw.edu.au;
   petri.laukka@psychology.su.se; shri@sipi.usc.edu; k.p.truong@utwente.nl
RI Laukka, Petri/B-5259-2008; VARRECCHIA, TIWANA/AAJ-8712-2021; Narayanan,
   Shrikanth S/D-5676-2012; Schuller, Björn Wolfgang/D-3241-2011; Andre,
   Elisabeth/AAW-4960-2021
OI Laukka, Petri/0000-0001-8771-6818; Schuller, Björn
   Wolfgang/0000-0002-6478-8699; Andre, Elisabeth/0000-0002-2367-162X;
   Epps, Julien/0000-0001-6624-5551; Busso, Carlos/0000-0002-4075-4072
FU RC Advanced Grant in the European Community's seventh Framework
   Programme [230331-PROPEREMO]; National Center of Competence in Research
   (NCCR) Affective Sciences - Swiss National Science Foundation
   [51NF40-104897]; Direct For Computer & Info Scie & Enginr; Div Of
   Information & Intelligent Systems [0911009] Funding Source: National
   Science Foundation
FX The authors would like to thank Tanja Banziger, Pascal Belin, and
   Olivier Lartillot for their helpful contributions and inspiring
   discussions at the Geneva Bridge Meeting, which started our joint effort
   to create this parameter set recommendation. This research was supported
   by an RC Advanced Grant in the European Community's seventh Framework
   Programme under grant agreement 230331-PROPEREMO (Production and
   perception of emotion: an affective sciences approach) to Klaus Scherer
   and by the National Center of Competence in Research (NCCR) Affective
   Sciences financed by the Swiss National Science Foundation
   (51NF40-104897) and hosted by the University of Geneva.
CR Airas M, 2005, P INTERSPEECH, P2145
   [Anonymous], 2011, P INTERSPEECH
   [Anonymous], 2013, P INT
   [Anonymous], P INTERSPEECH ISCA L
   [Anonymous], 1999, PSYCHOACOUSTICS FACT, DOI DOI 10.1007/978-3-662-09562-1
   [Anonymous], 2006, P 5 SLOV 1 INT C LAN
   [Anonymous], 2007, INTERSPEECH 2007 8 A
   [Anonymous], P INTERSPEECH
   Bänziger T, 2012, EMOTION, V12, P1161, DOI 10.1037/a0025827
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Boersma P., 2021, Glot International
   Bone D, 2014, IEEE T AFFECT COMPUT, V5, P201, DOI 10.1109/TAFFC.2014.2326393
   Burkhardt F, 2005, 9 EUR C SPEECH COMM, V5, P1517, DOI [10.21437/Interspeech.2005-446, DOI 10.21437/INTERSPEECH.2005-446]
   Busso C, 2009, IEEE T AUDIO SPEECH, V17, P582, DOI 10.1109/TASL.2008.2009578
   Cummins N, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P3008
   Eyben F., 2013, P 21 ACM INT C MULT, P835, DOI 10.1145/2502081.2502224
   Eyben F., 2012, P M AC, V9, P1
   Fonagy Ivan., 1983, VIVE VOIX ESSAIS PSY
   Goudbeek M, 2010, J ACOUST SOC AM, V128, P1322, DOI 10.1121/1.3466853
   Grimm M, 2007, SPEECH COMMUN, V49, P787, DOI 10.1016/j.specom.2007.01.010
   Grimm M, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P865, DOI 10.1109/ICME.2008.4607572
   Hall Mark, 2009, SIGKDD Explorations, V11, P10, DOI [10.1145/1656274.1656278, DOI 10.1145/1656274.1656278]
   HAMMARBERG B, 1980, ACTA OTO-LARYNGOL, V90, P441, DOI 10.3109/00016488009131746
   Harnmerschmidt K, 2007, J VOICE, V21, P531, DOI 10.1016/j.jvoice.2006.03.002
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423
   HERMES DJ, 1988, J ACOUST SOC AM, V83, P257, DOI 10.1121/1.396427
   Juslin PN, 2001, EMOTION, V1, P381, DOI 10.1037//1528-3542.1.4.381
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Laukka P, 2012, SOC PSYCHOL PERS SCI, V3, P529, DOI 10.1177/1948550611428011
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792
   Makhoul J., 1976, 1976 IEEE International Conference on Acoustics, Speech and Signal Processing, P466
   Marchi E, 2012, PROCEEDINGS OF 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON PRIVACY, SECURITY, RISK AND TRUST AND 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM/PASSAT 2012), P961, DOI 10.1109/SocialCom-PASSAT.2012.97
   Moore E, 2008, IEEE T BIO-MED ENG, V55, P96, DOI 10.1109/TBME.2007.900562
   Patel S., 2010, POWER, P1
   Patel S., 2013, VOCAL BEHAV, P167
   Patel S, 2011, BIOL PSYCHOL, V87, P93, DOI 10.1016/j.biopsycho.2011.02.010
   Le N, 2011, SPEECH COMMUN, V53, P540, DOI 10.1016/j.specom.2011.01.005
   Sauter DA, 2010, Q J EXP PSYCHOL, V63, P2251, DOI 10.1080/17470211003721642
   Scherer KR, 2015, COMPUT SPEECH LANG, V29, P218, DOI 10.1016/j.csl.2013.10.002
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   SCHLOSBERG H, 1954, PSYCHOL REV, V61, P81, DOI 10.1037/h0054570
   Schroder M., 2004, REPORTS PHONETICS U, V7
   Schroder M., 2010, BLUEPRINT AFFECTIVE, P222
   Schuller B., 2010, P INTERSPEECH, DOI DOI 10.21437/INTERSPEECH.2010-739
   Schuller B., 2014, P INTERSPEECH, P427
   Schuller B., 2013, SIGNALS OCMMUNICATIO
   Schuller B, 2008, INT CONF ACOUST SPEE, P4501, DOI 10.1109/ICASSP.2008.4518656
   Schuller B, 2010, IEEE T AFFECT COMPUT, V1, P119, DOI 10.1109/T-AFFC.2010.8
   Schuller B, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P552, DOI 10.1109/ASRU.2009.5372886
   Schuller B, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P336
   Schuller B, 2009, IMAGE VISION COMPUT, V27, P1760, DOI 10.1016/j.imavis.2009.02.013
   Sethu V, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P611, DOI 10.1109/ICDSP.2007.4288656
   Sethu V, 2013, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2013-19
   Steidl Stefan, 2009, Automatic classification of emotion related user states in spontaneous children's speech
   Sundberg J, 2011, IEEE T AFFECT COMPUT, V2, P162, DOI 10.1109/T-AFFC.2011.14
   Tahon M., 2010, P SPEECH PROS CHIC I
   Tamarit L., 2008, P SPEECH AN PROC KNO
   Trevino AC, 2011, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2011-42
   Ververidis D, 2006, SPEECH COMMUN, V48, P1162, DOI 10.1016/j.specom.2006.04.003
   Weninger F., 2012, P 13 ANN C INT SPEEC
   Weninger F, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00292
   Williamson J.R., 2013, P 3 ACM INT WORKSH A, P41, DOI [10.1145/2512530.2512531., DOI 10.1145/2512530.2512531, 10.1145/2512530.2512531]
   Yap T. F., 2012, THESIS
   Yap TF, 2011, INT CONF ACOUST SPEE, P5700
   Yap TF, 2011, EURASIP J ADV SIG PR, DOI 10.1155/2011/219253
   Yildirim S., 2004, International Conference on Spoken Language Processing (ICSLP), P2193, DOI DOI 10.21437/INTERSPEECH.2004-242
   Young S, 2006, The HTK Book
NR 68
TC 729
Z9 762
U1 8
U2 97
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1949-3045
J9 IEEE T AFFECT COMPUT
JI IEEE Trans. Affect. Comput.
PD APR-JUN
PY 2016
VL 7
IS 2
BP 190
EP 202
DI 10.1109/TAFFC.2015.2457417
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DW9PZ
UT WOS:000383995300007
OA Green Submitted, hybrid
DA 2024-01-09
ER

PT J
AU Nussbaum, C
AF Nussbaum, Christine
TI LINKS BETWEEN MUSICALITY AND VOCAL EMOTION PERCEPTION: ACOUSTIC
   PARAMETERS AND ELECTROPHYSIOLOGICAL CORRELATES
SO PSYCHOPHYSIOLOGY
LA English
DT Meeting Abstract
CT Annual Meeting of the Society-for-Psychophysiological-Research (SPR)
CY SEP 28-OCT 01, 2022
CL Vancouver, CANADA
SP Soc Psychophysiol Res
C1 [Nussbaum, Christine] Friedrich Schiller Univ Jena, Jena, Germany.
C3 Friedrich Schiller University of Jena
RI Nussbaum, Christine/AAV-3561-2021
FU Studienstiftung des Deutschen Volkes
FX Studienstiftung des Deutschen Volkes; Project "Vocal emotion perception:
   Acoustic parameters and electrophysiological correlates".
NR 0
TC 0
Z9 0
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0048-5772
EI 1469-8986
J9 PSYCHOPHYSIOLOGY
JI Psychophysiology
PD AUG
PY 2022
VL 59
SU 1
BP S31
EP S31
PG 1
WC Psychology, Biological; Neurosciences; Physiology; Psychology;
   Psychology, Experimental
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Psychology; Neurosciences & Neurology; Physiology
GA 6D2XW
UT WOS:000882561000443
DA 2024-01-09
ER

PT J
AU Kornreich, C
   Brevers, D
   Canivet, D
   Ermer, E
   Naranjo, C
   Constant, E
   Verbanck, P
   Campanella, S
   Noël, X
AF Kornreich, Charles
   Brevers, Damien
   Canivet, Delphine
   Ermer, Elsa
   Naranjo, Cecilia
   Constant, Eric
   Verbanck, Paul
   Campanella, Salvatore
   Noel, Xavier
TI Impaired processing of emotion in music, faces and voices supports a
   generalized emotional decoding deficit in alcoholism
SO ADDICTION
LA English
DT Article
DE Alcohol; emotion; empathy; face; mirror neurone; music; theory of mind;
   voice
ID FACIAL EXPRESSION RECOGNITION; HIGH-RISK; PERFORMANCE; AMYGDALA;
   COMMUNICATION; ALEXITHYMIA; IMPAIRMENTS; PERCEPTION; ACTIVATION;
   DEPENDENCE
AB Aim To test the generalized emotional decoding impairment hypothesis in alcoholism. Design Cross-sectional behavioural study comparing emotion recognition conveyed by faces, voices and musical excerpts. Setting Alcohol detoxification unit of Brugmann University Hospital. Participants Twenty-five recently detoxified alcohol-dependent patients were compared to 25 normal controls matched for sex, age and educational level. Measurements From faces, voices and musical excerpts, participants were instructed to rate the intensity of several emotions on a scale from 0 for absent to 9 for highly present. Depression, anxiety and sustained/selective attention capacities were controlled for. Findings Alcohol-dependent patients were less accurate than controls in identifying the target emotion in faces (P?<?0.001), voices (P?<?0.001) and musical excerpts (P?<?0.001). Conclusions Alcohol-dependent patients who are completing detoxification are impaired in recognizing emotions conveyed by faces, voices and music; these results suggest a generalized emotional decoding impairment. Hypothetically, deficits in the fronto-parietal mirror neurone system could link all these disturbances together.
C1 [Kornreich, Charles; Brevers, Damien; Canivet, Delphine; Naranjo, Cecilia; Verbanck, Paul; Campanella, Salvatore; Noel, Xavier] Univ Libre Bruxelles, Lab Psychol Med & Addictol, Brussels, Belgium.
   [Ermer, Elsa] Mind Res Network, Albuquerque, NM USA.
   [Constant, Eric] Catholic Univ Louvain, Dept Psychiat, B-1200 Brussels, Belgium.
C3 Universite Libre de Bruxelles; Lovelace Respiratory Research Institute;
   Universite Catholique Louvain
RP Kornreich, C (corresponding author), CHU Brugmann, Inst Psychiat, Pl Van Gehuchten 4, Brussels, Belgium.
EM ckornrei@ulb.ac.be
RI Brevers, Damien/Q-6171-2018
OI Brevers, Damien/0000-0003-4503-0898; Kornreich,
   Charles/0000-0002-4898-5588
FU Laboratoire de Psychologie Medicale et d'Addictologie, Universite Libre
   de Bruxelles (ULB), Belgium
FX Dr Xavier Noel and Dr Salvatore Campanella are Research Associates of
   the Belgium Fund for Scientific Research (FRS/FNRS). Mr Damien Brevers
   is Research Fellow of the FRS/FNRS. The present research was supported
   by the Laboratoire de Psychologie Medicale et d'Addictologie, Universite
   Libre de Bruxelles (ULB), Belgium.
CR [Anonymous], WORDSWORTH DICT MUSI
   Association A.P, 2000, Diagnostic and Statistical Manual of Mental Disorders, V4th
   Ayotte J, 2002, BRAIN, V125, P238, DOI 10.1093/brain/awf028
   BECK AT, 1988, CLIN PSYCHOL REV, V8, P77, DOI 10.1016/0272-7358(88)90050-5
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Brickenkamp R., 1998, The d2 Test of Attention
   Carr L, 2003, P NATL ACAD SCI USA, V100, P5497, DOI 10.1073/pnas.0935845100
   Drapeau J, 2009, ANN NY ACAD SCI, V1169, P342, DOI 10.1111/j.1749-6632.2009.04768.x
   Foisy ML, 2007, PSYCHIAT RES, V150, P33, DOI 10.1016/j.psychres.2005.12.008
   Foisy ML, 2007, ALCOHOL CLIN EXP RES, V31, P404, DOI 10.1111/j.1530-0277.2006.00321.x
   Foisy ML, 2005, J STUD ALCOHOL, V66, P673, DOI 10.15288/jsa.2005.66.673
   Franklin TR, 2002, BIOL PSYCHIAT, V51, P134, DOI 10.1016/S0006-3223(01)01269-0
   Frigerio E, 2002, PSYCHIAT RES, V113, P161, DOI 10.1016/S0165-1781(02)00244-5
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Fusar-Poli P, 2009, J PSYCHIATR NEUROSCI, V34, P418
   Gallese V, 2003, PSYCHOPATHOLOGY, V36, P171, DOI 10.1159/000072786
   Glahn DC, 2007, BIOL PSYCHIAT, V61, P1306, DOI 10.1016/j.biopsych.2006.09.041
   Gosselin N, 2011, CORTEX, V47, P1116, DOI 10.1016/j.cortex.2011.05.012
   Hill SY, 2001, BIOL PSYCHIAT, V49, P894, DOI 10.1016/S0006-3223(01)01088-5
   Jackendoff R, 2006, COGNITION, V100, P33, DOI 10.1016/j.cognition.2005.11.005
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Kornreich C, 2003, PSYCHIAT RES, V119, P251, DOI 10.1016/S0165-1781(03)00130-6
   Kornreich C, 2002, ALCOHOL ALCOHOLISM, V37, P394, DOI 10.1093/alcalc/37.4.394
   Kornreich C, 2001, PSYCHIAT RES, V102, P235, DOI 10.1016/S0165-1781(01)00261-X
   Kornreich C, 2001, J STUD ALCOHOL, V62, P533, DOI 10.15288/jsa.2001.62.533
   Kornreich C, 2011, ADDICTION, V106, P951, DOI 10.1111/j.1360-0443.2010.03346.x
   Le Berre AP, 2010, ALCOHOL CLIN EXP RES, V34, P1888, DOI 10.1111/j.1530-0277.2010.01277.x
   Leslie KR, 2004, NEUROIMAGE, V21, P601, DOI 10.1016/j.neuroimage.2003.09.038
   Lyvers M, 2012, ADDICT BEHAV, V37, P205, DOI 10.1016/j.addbeh.2011.10.012
   Malloch S., 2009, COMMUNICATIVE MUSICA, DOI DOI 10.1111/J.1752-0118.2009.01158_1.X
   Marinkovic K, 2009, ALCOHOL CLIN EXP RES, V33, P1880, DOI 10.1111/j.1530-0277.2009.01026.x
   Marlatt GA, 1996, ADDICTION, V91, pS37, DOI 10.1111/j.1360-0443.1996.tb02326.x
   Maurage P, 2008, ALCOHOL CLIN EXP RES, V32, P600, DOI 10.1111/j.1530-0277.2007.00611.x
   Maurage P, 2007, CLIN NEUROPHYSIOL, V118, P633, DOI 10.1016/j.clinph.2006.11.007
   Maurage P, 2008, INT J PSYCHOPHYSIOL, V70, P50, DOI 10.1016/j.ijpsycho.2008.05.572
   Maurage P, 2011, ALCOHOL CLIN EXP RES, V35, P1662, DOI 10.1111/j.1530-0277.2011.01512.x
   Maurage P, 2009, ALCOHOL ALCOHOLISM, V44, P476, DOI 10.1093/alcalc/agp037
   Menon V, 2002, NEUROIMAGE, V17, P1742, DOI 10.1006/nimg.2002.1295
   Molnar-Szakacs I, 2006, SOC COGN AFFECT NEUR, V1, P235, DOI 10.1093/scan/nsl029
   Monnot M, 2001, ALCOHOL CLIN EXP RES, V25, P362, DOI 10.1111/j.1530-0277.2001.tb02222.x
   Naranjo C, 2011, J AFFECT DISORDERS, V128, P243, DOI 10.1016/j.jad.2010.06.039
   Oosterhof NN, 2008, P NATL ACAD SCI USA, V105, P11087, DOI 10.1073/pnas.0805664105
   Philippot P, 1999, ALCOHOL CLIN EXP RES, V23, P1031, DOI 10.1097/00000374-199906000-00010
   Resnicow JE, 2004, MUSIC PERCEPT, V22, P145, DOI 10.1525/mp.2004.22.1.145
   Sacks Oliver, 2008, Musicophilia: Tales of Music and the Brain
   Salloum JB, 2007, ALCOHOL CLIN EXP RES, V31, P1490, DOI 10.1111/j.1530-0277.2007.00447.x
   Smith ML, 2005, PSYCHOL SCI, V16, P184, DOI 10.1111/j.0956-7976.2005.00801.x
   Spielberger C.D., 1983, Manual for the State-Trait Anxiety Inventory
   Stavro K., 2012, ADDICT BIOL, DOI [10.1111/j.1369-1600.2011.00418x, DOI 10.1111/J.1369-1600.2011.00418X]
   Stephens DN, 2008, PHILOS T R SOC B, V363, P3169, DOI 10.1098/rstb.2008.0097
   Thorberg FA, 2009, ADDICT BEHAV, V34, P237, DOI 10.1016/j.addbeh.2008.10.016
   Townshend JM, 2003, NEUROPSYCHOLOGIA, V41, P773, DOI 10.1016/S0028-3932(02)00284-1
   Uekermann J, 2007, ADDICTION, V102, P232, DOI 10.1111/j.1360-0443.2006.01656.x
   Uekermann J, 2005, CORTEX, V41, P189, DOI 10.1016/S0010-9452(08)70893-1
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   Volkow ND, 2003, J CLIN INVEST, V111, P1444, DOI 10.1172/JCI200318533
   Witvliet C.V., 1996, PSYCHOPHYSIOLOGY S1, V33, P91
NR 59
TC 53
Z9 66
U1 0
U2 43
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0965-2140
EI 1360-0443
J9 ADDICTION
JI Addiction
PD JAN
PY 2013
VL 108
IS 1
BP 80
EP 88
DI 10.1111/j.1360-0443.2012.03995.x
PG 9
WC Substance Abuse; Psychiatry
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Substance Abuse; Psychiatry
GA 061XU
UT WOS:000312884400016
PM 22725253
OA Green Published
DA 2024-01-09
ER

PT J
AU Pauletto, S
   Balentine, B
   Pidcock, C
   Jones, K
   Bottaci, L
   Aretoulaki, M
   Wells, J
   Mundy, DP
   Balentine, J
AF Pauletto, Sandra
   Balentine, Bruce
   Pidcock, Chris
   Jones, Kevin
   Bottaci, Leonardo
   Aretoulaki, Maria
   Wells, Jez
   Mundy, Darren P.
   Balentine, James
TI Exploring expressivity and emotion with artificial voice and speech
   technologies
SO LOGOPEDICS PHONIATRICS VOCOLOGY
LA English
DT Article
DE Artificial emotion; chatbot; conversational kiosk; speech synthesis;
   TTS; voice synthesis
ID SYNTHETIC SPEECH; SIMULATION; MUSIC
AB Emotion in audio-voice signals, as synthesized by text-to-speech (TTS) technologies, was investigated to formulate a theory of expression for user interface design. Emotional parameters were specified with markup tags, and the resulting audio was further modulated with post-processing techniques. Software was then developed to link a selected TTS synthesizer with an automatic speech recognition (ASR) engine, producing a chatbot that could speak and listen. Using these two artificial voice subsystems, investigators explored both artistic and psychological implications of artificial speech emotion. Goals of the investigation were interdisciplinary, with interest in musical composition, augmentative and alternative communication (AAC), commercial voice announcement applications, human-computer interaction (HCI), and artificial intelligence (AI). The work-in-progress points towards an emerging interdisciplinary ontology for artificial voices. As one study output, HCI tools are proposed for future collaboration.
C1 [Pauletto, Sandra] Univ York, Dept Theatre Film & Televis, York YO10 5GB, N Yorkshire, England.
   [Balentine, Bruce] Enterprise Integrat Grp, Zurich, Switzerland.
   [Pidcock, Chris] CereProc Ltd, Edinburgh, Midlothian, Scotland.
   [Bottaci, Leonardo] Univ Hull, Kingston Upon Hull HU6 7RX, N Humberside, England.
   [Aretoulaki, Maria] DialogCONNECTION Ltd, Manchester, Lancs, England.
   [Wells, Jez] Univ York, Dept Mus, York YO10 5GB, N Yorkshire, England.
   [Mundy, Darren P.] Univ Hull, Sch Arts & New Media, Kingston Upon Hull HU6 7RX, N Humberside, England.
   [Balentine, James] Univ Texas San Antonio, Dept Mus, San Antonio, TX USA.
C3 University of York - UK; University of Hull; University of York - UK;
   University of Hull; University of Texas System; University of Texas at
   San Antonio (UTSA)
RP Pauletto, S (corresponding author), Univ York, Dept Theatre Film & Televis, East Campus,Baird Lane, York YO10 5GB, N Yorkshire, England.
EM sandra.pauletto@york.ac.uk
RI Pauletto, Sandra/JNT-4780-2023
OI Pauletto, Sandra/0000-0002-9404-851X
FU EPSRC CreST Network; EPSRC [EP/I013512/1] Funding Source: UKRI;
   Engineering and Physical Sciences Research Council [EP/I013512/1]
   Funding Source: researchfish
FX We also would like to thank all colleagues from the EPSRC CreST Network
   for funding and supporting this work.
CR [Anonymous], 1964, The Communication of Emotional Meaning
   Aylett MP, 2007, CEREVOICE CHARACTERF, P174
   Bänziger T, 2005, SPEECH COMMUN, V46, P252, DOI 10.1016/j.specom.2005.02.016
   Bowles T, 2010, P 7 SOUND MUS COMP C
   Christian B., 2012, MOST HUMAN HUMAN
   Ekman P., 1999, HDB COGNITION EMOTIO, P45
   Jones K., 2011, MONOLOGUES UNPUB
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Murray IR, 2008, COMPUT SPEECH LANG, V22, P107, DOI 10.1016/j.csl.2007.06.001
   MURRAY IR, 1993, J ACOUST SOC AM, V93, P1097, DOI 10.1121/1.405558
   Pauletto S., 2010, PROC 5 AUDIO MOSTLY, P1
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Scherer KR., 1979, SOCIAL MARKERS SPEEC, P147
   Schroder M., 2001, INTERSPEECH P DALSG, V3
   Shouse E, 2005, M C J J MEDIA CULTUR, V8
NR 15
TC 9
Z9 9
U1 5
U2 74
PU INFORMA HEALTHCARE
PI NEW YORK
PA 52 VANDERBILT AVE, NEW YORK, NY 10017 USA
SN 1401-5439
J9 LOGOP PHONIATR VOCO
JI Logop. Phoniatr. Vocology.
PD OCT
PY 2013
VL 38
IS 3
BP 115
EP 125
DI 10.3109/14015439.2013.810303
PG 11
WC Audiology & Speech-Language Pathology; Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Audiology & Speech-Language Pathology; Otorhinolaryngology
GA 226AX
UT WOS:000325007700004
PM 24024543
DA 2024-01-09
ER

PT J
AU Livingstone, SR
   Russo, FA
AF Livingstone, Steven R.
   Russo, Frank A.
TI The Ryerson Audio-Visual Database of Emotional Speech and Song
   (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in
   North American English
SO PLOS ONE
LA English
DT Article
ID MULTISENSORY INTEGRATION; CULTURAL SPECIFICITY; PARKINSONS-DISEASE;
   CONGENITAL AMUSIA; NONVERBAL ACCENTS; RESISTANT RULES; BASIC EMOTIONS;
   VALIDATED SET; MUSIC-THERAPY; RECOGNITION
AB The RAVDESS is a validated multimodal database of emotional speech and song. The database is gender balanced consisting of 24 professional actors, vocalizing lexically-matched statements in a neutral North American accent. Speech includes calm, happy, sad, angry, fearful, surprise, and disgust expressions, and song contains calm, happy, sad, angry, and fearful emotions. Each expression is produced at two levels of emotional intensity, with an additional neutral expression. All conditions are available in face-and-voice, face-only, and voice-only formats. The set of 7356 recordings were each rated 10 times on emotional validity, intensity, and genuineness. Ratings were provided by 247 individuals who were characteristic of untrained research participants from North America. A further set of 72 participants provided test-retest data. High levels of emotional validity and test-retest intrarater reliability were reported. Corrected accuracy and composite "goodness" measures are presented to assist researchers in the selection of stimuli.
C1 [Livingstone, Steven R.; Russo, Frank A.] Ryerson Univ, Dept Psychol, Toronto, ON, Canada.
   [Livingstone, Steven R.] Univ Wisconsin, Dept Comp Sci & Informat Syst, River Falls, WI 54022 USA.
C3 Toronto Metropolitan University; University of Wisconsin System
RP Livingstone, SR (corresponding author), Ryerson Univ, Dept Psychol, Toronto, ON, Canada.; Livingstone, SR (corresponding author), Univ Wisconsin, Dept Comp Sci & Informat Syst, River Falls, WI 54022 USA.
EM steven.livingstone@uwrf.edu
RI Livingstone, Steven R./H-5695-2019
OI Livingstone, Steven R./0000-0002-6364-6410; Russo,
   Frank/0000-0002-2939-6358
FU FAR-Discovery Grant from the Natural Sciences and Engineering Research
   Council of Canada [2012-341583]; FAR-Hear the world research chair in
   music and emotional speech from Phonak
FX This work was supported by FAR-Discovery Grant (2012-341583) from the
   Natural Sciences and Engineering Research Council of Canada,
   http://www.nserc-crsng.gc.ca/; FAR-Hear the world research chair in
   music and emotional speech from Phonak, https://www.phonak.com.
CR Ambadar Z, 2005, PSYCHOL SCI, V16, P403, DOI 10.1111/j.0956-7976.2005.01548.x
   [Anonymous], 2001, Music and Emotion, DOI DOI 10.1525/MP.2004.21.4.561
   Ayotte J, 2002, BRAIN, V125, P238, DOI 10.1093/brain/awf028
   Bänziger T, 2007, LECT NOTES COMPUT SC, V4738, P476
   Bänziger T, 2012, EMOTION, V12, P1161, DOI 10.1037/a0025827
   Bänziger T, 2009, EMOTION, V9, P691, DOI 10.1037/a0017088
   Balconi M, 2011, J COGN PSYCHOL, V23, P132, DOI 10.1080/20445911.2011.473560
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Barrett LF, 1999, CURR DIR PSYCHOL SCI, V8, P10, DOI 10.1111/1467-8721.00003
   Barrett LF, 2006, PERSPECT PSYCHOL SCI, V1, P28, DOI 10.1111/j.1745-6916.2006.00003.x
   BASSILI JN, 1979, J PERS SOC PSYCHOL, V37, P2049, DOI 10.1037/0022-3514.37.11.2049
   Beaupré MG, 2005, J CROSS CULT PSYCHOL, V36, P355, DOI 10.1177/0022022104273656
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bidabadi SS, 2015, J AFFECT DISORDERS, V184, P13, DOI 10.1016/j.jad.2015.04.011
   Biele C, 2006, EXP BRAIN RES, V171, P1, DOI 10.1007/s00221-005-0254-0
   Bould E, 2008, COGNITION EMOTION, V22, P1569, DOI 10.1080/02699930801921156
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Breiter HC, 1996, NEURON, V17, P875, DOI 10.1016/S0896-6273(00)80219-6
   Burkhardt F, 2005, 9 EUR C SPEECH COMM, V5, P1517, DOI [10.21437/Interspeech.2005-446, DOI 10.21437/INTERSPEECH.2005-446]
   Busso C, 2017, IEEE T AFFECT COMPUT, V8, P67, DOI 10.1109/TAFFC.2016.2515617
   CACIOPPO JT, 1986, J PERS SOC PSYCHOL, V50, P260, DOI 10.1037/0022-3514.50.2.260
   Campanella S, 2007, TRENDS COGN SCI, V11, P535, DOI 10.1016/j.tics.2007.10.001
   CAMRAS L, 1980, AM J PSYCHOL, V93, P751, DOI 10.2307/1422394
   Cao HW, 2014, IEEE T AFFECT COMPUT, V5, P377, DOI 10.1109/TAFFC.2014.2336244
   Caria A, 2011, CEREB CORTEX, V21, P2838, DOI 10.1093/cercor/bhr084
   Castro SL, 2010, BEHAV RES METHODS, V42, P74, DOI 10.3758/BRM.42.1.74
   Chang A, 2017, P NATL ACAD SCI USA, V114, pE4134, DOI 10.1073/pnas.1617657114
   Cicchetti DV, 1994, Psychol Assess, V6, P284, DOI [DOI 10.1037/1040-3590.6.4.284, 10.1037/1040-3590.6.4.284]
   Cohn JF, 2003, ACTIVE MEDIA TECHNOLOGY, P57, DOI 10.1142/9789812704313_0005
   Collignon O, 2008, BRAIN RES, V1242, P126, DOI 10.1016/j.brainres.2008.04.023
   COLTHEART M, 1981, Q J EXP PSYCHOL-A, V33, P497, DOI 10.1080/14640748108400805
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Cowie R, 2011, COGN TECHNOL, P167, DOI 10.1007/978-3-642-15184-2_11
   Cowie R, 2011, COGN TECHNOL, P197, DOI 10.1007/978-3-642-15184-2_12
   Cowie R, 2009, PHILOS T R SOC B, V364, P3515, DOI 10.1098/rstb.2009.0139
   Cramer AOJ, 2016, PSYCHON B REV, V23, P640, DOI 10.3758/s13423-015-0913-5
   Cuddy LL, 2005, MED HYPOTHESES, V64, P229, DOI 10.1016/j.mehy.2004.09.005
   Cunningham DW, 2009, J VISION, V9, DOI 10.1167/9.13.7
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Darwin C., 1872, The Expression of the Emotions in Man and Animals
   Davidson JW., 1993, PSYCHOL MUSIC, V21, P103, DOI [10.1177/030573569302100201, DOI 10.1177/030573569302100201]
   De Gelder B, 2003, TRENDS COGN SCI, V7, P460, DOI 10.1016/j.tics.2003.08.014
   de Gelder B, 2000, COGNITION EMOTION, V14, P289, DOI 10.1080/026999300378824
   de Gelder B, 2005, SCHIZOPHR RES, V72, P195, DOI 10.1016/j.schres.2004.02.013
   Delle-Vigne D, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00106
   Descartes R, 1984, PHILOS WORKS DESCART
   DIENER E, 1985, J PERS SOC PSYCHOL, V48, P1253, DOI 10.1037/0022-3514.48.5.1253
   Dixon W.J., 1957, Introduction to Statistical Analysis, V2nd
   Dolan RJ, 2001, P NATL ACAD SCI USA, V98, P10006, DOI 10.1073/pnas.171288598
   Donegan NH, 2003, BIOL PSYCHIAT, V54, P1284, DOI 10.1016/S0006-3223(03)00636-X
   Ebner NC, 2010, BEHAV RES METHODS, V42, P351, DOI 10.3758/BRM.42.1.351
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   Egger HL, 2011, INT J METH PSYCH RES, V20, P145, DOI 10.1002/mpr.343
   EKMAN P, 1969, SCIENCE, V164, P86, DOI 10.1126/science.164.3875.86
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Ekman P., 1978, Manual for the facial action coding system
   Ekman P, 1976, Pictures of facial affect
   Elfenbein HA, 2002, PSYCHOL BULL, V128, P203, DOI 10.1037//0033-2909.128.2.203
   ERWIN RJ, 1992, PSYCHIAT RES, V42, P231, DOI 10.1016/0165-1781(92)90115-J
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Flom R, 2007, DEV PSYCHOL, V43, P238, DOI 10.1037/0012-1649.43.1.238
   Frank MG, 2001, J PERS SOC PSYCHOL, V80, P75, DOI 10.1037/0022-3514.80.1.75
   Friesen W.V., 1983, Univ. California San Francisco, V2, P1
   FRIJDA NH, 1988, AM PSYCHOL, V43, P349, DOI 10.1037/0003-066X.43.5.349
   Gamer M, 2012, irr: Various Coefficients of Interrater Reliability and Agreement
   Garrido MV, 2017, BEHAV RES METHODS, V49, P1343, DOI 10.3758/s13428-016-0790-5
   Girden E. R., 1992, ANOVA, DOI DOI 10.4135/9781412983419
   Good A, 2017, EAR HEARING, V38, P455, DOI 10.1097/AUD.0000000000000402
   GOSSELIN P, 1995, J PERS SOC PSYCHOL, V68, P83, DOI 10.1037/0022-3514.68.1.83
   Hébert S, 2003, BRAIN, V126, P1838, DOI 10.1093/brain/awg186
   Hess U, 1997, J NONVERBAL BEHAV, V21, P241, DOI 10.1023/A:1024952730333
   Hess U, 2001, INT J PSYCHOPHYSIOL, V40, P129, DOI 10.1016/S0167-8760(00)00161-6
   HOAGLIN DC, 1986, J AM STAT ASSOC, V81, P991, DOI 10.2307/2289073
   HOAGLIN DC, 1987, J AM STAT ASSOC, V82, P1147, DOI 10.1080/01621459.1987.10478551
   Hsieh S, 2011, BRAIN, V134, P2523, DOI 10.1093/brain/awr190
   Hutchins S, 2012, J EXP PSYCHOL GEN, V141, P76, DOI 10.1037/a0025064
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Izard, 1979, MAXIMALLY DISCRIMINA
   IZARD CE, 1992, PSYCHOL REV, V99, P561, DOI 10.1037/0033-295X.99.3.561
   James W., 1884, Mind, V9, P188, DOI DOI 10.1093/MIND/OS-IX.34.188
   Jürgens R, 2015, J NONVERBAL BEHAV, V39, P195, DOI 10.1007/s10919-015-0209-5
   Juslin PN, 2008, EMOTION, V8, P668, DOI 10.1037/a0013505
   Juslin PN, 2001, EMOTION, V1, P381, DOI 10.1037//1528-3542.1.4.381
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN., 2001, Music and Emotion, P309, DOI 10.1093/oso/9780192631886.003.0014
   Kallinen K., 2005, Psychology of Music, V33, P373, DOI DOI 10.1177/0305735605056147
   Kanade T., 2000, Proceedings of the Fourth IEEE International Conference on Automatic Face and Gesture Recognition (FG'00), Grenoble, France, P46
   Katselas M., 2008, ACTING CLASS TAKE SE
   Kaulard K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0032321
   KELTNER D, 1995, J PERS SOC PSYCHOL, V68, P441, DOI 10.1037/0022-3514.68.3.441
   Koelsch S, 2014, NAT REV NEUROSCI, V15, P170, DOI 10.1038/nrn3666
   Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012
   Kreifelts B, 2007, NEUROIMAGE, V37, P1445, DOI 10.1016/j.neuroimage.2007.06.020
   Krumhuber E, 2005, J NONVERBAL BEHAV, V29, P3, DOI 10.1007/s10919-004-0887-x
   Krumhuber EG, 2013, EMOT REV, V5, P41, DOI 10.1177/1754073912451349
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Laukka P, 2011, COMPUT SPEECH LANG, V25, P84, DOI 10.1016/j.csl.2010.03.004
   Lima CF, 2013, BEHAV RES METHODS, V45, P1234, DOI 10.3758/s13428-013-0324-3
   Liu P, 2012, BEHAV RES METHODS, V44, P1042, DOI 10.3758/s13428-012-0203-3
   Livingstone SR, 2016, EMOTION, V16, P365, DOI 10.1037/emo0000106
   Livingstone SR, 2015, Q J EXP PSYCHOL, V68, P952, DOI 10.1080/17470218.2014.971034
   Livingstone SR, 2010, COMPUT MUSIC J, V34, P41, DOI 10.1162/comj.2010.34.1.41
   LoBue Vanessa, 2014, Front Psychol, V5, P1532, DOI 10.3389/fpsyg.2014.01532
   Lundqvist D, 1998, KAROLINSKA DIRECTED
   Maratos AS, 2008, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD004517.pub2
   Marsh AA, 2003, PSYCHOL SCI, V14, P373, DOI 10.1111/1467-9280.24461
   Marsh AA, 2007, J CROSS CULT PSYCHOL, V38, P284, DOI 10.1177/0022022107300275
   Martin O, 2006, P 22 INT C DAT ENG W
   Massaro DW, 1996, PSYCHON B REV, V3, P215, DOI 10.3758/BF03212421
   Matsumoto D., 1988, Japanese and Caucasian Facial Expressions of Emotion (JACFEE)
   Matsumoto D, 1993, JAPANESE CAUCASIAN F
   MAZURSKI EJ, 1993, AUST J PSYCHOL, V45, P41, DOI 10.1080/00049539308259117
   Motley MT., 1988, Western Journal of Speech Communication, V52, P1, DOI [10.1080/10570318809389622, DOI 10.1080/10570318809389622]
   Nelson NL, 2014, EMOTION, V14, P857, DOI 10.1037/a0036789
   ORTONY A, 1990, PSYCHOL REV, V97, P315, DOI 10.1037/0033-295X.97.3.315
   Osgood C. E., 1957, Themeasurement ofmeaning
   Pacchetti C, 2000, PSYCHOSOM MED, V62, P386, DOI 10.1097/00006842-200005000-00012
   Palermo R, 2004, BEHAV RES METH INS C, V36, P634, DOI 10.3758/BF03206544
   Palmer C, 1997, ANNU REV PSYCHOL, V48, P115, DOI 10.1146/annurev.psych.48.1.115
   Paquette S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00509
   Paulmann S, 2011, MOTIV EMOTION, V35, P192, DOI 10.1007/s11031-011-9206-0
   Pitcher D, 2011, NEUROIMAGE, V56, P2356, DOI 10.1016/j.neuroimage.2011.03.067
   Plant RR, 2002, BEHAV RES METH INS C, V34, P218, DOI 10.3758/BF03195446
   Pollick FE, 2003, PERCEPTION, V32, P813, DOI 10.1068/p3319
   Pourtois G, 2000, NEUROREPORT, V11, P1329, DOI 10.1097/00001756-200004270-00036
   Punkanen M, 2011, J AFFECT DISORDERS, V130, P118, DOI 10.1016/j.jad.2010.10.034
   R Core Team, 2018, R: A Language and Environment for Statistical Computing
   Recio G, 2011, BRAIN RES, V1376, P66, DOI 10.1016/j.brainres.2010.12.041
   Regenbogen C, 2012, COGNITION EMOTION, V26, P995, DOI 10.1080/02699931.2011.631296
   Regenbogen C, 2012, NEUROIMAGE, V60, P2346, DOI 10.1016/j.neuroimage.2012.02.043
   REISENZEIN R, 1994, J PERS SOC PSYCHOL, V67, P525, DOI 10.1037/0022-3514.67.3.525
   Roesch E. B., 2010, BLUEPRINT AFFECTIVE, P271, DOI DOI 10.1037/A0025827
   RUSSELL JA, 1994, PSYCHOL BULL, V115, P102, DOI 10.1037/0033-2909.115.1.102
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Russell JA, 2003, PSYCHOL REV, V110, P145, DOI 10.1037/0033-295X.110.1.145
   Särkämö T, 2008, BRAIN, V131, P866, DOI 10.1093/brain/awn013
   Sato W, 2004, COGNITION EMOTION, V18, P701, DOI 10.1080/02699930341000176
   Sato W, 2007, COGNITION, V104, P1, DOI 10.1016/j.cognition.2006.05.001
   Sauter DA, 2007, MOTIV EMOTION, V31, P192, DOI 10.1007/s11031-007-9065-x
   Sauter DA, 2010, Q J EXP PSYCHOL, V63, P2251, DOI 10.1080/17470211003721642
   Sauter DA, 2010, P NATL ACAD SCI USA, V107, P2408, DOI 10.1073/pnas.0908239106
   Scherer KR, 2011, INT J PSYCHOL, V46, P401, DOI 10.1080/00207594.2011.626049
   SCHERER KR, 1991, MOTIV EMOTION, V15, P123, DOI 10.1007/BF00995674
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Schlaug G, 2008, MUSIC PERCEPT, V25, P315, DOI 10.1525/MP.2008.25.4.315
   Schlaug G, 2009, ANN NY ACAD SCI, V1169, P385, DOI 10.1111/j.1749-6632.2009.04587.x
   SCHLOSBERG H, 1952, J EXP PSYCHOL, V44, P229, DOI 10.1037/h0055778
   Schlosberg H, 1941, J EXP PSYCHOL, V29, P497
   SCHLOSBERG H, 1954, PSYCHOL REV, V61, P81, DOI 10.1037/h0054570
   Scotto di Carlo N, 2004, SEMIOTICA, V149, P37
   Sestito M, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00368
   SHAVER P, 1987, J PERS SOC PSYCHOL, V52, P1061, DOI 10.1037/0022-3514.52.6.1061
   SHROUT PE, 1979, PSYCHOL BULL, V86, P420, DOI 10.1037/0033-2909.86.2.420
   Simon D, 2008, PAIN, V135, P55, DOI 10.1016/j.pain.2007.05.008
   SONNEMANS J, 1994, COGNITION EMOTION, V8, P329, DOI 10.1080/02699939408408945
   Spencer Herbert, 1855, The Principles of Psychology
   Stanislavsky K., 1936, ACTOR PREPARES
   Tanaka A, 2010, PSYCHOL SCI, V21, P1259, DOI 10.1177/0956797610380698
   Tcherkassof A, 2007, EUR J SOC PSYCHOL, V37, P1325, DOI 10.1002/ejsp.427
   Team R., 2016, RStudio: Integrated development for R.
   Thaut MH, 1996, MOVEMENT DISORD, V11, P193, DOI 10.1002/mds.870110213
   Thomas KM, 2001, BIOL PSYCHIAT, V49, P309, DOI 10.1016/S0006-3223(00)01066-0
   Thompson WF, 2012, P NATL ACAD SCI USA, V109, P19027, DOI 10.1073/pnas.1210344109
   Thompson WF, 2008, COGNITION EMOTION, V22, P1457, DOI 10.1080/02699930701813974
   Tomkins S. S., 1962, Affect Imagery Consciousness: Volume I: The Positive Affects, VI
   Tottenham N, 2009, PSYCHIAT RES, V168, P242, DOI 10.1016/j.psychres.2008.05.006
   Tracy JL, 2008, P NATL ACAD SCI USA, V105, P11655, DOI 10.1073/pnas.0802686105
   Tracy JL, 2009, EMOTION, V9, P554, DOI 10.1037/a0015766
   Tracy JL, 2004, PSYCHOL SCI, V15, P194, DOI 10.1111/j.0956-7976.2004.01503008.x
   Trautmann SA, 2009, BRAIN RES, V1284, P100, DOI 10.1016/j.brainres.2009.05.075
   van Besouw RM, 2008, MUSIC PERCEPT, V26, P145, DOI 10.1525/MP.2008.26.2.145
   van der Schalk J, 2011, EMOTION, V11, P907, DOI 10.1037/a0023853
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   Vines BW, 2011, COGNITION, V118, P157, DOI 10.1016/j.cognition.2010.11.010
   Vurma A, 2006, MUSIC PERCEPT, V23, P331, DOI 10.1525/mp.2006.23.4.331
   WAGNER HL, 1993, J NONVERBAL BEHAV, V17, P3, DOI 10.1007/BF00987006
   WAGNER HL, 1986, J PERS SOC PSYCHOL, V50, P737, DOI 10.1037/0022-3514.50.4.737
   Wan CY, 2010, MUSIC PERCEPT, V27, P287, DOI 10.1525/MP.2010.27.4.287
   Wang L, 1999, J CROSS CULT PSYCHOL, V30, P397, DOI 10.1177/0022022199030004001
   Wehrle T, 2000, J PERS SOC PSYCHOL, V78, P105, DOI 10.1037/0022-3514.78.1.105
   Weyers P, 2006, PSYCHOPHYSIOLOGY, V43, P450, DOI 10.1111/j.1469-8986.2006.00451.x
   Wickham H., 2017, Tidyverse: Easily Install and Load the "Tidyverse"
   Wilhelm O, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00404
   Wundt W., 1896, Outlines of psychology
   Zhang B, 2016, IEEE INT C AC SPEECH
   Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002
   Zvyagintsev M, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00674
NR 190
TC 454
Z9 494
U1 11
U2 72
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD MAY 16
PY 2018
VL 13
IS 5
AR e0196391
DI 10.1371/journal.pone.0196391
PG 35
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Science & Technology - Other Topics
GA GF9WG
UT WOS:000432329200024
PM 29768426
OA gold, Green Submitted, Green Published
DA 2024-01-09
ER

PT J
AU Nussbaum, C
   Schirmer, A
   Schweinberger, S
AF Nussbaum, C.
   Schirmer, A.
   Schweinberger, S.
TI Integration of auditory cues for vocal emotion perception - differences
   between musicians and non-musicians
SO INTERNATIONAL JOURNAL OF PSYCHOPHYSIOLOGY
LA English
DT Meeting Abstract
C1 [Nussbaum, C.; Schirmer, A.; Schweinberger, S.] Friedrich Schiller Univ, Dept Gen Psychol & Cognit Neurosci, Jena, Germany.
   [Nussbaum, C.; Schweinberger, S.] Friedrich Schiller Univ, Voice Res Unit, Jena, Germany.
   [Schirmer, A.] Univ Innsbruck, Inst Psychol, Innsbruck, Austria.
   [Schweinberger, S.] Univ Geneva, Swiss Ctr Affect Sci, Geneva, Switzerland.
C3 Friedrich Schiller University of Jena; Friedrich Schiller University of
   Jena; University of Innsbruck; University of Geneva
NR 0
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8760
EI 1872-7697
J9 INT J PSYCHOPHYSIOL
JI Int. J. Psychophysiol.
PD JUN
PY 2023
VL 188
SU S
BP 80
EP 81
DI 10.1016/j.ijpsycho.2023.05.209
EA JUN 2023
PG 2
WC Psychology, Biological; Neurosciences; Physiology; Psychology;
   Psychology, Experimental
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Psychology; Neurosciences & Neurology; Physiology
GA N6HJ4
UT WOS:001037996300208
DA 2024-01-09
ER

PT J
AU Rachman, L
   Liuni, M
   Arias, P
   Lind, A
   Johansson, P
   Hall, L
   Richardson, D
   Watanabe, K
   Dubal, S
   Aucouturier, JJ
AF Rachman, Laura
   Liuni, Marco
   Arias, Pablo
   Lind, Andreas
   Johansson, Petter
   Hall, Lars
   Richardson, Daniel
   Watanabe, Katsumi
   Dubal, Stephanie
   Aucouturier, Jean-Julien
TI DAVID: An open-source platform for real-time transformation of
   infra-segmental emotional cues in running speech
SO BEHAVIOR RESEARCH METHODS
LA English
DT Article
DE Emotional transformations; Nonverbal behavior; Voice; Real-time;
   Software; Infra-segmental cues
ID JAPANESE CULTURAL-DIFFERENCES; VOCAL EXPRESSION; FACIAL EXPRESSIONS;
   UNITED-STATES; INTENSITY; PITCH; VOICE; PERCEPTION; MUSIC; COMMUNICATION
AB We present an open-source software platform that transforms emotional cues expressed by speech signals using audio effects like pitch shifting, inflection, vibrato, and filtering. The emotional transformations can be applied to any audio file, but can also run in real time, using live input from a microphone, with less than 20-ms latency. We anticipate that this tool will be useful for the study of emotions in psychology and neuroscience, because it enables a high level of control over the acoustical and emotional content of experimental stimuli in a variety of laboratory situations, including real-time social situations. We present here results of a series of validation experiments aiming to position the tool against several methodological requirements: that transformed emotions be recognized at above-chance levels, valid in several languages (French, English, Swedish, and Japanese) and with a naturalness comparable to natural speech.
C1 [Rachman, Laura; Liuni, Marco; Arias, Pablo; Aucouturier, Jean-Julien] UPMC, STMS, IRCAM, UMR 9912,CNRS, 1 Pl Stravinsky, F-75004 Paris, France.
   [Rachman, Laura; Dubal, Stephanie] UPMC Univ Paris 06, Sorbonne Univ, Inst Cerveau & Moelle Epiniere ICM,Inserm,U1127, CNRS,UMR 7225,UMR S 1127,Social & Affect Neurosci, Paris, France.
   [Lind, Andreas; Johansson, Petter; Hall, Lars] Lund Univ, Cognit Sci, Lund, Sweden.
   [Johansson, Petter] Swedish Coll Adv Study, Uppsala, Sweden.
   [Richardson, Daniel] UCL, Dept Expt Psychol, London, England.
   [Watanabe, Katsumi] Waseda Univ, Dept Intermedia Art & Sci, Fac Sci & Engn, Tokyo, Japan.
   [Watanabe, Katsumi] Univ Tokyo, Res Ctr Adv Sci & Technol, Tokyo, Japan.
C3 Sorbonne Universite; Centre National de la Recherche Scientifique
   (CNRS); Sorbonne Universite; Centre National de la Recherche
   Scientifique (CNRS); CNRS - National Institute for Biology (INSB);
   Institut National de la Sante et de la Recherche Medicale (Inserm); Lund
   University; Swedish Collegium for Advanced Study (SCAS); University of
   London; University College London; Waseda University; University of
   Tokyo
RP Rachman, L (corresponding author), UPMC, STMS, IRCAM, UMR 9912,CNRS, 1 Pl Stravinsky, F-75004 Paris, France.; Rachman, L (corresponding author), UPMC Univ Paris 06, Sorbonne Univ, Inst Cerveau & Moelle Epiniere ICM,Inserm,U1127, CNRS,UMR 7225,UMR S 1127,Social & Affect Neurosci, Paris, France.
EM rachman.laura@gmail.com
RI Richardson, Daniel C/C-2375-2008; Lind, Andreas/HDN-3220-2022
OI Arias Sarah, Pablo/0000-0002-4868-120X; Richardson,
   Daniel/0000-0003-0039-9755; Watanabe, Katsumi/0000-0003-1282-9994;
   Dubal, Stephanie/0000-0001-6026-9990; Lind, Andreas/0000-0001-9568-2865
FU European Research Council [StG-335536 CREAM]; Japan Science and
   Technology Agency CREST grant; Bank of Sweden Tercentenary Foundation;
   Swedish Research Council [2014-1371, 2011-1795]
FX This research was funded by a European Research Council Grant StG-335536
   CREAM to JJA and a Japan Science and Technology Agency CREST grant to
   KW. PJ was supported by the Bank of Sweden Tercentenary Foundation and
   Swedish Research Council Grant 2014-1371. LH was supported by the
   Swedish Research Council Grant 2011-1795.
CR [Anonymous], HDB AFFECTIVE SCI
   [Anonymous], 2005, VOCAL EXPRESSION AFF
   Arminjon M, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00650
   Astrinaki M, 2012, IEEE W SP LANG TECH, P252, DOI 10.1109/SLT.2012.6424231
   Aucouturier JJ, 2016, P NATL ACAD SCI USA, V113, P948, DOI 10.1073/pnas.1506552113
   Aylett M. P., 2013, EXPRESSIVE SPEECH SY
   BACHOROWSKI JA, 1995, PSYCHOL SCI, V6, P219, DOI 10.1111/j.1467-9280.1995.tb00596.x
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Bänziger T, 2005, SPEECH COMMUN, V46, P252, DOI 10.1016/j.specom.2005.02.016
   Behroozmand R, 2012, J ACOUST SOC AM, V132, P2468, DOI 10.1121/1.4746984
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Bestelmeyer PEG, 2012, CEREB CORTEX, V22, P1263, DOI 10.1093/cercor/bhr204
   Biehl M, 1997, J NONVERBAL BEHAV, V21, P3, DOI 10.1023/A:1024902500935
   Boersma PPG, 1996, PRAAT DOING PHONETIC
   Bulut M., 2005, P 6 ANN C INT SPEECH
   Bulut M, 2008, J ACOUST SOC AM, V123, P4547, DOI 10.1121/1.2909562
   Cabral J. P., 2005, PITCH SYNCHRONOUS TI
   Camacho A, 2008, J ACOUST SOC AM, V124, P1638, DOI 10.1121/1.2951592
   Cheung S, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00401
   DAMASIO AR, 1994, SCI AM, V271, P144, DOI 10.1038/scientificamerican1094-144
   Dromey C, 2015, J VOICE, V29, P170, DOI 10.1016/j.jvoice.2014.06.007
   Eide E., 2004, P 5 ISCA SPEECH SYNT
   Elfenbein HA, 2002, PSYCHOL BULL, V128, P203, DOI 10.1037//0033-2909.128.2.203
   Engelmann JB, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00118
   Ethofer T, 2006, NEUROREPORT, V17, P249, DOI 10.1097/01.wnr.0000199466.32036.5d
   Godoy E., 2009, P 10 ANN C INT SPEEC
   Goeleven E, 2008, COGNITION EMOTION, V22, P1094, DOI 10.1080/02699930701626582
   Grimm S, 2009, HUM BRAIN MAPP, V30, P2617, DOI 10.1002/hbm.20693
   Harnmerschmidt K, 2007, J VOICE, V21, P531, DOI 10.1016/j.jvoice.2006.03.002
   Haspelmath M., 2005, WORLD ATLAS LANGUAGE, V1
   de Mendoza AH, 2010, COGNITION EMOTION, V24, P661, DOI 10.1080/02699930902958255
   Inanoglu Z., 2007, SYSTEM TRANSFORMING
   Jürgens R, 2015, J NONVERBAL BEHAV, V39, P195, DOI 10.1007/s10919-015-0209-5
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2001, EMOTION, V1, P381, DOI 10.1037//1528-3542.1.4.381
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kato H., 2000, US Patent, Patent No. [6,121,531, 6121531]
   Kayyal M. H., 2012, J LANG SOC PSYCHOL, V32, P261
   Kitayama S, 2000, COGNITION EMOTION, V14, P93, DOI 10.1080/026999300379003
   Kitayama S, 2006, J PERS SOC PSYCHOL, V91, P890, DOI 10.1037/0022-3514.91.5.890
   Klofstad CA, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0133779
   Klofstad CA, 2012, P ROY SOC B-BIOL SCI, V279, P2698, DOI 10.1098/rspb.2012.0311
   Laukka P, 2005, COGNITION EMOTION, V19, P633, DOI 10.1080/02699930441000445
   Lima CF, 2013, BEHAV RES METHODS, V45, P1234, DOI 10.3758/s13428-013-0324-3
   Lind A., 2014, FRONT HUM NEUROSCI, V8, P116
   Ma WY, 2015, P NATL ACAD SCI USA, V112, P14563, DOI 10.1073/pnas.1515087112
   Mangini MC, 2004, COGNITIVE SCI, V28, P209, DOI 10.1016/j.cogsci.2003.11.004
   Marsella Stacy, 2013, P 12 ACM SIGGRAPHEUR, P25, DOI [10.1145/2485895.2485900, DOI 10.1145/2485895.2485900]
   Matsumoto D, 1999, COGNITION EMOTION, V13, P201, DOI 10.1080/026999399379339
   MATSUMOTO D, 1989, MOTIV EMOTION, V13, P143, DOI 10.1007/BF00992959
   Mayor O., 2009, P AES 35 INT C LOND
   MCGRAW KO, 1992, PSYCHOL BULL, V111, P361, DOI 10.1037/0033-2909.111.2.361
   Mills T, 2014, AUGMENT ALTERN COMM, V30, P226, DOI 10.3109/07434618.2014.924026
   MOULINES E, 1990, SPEECH COMMUN, V9, P453, DOI 10.1016/0167-6393(90)90021-Z
   NEUBERG SL, 1989, J PERS SOC PSYCHOL, V56, P374, DOI 10.1037/0022-3514.56.3.374
   Öhman A, 2002, CURR DIR PSYCHOL SCI, V11, P62, DOI 10.1111/1467-8721.00169
   PAQUETTE S, 2013, FRONT PSYCHOL, V4
   Parker JN, 2012, AM SOCIOL REV, V77, P21, DOI 10.1177/0003122411433763
   Patel S., 2013, HDB NONVERBAL COMMUN, P167
   Paulmann S, 2014, COGNITION EMOTION, V28, P230, DOI 10.1080/02699931.2013.812033
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Pell MD, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027256
   Pell MD, 2009, J NONVERBAL BEHAV, V33, P107, DOI 10.1007/s10919-008-0065-7
   Pierre-Yves O, 2003, INT J HUM-COMPUT ST, V59, P157, DOI 10.1016/S1071-5819(03)00141-6
   PITTAM J, 1990, SPEECH COMMUN, V9, P177, DOI 10.1016/0167-6393(90)90055-E
   Prablanc P., 2016, 24 EUR SIGN PROC C E
   Pullin G, 2015, AUGMENT ALTERN COMM, V31, P170, DOI 10.3109/07434618.2015.1037930
   Richards JM, 2000, J ABNORM PSYCHOL, V109, P156, DOI 10.1037/0021-843X.109.1.156
   Röbel A, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2146
   Roesch EB, 2011, J NONVERBAL BEHAV, V35, P1, DOI 10.1007/s10919-010-0095-9
   ROSENTHAL R, 1989, PSYCHOL BULL, V106, P332, DOI 10.1037/0033-2909.106.2.332
   Russ JB, 2008, BEHAV RES METHODS, V40, P935, DOI 10.3758/BRM.40.4.935
   Sato W, 2004, COGNITIVE BRAIN RES, V20, P81, DOI 10.1016/j.cogbrainres.2004.01.008
   Scherer K., 1977, MOTIV EMOTION, V1, P331, DOI [DOI 10.1007/BF00992539, 10.1007/bf00992539]
   Scherer KR, 2011, INT J PSYCHOL, V46, P401, DOI 10.1080/00207594.2011.626049
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Schroder M., 2001, P EUR 01 ALB
   SHAHIDI S, 1991, PSYCHOL REP, V69, P1024, DOI 10.2466/PR0.69.7.1024-1026
   SIEGMAN AW, 1993, J ABNORM PSYCHOL, V102, P430, DOI 10.1037/0021-843X.102.3.430
   Slatcher RB, 2006, PSYCHOL SCI, V17, P660, DOI 10.1111/j.1467-9280.2006.01762.x
   Takeda S., 2013, INT J AFFECTIVE ENG, V12, P79
   TARTTER VC, 1980, PERCEPT PSYCHOPHYS, V27, P24, DOI 10.3758/BF03199901
   TICE DM, 1992, J PERS SOC PSYCHOL, V63, P435, DOI 10.1037/0022-3514.63.3.435
   Toda T., 2012, INTERSPEECH
   Todorov A, 2013, EMOTION, V13, P724, DOI 10.1037/a0032335
   Toen J, 2002, P SPEECH PROS, P187
   Van Doorn EA, 2012, COGNITION EMOTION, V26, P442, DOI 10.1080/02699931.2011.648174
   Vukovic J, 2011, BRIT J PSYCHOL, V102, P37, DOI 10.1348/000712610X498750
   WAGNER HL, 1993, J NONVERBAL BEHAV, V17, P3, DOI 10.1007/BF00987006
   WALLBOTT HG, 1988, J NONVERBAL BEHAV, V12, P98, DOI 10.1007/BF00986928
   Wang Y., 2010, AUDIO ENG SOC CONVEN
   Xiao Q., 2015, PLOS ONE, V10
NR 93
TC 29
Z9 29
U1 2
U2 11
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1554-351X
EI 1554-3528
J9 BEHAV RES METHODS
JI Behav. Res. Methods
PD FEB
PY 2018
VL 50
IS 1
BP 323
EP 343
DI 10.3758/s13428-017-0873-y
PG 21
WC Psychology, Mathematical; Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA FV9QE
UT WOS:000424922400022
PM 28374144
OA Green Published, hybrid
DA 2024-01-09
ER

PT J
AU Tsai, CG
   Wang, LC
   Wang, SF
   Shau, YW
   Hsiao, TY
   Auhagen, W
AF Tsai, Chen-Gia
   Wang, Li-Ching
   Wang, Shwu-Fen
   Shau, Yio-Wha
   Hsiao, Tzu-Yu
   Auhagen, Wolfgang
TI AGGRESSIVENESS OF THE GROWL-LIKE TIMBRE: ACOUSTIC CHARACTERISTICS,
   MUSICAL IMPLICATIONS, AND BIOMECHANICAL MECHANISMS
SO MUSIC PERCEPTION
LA English
DT Article
DE growl; aggressiveness; Beijing opera; heavy metal; spine stability
ID VOCAL-TRACT LENGTH; INTRAABDOMINAL PRESSURE; NONLINEAR PHENOMENA; VOICE
   QUALITY; LUMBAR SPINE; CONTRACTION; PERSONALITY; EXPRESSION; STABILITY;
   STIFFNESS
AB THE TERM GROWL TYPICALLY REFERS TO LOW-PITCHED, rough sounds uttered by animals. Humans occasionally use growl-like voices to express excessive emotions. Acoustically characterized by loud dynamics and low values of the harmonic-to-noise ratio, growl-like sounds usually express anger and excitement associated with aggression. We propose a biomechanical model relating the aggressive characteristic of the growl-like timbre to the motor mechanisms underlying growl production in humans, highlighting how an abdominal muscle contraction enhances spine stability, which plays a critical role in physical attacks. This model was supported by the experimental data of activation of the deepest abdominal muscle during resting, singing, and growling. We found a significant positive correlation between the abdominal muscle activity associated with producing voice and the perceived aggressiveness intensity of voice. The cognition of growl-like sounds is discussed from the perspectives of biomechanics, evolutionary biology, and cognitive science.
C1 [Tsai, Chen-Gia] Natl Taiwan Univ, Grad Inst Musicol, Taipei 106, Taiwan.
   [Auhagen, Wolfgang] Univ Halle Wittenberg, D-4010 Halle, Germany.
C3 National Taiwan University; Martin Luther University Halle Wittenberg
RP Tsai, CG (corresponding author), Natl Taiwan Univ, Grad Inst Musicol, 1 Sec 4,Roosevelt Rd, Taipei 106, Taiwan.
EM tsaichen-gia@ntu.edu.tw
OI WANG, SHWU-FEN/0000-0002-2114-2003; Tsai, Chen-Gia/0000-0001-9398-6080;
   HSIAO, TZU-YU/0000-0001-5052-6244
CR Agostoni E, 1970, RESPIRATORY MUSCLES, P175
   Amodio DM, 2006, NAT REV NEUROSCI, V7, P268, DOI 10.1038/nrn1884
   [Anonymous], 2005, SELECTED REPORTS ETH
   Baker Janet, 2002, Logoped Phoniatr Vocol, V27, P84, DOI 10.1080/140154302760409310
   Boersma P, 1993, P I PHONETIC SCI, V17, P97, DOI DOI 10.1371/JOURNAL.PONE.0069107
   Borch D Zangger, 2004, Logoped Phoniatr Vocol, V29, P147
   BOUISSET S, 1981, NEUROSCI LETT, V22, P263, DOI 10.1016/0304-3940(81)90117-8
   Cholewicki J, 1999, EUR SPINE J, V8, P388, DOI 10.1007/s005860050192
   Cholewicki J, 1996, CLIN BIOMECH, V11, P1, DOI 10.1016/0268-0033(95)00035-6
   CRESSWELL AG, 1994, EXP BRAIN RES, V98, P336
   CRITCHIEY DJ, 2002, PHYSIOTHER RES INT, V7, P66
   Daniel P, 1997, ACUSTICA, V83, P113
   DUGATKIN LA, 1990, ANIM BEHAV, V39, P802, DOI 10.1016/S0003-3472(05)80394-X
   Eisenberg N., 2011, Handbook of self-regulation: Research, theory, and applications, P263, DOI DOI 10.1146/ANNUREV-PSYCH-113011-143750
   Esling JH, 1996, J INT PHON ASSOC, V26, P65, DOI DOI 10.1017/S0025100300006125
   Fitch WT, 2003, SPR HDB AUD, V16, P65
   Fitch WT, 1997, J ACOUST SOC AM, V102, P1213, DOI 10.1121/1.421048
   Fitch WT, 2002, ANIM BEHAV, V63, P407, DOI 10.1006/anbe.2001.1912
   Fitch WT, 2001, P ROY SOC B-BIOL SCI, V268, P1669, DOI 10.1098/rspb.2001.1704
   Gallese V, 2004, TRENDS COGN SCI, V8, P396, DOI 10.1016/j.tics.2004.07.002
   Gibiat V, 2000, ACUSTICA, V86, P746
   GREEN G, 1989, J SPEECH HEAR DISORD, V54, P306, DOI 10.1044/jshd.5403.306
   Halpern AR, 1999, CEREB CORTEX, V9, P697, DOI 10.1093/cercor/9.7.697
   Helmholtz Hermann von, 1885, On the sensations of tone as a physiological basis for the theory of music
   Hodges P, 2003, SPINE, V28, P2594, DOI 10.1097/01.BRS.0000096676.14323.25
   Hodges PW, 2005, J BIOMECH, V38, P1873, DOI 10.1016/j.jbiomech.2004.08.016
   Hodges PW, 1997, PHYS THER, V77, P132, DOI 10.1093/ptj/77.2.132
   Johnstone T., 2000, Handbook of Emotions, V2nd ed., P220
   Juslin P. N., 1996, PSYCHOL MUSIC, V24, P68, DOI [10.1177/0305735696241007, DOI 10.1177/0305735696241007]
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN., 2001, Music and Emotion, P309, DOI 10.1093/oso/9780192631886.003.0014
   Just W, 2003, EVOL ECOL, V17, P509, DOI 10.1023/B:EVEC.0000005629.54152.83
   KERNFELD B, 2002, NEW GROVE DICT JAZZ, P455
   Keysers C, 2007, TRENDS COGN SCI, V11, P194, DOI 10.1016/j.tics.2007.02.002
   Koelsch S, 2006, HUM BRAIN MAPP, V27, P239, DOI 10.1002/hbm.20180
   Leinonen Lea, 2003, Logoped Phoniatr Vocol, V28, P53, DOI 10.1080/14015430310011754
   Lindestad PÅ, 2001, J VOICE, V15, P78, DOI 10.1016/S0892-1997(01)00008-X
   Mazo M, 1995, VOCAL FOLD, P173
   McHughMunier C, 1997, J VOICE, V11, P452
   Molnar-Szakacs I, 2006, SOC COGN AFFECT NEUR, V1, P235, DOI 10.1093/scan/nsl029
   Morrell LJ, 2005, P ROY SOC B-BIOL SCI, V272, P1235, DOI 10.1098/rspb.2005.3085
   MORTON ES, 1977, AM NAT, V111, P855, DOI 10.1086/283219
   Moses, 1954, VOICE NEUROSIS
   Negus VE., 1949, Comparative anatomy and physiology of the larynx
   Neubauer J, 2004, J VOICE, V18, P1, DOI 10.1016/S0892-1997(03)00073-0
   PLOMP R, 1965, J ACOUST SOC AM, V38, P548, DOI 10.1121/1.1909741
   Pressnitzer D, 2000, PERCEPT PSYCHOPHYS, V62, P66, DOI 10.3758/BF03212061
   Riede T, 1999, J EXP BIOL, V202, P2859
   Riede T, 2001, J ACOUST SOC AM, V110, P2191, DOI 10.1121/1.1398052
   Risset J.-C., 1999, PSYCHOL MUSIC, p113 , DOI [DOI 10.1016/B978-012213564-4/50006-8, 10.1016/B978-012213564-4/50006-8]
   Rothbart, 1989, TEMPERAMENT CHILDHOO, P187
   Roy N, 2000, J VOICE, V14, P521, DOI 10.1016/S0892-1997(00)80009-0
   Sakakibara K. I., 2004, P INT S MUS AC NAR J
   Sangild Torben, 2004, J MUSIC MEANING, V2
   Searcy WA., 2005, The evolution of animal communication: reliability and deception in signaling systems
   Teyhen DS, 2008, J ORTHOP SPORT PHYS, V38, P596, DOI 10.2519/jospt.2008.2897
   TINBERGEN N., 1952, QUART REV BIOL, V27, P1
   TSAI CG, 2005, TAIPEI THEATRE J, V2, P39
   TSAI CG, 2006, J ACOUST SOC AM, V120, P3119
   Walser Robert, 1993, Running with the Devil: Power, Gender, and Madness in Heavy Metal
   Wilkowski BM, 2008, PERS SOC PSYCHOL REV, V12, P3, DOI 10.1177/1088868307309874
NR 61
TC 33
Z9 40
U1 0
U2 12
PU UNIV CALIFORNIA PRESS
PI OAKLAND
PA 155 GRAND AVE, SUITE 400, OAKLAND, CA 94612-3758 USA
SN 0730-7829
J9 MUSIC PERCEPT
JI Music Percept.
PD FEB
PY 2010
VL 27
IS 3
BP 209
EP 221
DI 10.1525/MP.2010.27.3.209
PG 13
WC Music; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music; Psychology
GA 550UK
UT WOS:000274155700005
DA 2024-01-09
ER

PT J
AU Sheng, X
   Li, MT
AF Sheng, X.
   Li, M. T.
TI REFERENCE AND INNOVATION OF NATIONAL VOCAL MUSIC TO OPERA ELEMENTS UNDER
   THE VIEW OF EMOTION EXPRESSION
SO PSYCHIATRIA DANUBINA
LA English
DT Meeting Abstract
C1 [Sheng, X.] TongLing Univ, Tongling 244000, Peoples R China.
   [Li, M. T.] St Paul Univ, Manila 0900, Philippines.
C3 Tongling University
NR 0
TC 0
Z9 0
U1 0
U2 1
PU MEDICINSKA NAKLADA
PI ZAGREB
PA VLASKA 69, HR-10000 ZAGREB, CROATIA
SN 0353-5053
EI 1849-0867
J9 PSYCHIAT DANUB
JI Psychiatr. Danub.
PY 2022
VL 34
SU 4
BP S813
EP S813
PG 1
WC Psychiatry
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Psychiatry
GA 3F7FH
UT WOS:000830830000580
DA 2024-01-09
ER

PT J
AU Lim, A
   Ogata, T
   Okuno, HG
AF Lim, Angelica
   Ogata, Tetsuya
   Okuno, Hiroshi G.
TI Towards expressive musical robots: a cross-modal framework for emotional
   gesture, voice and music
SO EURASIP JOURNAL ON AUDIO SPEECH AND MUSIC PROCESSING
LA English
DT Article
DE affective computing; gesture; entertainment robots
ID PERFORMANCE; AUDIO; FLUTIST; WF-4RII; SCORE
AB It has been long speculated that expression of emotions from different modalities have the same underlying 'code', whether it be a dance step, musical phrase, or tone of voice. This is the first attempt to implement this theory across three modalities, inspired by the polyvalence and repeatability of robotics. We propose a unifying framework to generate emotions across voice, gesture, and music, by representing emotional states as a 4-parameter tuple of speed, intensity, regularity, and extent (SIRE). Our results show that a simple 4-tuple can capture four emotions recognizable at greater than chance across gesture and voice, and at least two emotions across all three modalities. An application for multi-modal, expressive music robots is discussed.
C1 [Lim, Angelica; Ogata, Tetsuya; Okuno, Hiroshi G.] Kyoto Univ, Grad Sch Informat, Kyoto, Japan.
C3 Kyoto University
RP Lim, A (corresponding author), Kyoto Univ, Grad Sch Informat, Kyoto, Japan.
EM angelica@kuis.kyoto-u.ac.jp
RI Okuno, Hiroshi G./S-3130-2018
OI Okuno, Hiroshi G./0000-0002-8704-4318; Ogata,
   Tetsuya/0000-0001-7015-0379
FU Grants-in-Aid for Scientific Research [19100003, 23650097] Funding
   Source: KAKEN
CR Amaya K, 1996, PROC GRAPH INTERF, P222
   [Anonymous], P INTERSPEECH ANTW B
   [Anonymous], 2010, HDB MUSIC EMOTION
   [Anonymous], 2011, MUSIC MED, DOI DOI 10.1177/1943862111414433
   Breazeal C., 2004, Designing sociable robots
   Camurri A, 2005, IEEE MULTIMEDIA, V12, P43, DOI 10.1109/MMUL.2005.2
   Clynes M., 1989, Sentics: The Touch of the Emotions
   Cowie R, 2005, IEEE SIGNAL PROCESS, V22, P33
   Fellous JM., 2004, TECHNICAL REPORT SS0, P39
   Fernandez R, 2005, EUR 9 EUR C SPEECH C, P4
   GALLAHER PE, 1992, J PERS SOC PSYCHOL, V63, P133, DOI 10.1037/0022-3514.63.1.133
   Gunes Hatice, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P827, DOI 10.1109/FG.2011.5771357
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 1999, PSYCHOMUSICOLOGY, V16, P77
   Kessous L, 2010, J MULTIMODAL USER IN, V3, P33, DOI 10.1007/s12193-009-0025-5
   Kirke A, 2009, ACM COMPUT SURV, V42, DOI 10.1145/1592451.1592454
   Kusuda Y, 2008, IND ROBOT, V35, P504, DOI 10.1108/01439910810909493
   Laukka P., 2004, Music Education Research, V6, P45, DOI DOI 10.1080/1461380032000182821
   Lim Angelica, 2011, 2011 11th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2011), P472, DOI 10.1109/Humanoids.2011.6100891
   Lim A, 2010, IROS WORKSH ROB MUS
   Lim A, 2010, IEEE INT C INT ROBOT, P1964, DOI 10.1109/IROS.2010.5650427
   Lindstrom E, 2003, RES STUDIES MUSIC ED, V20, P23, DOI DOI 10.1177/1321103X030200010201
   Livingstone SR, 2010, COMPUT MUSIC J, V34, P41, DOI 10.1162/comj.2010.34.1.41
   Mancini M., 2007, P DOCT CONS INT C AF
   Mion L, 2008, IEEE T AUDIO SPEECH, V16, P458, DOI 10.1109/TASL.2007.913743
   Mizumoto T, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P2297, DOI 10.1109/IROS.2009.5354473
   Nakano T., 2009, P SOUND MUS COMP C, P343
   Ogata T, 2000, IEEE SYS MAN CYBERN, P1342, DOI 10.1109/ICSMC.2000.886040
   Pelachaud C, 2009, SPEECH COMMUN, V51, P630, DOI 10.1016/j.specom.2008.04.009
   Pollick FE, 2001, COGNITION, V82, pB51, DOI 10.1016/S0010-0277(01)00147-0
   Schutz M, 2006, P MUS GEST MANCH, P148
   Singer Eric, 2004, P INT C NEW INT MUS, P181
   Solis J, 2007, IEEE INT CONF ROBOT, P2552, DOI 10.1109/ROBOT.2007.363849
   Solis J, 2006, COMPUT MUSIC J, V30, P12, DOI 10.1162/comj.2006.30.4.12
   Thompson WF, 2005, SEMIOTICA, V156, P203, DOI 10.1515/semi.2005.2005.156.203
   Wallbott HG, 1998, EUR J SOC PSYCHOL, V28, P879, DOI 10.1002/(SICI)1099-0992(1998110)28:6<879::AID-EJSP901>3.0.CO;2-W
   Weinberg G., 2009, 2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P233
   Zecca Massimiliano, 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P381, DOI 10.1109/ROMAN.2009.5326184
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
NR 39
TC 17
Z9 18
U1 0
U2 12
PU SPRINGEROPEN
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND
SN 1687-4722
J9 EURASIP J AUDIO SPEE
JI EURASIP J. Audio Speech Music Process.
PY 2012
BP 1
EP 12
DI 10.1186/1687-4722-2012-3
PG 12
WC Acoustics; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Acoustics; Engineering
GA 912YO
UT WOS:000301838200001
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Zhang, WX
   Liu, F
   Zhou, LS
   Wang, WQ
   Jiang, HY
   Jiang, CM
AF Zhang, Weixia
   Liu, Fang
   Zhou, Linshu
   Wang, Wanqi
   Jiang, Hanyuan
   Jiang, Cunmei
TI THE EFFECTS OF TIMBRE ON NEURAL RESPONSES TO MUSICAL EMOTION
SO MUSIC PERCEPTION
LA English
DT Article
DE timbre; affective priming; N400; LPC; P3
ID VOICE; PERCEPTION; BRAIN; SOUNDS; SIMILARITY; ATTENTION; AROUSAL; P300
AB TIMBRE IS AN IMPORTANT FACTOR THAT AFFECTS the perception of emotion in music. To date, little is known about the effects of timbre on neural responses to musical emotion. To address this issue, we used ERPs to investigate whether there are different neural responses to musical emotion when the same melodies are presented in different timbres. With a cross-modal affective priming paradigm, target faces were primed by affectively congruent or incongruent melodies without lyrics presented in the violin, flute, and voice. Results showed a larger P3 and a larger left anterior distributed LPC in response to affectively incongruent versus congruent trials in the voice version. For the flute version, however, only the LPC effect was found, which was distributed over centro-parietal electrodes. Unlike the voice and flute versions, an N400 effect was observed in the violin version. These findings revealed different patterns of neural responses to musical emotion when the same melodies were presented in different timbres, and provide evidence for the hypothesis that there are specialized neural responses to the human voice.
C1 [Zhang, Weixia; Zhou, Linshu; Wang, Wanqi; Jiang, Cunmei] Shanghai Normal Univ, Shanghai, Peoples R China.
   [Liu, Fang] Univ Reading, Reading, Berks, England.
   [Jiang, Hanyuan] Macau Univ Sci & Technol, Macau, Peoples R China.
C3 Shanghai Normal University; University of Reading; Macau University of
   Science & Technology
RP Jiang, CM (corresponding author), Shanghai Normal Univ, Mus Coll, 100 E Guilin Rd, Shanghai 200234, Peoples R China.
EM cunmeijiang@126.com
RI Liu, Fang/AAJ-7344-2021; Jiang, Jan/ABF-1730-2020; Jiang,
   Cunmei/IUM-3917-2023
OI Liu, Fang/0000-0002-7776-0222; Zhou, Linshu/0000-0003-3134-8635
FU National Natural Science Foundation of China [31470972, 31500876];
   European Research Council [678733]; European Research Council (ERC)
   [678733] Funding Source: European Research Council (ERC)
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 31470972 to C. J. and F. L., and Grant No. 31500876 to
   L. Z.), and the European Research Council Starting Grant to F. L. and C.
   J. (CAASD, No. 678733). We wish to thank Dr. Carolyn Wu for her help
   with the revisions on an earlier version of this manuscript.
CR Abrahamse EL, 2013, J EXP PSYCHOL LEARN, V39, P1552, DOI 10.1037/a0032426
   Alluri V, 2010, MUSIC PERCEPT, V27, P223, DOI 10.1525/mp.2010.27.3.223
   Andics A, 2014, CURR BIOL, V24, P574, DOI 10.1016/j.cub.2014.01.058
   [Anonymous], 2005, Event-related potentials
   [Anonymous], 2016, CANCER DISCOV, DOI [DOI 10.1158/2159-8290.CD-16-0217, DOI 10.1158/2159-8290.CD-16-0040]
   Aramaki M, 2009, LECT NOTES COMPUT SC, V5493, P1, DOI 10.1007/978-3-642-02518-1_1
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Barthet M, 2010, MUSIC PERCEPT, V28, P135, DOI 10.1525/mp.2010.28.2.135
   Beauchemin M, 2006, EUR J NEUROSCI, V23, P3081, DOI 10.1111/j.1460-9568.2006.04856.x
   Behrens Gene Ann, 1993, Psychology of Music, V21, P20, DOI DOI 10.1177/030573569302100102
   Belin P, 2004, TRENDS COGN SCI, V8, P129, DOI 10.1016/j.tics.2004.01.008
   Belin P, 2002, COGNITIVE BRAIN RES, V13, P17, DOI 10.1016/S0926-6410(01)00084-2
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Bowman C.D., 2016, PSYCHOMUSICOLOGY, V26, P15, DOI DOI 10.1037/pmu0000105
   Bruneau N, 2013, BRAIN RES, V1528, P20, DOI 10.1016/j.brainres.2013.06.008
   Calvo MG, 2008, Q J EXP PSYCHOL, V61, P1669, DOI 10.1080/17470210701743700
   Capilla A, 2013, CEREB CORTEX, V23, P1388, DOI 10.1093/cercor/bhs119
   Charest I, 2009, BMC NEUROSCI, V10, DOI 10.1186/1471-2202-10-127
   CRUMMER GC, 1994, J ACOUST SOC AM, V95, P2720, DOI 10.1121/1.409840
   Daltrozzo J, 2009, J COGNITIVE NEUROSCI, V21, P1882, DOI 10.1162/jocn.2009.21113
   De Baene W, 2004, BIOL PSYCHOL, V67, P319, DOI 10.1016/j.biopsycho.2004.01.003
   Eder AB, 2012, SOC COGN AFFECT NEUR, V7, P436, DOI 10.1093/scan/nsr033
   Eerola T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00487
   Eerola T, 2013, MUSIC PERCEPT, V30, P307, DOI [10.1525/mp.2012.30.3.307, 10.1525/MP.2012.30.1.49]
   ERBER R, 1994, EUR J SOC PSYCHOL, V24, P79, DOI 10.1002/ejsp.2420240106
   Field A., 2013, DISCOVERING STAT USI, P623
   Foti D, 2009, PSYCHOPHYSIOLOGY, V46, P521, DOI 10.1111/j.1469-8986.2009.00796.x
   Goerlich KS, 2012, J COGNITIVE NEUROSCI, V24, P1725, DOI 10.1162/jocn_a_00213
   [龚栩 Gong Xu], 2011, [中国心理卫生杂志, Chinese Mental Health Journal], V25, P40
   Griffiths SW, 2004, P ROY SOC B-BIOL SCI, V271, P695, DOI 10.1098/rspb.2003.2648
   Griffiths TD, 2004, NAT REV NEUROSCI, V5, P887, DOI 10.1038/nrn1538
   Grossmann T, 2010, NEURON, V65, P852, DOI 10.1016/j.neuron.2010.03.001
   Hailstone JC, 2009, Q J EXP PSYCHOL, V62, P2141, DOI 10.1080/17470210902765957
   HAUTUS MJ, 1995, BEHAV RES METH INS C, V27, P46, DOI 10.3758/BF03203619
   Hermans D, 2001, COGNITION EMOTION, V15, P143, DOI 10.1080/0269993004200033
   Herring DR, 2011, EMOTION, V11, P794, DOI 10.1037/a0022804
   Hinojosa JA, 2009, EMOTION, V9, P164, DOI 10.1037/a0014680
   Jiang CM, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-08005-x
   Juslin P. N., 1996, PSYCHOL MUSIC, V24, P68, DOI [10.1177/0305735696241007, DOI 10.1177/0305735696241007]
   Kamiyama KS, 2013, NEUROPSYCHOLOGIA, V51, P500, DOI 10.1016/j.neuropsychologia.2012.11.031
   Kujawa A, 2013, DEV PSYCHOBIOL, V55, P539, DOI 10.1002/dev.21058
   KUTAS M, 1980, BRAIN LANG, V11, P354, DOI 10.1016/0093-934X(80)90133-9
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   LARTILLOT O., 2017, MIR TOOLBOX 1 7 USER
   Lartillot O, 2008, ST CLASS DAT ANAL, P261, DOI 10.1007/978-3-540-78246-9_31
   LENSE M. D., 2012, 12 INT C MUS PERC CO
   Leutgeb V, 2012, BIOL PSYCHOL, V90, P97, DOI 10.1016/j.biopsycho.2012.02.008
   Levy DA, 2001, NEUROREPORT, V12, P2653, DOI 10.1097/00001756-200108280-00013
   Levy DA, 2003, PSYCHOPHYSIOLOGY, V40, P291, DOI 10.1111/1469-8986.00031
   Logeswaran N, 2009, NEUROSCI LETT, V455, P129, DOI 10.1016/j.neulet.2009.03.044
   Macmillan NA., 2005, Detection theory: A user's guide, V2nd edn
   MCADAMS S, 1992, PHILOS T ROY SOC B, V336, P383, DOI 10.1098/rstb.1992.0072
   Menon V, 2002, NEUROIMAGE, V17, P1742, DOI 10.1006/nimg.2002.1295
   Owings D. H., 1998, Animal vocal communication: A new approach
   Paquette S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00509
   Petkov CI, 2008, NAT NEUROSCI, V11, P367, DOI 10.1038/nn2043
   POLICH J, 1995, BIOL PSYCHOL, V41, P103, DOI 10.1016/0301-0511(95)05130-9
   Schirmer A, 2002, COGNITIVE BRAIN RES, V14, P228, DOI 10.1016/S0926-6410(02)00108-8
   SEMLITSCH HV, 1986, PSYCHOPHYSIOLOGY, V23, P695, DOI 10.1111/j.1469-8986.1986.tb00696.x
   Sollberger B, 2003, MUSIC PERCEPT, V20, P263, DOI 10.1525/mp.2003.20.3.263
   Steinbeis N, 2011, J COGNITIVE NEUROSCI, V23, P604, DOI 10.1162/jocn.2009.21383
   Timmers R, 2014, MUSIC PERCEPT, V31, P470, DOI 10.1525/MP.2014.31.5.470
   Toiviainen P, 1998, MUSIC PERCEPT, V16, P223
   Weinberg A, 2011, J COGNITIVE NEUROSCI, V23, P2994, DOI 10.1162/jocn.2011.21630
   Werheid K, 2005, INT J PSYCHOPHYSIOL, V55, P209, DOI 10.1016/j.ijpsycho.2004.07.006
   Wolfe J., 2018, ACOUSTICS TODAY, V14, P50
   Wolfe J, 2009, HFSP J, V3, P6, DOI 10.2976/1.2998482
   Zhang Q, 2006, BRAIN RES BULL, V71, P316, DOI 10.1016/j.brainresbull.2006.09.023
   Zhang Q, 2012, BRAIN RES, V1474, P60, DOI 10.1016/j.brainres.2012.07.023
   Zhang Q, 2010, BRAIN RES, V1329, P142, DOI 10.1016/j.brainres.2010.03.021
NR 70
TC 3
Z9 4
U1 9
U2 26
PU UNIV CALIFORNIA PRESS
PI OAKLAND
PA 155 GRAND AVE, SUITE 400, OAKLAND, CA 94612-3758 USA
SN 0730-7829
J9 MUSIC PERCEPT
JI Music Percept.
PD DEC
PY 2019
VL 37
IS 2
BP 134
EP 146
DI 10.1525/MP.2019.37.2.134
PG 13
WC Music; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music; Psychology
GA NT9RD
UT WOS:000573278100003
OA Green Accepted
DA 2024-01-09
ER

PT J
AU Gingras, B
AF Gingras, Bruno
TI Individuality in music performance: introduction to the research topic
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Editorial Material
DE music performance; individuality; individual differences; piano
   performance; vocal emotions
ID PERCEPTION
C1 Univ Vienna, Fac Life Sci, Dept Cognit Biol, Vienna, Austria.
C3 University of Vienna
RP Gingras, B (corresponding author), Univ Vienna, Fac Life Sci, Dept Cognit Biol, Vienna, Austria.
EM brunogingras@gmail.com
CR [Anonymous], 2003, Psychology of Music, DOI DOI 10.1177/03057356030313002
   Belin P, 2004, TRENDS COGN SCI, V8, P129, DOI 10.1016/j.tics.2004.01.008
   Bernays M, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00157
   Blake R, 2007, ANNU REV PSYCHOL, V58, P47, DOI 10.1146/annurev.psych.57.102904.190152
   CAREY S, 1992, PHILOS T ROY SOC B, V335, P95, DOI 10.1098/rstb.1992.0012
   Farbood MM, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00998
   Flach R, 2004, PSYCHOL RES-PSYCH FO, V69, P147, DOI 10.1007/s00426-003-0165-2
   Fritz TH, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00921
   Gingras B, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00895
   Gingras B, 2011, PERCEPTION, V40, P1206, DOI 10.1068/p6891
   Hutchins S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00825
   Koren R, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00141
   Livingstone SR, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00156
   Marin MM, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00853
   Quinto LR, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00262
   REPP BH, 1992, J ACOUST SOC AM, V92, P2546, DOI 10.1121/1.404425
   REPP BH, 1987, J ACOUST SOC AM, V81, P1100, DOI 10.1121/1.394630
   Sloboda JA, 2000, TRENDS COGN SCI, V4, P397, DOI 10.1016/S1364-6613(00)01531-X
   Srinivasan N, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00608
   Tang-Martinez Z, 2001, BEHAV PROCESS, V53, P21, DOI 10.1016/S0376-6357(00)00148-0
   Trehub SE, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00811
   Van Vugt FT, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00134
   Williamon A, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00025
   Wöllner C, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00361
   Yang WX, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01024
NR 25
TC 3
Z9 3
U1 1
U2 8
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD JUN 25
PY 2014
VL 5
AR 661
DI 10.3389/fpsyg.2014.00661
PG 2
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA AK9CO
UT WOS:000338725300001
PM 25009528
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Neumann, C
   Sares, A
   Chelini, E
   Deroche, M
AF Neumann, Cassandra
   Sares, Anastasia
   Chelini, Erica
   Deroche, Mickael
TI Roles of bilingualism and musicianship in resisting semantic or prosodic
   interference while recognizing emotion in sentences
SO BILINGUALISM-LANGUAGE AND COGNITION
LA English
DT Article; Early Access
DE bilingualism; musicianship; prosody; semantics; vocal emotion
   recognition
ID EXECUTIVE FUNCTION; MUSICAL EXPERTISE; COGNITIVE CONTROL; VOCAL
   EXPRESSION; BRAIN-STEM; LANGUAGE; SPEECH; RECOGNITION; PERCEPTION;
   ADVANTAGE
AB Listeners can use the way people speak (prosody) or what people say (semantics) to infer vocal emotions. It can be speculated that bilinguals and musicians can better use the former rather than the latter compared to monolinguals and non-musicians. However, the literature to date has offered mixed evidence for this prosodic bias. Bilinguals and musicians are also arguably known for their ability to ignore distractors and can outperform monolinguals and non-musicians when prosodic and semantic cues conflict. In two online experiments, 1041 young adults listened to sentences with either matching or mismatching semantic and prosodic cues to emotions. 526 participants were asked to identify the emotion using the prosody and 515 using the semantics. In both experiments, performance suffered when cues conflicted, and in such conflicts, musicians outperformed non-musicians among bilinguals, but not among monolinguals. This finding supports an increased ability of bilingual musicians to inhibit irrelevant information in speech.
C1 [Neumann, Cassandra; Sares, Anastasia; Chelini, Erica; Deroche, Mickael] Concordia Univ, Psychol Dept, Lab Hearing & Cognit, 7141 Sherbrooke St West, Montreal, PQ H4B 1R6, Canada.
   [Neumann, Cassandra; Sares, Anastasia; Chelini, Erica; Deroche, Mickael] Ctr Res Brain Language & Mus, Montreal, PQ, Canada.
C3 Concordia University - Canada
RP Neumann, C (corresponding author), Concordia Univ, Psychol Dept, Lab Hearing & Cognit, 7141 Sherbrooke St West, Montreal, PQ H4B 1R6, Canada.; Neumann, C (corresponding author), Ctr Res Brain Language & Mus, Montreal, PQ, Canada.
EM cassandra.neumann@concordia.ca
RI Deroche, Mickael L. D./I-7516-2019
OI Deroche, Mickael L. D./0000-0002-8698-2249
FU Natural Sciences and Engineering Research Council of Canada's (NSERC)
   Discovery Grant [DGECR-2020-00106]; NSERC's Canada Graduate Scholarship;
   les Fonds de recherche du Quebec - Nature et technologies (FRQNT)
   [301964]; Center for Research on Brain, Language, and Music (CRBLM)
   Scholarship; Government of Quebec via the Fonds de Recherche Nature et
   Technologies and Societe et Culture
FX We would like to thank all participants on Prolific who gave their time
   to complete this study. We also acknowledge the support of the Natural
   Sciences and Engineering Research Council of Canada's (NSERC) Discovery
   Grant awarded to M.D. (ref: DGECR-2020-00106), NSERC's Canada Graduate
   Scholarship awarded to C.N., les Fonds de recherche du Quebec - Nature
   et technologies (FRQNT) Scholarship awarded to C.N. (#301964), and the
   Center for Research on Brain, Language, and Music (CRBLM) Scholarship
   awarded to C.N. The CRBLM is funded by the Government of Quebec via the
   Fonds de Recherche Nature et Technologies and Societe et Culture.
CR Adesope OO, 2010, REV EDUC RES, V80, P207, DOI 10.3102/0034654310368803
   Aguert M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0083657
   Aguert M, 2010, J SPEECH LANG HEAR R, V53, P1629, DOI 10.1044/1092-4388(2010/08-0078)
   Alqarni N, 2020, INT J BILINGUAL, V24, P141, DOI 10.1177/1367006918813597
   Bailey C, 2020, LANG COGN, V12, P225, DOI 10.1017/langcog.2019.43
   BARONCOHEN S, 1985, COGNITION, V21, P37, DOI 10.1016/0010-0277(85)90022-8
   Barrett KC, 2020, EAR HEARING, V41, P1372, DOI 10.1097/AUD.0000000000000862
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Besson M, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00094
   Bialystok E, 1999, CHILD DEV, V70, P636, DOI 10.1111/1467-8624.00046
   Bialystok E., 2005, Int J Biling, V9, P103, DOI DOI 10.1177/13670069050090010701
   Bialystok E, 2017, PSYCHOL BULL, V143, P233, DOI 10.1037/bul0000099
   Bialystok E, 2015, CHILD DEV PERSPECT, V9, P117, DOI 10.1111/cdep.12116
   Bialystok E, 2010, CURR DIR PSYCHOL SCI, V19, P19, DOI 10.1177/0963721409358571
   Bialystok E, 2009, J EXP PSYCHOL HUMAN, V35, P565, DOI 10.1037/a0012735
   Bidelman GM, 2011, BRAIN COGNITION, V77, P1, DOI 10.1016/j.bandc.2011.07.006
   Botinis A, 2001, SPEECH COMMUN, V33, P263, DOI 10.1016/S0167-6393(00)00060-1
   Champoux-Larsson MF, 2021, INT J BILINGUAL, V25, P1297, DOI 10.1177/13670069211018847
   Champoux-Larsson MF, 2019, BILING-LANG COGN, V22, P416, DOI 10.1017/S1366728918000640
   Chandler J, 2016, ANNU REV CLIN PSYCHO, V12, P53, DOI 10.1146/annurev-clinpsy-021815-093623
   Chatterjee M, 2015, HEARING RES, V322, P151, DOI 10.1016/j.heares.2014.10.003
   Chobert J, 2013, BRAIN SCI, V3, P923, DOI 10.3390/brainsci3020923
   Christoffels IK, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00199
   Chung H. J., 2014, Handbook of executive functioning, P13, DOI DOI 10.1007/978-1-4614-8106-5_2
   Coffey EBJ, 2017, HEARING RES, V352, P49, DOI 10.1016/j.heares.2017.02.006
   Costa A, 2008, COGNITION, V106, P59, DOI 10.1016/j.cognition.2006.12.013
   Cutler A, 1997, LANG SPEECH, V40, P141, DOI 10.1177/002383099704000203
   D'Souza AA, 2018, COGN RES, V3, DOI 10.1186/s41235-018-0095-6
   Daly H. R., 2018, Psychomusicology: Music, Mind, and Brain, V28, P117, DOI DOI 10.1037/PMU0000213
   de Bruin A, 2019, BEHAV SCI-BASEL, V9, DOI 10.3390/bs9030033
   Deroche MLD, 2019, EAR HEARING, V40, P1197, DOI 10.1097/AUD.0000000000000701
   Deroche MLD, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-36393-1
   Donnelly S, 2019, PSYCHON B REV, V26, P1122, DOI 10.3758/s13423-019-01567-z
   Dupuis K, 2010, PSYCHOL AGING, V25, P16, DOI 10.1037/a0018777
   Emmorey K, 2008, PSYCHOL SCI, V19, P1201, DOI 10.1111/j.1467-9280.2008.02224.x
   Eyal P, 2022, BEHAV RES METHODS, V54, P1643, DOI 10.3758/s13428-021-01694-3
   Fedorenko E, 2009, MEM COGNITION, V37, P1, DOI 10.3758/MC.37.1.1
   Filippi R, 2022, INT J BILING EDUC BI, V25, P3489, DOI 10.1080/13670050.2022.2064191
   Folke T, 2016, COGNITION, V150, P119, DOI 10.1016/j.cognition.2016.02.008
   Friend M, 2000, MERRILL PALMER QUART, V46, P342
   Friend Margaret, 2001, First Lang, V21, P219, DOI 10.1177/014272370102106302
   Friend M, 2000, DEVELOPMENTAL SCI, V3, P148, DOI 10.1111/1467-7687.00108
   George EM, 2011, NEUROPSYCHOLOGIA, V49, P1083, DOI 10.1016/j.neuropsychologia.2011.02.001
   Graham R. E., 2018, Tunes and Tones: Music, Language, and Inhibitory Control, V18, P104, DOI [10.1163/15685373-12340022, DOI 10.1163/15685373-12340022]
   Grosjean F., 2010, Bilingual: Life and reality
   Hausen M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00566
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kang WX, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.651547
   Kovács AM, 2009, P NATL ACAD SCI USA, V106, P6556, DOI 10.1073/pnas.0811323106
   Krishnan A, 2009, BRAIN LANG, V110, P135, DOI 10.1016/j.bandl.2009.03.005
   Krizman J, 2012, P NATL ACAD SCI USA, V109, P7877, DOI 10.1073/pnas.1201575109
   Kroll JF, 2013, J COGN PSYCHOL, V25, P497, DOI 10.1080/20445911.2013.799170
   Lehiste I., 1970, Suprasegmentals
   Lehtonen M, 2018, PSYCHOL BULL, V144, P394, DOI 10.1037/bul0000142
   Lenth R., 2023, emmeans: Estimated Marginal Means, aka Least-Squares Means
   Levitin DJ, 2003, NEUROIMAGE, V20, P2142, DOI 10.1016/j.neuroimage.2003.08.016
   Lim VPC, 2008, APPL PSYCHOLINGUIST, V29, P389, DOI 10.1017/S0142716408080181
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Lin YS, 2022, LARYNGOSCOPE INVEST, V7, P250, DOI 10.1002/lio2.732
   Luk G, 2015, BILING-LANG COGN, V18, P35, DOI 10.1017/S1366728914000625
   Luk G, 2013, J COGN PSYCHOL, V25, P605, DOI 10.1080/20445911.2013.795574
   MacCallum RC, 2002, PSYCHOL METHODS, V7, P19, DOI 10.1037//1082-989X.7.1.19
   Maess B, 2001, NAT NEUROSCI, V4, P540, DOI 10.1038/87502
   Mankel K, 2018, P NATL ACAD SCI USA, V115, P13129, DOI 10.1073/pnas.1811793115
   Marion V, 2007, J SPEECH LANG HEAR R, V50, P940, DOI 10.1044/1092-4388(2007/067)
   Mastropieri D, 1999, DEV PSYCHOBIOL, V35, P204, DOI 10.1002/(SICI)1098-2302(199911)35:3<204::AID-DEV5>3.0.CO;2-V
   McKay CM, 2021, TRENDS HEAR, V25, DOI 10.1177/2331216520985678
   Moradzadeh L, 2015, COGNITIVE SCI, V39, P992, DOI 10.1111/cogs.12183
   Moreno S, 2009, CONTEMP MUSIC REV, V28, P329, DOI 10.1080/07494460903404410
   Morton JB, 2007, DEVELOPMENTAL SCI, V10, P719, DOI 10.1111/j.1467-7687.2007.00623.x
   Morton JB, 2001, CHILD DEV, V72, P834, DOI 10.1111/1467-8624.00318
   Most T, 2007, J DEAF STUD DEAF EDU, V12, P350, DOI 10.1093/deafed/enm012
   Naeem K, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01818
   Nair VKK, 2017, BILING-LANG COGN, V20, P999, DOI 10.1017/S1366728916000778
   Nygaard LC, 2008, J EXP PSYCHOL HUMAN, V34, P1017, DOI 10.1037/0096-1523.34.4.1017
   Paap K. R., 2019, The Handbook Of Neuroscience Of Multilingualism, P701, DOI DOI 10.1002/9781119387725.CH34
   Paap KR, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01409
   Paap KR, 2017, J COGN PSYCHOL, V29, P89, DOI 10.1080/20445911.2016.1248436
   Paap KR, 2015, CORTEX, V69, P265, DOI 10.1016/j.cortex.2015.04.014
   Paap KR, 2013, COGNITIVE PSYCHOL, V66, P232, DOI 10.1016/j.cogpsych.2012.12.002
   Paquette S, 2018, ANN NY ACAD SCI, V1423, P329, DOI 10.1111/nyas.13666
   Patel AD, 2007, TRENDS COGN SCI, V11, P369, DOI 10.1016/j.tics.2007.08.003
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Peirce J, 2019, BEHAV RES METHODS, V51, P195, DOI 10.3758/s13428-018-01193-y
   Pell MD, 2008, SPEECH COMMUN, V50, P519, DOI 10.1016/j.specom.2008.03.006
   Penhune V. B., 2019, OXFORD HDB MUSIC BRA, P417, DOI [DOI 10.1093/OXFORDHB/9780198804123.013.17, 10.1093/oxford he/9780198804123.013.17, DOI 10.1093/OXFORDHE/9780198804123.013.17]
   Peretz I, 2015, PHILOS T R SOC B, V370, P68, DOI 10.1098/rstb.2014.0090
   Preti E, 2016, BEHAV RES METHODS, V48, P259, DOI 10.3758/s13428-015-0570-7
   Raji S, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2991, DOI 10.1145/3366423.3380068
   Sares AG, 2018, J SPEECH LANG HEAR R, V61, P496, DOI 10.1044/2017_JSLHR-S-17-0207
   Sauter DA, 2013, BRIT J DEV PSYCHOL, V31, P97, DOI 10.1111/j.2044-835X.2012.02081.x
   Schellenberg EG, 2011, BRIT J PSYCHOL, V102, P283, DOI 10.1111/j.2044-8295.2010.02000.x
   Schön D, 2004, PSYCHOPHYSIOLOGY, V41, P341, DOI 10.1111/1469-8986.00172.x
   Schroeder SR, 2016, NEURAL PLAST, V2016, DOI 10.1155/2016/4058620
   Schwartz AI, 2006, J MEM LANG, V55, P197, DOI 10.1016/j.jml.2006.03.004
   Shakuf V, 2022, J CULT COGN SCI, V6, P251, DOI 10.1007/s41809-022-00107-x
   Shameem N., 1998, Validating self-reported language proficiency by testing performance in an immigrant community: The Wellington Indo-Fijians, V15, P86, DOI [10.1177/026553229801500104, DOI 10.1177/026553229801500104]
   Shenker JJ, 2022, BRAIN STRUCT FUNCT, V227, P407, DOI 10.1007/s00429-021-02409-2
   Shook A, 2013, AM J PSYCHOL, V126, P95, DOI 10.5406/amerjpsyc.126.1.0095
   Slevc LR, 2006, PSYCHOL SCI, V17, P675, DOI 10.1111/j.1467-9280.2006.01765.x
   Strong JV, 2019, AGING NEUROPSYCHOL C, V26, P367, DOI 10.1080/13825585.2018.1448356
   Swaminathan S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-27571-2
   Tierney A, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00855
   Tierney A, 2013, PROG BRAIN RES, V207, P209, DOI 10.1016/B978-0-444-63327-9.00008-4
   Tomoschuk B, 2019, BILING-LANG COGN, V22, P516, DOI 10.1017/S1366728918000421
   Trimmer CG, 2008, EMOTION, V8, P838, DOI 10.1037/a0014080
   Vaquero L, 2020, NEUROIMAGE, V213, DOI 10.1016/j.neuroimage.2020.116689
   Wiseheart M, 2016, BILING-LANG COGN, V19, P141, DOI 10.1017/S1366728914000273
   Wurm LH, 2001, COGNITION EMOTION, V15, P831, DOI 10.1080/02699930143000086
   Yow WQ, 2016, CHILD DEV, V87, P385, DOI 10.1111/cdev.12479
   Yow WQ, 2015, BILING-LANG COGN, V18, P391, DOI 10.1017/S1366728914000133
   Yow WQ, 2011, BILING-LANG COGN, V14, P562, DOI 10.1017/S1366728910000404
   Zeromskaite I., 2014, Journal of European Psychology Students, V5, P78, DOI [DOI 10.5334/JEPS.CI, 10.5334/jeps.ci]
   Zuk J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0099868
NR 114
TC 0
Z9 0
U1 1
U2 1
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 1366-7289
EI 1469-1841
J9 BILING-LANG COGN
JI Biling.-Lang. Cogn.
PD 2023 SEP 28
PY 2023
DI 10.1017/S1366728923000573
EA SEP 2023
PG 15
WC Linguistics; Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Linguistics; Psychology
GA T0GP6
UT WOS:001074861300001
OA Green Submitted, hybrid
DA 2024-01-09
ER

PT J
AU Akkermans, J
   Schapiro, R
   Müllensiefen, D
   Jakubowski, K
   Shanahan, D
   Baker, D
   Busch, V
   Lothwesen, K
   Elvers, P
   Fischinger, T
   Schlemmer, K
   Frieler, K
AF Akkermans, Jessica
   Schapiro, Renee
   Mullensiefen, Daniel
   Jakubowski, Kelly
   Shanahan, Daniel
   Baker, David
   Busch, Veronika
   Lothwesen, Kai
   Elvers, Paul
   Fischinger, Timo
   Schlemmer, Kathrin
   Frieler, Klaus
TI Decoding emotions in expressive music performances: A multi-lab
   replication and extension study
SO COGNITION & EMOTION
LA English
DT Article
DE Emotion decoding; emotion study; musical training; replication;
   expressive performance
ID VOCAL EXPRESSION; INTELLIGENCE; GENDER; CONTAGION; SAD; QUESTIONNAIRE;
   RECOGNITION; PERCEPTION; ABILITIES; EMPATHY
AB With over 560 citations reported on Google Scholar by April 2018, a publication by Juslin and Gabrielsson (1996) presented evidence supporting performers' abilities to communicate, with high accuracy, their intended emotional expressions in music to listeners. Though there have been related studies published on this topic, there has yet to be a direct replication of this paper. A replication is warranted given the paper's influence in the field and the implications of its results. The present experiment joins the recent replication effort by producing a five-lab replication using the original methodology. Expressive performances of seven emotions (e.g. happy, sad, angry, etc.) by professional musicians were recorded using the same three melodies from the original study. Participants (N = 319) were presented with recordings and rated how well each emotion matched the emotional quality using a 0-10 scale. The same instruments from the original study (i.e. violin, voice, and flute) were used, with the addition of piano. In an effort to increase the accessibility of the experiment and allow for a more ecologically-valid environment, the recordings were presented using an internet-based survey platform. As an extension to the original study, this experiment investigated how musicality, emotional intelligence, and emotional contagion might explain individual differences in the decoding process. Results found overall high decoding accuracy (57%) when using emotion ratings aggregated for the sample of participants, similar to the method of analysis from the original study. However, when decoding accuracy was scored for each participant individually the average accuracy was much lower (31%). Unlike in the original study, the voice was found to be the most expressive instrument. Generalised Linear Mixed Effects Regression modelling revealed that musical training and emotional engagement with music positively influences emotion decoding accuracy.
C1 [Akkermans, Jessica; Schapiro, Renee; Mullensiefen, Daniel] Goldsmiths Univ London, Dept Psychol, London, England.
   [Jakubowski, Kelly] Univ Durham, Dept Mus, Durham, England.
   [Shanahan, Daniel; Baker, David] Louisiana State Univ, Coll Humanities & Social Sci, Baton Rouge, LA 70803 USA.
   [Busch, Veronika; Lothwesen, Kai] Univ Bremen, Dept Musicol & Mus Educ, Bremen, Germany.
   [Elvers, Paul; Fischinger, Timo] Max Planck Inst Empir Aesthet, Mus Dept, Frankfurt, Germany.
   [Schlemmer, Kathrin] Catholic Univ Eichstatt Ingolstadt, Mus Dept, Eichstatt, Germany.
   [Frieler, Klaus] Univ Mus Franz Liszt Weimar, Inst Musicol, Hamburg, Germany.
C3 University of London; Goldsmiths University London; Durham University;
   Louisiana State University System; Louisiana State University;
   University of Bremen
RP Akkermans, J (corresponding author), Goldsmiths Univ London, Dept Psychol, London, England.
EM jess.akkermans@gmail.com
OI Jakubowski, Kelly/0000-0002-4954-7117
CR Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Baumgartner T, 2006, BRAIN RES, V1075, P151, DOI 10.1016/j.brainres.2005.12.065
   Bhatara A, 2011, J EXP PSYCHOL HUMAN, V37, P921, DOI 10.1037/a0021922
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Brackett MA, 2006, J PERS SOC PSYCHOL, V91, P780, DOI 10.1037/0022-3514.91.4.780
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Campbell IG, 1942, AM J PSYCHOL, V55, P1, DOI 10.2307/1417020
   Chan AS, 1998, NATURE, V396, P128, DOI 10.1038/24075
   Cohen MA, 2011, PSYCHON B REV, V18, P586, DOI 10.3758/s13423-011-0074-0
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Daly I, 2015, BRAIN COGNITION, V101, P1, DOI 10.1016/j.bandc.2015.08.003
   Decety Jean, 2004, Behav Cogn Neurosci Rev, V3, P71, DOI 10.1177/1534582304267187
   DEGELDER B, 1996, J ACOUST SOC AM, V100, P2818, DOI DOI 10.1121/1.416612
   Doherty RW, 1997, J NONVERBAL BEHAV, V21, P131, DOI 10.1023/A:1024956003661
   DOHERTY RW, 1995, PSYCHOL WOMEN QUART, V19, P355, DOI 10.1111/j.1471-6402.1995.tb00080.x
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   Egermann H, 2013, MUSIC PERCEPT, V31, P139, DOI 10.1525/MP.2013.31.2.139
   Escoffier N, 2013, HUM BRAIN MAPP, V34, P1796, DOI 10.1002/hbm.22029
   Frieler K, 2013, MUSIC SCI, V17, P265, DOI 10.1177/1029864913495404
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Gabrielsson A, 2003, SER AFFECTIVE SCI, P503
   GABRIELSSON A, 1995, MUSIC MIND MACHINE, P35
   Gabrielsson A., 2002, HDB AFFECTIVE SCI
   Gabrielsson A., 1995, Psychomusicol. J. Res. Music Cogn, V14, P94, DOI DOI 10.1037/H0094089
   Gabrielsson A., 2010, HDB MUSIC EMOTION TH, P367, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0014
   Galton F, 1907, NATURE, V75, P450, DOI 10.1038/075450a0
   Hothorn T, 2006, J COMPUT GRAPH STAT, V15, P651, DOI 10.1198/106186006X133933
   Huron D, 2014, EMPIR MUSICOL REV, V9, P29
   Jancke Lutz, 2008, J Biol, V7, P21, DOI 10.1186/jbiol82
   Juslin P. N., 2011, HDB MUSIC EMOTION TH
   Juslin P. N., 1996, PSYCHOL MUSIC, V24, P68, DOI [10.1177/0305735696241007, DOI 10.1177/0305735696241007]
   Juslin PN, 2001, MUSIC SCI, V5, P63, DOI 10.1177/10298649020050S104
   Juslin PN, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00596
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P751, DOI 10.1017/S0140525X08006079
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 1997, MUSIC PERCEPT, V14, P383
   Kafetsios K, 2004, PERS INDIV DIFFER, V37, P129, DOI 10.1016/j.paid.2003.08.006
   Lange EB, 2018, MUSIC PERCEPT, V36, P217, DOI 10.1525/MP.2018.36.2.217
   Lartillot O., 2007, P INT C DIG AUD EFF, DOI DOI 10.1007/978-3-540-78246-9_31
   Long JD., 2012, Longitudinal Data Analysis for the Behavioral Sciences Using R
   Mayer J.D., 1997, Emotional development and emotional intelligence: Implications for educators., P3, DOI DOI 10.1177/1066480710387486
   Mayer JD, 2008, ANNU REV PSYCHOL, V59, P507, DOI 10.1146/annurev.psych.59.103006.093646
   Mcrae K, 2008, GROUP PROCESS INTERG, V11, P143, DOI 10.1177/1368430207088035
   Mohn C, 2011, PSYCHOL MUSIC, V39, P503, DOI 10.1177/0305735610378183
   Müllensiefan D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089642
   Nair D. G., 2002, P 7 INT C MUS PERC C, P627
   Nakagawa S, 2013, METHODS ECOL EVOL, V4, P133, DOI 10.1111/j.2041-210x.2012.00261.x
   Nakata T, 2004, INFANT BEHAV DEV, V27, P455, DOI 10.1016/j.infbeh.2004.03.002
   Park M, 2014, NEUROSCI LETT, V566, P120, DOI 10.1016/j.neulet.2014.02.041
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   Petrides KV, 2009, SPRINGER SER HUM EXC, P85, DOI 10.1007/978-0-387-88370-0_5
   Petrides KV, 2004, J SOC PSYCHOL, V144, P149, DOI 10.3200/SOCP.144.2.149-162
   Petrides KV, 2003, EUR J PERSONALITY, V17, P39, DOI 10.1002/per.466
   Preston SD, 2002, BEHAV BRAIN SCI, V25, P1, DOI 10.1017/S0140525X02000018
   Reips UD, 2012, APA Handbook of Research Methods in Psychology (Vol 2): Research designs: Quantitative, qualitative, neuropsychological, and biological, V2, P291, DOI [DOI 10.1037/13620-017, 10.1037/13620-017.]
   Resnicow JE, 2004, MUSIC PERCEPT, V22, P145, DOI 10.1525/mp.2004.22.1.145
   ROBAZZA C, 1994, PERCEPT MOTOR SKILL, V79, P939, DOI 10.2466/pms.1994.79.2.939
   Salovey P., 1990, IMAG COGN PERS, V9, P185, DOI [DOI 10.2190/DUGG-P24E-52WK-6CDG, 10.2190/DUGG-P24E-52WK-6CDG, 10.2190/dugg-p24e-52wk-6cdg]
   Schellenberg EG, 2012, EMOTION, V12, P887, DOI 10.1037/a0027971
   Schellenberg EG, 2011, MUSIC PERCEPT, V29, P185, DOI 10.1525/MP.2011.29.2.185
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   Sloboda JA, 2001, MUSIC PERCEPT, V19, P87, DOI 10.1525/mp.2001.19.1.87
   Strobl C, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-25
   Thompson W., 1992, Empirical Studies of the Arts, V10, P79, DOI DOI 10.2190/NBNY-AKDK-GW58-MTEL
   Trainor LJ, 2000, PSYCHOL SCI, V11, P188, DOI 10.1111/1467-9280.00240
   TVERSKY A, 1973, COGNITIVE PSYCHOL, V5, P207, DOI 10.1016/0010-0285(73)90033-9
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   Vuoskoski JK, 2012, PSYCHOL AESTHET CREA, V6, P204, DOI 10.1037/a0026937
   Ward J., 2019, STUDENTS GUIDE COGNI, V4th
   Weiss MW, 2012, PSYCHOL SCI, V23, P1074, DOI 10.1177/0956797612442552
   Yang YH, 2008, IEEE T AUDIO SPEECH, V16, P448, DOI 10.1109/TASL.2007.911513
   Yi SKM, 2012, COGNITIVE SCI, V36, P452, DOI 10.1111/j.1551-6709.2011.01223.x
NR 74
TC 19
Z9 20
U1 2
U2 30
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 0269-9931
EI 1464-0600
J9 COGNITION EMOTION
JI Cogn. Emot.
PD AUG 18
PY 2019
VL 33
IS 6
BP 1099
EP 1118
DI 10.1080/02699931.2018.1541312
PG 20
WC Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA IE1AB
UT WOS:000472116900001
PM 30409082
OA Green Accepted
DA 2024-01-09
ER

PT J
AU Lima, CF
   Castro, SL
AF Lima, Cesar F.
   Castro, Sao Luis
TI Speaking to the Trained Ear: Musical Expertise Enhances the Recognition
   of Emotions in Speech Prosody
SO EMOTION
LA English
DT Article
DE speech prosody; emotion recognition; musical expertise; transfer effects
ID RECOGNIZING EMOTIONS; VOCAL EXPRESSIONS; BASIC EMOTIONS; LANGUAGE;
   VOICE; PERFORMANCE; EXPERIENCE; MUSICIANS; LESSONS; FACE
AB Language and music are closely related in our minds. Does musical expertise enhance the recognition of emotions in speech prosody? Forty highly trained musicians were compared with 40 musically untrained adults (controls) in the recognition of emotional prosody. For purposes of generalization, the participants were from two age groups, young (18-30 years) and middle adulthood (40-60 years). They were presented with short sentences expressing six emotions-anger, disgust, fear, happiness, sadness, surprise-and neutrality, by prosody alone. In each trial, they performed a forced-choice identification of the expressed emotion (reaction times, RTs, were collected) and an intensity judgment. General intelligence, cognitive control, and personality traits were also assessed. A robust effect of expertise was found: musicians were more accurate than controls, similarly across emotions and age groups. This effect cannot be attributed to socioeducational background, general cognitive or personality characteristics, because these did not differ between musicians and controls; perceived intensity and RTs were also similar in both groups. Furthermore, basic acoustic properties of the stimuli like fundamental frequency and duration were predictive of the participants' responses, and musicians and controls were similarly efficient in using them. Musical expertise was thus associated with cross-domain benefits to emotional prosody. These results indicate that emotional processing in music and in language engages shared resources.
C1 [Lima, Cesar F.; Castro, Sao Luis] Univ Porto, Fac Psychol & Educ, P-4200135 Oporto, Portugal.
C3 Universidade do Porto
RP Castro, SL (corresponding author), Univ Porto, Fac Psychol & Educ, Rua Doutor Alfredo Allen, P-4200135 Oporto, Portugal.
EM slcastro@fpce.up.pt
RI Lima, Cesar F./HSF-6972-2023; Castro, Sao Luis/E-5518-2017; Castro, Sao
   Luis/ISV-1010-2023
OI Lima, Cesar F./0000-0003-3058-7204; Castro, Sao
   Luis/0000-0002-1487-3596; Castro, Sao Luis/0000-0002-1487-3596
CR Adolphs R, 2001, NEUROPSYCHOLOGY, V15, P396, DOI 10.1037//0894-4105.15.3.396
   Adolphs R, 2002, EMOTION, V2, P23, DOI 10.1037/1528-3542.2.1.23
   [Anonymous], 2005, SINGING NEANDERTHALS
   [Anonymous], SUPERLAB VERSION 4 0
   [Anonymous], 2010, HDB EMOTIONS
   Ashwin C, 2006, SOC NEUROSCI-UK, V1, P349, DOI 10.1080/17470910601040772
   Bänziger T, 2009, EMOTION, V9, P691, DOI 10.1037/a0017088
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Baron-Cohen S, 2001, J AUTISM DEV DISORD, V31, P5, DOI 10.1023/A:1005653411471
   Barrett LF, 2006, PERS SOC PSYCHOL REV, V10, P20, DOI 10.1207/s15327957pspr1001_2
   Barrett LF, 2009, COGNITION EMOTION, V23, P1284, DOI 10.1080/02699930902985894
   Besson M, 2002, TRENDS COGN SCI, V6, P405, DOI 10.1016/S1364-6613(02)01975-7
   Bialystok E, 2009, J EXP PSYCHOL HUMAN, V35, P565, DOI 10.1037/a0012735
   Borod JC, 2000, COGNITION EMOTION, V14, P193, DOI 10.1080/026999300378932
   Bowling DL, 2010, J ACOUST SOC AM, V127, P491, DOI 10.1121/1.3268504
   Brochard R, 2004, BRAIN COGNITION, V54, P103, DOI 10.1016/S0278-2626(03)00264-1
   Carton JS, 1999, J NONVERBAL BEHAV, V23, P91, DOI 10.1023/A:1021339410262
   Castro SL, 2010, BEHAV RES METHODS, V42, P74, DOI 10.3758/BRM.42.1.74
   Castro SL, 2003, CLIN NEUROPSYCHOL, V17, P104
   Chartrand JP, 2006, NEUROSCI LETT, V405, P164, DOI 10.1016/j.neulet.2006.06.053
   Curtis ME, 2010, EMOTION, V10, P335, DOI 10.1037/a0017928
   Di Martino A, 2009, AM J PSYCHIAT, V166, P891, DOI 10.1176/appi.ajp.2009.08121894
   Ericsson K. A, 2010, COGNITIVE SCI, V1, P404, DOI DOI 10.1002/WCS.47
   Ericsson KA, 1996, ANNU REV PSYCHOL, V47, P273, DOI 10.1146/annurev.psych.47.1.273
   Fitch WT, 2006, MUSIC PERCEPT, V24, P85, DOI 10.1525/mp.2006.24.1.85
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Fujioka T, 2006, BRAIN, V129, P2593, DOI 10.1093/brain/awl247
   Gaser C, 2003, J NEUROSCI, V23, P9240
   Globerson E., 2010, SPEECH PROS 5 INT C
   Golan O, 2006, J AUTISM DEV DISORD, V36, P169, DOI 10.1007/s10803-005-0057-y
   Gosling SD, 2003, J RES PERS, V37, P504, DOI 10.1016/S0092-6566(03)00046-1
   Grandjean D, 2006, PROG BRAIN RES, V156, P235, DOI 10.1016/S0079-6123(06)56012-1
   Hamann S, 2004, CURR OPIN NEUROBIOL, V14, P233, DOI 10.1016/j.conb.2004.03.010
   Hamel R, 2006, EDUC PSYCHOL MEAS, V66, P1039, DOI 10.1177/0013164406288169
   Hauser MD, 2003, NAT NEUROSCI, V6, P663, DOI 10.1038/nn1080
   Hyde KL, 2009, J NEUROSCI, V29, P3019, DOI 10.1523/JNEUROSCI.5118-08.2009
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Juslin P. N., 2010, Handbook of music and emotion: Theory, research, applications, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0022
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2001, EMOTION, V1, P381, DOI 10.1037//1528-3542.1.4.381
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 2009, OXFORD HDB MUSIC PSY, P131
   Knösche TR, 2005, HUM BRAIN MAPP, V24, P259, DOI 10.1002/hbm.20088
   Koelsch S, 2005, J COGNITIVE NEUROSCI, V17, P1565, DOI 10.1162/089892905774597290
   Koelsch S, 2004, NAT NEUROSCI, V7, P302, DOI 10.1038/nn1197
   Leitman DI, 2010, SCHIZOPHRENIA BULL, V36, P545, DOI 10.1093/schbul/sbn115
   Lima CF, 2011, COGNITION EMOTION, V25, P585, DOI 10.1080/02699931.2010.502449
   Livingstone SR, 2010, COMPUT MUSIC J, V34, P41, DOI 10.1162/comj.2010.34.1.41
   Marques C, 2007, J COGNITIVE NEUROSCI, V19, P1453, DOI 10.1162/jocn.2007.19.9.1453
   Mill A, 2009, EMOTION, V9, P619, DOI 10.1037/a0016562
   Moreno S, 2009, CEREB CORTEX, V19, P712, DOI 10.1093/cercor/bhn120
   Musacchia G, 2007, P NATL ACAD SCI USA, V104, P15894, DOI 10.1073/pnas.0701498104
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Patel A. D., 2008, Music, Language, and the Brain
   Patel AD, 2003, NAT NEUROSCI, V6, P674, DOI 10.1038/nn1082
   Patel AD, 2008, BEHAV BRAIN SCI, V31, P589, DOI 10.1017/S0140525X0800544X
   Paulmann S, 2008, BRAIN LANG, V104, P262, DOI 10.1016/j.bandl.2007.03.002
   Pell MD, 2003, COGN AFFECT BEHAV NE, V3, P275, DOI 10.3758/CABN.3.4.275
   Pell MD, 2009, J NONVERBAL BEHAV, V33, P107, DOI 10.1007/s10919-008-0065-7
   Pell MD, 2002, BRAIN COGNITION, V48, P499, DOI 10.1006/brxg.2001.1406
   Peretz I, 2003, NAT NEUROSCI, V6, P688, DOI 10.1038/nn1083
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   Peretz I., 2013, HDB MUSIC EMOTION TH, P99, DOI [10.1093/acprof:oso/9780199230143.003.0005, DOI 10.1093/ACPROF:OSO/9780199230143.003.0005]
   Peretz I, 2008, CURR DIR PSYCHOL SCI, V17, P329, DOI 10.1111/j.1467-8721.2008.00600.x
   Salthouse TA, 2009, NEUROBIOL AGING, V30, P507, DOI 10.1016/j.neurobiolaging.2008.09.023
   Sauter DA, 2010, Q J EXP PSYCHOL, V63, P2251, DOI 10.1080/17470211003721642
   Sauter DA, 2010, P NATL ACAD SCI USA, V107, P2408, DOI 10.1073/pnas.0908239106
   Schellenberg EG, 2006, J EDUC PSYCHOL, V98, P457, DOI 10.1037/0022-0663.98.2.457
   Schellenberg EG, 2004, PSYCHOL SCI, V15, P511, DOI 10.1111/j.0956-7976.2004.00711.x
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Scherer KR, 2003, SER AFFECTIVE SCI, P433
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   Schön D, 2010, J COGNITIVE NEUROSCI, V22, P1026, DOI 10.1162/jocn.2009.21302
   Schön D, 2004, PSYCHOPHYSIOLOGY, V41, P341, DOI 10.1111/1469-8986.00172.x
   Strait DL, 2009, EUR J NEUROSCI, V29, P661, DOI 10.1111/j.1460-9568.2009.06617.x
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Trehub SE, 2006, COGNITION, V100, P73, DOI 10.1016/j.cognition.2005.11.006
   Trenerry M. R, 1995, STROOP NEUROPSYCHOLO
   Trimmer CG, 2008, EMOTION, V8, P838, DOI 10.1037/a0014080
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   von dem Hagen EAH, 2011, CEREB CORTEX, V21, P493, DOI 10.1093/cercor/bhq062
   WAGNER HL, 1993, J NONVERBAL BEHAV, V17, P3, DOI 10.1007/BF00987006
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 85
TC 108
Z9 125
U1 3
U2 77
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 1528-3542
EI 1931-1516
J9 EMOTION
JI Emotion
PD OCT
PY 2011
VL 11
IS 5
BP 1021
EP 1031
DI 10.1037/a0024521
PG 11
WC Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA 826RR
UT WOS:000295372600002
PM 21942696
DA 2024-01-09
ER

PT J
AU Kornreich, C
   Saeremans, M
   Delwarte, J
   Noël, X
   Campanella, S
   Verbanck, P
   Ermer, E
   Brevers, D
AF Kornreich, Charles
   Saeremans, Melanie
   Delwarte, Jennifer
   Noel, Xavier
   Campanella, Salvatore
   Verbanck, Paul
   Ermer, Elsa
   Brevers, Damien
TI Impaired non-verbal emotion processing in Pathological Gamblers
SO PSYCHIATRY RESEARCH
LA English
DT Article
DE Pathological gambling; Emotion; Non-verbal; Faces; Voices; Music; Social
   perception
ID FACIAL EXPRESSION RECOGNITION; HIGH-RISK; ALCOHOLISM; ALEXITHYMIA;
   IMPAIRMENTS; PERCEPTION; BEHAVIORS; FAMILIES; DEFICITS; PROSODY
AB Impaired perception of emotion in others has been described and confirmed in addictions with substances, but no such data exists regarding addictions without substances. As it has been hypothesized that toxic effect of substances on the brain was responsible for the impairments described, studying addictions without substances could be of interest to confirm this hypothesis. Twenty-two male pathological gamblers were compared to 22 male healthy controls matched for age and education level on non-verbal emotion perception tasks including faces, voices, and musical excerpts. Depression and anxiety levels were controlled for. Pathological gamblers significantly underestimated the intensity of peacefulness in music, and overall they were less accurate when reading emotion in voices and faces. They also overestimated emotional intensity in neutral voices and faces. Although anxiety levels did account for accuracy problems when detecting fear in voices and for overestimating emotions in neutral faces, anxiety levels did not explain the range of deficits observed. This is the first study showing nonverbal perception deficits in a purely behavioural addiction. These findings show that deficits in decoding non-verbal signals are associated with addictive behaviours per se, and are not due solely to toxic effects of substances on the brain. (C) 2015 Elsevier Ireland Ltd. All rights reserved.
C1 [Kornreich, Charles; Saeremans, Melanie; Delwarte, Jennifer; Noel, Xavier; Campanella, Salvatore; Verbanck, Paul; Brevers, Damien] Univ Libre Bruxelles, Psychol Med Lab & Addictol, Brussels, Belgium.
   [Ermer, Elsa] Univ Maryland, Sch Med, Baltimore, MD 21201 USA.
C3 Universite Libre de Bruxelles; University System of Maryland; University
   of Maryland Baltimore
RP Kornreich, C (corresponding author), Univ Libre Bruxelles, Psychol Med Lab & Addictol, Brussels, Belgium.
EM ckornrei@ulb.ac.be
RI ; Brevers, Damien/Q-6171-2018
OI Kornreich, Charles/0000-0002-4898-5588; Brevers,
   Damien/0000-0003-4503-0898
CR Aïte A, 2014, COGN BEHAV NEUROL, V27, P59, DOI 10.1097/WNN.0000000000000027
   Association AP., 2022, Diagnostic and statistical manual of mental disorders, DOI DOI 10.1176/APPI.BOOKS.9780890425787
   BECK AT, 1988, CLIN PSYCHOL REV, V8, P77, DOI 10.1016/0272-7358(88)90050-5
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Blaszczynski A, 2002, ADDICTION, V97, P487, DOI 10.1046/j.1360-0443.2002.00015.x
   Brevers D, 2014, J GAMBL STUD, V30, P141, DOI 10.1007/s10899-012-9348-3
   Brevers D, 2013, J GAMBL STUD, V29, P119, DOI 10.1007/s10899-012-9292-2
   Brevers D, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0050647
   D'Hondt Fabien, 2014, Neuropsychiatr Dis Treat, V10, P2177, DOI 10.2147/NDT.S74963
   Donadon MF, 2014, NEUROPSYCH DIS TREAT, V10, P1655, DOI 10.2147/NDT.S65376
   Frigerio E, 2002, PSYCHIAT RES, V113, P161, DOI 10.1016/S0165-1781(02)00244-5
   Glahn DC, 2007, BIOL PSYCHIAT, V61, P1306, DOI 10.1016/j.biopsych.2006.09.041
   Goudriaan AE, 2004, NEUROSCI BIOBEHAV R, V28, P123, DOI 10.1016/j.neubiorev.2004.03.001
   Hill SY, 2007, ALCOHOL CLIN EXP RES, V31, P2028, DOI 10.1111/j.1530-0277.2007.00535.x
   Hill SY, 2001, BIOL PSYCHIAT, V49, P894, DOI 10.1016/S0006-3223(01)01088-5
   Ibáñez A, 2001, AM J PSYCHIAT, V158, P1733, DOI 10.1176/appi.ajp.158.10.1733
   Kim SW, 2001, PSYCHIAT RES, V104, P205
   Kopelman MD, 2008, ADDICTION, V103, P736, DOI 10.1111/j.1360-0443.2008.02225.x
   Kornreich C, 2003, PSYCHIAT RES, V119, P251, DOI 10.1016/S0165-1781(03)00130-6
   Kornreich C, 2002, ALCOHOL ALCOHOLISM, V37, P394, DOI 10.1093/alcalc/37.4.394
   Kornreich C, 2001, PSYCHIAT RES, V102, P235, DOI 10.1016/S0165-1781(01)00261-X
   Kornreich C, 2013, ADDICTION, V108, P80, DOI 10.1111/j.1360-0443.2012.03995.x
   Ledgerwood DM, 2006, PSYCHIAT RES, V144, P17, DOI 10.1016/j.psychres.2005.08.017
   Martins SS, 2004, ADDICT BEHAV, V29, P1231, DOI 10.1016/j.addbeh.2004.03.023
   Maurage P, 2007, CLIN NEUROPHYSIOL, V118, P633, DOI 10.1016/j.clinph.2006.11.007
   Maurage P, 2011, ALCOHOL CLIN EXP RES, V35, P1662, DOI 10.1111/j.1530-0277.2011.01512.x
   Maurage P, 2009, ALCOHOL ALCOHOLISM, V44, P476, DOI 10.1093/alcalc/agp037
   Milosevic A, 2010, CLIN PSYCHOL REV, V30, P988, DOI 10.1016/j.cpr.2010.06.013
   Monnot M, 2001, ALCOHOL CLIN EXP RES, V25, P362, DOI 10.1111/j.1530-0277.2001.tb02222.x
   O'Daly OG, 2012, NEUROPSYCHOPHARMACOL, V37, P2267, DOI 10.1038/npp.2012.77
   Parker JDA, 2008, PERS INDIV DIFFER, V45, P174, DOI 10.1016/j.paid.2008.03.018
   Petry NM, 2006, ADDICTION, V101, P152, DOI 10.1111/j.1360-0443.2006.01593.x
   Philippot P, 1999, ALCOHOL CLIN EXP RES, V23, P1031, DOI 10.1097/00000374-199906000-00010
   Potenza MN, 2008, PHILOS T R SOC B, V363, P3181, DOI 10.1098/rstb.2008.0100
   SELZER ML, 1975, J STUD ALCOHOL, V36, P117, DOI 10.15288/jsa.1975.36.117
   Spielberger C.D., 1983, Manual for the State-Trait Anxiety Inventory
   Toneatto T, 2009, J ADDICT DIS, V28, P193, DOI 10.1080/10550880903014775
   Townshend JM, 2003, NEUROPSYCHOLOGIA, V41, P773, DOI 10.1016/S0028-3932(02)00284-1
   Uekermann J, 2007, ADDICTION, V102, P232, DOI 10.1111/j.1360-0443.2006.01656.x
   Uekermann J, 2005, CORTEX, V41, P189, DOI 10.1016/S0010-9452(08)70893-1
   Uekermann J, 2008, ADDICTION, V103, P726, DOI 10.1111/j.1360-0443.2008.02157.x
   van den Brink W, 2014, Tijdschr Psychiatr, V56, P206
   Verdejo-Garcia A, 2008, NEUROSCI BIOBEHAV R, V32, P777, DOI 10.1016/j.neubiorev.2007.11.003
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   Williams AD, 2012, BRIT J CLIN PSYCHOL, V51, P223, DOI 10.1111/j.2044-8260.2011.02022.x
NR 45
TC 13
Z9 13
U1 0
U2 11
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0165-1781
J9 PSYCHIAT RES
JI Psychiatry Res.
PD FEB 28
PY 2016
VL 236
BP 125
EP 129
DI 10.1016/j.psychres.2015.12.020
PG 5
WC Psychiatry
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Psychiatry
GA DE8VD
UT WOS:000370913900021
PM 26730447
DA 2024-01-09
ER

PT J
AU Xia, H
AF Xia, Han
TI Influence of Diversified Health Elements Based on Machine Learning
   Technology on Pop Vocal Singing in a Cultural Fusion Environment
SO JOURNAL OF ENVIRONMENTAL AND PUBLIC HEALTH
LA English
DT Article
AB The multicultural environment is affected by the ongoing advancement of science and technology, which results in more and more planned cultural fusions and collisions between various cultures. The emergence of distinct national cultures has emphasised cultural diversity. Music naturally takes the initiative and promotes diversity in social and cultural awareness as a cultural art form with distinctive charm. Cultural variables play a significant role in the development, appeal, and wide transmission of voice output. It is an authentic catharsis and a vivid record of spiritual activity among people. Because the diversity of art is also the source of the legacy and growth of creative innovation, the diversified integration of art will also promote the shared development of all nations. Vocal music and singing art must adapt to the circumstances, follow the trend of the times, and grow slowly and healthily in the direction of diversity in the context of multicultural development. Musical emotion is the key component of music. The periodic properties of sound should be studied since they have important implications for music study. In order to learn and predict the 8-dimensional emotion vector of musical compositions, this study creates a dataset of 200 pieces of music, isolates music emotion detection as a regression issue, and applies machine learning techniques. According to experimental findings, when mid- and high-level characteristics are used as input instead of low-level features, accuracy can increase from 50.28% to 68.39%.
C1 [Xia, Han] Shenyang Conservatory Mus, Modern Conservatory Mus, Dept Popular Vocal Mus, Shenyang 110168, Liaoning, Peoples R China.
C3 Shenyang Conservatory of Music
RP Xia, H (corresponding author), Shenyang Conservatory Mus, Modern Conservatory Mus, Dept Popular Vocal Mus, Shenyang 110168, Liaoning, Peoples R China.
EM wallard32317@student.napavalley.edu
CR Bennett A., 2017, OPEN U PRESS, V5, P32
   Cahn W.L., 2018, PERFORMING ARTS, V489, P49
   Deng Y., 2018, J LIUZHOU TEACHERS C, V49, P487
   Guo X., 2021, ART MUSIC J SHANGHAI, V58, P21
   Ji-Jun H.E., 2019, J HUAIHUA U, V39, P408
   Klement B, 2019, REG STUD, V53, P1447, DOI 10.1080/00343404.2019.1580817
   Lei M., 2019, J HEIHE U, V92, P40
   Lin X.U., 2019, COMPUTER ENG, V190, P40
   Oliveira R.S., 2018, POPULAR MUSIC STUDIE, V9, P30
   Onwuegbuna I.E., 2020, INT J EDUC RES, V12, P212
   Owen S.E., 2020, U HOUSTON, V28, P389
   Podmore C., 2018, NOTES, V589, P390
   Tong C., 2018, J HEIHE U, V209, P9
   Wang Y., 2017, REV FACULTAD INGENIE, V32, P707
   Wang Z.X., 2019, JILIN NORMAL U J HUM, V290, P39
   Wei C.C., 2017, COMPUTER ART, V20, P099
   Xie H., 2018, J HEBEI NORMAL U ED, V99, P49
   Xue F., 2019, VALUE ENG, V2, P30
   Yan F, 2019, TRANSL NEUROSCI, V10, P135, DOI 10.1515/tnsci-2019-0023
   Yang L.J., 2019, J YANGTZE U SOCIAL S, V209, P380
   Yang Y., 2017, J CHIFENG U PHILOS S, V29, P300
NR 21
TC 0
Z9 0
U1 10
U2 15
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1687-9805
EI 1687-9813
J9 J ENVIRON PUBLIC HEA
JI J. Environ. Public Health
PD SEP 26
PY 2022
VL 2022
AR 7903838
DI 10.1155/2022/7903838
PG 10
WC Public, Environmental & Occupational Health
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Public, Environmental & Occupational Health
GA 5I8XV
UT WOS:000868633700008
PM 36200080
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Sturgeon, BA
   Hubbard, RJ
   Schmidt, SA
   Loucks, TM
AF Sturgeon, Brantly A.
   Hubbard, Ryan J.
   Schmidt, Sara A.
   Loucks, Torrey M.
TI High F<sub>o</sub> and musicianship make a difference: Pitch-shift
   responses across the vocal range
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Pitch-shift response; Fundamental frequency; Pitch High F-o; Musical
   experience; Musician
ID AUDITORY-FEEDBACK; FUNDAMENTAL-FREQUENCY; FOLD ADDUCTION; VOICE;
   INTENSITY; ELECTROMYOGRAPHY; EMOTION; LEVEL
AB The control of vocal pitch plays a central role in speech and singing, where accurate tonal production relies on modulating F-o production. Previous research has shown that vocal pitch is modulated in response to artificial pitch perturbations during ongoing vocalization (i.e., the pitch-shift response) with response characteristics differing between musicians and non-musicians. However, little is known about the behavior of these responses in the higher portion of a speaker's vocal range for amateur musicians or non-musicians. The present study addresses whether pitch control changes as target pitch is systematically increased and whether this variation is affected by musicianship. We predicted that as Fo moves away from comfortable speaking level, pitch-shift response peak amplitude would increase and peak latency would decrease, while participants with musical experience would have lower amplitude responses than those without experience. Results showed that peak amplitude linearly increased as Fo was raised, and that peak latency similarly decreased but with more variability. However, musical participants had larger pitch-shift response amplitudes and longer peak latency times than non-musical participants, which is an unanticipated finding for persons with musical training. These patterns suggest that pitch control can be manipulated by vocal tasks that vary Fo while still being subject to strong modulation by musical background. (C) 2014 Elsevier Ltd. All rights reserved.
C1 [Sturgeon, Brantly A.] Univ Illinois, Dept Elect & Comp Engn, Champaign, IL 61820 USA.
   [Hubbard, Ryan J.] Univ Illinois, Dept Psychol, Champaign, IL 61820 USA.
   [Schmidt, Sara A.; Loucks, Torrey M.] Univ Illinois, Program Neurosci, Urbana, IL 61801 USA.
   [Loucks, Torrey M.] Univ Illinois, Dept Speech & Hearing Sci, Champaign, IL 61820 USA.
   [Loucks, Torrey M.] Beckman Inst Adv Sci & Technol, Urbana, IL 61801 USA.
C3 University of Illinois System; University of Illinois Urbana-Champaign;
   University of Illinois System; University of Illinois Urbana-Champaign;
   University of Illinois System; University of Illinois Urbana-Champaign;
   University of Illinois System; University of Illinois Urbana-Champaign
RP Loucks, TM (corresponding author), Univ Illinois, Dept Speech & Hearing Sci, 901 S Sixth St, Champaign, IL 61820 USA.
EM brantly106@gmail.com; rjhubba2@illinois.edu; saschmi3@illinois.edu;
   tloucks@illinois.edu
OI Schmidt, Sara/0000-0002-0161-8350
FU National Science Foundation Award [0903622]; Division Of Graduate
   Education; Direct For Education and Human Resources [0903622] Funding
   Source: National Science Foundation
FX This research was partially supported by a National Science Foundation
   Award "Neuroengineering IGERT", Grant no. 0903622.
CR [Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225
   Bauer JJ, 2003, J ACOUST SOC AM, V114, P1048, DOI 10.1121/1.1592161
   Behroozmand R, 2014, BRAIN COGNITION, V84, P97, DOI 10.1016/j.bandc.2013.11.007
   Behroozmand R, 2012, J ACOUST SOC AM, V132, P2468, DOI 10.1121/1.4746984
   Burnett TA, 1997, J VOICE, V11, P202, DOI 10.1016/S0892-1997(97)80079-3
   Burnett TA, 1998, J ACOUST SOC AM, V103, P3153, DOI 10.1121/1.423073
   Camacho A., 2007, THESIS U FLORIDA
   Chhetri DK, 2012, J ACOUST SOC AM, V131, P1401, DOI 10.1121/1.3672686
   GAY T, 1972, ANN OTO RHINOL LARYN, V81, P401, DOI 10.1177/000348947208100311
   Hain TC, 2000, EXP BRAIN RES, V130, P133, DOI 10.1007/s002219900237
   Hain TC, 2001, J ACOUST SOC AM, V109, P2146, DOI 10.1121/1.1366319
   Herbst CT, 2011, J ACOUST SOC AM, V129, P2253, DOI 10.1121/1.3552874
   HIRANO M, 1969, J SPEECH HEAR RES, V12, P362, DOI 10.1044/jshr.1202.362
   HIRANO M, 1970, FOLIA PHONIATR, V22, P1, DOI 10.1159/000263363
   ISSHIKI N, 1965, FOLIA PHONIATR, V17, P92, DOI 10.1159/000263031
   Jones JA, 2008, EXP BRAIN RES, V190, P279, DOI 10.1007/s00221-008-1473-y
   Juslin PN, 2001, EMOTION, V1, P381, DOI 10.1037//1528-3542.1.4.381
   Keough D, 2009, J ACOUST SOC AM, V126, P837, DOI 10.1121/1.3158600
   Kochis-Jennings KA, 2012, J VOICE, V26, P182, DOI 10.1016/j.jvoice.2010.11.002
   Larson CR, 2008, EXP BRAIN RES, V187, P613, DOI 10.1007/s00221-008-1330-z
   LIEBERMAN P, 1962, J ACOUST SOC AM, V34, P922, DOI 10.1121/1.1918222
   Lima CF, 2013, BEHAV RES METHODS, V45, P1234, DOI 10.3758/s13428-013-0324-3
   Liu HJ, 2007, J ACOUST SOC AM, V122, P3671, DOI 10.1121/1.2800254
   Liu HJ, 2011, J ACOUST SOC AM, V129, P3946, DOI 10.1121/1.3575593
   Liu HJ, 2010, NEUROREPORT, V21, P527, DOI 10.1097/WNR.0b013e3283393a44
   Liu HJ, 2010, J ACOUST SOC AM, V127, pEL1, DOI 10.1121/1.3263897
   Liu HJ, 2009, J ACOUST SOC AM, V125, P2299, DOI 10.1121/1.3081523
   Mandell J., 2009, ADAPTIVE PITCH TEST
   McCrea CR, 2005, J SPEECH LANG HEAR R, V48, P1013, DOI 10.1044/1092-4388(2005/069)
   Rosenberg S., 1970, J ACOUSTICAL SOC S2, V49, P583
   STEMPLE JC, 1995, J VOICE, V9, P127, DOI 10.1016/S0892-1997(05)80245-0
   Titze I., 1994, Principles of Voice Production
   Trainor LJ, 2014, HEARING RES, V308, P60, DOI 10.1016/j.heares.2013.07.014
   VERDOLINIMARSTON K, 1990, J VOICE, V4, P142, DOI 10.1016/S0892-1997(05)80139-0
   Zarate JM, 2008, NEUROIMAGE, V40, P1871, DOI 10.1016/j.neuroimage.2008.01.026
   Zarate JM, 2010, NEUROPSYCHOLOGIA, V48, P607, DOI 10.1016/j.neuropsychologia.2009.10.025
   Zarate JM, 2005, ANN NY ACAD SCI, V1060, P404, DOI 10.1196/annals.1360.058
NR 37
TC 9
Z9 10
U1 0
U2 7
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD JUL
PY 2015
VL 51
SI SI
BP 70
EP 81
DI 10.1016/j.wocn.2014.12.001
PG 12
WC Linguistics; Language & Linguistics
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Linguistics
GA CN5JY
UT WOS:000358466800005
DA 2024-01-09
ER

PT J
AU Sachs, ME
   Habibi, A
   Damasio, A
   Kaplan, JT
AF Sachs, Matthew E.
   Habibi, Assal
   Damasio, Antonio
   Kaplan, Jonas T.
TI Decoding the neural signatures of emotions expressed through sound
SO NEUROIMAGE
LA English
DT Article
DE fMRI; Music; Voice; Emotions; Multivoxel pattern analysis
ID VOXEL PATTERN-ANALYSIS; FMRI DATA; MUSICAL SOUNDS; BASIC EMOTIONS; RIGHT
   INSULA; BRAIN; PERCEPTION; EMPATHY; AUTISM; REPRESENTATIONS
AB Effective social functioning relies in part on the ability to identify emotions from auditory stimuli and respond appropriately. Previous studies have uncovered brain regions engaged by the affective information conveyed by sound. But some of the acoustical properties of sounds that express certain emotions vary remarkably with the instrument used to produce them, for example the human voice or a violin. Do these brain regions respond in the same way to different emotions regardless of the sound source? To address this question, we had participants (N -38, 20 females) listen to brief audio excerpts produced by the violin, clarinet, and human voice, each conveying one of three target emotions-happiness, sadness, and fear-while brain activity was measured with fMRI. We used multivoxel pattern analysis to test whether emotion-specific neural responses to the voice could predict emotion-specific neural responses to musical instruments and vice-versa. A whole-brain searchlight analysis revealed that patterns of activity within the primary and secondary auditory cortex, posterior insula, and parietal operculum were predictive of the affective content of sound both within and across instruments. Furthermore, classification accuracy within the anterior insula was correlated with behavioral measures of empathy. The findings suggest that these brain regions carry emotion-specific patterns that generalize across sounds with different acoustical properties. Also, individuals with greater empathic ability have more distinct neural patterns related to perceiving emotions. These results extend previous knowledge regarding how the human brain extracts emotional meaning from auditory stimuli and enables us to understand and connect with others effectively.
C1 [Sachs, Matthew E.; Habibi, Assal; Damasio, Antonio; Kaplan, Jonas T.] Univ Southern Calif, Brain & Creat Inst, 3620A McClintock Ave, Los Angeles, CA 90089 USA.
C3 University of Southern California
RP Sachs, ME (corresponding author), Univ Southern Calif, Brain & Creat Inst, 3620A McClintock Ave, Los Angeles, CA 90089 USA.
EM msachs@usc.edu
RI Damasio, Antonio/AAD-1342-2019
FU Brain and Creativity Institute
FX Funding for this work was provided by the Brain and Creativity
   Institute.
CR Adolphs R, 2000, J NEUROSCI, V20, P2683
   Alaerts K, 2014, SOC COGN AFFECT NEUR, V9, P1589, DOI 10.1093/scan/nst156
   Allen R, 2013, J AUTISM DEV DISORD, V43, P432, DOI 10.1007/s10803-012-1587-8
   Alluri V, 2012, NEUROIMAGE, V59, P3677, DOI 10.1016/j.neuroimage.2011.11.019
   Aube W., 2013, SOC COGN AFFECT NEUR, V10, P399
   Bamiou DE, 2003, BRAIN RES REV, V42, P143, DOI 10.1016/S0165-0173(03)00172-3
   Baumgartner T, 2006, BRAIN RES, V1075, P151, DOI 10.1016/j.brainres.2005.12.065
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Bestelmeyer PEG, 2014, J NEUROSCI, V34, P8098, DOI 10.1523/JNEUROSCI.4820-13.2014
   Calder AJ, 2000, NAT NEUROSCI, V3, P1077, DOI 10.1038/80586
   Carr L, 2003, P NATL ACAD SCI USA, V100, P5497, DOI 10.1073/pnas.0935845100
   Craig AD, 2009, NAT REV NEUROSCI, V10, P59, DOI 10.1038/nrn2555
   Damasio A, 2013, CEREB CORTEX, V23, P833, DOI 10.1093/cercor/bhs077
   Dapretto M, 2006, NAT NEUROSCI, V9, P28, DOI 10.1038/nn1611
   DAVIS MH, 1983, J PERS SOC PSYCHOL, V44, P113, DOI 10.1037/0022-3514.44.1.113
   Deen B, 2011, CEREB CORTEX, V21, P1498, DOI 10.1093/cercor/bhq186
   Ebisch SJH, 2011, HUM BRAIN MAPP, V32, P1013, DOI 10.1002/hbm.21085
   Eickhoff SB, 2006, CEREB CORTEX, V16, P254, DOI 10.1093/cercor/bhi105
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Escoffier N, 2013, HUM BRAIN MAPP, V34, P1796, DOI 10.1002/hbm.22029
   Ethofer T, 2009, CURR BIOL, V19, P1028, DOI 10.1016/j.cub.2009.04.054
   Fifer R C, 1993, J Am Acad Audiol, V4, P364
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Frühholz S, 2014, PROG NEUROBIOL, V123, P1, DOI 10.1016/j.pneurobio.2014.09.003
   Hailstone JC, 2009, Q J EXP PSYCHOL, V62, P2141, DOI 10.1080/17470210902765957
   Heller R, 2006, NEUROIMAGE, V33, P599, DOI 10.1016/j.neuroimage.2006.04.233
   Immordino-Yang MH, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00728
   Jenkinson M, 2001, MED IMAGE ANAL, V5, P143, DOI 10.1016/S1361-8415(01)00036-6
   Johnsen EL, 2009, INT J PSYCHOPHYSIOL, V72, P24, DOI 10.1016/j.ijpsycho.2008.03.011
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kao MH, 2009, NEUROIMAGE, V44, P849, DOI 10.1016/j.neuroimage.2008.09.025
   Kaplan JT, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00151
   Kim J, 2017, NEUROIMAGE, V148, P42, DOI 10.1016/j.neuroimage.2017.01.002
   Kim Youngmoo E, 2010, P ISMIR, P255
   Kleiner M, 2007, PERCEPTION, V36, P14
   Koelsch S, 2014, NAT REV NEUROSCI, V15, P170, DOI 10.1038/nrn3666
   Kotz SA, 2013, HUM BRAIN MAPP, V34, P1971, DOI 10.1002/hbm.22041
   Kragel PA, 2015, SOC COGN AFFECT NEUR, V10, P1437, DOI 10.1093/scan/nsv032
   Kreifelts B, 2009, NEUROPSYCHOLOGIA, V47, P3059, DOI 10.1016/j.neuropsychologia.2009.07.001
   Kriegeskorte N., 2006, INFORM BASED FUNCTIO
   Kurth F, 2010, BRAIN STRUCT FUNCT, V214, P519, DOI 10.1007/s00429-010-0255-z
   Lamm C, 2007, J COGNITIVE NEUROSCI, V19, P42, DOI 10.1162/jocn.2007.19.1.42
   Lartillot O., 2007, P INT C DIG AUD EFF, DOI DOI 10.1007/978-3-540-78246-9_31
   Linke A. C., 2015, J COGNIT NEUROSCI, V27
   Man K, 2015, HUM BRAIN MAPP, V36, P3629, DOI 10.1002/hbm.22867
   Müllensiefen D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0101091
   Norman KA, 2006, TRENDS COGN SCI, V10, P424, DOI 10.1016/j.tics.2006.07.005
   Paquette S., 2013, FRONT PSYCHOL, V4, P1
   Park M, 2013, BRAIN RES, V1523, P68, DOI 10.1016/j.brainres.2013.05.042
   Peelen MV, 2010, J NEUROSCI, V30, P10127, DOI 10.1523/JNEUROSCI.2161-10.2010
   Rigoulot S, 2015, NEUROSCIENCE, V290, P175, DOI 10.1016/j.neuroscience.2015.01.033
   Saarimäki H, 2016, CEREB CORTEX, V26, P2563, DOI 10.1093/cercor/bhv086
   Salimpoor VN, 2015, TRENDS COGN SCI, V19, P86, DOI 10.1016/j.tics.2014.12.001
   Sander K, 2005, J COGNITIVE NEUROSCI, V17, P1519, DOI 10.1162/089892905774597227
   Schirmer A, 2017, TRENDS COGN SCI, V21, P216, DOI 10.1016/j.tics.2017.01.001
   Schönwiesner M, 2005, EUR J NEUROSCI, V22, P1521, DOI 10.1111/j.1460-9568.2005.04315.x
   Silani G, 2008, SOC NEUROSCI-UK, V3, P97, DOI 10.1080/17470910701577020
   Singer T, 2004, SCIENCE, V303, P1157, DOI 10.1126/science.1093535
   Skerry AE, 2014, J NEUROSCI, V34, P15997, DOI 10.1523/JNEUROSCI.1676-14.2014
   Smith SM, 2004, NEUROIMAGE, V23, pS208, DOI 10.1016/j.neuroimage.2004.07.051
   Smith SM, 2009, NEUROIMAGE, V44, P83, DOI 10.1016/j.neuroimage.2008.03.061
   Stelzer J, 2013, NEUROIMAGE, V65, P69, DOI 10.1016/j.neuroimage.2012.09.063
   Straube T, 2011, NEUROIMAGE, V54, P2534, DOI 10.1016/j.neuroimage.2010.10.010
   van Rijn S, 2005, EUR J NEUROSCI, V21, P3195, DOI 10.1111/j.1460-9568.2005.04130.x
   von dem Hagen EAH, 2011, CEREB CORTEX, V21, P493, DOI 10.1093/cercor/bhq062
   Wegrzyn M, 2015, CORTEX, V69, P131, DOI 10.1016/j.cortex.2015.05.003
   Winkler AM, 2014, NEUROIMAGE, V92, P381, DOI 10.1016/j.neuroimage.2014.01.060
NR 67
TC 26
Z9 29
U1 2
U2 61
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD JUL 1
PY 2018
VL 174
BP 1
EP 10
DI 10.1016/j.neuroimage.2018.02.058
PG 10
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA GM9XK
UT WOS:000438609100001
PM 29501874
DA 2024-01-09
ER

PT J
AU Tang, ZC
AF Tang, Zhangcheng
TI Application Model Construction of Emotional Expression and Propagation
   Path of Deep Learning in National Vocal Music
SO INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS
LA English
DT Article
DE Deep learning; national vocal music; innovation; emotion; dissemination
AB expression is important in Chinese national vocal music art. The emotional expression in national vocal music is based on the art of national vocal music, with distinct characteristics and requirements. The ultimate goal is to spread the expression of various emotions in the national vocal music art. Promoting the spread of national vocal music singing art using modern media is an urgent requirement for the inheritance and development of national vocal music singing art. With the rapid development of science and technology, integrating deep learning and traditional music has become the general trend. It has been gradually applied to melody recognition, intelligent composition, virtual performance, and other aspects of traditional music and has achieved good results, but also hidden behind a series of ideas and technical and ethical issues. In this paper, the application of deep learning has been discussed and prospected. The recognition rate of emotional expression in national vocal music is 92 %. In terms of communication, combined with the deep learning algorithm, this paper analyzes the characteristics and requirements of emotional expression in the art of national vocal music singing and puts forward a new method of promoting the development of the art of national vocal music singing, hoping to attract more attention and enhance the social awareness of the application field, to promote the steady development of Chinese traditional music in the information age.
C1 [Tang, Zhangcheng] Hunan First Normal Univ, Mus & Dance Acad, Changsha 410012, Peoples R China.
C3 Hunan First Normal University
RP Tang, ZC (corresponding author), Hunan First Normal Univ, Mus & Dance Acad, Changsha 410012, Peoples R China.
CR Chowdhuri S, 2019, J Acoust Soc Am, V146, P2947
   Dean RT, 2020, NEURAL COMPUT APPL, V32, P969, DOI 10.1007/s00521-018-3765-x
   Du XF, 2020, J INTELL FUZZY SYST, V38, P7241, DOI 10.3233/JIFS-179800
   Er MB, 2019, INT J COMPUT INT SYS, V12, P1622, DOI 10.2991/ijcis.d.191216.001
   Hong H, 2021, INT J ELEC ENG EDUC, DOI 10.1177/0020720920983559
   Hu Y, 2022, J MATH-UK, V2022, DOI 10.1155/2022/2446399
   Kereliuk C, 2015, IEEE WORK APPL SIG
   Kereliuk C, 2015, IEEE T MULTIMEDIA, V17, P2059, DOI 10.1109/TMM.2015.2478068
   Kimmatkar NV, 2021, COMPUTERS, V10, DOI 10.3390/computers10030037
   Nag S, 2022, PHYSICA A, V597, DOI 10.1016/j.physa.2022.127261
   Nam J, 2019, IEEE SIGNAL PROC MAG, V36, P41, DOI 10.1109/MSP.2018.2874383
   Thammasan N, 2016, IEICE T INF SYST, VE99D, P1234, DOI 10.1587/transinf.2015EDP7251
   Wang HD, 2022, COMPUT ELECTR ENG, V100, DOI 10.1016/j.compeleceng.2022.107978
   Wittmann-Price RA, 2009, NURS EDUC, V34, P214, DOI 10.1097/NNE.0b013e3181b2b576
   Zhao SC, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2945, DOI 10.1145/3394171.3413776
NR 15
TC 0
Z9 0
U1 0
U2 0
PU SCIENCE & INFORMATION SAI ORGANIZATION LTD
PI WEST YORKSHIRE
PA 19 BOLLING RD, BRADFORD, WEST YORKSHIRE, 00000, ENGLAND
SN 2158-107X
EI 2156-5570
J9 INT J ADV COMPUT SC
JI Int. J. Adv. Comput. Sci. Appl.
PD NOV
PY 2023
VL 14
IS 11
BP 1055
EP 1062
PG 8
WC Computer Science, Theory & Methods
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA CN6P3
UT WOS:001125970300001
DA 2024-01-09
ER

PT J
AU Inoue, H
AF Inoue, Haruo
TI The Voice in the Drum: Music, Language, and Emotion in Islamicate South
   Asia
SO ETHNOMUSICOLOGY
LA English
DT Book Review
C1 [Inoue, Haruo] Kyoto Univ, Kyoto, Japan.
C3 Kyoto University
RP Inoue, H (corresponding author), Kyoto Univ, Kyoto, Japan.
CR Wolf RK, 2014, VOICE IN THE DRUM: MUSIC, LANGUAGE, AND EMOTION IN ISLAMICATE SOUTH ASIA, P1
NR 1
TC 0
Z9 0
U1 1
U2 1
PU SOC ETHNOMUSICOLOGY INC
PI BLOOMINGTON
PA MORRISON HALL, ROOM 005 INDIANA UNIVERSITY, BLOOMINGTON, IN 47405 USA
SN 0014-1836
EI 2156-7417
J9 ETHNOMUSICOLOGY
JI Ethnomusicology
PD FAL
PY 2021
VL 65
IS 3
BP 627
EP 629
DI 10.5406/ethnomusicology.65.3.0627
PG 4
WC Music
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music
GA WQ8MC
UT WOS:000714063800018
DA 2024-01-09
ER

PT J
AU Robledo, JP
   Hurtado, E
   Prado, F
   Román, D
   Cornejo, C
AF Robledo, Juan P.
   Hurtado, Esteban
   Prado, Felipe
   Roman, Domingo
   Cornejo, Carlos
TI Music intervals in speech: Psychological disposition modulates ratio
   precision among interlocutors' nonlocal f0 production in real-time
   dyadic conversation
SO PSYCHOLOGY OF MUSIC
LA English
DT Article
DE dialogic speech; musical intervals; music cognition; nonlocal
   dependencies; pitch; trust; vocal prosody
ID PITCH; COMMUNICATION; INTONATION; PREFERENCE; CONSONANCE; ABSOLUTE;
   EMOTION; INFANTS
AB Drawing on the notion of musical intervals, recent studies have demonstrated the use of precise frequency ratios within human vocalisation. Methodologically, these studies have addressed human vocalisation at an individual level. In the present study, we asked whether patterns such as musical intervals can also be found among the voices of people engaging in a conversation as an emerging interpersonal phenomenon. Fifty-six participants were randomly paired and assigned to either a control or a low-trust condition. Frequency ratios were generated by juxtaposing nonlocal fundamental frequency (f0) productions from two people engaged in each given dyadic conversation. Differences were found among conditions, both in terms of interval distribution and precision. These results support the idea that psychological dispositions modulate the musical intervals generated between participants through mutual real-time vocal accommodation. They also underscore the inter-domain use of musical intervals.
C1 [Robledo, Juan P.; Hurtado, Esteban; Prado, Felipe; Cornejo, Carlos] Pontificia Univ Catolica Chile, Dept Psychol, Language Interact & Phenomenol Lab LIF, Santiago, Chile.
   [Hurtado, Esteban] Univ Diego Portales, UDP INECO Fdn Core Neurosci UIFCoN, Lab Cognit & Social Neurosci, Santiago, Chile.
   [Roman, Domingo] Univ Santiago Chile, Humanities Fac, Santiago, Chile.
   [Robledo, Juan P.] Univ Cambridge, Fac Mus, Ctr Mus & Sci, Cambridge, England.
C3 Pontificia Universidad Catolica de Chile; University Diego Portales;
   Universidad de Santiago de Chile; University of Cambridge
RP Robledo, JP (corresponding author), Univ Cambridge Wolfson Coll, Barton Rd, Cambridge CB3 9BB, England.
EM jper2@cam.ac.uk
RI Cornejo, Carlos/Q-6871-2017
OI Cornejo, Carlos/0000-0001-5426-0025; Prado, Felipe/0000-0003-3257-9646
FU Bioethics Advisory Committee of the Chilean National Fund for Scientific
   and Technological Research (FONDECYT) [1100863]
FX Ethical approval for this project was given by the Ethical Committee of
   the Psychology Department of Pontificia Universidad Catolica de Chile as
   well as by the Bioethics Advisory Committee of the Chilean National Fund
   for Scientific and Technological Research (FONDECYT) [Grant 1100863].
CR [Anonymous], 2009, PREHISTORY LANGUAGE
   [Anonymous], ANN CHILD DEV
   [Anonymous], 2009, Communicative Musicality, DOI [10.1016/B978-0-12-374370-1.X0001-8, DOI 10.1016/B978-0-12-374370-1.X0001-8]
   Aron A, 1997, PERS SOC PSYCHOL B, V23, P363, DOI 10.1177/0146167297234003
   Bakhtin M. M., 1981, DIALOGIC IMAGINATION
   Bannan N, 2008, AUST J ANTHROPOL, V19, P272, DOI 10.1111/j.1835-9310.2008.tb00354.x
   Barker A., 1984, Greek Musical Writings i. The Musician and his Art
   Boersma P., 2021, Glot International
   Bowling DL, 2010, J ACOUST SOC AM, V127, P491, DOI 10.1121/1.3268504
   Bowling DL, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0031942
   Brown S, 2000, ORIGINS OF MUSIC, P271
   BURNS EM, 1978, J ACOUST SOC AM, V63, P456, DOI 10.1121/1.381737
   BURNS EM, 1994, J ACOUST SOC AM, V96, P2704, DOI 10.1121/1.411447
   Cruttenden A., 1997, Intonation
   Curtis ME, 2010, EMOTION, V10, P335, DOI 10.1037/a0017928
   Darwin G., 1871, P423
   FERNALD A, 1989, CHILD DEV, V60, P1497, DOI 10.2307/1130938
   Fernald A., 1992, Nonverbal vocal communication: Comparative and developmental approaches, P262
   Gregory SW, 1997, J NONVERBAL BEHAV, V21, P23
   HOCKETT CF, 1960, SCI AM, V203, P88, DOI 10.1038/scientificamerican0960-88
   Johnson Keith, 2003, ACOUSTIC AUDITORY PH
   Jonas O., 1956, NEUE MUSIKALISCHE TH
   Kashkin V., 2012, J SIBERIAN FEDERAL U, V12, P1733
   Kelso JS., 1995, Dynamic patterns: the self-organization of brain and behavior
   Kim Midam, 2011, Lab Phonol, V2, P125
   Koelsch S, 2013, P NATL ACAD SCI USA, V110, P15443, DOI 10.1073/pnas.1300272110
   KRAMER E, 1964, J ABNORM SOC PSYCH, V68, P390, DOI 10.1037/h0042473
   Luhmann N., 1998, TRUST MAKING BREAKIN, P94
   Masataka N, 2006, DEVELOPMENTAL SCI, V9, P46, DOI 10.1111/j.1467-7687.2005.00462.x
   Nevins A, 2009, LANGUAGE, V85, P355
   Ochs Elinor, 1996, Rethinking linguistic relativity, V17, P407
   Oelmann H., 2008, COGNITIVE PROCESSING, V10, P113
   Ogden R, 2006, J PRAGMATICS, V38, P1752, DOI 10.1016/j.pragma.2005.04.011
   Quezada C, 2012, RLA-REV LINGUIST TEO, V50, P145, DOI 10.4067/S0718-48832012000200007
   Ross D, 2007, P NATL ACAD SCI USA, V104, P9852, DOI 10.1073/pnas.0703140104
   Saarni C, 1998, DEV PSYCHOL, V34, P647, DOI 10.1037/0012-1649.34.4.647
   Salzer F, 1962, STRUCTURAL HEARING T, V1
   Schellenberg EG, 1996, PSYCHOL SCI, V7, P272, DOI 10.1111/j.1467-9280.1996.tb00373.x
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Schwartz DA, 2003, J NEUROSCI, V23, P7160, DOI 10.1523/JNEUROSCI.23-18-07160.2003
   SIEGEL JA, 1977, PERCEPT PSYCHOPHYS, V21, P143, DOI 10.3758/BF03198717
   Simpson JA, 2007, CURR DIR PSYCHOL SCI, V16, P264, DOI 10.1111/j.1467-8721.2007.00517.x
   Smith LD, 1999, AM J PSYCHOL, V112, P383, DOI 10.2307/1423638
   STERN DN, 1982, DEV PSYCHOL, V18, P727
   Trainor LJ, 2002, MUSIC PERCEPT, V20, P187, DOI 10.1525/mp.2002.20.2.187
   Trainor LJ, 2000, PSYCHOL SCI, V11, P188, DOI 10.1111/1467-9280.00240
   Trainor LJ, 2002, PSYCHON B REV, V9, P335, DOI 10.3758/BF03196290
   TREHUB SE, 1993, ADV CHILD DEV BEHAV, V24, P1, DOI 10.1016/S0065-2407(08)60298-0
   Trehub SE, 2003, NAT NEUROSCI, V6, P669, DOI 10.1038/nn1084
   Wiener N., 1961, CYBERNETICS CONTROL
   Wray A, 2007, LINGUA, V117, P543, DOI 10.1016/j.lingua.2005.05.005
   Zatorre RJ, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001372
NR 52
TC 1
Z9 1
U1 0
U2 9
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0305-7356
EI 1741-3087
J9 PSYCHOL MUSIC
JI Psychol. Music
PD NOV
PY 2016
VL 44
IS 6
BP 1404
EP 1418
DI 10.1177/0305735616634452
PG 15
WC Psychology, Educational; Psychology, Applied; Music; Psychology,
   Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Psychology; Music
GA EJ4TV
UT WOS:000393210700013
OA Green Published, Green Submitted
DA 2024-01-09
ER

PT J
AU Fiol, S
AF Fiol, Stefan
TI The Voice in the Drum: Music, Language, and Emotion in Islamicate South
   Asia.
SO JOURNAL OF ASIAN STUDIES
LA English
DT Book Review
C1 [Fiol, Stefan] Univ Cincinnati, Cincinnati, OH 45221 USA.
C3 University System of Ohio; University of Cincinnati
RP Fiol, S (corresponding author), Univ Cincinnati, Cincinnati, OH 45221 USA.
EM stefan.fiol@uc.edu
CR Wolf RK, 2014, VOICE IN THE DRUM: MUSIC, LANGUAGE, AND EMOTION IN ISLAMICATE SOUTH ASIA, P1
NR 1
TC 0
Z9 0
U1 0
U2 0
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0021-9118
EI 1752-0401
J9 J ASIAN STUD
JI J. Asian Stud.
PD FEB
PY 2019
VL 78
IS 1
BP 232
EP 234
DI 10.1017/S0021911818002887
PG 3
WC Area Studies; Asian Studies
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Area Studies; Asian Studies
GA HO7AL
UT WOS:000461085900036
OA Bronze
DA 2024-01-09
ER

PT J
AU Catlin-Jairazbhoy, A
AF Catlin-Jairazbhoy, Amy
TI The Voice in the Drum: Music, Language, and Emotion in Islamicate South
   Asia
SO AMERICAN ANTHROPOLOGIST
LA English
DT Book Review
C1 [Catlin-Jairazbhoy, Amy] Univ Calif Los Angeles, Los Angeles, CA 90024 USA.
C3 University of California System; University of California Los Angeles
RP Catlin-Jairazbhoy, A (corresponding author), Univ Calif Los Angeles, Los Angeles, CA 90024 USA.
CR Wolf RK, 2014, VOICE IN THE DRUM: MUSIC, LANGUAGE, AND EMOTION IN ISLAMICATE SOUTH ASIA, P1
NR 1
TC 0
Z9 0
U1 0
U2 1
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0002-7294
EI 1548-1433
J9 AM ANTHROPOL
JI Am. Anthropol.
PD MAR
PY 2016
VL 118
IS 1
BP 224
EP 225
DI 10.1111/aman.12496
PG 2
WC Anthropology
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Anthropology
GA DI4TK
UT WOS:000373492000076
DA 2024-01-09
ER

PT J
AU Lima, CF
   Anikin, A
   Monteiro, AC
   Scott, SK
   Castro, SL
AF Lima, Cesar F.
   Anikin, Andrey
   Monteiro, Ana Catarina
   Scott, Sophie K.
   Castro, Sao Luis
TI Automaticity in the Recognition of Nonverbal Emotional Vocalizations
SO EMOTION
LA English
DT Article
DE automaticity; cognitive load; deliberation; emotion recognition;
   nonverbal vocalizations
ID VOCAL EXPRESSIONS; PARKINSONS-DISEASE; TIME-COURSE; PERCEPTION; VOICE;
   ATTENTION; CHANNELS; MUSIC; FACE; FEAR
AB The ability to perceive the emotions of others is crucial for everyday social interactions. Important aspects of visual socioemotional processing, such as the recognition of facial expressions, are known to depend on largely automatic mechanisms. However, whether and how properties of automaticity extend to the auditory domain remains poorly understood. Here we ask if nonverbal auditory emotion recognition is a controlled deliberate or an automatic efficient process, using vocalizations such as laughter, crying, and screams. In a between-subjects design (N = 112), and covering eight emotions (four positive), we determined whether emotion recognition accuracy (a) is improved when participants actively deliberate about their responses (compared with when they respond as fast as possible) and (b) is impaired when they respond under low and high levels of cognitive load (concurrent task involving memorizing sequences of six or eight digits, respectively). Response latencies were also measured. Mixed-effects models revealed that recognition accuracy was high across emotions, and only minimally affected by deliberation and cognitive load; the benefits of deliberation and costs of cognitive load were significant mostly for positive emotions, notably amusement/laughter, and smaller or absent for negative ones; response latencies did not suffer under low or high cognitive load; and high recognition accuracy (approximately 90%) could be reached within 500 ms after the stimulus onset, with performance exceeding chance-level already between 300 and 360 ms. These findings indicate that key features of automaticity, namely fast and efficient/effortless processing, might be a modality-independent component of emotion recognition.
C1 [Lima, Cesar F.; Monteiro, Ana Catarina; Castro, Sao Luis] Univ Porto, Fac Psychol & Educ Sci, Porto, Portugal.
   [Lima, Cesar F.] IUL, ISCTE, Ctr Invest & Intervencao Social, Ave Forcas Armadas, P-1649026 Lisbon, Portugal.
   [Lima, Cesar F.; Scott, Sophie K.] UCL, Inst Cognit Neurosci, London, England.
   [Anikin, Andrey] Lund Univ, Dept Philosophy, Div Cognit Sci, Lund, Sweden.
C3 Universidade do Porto; Instituto Universitario de Lisboa; University of
   London; University College London; Lund University
RP Lima, CF (corresponding author), IUL, ISCTE, Ctr Invest & Intervencao Social, Ave Forcas Armadas, P-1649026 Lisbon, Portugal.
EM cesar.lima@iscte-iul.pt
RI Scott, Sophie K/A-1843-2010; Castro, Sao Luis/ISV-1010-2023; Castro, Sao
   Luis/E-5518-2017; Lima, Cesar F./HSF-6972-2023
OI Scott, Sophie K/0000-0001-7510-6297; Castro, Sao
   Luis/0000-0002-1487-3596; Castro, Sao Luis/0000-0002-1487-3596; Lima,
   Cesar F./0000-0003-3058-7204; Anikin, Andrey/0000-0002-1250-8261
FU Portuguese Foundation for Science and Technology, Programa Operacional
   Fatores de Competitividade; Portuguese Foundation for Science and
   Technology, Fundo Europeu de Desenvolvimento Regional (FEDER programs)
   [UID/PSI/00050/2013, POCI-01-0145-FEDER-007294]; Bial Foundation
   [N29/08]; FCT Investigator Grant from FCT (Fundacao para a Ciencia e a
   Tecnologia) [IF/00172/2015]
FX This research was supported by grants from the Portuguese Foundation for
   Science and Technology, Programa Operacional Fatores de Competitividade
   and Fundo Europeu de Desenvolvimento Regional (FEDER programs;
   UID/PSI/00050/2013; POCI-01-0145-FEDER-007294), and from the Bial
   Foundation (N29/08). During the preparation of the manuscript, Cesar F.
   Lima was supported by an FCT Investigator Grant from FCT (Fundacao para
   a Ciencia e a Tecnologia; IF/00172/2015).
CR Abboud H., 2006, SUPERLAB STIMULUS PR
   Anikin A, 2018, Q J EXP PSYCHOL, V71, P622, DOI 10.1080/17470218.2016.1270976
   Aviezer H, 2011, EMOTION, V11, P1406, DOI 10.1037/a0023578
   Bach DR, 2008, NEUROIMAGE, V42, P919, DOI 10.1016/j.neuroimage.2008.05.034
   Banissy MJ, 2010, J NEUROSCI, V30, P13552, DOI 10.1523/JNEUROSCI.0786-10.2010
   BARGH JA, 1988, J PERS SOC PSYCHOL, V54, P925, DOI 10.1037/0022-3514.54.6.925
   Bargh JA., 1994, Handbook of social cognition: Basic processes; applications, P1
   Bargh JA, 2012, TRENDS COGN SCI, V16, P593, DOI 10.1016/j.tics.2012.10.002
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Bestelmeyer PEG, 2014, J NEUROSCI, V34, P8098, DOI 10.1523/JNEUROSCI.4820-13.2014
   Blasi A, 2011, CURR BIOL, V21, P1220, DOI 10.1016/j.cub.2011.06.009
   Borod JC, 2000, COGNITION EMOTION, V14, P193, DOI 10.1080/026999300378932
   Breitenstein C, 2001, BRAIN COGNITION, V45, P277, DOI 10.1006/brcg.2000.1246
   Bürkner PC, 2017, J STAT SOFTW, V80, P1, DOI 10.18637/jss.v080.i01
   Carvalho CM., 2009, Artificial Intelligence and Statistics, P73
   Dimberg U, 2000, PSYCHOL SCI, V11, P86, DOI 10.1111/1467-9280.00221
   Ekman Paul, 1977, ANTHR BODY, P39
   GILBERT DT, 1989, J PERS SOC PSYCHOL, V57, P940, DOI 10.1037/0022-3514.57.6.940
   Globerson E, 2013, ATTEN PERCEPT PSYCHO, V75, P1799, DOI 10.3758/s13414-013-0518-x
   Gruber T, 2017, NEUROSCI BIOBEHAV R, V73, P182, DOI 10.1016/j.neubiorev.2016.12.004
   Hairston WD, 2009, COMPUT METH PROG BIO, V93, P104, DOI 10.1016/j.cmpb.2008.08.003
   Hawk ST, 2009, EMOTION, V9, P293, DOI 10.1037/a0015178
   Hoaken PNS, 2007, AGGRESSIVE BEHAV, V33, P412, DOI 10.1002/ab.20194
   Jiang XM, 2015, J EXP PSYCHOL HUMAN, V41, P597, DOI 10.1037/xhp0000043
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Karatekin C, 2004, INT J PSYCHOPHYSIOL, V52, P7, DOI 10.1016/j.ijpsycho.2003.12.002
   Kiss M, 2008, PSYCHOPHYSIOLOGY, V45, P318, DOI 10.1111/j.1469-8986.2007.00634.x
   Kruschke J.K., 2014, DOING BAYESIAN DATA, V2nd ed., DOI [DOI 10.1016/B978-0-12-405888-0.00001-5, 10.1016/B978-0-12-405888-0.09999-2, 10.1016/B978-0-12-405888-0.00005-2]
   Lavan N, 2016, J NONVERBAL BEHAV, V40, P133, DOI 10.1007/s10919-015-0222-8
   Lima CF, 2015, CEREB CORTEX, V25, P4638, DOI 10.1093/cercor/bhv134
   Lima CF, 2014, EMOTION, V14, P145, DOI 10.1037/a0034287
   Lima CF, 2013, BEHAV RES METHODS, V45, P1234, DOI 10.3758/s13428-013-0324-3
   Lima CF, 2013, J CLIN EXP NEUROPSYC, V35, P373, DOI 10.1080/13803395.2013.776518
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Liu TS, 2012, NEUROREPORT, V23, P108, DOI 10.1097/WNR.0b013e32834ea757
   Martinez L, 2016, COGNITION EMOTION, V30, P939, DOI 10.1080/02699931.2015.1035229
   McGettigan C, 2015, CEREB CORTEX, V25, P246, DOI 10.1093/cercor/bht227
   Moors A, 2006, PSYCHOL BULL, V132, P297, DOI 10.1037/0033-2909.132.2.297
   Morey RD, 2016, PSYCHON B REV, V23, P103, DOI 10.3758/s13423-015-0947-8
   Öhman A, 2001, J EXP PSYCHOL GEN, V130, P466, DOI 10.1037/0096-3445.130.3.466
   OHMAN A, 1986, PSYCHOPHYSIOLOGY, V23, P123, DOI 10.1111/j.1469-8986.1986.tb00608.x
   Otten M, 2017, SOC NEUROSCI-UK, V12, P182, DOI 10.1080/17470919.2016.1162194
   Pell MD, 2015, BIOL PSYCHOL, V111, P14, DOI 10.1016/j.biopsycho.2015.08.008
   Pinheiro AP, 2016, SOC COGN AFFECT NEUR, V11, P127, DOI 10.1093/scan/nsv103
   Ransdell S, 2001, APPL PSYCHOLINGUIST, V22, P113, DOI 10.1017/S0142716401001060
   Rigoulot S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00367
   Sander D, 2005, NEUROIMAGE, V28, P848, DOI 10.1016/j.neuroimage.2005.06.023
   Sauter DA, 2007, MOTIV EMOTION, V31, P192, DOI 10.1007/s11031-007-9065-x
   Sauter DA, 2013, BRIT J DEV PSYCHOL, V31, P97, DOI 10.1111/j.2044-835X.2012.02081.x
   Sauter DA, 2010, Q J EXP PSYCHOL, V63, P2251, DOI 10.1080/17470211003721642
   Sauter DA, 2010, P NATL ACAD SCI USA, V107, P2408, DOI 10.1073/pnas.0908239106
   Sauter DA, 2010, J COGNITIVE NEUROSCI, V22, P474, DOI 10.1162/jocn.2009.21215
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Schröber M, 2003, SPEECH COMMUN, V40, P99, DOI 10.1016/S0167-6393(02)00078-X
   Scott SK, 1997, NATURE, V385, P254, DOI 10.1038/385254a0
   Scott SK, 2014, TRENDS COGN SCI, V18, P618, DOI 10.1016/j.tics.2014.09.002
   Scott SK, 2010, HBK BEHAV NEUROSCI, V19, P187, DOI 10.1016/B978-0-12-374593-4.00019-X
   Simon-Thomas ER, 2009, EMOTION, V9, P838, DOI 10.1037/a0017810
   Soderstrom M, 2017, COGNITION EMOTION, V31, P298, DOI 10.1080/02699931.2015.1108904
   Sweet TM, 2017, J EDUC BEHAV STAT, V42, P107, DOI 10.3102/1076998616659752
   Tracy JL, 2008, EMOTION, V8, P81, DOI 10.1037/1528-3542.8.1.81
   TZELGOV J, 1997, ADV SOC COG, V10, P217
   Warren JE, 2006, J NEUROSCI, V26, P13067, DOI 10.1523/JNEUROSCI.3907-06.2006
   Winkielman P, 2005, PERS SOC PSYCHOL B, V31, P121, DOI 10.1177/0146167204271309
   Wood S., 2006, GEN ADDITIVE MODELS, Vsecond
NR 66
TC 23
Z9 26
U1 3
U2 27
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 1528-3542
EI 1931-1516
J9 EMOTION
JI Emotion
PD MAR
PY 2019
VL 19
IS 2
BP 219
EP 233
DI 10.1037/emo0000429
PG 15
WC Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA HL7WI
UT WOS:000458951400004
PM 29792444
OA Green Submitted, Green Accepted
DA 2024-01-09
ER

PT J
AU Dalzell, VM
AF Dalzell, Victoria M.
TI The Voice in the Drum: Music, Language, and Emotion in Islamicate South
   Asia.
SO NOTES
LA English
DT Book Review
CR Wolf RK, 2014, VOICE IN THE DRUM: MUSIC, LANGUAGE, AND EMOTION IN ISLAMICATE SOUTH ASIA, P1
NR 1
TC 0
Z9 0
U1 0
U2 0
PU MUSIC LIBRARY ASSOC
PI MIDDLETON
PA C/O A-R EDITIONS, INC, 8551 RESEARCH WAY, STE 180, MIDDLETON, WI 53562
   USA
SN 0027-4380
EI 1534-150X
J9 NOTES
JI Notes
PD DEC
PY 2016
VL 73
IS 2
BP 276
EP 279
DI 10.1353/not.2016.0122
PG 4
WC Music
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music
GA ET4ES
UT WOS:000400232700007
DA 2024-01-09
ER

PT J
AU Hancock, M
AF Hancock, Mary
TI The Voice in the Drum: Music, Language, and Emotion in Islamicate South
   Asia
SO AMERICAN ETHNOLOGIST
LA English
DT Book Review
C1 [Hancock, Mary] Univ Calif Santa Barbara, Santa Barbara, CA 93106 USA.
C3 University of California System; University of California Santa Barbara
RP Hancock, M (corresponding author), Univ Calif Santa Barbara, Santa Barbara, CA 93106 USA.
CR Wolf RK, 2014, VOICE IN THE DRUM: MUSIC, LANGUAGE, AND EMOTION IN ISLAMICATE SOUTH ASIA, P1
NR 1
TC 0
Z9 0
U1 0
U2 1
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0094-0496
EI 1548-1425
J9 AM ETHNOL
JI Am. Ethnol.
PD FEB
PY 2016
VL 43
IS 1
BP 178
EP 179
DI 10.1111/amet.12276
PG 2
WC Anthropology
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Anthropology
GA DE4ZA
UT WOS:000370638200019
DA 2024-01-09
ER

PT J
AU Slawek, S
AF Slawek, Stephen
TI The voice in the drum: music, language, and emotion in Islamicate South
   Asia
SO ETHNOMUSICOLOGY FORUM
LA English
DT Book Review
C1 [Slawek, Stephen] Univ Texas Austin, Butler Sch Mus, Austin, TX 78712 USA.
C3 University of Texas System; University of Texas Austin
RP Slawek, S (corresponding author), Univ Texas Austin, Butler Sch Mus, Austin, TX 78712 USA.
EM slawek@austin.utexas.edu
CR Wolf RK, 2014, VOICE IN THE DRUM: MUSIC, LANGUAGE, AND EMOTION IN ISLAMICATE SOUTH ASIA, P1
NR 1
TC 0
Z9 0
U1 0
U2 0
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1741-1912
EI 1741-1920
J9 ETHNOMUSICOL FORUM
JI Ethnomusicol. Forum
PY 2018
VL 27
IS 2
BP 249
EP 251
DI 10.1080/17411912.2018.1521294
PG 3
WC Music
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music
GA GX3NO
UT WOS:000447631700010
DA 2024-01-09
ER

PT J
AU Provenzano, C
AF Provenzano, Catherine
TI Making Voices <i>The Gendering of Pitch Correction and The
   Auto</i>-<i>Tune Effect in Contemporary Pop Music</i>
SO JOURNAL OF POPULAR MUSIC STUDIES
LA English
DT Article
DE popular music; ethnography; music industry
AB This article is an examination of contemporary practices of pitch correction and what is called the Auto-Tune effect (TATE) on pop music voices. I argue that the split initiated by digital pitch correction softwares, which came to market in 1998, of the labor of precise pitch from the labor of singing more generally leaves in its wake a redoubled emphasis on the supposed truth of emotional delivery. Yet pitch corrected and Auto-Tuned voices are not understood to sound emotion in the same way, and instead rely upon and often reproduce hearings of voices as gendered and raced. I examine the status of pitch correction softwares (PCS) and the sometimes blunt, sometimes subtle ways they intersect with the statuses of marked identity and embodied vocality. These intersections inform ways of knowing emotion, creating epistemic relationships between emotion, body, voice, and work. Drawing on fieldwork conducted between 2014 and 2018 in Los Angeles and New York, I engage the specifics of the gendered labor involved creating pop voices, and the implications of the reality of that labor on the potentials the pop "cyborg" voice.
C1 [Provenzano, Catherine] NYU, Ethnomusicol, New York, NY 10003 USA.
C3 New York University
RP Provenzano, C (corresponding author), NYU, Ethnomusicol, New York, NY 10003 USA.
EM catherine.provenzano@gmail.com
CR [Anonymous], 2010, WRECK NICE BEACH VOC
   [Anonymous], AUDIBLE TRACES GENDE
   Barrett Lindon, 2009, BLACKNESS VALUE SEEI
   Bates Eliot, 2012, J ART RECORD PRODUCT
   Baudrillard J, 1994, Simulacra and Simulation
   Brovig-Hansen Ragnhild, 2017, DIGITAL SIGNATURES I
   Carson Anne, 1992, GLASS IRONY AND GOD
   Cavarero A., 2012, The sound studies reader
   Connor Stephen, 2000, Dumbstruck. A Cultural History of Ventriloquism
   Daughtry Martin, 2012, MUSIC POLITICS VIOLE
   Dickinson Kay, 2001, Popular Music, V20, P333, DOI DOI 10.1017/S0261143001001532
   Eidsheim N., 2009, TRANS, P13
   Eidsheim NS, 2011, AM QUART, V63, P641
   Eidsheim Nina Sun, 2018, RACE SOUND LISTENING
   Fournet Adele, 2018, THESIS
   Goh A, 2017, PARALLAX, V23, P283, DOI 10.1080/13534645.2017.1339968
   Goh Annie, 2014, CTM FESTIVAL PUBLICA
   Haraway Donna., 1991, SIMIANS CYBORGS WOME, P149
   Horning SS, 2004, SOC STUD SCI, V34, P703, DOI 10.1177/0306312704047536
   James R, 2008, J POP MUSIC STUD, V20, P402, DOI 10.1111/j.1533-1598.2008.00171.x
   Kajikawa Loren, 2015, SOUNDING RACE RAP SO
   Lieb Kristin J., 2013, Gender, Branding, and the Modern Music Industry: The Social Construction of Female Popular Music Stars
   McCartney Andra, 2003, ORGAN SOUND, V8, P89, DOI DOI 10.1017/S1355771803001109
   McCartney Andra, 2006, INTERSECTIONS CANADI, V26, P3, DOI [DOI 10.7202/1013223AR, 10.7202/1013223ar]
   McCracken Allison, 2015, Real Men Don't Sing: Crooning in American Culture
   Neal MA, 2006, New Black Man
   Obadike Mendi, 2005, THESIS
   Porco Alex S., 2014, DISABILITY STUDIES Q, V34, DOI DOI 10.18061/DSQ.V34I4.3822
   Rodgers T., 2010, Pink Noises: Women on Electronic Music and Sound
   Rodgers Tara, 2016, ENGAGING WORLD THINK
   Rose T., 2008, The Hip Hop Wars: What We Talk About When We Talk About Hip Hop-And Why It Matters
   Schlichter A, 2011, BODY SOC, V17, P31, DOI 10.1177/1357034X10394669
   Schmidt-Horning S., 2013, CHASING SOUND TECHNO
   Schmidt-Horning S., 2012, ART RECORD PRODUCTIO
   Stoever Jennifer Lynn, 2016, SONIC COLOR LINE RAC
   Stras L, 2007, J SOC AM MUSIC, V1, P207, DOI 10.1017/S1752196307070083
   Stras Laurie, 2015, OXFORD HDB MUSIC DIS
   Thrift Nigel, 2005, Knowing Capitalism
   Warwick Jacqueline, 2007, Girl Groups, Girl Culture: Popular Music and Identity in the 1960s
   Wosk Julie, 2015, MY FAIR LADIES FEMAL
NR 40
TC 3
Z9 5
U1 3
U2 11
PU UNIV CALIFORNIA PRESS
PI OAKLAND
PA 155 GRAND AVE, SUITE 400, OAKLAND, CA 94612-3758 USA
SN 1524-2226
EI 1533-1598
J9 J POP MUSIC STUD
JI J. Pop. Music Stud.
PD JUN
PY 2019
VL 31
IS 2
BP 63
EP 83
DI 10.1525/jpms.2019.312008
PG 21
WC Music
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music
GA IT5FQ
UT WOS:000482888300008
DA 2024-01-09
ER

PT J
AU Chen, XH
   Yang, JF
   Gan, SZ
   Yang, YF
AF Chen, Xuhai
   Yang, Jianfeng
   Gan, Shuzhen
   Yang, Yufang
TI The Contribution of Sound Intensity in Vocal Emotion Perception:
   Behavioral and Electrophysiological Evidence
SO PLOS ONE
LA English
DT Article
ID THETA BAND POWER; FACIAL EXPRESSIONS; EEG; PROSODY; SYNCHRONIZATION;
   COMMUNICATION; APPRAISAL; PLEASANT; IMPACT; MUSIC
AB Although its role is frequently stressed in acoustic profile for vocal emotion, sound intensity is frequently regarded as a control parameter in neurocognitive studies of vocal emotion, leaving its role and neural underpinnings unclear. To investigate these issues, we asked participants to rate the angry level of neutral and angry prosodies before and after sound intensity modification in Experiment 1, and recorded electroencephalogram (EEG) for mismatching emotional prosodies with and without sound intensity modification and for matching emotional prosodies while participants performed emotional feature or sound intensity congruity judgment in Experiment 2. It was found that sound intensity modification had significant effect on the rating of angry level for angry prosodies, but not for neutral ones. Moreover, mismatching emotional prosodies, relative to matching ones, induced enhanced N2/P3 complex and theta band synchronization irrespective of sound intensity modification and task demands. However, mismatching emotional prosodies with reduced sound intensity showed prolonged peak latency and decreased amplitude in N2/P3 complex and smaller theta band synchronization. These findings suggest that though it cannot categorically affect emotionality conveyed in emotional prosodies, sound intensity contributes to emotional significance quantitatively, implying that sound intensity should not simply be taken as a control parameter and its unique role needs to be specified in vocal emotion studies.
C1 [Chen, Xuhai; Yang, Jianfeng; Gan, Shuzhen; Yang, Yufang] Chinese Acad Sci, Inst Psychol, State Key Lab Brain & Cognit Sci, Beijing 100101, Peoples R China.
   [Chen, Xuhai; Gan, Shuzhen] Chinese Acad Sci, Grad Univ, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Psychology, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Chen, XH (corresponding author), Chinese Acad Sci, Inst Psychol, State Key Lab Brain & Cognit Sci, Beijing 100101, Peoples R China.
EM yangyf@psych.ac.cn
RI Yang, Jianfeng/ABH-1554-2020; Yang, Yu-Fang/ABE-6811-2021
OI Yang, Jianfeng/0000-0002-0140-3675; Yang, Yu-Fang/0000-0001-9089-6020
FU National Natural Science Foundation of China [31070989]
FX This research was supported by the National Natural Science Foundation
   of China (31070989). The funders had no role in study design, data
   collection and analysis, decision to publish, or preparation of the
   manuscript.
CR Aftanas LI, 2003, INT J PSYCHOPHYSIOL, V50, P205, DOI 10.1016/S0167-8760(03)00156-9
   Aftanas LI, 2001, NEUROSCI LETT, V303, P115, DOI 10.1016/S0304-3940(01)01703-7
   [Anonymous], HDB COMMUNICATION MO
   [Anonymous], 2005, EVENT RELATED POTENT
   Audibert N, 2005, LECT NOTES COMPUT SC, V3784, P527
   Bach DR, 2008, CEREB CORTEX, V18, P145, DOI 10.1093/cercor/bhm040
   Bach DR, 2009, INT J PSYCHOPHYSIOL, V74, P28, DOI 10.1016/j.ijpsycho.2009.06.004
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P14
   Banziger T, 2005, SPEECH COMMUN, V46, P52
   Belin P, 1998, J NEUROSCI, V18, P6388
   Breitenstein C, 2001, COGNITION EMOTION, V15, P57, DOI 10.1080/0269993004200114
   Bulut M, 2008, J ACOUST SOC AM, V123, P4547, DOI 10.1121/1.2909562
   Campanella S, 2002, BIOL PSYCHOL, V59, P171, DOI 10.1016/S0301-0511(02)00005-4
   Cavanagh JF, 2010, NEUROIMAGE, V49, P3198, DOI 10.1016/j.neuroimage.2009.11.080
   Chen XH, 2011, BIOL PSYCHOL, V86, P158, DOI 10.1016/j.biopsycho.2010.11.004
   Cohen MX, 2007, NEUROIMAGE, V35, P968, DOI 10.1016/j.neuroimage.2006.11.056
   Cowie R, 2003, SPEECH COMMUN, V40, P5, DOI 10.1016/S0167-6393(02)00071-7
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Ethofer T, 2009, CURR BIOL, V19, P1028, DOI 10.1016/j.cub.2009.04.054
   Fuentemilla L, 2008, BRAIN RES, V1220, P93, DOI 10.1016/j.brainres.2007.07.079
   Gobl C, 2003, SPEECH COMMUN, V40, P189, DOI 10.1016/S0167-6393(02)00082-1
   Goydke KN, 2004, COGNITIVE BRAIN RES, V21, P351, DOI 10.1016/j.cogbrainres.2004.06.009
   Grandjean D, 2005, NAT NEUROSCI, V8, P145, DOI 10.1038/nn1392
   Hsiao FJ, 2009, BIOL PSYCHOL, V81, P58, DOI 10.1016/j.biopsycho.2009.01.007
   Juslin PN, 2001, EMOTION, V1, P381, DOI 10.1037//1528-3542.1.4.381
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Klimesch W, 1996, NEUROREPORT, V7, P1235, DOI 10.1097/00001756-199605170-00002
   Knyazev GG, 2009, NEUROSCIENCE, V164, P1588, DOI 10.1016/j.neuroscience.2009.09.057
   Knyazev GG, 2010, EMOTION, V10, P678, DOI 10.1037/a0019175
   Kok A, 2001, PSYCHOPHYSIOLOGY, V38, P557, DOI 10.1017/S0048577201990559
   Kotz SA, 2007, BRAIN RES, V1151, P107, DOI 10.1016/j.brainres.2007.03.015
   Lakshminarayanan K, 2003, BRAIN LANG, V84, P250, DOI 10.1016/S0093-934X(02)00516-3
   Laukka P, 2005, COGNITION EMOTION, V19, P633, DOI 10.1080/02699930441000445
   Nieuwenhuis S, 2005, PSYCHOL BULL, V131, P510, DOI 10.1037/0033-2909.131.4.510
   Patel A. D., 2008, Music, Language, and the Brain
   Patel S, 2011, BIOL PSYCHOL, V87, P93, DOI 10.1016/j.biopsycho.2011.02.010
   Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8
   Pittam J., 1993, HDB EMOTIONS
   ROSS ED, 1986, J PHONETICS, V14, P283, DOI 10.1016/S0095-4470(19)30669-2
   Sammler D, 2007, PSYCHOPHYSIOLOGY, V44, P293, DOI 10.1111/j.1469-8986.2007.00497.x
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Schirmer A, 2007, BRAIN RES, V1176, P103, DOI 10.1016/j.brainres.2007.08.008
   SMITH CA, 1985, J PERS SOC PSYCHOL, V48, P813, DOI 10.1037/0022-3514.48.4.813
   Steinhauer K, 1999, NAT NEUROSCI, V2, P191, DOI 10.1038/5757
   Tajadura-Jiménez A, 2010, EMOTION, V10, P216, DOI 10.1037/a0018422
   Tao JH, 2005, LECT NOTES COMPUT SC, V3784, P449
   Tzur G, 2007, NEUROPSYCHOLOGIA, V45, P3122, DOI 10.1016/j.neuropsychologia.2007.05.004
   Tzur G, 2009, BEHAV BRAIN RES, V198, P420, DOI 10.1016/j.bbr.2008.11.041
   Yordanova J, 1998, PSYCHOPHYSIOLOGY, V35, P116, DOI 10.1111/1469-8986.3510116
   Yuan JJ, 2010, NEUROSCIENCE, V169, P1758, DOI 10.1016/j.neuroscience.2010.06.024
NR 50
TC 11
Z9 15
U1 1
U2 26
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD JAN 23
PY 2012
VL 7
IS 1
AR e30278
DI 10.1371/journal.pone.0030278
PG 11
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Science & Technology - Other Topics
GA 909NE
UT WOS:000301570600029
PM 22291928
OA Green Published, gold, Green Submitted
DA 2024-01-09
ER

PT J
AU Piazza, EA
   Iordan, MC
   Lew-Williams, C
AF Piazza, Elise A.
   Iordan, Marius Catalin
   Lew-Williams, Casey
TI Mothers Consistently Alter Their Unique Vocal Fingerprints When
   Communicating with Infants
SO CURRENT BIOLOGY
LA Welsh
DT Article
ID DIRECTED SPEECH; VOICE QUALITY; LANGUAGE; EMOTION; PROSODY; RECOGNITION;
   EXPRESSION; FEATURES; TEMPO; PITCH
AB The voice is the most direct link we have to others' minds, allowing us to communicate using a rich variety of speech cues [1, 2]. This link is particularly critical early in life as parents draw infants into the structure of their environment using infant-directed speech (IDS), a communicative code with unique pitch and rhythmic characteristics relative to adult-directed speech (ADS) [3, 4]. To begin breaking into language, infants must discern subtle statistical differences about people and voices in order to direct their attention toward the most relevant signals. Here, we uncover a new defining feature of IDS: mothers significantly alter statistical properties of vocal timbre when speaking to their infants. Timbre, the tone color or unique quality of a sound, is a spectral fingerprint that helps us instantly identify and classify sound sources, such as individual people and musical instruments [5-7]. We recorded 24 mothers' naturalistic speech while they interacted with their infants and with adult experimenters in their native language. Half of the participants were English speakers, and half were not. Using a support vector machine classifier, we found that mothers consistently shifted their timbre between ADS and IDS. Importantly, this shift was similar across languages, suggesting that such alterations of timbre may be universal. These findings have theoretical implications for understanding how infants tune in to their local communicative environments. Moreover, our classification algorithm for identifying infant-directed timbre has direct translational implications for speech recognition technology.
C1 [Piazza, Elise A.; Iordan, Marius Catalin] Princeton Univ, Princeton Neurosci Inst, Princeton, NJ 08544 USA.
   [Piazza, Elise A.; Iordan, Marius Catalin; Lew-Williams, Casey] Princeton Univ, Dept Psychol, Princeton, NJ 08544 USA.
C3 Princeton University; Princeton University
RP Piazza, EA (corresponding author), Princeton Univ, Princeton Neurosci Inst, Princeton, NJ 08544 USA.; Piazza, EA (corresponding author), Princeton Univ, Dept Psychol, Princeton, NJ 08544 USA.
EM elise.piazza@gmail.com
FU Princeton Neuroscience Institute; National Institute of Child Health and
   Human Development [HD079779]
FX This research was supported by a C.V. Starr Postdoctoral Fellowship from
   the Princeton Neuroscience Institute awarded to E.A.P. and a grant from
   the National Institute of Child Health and Human Development awarded to
   C.L.-W. (HD079779). The authors thank Julia Schorn and Eva Fourakis for
   assistance with data collection.
CR [Anonymous], 1999, Language in Time: The Rhythm and Tempo of Spoken Interaction
   BELL A, 1984, LANG SOC, V13, P145, DOI 10.1017/S004740450001037X
   Bergeson TR, 2007, INFANT BEHAV DEV, V30, P648, DOI 10.1016/j.infbeh.2007.03.003
   Bergeson TR, 2002, PSYCHOL SCI, V13, P72, DOI 10.1111/1467-9280.00413
   Binder JR, 2000, CEREB CORTEX, V10, P512, DOI 10.1093/cercor/10.5.512
   BLUBAUGH JA, 1969, SPEECH MONOGR, V36, P131, DOI 10.1080/03637756909375619
   Boersma P., 2014, PRAAT DOING PHONETIC
   Bosseler A, 2003, J AUTISM DEV DISORD, V33, P653, DOI 10.1023/B:JADD.0000006002.82367.4f
   Bregman AS, 1994, Auditory scene analysis: the perceptual organization of sound, DOI DOI 10.1121/1.408434
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   COOPER RP, 1990, CHILD DEV, V61, P1584, DOI 10.2307/1130766
   Coutinho E, 2013, COGNITION EMOTION, V27, P658, DOI 10.1080/02699931.2012.732559
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   DEBOSE CE, 1992, J MULTILING MULTICUL, V13, P157, DOI 10.1080/01434632.1992.9994489
   DECASPER AJ, 1980, SCIENCE, V208, P1174, DOI 10.1126/science.7375928
   Dieleman S., 2013, PROC 26 INT C NEURAL, P2643, DOI DOI 10.1109/MMUL.2011.34.VAN
   Eaves BS Jr, 2016, PSYCHOL REV, V123, P758, DOI 10.1037/rev0000031
   Elliott TM, 2013, J ACOUST SOC AM, V133, P389, DOI 10.1121/1.4770244
   Estes KG, 2013, INFANCY, V18, P797, DOI 10.1111/infa.12006
   FERNALD A, 1984, DEV PSYCHOL, V20, P104, DOI 10.1037/0012-1649.20.1.104
   Fernald A., 1992, The Adapted Mind: Evolutionary Psychology and the Generation of Culture, P391, DOI DOI 10.1007/BF00852474
   Ford M., 2009, LENA LANGUAGE ENV AN
   Gobl C, 2003, SPEECH COMMUN, V40, P189, DOI 10.1016/S0167-6393(02)00082-1
   GRIESER DL, 1988, DEV PSYCHOL, V24, P14, DOI 10.1037/0012-1649.24.1.14
   HOWELL P, 1991, SPEECH COMMUN, V10, P163, DOI 10.1016/0167-6393(91)90039-V
   Jürgens R, 2015, J NONVERBAL BEHAV, V39, P195, DOI 10.1007/s10919-015-0209-5
   KAPLAN PS, 1995, INFANT BEHAV DEV, V18, P209, DOI 10.1016/0163-6383(95)90050-0
   Kaplan PS, 1999, CHILD DEV, V70, P560, DOI 10.1111/1467-8624.00041
   Koch Lisa M., 2001, Journal of Black psychology, V27, P29, DOI [10.1177/0095798401027001002, DOI 10.1177/0095798401027001002]
   Koreman J., 1999, P ICPHS, V99, P719
   KREIMAN J, 1992, J SPEECH HEAR RES, V35, P512, DOI 10.1044/jshr.3503.512
   Krumhansl CL, 2010, MUSIC PERCEPT, V27, P337, DOI 10.1525/mp.2010.27.5.337
   Kuhl PK, 1997, SCIENCE, V277, P684, DOI 10.1126/science.277.5326.684
   Lam TQ, 2010, MEM COGNITION, V38, P1137, DOI 10.3758/MC.38.8.1137
   Massaro D.W., 2008, P ICMI, V10, P197
   McAdams S, 2009, The Oxford handbook of music psychology, P72
   McKinney M., 2003, P ISMIR, P151
   NELSON DGK, 1989, J CHILD LANG, V16, P55, DOI 10.1017/S030500090001343X
   OHALA JJ, 1983, PHONETICA, V40, P1, DOI 10.1159/000261678
   Patil K, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002759
   POLLACK I, 1954, J ACOUST SOC AM, V26, P403, DOI 10.1121/1.1907349
   Reynolds DA, 1994, IEEE T SPEECH AUDI P, V2, P639, DOI 10.1109/89.326623
   Rosa EC, 2015, LANG COGN NEUROSCI, V30, P48, DOI 10.1080/01690965.2013.772213
   SAUNDERS FA, 1983, INT J NEUROSCI, V19, P21, DOI 10.3109/00207458309148642
   Terasawa H, 2005, PERCEPTUAL DISTANCE
   Thiessen ED, 2005, INFANCY, V7, P53, DOI 10.1207/s15327078in0701_5
   Tiwari V., 2010, International journal on emerging technologies, V1, P19
   Trainor LJ, 2000, PSYCHOL SCI, V11, P188, DOI 10.1111/1467-9280.00240
   Trainor LJ, 2004, DEVELOPMENTAL SCI, V7, P289, DOI 10.1111/j.1467-7687.2004.00348.x
   Trainor LJ, 1997, INFANT BEHAV DEV, V20, P383, DOI 10.1016/S0163-6383(97)90009-6
   TREHUB SE, 1990, J EXP CHILD PSYCHOL, V49, P300, DOI 10.1016/0022-0965(90)90060-L
   Wessel D. L., 1979, Computer Music Journal, V3, P45, DOI 10.2307/3680283
   Xu D., 2009, RELIABILITY LENA TM
   Young S, 2006, The HTK Book
NR 54
TC 36
Z9 40
U1 0
U2 8
PU CELL PRESS
PI CAMBRIDGE
PA 50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA
SN 0960-9822
EI 1879-0445
J9 CURR BIOL
JI Curr. Biol.
PD OCT 23
PY 2017
VL 27
IS 20
BP 3162
EP +
DI 10.1016/j.cub.2017.08.074
PG 9
WC Biochemistry & Molecular Biology; Biology; Cell Biology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Biochemistry & Molecular Biology; Life Sciences & Biomedicine - Other
   Topics; Cell Biology
GA FK4EG
UT WOS:000413441700028
PM 29033333
OA Green Accepted, hybrid
DA 2024-01-09
ER

PT J
AU Curtis, ME
   Bharucha, JJ
AF Curtis, Meagan E.
   Bharucha, Jamshed J.
TI The Minor Third Communicates Sadness in Speech, Mirroring Its Use in
   Music
SO EMOTION
LA English
DT Article
DE emotions; communication; prosody; music and emotion; musical intervals
ID CATEGORICAL PERCEPTION; VOCAL EXPRESSION; CONSONANCE; EMOTIONS;
   PERFORMANCE; RESPONSES; INTERVALS; ABSOLUTE; MELODY; PITCH
AB There is a long history of attempts to explain why music is perceived as expressing emotion. The relationship between pitches serves as an important cue for conveying emotion in music. The musical interval referred to as the minor third is generally thought to convey sadness. We reveal that the minor third also occurs in the pitch contour of speech conveying sadness. Bisyllabic speech samples conveying four emotions were recorded by 9 actresses. Acoustic analyses revealed that the relationship between the 2 salient pitches of the sad speech samples tended to approximate a minor third. Participants rated the speech samples for perceived emotion, and the use of numerous acoustic parameters as cues for emotional identification was modeled using regression analysis. The minor third was the most reliable cue for identifying sadness. Additional participants rated musical intervals for emotion, and their ratings verified the historical association between the musical minor third and sadness. These findings support the theory that human vocal expressions and music share an acoustic code for communicating sadness.
C1 [Curtis, Meagan E.; Bharucha, Jamshed J.] Tufts Univ, Dept Psychol, Medford, MA 02155 USA.
C3 Tufts University
RP Curtis, ME (corresponding author), Tufts Univ, Dept Psychol, 490 Boston Ave, Medford, MA 02155 USA.
EM meagan.curtis@tufts.edu
CR [Anonymous], SOUND SENTIMENT
   Boersma P., 2021, Glot International
   Boersma P, 1993, P I PHONETIC SCI, V17, P97, DOI DOI 10.1371/JOURNAL.PONE.0069107
   Bregman A.S., 1990, AUDITORY SCENE ANAL, DOI DOI 10.7551/MITPRESS/1486.001.0001
   Brown S, 2000, ORIGINS OF MUSIC, P271
   BURNS EM, 1978, J ACOUST SOC AM, V63, P456, DOI 10.1121/1.381737
   BURNS EM, 1994, J ACOUST SOC AM, V96, P2704, DOI 10.1121/1.411447
   Cooke, 1959, LANGUAGE MUSIC
   Cross I., 2008, PREHISTORY LANGUAGE, P113, DOI DOI 10.1093/ACPROF:OSO/9780199545872.003.0005
   CROWDER RG, 1985, B PSYCHONOMIC SOC, V23, P314
   DALESSANDRO C, 1994, J ACOUST SOC AM, V95, P1617, DOI 10.1121/1.408548
   EKMAN P, 1983, SCIENCE, V221, P1208, DOI 10.1126/science.6612338
   FONAGY I, 1978, LANG SPEECH, V21, P34, DOI 10.1177/002383097802100102
   GERARDI GM, 1995, MUSIC PERCEPT, V12, P279
   Hevner K, 1935, PSYCHOL REV, V42, P186, DOI 10.1037/h0054832
   Hevner K, 1936, AM J PSYCHOL, V48, P246, DOI 10.2307/1415746
   Hevner K, 1935, AM J PSYCHOL, V47, P103, DOI 10.2307/1416710
   Hevner K, 1937, AM J PSYCHOL, V49, P621, DOI 10.2307/1416385
   House David., 1990, Tonal Perception in Speech
   Johnstone T., 2000, Handbook of Emotions, V2nd ed., P220
   Jowett B., 1885, POLITICS ARISTOTLE
   Juslin PN, 2001, EMOTION, V1, P381, DOI 10.1037//1528-3542.1.4.381
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 1997, MUSIC PERCEPT, V14, P383
   Juslin PN., 2001, Music and Emotion, P309, DOI 10.1093/oso/9780192631886.003.0014
   Krumhansl CL, 1997, CAN J EXP PSYCHOL, V51, P336, DOI 10.1037/1196-1961.51.4.336
   Maher T. F., 1982, PSYCHOL MUSIC, V10, P11, DOI DOI 10.1177/0305735682101002
   Mertens P., 2004, Proceedings of Speech Prosody 2004
   Nielzen S., 1982, Psychology of Music, V10, P7, DOI [DOI 10.1177/0305735682102002, 10.1177/0305735682102002]
   PAPOUAEK Mechthild, 1996, Musical Beginnings. Origins and Development of Musical Competence, P88
   Patel AD, 2006, J ACOUST SOC AM, V119, P3034, DOI 10.1121/1.2179657
   Patel AD, 2005, ANN NY ACAD SCI, V1060, P59, DOI 10.1196/annals.1360.005
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   PLOMP R, 1965, J ACOUST SOC AM, V38, P548, DOI 10.1121/1.1909741
   Scherer K., 1977, MOTIV EMOTION, V1, P331, DOI [DOI 10.1007/BF00992539, 10.1007/bf00992539]
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Sherer K. R., 1989, Handbook of social psychophysiology, P165
   SIEGEL JA, 1977, PERCEPT PSYCHOPHYS, V21, P399, DOI 10.3758/BF03199493
   SIEGEL JA, 1977, PERCEPT PSYCHOPHYS, V21, P143, DOI 10.3758/BF03198717
   Trainor LJ, 1998, INFANT BEHAV DEV, V21, P77, DOI 10.1016/S0163-6383(98)90055-8
   Trainor LJ, 2002, MUSIC PERCEPT, V20, P187, DOI 10.1525/mp.2002.20.2.187
   WEDIN L, 1972, SCAND J PSYCHOL, V13, P241, DOI 10.1111/j.1467-9450.1972.tb00072.x
   WILLIAMS CE, 1972, J ACOUST SOC AM, V52, P1238, DOI 10.1121/1.1913238
   Zentner MR, 1998, INFANT BEHAV DEV, V21, P483, DOI 10.1016/S0163-6383(98)90021-2
   Zentner MR, 1996, NATURE, V383, P29, DOI 10.1038/383029a0
NR 45
TC 57
Z9 71
U1 5
U2 24
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 1528-3542
EI 1931-1516
J9 EMOTION
JI Emotion
PD JUN
PY 2010
VL 10
IS 3
BP 335
EP 348
DI 10.1037/a0017928
PG 14
WC Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Psychology
GA 605WI
UT WOS:000278378200004
PM 20515223
DA 2024-01-09
ER

PT J
AU Eerola, T
   Friberg, A
   Bresin, R
AF Eerola, Tuomas
   Friberg, Anders
   Bresin, Roberto
TI Emotional expression in music: contribution, linearity, and additivity
   of primary musical cues
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE emotion; music cues; factorial design; discrete emotion ratings
ID VOCAL EXPRESSION; VOICE QUALITY; COMMUNICATION; PERFORMANCE; RESPONSES;
   SPEECH; PERSPECTIVE; DIMENSIONS; DESIGN; RANGE
AB The aim of this study is to manipulate musical cues systematically to determine the aspects of music that contribute to emotional expression, and whether these cues operate in additive or interactive fashion, and whether the cue levels can be characterized as linear or non-linear. An optimized factorial design was used with six primary musical cues (mode, tempo, dynamics, articulation, timbre, and register) across four different music examples. Listeners rated 200 musical examples according to four perceived emotional characters (happy, sad, peaceful, and scary). The results exhibited robust effects for all cues and the ranked importance of these was established by multiple regression. The most important cue was mode followed by tempo, register, dynamics, articulation, and timbre, although the ranking varied across the emotions. The second main result suggested that most cue levels contributed to the emotions in a linear fashion, explaining 77-89% of variance in ratings. Quadratic encoding of cues did lead to minor but significant increases of the models (0-8%). Finally, the interactions between the cues were non-existent suggesting that the cues operate mostly in an additive fashion, corroborating recent findings on emotional expression in music (Juslin and Lindstrom, 2010).
C1 [Eerola, Tuomas] Univ Jyvaskyla, Dept Mus, FI-40014 Jyvaskyla, Finland.
   [Friberg, Anders; Bresin, Roberto] KTH Royal Inst Technol, Dept Speech Mus & Hearing, Stockholm, Sweden.
C3 University of Jyvaskyla; Royal Institute of Technology
RP Eerola, T (corresponding author), Univ Jyvaskyla, Dept Mus, Seminaarinkatu 35, FI-40014 Jyvaskyla, Finland.
EM tuomas.eerola@jyu.fi
RI Bresin, Roberto/J-4240-2012; Friberg, Anders K/A-2490-2012; Eerola,
   Tuomas/K-7596-2019; Bresin, Roberto/I-3458-2019; Eerola,
   Tuomas/I-6190-2013
OI Bresin, Roberto/0000-0002-3086-0322; Eerola, Tuomas/0000-0002-2896-929X;
   Bresin, Roberto/0000-0002-3086-0322; Eerola, Tuomas/0000-0002-2896-929X
CR Adachi M., 1998, PSYCHOL MUSIC, V26, P133, DOI [DOI 10.1177/0305735698262003, 10.1177/0305735698262003]
   [Anonymous], PERCEPTION AND THE R
   Bachorowski JA, 2001, J ACOUST SOC AM, V110, P1581, DOI 10.1121/1.1391244
   Bowling DL, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0031942
   Box G.E., 1987, Empirical model-building and response surfaces
   Bresin R, 2000, COMPUT MUSIC J, V24, P44, DOI 10.1162/014892600559515
   Bresin R., 2001, P INT COMP MUS C ICM, P294
   Bresin R, 2011, CORTEX, V47, P1068, DOI 10.1016/j.cortex.2011.05.009
   Collins LM, 2009, PSYCHOL METHODS, V14, P202, DOI 10.1037/a0015826
   Crowder R. G., 1985, PSYCHOMUSICOLOGY, V5, P3, DOI [DOI 10.1037/H0094203, 10.1037/h0094203]
   Curtis ME, 2010, EMOTION, V10, P335, DOI 10.1037/a0017928
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Eerola T, 2013, MUSIC PERCEPT, V30, P307, DOI [10.1525/mp.2012.30.3.307, 10.1525/MP.2012.30.1.49]
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   Fletcher N. H., 1998, THE PHYSICS OF MUSIC
   Friberg A, 2000, COMPUT MUSIC J, V24, P23, DOI 10.1162/014892600559407
   Friberg A, 1998, J NEW MUSIC RES, V27, P271, DOI 10.1080/09298219808570749
   Friberg A., 2006, ADV COGN PSYCHOL, V2, P145, DOI [DOI 10.2478/V10053-008-0052-X, 10.2478/v10053-008-0052-x]
   Gabrielsson A., 2010, HDB MUSIC EMOTION TH, P367, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0014
   GERARDI GM, 1995, MUSIC PERCEPT, V12, P279
   Gundlach RH, 1935, AM J PSYCHOL, V47, P624, DOI 10.2307/1416007
   Harrigan J. A., 2005, NEW HDB METHODS NONV, P65, DOI DOI 10.1093/ACPROF:OSO/9780198529620.003.0003
   Hevner K, 1936, AM J PSYCHOL, V48, P246, DOI 10.2307/1415746
   Hevner K, 1935, AM J PSYCHOL, V47, P103, DOI 10.2307/1416710
   Hevner K, 1937, AM J PSYCHOL, V49, P621, DOI 10.2307/1416385
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Juslin, 1997, PSYCHOMUSICOLOGY, V16, P77, DOI DOI 10.1037/H0094065
   Juslin P. N., 2003, PAPER PRESENTED AT T
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2001, MUSIC SCI, V5, P63, DOI 10.1177/10298649020050S104
   Juslin PN, 2010, MUSIC ANAL, V29, P334, DOI 10.1111/j.1468-2249.2011.00323.x
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Juslin PN, 1999, MUSIC PERCEPT, V17, P197
   Juslin PN, 1997, MUSIC PERCEPT, V14, P383
   Juslin PN, 1997, MUSIC SCI, V1, P225, DOI DOI 10.1177/102986499700100205
   LADD DR, 1985, J ACOUST SOC AM, V78, P435, DOI 10.1121/1.392466
   Lindström E, 2006, MUSIC SCI, V10, P85, DOI 10.1177/102986490601000105
   Lindström E, 2003, J NEW MUSIC RES, V32, P269, DOI 10.1076/jnmr.32.3.269.16865
   Lindstrom E, 2001, MUSIC EMOTION THEORY, P235
   Mauss I, 2009, COGNITION EMOTION, V23, P209, DOI 10.1080/02699930802204677
   McClelland GH, 1997, PSYCHOL METHODS, V2, P3, DOI 10.1037/1082-989X.2.1.3
   MEYER RK, 1995, TECHNOMETRICS, V37, P60, DOI 10.2307/1269153
   MURRAY IR, 1993, J ACOUST SOC AM, V93, P1097, DOI 10.1121/1.405558
   Myers J. L., 2003, RESEARCH DESIGN AND
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   Rigg M, 1937, J EXP PSYCHOL, V21, P223, DOI 10.1037/h0056146
   Rigg M. G., 1940, J MUSICOLOGY, V2, P49
   Rigg MG, 1940, J EXP PSYCHOL, V27, P566, DOI 10.1037/h0058652
   RIGG MG, 1964, J PSYCHOL, V58, P427, DOI 10.1080/00223980.1964.9916765
   Rosenthal R., 2008, ESSENTIALS OF BEHAVI
   Schellenberg EG, 2000, MUSIC PERCEPT, V18, P155
   Scherer K., 1977, MOTIV EMOTION, V1, P331, DOI [DOI 10.1007/BF00992539, 10.1007/bf00992539]
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   SCHERER KR, 1978, EUR J SOC PSYCHOL, V8, P467, DOI 10.1002/ejsp.2420080405
   SPENCER H, 1857, FRASERS MAGAZINE, V56, P396, DOI DOI 10.1017/S0140525X08005293
   Stewart T.R., 2001, ESSENTIAL BRUNSWIK B, P357
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   Webster GD, 2005, MOTIV EMOTION, V29, P19, DOI 10.1007/s11031-005-4414-0
   WEDIN L, 1972, SCAND J PSYCHOL, V13, P241, DOI 10.1111/j.1467-9450.1972.tb00072.x
   Wilks SS, 1963, SANKHYA A, P407
   Zentner M., 2010, Handbook of music and emotion: theory, research, and applications, P367, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0008
NR 65
TC 78
Z9 82
U1 0
U2 25
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD JUL 30
PY 2013
VL 4
AR 487
DI 10.3389/fpsyg.2013.00487
PG 12
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA AA5UT
UT WOS:000331165800001
PM 23908642
OA gold, Green Accepted, Green Published
DA 2024-01-09
ER

PT J
AU Zhang, J
   Xu, ZM
   Zhou, YY
   Wang, PP
   Fu, P
   Xu, XJ
   Zhang, DQ
AF Zhang, Jin
   Xu, Ziming
   Zhou, Yueying
   Wang, Pengpai
   Fu, Ping
   Xu, Xijia
   Zhang, Daoqiang
TI An Empirical Comparative Study on the Two Methods of Eliciting Singers'
   Emotions in Singing: Self-Imagination and VR Training
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE vocal music teaching; singing emotion; self-imagination; virtual
   reality; electroencephalogram; emotion classification
ID CORTEX; CLASSIFICATION; NETWORKS; ACTIVATION; FRAMEWORK; CINGULATE;
   REGIONS
AB Emotional singing can affect vocal performance and the audience's engagement. Chinese universities use traditional training techniques for teaching theoretical and applied knowledge. Self-imagination is the predominant training method for emotional singing. Recently, virtual reality (VR) technologies have been applied in several fields for training purposes. In this empirical comparative study, a VR training task was implemented to elicit emotions from singers and further assist them with improving their emotional singing performance. The VR training method was compared against the traditional self-imagination method. By conducting a two-stage experiment, the two methods were compared in terms of emotions' elicitation and emotional singing performance. In the first stage, electroencephalographic (EEG) data were collected from the subjects. In the second stage, self-rating reports and third-party teachers' evaluations were collected. The EEG data were analyzed by adopting the max-relevance and min-redundancy algorithm for feature selection and the support vector machine (SVM) for emotion recognition. Based on the results of EEG emotion classification and subjective scale, VR can better elicit the positive, neutral, and negative emotional states from the singers than not using this technology (i.e., self-imagination). Furthermore, due to the improvement of emotional activation, VR brings the improvement of singing performance. The VR hence appears to be an effective approach that may improve and complement the available vocal music teaching methods.
C1 [Zhang, Jin] Nanjing Univ Aeronaut & Astronaut, Coll Arts, Nanjing, Peoples R China.
   [Xu, Ziming; Zhou, Yueying; Wang, Pengpai; Zhang, Daoqiang] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, MIIT Key Lab Pattern Anal & Machine Intelligence, Nanjing, Peoples R China.
   [Fu, Ping] Cent Washington Univ, Dept Lib Serv, Ellensburg, WA USA.
   [Xu, Xijia] Nanjing Med Univ, Affiliated Nanjing Brain Hosp, Dept Psychiat, Nanjing, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Nanjing University of
   Aeronautics & Astronautics; Central Washington University; Nanjing
   Medical University
RP Zhang, DQ (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, MIIT Key Lab Pattern Anal & Machine Intelligence, Nanjing, Peoples R China.
EM dqzhang@nuaa.edu.cn
RI Fu, Ping/A-2692-2014
OI Fu, Ping/0000-0002-5386-748X; Zhou, Yueying/0000-0003-0971-9428
FU National Key Research and Development Program of China [2018YFC2001600,
   2018YFC2001602]; National Natural Science Foundation of China [61876082,
   61861130366]; Fundamental Research Funds for the Central Universities
FX This work was supported by the National Key Research and Development
   Program of China (Nos. 2018YFC2001600 and 2018YFC2001602), the National
   Natural Science Foundation of China (Nos. 61876082 and 61861130366), and
   the Fundamental Research Funds for the Central Universities (No.
   ND2021009).
CR Alarcao SM, 2019, IEEE T AFFECT COMPUT, V10, P374, DOI 10.1109/TAFFC.2017.2714671
   Alvarez RP, 2011, NEUROIMAGE, V55, P389, DOI 10.1016/j.neuroimage.2010.11.057
   [Anonymous], 2018, 2018 26 INT C SYSTEM, DOI DOI 10.1109/ICSENG.2018.8638206
   Bashivan P, 2015, IEEE SIG PROC MED, DOI 10.1109/SPMB.2015.7405422
   Basti A, 2018, NEUROIMAGE, V175, P161, DOI 10.1016/j.neuroimage.2018.03.004
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Calabrò RS, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0268-4
   Chiu PH, 2008, NEUROIMAGE, V42, P988, DOI 10.1016/j.neuroimage.2008.04.248
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021
   Dimitrakopoulos GN, 2017, IEEE T NEUR SYS REH, V25, P1940, DOI 10.1109/TNSRE.2017.2701002
   Esslen M, 2004, NEUROIMAGE, V21, P1189, DOI 10.1016/j.neuroimage.2003.10.001
   Gao Y.J., 2013, J HEBEI NORM U, V15, P95
   Garcia L, 2012, VIRTUAL REALITY IN PSYCHOLOGICAL, MEDICAL AND PEDAGOGICAL APPLICATIONS, P123, DOI 10.5772/46412
   Güntekin B, 2007, INT J PSYCHOPHYSIOL, V64, P91, DOI 10.1016/j.ijpsycho.2006.07.003
   Hajcak G, 2010, DEV NEUROPSYCHOL, V35, P129, DOI 10.1080/87565640903526504
   Halim Z, 2020, INFORM FUSION, V53, P66, DOI 10.1016/j.inffus.2019.06.006
   Hassan M, 2018, IEEE SIGNAL PROC MAG, V35, P81, DOI 10.1109/MSP.2017.2777518
   Hooker CI, 2006, The Orbitofrontal Cortex, P307, DOI [DOI 10.1093/ACPROF:OSO/9780198565741.003.0012, 10.1093/acprof:oso/9780198565741.003.0012]
   Howett D, 2019, BRAIN, V142, P1751, DOI 10.1093/brain/awz116
   Huang HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI [10.1145/3290605.3300851, 10.1109/TAFFC.2019.2901456]
   Huang X.Y., 2017, MODERN COMMUN, V39, P85, DOI [10.3969/j.issn.1007-8770.2017.01.015, DOI 10.3969/J.ISSN.1007-8770.2017.01.015]
   Jacobs J, 2010, P NATL ACAD SCI USA, V107, P6487, DOI 10.1073/pnas.0911213107
   Kourtesis P, 2020, FRONT COMP SCI-SWITZ, V1, DOI 10.3389/fcomp.2019.00012
   Kourtesis P, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00417
   Kourtesis P, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00342
   Krautheim JT, 2020, CORTEX, V127, P17, DOI 10.1016/j.cortex.2020.01.026
   Lakens D, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00863
   LeDoux JE, 2000, ANNU REV NEUROSCI, V23, P155, DOI 10.1146/annurev.neuro.23.1.155
   Lei X, 2011, HUM BRAIN MAPP, V32, P1141, DOI 10.1002/hbm.21098
   Li JP, 2018, COGN COMPUT, V10, P368, DOI 10.1007/s12559-017-9533-x
   Li PY, 2019, IEEE T BIO-MED ENG, V66, P2869, DOI 10.1109/TBME.2019.2897651
   Li WY, 2020, NEUROCOMPUTING, V415, P368, DOI 10.1016/j.neucom.2020.07.123
   Li Y, 2016, N MUSIC, V36, P54
   Liao D, 2020, IEEE J ELECTROMAG RF, V4, P216, DOI 10.1109/JERM.2019.2948767
   Lin T, 2017, FRONT BEHAV NEUROSCI, V11, DOI 10.3389/fnbeh.2017.00038
   Maddock RJ, 2003, HUM BRAIN MAPP, V18, P30, DOI 10.1002/hbm.10075
   Mosher JC, 1999, IEEE T SIGNAL PROCES, V47, P332, DOI 10.1109/78.740118
   Mu J, 2011, LIT LIFE, V8, P115
   Pascual-Marqui RD, 2002, METHOD FIND EXP CLIN, V24, P5
   Patel S, 2018, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.00224
   Pei X.Y, 2017, AUTOMAT INSTRUMENT, V6, P216, DOI [10.14016/j.cnki.1001-9227.2017.06.216, DOI 10.14016/J.CNKI.1001-9227.2017.06.216]
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Pion-Tonachini L, 2019, NEUROIMAGE, V198, P181, DOI 10.1016/j.neuroimage.2019.05.026
   Ren Y.Q, 2019, J DIST ED, V37, P47
   Román C, 2017, FRONT NEUROINFORM, V11, DOI 10.3389/fninf.2017.00073
   Shi W.Z, 2002, FUNDAMENTALS VOCAL M
   Sitaram R, 2011, NEUROIMAGE, V56, P753, DOI 10.1016/j.neuroimage.2010.08.007
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Somrak A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041185
   Sood SK, 2018, COMPUT APPL ENG EDUC, V26, P1565, DOI 10.1002/cae.21965
   Tadel F, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/879716
   Tarrant J, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01280
   Wang HL, 2022, IEEE T AFFECT COMPUT, V13, P1489, DOI 10.1109/TAFFC.2020.3006847
   Wang XW, 2014, NEUROCOMPUTING, V129, P94, DOI 10.1016/j.neucom.2013.06.046
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Wild B, 2006, NEUROLOGY, V66, P887, DOI 10.1212/01.wnl.0000203123.68747.02
   Xi X, 2010, HOME DRAMA, V7
   Xu N, 2008, SCI ED ARTICLE COLLE, V8, DOI [10.3969/j.issn.1672-7894.2008.24.158, DOI 10.3969/J.ISSN.1672-7894.2008.24.158]
   Zhang G., 2019, Scientia Sinica Informat., V49, P1097
   Zhang Y, 2019, CEREB CORTEX, V29, P517, DOI 10.1093/cercor/bhx334
   Zhang Z.D, 2018, SICHUAN THEATRE, V12, P186
   Zheng WL, 2019, IEEE T AFFECT COMPUT, V10, P417, DOI 10.1109/TAFFC.2017.2712143
   Zheng WL, 2015, IEEE T AUTON MENT DE, V7, P162, DOI 10.1109/TAMD.2015.2431497
NR 65
TC 2
Z9 2
U1 5
U2 28
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD AUG 12
PY 2021
VL 15
AR 693468
DI 10.3389/fnins.2021.693468
PG 12
WC Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Neurosciences & Neurology
GA UF3TJ
UT WOS:000688498600001
PM 34456670
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Bowling, DL
   Gill, K
   Choi, JD
   Prinz, J
   Purves, D
AF Bowling, Daniel L.
   Gill, Kamraan
   Choi, Jonathan D.
   Prinz, Joseph
   Purves, Dale
TI Major and minor music compared to excited and subdued speech
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID VOCAL EXPRESSION; PITCH; EMOTION; COMMUNICATION; DETERMINANTS; MODES
AB The affective impact of music arises from a variety of factors, including intensity, tempo, rhythm, and tonal relationships. The emotional coloring evoked by intensity, tempo, and rhythm appears to arise from association with the characteristics of human behavior in the corresponding condition; however, how and why particular tonal relationships in music convey distinct emotional effects are not clear. The hypothesis examined here is that major and minor tone collections elicit different affective reactions because their spectra are similar to the spectra of voiced speech uttered in different emotional states. To evaluate this possibility the spectra of the intervals that distinguish major and minor music were compared to the spectra of voiced segments in excited and subdued speech using fundamental frequency and frequency ratios as measures. Consistent with the hypothesis, the spectra of major intervals are more similar to spectra found in excited speech, whereas the spectra of particular minor intervals are more similar to the spectra of subdued speech. These results suggest that the characteristic affective impact of major and minor tone collections arises from associations routinely made between particular musical intervals and voiced speech. (C) 2010 Acoustical Society of America. [DOI: 10.1121/1.3268504]
C1 [Bowling, Daniel L.] Duke Univ, Dept Neurobiol, Durham, NC 27708 USA.
   Duke Univ, Ctr Cognit Neurosci, Durham, NC 27708 USA.
C3 Duke University; Duke University
RP Bowling, DL (corresponding author), Duke Univ, Dept Neurobiol, Durham, NC 27708 USA.
OI Bowling, Daniel/0000-0002-5303-5472
FU Direct For Social, Behav & Economic Scie; Division Of Behavioral and
   Cognitive Sci [0924181] Funding Source: National Science Foundation
CR Aldwell Edward., 2011, HARMONY VOICE LEADIN
   [Anonymous], 1868, SOCIAL STATICS
   [Anonymous], 1994, VOWEL PERCEPTION PRO
   [Anonymous], 2001, MUSIC EMOTION THEORY
   [Anonymous], MEASURED TONES INTER
   [Anonymous], 1999, The psychology of music
   [Anonymous], 2007, MATLAB VERS R2007A
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   BARLOW H, 1974, DICT MUSICAL THEMES
   Bernstein L., 1976, The unanswered question: Six talks at Harvard
   Boersma P, 1993, P I PHONETIC SCI, V17, P97, DOI DOI 10.1371/JOURNAL.PONE.0069107
   Boersma P., 2008, Praat: Doing Phonetics by Computer
   BURKHOLDER JP, 2005, HIST W MUSIC
   CARTERETTE EC, 1999, PSYCHOL MUSIC
   COHEN D, 1971, J MUSIC THEORY, V15, P85
   Cooke, 1959, LANGUAGE MUSIC
   CROWDER RG, 1985, B PSYCHONOMIC SOC, V23, P314
   CRYSTAL D, 1997, The Cambridge Encyclopedia of Language, VSecond
   Delattre P, 1952, WORD, V8, P195, DOI 10.1080/00437956.1952.11659431
   EEROLA T., 2004, MIDI toolbox: MATLAB tools for music research
   EEROLA T, 2004, SUOMEN KASAN ESAVELM
   Fant G., 1960, ACOUSTIC THEORY SPEE
   Gregory A. H., 1996, PSYCHOL MUSIC, V24, P47, DOI [10.1177/0305735696241005, DOI 10.1177/0305735696241005]
   Grose JH, 2002, J ACOUST SOC AM, V112, P2956, DOI 10.1121/1.1514934
   HALL JW, 1981, J ACOUST SOC AM, V69, P509, DOI 10.1121/1.385480
   Harnmerschmidt K, 2007, J VOICE, V21, P531, DOI 10.1016/j.jvoice.2006.03.002
   Harrington J., 2007, P INT 2007 ANTW
   Heinlein CP, 1928, J COMP PSYCHOL, V8, P101, DOI 10.1037/h0070573
   Helmholtz H, 1885, LEHRE TONEMPFINDUNGE
   Hevner K, 1935, AM J PSYCHOL, V47, P103, DOI 10.2307/1416710
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Hillenbrand JM, 2001, J ACOUST SOC AM, V109, P748, DOI 10.1121/1.1337959
   HOLLIEN H, 1960, J SPEECH HEAR RES, V3, P52, DOI 10.1044/jshr.0301.52
   HURON DAVID, 2006, SWEET ANTICIPATION M, P148, DOI DOI 10.7551/MITPRESS/6575.001.0001
   Johnstone T., 2000, HDB EMOTIONS, V01
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Krumhansl C.L., 1990, COGNITIVE FDN MUSICA
   Nettl B., 1956, MUSIC PRIMITIVE CULT
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   PICKETT JM, 1957, J ACOUST SOC AM, V29, P613, DOI 10.1121/1.1908983
   PIERCE JR, 1962, SCI MUSICAL SOUND
   Press W. H., 1992, Numerical Recipes in C++: The Art of Scientific Computing, V2nd
   Protopapas A, 1997, J ACOUST SOC AM, V101, P2267, DOI 10.1121/1.418247
   Randel D., 1986, The New Harvard Dictionary of Music
   Rossing T., 1990, The science of sound
   Schellenberg EG, 2000, MUSIC PERCEPT, V18, P155
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   Schwartz DA, 2004, HEARING RES, V194, P31, DOI 10.1016/j.heares.2004.01.019
   Schwartz DA, 2003, J NEUROSCI, V23, P7160, DOI 10.1523/JNEUROSCI.23-18-07160.2003
   Stevens K., 1998, Acoustic phonetics
   TERHARDT E, 1974, J ACOUST SOC AM, V55, P1061, DOI 10.1121/1.1914648
   TERHARDT E, 1982, J ACOUST SOC AM, V71, P671, DOI 10.1121/1.387543
   Thompson WF, 2006, SEMIOTICA, V158, P407, DOI 10.1515/SEM.2006.017
   VOS PG, 1989, MUSIC PERCEPT, V6, P383
   ZARLINO G, 1558, I HAMONICHE
NR 57
TC 51
Z9 59
U1 1
U2 20
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD JAN
PY 2010
VL 127
IS 1
BP 491
EP 503
DI 10.1121/1.3268504
PG 13
WC Acoustics; Audiology & Speech-Language Pathology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Acoustics; Audiology & Speech-Language Pathology
GA 540UF
UT WOS:000273364700055
PM 20058994
OA Green Published
DA 2024-01-09
ER

PT J
AU Brown, S
AF Brown, Steven
TI A Joint Prosodic Origin of Language and Music
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE language; music; speech; song; evolution; prosody; intonation; emotion
ID EVOLUTION; SPEECH; ICONICITY; BRAIN; COMMUNICATION; EMOTIONS; REVEALS;
   MODELS; DANCE
AB Vocal theories of the origin of language rarely make a case for the precursor functions that underlay the evolution of speech. The vocal expression of emotion is unquestionably the best candidate for such a precursor, although most evolutionary models of both language and speech ignore emotion and prosody altogether. I present here a model for a joint prosodic precursor of language and music in which ritualized group-level vocalizations served as the ancestral state. This precursor combined not only affective and intonational aspects of prosody, but also holistic and combinatorial mechanisms of phrase generation. From this common stage, there was a bifurcation to form language and music as separate, though homologous, specializations. This separation of language and music was accompanied by their (re) unification in songs with words.
C1 [Brown, Steven] McMaster Univ, Dept Psychol Neurosci & Behav, Hamilton, ON, Canada.
C3 McMaster University
RP Brown, S (corresponding author), McMaster Univ, Dept Psychol Neurosci & Behav, Hamilton, ON, Canada.
EM stebro@mcmaster.ca
RI Brown, Steven/IWD-6669-2023
OI Brown, Steven/0000-0002-2457-7942
FU Natural Sciences and Engineering Research Council (NSERC) of Canada
FX I am grateful to Michel Belyk and Piera Filippi for critical reading of
   an earlier version of the manuscript and for their useful suggestions
   for improvement. I thank Aleksey Nikolsky for a detailed and insightful
   critique of the manuscript, as well as the reviewers for their comments.
   This work was supported by a grant from the Natural Sciences and
   Engineering Research Council (NSERC) of Canada.
CR Aboitiz Francisco, 2012, Front Evol Neurosci, V4, P2, DOI 10.3389/fnevo.2012.00002
   Aboitiz F, 2009, REV NEUROSCIENCE, V20, P71
   ACKERMANN H, 2014, BEHAV BRAIN SCI, V37
   [Anonymous], 2005, SINGING NEANDERTHALS
   [Anonymous], MUSICAL Q
   [Anonymous], 1968, FOLK SONG STYLE CULT
   [Anonymous], 1979, PSYCHOL MUSIC, DOI DOI 10.1177/030573567971006
   [Anonymous], 2007, GESTURAL ORIGINS LAN
   [Anonymous], 1967, Intonation and grammar in British English
   [Anonymous], 2005, INTERACT STUD
   [Anonymous], 2012, BRAIN GOT LANGUAGE, DOI DOI 10.1093/ACPROF:OSOBL/9780199896684.001.0001
   [Anonymous], 2015, UNDERSTANDING SYNTAX
   Auer P., 2015, TEMPORALITY INTERACT, P27, DOI [DOI 10.1075/SLSI.27.01AUE, 10.1075/slsi.27.01aue]
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Beattie G., 2016, Rethinking body language: how hand movements reveal hidden thoughts
   Belyk M, 2017, NEUROSCI BIOBEHAV R, V77, P177, DOI 10.1016/j.neubiorev.2017.03.014
   Berwick Robert, 2011, BIOLINGUISTIC ENTERP, P65
   Bickerton D., 1995, LANGUAGE HUMAN BEHAV
   Bögels S, 2015, J PHONETICS, V52, P46, DOI 10.1016/j.wocn.2015.04.004
   Bowling DL, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0031942
   Briefer EF, 2012, J ZOOL, V288, P1, DOI 10.1111/j.1469-7998.2012.00920.x
   Brown S, 2001, ANN NY ACAD SCI, V930, P372, DOI 10.1111/j.1749-6632.2001.tb05745.x
   Brown S, 2000, PERSP ETHOL, V13, P231
   Brown S, 2000, ORIGINS OF MUSIC, P271
   Brown S., 2008, SCI AM, V299, P32, DOI [10.1038/scientificamerican0708-78, DOI 10.1038/SCIENTIFICAMERICAN0708-78]
   Brown S., 2017, PSYCHOMUSICOL MUSIC, V27, P95
   Brown S, 2007, MUSIC SCI, V11, P3, DOI 10.1177/102986490701100101
   Brown S, 2006, EUR J NEUROSCI, V23, P2791, DOI 10.1111/j.1460-9568.2006.04785.x
   Brown S, 2006, CEREB CORTEX, V16, P1157, DOI 10.1093/cercor/bhj057
   Brown S, 2009, BRAIN COGNITION, V70, P31, DOI 10.1016/j.bandc.2008.12.006
   Chauvigné LAS, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00776
   Condillac E., 1746, REPRINTED FACSIMILE
   Corballis M. C., 2002, HAND MOUTH ORIGINS L
   Couper-Kuhlen Elizabeth, 2014, PROSODIE PHONETIK IN, P221
   Cruttenden A., 1997, Intonation
   Cummins F., 2013, PERCEPTA-Revista de Cognicao Musical, V1, P17
   Cummins F, 2009, J PHONETICS, V37, P16, DOI 10.1016/j.wocn.2008.08.003
   Dahlin CR, 2014, ETHOLOGY, V120, P1, DOI 10.1111/eth.12182
   Darwin G., 1871, P423
   Darwin C., 1872, The Expression of the Emotions in Man and Animals
   Deutsch D, 2011, J ACOUST SOC AM, V129, P2245, DOI 10.1121/1.3562174
   Dingemanse M, 2016, LANGUAGE, V92, pE117, DOI 10.1353/lan.2016.0034
   Dingemanse M, 2015, TRENDS COGN SCI, V19, P603, DOI 10.1016/j.tics.2015.07.013
   Dissanayake E, 2000, ORIGINS OF MUSIC, P389
   Donald Merlin, 1991, ORIGINS MODERN MIND
   Du Bois JW, 2014, COGN LINGUIST, V25, P359, DOI 10.1515/cog-2014-0024
   Falk D., 2009, Finding our tongues: Mothers, infants and the origins of language
   FERNALD A, 1989, CHILD DEV, V60, P1497, DOI 10.2307/1130938
   Filippi P, 2017, COGNITION EMOTION, V31, P879, DOI 10.1080/02699931.2016.1177489
   Filippi P, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01393
   Fitch WT, 2010, EVOLUTION OF LANGUAGE, PROCEEDINGS, P137
   Fuchs S, 2013, J PHONETICS, V41, P29, DOI 10.1016/j.wocn.2012.08.007
   García RR, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00605
   Ghazanfar AA, 2012, CURR BIOL, V22, P1176, DOI 10.1016/j.cub.2012.04.055
   GROSJEAN F, 1979, PHONETICA, V36, P98, DOI 10.1159/000259950
   Hagen EH, 2003, HUM NATURE-INT BIOS, V14, P21, DOI 10.1007/s12110-003-1015-z
   Halliday M.A.K., 1970, COURSE SPOKEN ENGLIS
   HOCKETT CF, 1960, SCI AM, V203, P88, DOI 10.1038/scientificamerican0960-88
   Huron D, 2008, EMPIR MUSICOL REV, V3, P59, DOI 10.18061/1811/31940
   HURON DAVID, 2006, SWEET ANTICIPATION M, P148, DOI DOI 10.7551/MITPRESS/6575.001.0001
   Imai M, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0298
   Jackendoff R, 1999, TRENDS COGN SCI, V3, P272, DOI 10.1016/S1364-6613(99)01333-9
   Jackendoff R, 2002, FDN LANGUAGE BRAIN M, DOI DOI 10.1093/ACPROF:OSO/9780198270126.001.0001
   Jackendoff R, 2011, LANGUAGE, V87, P586
   Jaffe-Berg Erith, 2001, J DRAMATIC THEORY CR, V15, P3
   Jespersen Otto, 1922, LANGUAGE ITS NATURE
   Jordania J., 2006, Who Asked the First Question? The Origins of Human Choral Singing, Intelligence, Language and Speech
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Keating Patricia, 2002, UCLA WORKING PAPERS, V101, P112, DOI DOI 10.1182/blood-2002-01-0025
   [Китаев С.В. Kitayev S.V.], 2008, [Онкоурология, Onkourologiya], P25
   Koelsch S, 2004, NAT NEUROSCI, V7, P302, DOI 10.1038/nn1197
   Krieger-Redwood K, 2015, NEUROPSYCHOLOGIA, V76, P92, DOI 10.1016/j.neuropsychologia.2015.02.030
   Krivokapic J., 2012, SPEECH PLANNING DYNA, P157, DOI DOI 10.3726/978-3-653-01438-9
   Krivokapic J, 2007, J PHONETICS, V35, P162, DOI 10.1016/j.wocn.2006.04.001
   Ladd DR, 2012, LANG COGN, V4, P261, DOI 10.1515/langcog-2012-0015
   Ladd DR, 2008, CAMB STUD LINGUIST, V79, P1
   Lee Wai-Sum., 2003, Journal of the International Phonetic Association, V33, P109, DOI [DOI 10.1017/S0025100303001208, 10.1017/S0025100303001208]
   Lerdahl F, 2001, ANN NY ACAD SCI, V930, P337, DOI 10.1111/j.1749-6632.2001.tb05743.x
   Lerdahl Fred, 1983, A generative theory of tonal music
   Levelt WJM, 1999, TRENDS COGN SCI, V3, P223, DOI 10.1016/S1364-6613(99)01319-4
   Levinson SC, 2016, TRENDS COGN SCI, V20, P6, DOI 10.1016/j.tics.2015.10.010
   Maclarnon A, 2004, EVOL ANTHROPOL, V13, P181, DOI 10.1002/evan.20032
   MacLarnon AM, 1999, AM J PHYS ANTHROPOL, V109, P341, DOI 10.1002/(SICI)1096-8644(199907)109:3<341::AID-AJPA5>3.0.CO;2-2
   MacNeilage PF, 1998, BEHAV BRAIN SCI, V21, P499, DOI 10.1017/S0140525X98001265
   Malm W.P., 1996, MUSIC CULTURES PACIF
   Margulis EH, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00167
   Margulis Elizabeth Hellmuth, 2014, On Repeat: How Music Plays the Mind
   Marler P, 2000, ORIGINS OF MUSIC, P31
   McGinn Colin, 2015, PREHENSION HAND EMER
   McNeill D., 2008, Gesture and thought
   Mertens P., 2004, P SPEECH PROS C 2004
   Monaghan P, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0299
   MORTON ES, 1977, AM NAT, V111, P855, DOI 10.1086/283219
   Newman Ernest, 1905, Musical Studies
   Nikolsky A., 2015, PREHISTORIC FRONT PS, V6, P1405, DOI [10.3389/fpsyg.2015.01405, DOI 10.3389/FPSYG.2015.01405]
   Nikolsky A, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00211
   Nygaard LC, 2009, COGNITIVE SCI, V33, P127, DOI 10.1111/j.1551-6709.2008.01007.x
   Ohala J. J., 1994, Sound Symbolism, DOI DOI 10.1017/CBO9780511751806.022
   OHALA JJ, 1984, PHONETICA, V41, P1, DOI 10.1159/000261706
   PAPOUAEK Mechthild, 1996, Musical Beginnings. Origins and Development of Musical Competence, P88
   Parncutt R, 2014, MUSIC SCI, V18, P324, DOI 10.1177/1029864914542842
   Patel A. D., 2008, Music, Language, and the Brain
   Patel AD, 2014, PLOS BIOL, V12, DOI 10.1371/journal.pbio.1001821
   Perlman M, 2014, GESTURE, V14, P320, DOI 10.1075/gest.14.3.03per
   Perlman M, 2015, ROY SOC OPEN SCI, V2, DOI 10.1098/rsos.150152
   Perniss P, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00227
   Pfordresher PQ, 2017, J COGN PSYCHOL, V29, P35, DOI 10.1080/20445911.2015.1132024
   Pickett JM., 1999, The acoustics of speech communication: Fundamentals, speech perception theory, and technology
   Provine RR, 2017, PSYCHON B REV, V24, P238, DOI 10.3758/s13423-016-1089-3
   Reed BS, 2012, LANG SPEECH, V55, P13, DOI 10.1177/0023830911428871
   Robinson D, 2005, INTRO PERFORMATIVE P
   Rousseau Jean-Jacques., 1781, Essay on the Origin of Languages and Writings Related to Music
   Rudlin J, 2015, ROUTLEDGE COMPANION TO COMMEDIA DELL'ARTE, P155
   Sachs Curt, 1943, The Rise of Music in the Ancient World: East and West
   Savage PE, 2015, P NATL ACAD SCI USA, V112, P8987, DOI 10.1073/pnas.1414495112
   Savage Patrick E., 2012, ANAL APPROACHES WORL, V2, P87
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Scott-Phillips TC, 2017, PSYCHON B REV, V24, P186, DOI 10.3758/s13423-016-1061-2
   Shin OH, 2009, P NATL ACAD SCI USA, V106, P16469, DOI 10.1073/pnas.0908798106
   Spencer H., 1890, Mind, V15, P449, DOI [10.1093/mind/os-XV.60.449, DOI 10.1093/MIND/OS-XV.60.449]
   SPENCER H, 1857, FRASERS MAGAZINE, V56, P396, DOI DOI 10.1017/S0140525X08005293
   Stater PJB, 2000, ORIGINS OF MUSIC, P49
   STERN T, 1957, AM ANTHROPOL, V59, P487, DOI 10.1525/aa.1957.59.3.02a00070
   Svantesson JO, 2017, WIRES COGN SCI, V8, DOI 10.1002/wcs.1441
   Szczepek Reed B. B., 2013, ENCY APPL LINGUISTIC, P1
   Tabei K, 2015, BEHAV NEUROL, V2015, DOI 10.1155/2015/529043
   Tallerman M, 2013, J LINGUIST, V49, P455, DOI 10.1017/S0022226713000017
   Thomas Downing A., 1995, MUSIC ORIGINS LANGUA
   Tomasello M., 2003, Constructing a Language: The usage-based theory of language acquisition
   Van Dyck E, 2013, J NONVERBAL BEHAV, V37, P175, DOI 10.1007/s10919-013-0153-1
   Visser M, 2012, J COGNITIVE NEUROSCI, V24, P1766, DOI 10.1162/jocn_a_00244
   Wallaschek Richard, 1891, MIND, V16.63, P375, DOI DOI 10.1093/MIND/OS-XVI.63.375
   Welch G. F., 2006, CHILD MUSICIAN HDB M, P311, DOI [DOI 10.1093/ACPROF:OSO/9780198530329.003.0016, 10.1093/acprof:oso/9780198530329.003.0016]
   WELCH GF, 1979, PSYCHOL MUSIC, V7, P13, DOI DOI 10.1177/030573567972002
   Wray A, 1998, LANG COMMUN, V18, P47, DOI 10.1016/S0271-5309(97)00033-5
   YIP M, 2000, TONE
NR 136
TC 42
Z9 44
U1 2
U2 24
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD OCT 30
PY 2017
VL 8
AR 1894
DI 10.3389/fpsyg.2017.01894
PG 20
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA FL0HK
UT WOS:000413892000001
PM 29163276
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Corbeil, M
   Trehub, SE
   Peretz, I
AF Corbeil, Marieve
   Trehub, Sandra E.
   Peretz, Isabelle
TI Speech vs. singing: infants choose happier sounds
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE infants; music; language; singing; speech; emotion; attention
ID MATERNAL SPEECH; MOTHERS SPEECH; VOCAL EXPRESSION; DIRECTED SPEECH;
   COMMUNICATIVE INTENT; INTONATION CONTOURS; UNITED-STATES; BABY TALK;
   MUSIC; LANGUAGE
AB Infants prefer speech to non-vocal sounds and to non-human vocalizations, and they prefer happy-sounding speech to neutral speech. They also exhibit an interest in singing, but there is little knowledge of their relative interest in speech and singing. The present study explored infants' attention to unfamiliar audio samples of speech and singing. In Experiment 1, infants 4-13 months of age were exposed to happy-sounding infant-directed speech vs hummed lullabies by the same woman. They listened significantly longer to the speech, which had considerably greater acoustic variability and expressiveness, than to the lullabies. In Experiment 2, infants of comparable age who heard the lyrics of a Turkish children's song spoken vs sung in a joyful/happy manner did not exhibit differential listening. Infants in Experiment 3 heard the happily sung lyrics of the Turkish children's song vs a version that was spoken in an adult directed or affectively neutral manner. They listened significantly longer to the sung version. Overall, happy voice quality rather than vocal mode (speech or singing) was the principal contributor to infant attention, regardless of age.
C1 [Corbeil, Marieve; Trehub, Sandra E.; Peretz, Isabelle] Univ Montreal, Int Lab Brain Mus & Sound Res, Dept Psychol, Montreal, PQ H2V 4P3, Canada.
   [Trehub, Sandra E.] Univ Toronto, Dept Psychol, Mus Dev Lab, Mississauga, ON L5L 1C6, Canada.
C3 Universite de Montreal; University of Toronto; University Toronto
   Mississauga
RP Corbeil, M (corresponding author), Univ Montreal, Int Lab Brain Mus & Sound Res, Dept Psychol, 1430 Mt Royal Boul, Montreal, PQ H2V 4P3, Canada.
EM marieve.corbeil@umontreal.ca; isabelle.peretz@umontreal.ca
CR [Anonymous], 2005, SINGING NEANDERTHALS
   [Anonymous], 1998, ADV INFANCY RES
   [Anonymous], ANN CHILD DEV
   [Anonymous], 1999, NORM: Multiple Imputation of Incomplete Multivariate Data Under a Normal Model, version 2: Software for Windows 95/98/NT
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Bänziger T, 2005, SPEECH COMMUN, V46, P252, DOI 10.1016/j.specom.2005.02.016
   Bergeson TR, 2007, INFANT BEHAV DEV, V30, P648, DOI 10.1016/j.infbeh.2007.03.003
   Bergeson TR, 2002, PSYCHOL SCI, V13, P72, DOI 10.1111/1467-9280.00413
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Boersma P., 2010, PRAAT DOING PHONETIC
   Brandt A, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00327
   Chen-Hafteck L., 1997, Early Childhood Development and Care, V130, P85, DOI [DOI 10.1080/0300443971300109, 10.1080/0300443971300109]
   Clayton M., 2000, Time in Indian music
   COLOMBO J, 1981, INFANT BEHAV DEV, V4, P219, DOI 10.1016/S0163-6383(81)80025-2
   Darwin G., 1871, P423
   De Looze Celine, 2008, PROC SPEECH PROSODY, P135
   Dissanayake E, 2000, ORIGINS OF MUSIC, P389
   Eckerdal P., 2009, Communicative musicality: Exploring the basis of human companionship, P241
   FERGUSON CA, 1964, AM ANTHROPOL, V66, P103, DOI 10.1525/aa.1964.66.suppl_3.02a00060
   FERNALD A, 1987, INFANT BEHAV DEV, V10, P279, DOI 10.1016/0163-6383(87)90017-8
   FERNALD A, 1989, CHILD DEV, V60, P1497, DOI 10.2307/1130938
   FERNALD A, 1993, CHILD DEV, V64, P657, DOI 10.1111/j.1467-8624.1993.tb02934.x
   FERNALD A, 1989, J CHILD LANG, V16, P477, DOI 10.1017/S0305000900010679
   FERNALD A, 1985, INFANT BEHAV DEV, V8, P181, DOI 10.1016/S0163-6383(85)80005-9
   FERNALD A, 1984, DEV PSYCHOL, V20, P104, DOI 10.1037/0012-1649.20.1.104
   Fernald A., 1992, Nonverbal vocal communication: Comparative and developmental approaches, P262
   FRICK RW, 1985, PSYCHOL BULL, V97, P412, DOI 10.1037/0033-2909.97.3.412
   GLENN SM, 1981, CHILD DEV, V52, P1303, DOI 10.2307/1129520
   Graham J. W., 2012, MISSING DATA, P73
   GRIESER DL, 1988, DEV PSYCHOL, V24, P14, DOI 10.1037/0012-1649.24.1.14
   Jackendoff R, 2009, MUSIC PERCEPT, V26, P195, DOI 10.1525/MP.2009.26.3.195
   JACOBSON JL, 1983, CHILD DEV, V54, P436, DOI 10.2307/1129704
   Jones M.R., 2010, ATTENTION TIME, P317
   Jordania J., 2010, PROBLEMS TRADITIONAL, P41
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kent R. D., 2002, ACOUSTING ANAL SPEEC
   Kitamura C, 2003, INFANCY, V4, P85, DOI 10.1207/S15327078IN0401_5
   Kitamura C, 2002, INFANT BEHAV DEV, V24, P372
   Kitamura C, 2009, INFANCY, V14, P77, DOI 10.1080/15250000802569777
   Kivy P., 1993, FINE ART REPETTION E
   KUCHUK A, 1986, CHILD DEV, V57, P1054
   Laukka P, 2005, COGNITION EMOTION, V19, P633, DOI 10.1080/02699930441000445
   MANDEL DR, 1995, PSYCHOL SCI, V6, P314, DOI 10.1111/j.1467-9280.1995.tb00517.x
   Masataka N, 1999, DEV PSYCHOL, V35, P1001, DOI 10.1037/0012-1649.35.4.1001
   McMullen E, 2004, MUSIC PERCEPT, V21, P289, DOI 10.1525/mp.2004.21.3.289
   McRoberts GW, 2009, INFANCY, V14, P162, DOI 10.1080/15250000802707062
   Menon V, 2005, NEUROIMAGE, V28, P175, DOI 10.1016/j.neuroimage.2005.05.053
   MORIKAWA H, 1988, J CHILD LANG, V15, P237, DOI 10.1017/S0305000900012356
   Nakata T, 2004, INFANT BEHAV DEV, V27, P455, DOI 10.1016/j.infbeh.2004.03.002
   Nakata T., 2011, Psychomusicology: Music Mind Brain, V21, P45, DOI DOI 10.1037/H0094003
   NELSON DGK, 1995, INFANT BEHAV DEV, V18, P111
   O'Callaghan C, 2008, AM J HOSP PALLIAT ME, V25, P93, DOI 10.1177/1049909107310139
   Obermeier C, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00010
   Panneton R., 2006, RES HUMAN DEV, V3, P7, DOI [DOI 10.1207/S15427617RHD0301_2, 10.1207/s15427617rhd0301_2]
   PAPOUSEK M, 1990, INFANT BEHAV DEV, V13, P539, DOI 10.1016/0163-6383(90)90022-Z
   PAPOUSEK M, 1994, EARLY DEV PARENTING, V3, P5
   Papousek M., 1981, ADV INFANCY RES, P163
   Patel A. D., 2008, Music, Language, and the Brain
   Patel AD, 1998, BRAIN LANG, V61, P123, DOI 10.1006/brln.1997.1862
   PEGG JE, 1992, INFANT BEHAV DEV, V15, P325, DOI 10.1016/0163-6383(92)80003-D
   Perani D, 2011, P NATL ACAD SCI USA, V108, P16056, DOI 10.1073/pnas.1102991108
   Peretz I, 2009, PSYCHOL BELG, V49, P157, DOI 10.5334/pb-49-2-3-157
   Pinker S., 1997, How the mind works
   Plantinga J., 2011, MUTLIMODAL ASPECTS M
   Richards JE, 2010, CURR DIR PSYCHOL SCI, V19, P41, DOI 10.1177/0963721409360003
   ROSE SA, 1982, DEV PSYCHOL, V18, P704, DOI 10.1037/0012-1649.18.5.704
   Salimpoor VN, 2011, NAT NEUROSCI, V14, P257, DOI 10.1038/nn.2726
   Sambeth A, 2008, CLIN NEUROPHYSIOL, V119, P332, DOI 10.1016/j.clinph.2007.09.144
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Serrano JM, 1995, INFANT BEHAV DEV, V18, P477, DOI 10.1016/0163-6383(95)90036-5
   Shenfield T., 2003, Psychol. Music, V31, P365, DOI DOI 10.1177/03057356030314002
   Shultz S, 2010, LANG LEARN DEV, V6, P241, DOI 10.1080/15475440903507830
   Singh L, 2002, INFANCY, V3, P365, DOI 10.1207/S15327078IN0303_5
   Soley G, 2010, DEV PSYCHOL, V46, P286, DOI 10.1037/a0017555
   STERN DN, 1982, DEV PSYCHOL, V18, P727
   STERN DN, 1983, J CHILD LANG, V10, P1, DOI 10.1017/S0305000900005092
   TARTTER VC, 1980, PERCEPT PSYCHOPHYS, V27, P24, DOI 10.3758/BF03199901
   Tillmann B, 2007, MEM COGNITION, V35, P628, DOI 10.3758/BF03193301
   TODA S, 1990, J CHILD LANG, V17, P279, DOI 10.1017/S0305000900013775
   Trainor L. J., 2008, OXFORD HDB MUSIC PSY, P171
   Trainor LJ, 1998, INFANT BEHAV DEV, V21, P77, DOI 10.1016/S0163-6383(98)90055-8
   Trainor LJ, 2002, MUSIC PERCEPT, V20, P187, DOI 10.1525/mp.2002.20.2.187
   Trainor LJ, 1998, INFANT BEHAV DEV, V21, P799, DOI 10.1016/S0163-6383(98)90047-9
   Trainor LJ, 2000, PSYCHOL SCI, V11, P188, DOI 10.1111/1467-9280.00240
   Trainor LJ, 1996, INFANT BEHAV DEV, V19, P83, DOI 10.1016/S0163-6383(96)90046-6
   Trainor LJ, 1997, INFANT BEHAV DEV, V20, P383, DOI 10.1016/S0163-6383(97)90009-6
   Trehub S, 2000, ORIGINS OF MUSIC, P427
   Trehub S., 2010, HDB MUSIC EMOTION TH, P645, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0023
   Trehub S. E., 1998, Advances in Infancy Research, V12, P43
   Trehub S. E., 2010, UNESCO OBSERVATORY E, V2, P1
   Trehub SE, 2012, ANN NY ACAD SCI, V1252, P37, DOI 10.1111/j.1749-6632.2012.06448.x
   TREHUB SE, 1993, ADV CHILD DEV BEHAV, V24, P1, DOI 10.1016/S0065-2407(08)60298-0
   Trehub SE, 1997, CAN J EXP PSYCHOL, V51, P385, DOI 10.1037/1196-1961.51.4.385
   Trehub SE, 1997, DEV PSYCHOL, V33, P500, DOI 10.1037/0012-1649.33.3.500
   Unyk AM., 1992, Psychol Music, V20, P15, DOI [10.1177/0305735692201002, DOI 10.1177/0305735692201002]
   Volkova A, 2006, DEVELOPMENTAL SCI, V9, P583, DOI 10.1111/j.1467-7687.2006.00536.x
   VOS PG, 1989, MUSIC PERCEPT, V6, P383
   Vouloumanos A, 2004, DEVELOPMENTAL SCI, V7, P270, DOI 10.1111/j.1467-7687.2004.00345.x
   Vouloumanos A, 2007, DEVELOPMENTAL SCI, V10, P159, DOI 10.1111/j.1467-7687.2007.00549.x
   Vouloumanos A, 2010, CHILD DEV, V81, P517, DOI 10.1111/j.1467-8624.2009.01412.x
   WERKER JF, 1989, CAN J PSYCHOL, V43, P230, DOI 10.1037/h0084224
   Zajonc RB, 2001, CURR DIR PSYCHOL SCI, V10, P224, DOI 10.1111/1467-8721.00154
   Zatorre RJ, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001372
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
   Zentner M, 2010, P NATL ACAD SCI USA, V107, P5768, DOI 10.1073/pnas.1000121107
   Zentner MR, 1998, INFANT BEHAV DEV, V21, P483, DOI 10.1016/S0163-6383(98)90021-2
NR 107
TC 67
Z9 73
U1 2
U2 35
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD JUN 26
PY 2013
VL 4
AR 372
DI 10.3389/fpsyg.2013.00372
PG 11
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA AA4FL
UT WOS:000331050800001
PM 23805119
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Lau, HYC
   Scherer, RC
AF Lau, Hiu Yan Crystal
   Scherer, Ronald C.
TI Objective Measures of Two Musical Interpretations of an Excerpt From
   Berlioz's "La mort d'Ophelie"
SO JOURNAL OF VOICE
LA English
DT Article
DE Art song; Emotional interpretation; Objective measures; Musical
   interpretation; Singing; Voice
ID SINGING VOICE; EMOTION; EXPRESSION
AB Objective/Hypothesis. This study aimed to determine objective production differences relative to two emotional interpretations in performing an excerpt from a classical art song. The null hypothesis was proposed.Methods. The first author recorded an excerpt from an art song. The excerpt was sung with two contrasting musical interpretations: an "empathetic legato" approach, and a "sarcastic" approach characterized by emphatic attacks. Microphone, airflow, and electroglottography signals were digitized. The vowels were analyzed in terms of intensity, long term average spectra, fundamental frequency (f(o)), airflow vibrato rate and extent, vowel onsetslope, intensity comparison of harmonic frequencies, and glottal measures based on electroglottograph wave-forms. Four consonant tokens were analyzed relative to airflow, voice onset time, and production duration.Results & Conclusions.The emphatic performance had faster vowel onset, increased glottal adduction,increased intensity of harmonics in 2-3 kHz, increased intensity in the fourth andfifth formants, inferred subglot-tal pressure increase, increased airflow for /f/, and greater aspiration airflow for /p, t/. Vibrato extents for inten-sity,f(o), and airflow were wider in the emphatic approach. Findings revealed larger EGGW25 and peak-to-peakamplitude values of the electroglottography waveform, suggesting greater vocal fold contact area and longer glot-tal closure for the emphatic approach. Long-term average spectrum analyses of the entire production displayedminor variation across all formant frequencies, suggesting an insignificant change in vocal tract shaping betweenthe two approaches. This single-case objective study emphasizes the reality of physiological, aerodynamic, andacoustic production differences in the interpretive and pedagogical aspects of art song performance
C1 [Lau, Hiu Yan Crystal] Bowling Green State Univ, Interdisciplinary Studies, Bowling Green, OH USA.
   [Scherer, Ronald C.] Bowling Green State Univ, Dept Commun Sci & Disorders, Bowling Green, OH USA.
   [Scherer, Ronald C.] Bowling Green State Univ, 243 Hlth & Human Serv Bldg, Bowling Green, OH 43403 USA.
C3 University System of Ohio; Bowling Green State University; University
   System of Ohio; Bowling Green State University; University System of
   Ohio; Bowling Green State University
RP Scherer, RC (corresponding author), Bowling Green State Univ, 243 Hlth & Human Serv Bldg, Bowling Green, OH 43403 USA.
EM ronalds@bgsu.edu
CR Alku P, 2011, SADHANA-ACAD P ENG S, V36, P623, DOI 10.1007/s12046-011-0041-5
   Arroabarren I, 2004, EURASIP J APPL SIG P, V2004, P1007, DOI 10.1155/S1110865704401127
   Arroabarren I, 2006, IEEE T AUDIO SPEECH, V14, P1422, DOI 10.1109/TSA.2005.858013
   Bachorowski JA, 2003, ANN NY ACAD SCI, V1000, P244, DOI 10.1196/annals.1280.012
   Cochrane T., 2013, The Emotional Power of Music: Multidisciplinary Perspectives on Musical Arousal, Expression, and Social Control
   Darwin C., 1872, P374
   Dromey C, 2015, J VOICE, V29, P170, DOI 10.1016/j.jvoice.2014.06.007
   Eguchi S, 1969, ACTA OTO-LARYNGOL, V257
   Hakanpaa T, 2019, J VOICE, DOI [10.1016/j.voice.2019.10.002, DOI 10.1016/J.VOICE.2019.10.002]
   Hampala V, 2016, J VOICE, V30, P161, DOI 10.1016/j.jvoice.2015.03.018
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Nandamudi S, 2019, J VOICE, V33, P815, DOI 10.1016/j.jvoice.2018.05.007
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   Scherer KR, 2017, J ACOUST SOC AM, V142, P1805, DOI 10.1121/1.5002886
   Scherer KR, 2015, COMPUT SPEECH LANG, V29, P218, DOI 10.1016/j.csl.2013.10.002
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Scherer RC, 1988, VOCAL PHYSL VOICE PR, P279
   SCHERER RC, 1995, PRODUCING SPEECH CON, P269
   Seashore CE, 1923, P NATL ACAD SCI USA, V9, P323, DOI 10.1073/pnas.9.9.323
   Sundberg J, 1995, VIBRATO, P35
   Sundberg J, 2019, J VOICE, DOI [10.1016/j.voice.2019.08.007, DOI 10.1016/J.VOICE.2019.08.007]
   Titze I., 1994, Principles of Voice Production
   Vogel AP, 2009, BEHAV RES METHODS, V41, P318, DOI 10.3758/BRM.41.2.318
NR 24
TC 0
Z9 0
U1 0
U2 1
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0892-1997
EI 1873-4588
J9 J VOICE
JI J. Voice
PD MAR
PY 2023
VL 37
IS 2
BP 301e9
EP 301e25
DI 10.1016/j.jvoice.2020.12.045
EA MAR 2023
PG 17
WC Audiology & Speech-Language Pathology; Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Audiology & Speech-Language Pathology; Otorhinolaryngology
GA A6DQ1
UT WOS:000956011200001
PM 33589372
DA 2024-01-09
ER

PT J
AU Huron, D
AF Huron, David
TI Affect induction through musical sounds: an ethological perspective
SO PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY B-BIOLOGICAL SCIENCES
LA English
DT Article
DE music; emotion; ethology; signals; cues; mirror neurons
ID PITCH HEIGHT EVIDENCE; VOCAL-TRACT LENGTH; FACIAL EXPRESSION; EMOTIONS;
   EMPATHY; TALK
AB How does music induce or evoke feeling states in listeners? A number of mechanisms have been proposed for how sounds induce emotions, including innate auditory responses, learned associations and mirror neuron processes. Inspired by ethology, it is suggested that the ethological concepts of signals, cues and indices offer additional analytic tools for better understanding induced affect. It is proposed that ethological concepts help explain why music is able to induce only certain emotions, why some induced emotions are similar to the displayed emotion (whereas other induced emotions differ considerably from the displayed emotion), why listeners often report feeling mixed emotions and why only some musical expressions evoke similar responses across cultures.
C1 [Huron, David] Ohio State Univ, Sch Mus, Columbus, OH 43210 USA.
   [Huron, David] Ohio State Univ, Ctr Cognit & Brain Sci, Columbus, OH 43210 USA.
C3 University System of Ohio; Ohio State University; University System of
   Ohio; Ohio State University
RP Huron, D (corresponding author), Ohio State Univ, Sch Mus, 1866 Coll Rd, Columbus, OH 43210 USA.
EM huron.1@osu.edu
OI Huron, David/0000-0001-5295-9457
CR [Anonymous], 1996, The language of tears
   [Anonymous], 1994, THESIS BROWN U PROVI
   [Anonymous], 2011, NATURE ED KNOWLEDGE
   [Anonymous], 1992, Emotion and Social Behavior
   Aziz-Zadeh L, 2004, EUR J NEUROSCI, V19, P2609, DOI 10.1111/j.0953-816X.2004.03348.x
   BAUER HR, 1987, PHONETICA, V44, P173, DOI 10.1159/000261793
   Bolinger D. L., 1964, UNIVERSALS HUMAN LAN, V2, P471
   Buccino G, 2005, COGNITIVE BRAIN RES, V24, P355, DOI 10.1016/j.cogbrainres.2005.02.020
   Carr L, 2003, P NATL ACAD SCI USA, V100, P5497, DOI 10.1073/pnas.0935845100
   Darwin C., 1872, The Expression of the Emotions in Man and Animals
   EKMAN P, 1986, MOTIV EMOTION, V10, P159, DOI 10.1007/BF00992253
   EKMAN P, 1988, MOTIV EMOTION, V12, P303, DOI 10.1007/BF00993116
   EPPLE G, 1967, FOLIA PRIMATOL, V7, P37, DOI 10.1159/000155095
   Fant G., 1960, ACOUSTIC THEORY SPEE
   Fitch WT, 1997, J ACOUST SOC AM, V102, P1213, DOI 10.1121/1.421048
   Fox M. W, 1977, P728
   Gabrielsson A, 2003, MUSIC SCI, V7, P157, DOI 10.1177/102986490300700201
   Gabrielsson A., 2011, Strong Experiences with Music
   Gallese V, 2003, PSYCHOPATHOLOGY, V36, P171, DOI 10.1159/000072786
   Gallese V, 2004, TRENDS COGN SCI, V8, P396, DOI 10.1016/j.tics.2004.07.002
   Gelstein S, 2011, SCIENCE, V331, P226, DOI 10.1126/science.1198331
   Hunter PG, 2010, PSYCHOL AESTHET CREA, V4, P47, DOI 10.1037/a0016873
   Huron D., 2012, P 12 INT C MUS PERC, P473
   Huron D, 2013, J ACOUST SOC AM, V133, P2947, DOI 10.1121/1.4798801
   Huron D, 2009, EMPIR MUSICOL REV, V4, P93, DOI 10.18061/1811/44530
   Huron D, 2006, EMPIR MUSICOL REV, V1, P170, DOI 10.18061/1811/24068
   Johnstone Rufus A., 1997, P155
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2013, PHYS LIFE REV, V10, P235, DOI 10.1016/j.plrev.2013.05.008
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kaufmann J.H., 1967, pUnpaginated
   LADEFOGED P, 1962, ELEMENTS ACOUSTIC PH
   Ladinig O, 2012, PSYCHOL AESTHET CREA, V6, P146, DOI 10.1037/a0024671
   Laird James D., 2007, Feelings: The Perception of Self
   Lane CJ, 2006, THESIS U TEXAS ARLIN
   Lorenz K., 1939, Verhandlungen der Deutschen Zoologischen Gesellschaft Leipzig, V41, P69
   Lorenz K., 1970, Studies in Animal and Human Behavior, V1
   MacDougall HG, 2005, J APPL PHYSIOL, V99, P1164, DOI 10.1152/japplphysiol.00138.2005
   Maynard Smith J. M., 2003, Animal signals
   MILLER EH, 1975, BEHAVIOUR, V53, P268, DOI 10.1163/156853975X00227
   Molnar-Szakacs I, 2006, SOC COGN AFFECT NEUR, V1, P235, DOI 10.1093/scan/nsl029
   MORTON ES, 1977, AM NAT, V111, P855, DOI 10.1086/283219
   Ohala J. J., 1980, J ACOUST SOC AM, V68, pS33
   Paul B, 2010, EMPIR MUSICOL REV, V5, P27, DOI 10.18061/1811/46747
   Plazak J.S, 2011, THESIS OHIO STATE U
   Plutchik R., 1980, Emotion: Theory, research, and experience: Vol. 1, V1, P141, DOI DOI 10.1016/B978-0-12-558701-3.50012-0
   Pruitt CH., 1977, ANIMALS COMMUNICATE, P767
   Seashore CE, 1932, THE VIBRATO
   Shanahan D., 2014, EMPIR MUSICOL REV, V9, P46, DOI [10.18061/emr.v9i2.4441, DOI 10.18061/EMR.V9I2.4441]
   Silk JB, 2000, ANIM BEHAV, V59, P423, DOI 10.1006/anbe.1999.1312
   Singer T, 2004, SCIENCE, V303, P1157, DOI 10.1126/science.1093535
   Smith JM, 1995, J THEOR BIOL, V177, P305
   TARTTER VC, 1980, PERCEPT PSYCHOPHYS, V27, P24, DOI 10.3758/BF03199901
   TARTTER VC, 1994, J ACOUST SOC AM, V96, P2101, DOI 10.1121/1.410151
   Vorperian HK, 2005, J ACOUST SOC AM, V117, P338, DOI 10.1121/1.1835958
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
   [No title captured]
NR 57
TC 19
Z9 23
U1 1
U2 24
PU ROYAL SOC
PI LONDON
PA 6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND
SN 0962-8436
EI 1471-2970
J9 PHILOS T R SOC B
JI Philos. Trans. R. Soc. B-Biol. Sci.
PD MAR 19
PY 2015
VL 370
IS 1664
BP 122
EP 128
AR 20140098
DI 10.1098/rstb.2014.0098
PG 7
WC Biology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Life Sciences & Biomedicine - Other Topics
GA CC7HC
UT WOS:000350537300011
PM 25646521
OA Bronze, Green Published
DA 2024-01-09
ER

PT J
AU Livingstone, SR
   Palmer, C
AF Livingstone, Steven R.
   Palmer, Caroline
TI Head Movements Encode Emotions During Speech and Song
SO EMOTION
LA English
DT Article
DE head motion; emotion; vocal communication; speech; song
ID SPONTANEOUS FACIAL EXPRESSIONS; FALSE DISCOVERY RATE; NONVERBAL
   BEHAVIOR; MUSIC PERFORMANCE; BODY EXPRESSIONS; VOCAL EXPRESSION; CUE
   UTILIZATION; LIGHT DISPLAYS; POINT-LIGHT; PERCEPTION
AB When speaking or singing, vocalists often move their heads in an expressive fashion, yet the influence of emotion on vocalists' head motion is unknown. Using a comparative speech/song task, we examined whether vocalists' intended emotions influence head movements and whether those movements influence the perceived emotion. In Experiment 1, vocalists were recorded with motion capture while speaking and singing each statement with different emotional intentions (very happy, happy, neutral, sad, very sad). Functional data analyses showed that head movements differed in translational and rotational displacement across emotional intentions, yet were similar across speech and song, transcending differences in F-0 (varied freely in speech, fixed in song) and lexical variability. Head motion specific to emotional state occurred before and after vocalizations, as well as during sound production, confirming that some aspects of movement were not simply a by-product of sound production. In Experiment 2, observers accurately identified vocalists' intended emotion on the basis of silent, face-occluded videos of head movements during speech and song. These results provide the first evidence that head movements encode a vocalist's emotional intent and that observers decode emotional information from these movements. We discuss implications for models of head motion during vocalizations and applied outcomes in social robotics and automated emotion recognition.
C1 [Livingstone, Steven R.; Palmer, Caroline] McGill Univ, Dept Psychol, 1205 Dr Penfield Ave, Montreal, PQ H3A 1B1, Canada.
C3 McGill University
RP Palmer, C (corresponding author), McGill Univ, Dept Psychol, 1205 Dr Penfield Ave, Montreal, PQ H3A 1B1, Canada.; Livingstone, SR (corresponding author), Dept Psychol Neurosci & Behav, 1280 Main St West, Hamilton, ON L8S 4K1, Canada.
EM steven.livingstone@mcmaster.ca; caroline.palmer@mcgill.ca
RI Livingstone, Steven R./H-5695-2019
OI Livingstone, Steven R./0000-0002-6364-6410; Palmer,
   Caroline/0000-0003-4816-8067
FU ACN-Create NSERC Fellowship; Canada Research Chair; NSERC Grant [298173]
FX This research was funded in part by an ACN-Create NSERC Fellowship to
   Steven R. Livingstone and by a Canada Research Chair and NSERC Grant
   298173 to Caroline Palmer. The authors thank Erik Koopmans, Sasha
   Ilnyckyj, Marcelo Wanderley, David Ostry, Frank A. Russo, Pascal van
   Lieshout, Frances Spidle, Rachel Brown, and Pascale Lidji for their
   assistance and comments.
CR Ambadar Z, 2009, J NONVERBAL BEHAV, V33, P17, DOI 10.1007/s10919-008-0059-5
   [Anonymous], 2011, International Journal of Wavelets Multiresolution and Information Processing, DOI [DOI 10.1142/S021969130400041X, 10.1142/S021969130400041X]
   [Anonymous], E PRIME VERSION 2 0
   [Anonymous], 2002, APPL FUNCTIONAL DATA
   [Anonymous], 2001, Music and Emotion, DOI DOI 10.1525/MP.2004.21.4.561
   Atkinson AP, 2004, PERCEPTION, V33, P717, DOI 10.1068/p5096
   Bänziger T, 2012, EMOTION, V12, P1161, DOI 10.1037/a0025827
   BASSILI JN, 1979, J PERS SOC PSYCHOL, V37, P2049, DOI 10.1037/0022-3514.37.11.2049
   BASSILI JN, 1978, J EXP PSYCHOL HUMAN, V4, P373, DOI 10.1037/0096-1523.4.3.373
   Benjamini Y, 2001, ANN STAT, V29, P1165
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Boersma P., 2010, PRAAT DOING PHONETIC
   Boone RT, 1998, DEV PSYCHOL, V34, P1007, DOI 10.1037/0012-1649.34.5.1007
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Brunswik E., 1956, Perception and the representative design of psychological experiments, V2nd
   BUGENTAL DB, 1986, PERS SOC PSYCHOL B, V12, P7, DOI 10.1177/0146167286121001
   Busso C, 2007, IEEE T AUDIO SPEECH, V15, P1075, DOI 10.1109/TASL.2006.885910
   CACIOPPO JT, 1986, J PERS SOC PSYCHOL, V50, P260, DOI 10.1037/0022-3514.50.2.260
   Carlo N. S., 2004, SEMIOTICA, V2004, P37, DOI [10.1515/semi.2004.036, DOI 10.1515/SEMI.2004.036]
   COLTHEART M, 1981, Q J EXP PSYCHOL-A, V33, P497, DOI 10.1080/14640748108400805
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Cunningham DW, 2009, J VISION, V9, DOI 10.1167/9.13.7
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Darwin C., 1965, EXPRESS EMOT MAN, DOI DOI 10.1037/10001-000
   Davidson JW., 1993, PSYCHOL MUSIC, V21, P103, DOI [10.1177/030573569302100201, DOI 10.1177/030573569302100201]
   Dittrich WH, 1996, PERCEPTION, V25, P727, DOI 10.1068/p250727
   Douglas-Cowie E, 2003, SPEECH COMMUN, V40, P33, DOI 10.1016/S0167-6393(02)00070-5
   Douglas-Cowie E, 2007, LECT NOTES COMPUT SC, V4738, P488
   Ebner NC, 2010, BEHAV RES METHODS, V42, P351, DOI 10.3758/BRM.42.1.351
   EKMAN P, 1965, J PERS SOC PSYCHOL, V2, P726, DOI 10.1037/h0022736
   Ekman P., 1978, MANUAL FACIAL ACTION, DOI [DOI 10.1037/T27734-000, 10.1037/t27734-000]
   Ekman P., 1969, Semiotica, V1, P49, DOI [10.1515/semi.1969.1.1.49, DOI 10.1515/SEMI.1969.1.1.49]
   Elfenbein HA, 2002, PSYCHOL BULL, V128, P203, DOI 10.1037//0033-2909.128.2.203
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Fong T, 2003, ROBOT AUTON SYST, V42, P143, DOI 10.1016/S0921-8890(02)00372-X
   Frijda N., 1986, The emotions: Studies in emotion and social interaction
   Ghazanfar AA, 2014, TRENDS COGN SCI, V18, P543, DOI 10.1016/j.tics.2014.06.004
   GOSSELIN P, 1995, J PERS SOC PSYCHOL, V68, P83, DOI 10.1037/0022-3514.68.1.83
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   GREEN GA, 1994, J RES MUSIC EDUC, V42, P105, DOI 10.2307/3345495
   HADAR U, 1983, LANG SPEECH, V26, P117, DOI 10.1177/002383098302600202
   IBM Corp Released, 2011, IBM SPSS STAT WIND V
   Ishiguro H, 2007, SPR TRA ADV ROBOT, V28, P118
   Jesse A, 2010, PSYCHON B REV, V17, P323, DOI 10.3758/PBR.17.3.323
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2001, EMOTION, V1, P381, DOI 10.1037//1528-3542.1.4.381
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Juslin PN., 2001, Music and Emotion, P309, DOI 10.1093/oso/9780192631886.003.0014
   Kamachi M, 2001, PERCEPTION, V30, P875, DOI 10.1068/p3131
   KASTNER MP, 1990, MUSIC PERCEPT, V8, P189
   Kaulard K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0032321
   KELTNER D, 1995, J PERS SOC PSYCHOL, V68, P441, DOI 10.1037/0022-3514.68.3.441
   Kohler CG, 2004, PSYCHIAT RES, V128, P235, DOI 10.1016/j.psychres.2004.07.003
   Krumhuber E, 2005, J NONVERBAL BEHAV, V29, P3, DOI 10.1007/s10919-004-0887-x
   Krumhuber EG, 2013, EMOT REV, V5, P41, DOI 10.1177/1754073912451349
   Ladefoged P, 2010, COURSE PHONETICS
   Livingstone SR, 2015, Q J EXP PSYCHOL, V68, P952, DOI 10.1080/17470218.2014.971034
   Livingstone SR, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00156
   Livingstone SR, 2012, EMOTION, V12, P552, DOI 10.1037/a0023747
   Livingstone SR, 2010, COMPUT MUSIC J, V34, P41, DOI 10.1162/comj.2010.34.1.41
   Livingstone SR, 2009, MUSIC PERCEPT, V26, P475, DOI 10.1525/MP.2009.26.5.475
   Matlab, 2013, COMPUTER SOFTWARE
   Matsumoto D, 2009, J PERS SOC PSYCHOL, V96, P1, DOI 10.1037/a0014037
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Motley MT., 1988, Western Journal of Speech Communication, V52, P1, DOI [10.1080/10570318809389622, DOI 10.1080/10570318809389622]
   Munhall KG, 2004, PSYCHOL SCI, V15, P133, DOI 10.1111/j.0963-7214.2004.01502010.x
   Nelson NL, 2014, EMOTION, V14, P857, DOI 10.1037/a0036789
   O'Toole AJ, 2002, TRENDS COGN SCI, V6, P261, DOI 10.1016/S1364-6613(02)01908-3
   OTTA E, 1994, J PSYCHOL, V128, P323, DOI 10.1080/00223980.1994.9712736
   Plant RR, 2002, BEHAV RES METH INS C, V34, P218, DOI 10.3758/BF03195446
   Quinto LR, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00262
   Ramsay JO, 2009, USE R, P1, DOI 10.1007/978-0-387-98185-7_1
   Ramsay J. O., 2005, Functional Data Analysis
   SCHERER KR, 1991, MOTIV EMOTION, V15, P123, DOI 10.1007/BF00995674
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   SCHOUWSTRA SJ, 1995, PERCEPT MOTOR SKILL, V81, P673, DOI 10.1177/003151259508100262
   Tasko SM, 2004, J SPEECH LANG HEAR R, V47, P85, DOI 10.1044/1092-4388(2004/008)
   Thompson WF, 2007, PSYCHOL SCI, V18, P756, DOI 10.1111/j.1467-9280.2007.01973.x
   Thompson WF, 2010, PSYCHON B REV, V17, P317, DOI 10.3758/PBR.17.3.317
   Tracy JL, 2008, P NATL ACAD SCI USA, V105, P11655, DOI 10.1073/pnas.0802686105
   Tracy JL, 2004, PSYCHOL SCI, V15, P194, DOI 10.1111/j.0956-7976.2004.01503008.x
   Van den Stock J, 2007, EMOTION, V7, P487, DOI 10.1037/1528-3542.7.3.487
   VATIKIOTISBATESON E, 1995, J PHONETICS, V23, P101, DOI 10.1016/S0095-4470(95)80035-2
   Vines BW, 2011, COGNITION, V118, P157, DOI 10.1016/j.cognition.2010.11.010
   WAGNER HL, 1993, J NONVERBAL BEHAV, V17, P3, DOI 10.1007/BF00987006
   WAGNER HL, 1986, J PERS SOC PSYCHOL, V50, P737, DOI 10.1037/0022-3514.50.4.737
   Wallbott HG, 1998, EUR J SOC PSYCHOL, V28, P879, DOI 10.1002/(SICI)1099-0992(1998110)28:6<879::AID-EJSP901>3.0.CO;2-W
   Wanderley MM, 2005, J NEW MUSIC RES, V34, P97, DOI 10.1080/09298210500124208
   WIENER M, 1972, PSYCHOL REV, V79, P185, DOI 10.1037/h0032710
   Yehia H, 1998, SPEECH COMMUN, V26, P23, DOI 10.1016/S0167-6393(98)00048-X
   Yehia HC, 2002, J PHONETICS, V30, P555, DOI 10.1006/jpho.2002.0165
NR 94
TC 28
Z9 29
U1 0
U2 20
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 1528-3542
EI 1931-1516
J9 EMOTION
JI Emotion
PD APR
PY 2016
VL 16
IS 3
BP 365
EP 380
DI 10.1037/emo0000106
PG 16
WC Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA DI3LJ
UT WOS:000373399800009
PM 26501928
DA 2024-01-09
ER

PT J
AU Juslin, PN
AF Juslin, Patrik N.
TI What does music express? Basic emotions and beyond
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE music; emotion; expression; communication; categories; dimensions
ID CATEGORICAL PERCEPTION; VOCAL EXPRESSION; DIMENSIONAL MODELS;
   RECOGNITION; PERFORMANCE; COMMUNICATION; RESPONSES; DISCRETE;
   CLASSIFICATION; DETERMINANTS
AB Numerous studies have investigated whether music can reliably convey emotions to listeners, and if so what musical parameters might carry this information. Far less attention has been devoted to the actual contents of the communicative process. The goal of this article is thus to consider what types of emotional content are possible to convey in music. I will argue that the content is mainly constrained by the type of coding involved, and that distinct types of content are related to different types of coding. Based on these premises, I suggest a conceptualization in terms of "multiple layers" of musical expression of emotions. The "core" layer is constituted by iconically-coded basic emotions. I attempt to clarify the meaning of this concept, dispel the myths that surround it, and provide examples of how it can be heuristic in explaining findings in this domain. However, I also propose that this "core" layer may be extended, qualified, and even modified by additional layers of expression that involve intrinsic and associative coding. These layers enable listeners to perceive more complex emotions though the expressions are less cross-culturally invariant and more dependent on the social context and/or the individual listener. This multiple-layer conceptualization of expression in music can help to explain both similarities and differences between vocal and musical expression of emotions.
C1 Uppsala Univ, Dept Psychol, SE-75142 Uppsala, Sweden.
C3 Uppsala University
RP Juslin, PN (corresponding author), Uppsala Univ, Dept Psychol, POB 1225, SE-75142 Uppsala, Sweden.
EM patrik.juslin@psyk.uu.se
CR Adachi M., 1998, PSYCHOL MUSIC, V26, P133, DOI [DOI 10.1177/0305735698262003, 10.1177/0305735698262003]
   [Anonymous], MUSIC EXPRESSION
   [Anonymous], 1983, NEW MA HESONSTUDIES
   [Anonymous], 2001, Music and Emotion: Theory and Research
   [Anonymous], 1985, MUSIC EMOTIONS
   [Anonymous], P 17 C INT ASS EMP A
   [Anonymous], COMPUTATIONAL INTELL
   [Anonymous], MUSIC LANGUAGE HUMAN
   [Anonymous], 1977, EMOTIONS
   Bachorowski JA, 1999, CURR DIR PSYCHOL SCI, V8, P53, DOI 10.1111/1467-8721.00013
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Ball P., 2010, MUSIC INSTINCT MUSIC
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Barrett LF, 2006, PERSPECT PSYCHOL SCI, V1, P28, DOI 10.1111/j.1745-6916.2006.00003.x
   Becker J., 2004, Deep listeners: Music emotions and trancing
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Brown R., 1981, NAT S APPL PSYCH TEA, P233
   Bryant GA, 2008, J COGN CULT, V8, P135, DOI 10.1163/156770908X289242
   Campbell IG, 1942, AM J PSYCHOL, V55, P1, DOI 10.2307/1417020
   Clynes M, 1977, SENTICS TOUCH EMOTIO
   Cohen AJ., 2011, MUSIC EMOTION THEORY, P1099, DOI [DOI 10.1093/ACPROF:OSO/9780199230143.003.0031, 10.1093/acprof:oso/9780199230143.003.0031]
   Conway Martin A., 1987, COGNITION EMOTION, V1, P145, DOI [DOI 10.1080/02699938708408044, 10.1080/02699938708408044]
   Cooke, 1959, LANGUAGE MUSIC
   CORTER JE, 1992, PSYCHOL BULL, V111, P291, DOI 10.1037/0033-2909.111.2.291
   Cross I, 2009, The Oxford handbook of music psychology, P24
   CUNNINGHAM JG, 1988, MOTIV EMOTION, V12, P399, DOI 10.1007/BF00992362
   Damasio A.R., 1994, Descartes' Error: Emotion, Reason and the Human Brain
   DEGELDER B, 1996, J ACOUST SOC AM, V100, P2818, DOI DOI 10.1121/1.416612
   DELIS D, 1978, PERCEPT PSYCHOPHYS, V23, P215, DOI 10.3758/BF03204128
   DOWLING WJ, 1986, MUSIC COGNITION
   Duffy E, 1941, J GEN PSYCHOL, V25, P283, DOI 10.1080/00221309.1941.10544400
   Eerola T, 2013, MUSIC PERCEPT, V30, P307, DOI [10.1525/mp.2012.30.3.307, 10.1525/MP.2012.30.1.49]
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   EKMAN P, 1983, SCIENCE, V221, P1208, DOI 10.1126/science.6612338
   Elfenbein HA, 2002, PSYCHOL BULL, V128, P203, DOI 10.1037//0033-2909.128.2.203
   Escoffier N, 2013, HUM BRAIN MAPP, V34, P1796, DOI 10.1002/hbm.22029
   ETCOFF NL, 1992, COGNITION, V44, P227, DOI 10.1016/0010-0277(92)90002-Y
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Gabrielsson A, 2003, SER AFFECTIVE SCI, P503
   Gabrielsson A, 2003, MUSIC SCI, V7, P157, DOI 10.1177/102986490300700201
   Gabrielsson A, 2001, MUSIC SCI, V5, P123, DOI 10.1177/10298649020050S105
   GABRIELSSON Alf, 2010, Handbook of Music and Emotion: Theory, Research, Applications, V2, P547, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0020
   Gregory A. H., 1996, PSYCHOL MUSIC, V24, P47, DOI [10.1177/0305735696241005, DOI 10.1177/0305735696241005]
   Hargreaves D. J., 1986, DEV PSYCHOL MUSIC, DOI DOI 10.1017/CBO9780511521225
   Harrigan J. A., 2005, NEW HDB METHODS NONV, P65, DOI DOI 10.1093/ACPROF:OSO/9780198529620.003.0003
   Harris P.L., 1989, CHILDREN EMOTION DEV
   HASLAM N, 1995, PERS SOC PSYCHOL B, V21, P1012, DOI 10.1177/01461672952110002
   HATTEN Robert S., 1994, Musical Meaning in Beethoven: Markedness, Correlation, and Interpretation
   Hevner K, 1936, AM J PSYCHOL, V48, P246, DOI 10.2307/1415746
   Holmes KJ, 2012, J EXP PSYCHOL GEN, V141, P439, DOI 10.1037/a0027289
   Huber K., 1923, AUSDRUCK MUSIKALISCH
   IZARD CE, 1993, PSYCHOL REV, V100, P68
   Johnson-Laird Philip Nicholas, 1989, Cognition and emotion, V3, P81, DOI [DOI 10.1080/02699938908408075, 10.1080/02699938908408075]
   Juslin P., 2010, Handbook of Music and Emotion: Theory, Research, Applications, P453, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0017
   Juslin P. N., 2011, Music and the mind: Essays in honour of John Sloboda, P113
   Juslin P. N., 1996, PSYCHOL MUSIC, V24, P68, DOI [10.1177/0305735696241007, DOI 10.1177/0305735696241007]
   Juslin P. N., 2005, MUSICAL COMMUNICATIO, P85, DOI [DOI 10.1093/ACPROF:OSO/9780198529361.003.0005, 10.1093/acprof:oso/9780198529361.003.0005]
   Juslin P. N., 1998, FUNCTIONALIST PERSPE, V78
   Juslin P. N., 2004, MUSICAL EXCELLENCE S, P247
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2008, EMOTION, V8, P668, DOI 10.1037/a0013505
   Juslin PN, 2013, PHYS LIFE REV, V10, P235, DOI 10.1016/j.plrev.2013.05.008
   Juslin PN, 2012, EMOT REV, V4, P283, DOI 10.1177/1754073912439773
   Juslin PN, 2010, MUSIC ANAL, V29, P334, DOI 10.1111/j.1468-2249.2011.00323.x
   Juslin PN, 2011, MUSIC SCI, V15, P174, DOI 10.1177/1029864911401169
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Juslin PN, 1997, MUSIC PERCEPT, V14, P383
   Juslin PN., 2001, Music and Emotion, P309, DOI 10.1093/oso/9780192631886.003.0014
   KLEINGINNA P R JR, 1981, Motivation and Emotion, V5, P345, DOI 10.1007/BF00992553
   Kragel PA, 2013, EMOTION, V13, P681, DOI 10.1037/a0031820
   Kreutz G., 2000, P 6 INT C MUS PERC C
   Lamont A, 2011, MUSIC SCI, V15, P139, DOI 10.1177/1029864911403366
   Larson S, 2005, MUSIC PERCEPT, V23, P119, DOI 10.1525/mp.2005.23.2.119
   Laukka P, 2005, EMOTION, V5, P277, DOI 10.1037/1528-3542.5.3.277
   Laukka P, 2007, MOTIV EMOTION, V31, P182, DOI 10.1007/s11031-007-9063-z
   Laukka P, 2013, EMOTION, V13, P434, DOI 10.1037/a0031388
   Lazarus R., 1991, Emotion and Adaptation.
   Leech-Wilkinson D., 2006, NORD J AESTHET, V33, P51
   Lerdahl F, 2007, MUSIC PERCEPT, V24, P329, DOI 10.1525/MP.2007.24.4.329
   Lima CF, 2011, COGNITION EMOTION, V25, P585, DOI 10.1080/02699931.2010.502449
   Lindstrom E, 2003, RES STUDIES MUSIC ED, V20, P23, DOI DOI 10.1177/1321103X030200010201
   MacDonald R, 2012, PSYCHOL MUSIC, V40, P3, DOI 10.1177/0305735611433627
   Markman A. B., 2013, OXFORD HDB COGNITIVE, P321, DOI DOI 10.1093/OXFORDHB/9780195376746.013.0021
   Meyer LB., 1956, Emotion and meaning in music
   Murphy FC, 2003, COGN AFFECT BEHAV NE, V3, P207, DOI 10.3758/CABN.3.3.207
   Nyklicek I, 1997, J PSYCHOPHYSIOL, V11, P304
   Oatley Keith, 1992, Best Laid Schemes
   ORTONY A, 1990, PSYCHOL REV, V97, P315, DOI 10.1037/0033-295X.97.3.315
   Panksepp J., 2004, Affective Neuroscience
   PAPOUSEK M, 1990, INFANT BEHAV DEV, V13, P539, DOI 10.1016/0163-6383(90)90022-Z
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   Ploog Detlev W., 1992, P6
   Plutchik R., 1980, THEORIES EMOTION, P333, DOI 10.1016/b978-0-12-558701-3.50007-7
   Plutchik Robert, 1994, The psychology and biology of emotion
   Power M. J., 1997, Cognition and emotion: From order to disorder
   Resnicow JE, 2004, MUSIC PERCEPT, V22, P145, DOI 10.1525/mp.2004.22.1.145
   ROSEMAN IJ, 1991, COGNITION EMOTION, V5, P161, DOI 10.1080/02699939108411034
   Ross B. H., 1994, THINKING PROBLEM SOL, P119, DOI DOI 10.1016/B978-0-08-057299-4.50010-4
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Scherer K., 1977, MOTIV EMOTION, V1, P331, DOI [DOI 10.1007/BF00992539, 10.1007/bf00992539]
   Scherer K. R., 1984, APPROACHES EMOTION, DOI 10.4324/9781315798806
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   Schimmack U, 2000, EUR J PERSONALITY, V14, P325, DOI 10.1002/1099-0984(200007/08)14:4<325::AID-PER380>3.0.CO;2-I
   Schubert E, 2003, PERCEPT MOTOR SKILL, V96, P1117, DOI 10.2466/PMS.96.4.1117-1122
   Schubert E., 2010, Handbook of music and emotion: Theory, research, applications, P223, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0009
   SENJU M, 1987, MUSIC PERCEPT, V4, P311
   SHAVER P, 1987, J PERS SOC PSYCHOL, V52, P1061, DOI 10.1037/0022-3514.52.6.1061
   SLOBODA JA, 1992, COGNITIVE BASES OF MUSICAL COMMUNICATION, P33, DOI 10.1037/10104-003
   Sloboda JA, 2001, MUSIC PERCEPT, V19, P87, DOI 10.1525/mp.2001.19.1.87
   Sloboda JA., 2001, MUSIC EMOTION THEORY, P71
   SPENCER H, 1857, FRASERS MAGAZINE, V56, P396, DOI DOI 10.1017/S0140525X08005293
   Spitzer M, 2010, MUSIC ANAL, V29, P149, DOI 10.1111/j.1468-2249.2011.00329.x
   STEIN NL, 1992, COGNITION EMOTION, V6, P225, DOI 10.1080/02699939208411070
   Terwogt M. M., 1991, PSYCHOL MUSIC, V19, P99, DOI DOI 10.1177/0305735691192001
   Thayer RE., 1990, The Biopsychology of Mood and Activation
   Thompson W., 1992, Empirical Studies of the Arts, V10, P79, DOI DOI 10.2190/NBNY-AKDK-GW58-MTEL
   Thompson WF, 2012, P NATL ACAD SCI USA, V109, P19027, DOI 10.1073/pnas.1210344109
   Timmers R, 2007, MUSIC PERCEPT, V25, P117, DOI 10.1525/MP.2007.25.2.117
   Tomkins S. S., 1962, Affect Imagery Consciousness: Volume I: The Positive Affects, VI
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   WATSON D, 1985, PSYCHOL BULL, V98, P219, DOI 10.1037/0033-2909.98.2.219
   Wedin L., 1972, SWEDISH J MUSICOLOGY, V54, P1
   WELLS A, 1991, JOURNALISM QUART, V68, P445, DOI 10.1177/107769909106800315
   Zentner M., 2010, Handbook of music and emotion: theory, research, and applications, P367, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0008
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 128
TC 76
Z9 92
U1 0
U2 30
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD SEP 6
PY 2013
VL 4
AR 596
DI 10.3389/fpsyg.2013.00596
PG 14
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA AB1QV
UT WOS:000331569300001
PM 24046758
OA gold, Green Published
DA 2024-01-09
ER

PT J
AU Tan, DE
   Diaz, FM
   Miksza, P
AF Tan, Daphne
   Diaz, Frank M.
   Miksza, Peter
TI Expressing emotion through vocal performance: Acoustic cues and the
   effects of a mindfulness induction
SO PSYCHOLOGY OF MUSIC
LA English
DT Article
DE acoustic cues; emotion; expression; mindfulness; vocal performance
ID MUSIC PERFORMANCE; COMMUNICATION; CONNOTATIONS; ATTENTION; SCALE
AB Previous research suggests that musicians modulate a predictable set of acoustic cues to convey distinct emotions. The current study focuses on singers, testing the validity of cues previously reported for a wide range of instruments. The study also asks: What effect might a musician's mindfulness have on their expressive performance? Two groups of highly skilled vocalists recorded performances of a novel melody with four distinct emotions. Prior to the performance task, an experimental group took part in a guided mindfulness induction, while a control group engaged in a self-selected relaxation activity; state mindfulness was assessed immediately after. Recordings were analyzed for tempo, temporal variation, intensity, mean centroid, vibrato rate, vibrato extent, and attack slope; individual notes with particular scale-degree functions were also compared. Results show that the two groups of participants had similar cue usage, although those in the experimental condition had higher mindfulness scores and attributed improvements in focus and awareness to the induction task. Participants as a whole used cues in the predicted directions, and significant differences were found on all acoustical measures, except vibrato rate, as a function of expressed emotion. Results also indicate that participants modified intonation to distinguish between positive and negative emotions.
C1 [Tan, Daphne] Indiana Univ, Jacobs Sch Mus, Bloomington, IN USA.
   [Diaz, Frank M.; Miksza, Peter] Indiana Univ, Jacobs Sch Mus, Mus Educ Dept, Bloomington, IN USA.
C3 Indiana University System; Indiana University Bloomington; Indiana
   University System; Indiana University Bloomington
RP Tan, DE (corresponding author), Univ Toronto, Fac Mus, 80 Queens Pk Crescent, Toronto, ON M5S 2C5, Canada.
EM daphne.tan@utoronto.ca
CR [Anonymous], MUSIC EXPRESSION
   [Anonymous], 1949, ESSAY TRUE ART PLAYI
   [Anonymous], 2016, OXFORD HDB MUSIC PSY
   [Anonymous], 2010, HDB MUSIC EMOTION TH
   [Anonymous], 2003, Psychology of Music, DOI [DOI 10.1177/03057356030313003, 10.1177/03057356030313003]
   [Anonymous], B COUNCIL RES MUSIC
   Boersma P., 2017, PRAAT DOING PHONETIC
   Brown KW, 2003, J PERS SOC PSYCHOL, V84, P822, DOI 10.1037/0022-3514.84.4.822
   Brunswik E., 1956, Perception and the representative design of psychological experiments, V2nd
   CANNAM Chris, 2010, ACM MUL 2010 INT C 2
   Carlson LE, 2005, J PSYCHOSOM RES, V58, P29, DOI 10.1016/j.jpsychores.2004.04.366
   Czajkowski AML, 2015, BRIT J MUSIC EDUC, V32, P211, DOI 10.1017/S0265051715000145
   Diaz FM, 2018, J RES MUSIC EDUC, V66, P150, DOI 10.1177/0022429418765447
   Diaz FM, 2013, PSYCHOL MUSIC, V41, P42, DOI 10.1177/0305735611415144
   Gabrielsson A., 1995, Psychomusicol. J. Res. Music Cogn, V14, P94, DOI DOI 10.1037/H0094089
   Garcia M., 1924, TREATISE ART SINGING
   Gooding A, 2009, J CLIN SPORT PSYCHOL, V3, P303, DOI 10.1123/jcsp.3.4.303
   Greene, 2018, HDB SELF REGULATION, P181, DOI DOI 10.4324/9781315697048-12
   Juslin P., 2010, Handbook of Music and Emotion: Theory, Research, Applications, P453, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0017
   Juslin P. N., 1996, PSYCHOL MUSIC, V24, P68, DOI [10.1177/0305735696241007, DOI 10.1177/0305735696241007]
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Juslin PN, 1997, MUSIC PERCEPT, V14, P383
   Kabat-Zinn J., 1994, WHEREVER YOU GO THER
   Karpinski G. S., 2017, MANUAL EAR TRAINING
   KENDALL RA, 1990, MUSIC PERCEPT, V8, P129
   KOTLYAR GM, 1976, SOV PHYS ACOUST+, V22, P208
   Lartillot O, 2008, ST CLASS DAT ANAL, P261, DOI 10.1007/978-3-540-78246-9_31
   Lau MA, 2006, J CLIN PSYCHOL, V62, P1445, DOI 10.1002/jclp.20326
   Lindstrom E, 2003, RES STUDIES MUSIC ED, V20, P23, DOI DOI 10.1177/1321103X030200010201
   Lindstrom Erik, 1999, M SOC MUS PERC COGN
   MathWorks, 1996, MATLAB LANGUAGE TECH
   OHGUSHI K, 1996, 3 JOINT M AC SOC AM
   Palmer C, 1996, MUSIC PERCEPT, V13, P433
   Parncutt R, 2014, MUSIC SCI, V18, P324, DOI 10.1177/1029864914542842
   Quinto L, 2014, PSYCHOL MUSIC, V42, P503, DOI 10.1177/0305735613482023
   Rogers N., 2014, MUSIC SIGHT SINGING
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Scherer K.R., 2017, PSYCHOMUSICOL MUSIC, V27, P244, DOI DOI 10.1037/PMU0000193
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Simon R, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00776
   Sundberg J., 2013, J VOICE, V27, P1
   Tan D, 2017, MUSIC PERCEPT, V34, P352, DOI 10.1525/MP.2017.34.3.352
   Temperley D, 2013, MUSIC PERCEPT, V30, P237, DOI 10.1525/mp.2012.30.3.237
   Woody R. H., 2002, RES STUDIES MUSIC ED, V18, P57, DOI DOI 10.1177/1321103X020180010701
   Woody RH, 2006, J RES MUSIC EDUC, V54, P125, DOI 10.1177/002242940605400204
   Zhang CQ, 2016, PSYCHOL SPORT EXERC, V22, P279, DOI 10.1016/j.psychsport.2015.09.005
NR 47
TC 3
Z9 5
U1 0
U2 6
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0305-7356
EI 1741-3087
J9 PSYCHOL MUSIC
JI Psychol. Music
PD JUL
PY 2020
VL 48
IS 4
BP 495
EP 512
DI 10.1177/0305735618809873
PG 18
WC Psychology, Educational; Psychology, Applied; Music; Psychology,
   Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Psychology; Music
GA MG1KV
UT WOS:000545792700003
DA 2024-01-09
ER

PT J
AU Felsberger, H
AF Felsberger, Helga
TI Vocal Matrix and Group Attachment - How Listening and Speaking in Groups
   Enable Mentalized Affectivity and Epistemic Trust
SO GRUPPENPSYCHOTHERAPIE UND GRUPPENDYNAMIK
LA German
DT Article
DE communicative relatedness in groups; communicative blockage; affective
   prosody; pathic (affective contagion) and phatic (contact keeping)
   function of language; social feedback mechanism; intersubjective and
   intercorporeal; joint social attention and intention
ID NATURAL PEDAGOGY; ENVIRONMENT; SPEECH; EVOLUTION; COGNITION; EMOTION;
   ORIGINS; MUSIC; VOICE
AB In group contexts and especially in group psychotherapy, speaking and listening should be seen in a totally different light in order to understand their crucial role in enhancing mentalized affectivity and epistemic trust. The inter-corporeal activity of speaking and listening in the context of a face-to-face exchange between co-present participants is claimed to be the core element of group attachment. This event is part of an intersubjective space and described by means of the concept of the "vocal matrix", which refers to S. H. Foulkes' concept of the group matrix. Similarities in the evolution and the development (phylo-and ontogenesis) of speaking and listening as well as their actual genesis in a communicative event are discussed. Putting aside a logos oriented view on language, its pathic (affective contagion) and phatic (contact keeping) function and therewith its importance as the social feedback mechanism is highlighted.
C1 [Felsberger, Helga] OAGG, Psychotherapeut Ambulanz, Vienna, Austria.
   [Felsberger, Helga] OAGG, Vienna, Austria.
   [Felsberger, Helga] SGAZ Zurich, Zurich, Switzerland.
   [Felsberger, Helga] Webster Vienna Private Univ, Vienna, Austria.
C3 Webster Vienna Private University
RP Felsberger, H (corresponding author), Neubaugasse 45-2-55, A-1070 Vienna, Austria.
EM helga.felsberger@gmx.at
CR Alba-Ferrara L. M., 2011, THESIS
   [Anonymous], GRUPPENANALYSE
   [Anonymous], J MENTAL HLTH
   [Anonymous], 1 RELATIONSHIP
   [Anonymous], DER GEGENWARTSMOMENT
   [Anonymous], 2015, Temporality in interaction
   Aristoteles, 1952, GREAT BOOKS W WORLD, V9
   Bahktin M., 1979, ASTHETIK WORTES
   Bateman A., 2008, Psychotherapie der Borderline-Personlichkeitsstorung: Ein mentalisierungsgestutztes Behandlungskonzept
   Bateman AW, 2004, J PERS DISORD, V18, P36, DOI 10.1521/pedi.18.1.36.32772
   Blasi A, 2011, CURR BIOL, V21, P1220, DOI 10.1016/j.cub.2011.06.009
   Bogner A., 2004, INTERNET Z KULTURWIS
   Brizic K, 2006, INT J APPL LINGUIST, V16, P339, DOI 10.1111/j.1473-4192.2006.00122.x
   Brod M., 1938, ABENDTEUER IN JAPAN
   Burrow T, 1926, IMAGO, V12, P211
   Callan DE, 2006, NEUROIMAGE, V31, P1327, DOI 10.1016/j.neuroimage.2006.01.036
   Chomsky Noam, 1975, Reflections on Language
   Corballis MC, 1999, AM SCI, V87, P138, DOI 10.1511/1999.20.810
   Csibra G, 2006, ATTENTION PERFORM, P249
   Csibra G, 2011, PHILOS T R SOC B, V366, P1149, DOI 10.1098/rstb.2010.0319
   Csibra G, 2009, TRENDS COGN SCI, V13, P148, DOI 10.1016/j.tics.2009.01.005
   Darwin G., 1871, P423
   ELIAS N, 1990, N ELIAS SICH SELBST
   Enfield N. J., 2009, ANATOMY MEANING
   Euler M., 1990, GRUNDPRINZIPIEN SELB, P31
   Fietz R., 1992, MUSIK SPRACHE SCHRIF
   Fitch WT, 2010, NEURON, V65, P795, DOI 10.1016/j.neuron.2010.03.011
   Fitch WT, 2000, TRENDS COGN SCI, V4, P258, DOI 10.1016/S1364-6613(00)01494-7
   Flakne A, 2007, PHILOS TODAY, V51, P42, DOI 10.5840/philtoday200751Supplement6
   Fonagy P., 2004, MENTALISIERUNG ENTWI
   Fonagy P, 2017, INT J GROUP PSYCHOTH, V67, P176, DOI 10.1080/00207284.2016.1263156
   Fonagy P, 2015, J PERS DISORD, V29, P575, DOI 10.1521/pedi.2015.29.5.575
   Fonagy P, 2014, PSYCHOTHERAPY, V51, P372, DOI 10.1037/a0036505
   Foulkes S. H., 1992, GRUPPENANALYTISCHE P
   Foulkes S. H., 1975, GROUP ANAL PSYCHOTHE
   Foulkes S. H., 1957, Group Psychotherapy. The Psychoanalytic Approach
   FOULKES SH, 1973, SELECTED PAPERS, P223
   Foulkes SH., 1964, Therapeutic group analysis
   FOULKES SH, 1990, SELECTED PAPERS
   Friedman R., 2004, INT J COUNSELING PSY, V2, P108
   Frota S., 2011, STUDIES NATURAL LANG
   Fuchs M, 2008, LARYNGO RHINO OTOL, V87, P10, DOI 10.1055/s-2007-995343
   Greenspan SI, 2007, ERSTE GEDANKE FRUHKI
   Henke W., 2015, REIHE FISCHER KOMPAK
   Heyes C, 2016, PERSPECT PSYCHOL SCI, V11, P280, DOI 10.1177/1745691615621276
   Hobson Peter, 2002, The cradle of thought
   Hooker CI, 2003, COGNITIVE BRAIN RES, V17, P406, DOI 10.1016/S0926-6410(03)00143-5
   Jaffe J, 2001, MONOGR SOC RES CHILD, V66, P1, DOI 10.1111/1540-5834.00137
   Jakobson Roman, 1960, InStyle in language, DOI DOI 10.1371/JOURNAL.PONE.0098679
   Jentschke S, 2008, J COGNITIVE NEUROSCI, V20, P1940, DOI 10.1162/jocn.2008.20135
   Jourdain R., 1997, WOHLTEMPERIERTE GEHI
   Jürgens U, 1998, NATURWISSENSCHAFTEN, V85, P376, DOI 10.1007/s001140050519
   Jürgens U, 2002, NEUROSCI BIOBEHAV R, V26, P235, DOI 10.1016/S0149-7634(01)00068-9
   Köhncke D, 2012, GRUPPENPSYCHOTHER GR, V48, P26
   Koelsch S, 2006, HUM BRAIN MAPP, V27, P239, DOI 10.1002/hbm.20180
   Koelsch S., 2008, MUSIKTHERAPEUTISCHE, V29, P201
   Kramer S., 2005, SEKUNDARE ORALITAT
   Kramer S., 2006, REHABILITIERUNG STIM
   Kramer Sybille, 2003, MEDIEN STIMMEN, P65
   Kunert R., 2015, DOPPELTE HERAUSFORDE
   Lorenzer A., 1972, KRITIK PSYCHOANALYTI
   Losener H., 1997, Z LINGUISTIK LITERAT, V106, P139
   MALINOWSKI Bronislaw, 1923, The meaning of meaning: A study of the influence of language upon thought and of the science of symbolism, P296
   Malloch S., 1999, MUSIC SCI, P13, DOI DOI 10.1177/10298649000030S104
   Malloch S., 2009, COMMNICATIVE MUSICAL
   Mattos O, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01424
   Mead George H., 1934, Mind, self, and society: From the standpoint of a social behaviorist
   Mehler J., 1993, WHAT INFANTS KNOW
   Merleau-Ponty M., 1945, The phenomenology of perception
   Mies T., 1992, ARBEITSHEFTE GRUPPEN, P1
   Mies T., 2015, GROUP ANAL, V48, P455
   Mithen S, 2006, CAMB ARCHAEOL J, V16, P97, DOI 10.1017/S0959774306000060
   Muller K., 1999, RHYTHMUS SPRACHE EIN
   Murakami Y., 2011, PHENOMENOLOGY COGNIT
   Nakao H, 2014, REV PHILOS PSYCHOL, V5, P465, DOI 10.1007/s13164-014-0187-2
   Nietzsche F., 1980, SAMTLICHE WERKE KRIT
   Nietzsche F., 1956, UNSCHULD WERDEN NACH, VI
   Nitzgen D., 2017, SGAZ SEM GRUPP UNPUB
   Ogden T. H., 2004, GESPRACHE ZWISCHENRE
   Özdemir E, 2006, NEUROIMAGE, V33, P628, DOI 10.1016/j.neuroimage.2006.07.013
   Parncutt R., 2006, CHILD MUSICIAN, P1, DOI DOI 10.1093/ACPROF:OSO/9780198530329.003.0001
   Partanen E, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0078946
   Pinker Steven, 1994, The language instinct
   Reddy V., 2008, How Infants Know Minds
   Rizzolatti G, 2004, ANNU REV NEUROSCI, V27, P169, DOI 10.1146/annurev.neuro.27.070203.144230
   Rossell SL, 2013, PSYCHIAT RES, V210, P896, DOI 10.1016/j.psychres.2013.07.037
   Scholz R., 2004, GRUPPENANALYSE, V2, P147
   Schultz-Venrath U., 2016, MENTALISIEREN GRUPPE
   Selting Margaret, 2000, Gesprachsforschung-Online-Zeitschrift zur verbalen Interaktion, V1, P76
   Sloterdijk Peter., 1983, Kritik der zynischen Vernunft
   Sperber D, 2010, MIND LANG, V25, P359, DOI 10.1111/j.1468-0017.2010.01394.x
   Sperber Dan., 1995, Relevance: Communication and cognition, V2nd ed.
   Stern D.N., 1995, Motherhood Constellation
   Stern DN, 1985, The interpersonal world of the infant
   Tawada Y., 1998, VERWANDLUNGEN TUBING
   Tomasello M., 2001, The cultural origins of human cognition
   Tomasello M, 2008, JEAN NICOD LECT, P1
   Tomasello M, 2010, CURR DIR PSYCHOL SCI, V19, P3, DOI 10.1177/0963721409359300
   Tomasello Michael, 2014, NATURGESCHICHTE MENS
   Tomatis A., 1978, OREILLE LANGAGE
   Tost H, 2012, NAT MED, V18, P211, DOI 10.1038/nm.2671
   Trabant J., 1988, MAT KOMMUNIKATION, P63
   Trehub SE, 2003, NAT NEUROSCI, V6, P669, DOI 10.1038/nn1084
   Trotzke A., 2017, SPRACHEVOLUTION EINF
   Van Os J, 2004, BRIT J PSYCHIAT, V184, P287, DOI 10.1192/bjp.184.4.287
   van Os J, 2010, NATURE, V468, P203, DOI 10.1038/nature09563
   von Foerster Heinz, 1993, Wissen und Gewissen. Versuch einer Brucke, P211
   Vygotskij L., 1934, DENKEN SPRECHEN PSYC
   Waldenfels B, 2011, STUD PHENOM EXISTEN, P1
   Waldenfels Bernhard, 2003, MEDIEN STIMMEN, P19
   Waldenfels Bernhard, 2007, The Question of the Other
   WIERLACHER A, 1993, KULTURTHEMA FREMDHEI
   Wildgruber D, 2004, CEREB CORTEX, V14, P1384, DOI 10.1093/cercor/bhh099
   Wilson Deirdre, 2012, Meaning and Relevance
   Wotton L., 2015, GROUP ANAL, V48, P447
   Zahavi D., 2005, Subjectivity and selfhood. Investigating the first-person perspective
   Zahavi D., 2007, ROYAL I PHILOS S, V60
   Zahavi D, 2010, AUTISM, V14, P547, DOI 10.1177/1362361310370040
   Zahavi D, 2009, INQUIRY, V52, P551, DOI 10.1080/00201740903377826
NR 119
TC 3
Z9 3
U1 0
U2 3
PU VANDENHOECK & RUPRECHT GMBH & CO KG
PI GOTTINGEN
PA VIENNA UNIV PRESS, ROBERT BOSCH BREITE 6, D-37079 GOTTINGEN, GERMANY
SN 0017-4947
EI 2196-7989
J9 GRUPPENPSYCHOTHER GR
JI Gruppenpsychother. Gruppendyn.
PY 2017
VL 53
IS 3
BP 188
EP 225
DI 10.13109/grup.2017.53.3.188
PG 38
WC Psychology, Clinical
WE Social Science Citation Index (SSCI)
SC Psychology
GA FI8UL
UT WOS:000412277500001
DA 2024-01-09
ER

PT J
AU Wan, MX
AF Wan, Mingxia
TI Designing an online vocal learning based on ZigBee-enabled wireless
   platform
SO WIRELESS NETWORKS
LA English
DT Article; Early Access
DE Vocal music singing; Online learning platform; Hadoop; Spectrum
   characteristics; Emotion; Music score; ZigBee network; Cloud platform;
   Wireless network
ID RESOURCE-ALLOCATION; INTERNET; NOMA
AB Vocal learning has found its proliferation in recent years due to the advancement in wireless networking. Vocal art encompasses profound cultural values and aesthetic preferences, making wireless platforms, e.g. Wi-Fi and ZigBee, essential for the enhancement of online vocal learning. ZigBee, as a wireless platform, has more recently been used quite frequently for online vocal learning and music. This paper aims to design an efficient wireless-enabled platform by using the lightweight features of ZigBee to support online vocal learning and expressions. The platform enables data transmission, storage, analysis, and playback of vocal learning sounds through the ZigBee network. It is built on a cloud platform, utilizing Docker virtualization technology to deploy a Hadoop distributed cluster, effectively simulating a distributed environment. The platform incorporates a model for recognizing musical sound and noise signals, empowering the online learning control platform to detect various characteristics of vocal music tones. Vocal music learning is enhanced by extracting endpoint fusion spectrum features and employing a tone adjustment and dynamic detection model. The proposed method improves anti-interference capability, online learning control, vocal tone recognition, and emotional expression accuracy. Simulation results demonstrate its effectiveness in vocal music, online learning control, and tone recognition, leading to more precise vocal music pronunciation and intonation registration.
C1 [Wan, Mingxia] Nanjing Normal Univ, Taizhou Coll, Taizhou, Jiangsu, Peoples R China.
C3 Nanjing Normal University
RP Wan, MX (corresponding author), Nanjing Normal Univ, Taizhou Coll, Taizhou, Jiangsu, Peoples R China.
EM 2015021221@mailc.qjnu.edu.cn
CR Aslam A, 2020, IEEE SIGNAL PROC LET, V27, P2109, DOI 10.1109/LSP.2020.3039425
   Bedoya D, 2021, PHILOS T R SOC B, V376, DOI 10.1098/rstb.2020.0396
   Benalia E, 2020, T EMERG TELECOMMUN T, V31, DOI 10.1002/ett.3881
   Besser A, 2022, J VOICE, V36, DOI 10.1016/j.jvoice.2020.05.028
   Cao KR, 2021, IEEE T VEH TECHNOL, V70, P1978, DOI 10.1109/TVT.2021.3053093
   Cao KR, 2021, IEEE T INF FOREN SEC, V16, P786, DOI 10.1109/TIFS.2020.3023277
   Castro VP., 2022, PALGR COMMUN, V9, P1
   Chen W., 2016, WIRELESS PERS COMMUN, V86, P729
   He H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20174878
   Huizen R., 2021, INDONESIAN J ELECT E, V24, P815
   Hunter EJ., 2022, J VOICE OFFICIAL J V, V63, P221
   Kong H, 2021, IEEE T MOBILE COMPUT, V20, P3148, DOI 10.1109/TMC.2020.2994955
   Li B, 2022, IEEE T WIREL COMMUN, V21, P4579, DOI 10.1109/TWC.2021.3131384
   Li B, 2022, IEEE T WIREL COMMUN, V21, P4594, DOI 10.1109/TWC.2021.3131595
   Lu SY, 2023, INT J COMPUT INT SYS, V16, DOI 10.1007/s44196-023-00233-6
   Lv ZH, 2022, IEEE COMMUN MAG, V60, P68, DOI 10.1109/MCOM.004.2100990
   Mi C, 2022, J MAR SCI ENG, V10, DOI 10.3390/jmse10121961
   Mini PP, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102625
   Nikoukar A, 2018, IEEE ACCESS, V6, P67893, DOI 10.1109/ACCESS.2018.2879189
   Orand A., 2015, INT J ELECT COMPUTER, V5, P2088
   Pandiyan S, 2020, COMPUT COMMUN, V160, P512, DOI 10.1016/j.comcom.2020.06.016
   Paul A, 2021, PLOS COMPUT BIOL, V17, DOI 10.1371/journal.pcbi.1008820
   Peng ZN, 2020, APPL MATH COMPUT, V369, DOI 10.1016/j.amc.2019.124821
   Riddell F, 2020, VICTORIAN LIT CULT, V48, P485, DOI 10.1017/S1060150319000020
   Soundarya B., 2021, IOP Conference Series: Materials Science and Engineering, V1084, DOI 10.1088/1757-899X/1084/1/012020
   Sun J, 2020, COMPUT COMMUN, V160, P342, DOI 10.1016/j.comcom.2020.05.016
   Swan M, 2012, J SENS ACTUAR NETW, V1, P217, DOI 10.3390/jsan1030217
   Tian H, 2020, IEEE ACCESS, V8, P6117, DOI 10.1109/ACCESS.2019.2962009
   Tyack PL, 2020, PHILOS T R SOC B, V375, DOI 10.1098/rstb.2018.0406
   Upadhyaya Vivek, 2021, IOP Conference Series: Materials Science and Engineering, V1119, DOI 10.1088/1757-899X/1119/1/012005
   Wang H., 2023, IEEE Trans. Knowl. Data Eng.
   Wang J., 2019, J PHYS C SERIES, V1194
   Yalagi PS., 2021, J PHYS C SERIES, V1854
   Yao F, 2008, MEAS CONTROL-UK, V41, P310, DOI 10.1177/002029400804101003
NR 34
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1022-0038
EI 1572-8196
J9 WIREL NETW
JI Wirel. Netw.
PD 2023 AUG 16
PY 2023
DI 10.1007/s11276-023-03443-0
EA AUG 2023
PG 14
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA P2RI8
UT WOS:001049159600002
DA 2024-01-09
ER

PT J
AU Li, XF
   Shi, XH
   Hu, DS
   Li, YW
   Zhang, QC
   Wang, ZX
   Unoki, M
   Akagi, M
AF Li, Xingfeng
   Shi, Xiaohan
   Hu, Desheng
   Li, Yongwei
   Zhang, Qingchen
   Wang, Zhengxia
   Unoki, Masashi
   Akagi, Masato
TI Music Theory-Inspired Acoustic Representation for Speech Emotion
   Recognition
SO IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING
LA English
DT Article
DE Affective computing; speech emotion recognition; acoustic
   representation; music theory and speech analysis
ID PERCEPTION; EXPRESSION; PATTERNS; FEATURES; PITCH; PERSPECTIVE;
   MODALITIES; KNOWLEDGE; INTERVALS; COGNITION
AB This research presents a music theory-inspired acoustic representation (hereafter, MTAR) to address improved speech emotion recognition. The recognition of emotion in speech and music is developed in parallel, yet a relatively limited understanding of MTAR for interpreting speech emotions is involved. In the present study, we use music theory to study representative acoustics associated with emotion in speech from vocal emotion expressions and auditory emotion perception domains. In experiments assessing the role and effectiveness of the proposed representation in classifying discrete emotion categories and predicting continuous emotion dimensions, it shows promising performance compared with extensively used features for emotion recognition based on the spectrogram, Mel-spectrogram, Mel-frequency cepstral coefficients, VGGish, and the large baseline feature sets of the INTERSPEECH challenges. This proposal opens up a novel research avenue in developing a computational acoustic representation of speech emotion via music theory.
C1 [Li, Xingfeng; Zhang, Qingchen] Hainan Univ, Grad Sch Comp Sci & Technol, Haikou 570288, Peoples R China.
   [Shi, Xiaohan] Nagoya Univ, Sch Informat Sci, Nagoya 4648601, Japan.
   [Hu, Desheng] Taiyuan Univ Technol, Coll Informat & Comp, Taiyuan 030024, Peoples R China.
   [Li, Yongwei] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
   [Wang, Zhengxia] Hainan Univ, Sch Comp Sci & Technol, Haikou 570288, Peoples R China.
   [Unoki, Masashi; Akagi, Masato] Japan Adv Inst Sci & Technol, Sch Informat Sci, Nomi 9231292, Japan.
C3 Hainan University; Nagoya University; Taiyuan University of Technology;
   Chinese Academy of Sciences; Institute of Automation, CAS; Hainan
   University; Japan Advanced Institute of Science & Technology (JAIST)
RP Li, XF (corresponding author), Hainan Univ, Grad Sch Comp Sci & Technol, Haikou 570288, Peoples R China.
EM lixingfeng@hainanu.edu.cn; shi.xiaohan.t6@s.mail.nagoya-u.ac.jp;
   718416067@qq.com; yongwei.li@nlpr.ia.ac.cn; 623759909@qq.com;
   zxiawang@163.com; unoki@jaist.ac.jp; akagi@jaist.ac.jp
RI Li, Yongwei/JJE-8562-2023
OI SHI, Xiaohan/0000-0002-1917-4479; LI, Xingfeng/0000-0002-8958-0341
FU Key Research and Development Program of Hainan Province
   [ZDYF2021GXJS017]; National Natural Science Foundation of China
   [82160345, 62201571]; Key Science and Technology Plan Project of Haikou
   [2021-016]
FX This work was supported in part by the Key Research and Development
   Program of Hainan Province under Grant ZDYF2021GXJS017, in part by the
   National Natural Science Foundation of China under Grants 82160345 and
   62201571, and in part by the Key Science and Technology Plan Project of
   Haikou under Grant 2021-016. The associate editor coordinating the
   review of this manuscript and approving it for publication was Dr.
   Alberto Abad. (Corresponding author: Xingfeng Li.)
CR Adachi M., 1998, PSYCHOL MUSIC, V26, P133, DOI [DOI 10.1177/0305735698262003, 10.1177/0305735698262003]
   Akçay MB, 2020, SPEECH COMMUN, V116, P56, DOI 10.1016/j.specom.2019.12.001
   Albers C. J., 2020, EUR J PSYCHOL ASSESS
   Apel W., 2003, The Harvard dictionary of music
   Atmaja B. T., 2021, Journal of Physics: Conference Series, V1896, DOI 10.1088/1742-6596/1896/1/012004
   Atmaja BT, 2020, ASIAPAC SIGN INFO PR, P325
   Atmaja BT, 2021, SPEECH COMMUN, V126, P9, DOI 10.1016/j.specom.2020.11.003
   Barrett L. F., 2014, PSYCHOL CONSTRUCTION
   Benson D., 2006, Music: a mathematical offering
   Bergman P, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01565
   Bernstein L., 1976, UNANSWERED QUESTION, V33
   Blanchard DC, 2001, NEUROSCI BIOBEHAV R, V25, P761
   Brown S, 2001, ANN NY ACAD SCI, V930, P372, DOI 10.1111/j.1749-6632.2001.tb05745.x
   Brown S, 2000, ORIGINS OF MUSIC, P3
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Byun SW, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11041890
   Castellano G, 2008, LECT NOTES COMPUT SC, V4868, P92, DOI 10.1007/978-3-540-85099-1_8
   Choi E., 2022, ARXIV
   Clynes M, 2013, MUSIC MIND BRAIN NEU
   Darwin C., 1948, The Expression Of The Emotions In Man And Animals
   Denes P.B., 1993, The Speech Chain
   Deza M.M., 2014, ENCY DISTANCES
   Drugman T, 2019, Arxiv, DOI [arXiv:2001.00459, 10.48550/ARXIV.2001.00459, DOI 10.48550/ARXIV.2001.00459]
   Ekman P. E., 1994, The nature of emotion: fundamental questions
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   El-Amine A, 2019, IEEE WCNC
   Ellis Alexander J., 1885, Journal of the Society of Arts, V33, P1102
   Elowsson A, 2017, J ACOUST SOC AM, V141, P2224, DOI 10.1121/1.4978245
   Eyben F., 2010, P 18 ACM INT C MULT, P1459, DOI [DOI 10.1145/1873951.1874246, 10.1145/1873951.1874246]
   Eyben F, 2013, INTERSPEECH, P2043
   Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417
   Falk S, 2014, J EXP PSYCHOL HUMAN, V40, P1491, DOI 10.1037/a0036858
   Fujisawa T., 2003, P ISCA IEEE WORKSH S
   Gabrielsson A., 2003, EMOTIONAL EXPRESSION
   Gilleade K., 2005, DIGRA 2005 CHANGING
   Grandjean D, 2021, EMOT REV, V13, P34, DOI 10.1177/1754073919898522
   Griffiths P. E., 2005, Emotions in the wild: The situated perspective on emotion, V2, P256
   Guo LL, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6304, DOI 10.1109/ICASSP39728.2021.9414006
   Han WJ, 2020, INT CONF ACOUST SPEE, P6494, DOI [10.1109/icassp40776.2020.9053648, 10.1109/ICASSP40776.2020.9053648]
   Haque A, 2004, J RELIG HEALTH, V43, P357, DOI 10.1007/s10943-004-4302-z
   Harnmerschmidt K, 2007, J VOICE, V21, P531, DOI 10.1016/j.jvoice.2006.03.002
   HekmatiAthar S. P., 2021, ARXIV
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Hinrichsen Haye, 2016, Rev. Bras. Ensino Fís., V38, P1310, DOI 10.1590/S1806-11173812105
   Hudspeth AJ, 2000, P NATL ACAD SCI USA, V97, P11765, DOI 10.1073/pnas.97.22.11765
   i Vallet E. R., 2016, SONANCIA CLARIFICACI
   Jackendoff R, 1982, MUSIC MIND BRAIN, P83
   Jäncke L, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00123
   James W., 1948, WHAT IS EMOTION
   Janssen JH, 2012, USER MODEL USER-ADAP, V22, P255, DOI 10.1007/s11257-011-9107-7
   Jentschke S., 2015, RELATIONSHIP MUSIC L
   Jiang L, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5427
   Jozefowicz R, 2015, PR MACH LEARN RES, V37, P2342
   Juslin P. N., 2011, HDB MUSIC EMOTION TH
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kagan J., 2007, WHAT IS EMOTION HIST
   Kaiser J. F., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P149, DOI 10.1109/ICASSP.1993.319457
   KAISER JF, 1990, INT CONF ACOUST SPEE, P381, DOI 10.1109/ICASSP.1990.115702
   Kaygusuz C, 2018, Arxiv, DOI arXiv:1812.04723
   Keesing A, 2021, INTERSPEECH, P3415, DOI 10.21437/Interspeech.2021-2217
   Khan P, 2023, IEEE T AFFECT COMPUT, V14, P1520, DOI 10.1109/TAFFC.2021.3114123
   Kivy P., 1989, Sound Sentiment: An Essay on the Musical Emotions
   Kollias D, 2021, IEEE T AFFECT COMPUT, V12, P595, DOI 10.1109/TAFFC.2020.3014171
   Kooyman G. L., 2012, DIVERSE DIVERS PHYSL, V23
   Krishna DN, 2020, INTERSPEECH, P4243, DOI 10.21437/Interspeech.2020-1190
   Krumhansl CL, 2004, J NEW MUSIC RES, V33, P253, DOI 10.1080/0929821042000317831
   Kumar TM, 2021, INTERSPEECH, P3390, DOI 10.21437/Interspeech.2021-610
   Lahdelma I, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65615-8
   Laukka P, 2021, EMOT REV, V13, P3, DOI 10.1177/1754073919897295
   Lerdahl F., 1987, Contemporary Music Review, V2, P135, DOI [DOI 10.1080/07494468708567056, 10.1080/07494468708567056]
   Lerdahl Fred, 1983, A generative theory of tonal music
   LESSER R, 1974, Cortex, V10, P247
   Li HQ, 2020, INT CONF ACOUST SPEE, P7144, DOI [10.1109/ICASSP40776.2020.9054580, 10.1109/icassp40776.2020.9054580]
   Li RC, 2021, INTERSPEECH, P4488, DOI 10.21437/Interspeech.2021-785
   Li XF, 2019, SPEECH COMMUN, V110, P1, DOI 10.1016/j.specom.2019.04.004
   Li YW, 2021, IEEE-ACM T AUDIO SPE, V29, P3375, DOI 10.1109/TASLP.2021.3120585
   Lim W, 2016, ASIAPAC SIGN INFO PR, DOI 10.1109/APSIPA.2016.7820699
   Lin M, 2014, Arxiv, DOI [arXiv:1312.4400, DOI 10.48550/ARXIV.1312.4400]
   Lonsdale AJ, 2011, BRIT J PSYCHOL, V102, P108, DOI 10.1348/000712610X506831
   Mandler G., 1984, Mind and body: Psychology of emotion and stress
   McDermott JH, 2010, J ACOUST SOC AM, V128, P1943, DOI 10.1121/1.3478785
   McDermott JH, 2008, CURR OPIN NEUROBIOL, V18, P452, DOI 10.1016/j.conb.2008.09.005
   Metallinou A, 2011, INT CONF ACOUST SPEE, P2288
   MIDI Complete, 1996, MIDI COMPL 1 0 DET S
   MIYAZAKI K, 1989, MUSIC PERCEPT, V7, P1
   Müller M, 2010, IEEE T AUDIO SPEECH, V18, P649, DOI 10.1109/TASL.2010.2041394
   Neumann M, 2019, INT CONF ACOUST SPEE, P7390, DOI 10.1109/ICASSP.2019.8682541
   Nikolsky A, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00075
   Noh KJ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051579
   Oliveira AP, 2010, KNOWL-BASED SYST, V23, P901, DOI 10.1016/j.knosys.2010.06.006
   Panda R, 2023, IEEE T AFFECT COMPUT, V14, P68, DOI 10.1109/TAFFC.2020.3032373
   Panda R, 2020, IEEE T AFFECT COMPUT, V11, P614, DOI 10.1109/TAFFC.2018.2820691
   Panksepp J., 2004, Affective Neuroscience
   Patel AD, 2010, MUSIC LANGUAGE BRAIN
   Pedregosa F., 2011, JMLR, V12, P2825
   Pepino L, 2021, Arxiv, DOI arXiv:2104.03502
   Picard Rosalind W, 2000, Affective Computing
   Prout E., 2011, HARMONY ITS THEORY P
   Ross D, 2007, P NATL ACAD SCI USA, V104, P9852, DOI 10.1073/pnas.0703140104
   Rudovic O, 2021, Arxiv, DOI arXiv:2101.04800
   Ryan D, 2016, ARXIV
   Sadie S., 2001, DICT MUSIC MUSICIANS
   Sandner M, 2021, NEUROPSYCHOLOGIA, V157, DOI 10.1016/j.neuropsychologia.2021.107876
   Sauter DA, 2013, BRIT J DEV PSYCHOL, V31, P97, DOI 10.1111/j.2044-835X.2012.02081.x
   Schacter D. L., 2009, PSYCHOLOGY, V10010
   Scherer KR, 2017, J ACOUST SOC AM, V142, P1805, DOI 10.1121/1.5002886
   Scherer Klaus R., 2015, P INTERSPEECH
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Schuller B, 2016, INTERSPEECH, P2001, DOI 10.21437/Interspeech.2016-129
   Schuller B, 2013, INTERSPEECH, P148
   Schuller B, 2015, COMPUT SPEECH LANG, V29, P100, DOI 10.1016/j.csl.2014.08.003
   Schuller B, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P254
   Schuller B, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P3208
   Schuller B, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2798
   Schuller B, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P336
   Schuller BW, 2018, COMMUN ACM, V61, P90, DOI 10.1145/3129340
   Schuller B, 2014, INTERSPEECH, P427
   Schwarz N., 1990, Feelings as Information: Informational and Motivational Functions of Affective States, DOI DOI 10.2307/2072281
   Seeman TE, 2001, HEALTH PSYCHOL, V20, P243, DOI 10.1037//0278-6133.20.4.243
   Shahraki S. K., 2021, J INTELL PROCEDURES, V12, P1
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Slawson W., 1985, Sound Color
   Spring G., 2013, MUSICAL FORM ANAL TI
   Stalinski SM, 2012, TOP COGN SCI, V4, P485, DOI 10.1111/j.1756-8765.2012.01217.x
   Stewart L, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0001470
   Suchy Y., 2011, CLIN NEUROPSYCHOLOGY
   Sundberg J, 2021, J VOICE, V35, P52, DOI 10.1016/j.jvoice.2019.08.007
   Sundberg J, 2011, IEEE T AFFECT COMPUT, V2, P162, DOI 10.1109/T-AFFC.2011.14
   Swanwick K., 2003, MUSIC MIND ED
   Tan, 2017, PSYCHOL MUSIC SOUND
   Tandra A, 2020, IEEE-ACM T AUDIO SPE, V28, P976, DOI 10.1109/TASLP.2020.2977776
   Tao JH, 2005, LECT NOTES COMPUT SC, V3784, P981
   TAYLOR GJ, 1984, AM J PSYCHIAT, V141, P725
   The Laogai Research Foundation (TLRF), 2008, LAOG HDB 2007 2008
   Thiemel M., 2001, DYNAMICS GROVE MUSIC
   THOITS PA, 1989, ANNU REV SOCIOL, V15, P317
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Tillmann B, 2005, ANN NY ACAD SCI, V1060, P100, DOI 10.1196/annals.1360.007
   Tobin K., 2013, LEARNING ENVIRON RES, V16, P71, DOI DOI 10.1007/S10984-013-9125-Y
   Trehub SE, 2001, MUSIC SCI, V5, P37, DOI 10.1177/10298649020050S103
   Tria Assia, 2021, 2021 IEEE International Electron Devices Meeting (IEDM), P1, DOI 10.1109/IEDM19574.2021.9720637
   Trigeorgis G, 2016, INT CONF ACOUST SPEE, P5200, DOI 10.1109/ICASSP.2016.7472669
   Unoki M, 2020, ACOUST SCI TECHNOL, V41, P233, DOI 10.1250/ast.41.233
   Vidas D., 2018, MUSIC SCI, V1, p205920431876265, DOI [10.1177/2059204318762650, DOI 10.1177/2059204318762650]
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   Warrier CM, 2002, PERCEPT PSYCHOPHYS, V64, P198, DOI 10.3758/BF03195786
   Williams R, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01950
   Wilson TD, 2004, ANNU REV PSYCHOL, V55, P493, DOI 10.1146/annurev.psych.55.090902.141954
   Wu CH, 2016, BRIT J EDUC TECHNOL, V47, P1304, DOI 10.1111/bjet.12324
   Wu SQ, 2011, SPEECH COMMUN, V53, P768, DOI 10.1016/j.specom.2010.08.013
   Wu XX, 2022, INT CONF ACOUST SPEE, P6902, DOI 10.1109/ICASSP43922.2022.9746155
   Yang B, 2010, SIGNAL PROCESS, V90, P1415, DOI 10.1016/j.sigpro.2009.09.009
   Yao ZW, 2020, SPEECH COMMUN, V120, P11, DOI 10.1016/j.specom.2020.03.005
   Yonck Richard, 2020, HEART MACHINE OUR FU, P1
   Yuan JH, 2021, Arxiv, DOI arXiv:2108.01132
   Zhang Ruidong, 2021, PROC ACM INTERACT MO, V5, P1
   Zwicker E., 2013, Psychoacoustics: Facts and models, Vvol 22
NR 159
TC 0
Z9 0
U1 11
U2 11
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2329-9290
EI 2329-9304
J9 IEEE-ACM T AUDIO SPE
JI IEEE-ACM Trans. Audio Speech Lang.
PY 2023
VL 31
BP 2534
EP 2547
DI 10.1109/TASLP.2023.3289312
PG 14
WC Acoustics; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Acoustics; Engineering
GA L8BU0
UT WOS:001025466100003
DA 2024-01-09
ER

PT J
AU Weijkamp, J
   Sadakata, M
AF Weijkamp, Janne
   Sadakata, Makiko
TI Attention to affective audio-visual information: Comparison between
   musicians and non-musicians
SO PSYCHOLOGY OF MUSIC
LA English
DT Article
DE audio-visual; emotion; perception; speech; training
ID MUSICAL EXPERTISE; BRAIN-STEM; PERCEPTION; INTEGRATION; EMOTIONS;
   SPEECH; EAR
AB Individuals with more musical training repeatedly demonstrate enhanced auditory perception abilities. The current study examined how these enhanced auditory skills interact with attention to affective audio-visual stimuli. A total of 16 participants with more than 5 years of musical training (musician group) and 16 participants with less than 2 years of musical training (non-musician group) took part in a version of the audio-visual emotional Stroop test, using happy, neutral, and sad emotions. Participants were presented with congruent and incongruent combinations of face and voice stimuli while judging the emotion of either the face or the voice. As predicted, musicians were less susceptible to interference from visual information on auditory emotion judgments than non-musicians, as evidenced by musicians being more accurate when judging auditory emotions when presented with congruent and incongruent visual information. Musicians were also more accurate than non-musicians at identifying visual emotions when presented with concurrent auditory information. Thus, musicians were less influenced by congruent/incongruent information in a non-target modality compared to non-musicians. The results suggest that musical training influences audio-visual information processing.
C1 [Weijkamp, Janne; Sadakata, Makiko] Radboud Univ Nijmegen, Artificial Intelligence Dept, Nijmegen, Netherlands.
   [Sadakata, Makiko] Radboud Univ Nijmegen, Ctr Cognit, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
   [Sadakata, Makiko] Univ Amsterdam, Musicol Dept, Amsterdam, Netherlands.
   [Sadakata, Makiko] Univ Amsterdam, Inst Log Language & Commun, Amsterdam, Netherlands.
C3 Radboud University Nijmegen; Radboud University Nijmegen; University of
   Amsterdam; University of Amsterdam
RP Sadakata, M (corresponding author), Radboud Univ Nijmegen, Donders Inst, Montessorilaan 3, NL-6525 HR Nijmegen, Netherlands.
EM m.sadakata@donders.ru.nl
RI Sadakata, Makiko/J-4753-2012
CR Attardo S, 2003, HUMOR, V16, P243, DOI 10.1515/humr.2003.012
   Besson M, 2007, RESTOR NEUROL NEUROS, V25, P399
   Burnham Denis., 2012, AUDIOVISUAL SPEECH P, P62, DOI [10.1017/CBO9780511843891.006, DOI 10.1017/CBO9780511843891.006]
   CHANDLER P, 1991, COGNITION INSTRUCT, V8, P293, DOI 10.1207/s1532690xci0804_2
   Collignon O, 2008, BRAIN RES, V1242, P126, DOI 10.1016/j.brainres.2008.04.023
   de Gelder B, 2000, COGNITION EMOTION, V14, P289, DOI 10.1080/026999300378824
   Donohue SE, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0062802
   Donohue SE, 2013, J COGNITIVE NEUROSCI, V25, P623, DOI 10.1162/jocn_a_00336
   Fujioka T, 2006, BRAIN, V129, P2593, DOI 10.1093/brain/awl247
   Jeong JW, 2011, NEUROIMAGE, V54, P2973, DOI 10.1016/j.neuroimage.2010.11.017
   Lee H, 2011, P NATL ACAD SCI USA, V108, pE1441, DOI 10.1073/pnas.1115267108
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Milovanov R, 2009, NEUROSCI LETT, V460, P161, DOI 10.1016/j.neulet.2009.05.063
   Musacchia G, 2008, HEARING RES, V241, P34, DOI 10.1016/j.heares.2008.04.013
   Rammsayer T, 2006, MUSIC PERCEPT, V24, P37, DOI 10.1525/mp.2006.24.1.37
   Rodrigues AC, 2013, BRAIN COGNITION, V82, P229, DOI 10.1016/j.bandc.2013.04.009
   Sadakata M, 2011, ACTA PSYCHOL, V138, P1, DOI 10.1016/j.actpsy.2011.03.007
   SEKIYAMA K, 1991, J ACOUST SOC AM, V90, P1797, DOI 10.1121/1.401660
   Strait DL, 2010, HEARING RES, V261, P22, DOI 10.1016/j.heares.2009.12.021
   Stroop JR, 1935, J EXP PSYCHOL, V18, P643, DOI 10.1037/h0054651
   Tanaka A, 2010, PSYCHOL SCI, V21, P1259, DOI 10.1177/0956797610380698
   Thompson WF, 2008, COGNITION EMOTION, V22, P1457, DOI 10.1080/02699930701813974
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
NR 24
TC 17
Z9 17
U1 1
U2 20
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0305-7356
EI 1741-3087
J9 PSYCHOL MUSIC
JI Psychol. Music
PD MAR
PY 2017
VL 45
IS 2
BP 204
EP 215
DI 10.1177/0305735616654216
PG 12
WC Psychology, Educational; Psychology, Applied; Music; Psychology,
   Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Psychology; Music
GA ET2JW
UT WOS:000400099100004
DA 2024-01-09
ER

PT J
AU Czajkowski, AML
   Greasley, AE
AF Czajkowski, Anne-Marie L.
   Greasley, Alinka E.
TI Mindfulness for singers: The effects of a targeted mindfulness course on
   learning vocal technique
SO BRITISH JOURNAL OF MUSIC EDUCATION
LA English
DT Article
ID EMOTION REGULATION; STRESS REDUCTION; MUSIC-EDUCATION; SELF-REPORT;
   QUESTIONNAIRE; SPIRITUALITY; RELIABILITY; ATTENTION; BENEFITS; SCHOOLS
AB This paper reports the development and implementation of a unique Mindfulness for Singers (MfS) course designed to improve singers' vocal technique. Eight university students completed the intervention. Five Facet Mindfulness Questionnaire (FFMQ) scores showed general improvement across all five facets of mindfulness. Qualitative results showed benefits of daily mindfulness exercises on breathing, micro-muscular awareness, vocal tone, text communication and problem solving. Exercises also positively affected teacher/pupil relationships, concentration and focus in lessons and practice. Teachers identified six of the eight participants in a blind controlled study indicating that vocal students at any level would benefit greatly from a mindfulness course as a holistic intervention.
C1 [Czajkowski, Anne-Marie L.; Greasley, Alinka E.] Univ Leeds, Sch Mus, Leeds LS2 9JT, W Yorkshire, England.
C3 University of Leeds
RP Czajkowski, AML (corresponding author), Univ Leeds, Sch Mus, Leeds LS2 9JT, W Yorkshire, England.
EM A.M.L.Czajkowski@gmail.com; A.E.Greasley@leeds.ac.uk
RI Greasley, Alinka/AAA-4236-2021; Czajkowski, Anne-Marie/GOK-2219-2022
OI Greasley, Alinka/0000-0001-6262-2655; Czajkowski, Anne-Marie
   L./0000-0001-8013-1534
CR [Anonymous], THESIS
   Baer RA, 2006, ASSESSMENT, V13, P27, DOI 10.1177/1073191105283504
   Baer RA, 2004, ASSESSMENT, V11, P191, DOI 10.1177/1073191104268029
   Baer RA, 2003, CLIN PSYCHOL-SCI PR, V10, P125, DOI 10.1093/clipsy/bpg015
   Baer RA, 2011, ASSESSMENT, V18, P3, DOI 10.1177/1073191110392498
   Beauchemin J, 2008, J EVID-BASED INTEGR, V13, P34, DOI 10.1177/1533210107311624
   Bishop SR, 2004, CLIN PSYCHOL-SCI PR, V11, P230, DOI 10.1093/clipsy/bph077
   Braun V., 2006, Qual. Res. Psychol, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Brown KW, 2007, PSYCHOL INQ, V18, P211, DOI 10.1080/10478400701598298
   Brown KW, 2003, J PERS SOC PSYCHOL, V84, P822, DOI 10.1037/0022-3514.84.4.822
   Buchheld N., 2001, Journal for Meditation and Meditation Research, V1, P11
   BURNETT R, 2009, LEARNING LESSONS ADU
   Chadwick P, 2008, BRIT J CLIN PSYCHOL, V47, P451, DOI 10.1348/014466508X314891
   Cowdrey FA, 2012, EAT BEHAV, V13, P100, DOI 10.1016/j.eatbeh.2012.01.001
   Creswell JD, 2007, PSYCHOSOM MED, V69, P560, DOI 10.1097/PSY.0b013e3180f6171f
   CZAJKOWSKI A.-M. L, 2013, THESIS U LEEDS
   DESMOND C. T., 2009, RES REPORT
   ELLIOTT M., 2010, J SINGING, V67
   Esch T., 2014, Meditation-neuroscientific approaches and philosophical implications, P153, DOI DOI 10.1007/978-3-319-01634-4_9
   Farb NAS, 2013, SOC COGN AFFECT NEUR, V8, P15, DOI 10.1093/scan/nss066
   Feldman G, 2007, J PSYCHOPATHOL BEHAV, V29, P177, DOI 10.1007/s10862-006-9035-8
   FISHBEIN M, 1988, MED PROBL PERFORM AR, V3, P1
   Flook L, 2010, J APPL SCH PSYCHOL, V26, P70, DOI 10.1080/15377900903379125
   Frank JL, 2013, RES HUM DEV, V10, P205, DOI 10.1080/15427609.2013.818480
   Fruzzetti A. E., 2009, HDB COGNITIVE BEHAV, V3rd, P347
   *GARR I REP, 2005, CONT ED SURV PROGR U
   Gaunt H, 2008, PSYCHOL MUSIC, V36, P215, DOI 10.1177/0305735607080827
   Gaylord SA, 2011, AM J GASTROENTEROL, V106, P1678, DOI 10.1038/ajg.2011.184
   GEMBRIS H., 2011, P SEMPRE MUS HLTH WE, P58
   Ginsborg J., 2012, MUSIC HLTH WELLBEING, P357, DOI DOI 10.1093/ACPROF:OSO/9780199586974.003.0024
   Goldin PR, 2010, EMOTION, V10, P83, DOI 10.1037/a0018441
   Grepmair L, 2007, PSYCHOTHER PSYCHOSOM, V76, P332, DOI 10.1159/000107560
   Grossman P, 2004, J PSYCHOSOM RES, V57, P35, DOI 10.1016/S0022-3999(03)00573-7
   Hallam S., 2001, British Journal of Music Education, V18, P27
   HENNELLY S., 2011, THESIS U CAMBRIDGE
   Hofmann SG, 2010, J CONSULT CLIN PSYCH, V78, P169, DOI 10.1037/a0018555
   HRIBAR K, 2012, THESIS U CAMBRIDGE
   Huppert FA, 2010, J POSIT PSYCHOL, V5, P264, DOI 10.1080/17439761003794148
   Ives-Deliperi VL, 2011, SOC NEUROSCI-UK, V6, P231, DOI 10.1080/17470919.2010.513495
   Jha AP, 2010, EMOTION, V10, P54, DOI 10.1037/a0018438
   Kabat-Zinn J., 1994, Full catastrophe living: Using the wisdom of your body and mind to face stress, pain, and illness
   Kabat-Zinn J., 1994, Wherever you go, there you are: Mindfulness meditation in everyday life
   Kaufman KA, 2009, J CLIN SPORT PSYCHOL, V3, P334, DOI 10.1123/jcsp.3.4.334
   Kuyken W, 2013, BRIT J PSYCHIAT, V203, P126, DOI 10.1192/bjp.bp.113.126649
   Langer E, 2010, HARVARD BUSINESS REV
   Langer E, 2009, PSYCHOL MUSIC, V37, P125, DOI 10.1177/0305735607086053
   Leanderson R., 1988, J VOICE, V2, P2, DOI [10.1016/S0892-1997(88)80051-1, DOI 10.1016/S0892-1997(88)80051-1]
   Lilja Josefine L., 2011, Cognitive Behaviour Therapy, V40, P291, DOI 10.1080/16506073.2011.580367
   Lovas DA, 2010, J ANXIETY DISORD, V24, P931, DOI 10.1016/j.janxdis.2010.06.019
   MELL M. R, 2010, THESIS
   Moore ZE, 2009, J CLIN SPORT PSYCHOL, V3, P291, DOI 10.1123/jcsp.3.4.291
   NAPOLI M, 2004, J EVIDENCE BASED COM, V9, P31
   Napoli M, 2005, J APPL SCH PSYCHOL, V21, P99, DOI 10.1300/J370v21n01_05
   NICE, 2010, CG90 DEPR AD FULL GU
   Oyan S., 2006, THESIS
   Palmer AJ, 2010, PHILOS MUSIC EDUC RE, V18, P152, DOI 10.2979/pme.2010.18.2.152
   Palmer AJ, 2006, PHILOS MUSIC EDUC RE, V14, P143, DOI 10.2979/PME.2006.14.2.143
   Rerup C., 2014, MINDFUL CHANGE TIMES, P33
   RODRIGUEZ-CARVAJAL R., 2014, INT J BEHAV RES PSYC, V2
   Roeser RW, 2012, CHILD DEV PERSPECT, V6, P167, DOI 10.1111/j.1750-8606.2012.00238.x
   Sarath E.W., 2013, Improvisation, Creativity, and Consciousness: Jazz as Integral Template for Music, Education, and Society
   Schoeberlein D., 2009, Mindful Teaching and Teaching Mindfulness: A Guide for Anyone Who Teaches Anything
   Segal ZV., 2002, Mindfulness-based Cognitive Therapy for Depression: A New Approach to Preventing Relapse
   STEWART W., 2014, TES CONNECT     0312
   STEYN M. H., 2013, THESIS
   SUNDBERG J, 1992, STL QPSR J, V1, P49
   Tang YY, 2007, P NATL ACAD SCI USA, V104, P17152, DOI 10.1073/pnas.0707678104
   Thompson BL, 2010, J ANXIETY DISORD, V24, P409, DOI 10.1016/j.janxdis.2010.02.005
   Uebelacker LA, 2010, BEHAV MODIF, V34, P247, DOI 10.1177/0145445510368845
   Veehof MM, 2011, CLIN RHEUMATOL, V30, P1045, DOI 10.1007/s10067-011-1690-9
   Veehof MM, 2011, PAIN, V152, P533, DOI 10.1016/j.pain.2010.11.002
   Williams M., 2011, MINDFULNESS PRACTICA
NR 72
TC 13
Z9 20
U1 0
U2 22
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 0265-0517
EI 1469-2104
J9 BRIT J MUSIC EDUC
JI Brit. J. Music Educ.
PD JUL
PY 2015
VL 32
IS 2
BP 211
EP 233
DI 10.1017/S0265051715000145
PG 23
WC Education & Educational Research; Music
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Education & Educational Research; Music
GA CN2YO
UT WOS:000358289500007
OA Green Accepted
DA 2024-01-09
ER

PT J
AU Filippi, P
   Hoeschele, M
   Spierings, M
   Bowling, DL
AF Filippi, Piera
   Hoeschele, Marisa
   Spierings, Michelle
   Bowling, Daniel L.
TI Temporal modulation in speech, music, and animal vocal communication:
   evidence of conserved function
SO ANNALS OF THE NEW YORK ACADEMY OF SCIENCES
LA English
DT Review
DE temporal patterns; emotion expression; social interaction; unit
   identification; language evolution
ID ANTIPHONAL CALLING BEHAVIOR; WHITE COLOBUS MONKEYS; LANGUAGE
   DISCRIMINATION; TURN-TAKING; CIRCUMPLEX MODEL; COMMON MARMOSETS;
   SOCIAL-CONTEXT; PROSODIC CUES; SONG; EMOTION
AB Speech is a distinctive feature of our species. It is the default channel for language and constitutes our primary mode of social communication. Determining the evolutionary origins of speech is a challenging prospect, in large part because it appears to be unique in the animal kingdom. However, direct comparisons between speech and other forms of acoustic communication, both in humans (music) and animals (vocalization), suggest that important components of speech are shared across domains and species. In this review, we focus on a single aspect of speech-temporal patterning-examining similarities and differences across speech, music, and animal vocalization. Additional structure is provided by focusing on three specific functions of temporal patterning across domains: (1) emotional expression, (2) social interaction, and (3) unit identification. We hypothesize an evolutionary trajectory wherein the ability to identify units within a continuous stream of vocal sounds derives from social vocal interaction, which, in turn, derives from vocal emotional communication. This hypothesis implies that unit identification has parallels in music and precursors in animal vocal communication. Accordingly, we demonstrate the potential of comparisons between fundamental domains of biological acoustic communication to provide insight into the evolution of language.
C1 [Filippi, Piera] Aix Marseille Univ, CNRS, Lab Parole & Langage, LPL UMR 7309, Aix En Provence, France.
   [Filippi, Piera] Aix Marseille Univ, CNRS, Inst Language Commun & Brain, Aix En Provence, France.
   [Filippi, Piera] Aix Marseille Univ, CNRS, Lab Psychol Cognit LPC UMR 7290, Marseille, France.
   [Hoeschele, Marisa] Austrian Acad Sci, Acoust Res Inst, Vienna, Austria.
   [Hoeschele, Marisa; Spierings, Michelle] Univ Vienna, Dept Cognit Biol, Vienna, Austria.
   [Bowling, Daniel L.] Stanford Univ, Sch Med, Dept Psychiat & Behav Sci, Stanford, CA 94305 USA.
C3 Aix-Marseille Universite; Centre National de la Recherche Scientifique
   (CNRS); CNRS - Institute for Humanities & Social Sciences (INSHS);
   Aix-Marseille Universite; Centre National de la Recherche Scientifique
   (CNRS); Centre National de la Recherche Scientifique (CNRS);
   Aix-Marseille Universite; Austrian Academy of Sciences; University of
   Vienna; Stanford University
RP Filippi, P (corresponding author), Inst Language Commun & Brain, 5 Ave Pasteur BP 80975, F-13604 Aix En Provence 1, France.
EM pie.filippi@gmail.com
RI Hoeschele, Marisa/R-6198-2018
OI Hoeschele, Marisa/0000-0002-2102-0882; Bowling,
   Daniel/0000-0002-5303-5472
FU Excellence Initiative of Aix-Marseille University
FX P.F. is currently supported by Grants ANR-16-CONV-0002 (ILCB) and
   ANR-11-LABX-0036 (BLRI), and the Excellence Initiative of Aix-Marseille
   University (A<SUP>*</SUP>MIDEX).
CR [Anonymous], 2005, SINGING NEANDERTHALS
   [Anonymous], 2000, P ITRW SPEECH EMOTIO
   [Anonymous], COGN STUD, DOI DOI 10.11225/jcss.12.153
   [Anonymous], 1997, Keeping Together in Time: Dance and Drill in Human History
   Arnold K, 2008, CURR BIOL, V18, pR202, DOI 10.1016/j.cub.2008.01.040
   Arvaniti A, 2012, J PHONETICS, V40, P351, DOI 10.1016/j.wocn.2012.02.003
   Avey MT, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0023844
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Bastian A, 2008, J ACOUST SOC AM, V124, P598, DOI 10.1121/1.2924123
   Beier EJ, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00431
   Benichov JI, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00255
   Benichov JI, 2016, CURR BIOL, V26, P309, DOI 10.1016/j.cub.2015.12.037
   Berwick RC, 2011, TRENDS COGN SCI, V15, P113, DOI 10.1016/j.tics.2011.01.002
   Bethell D, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019283
   Blumstein DT, 1997, AM NAT, V150, P179, DOI 10.1086/286062
   Blumstein DT, 1999, BEHAVIOUR, V136, P731, DOI 10.1163/156853999501540
   Bohn KM, 2013, ANIM BEHAV, V85, P1485, DOI 10.1016/j.anbehav.2013.04.002
   Bowling DL, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0080402
   Bowling DL, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00464
   Bowling DL, 2010, J ACOUST SOC AM, V127, P491, DOI 10.1121/1.3268504
   Bowling DL, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0031942
   Briefer EF, 2012, J ZOOL, V288, P1, DOI 10.1111/j.1469-7998.2012.00920.x
   Brown S, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01894
   Brown S, 2013, PSYCHOL MUSIC, V41, P229, DOI 10.1177/0305735611425896
   Bryant Gregory A, 2013, Front Psychol, V4, P990, DOI 10.3389/fpsyg.2013.00990
   Bryant GA, 2008, J COGN CULT, V8, P135, DOI 10.1163/156770908X289242
   Candiotti A, 2012, ANIM COGN, V15, P327, DOI 10.1007/s10071-011-0456-8
   Carter GG, 2009, CAN J ZOOL, V87, P604, DOI 10.1139/Z09-051
   CHAIKEN M, 1990, DEV PSYCHOBIOL, V23, P233, DOI 10.1002/dev.420230304
   Chen HC, 2009, AM J PRIMATOL, V71, P165, DOI 10.1002/ajp.20636
   CLARK AB, 1985, INT J PRIMATOL, V6, P581, DOI 10.1007/BF02692290
   Clay Z, 2009, FOLIA PRIMATOL, V80, P114
   Cohen EEA, 2010, BIOL LETTERS, V6, P106, DOI 10.1098/rsbl.2009.0670
   Collins KT, 2011, BEHAV PROCESS, V87, P286, DOI 10.1016/j.beproc.2011.06.005
   Coye C, 2018, ANIM BEHAV, V141, P171, DOI 10.1016/j.anbehav.2018.05.014
   Coye C, 2016, ANIM BEHAV, V115, P97, DOI 10.1016/j.anbehav.2016.03.010
   Cummins F., 2004, UC MERC P ANN M COGN
   Curtin S, 2005, COGNITION, V96, P233, DOI 10.1016/j.cognition.2004.08.005
   CUTLER A, 1994, COGNITION, V50, P79, DOI 10.1016/0010-0277(94)90021-3
   Cutler A., 1987, Computer Speech and Language, V2, P133, DOI 10.1016/0885-2308(87)90004-0
   Cutler A., 1984, INTONATION ACCENT RH, V8, P76
   D'Amelio PB, 2017, FRONT ZOOL, V14, DOI 10.1186/s12983-017-0197-x
   Danieli M., 2004, P 4 INT C LANG RES E
   Darwin G., 1871, P423
   DAUER RM, 1983, J PHONETICS, V11, P51, DOI 10.1016/S0095-4470(19)30776-4
   Déaux EC, 2016, SCI REP-UK, V6, DOI 10.1038/srep30556
   Dehaene-Lambertz G, 1998, LANG SPEECH, V41, P21, DOI 10.1177/002383099804100102
   DRAKE C, 1993, MUSIC PERCEPT, V10, P343
   DuBois AL, 2009, BIOL LETTERS, V5, P163, DOI 10.1098/rsbl.2008.0626
   Dunbar RIM, 2004, VIENNA S THEOR BIOL, P257
   Echols CH, 1997, J MEM LANG, V36, P202, DOI 10.1006/jmla.1996.2483
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   ENDLER JA, 1993, PHILOS T R SOC B, V340, P215, DOI 10.1098/rstb.1993.0060
   Engesser S, 2019, WIRES COGN SCI, V10, DOI 10.1002/wcs.1493
   Esch HC, 2009, J MAMMAL, V90, P638, DOI 10.1644/08-MAMM-A-069R.1
   Falk S, 2017, COGNITION, V163, P80, DOI 10.1016/j.cognition.2017.02.017
   Fancourt D, 2016, ECANCERMEDICALSCIENC, V10, P1, DOI 10.3332/ecancer.2016.631
   Filippi P, 2017, P ROY SOC B-BIOL SCI, V284, DOI 10.1098/rspb.2017.0990
   Filippi P, 2017, CURR ZOOL, V63, P445, DOI 10.1093/cz/zox035
   Filippi P, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01393
   Filippi P, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01468
   Fitch WT, 2017, PSYCHON B REV, V24, P3, DOI 10.3758/s13423-017-1236-5
   Fitch WT, 2010, EVOLUTION OF LANGUAGE, PROCEEDINGS, P137
   Fitch WT, 2005, COGNITION, V97, P179, DOI 10.1016/j.cognition.2005.02.005
   Freeberg TM, 2012, PHILOS T R SOC B, V367, P1785, DOI 10.1098/rstb.2011.0213
   Freeman W, 2000, ORIGINS OF MUSIC, P411
   Fujioka T, 2012, J NEUROSCI, V32, P1791, DOI 10.1523/JNEUROSCI.4107-11.2012
   Gamba M, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00249
   Geissmann T, 2000, ANIM BEHAV, V60, P805, DOI 10.1006/anbe.2000.1540
   Geissmann T, 2000, ORIGINS OF MUSIC, P103
   Ghazanfar AA, 2002, ANIM BEHAV, V64, P427, DOI 10.1006/anbe.2002.3074
   Ghazanfar AA, 2001, J COMP PHYSIOL A, V187, P27, DOI 10.1007/s003590000173
   Gogoleva SS, 2010, BEHAVIOUR, V147, P1713, DOI 10.1163/000579510X528242
   Grafe TU, 2004, ANIM BEHAV, V68, P193, DOI 10.1016/j.anbehav.2003.11.003
   Grafe TU, 1996, BEHAV ECOL SOCIOBIOL, V38, P149, DOI 10.1007/s002650050227
   GREENFIELD MD, 1994, AM ZOOL, V34, P605
   Greenfield MD, 2016, SCI REP-UK, V6, DOI 10.1038/srep34369
   Hagen EH, 2003, HUM NATURE-INT BIOS, V14, P21, DOI 10.1007/s12110-003-1015-z
   Hall ML, 2007, CURR BIOL, V17, pR406, DOI 10.1016/j.cub.2007.04.022
   Hauser MD, 2002, SCIENCE, V298, P1569, DOI 10.1126/science.298.5598.1569
   Henry L, 2016, TURN TAKING HUMAN CO, P39
   HOCKETT CF, 1960, SCI AM, V203, P88, DOI 10.1038/scientificamerican0960-88
   Hoeschele M, 2016, ANIM COGN, V19, P643, DOI 10.1007/s10071-016-0968-3
   Hoeschele M, 2015, PHILOS T R SOC B, V370, P39, DOI 10.1098/rstb.2014.0094
   Holler J., 2016, TURN TAKING HUMAN CO, P6
   Honing H, 2014, ADV EXP MED BIOL, V829, P305, DOI 10.1007/978-1-4939-1782-2_16
   HULTSCH H, 1989, NATURWISSENSCHAFTEN, V76, P83, DOI 10.1007/BF00396717
   Iversen JR, 2009, ANN NY ACAD SCI, V1169, P58, DOI 10.1111/j.1749-6632.2009.04579.x
   Jansen DAWAM, 2012, BMC BIOL, V10, DOI 10.1186/1741-7007-10-97
   Jovanovic T, 2001, AM J PRIMATOL, V53, P33
   JUSCZYK PW, 1993, CHILD DEV, V64, P675, DOI 10.1111/j.1467-8624.1993.tb02935.x
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   KELLY MH, 1994, LINGUA, V92, P105, DOI 10.1016/0024-3841(94)90339-5
   KLUMP GM, 1992, NATO ADV SCI I A-LIF, V228, P153
   Knotková E, 2009, BIOACOUSTICS, V18, P241, DOI 10.1080/09524622.2009.9753604
   Kotz SA, 2018, TRENDS COGN SCI, V22, P896, DOI 10.1016/j.tics.2018.08.002
   Kragel PA, 2016, TRENDS COGN SCI, V20, P444, DOI 10.1016/j.tics.2016.03.011
   Kreutz G, 2004, J BEHAV MED, V27, P623, DOI 10.1007/s10865-004-0006-9
   Labrunie M, 2018, SPEECH COMMUN, V99, P27, DOI 10.1016/j.specom.2018.02.004
   Ladefoged P., 1996, Elements of acoustic phonetics
   Launay J, 2016, ETHOLOGY, V122, P779, DOI 10.1111/eth.12528
   Lemasson A, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0045106
   Levinson SC, 2016, TRENDS COGN SCI, V20, P6, DOI 10.1016/j.tics.2015.10.010
   Levinson SC, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0302
   LIBERMAN M, 1977, LINGUIST INQ, V8, P249
   Liebal K., 2006, GESTURE, V6, P1, DOI [DOI 10.1075/GEST.6.1.02LIE, 10.1075/gest.6.1.02lie]
   Magyari L, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00211
   Mann NI, 2006, BIOL LETTERS, V2, P1, DOI 10.1098/rsbl.2005.0373
   Manser MB, 2001, P ROY SOC B-BIOL SCI, V268, P2315, DOI 10.1098/rspb.2001.1773
   MARLER P, 1972, BEHAVIOUR, V43, P175, DOI 10.1163/156853972X00266
   McComb K, 2005, BIOL LETTERS, V1, P381, DOI 10.1098/rsbl.2005.0366
   Meise K, 2011, J ACOUST SOC AM, V129, P1631, DOI 10.1121/1.3531944
   Mendl M, 2010, P ROY SOC B-BIOL SCI, V277, P2895, DOI 10.1098/rspb.2010.0303
   Miller CT, 2004, J COMP PHYSIOL A, V190, P7, DOI 10.1007/s00359-003-0468-1
   MORTON ES, 1977, AM NAT, V111, P855, DOI 10.1086/283219
   Nazzi T, 1998, J EXP PSYCHOL HUMAN, V24, P756, DOI 10.1037/0096-1523.24.3.756
   Nespor M, 2007, STUD GENERAT GRAMM, V28, P1
   Nesse R M, 1990, Hum Nat, V1, P261, DOI 10.1007/BF02733986
   Nolan F, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0396
   OATES JF, 1983, FOLIA PRIMATOL, V40, P83, DOI 10.1159/000156092
   Ouattara K, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0007808
   PALMER C, 1993, J EXP PSYCHOL LEARN, V19, P457, DOI 10.1037/0278-7393.19.2.457
   PALMER C, 1989, J EXP PSYCHOL HUMAN, V15, P331, DOI 10.1037/0096-1523.15.2.331
   Patel AD, 2003, COGNITION, V87, pB35, DOI 10.1016/S0010-0277(02)00187-7
   Patel AD, 2010, MUSIC LANGUAGE BRAIN
   Pell MD, 2009, J NONVERBAL BEHAV, V33, P107, DOI 10.1007/s10919-008-0065-7
   Penel A, 1998, PSYCHOL RES-PSYCH FO, V61, P12, DOI 10.1007/PL00008161
   Phillips-Silver J, 2010, MUSIC PERCEPT, V28, P3, DOI 10.1525/MP.2010.28.1.3
   POLLOCK JI, 1986, INT J PRIMATOL, V7, P225, DOI 10.1007/BF02736391
   Posner J, 2005, DEV PSYCHOPATHOL, V17, P715, DOI 10.1017/S0954579405050340
   Purves D., 2017, MUSIC BIOL
   Ramus F, 2000, COGNITION, V75, DOI 10.1016/S0010-0277(00)00101-3
   Ramus F, 2000, SCIENCE, V288, P349, DOI 10.1126/science.288.5464.349
   Ramus F., 2002, Annual Review of Language Acquisition, V2, P85
   Ravignani A., 2019, PEERJ, DOI [10.7287/peerj.preprints.27539, DOI 10.7287/PEERJ.PREPRINTS.27539]
   Ravignani A, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01118
   Ravignani A, 2014, BIOL LETTERS, V10, DOI 10.1098/rsbl.2013.1018
   Rennung M, 2016, Z PSYCHOL, V224, P168, DOI 10.1027/2151-2604/a000252
   ROEDERER JG, 1984, MUSIC PERCEPT, V1, P350
   Rohrmeier M, 2015, PHILOS T R SOC B, V370, P107, DOI 10.1098/rstb.2014.0097
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   RYAN MJ, 1981, BEHAV ECOL SOCIOBIOL, V8, P273, DOI 10.1007/BF00299526
   Sacks Harvey, 1978, STUDIES ORG CONVERSA, P7, DOI DOI 10.1016/B978-0-12-623550-0.50008-2
   Sauter DA, 2010, P NATL ACAD SCI USA, V107, P2408, DOI 10.1073/pnas.0908239106
   Schel AM, 2009, J COMP PSYCHOL, V123, P136, DOI 10.1037/a0014280
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   Scherer KR., 2000, The Neuropsychology of Emotion, P137
   Schladt TM, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00430
   Schrader L, 1998, ETHOLOGY, V104, P859, DOI 10.1111/j.1439-0310.1998.tb00036.x
   SCHRADER L, 1993, ANIM BEHAV, V46, P1026, DOI 10.1006/anbe.1993.1288
   Slocombe KE, 2007, P NATL ACAD SCI USA, V104, P17228, DOI 10.1073/pnas.0706741104
   Snyder JS, 2005, COGNITIVE BRAIN RES, V24, P117, DOI 10.1016/j.cogbrainres.2004.12.014
   Soard CM, 2009, ANIM BEHAV, V78, P1447, DOI 10.1016/j.anbehav.2009.09.026
   Soderstrom M, 2003, J MEM LANG, V49, P249, DOI 10.1016/S0749-596X(03)00024-X
   Soltis J, 2005, ANIM BEHAV, V70, P579, DOI 10.1016/j.anbehav.2004.11.015
   SPENCER H, 1857, FRASERS MAGAZINE, V56, P396, DOI DOI 10.1017/S0140525X08005293
   Spierings M, 2015, ANIM COGN, V18, P867, DOI 10.1007/s10071-015-0855-3
   Spierings MJ, 2014, P ROY SOC B-BIOL SCI, V281, DOI 10.1098/rspb.2014.0480
   Stivers T, 2009, P NATL ACAD SCI USA, V106, P10587, DOI 10.1073/pnas.0903616106
   Stoeger AS, 2011, J ACOUST SOC AM, V130, P1700, DOI 10.1121/1.3605538
   Takahashi DY, 2013, CURR BIOL, V23, P2162, DOI 10.1016/j.cub.2013.09.005
   Takahasi M, 2010, ETHOLOGY, V116, P481, DOI 10.1111/j.1439-0310.2010.01772.x
   Tarr B, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01096
   Templeton CN, 2005, SCIENCE, V308, P1934, DOI 10.1126/science.1108841
   Thomas TJ, 2001, APPL ANIM BEHAV SCI, V74, P165, DOI 10.1016/S0168-1591(01)00164-2
   Tierney AT, 2011, P NATL ACAD SCI USA, V108, P15510, DOI 10.1073/pnas.1103882108
   Tilsen S, 2013, J ACOUST SOC AM, V134, P628, DOI 10.1121/1.4807565
   Tincoff R, 2005, DEVELOPMENTAL SCI, V8, P26, DOI 10.1111/j.1467-7687.2005.00390.x
   Titze I., 1994, Principles of Voice Production
   TODD N, 1985, MUSIC PERCEPT, V3, P33
   Todt D, 2000, ADV STUD BEHAV, V29, P247, DOI 10.1016/S0065-3454(08)60107-2
   Toro JM, 2003, ANIM COGN, V6, P131, DOI 10.1007/s10071-003-0172-0
   Toro JM, 2017, ANIM COGN, V20, P179, DOI 10.1007/s10071-016-1036-8
   Torti V, 2013, ITAL J ZOOL, V80, P596, DOI 10.1080/11250003.2013.845261
   van Donselaar W, 2005, Q J EXP PSYCHOL-A, V58, P251, DOI 10.1080/02724980343000927
   van Schaik CP, 1999, PRIMATES, V40, P69, DOI 10.1007/BF02557703
   Waaramaa T, 2010, J VOICE, V24, P30, DOI 10.1016/j.jvoice.2008.04.004
   Yang L. C, 2003, P 15 ICPHS, P1791
   Zanto TP, 2005, MUSIC PERCEPT, V22, P531, DOI 10.1525/mp.2005.22.3.531
   Zimmermann E., 2013, Evolution of emotional communication: From sounds in nonhuman mammals to speech and music in men, P117, DOI [10.1093/acprof:oso/9780199583560.001.0001, DOI 10.1093/ACPROF:OSO/9780199583560.001.0001]
NR 182
TC 12
Z9 13
U1 1
U2 24
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0077-8923
EI 1749-6632
J9 ANN NY ACAD SCI
JI Ann. N.Y. Acad. Sci.
PD OCT
PY 2019
VL 1453
IS 1
SI SI
BP 99
EP 113
DI 10.1111/nyas.14228
PG 15
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Science & Technology - Other Topics
GA JB1XN
UT WOS:000488353800008
PM 31482571
DA 2024-01-09
ER

PT J
AU Suslow, T
   Kersting, A
AF Suslow, Thomas
   Kersting, Anette
TI Beyond Face and Voice: A Review of Alexithymia and Emotion Perception in
   Music, Odor, Taste, and Touch
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Review
DE alexithymia; emotion perception; music; olfaction; gustation; touch
ID FACIAL EXPRESSIONS; BASIC EMOTIONS; PERCEIVED EMOTIONS; RECOGNITION;
   CATEGORIZATION; STIMULI
AB Alexithymia is a clinically relevant personality trait characterized by deficits in recognizing and verbalizing one's emotions. It has been shown that alexithymia is related to an impaired perception of external emotional stimuli, but previous research focused on emotion perception from faces and voices. Since sensory modalities represent rather distinct input channels it is important to know whether alexithymia also affects emotion perception in other modalities and expressive domains. The objective of our review was to summarize and systematically assess the literature on the impact of alexithymia on the perception of emotional (or hedonic) stimuli in music, odor, taste, and touch. Eleven relevant studies were identified. On the basis of the reviewed research, it can be preliminary concluded that alexithymia might be associated with deficits in the perception of primarily negative but also positive emotions in music and a reduced perception of aversive taste. The data available on olfaction and touch are inconsistent or ambiguous and do not allow to draw conclusions. Future investigations would benefit from a multimethod assessment of alexithymia and control of negative affect. Multimodal research seems necessary to advance our understanding of emotion perception deficits in alexithymia and clarify the contribution of modality-specific and supramodal processing impairments.
C1 [Suslow, Thomas; Kersting, Anette] Univ Leipzig, Med Ctr, Dept Psychosomat Med & Psychotherapy, Leipzig, Germany.
C3 Leipzig University
RP Suslow, T (corresponding author), Univ Leipzig, Med Ctr, Dept Psychosomat Med & Psychotherapy, Leipzig, Germany.
EM suslow@medizin.uni-leipzig.de
OI Suslow, Thomas/0000-0003-4560-0555
CR Allen R, 2013, J AUTISM DEV DISORD, V43, P432, DOI 10.1007/s10803-012-1587-8
   Aust S, 2013, PSYCHOL TRAUMA-US, V5, P225, DOI 10.1037/a0027314
   BAGBY RM, 1994, J PSYCHOSOM RES, V38, P23, DOI 10.1016/0022-3999(94)90005-1
   Bayot M, 2014, PSYCHIAT RES, V216, P242, DOI 10.1016/j.psychres.2013.12.007
   Bermond B, 2007, COGNITION EMOTION, V21, P1125, DOI 10.1080/02699930601056989
   Borhani K, 2017, BIOL PSYCHOL, V128, P132, DOI 10.1016/j.biopsycho.2017.07.012
   Brandt L, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0129905
   Breslin PAS, 2006, ADV OTO-RHINO-LARYNG, V63, P152, DOI 10.1159/000093760
   Brosch T, 2010, COGNITION EMOTION, V24, P377, DOI 10.1080/02699930902975754
   Brown S, 2018, PSYCHOL TRAUMA-US, V10, P300, DOI 10.1037/tra0000279
   Calvo MG, 2014, J NONVERBAL BEHAV, V38, P549, DOI 10.1007/s10919-014-0191-3
   Cascio CJ, 2019, DEV COGN NEUROS-NETH, V35, P5, DOI 10.1016/j.dcn.2018.04.009
   Cecchetto C, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-14404-x
   Connolly HL, 2020, COGNITION, V197, DOI 10.1016/j.cognition.2019.104166
   Constantinou E, 2014, BIOL PSYCHOL, V103, P212, DOI 10.1016/j.biopsycho.2014.09.011
   Croy I, 2011, EMOTION, V11, P1331, DOI 10.1037/a0024437
   Deborde AS, 2008, PSYCHOPATHOLOGY, V41, P43, DOI 10.1159/000109955
   Donges US, 2017, REV NEUROSCIENCE, V28, P247, DOI 10.1515/revneuro-2016-0049
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   Erickson K, 2003, BRAIN COGNITION, V52, P52, DOI 10.1016/S0278-2626(03)00008-3
   Etkin A, 2011, TRENDS COGN SCI, V15, P85, DOI 10.1016/j.tics.2010.11.004
   FAVA GA, 1995, PSYCHOTHER PSYCHOSOM, V63, P1, DOI 10.1159/000288931
   Franz M, 2008, SOC PSYCH PSYCH EPID, V43, P54, DOI 10.1007/s00127-007-0265-1
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Goerlich KS, 2018, ALEXITHYMIA: ADVANCES IN RESEARCH, THEORY, AND CLINICAL PRACTICE, P250
   Goerlich KS, 2018, ALEXITHYMIA: ADVANCES IN RESEARCH, THEORY, AND CLINICAL PRACTICE, P207
   Goerlich KS, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019501
   Grynberg D, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0042429
   Harris LT, 2007, COGN AFFECT BEHAV NE, V7, P309, DOI 10.3758/CABN.7.4.309
   Heaton P, 2012, PSYCHOL MED, V42, P2453, DOI 10.1017/S0033291712000621
   Hertenstein MJ, 2006, EMOTION, V6, P528, DOI 10.1037/1528-3542.6.3.528
   Herz RS, 2016, BRAIN SCI, V6, DOI 10.3390/brainsci6030022
   Hummel T, 2007, EUR ARCH OTO-RHINO-L, V264, P237, DOI 10.1007/s00405-006-0173-0
   Ihme K, 2014, NEUROPSYCHOLOGIA, V64, P289, DOI 10.1016/j.neuropsychologia.2014.09.044
   Iosifyan M, 2019, CONSCIOUS COGN, V71, P79, DOI 10.1016/j.concog.2019.03.012
   Jakobson LS, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.583786
   Jayasinghe SN, 2017, NUTRIENTS, V9, DOI 10.3390/nu9070750
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kätsyri J, 2008, NEUROPSYCHOLOGIA, V46, P1888, DOI 10.1016/j.neuropsychologia.2008.01.005
   Keltner D, 2019, J NONVERBAL BEHAV, V43, P133, DOI 10.1007/s10919-019-00293-3
   Kinnamon SC, 2012, ACTA PHYSIOL, V204, P158, DOI 10.1111/j.1748-1716.2011.02308.x
   Kircanski K, 2012, WIRES COGN SCI, V3, P301, DOI 10.1002/wcs.1177
   Klasen M, 2011, J NEUROSCI, V31, P13635, DOI 10.1523/JNEUROSCI.2833-11.2011
   Koelsch S, 2014, NAT REV NEUROSCI, V15, P170, DOI 10.1038/nrn3666
   Lane RD, 1997, BIOL PSYCHIAT, V42, P834, DOI 10.1016/S0006-3223(97)00050-4
   Larwood JL, 2021, COGNITION EMOTION, V35, P500, DOI 10.1080/02699931.2019.1707514
   Levant RF, 2009, PSYCHOL MEN MASCULIN, V10, P190, DOI 10.1037/a0015652
   Leweke F, 2012, PSYCHOPATHOLOGY, V45, P22, DOI 10.1159/000325170
   Lewis GJ, 2016, J EXP PSYCHOL GEN, V145, P589, DOI 10.1037/xge0000160
   Li SW, 2015, PSYCHIAT RES, V227, P1, DOI 10.1016/j.psychres.2015.02.006
   Lombion S, 2010, PSYCHIAT RES, V177, P135, DOI 10.1016/j.psychres.2009.01.018
   Mattila AK, 2006, J PSYCHOSOM RES, V61, P629, DOI 10.1016/j.jpsychores.2006.04.013
   Mohn C, 2011, PSYCHOL MUSIC, V39, P503, DOI 10.1177/0305735610378183
   Moller AR., 2002, SENSORY SYSTEMS ANAT
   Nawrot ES., 2003, Psychol. Music, V31, P75, DOI DOI 10.1177/0305735603031001325
   Özsoy-Ünübol T, 2020, ARCH RHEUMATOL, V35, P584, DOI 10.46497/ArchRheumatol.2020.7833
   Panayiotou G, 2015, COMPR PSYCHIAT, V56, P206, DOI 10.1016/j.comppsych.2014.09.006
   PARKER JDA, 1993, PSYCHOTHER PSYCHOSOM, V59, P197, DOI 10.1159/000288664
   Peelen MV, 2010, J NEUROSCI, V30, P10127, DOI 10.1523/JNEUROSCI.2161-10.2010
   Phillips ML, 2003, BRIT J PSYCHIAT, V182, P190, DOI 10.1192/bjp.182.3.190
   Porcelli P, 2018, ALEXITHYMIA: ADVANCES IN RESEARCH, THEORY, AND CLINICAL PRACTICE, P105
   Punkanen M, 2011, J AFFECT DISORDERS, V130, P118, DOI 10.1016/j.jad.2010.10.034
   Quintin EM, 2011, J AUTISM DEV DISORD, V41, P1240, DOI 10.1007/s10803-010-1146-0
   Robino A, 2016, PHYSIOL BEHAV, V157, P72, DOI 10.1016/j.physbeh.2016.01.022
   Rolls ET, 2008, PROG NEUROBIOL, V86, P216, DOI 10.1016/j.pneurobio.2008.09.001
   Rosenberg N, 2020, BMC NEUROSCI, V21, DOI 10.1186/s12868-020-00572-6
   Sauter DA, 2010, P NATL ACAD SCI USA, V107, P2408, DOI 10.1073/pnas.0908239106
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Schirmer A, 2017, TRENDS COGN SCI, V21, P216, DOI 10.1016/j.tics.2017.01.001
   Shepherd GM, 2006, NATURE, V444, P316, DOI 10.1038/nature05405
   Spitzer C, 2005, PSYCHOTHER PSYCHOSOM, V74, P240, DOI 10.1159/000085148
   Suslow T, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01758
   Swart M, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0005751
   Taruffi L, 2017, MUSIC PERCEPT, V34, P253, DOI 10.1525/MP.2017.34.3.253
   Taylor G. J., 2000, The handbook of emotional intelligence, P41
   TAYLOR GJ, 1985, PSYCHOTHER PSYCHOSOM, V44, P191, DOI 10.1159/000287912
   Vorst HCM, 2001, PERS INDIV DIFFER, V30, P413, DOI 10.1016/S0191-8869(00)00033-7
   Xu PF, 2018, NEUROSCI BIOBEHAV R, V87, P50, DOI 10.1016/j.neubiorev.2018.01.004
NR 78
TC 1
Z9 1
U1 6
U2 31
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD JUL 30
PY 2021
VL 12
AR 707599
DI 10.3389/fpsyg.2021.707599
PG 10
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA UA5XF
UT WOS:000685234100001
PM 34393944
OA gold, Green Published
DA 2024-01-09
ER

PT J
AU Perlovsky, L
AF Perlovsky, Leonid
TI "High" cognitive emotions in language prosody Commentary on "Emotional
   voices in context: A neurobiological model of multimodal affective
   information processing" by C. Bruck B. Kreifelts, & D. Wildgruber
SO PHYSICS OF LIFE REVIEWS
LA English
DT Editorial Material
ID MUSIC; RECOGNITION; SCIENCE
C1 Harvard Univ, Athinoula A Martinos Ctr Biomed Imaging, Charlestown, MA 02129 USA.
C3 Harvard University
RP Perlovsky, L (corresponding author), Harvard Univ, Athinoula A Martinos Ctr Biomed Imaging, 149 13th St, Charlestown, MA 02129 USA.
EM leonid@seas.harvard.edu
RI Perlovsky, Leonid I./A-8975-2009
CR Adolphs R, 2002, EMOTION, V2, P23, DOI 10.1037/1528-3542.2.1.23
   [Anonymous], 1995, COMPLETE WORKS
   [Anonymous], 1995, The Neuroscientist, DOI [10.1177/107385849500100104, DOI 10.1177/107385849500100104]
   [Anonymous], INT J SYNTHETIC EMOT, DOI DOI 10.4018/JSE.2010070101
   Ball P, 2008, NATURE, V453, P160, DOI 10.1038/453160a
   Bechara A, 2005, GAME ECON BEHAV, V52, P336, DOI 10.1016/j.geb.2004.06.010
   Bradley MM, 2001, EMOTION, V1, P276, DOI 10.1037//1528-3542.1.3.276
   Brück C, 2011, PHYS LIFE REV, V8, P383, DOI 10.1016/j.plrev.2011.10.002
   Buchanan TW, 2000, COGNITIVE BRAIN RES, V9, P227, DOI 10.1016/S0926-6410(99)00060-9
   Cross I., 2008, COMMUNICATIVE MUSICA, P61
   Darwin G., 1871, P423
   Davis PJ, 1996, J VOICE, V10, P23, DOI 10.1016/S0892-1997(96)80016-6
   Deacon T.W., 1989, Human Evolution, V4, P367, DOI 10.1007/BF02436435
   Duncan S, 2007, COGNITION EMOTION, V21, P1184, DOI 10.1080/02699930701437931
   Festinger L., 1957, Sel. Expo. Theory, V16, P401
   FONTANARI FJ, 2011, IEEE P INT JOINT C N, P95
   FONTANARI JF, 2011, INT JOINT C NEUR NET
   GROSSBERG S, 1987, PSYCHOBIOLOGY, V15, P195
   Haidt J, 2001, PSYCHOL REV, V108, P814, DOI 10.1037//0033-295X.108.4.814
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P600, DOI 10.1017/S0140525X08005554
   Levine DS, 2009, NEURAL NETWORKS, V22, P286, DOI 10.1016/j.neunet.2009.03.003
   Levitin Daniel, 2006, This is Your Brain on Music: The Science of a Human Obsession
   Masataka N, 2009, PHYS LIFE REV, V6, P11, DOI 10.1016/j.plrev.2008.08.003
   Mayer JD, 2008, AM PSYCHOL, V63, P503, DOI 10.1037/0003-066X.63.6.503
   Ochsner KN, 2007, TRENDS COGN SCI, V11, P317, DOI 10.1016/j.tics.2007.06.008
   Panksepp J, 2002, BEHAV PROCESS, V60, P133, DOI 10.1016/S0376-6357(02)00080-3
   Patel A. D., 2008, Music, Language, and the Brain
   Perlovsky L I, 2010, Open Neuroimag J, V4, P70, DOI 10.2174/1874440001004010070
   Perlovsky L, 2010, PHYS LIFE REV, V7, P2, DOI 10.1016/j.plrev.2009.11.001
   Perlovsky L, 2009, NEURAL NETWORKS, V22, P518, DOI 10.1016/j.neunet.2009.06.034
   Perlovsky LI, 2006, PHYS LIFE REV, V3, P23, DOI 10.1016/j.plrev.2005.11.003
   PERLOVSKY LI, 2006, LECT MUSICOLOGY
   PERLOVSKY LI, 2006, MUSIC 1 PRINCIPLE
   PERLOVSKY LI, 2010, WEBMEDCENTRAL BRAIN, V1
   Purwins H, 2008, PHYS LIFE REV, V5, P151, DOI 10.1016/j.plrev.2008.03.004
   Seyfarth RM, 2003, ANN NY ACAD SCI, V1000, P32, DOI 10.1196/annals.1280.004
   Sloboda JA., 2001, MUSIC EMOTION THEORY, P71
   Trainor L, 2008, NATURE, V453, P598, DOI 10.1038/453598a
NR 38
TC 11
Z9 11
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1571-0645
EI 1873-1457
J9 PHYS LIFE REV
JI Phys. Life Rev.
PD DEC
PY 2011
VL 8
IS 4
BP 408
EP 409
DI 10.1016/j.plrev.2011.10.007
PG 2
WC Biology; Biophysics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Life Sciences & Biomedicine - Other Topics; Biophysics
GA 867MB
UT WOS:000298457400018
PM 22018625
DA 2024-01-09
ER

PT J
AU Eerola, T
   Vuoskoski, JK
AF Eerola, Tuomas
   Vuoskoski, Jonna K.
TI A REVIEW OF MUSIC AND EMOTION STUDIES: APPROACHES, EMOTION MODELS, AND
   STIMULI
SO MUSIC PERCEPTION
LA English
DT Review
DE emotion; review; music; stimuli; theoretical
ID AFFECTIVE NEUROSCIENCE; MODERATING INFLUENCE; AFFECTIVE RESPONSES;
   DIMENSIONAL MODELS; CIRCUMPLEX MODEL; BACKGROUND MUSIC; VOCAL
   EXPRESSION; MOOD; RECOGNITION; PERCEPTION
AB THE FIELD OF MUSIC AND EMOTION RESEARCH HAS grown rapidly and diversified during the last decade. This has led to a certain degree of confusion and inconsistency between competing notions of emotions, data, and results. The present review of 251 studies describes the focus of prevalent research approaches, methods, and models of emotion, and documents the types of musical stimuli used over the past twenty years. Although self-report approaches to emotions are the most common way of dealing with music and emotions, using multiple approaches is becoming increasingly popular. A large majority (70%) of the studies employed variants of the discrete or the dimensional emotion models. A large proportion of stimuli rely on a relatively modest amount of familiar classical examples. The evident shortcomings of these prevalent patterns in music and emotion studies are highlighted, and concrete plans of action for future studies are suggested.
C1 [Eerola, Tuomas; Vuoskoski, Jonna K.] Univ Jyvaskyla, FI-40014 Jyvaskyla, Finland.
C3 University of Jyvaskyla
RP Eerola, T (corresponding author), Univ Jyvaskyla, Finnish Ctr Excellence Interdisciplinary Mus Res, Seminaarinkatu 35,BO Box 15, FI-40014 Jyvaskyla, Finland.
EM tuomas.eerola@jyu.fi
RI Eerola, Tuomas/I-6190-2013; Campailla, Jasmin/AAK-2420-2021; Eerola,
   Tuomas/K-7596-2019; Vuoskoski, Jonna K/B-4944-2018
OI Eerola, Tuomas/0000-0002-2896-929X; Eerola, Tuomas/0000-0002-2896-929X;
   Vuoskoski, Jonna K/0000-0003-0049-4373; Alluri,
   Vinoo/0000-0003-3689-1039
CR Adachi M., 2002, MUSIC PERCEPT, V18, P213
   Adachi M., 1998, PSYCHOL MUSIC, V26, P133, DOI [DOI 10.1177/0305735698262003, 10.1177/0305735698262003]
   ALBERSNAGEL FA, 1988, BEHAV RES THER, V26, P79, DOI 10.1016/0005-7967(88)90035-6
   Alfredson BB, 2004, APPL NEUROPSYCHOL, V11, P161, DOI 10.1207/s15324826an1103_4
   Ali SO., 2006, Psychology of Music, V34, P511, DOI DOI 10.1177/0305735606067168
   Allen, 2005, COMMUNICATION DISORD, V26, P131, DOI DOI 10.1177/15257401050260030201
   Altenmüller E, 2002, NEUROPSYCHOLOGIA, V40, P2242, DOI 10.1016/S0028-3932(02)00107-0
   [Anonymous], 2010, Handbook of Music and Emotion
   [Anonymous], 2005, PSYCHOL MUSIC, DOI DOI 10.1177/0305735605056144
   [Anonymous], PSYCHOL MUSIC
   [Anonymous], 2006, P 9 INT C MUS PERC C
   [Anonymous], PSYCHOL MUSIC
   [Anonymous], PSYCHOL MUSIC
   [Anonymous], 2000, HUM PHYSIOL+, DOI [DOI 10.1007/BF02760371, 10.1007/BF02760371]
   [Anonymous], PSYCHOL MUSIC, DOI [10.1177/0305735600282007, DOI 10.1177/0305735600282007]
   Asmus E.P., 1985, PSYCHOL MUSIC, V13, P19, DOI [DOI 10.1177/0305735685131002, https://doi.org/10.1177/0305735685131002]
   Balkwill LL, 2004, JPN PSYCHOL RES, V46, P337, DOI 10.1111/j.1468-5584.2004.00265.x
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   BANICH MT, 1992, NEUROPSY NEUROPSY BE, V5, P20
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Baraldi FB, 2006, J NEW MUSIC RES, V35, P197, DOI 10.1080/09298210601045575
   Barrett LF, 2006, CURR DIR PSYCHOL SCI, V15, P79, DOI 10.1111/j.0963-7214.2006.00411.x
   Barrett LF, 1999, CURR DIR PSYCHOL SCI, V8, P10, DOI 10.1111/1467-8721.00003
   Bartel L. R., 1992, PSYCHOMUSICOLOGY, V11, P15, DOI [10.1037/h0094135, DOI 10.1037/H0094135]
   Baumgartner T, 2006, INT J PSYCHOPHYSIOL, V60, P34, DOI 10.1016/j.ijpsycho.2005.04.007
   Behrens Gene Ann, 1993, Psychology of Music, V21, P20, DOI DOI 10.1177/030573569302100102
   BEVER TG, 1988, PSYCHOMUSICOLOGY, V7, P165, DOI DOI 10.1037/H0094171
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Blood AJ, 1999, NAT NEUROSCI, V2, P382, DOI 10.1038/7299
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Boone RT, 2001, J NONVERBAL BEHAV, V25, P21, DOI 10.1023/A:1006733123708
   BOUHUYS AL, 1995, J AFFECT DISORDERS, V33, P215, DOI 10.1016/0165-0327(94)00092-N
   Bresin R, 2000, COMPUT MUSIC J, V24, P44, DOI 10.1162/014892600559515
   Bresin R., 2005, Proceedings of the International Computer Music Conference, P367
   Brittin RV, 1997, J RES MUSIC EDUC, V45, P245, DOI 10.2307/3345584
   BROSGOLE L, 1995, INT J NEUROSCI, V82, P169, DOI 10.3109/00207459508999800
   Brown S, 2004, NEUROREPORT, V15, P2033, DOI 10.1097/00001756-200409150-00008
   Burkhardt F, 2005, 9 EUR C SPEECH COMM, V5, P1517, DOI [10.21437/Interspeech.2005-446, DOI 10.21437/INTERSPEECH.2005-446]
   Camurri A, 2003, INT J HUM-COMPUT ST, V59, P213, DOI 10.1016/S1071-5819(03)00050-8
   CANNAM C., 2006, Proceedings of the International Conference on Music Information Retrieval, P324
   Chapados C, 2008, COGNITION, V108, P639, DOI 10.1016/j.cognition.2008.05.008
   Chen J, 2008, NEUROSCI LETT, V445, P135, DOI 10.1016/j.neulet.2008.08.061
   Chen L, 2007, MEDIA PSYCHOL, V9, P695, DOI 10.1080/15213260701283293
   CLARK DM, 1985, J PERS SOC PSYCHOL, V48, P1595, DOI 10.1037/0022-3514.48.6.1595
   Coffman D. D., 1995, PSYCHOMUSICOLOGY, V14, P117, DOI DOI 10.1037/H0094088
   Collier WG, 2001, AM J PSYCHOL, V114, P355, DOI 10.2307/1423686
   Cook ND, 2007, MUSIC PERCEPT, V24, P315, DOI 10.1525/MP.2007.24.3.315
   Costa M, 2004, MUSIC PERCEPT, V22, P1, DOI 10.1525/mp.2004.22.1.1
   Costa M., 2000, PSYCHOL MUSIC, V28, P4, DOI [10.1177/0305735600281002, DOI 10.1177/0305735600281002]
   Cowie R, 2003, SPEECH COMMUN, V40, P5, DOI 10.1016/S0167-6393(02)00071-7
   CUNNINGHAM JG, 1988, MOTIV EMOTION, V12, P399, DOI 10.1007/BF00992362
   Dahl S, 2007, MUSIC PERCEPT, V24, P433, DOI 10.1525/MP.2007.24.5.433
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Dellacherie D, 2008, MUSIC PERCEPT, V25, P285, DOI 10.1525/MP.2008.25.4.285
   Dibben N, 2004, MUSIC PERCEPT, V22, P79, DOI 10.1525/mp.2004.22.1.79
   Dibben N, 2006, MUSIC ANAL, V25, P171, DOI 10.1111/j.1468-2249.2006.00237.x
   Douglas-Cowie E, 2003, SPEECH COMMUN, V40, P70
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   EFIMOVA IV, 2006, HUM PHYSIOL+, V32, P278, DOI DOI 10.1134/S0362119706030054
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Elfenbein HA, 2002, PSYCHOL BULL, V128, P203, DOI 10.1037//0033-2909.128.2.203
   Ellis RJ., 2005, Psychomusicology, V19, P15, DOI [DOI 10.1037/H0094042, 10.1037/h0094042]
   Erkkilä J, 2008, BMC PSYCHIATRY, V8, DOI 10.1186/1471-244X-8-50
   Eschrich S, 2008, BMC NEUROSCI, V9, DOI 10.1186/1471-2202-9-48
   Etzel JA, 2006, INT J PSYCHOPHYSIOL, V61, P57, DOI 10.1016/j.ijpsycho.2005.10.025
   Evans P, 2008, MUSIC SCI, V12, P75, DOI 10.1177/102986490801200105
   Faith M, 2001, SCAND J PSYCHOL, V42, P121, DOI 10.1111/1467-9450.00221
   Farnsworth P. R., 1954, J AESTHETICS ART CRI, V13, P97, DOI [10.1111/1540_6245.jaac13.1.0097, DOI 10.2307/427021]
   Flom R, 2008, INFANT BEHAV DEV, V31, P716, DOI 10.1016/j.infbeh.2008.04.004
   Flores-Gutiérrez EO, 2007, INT J PSYCHOPHYSIOL, V65, P69, DOI 10.1016/j.ijpsycho.2007.03.004
   Fredrickson W. E, 1995, PSYCHOL MUSIC, V23, P81, DOI 10.1177/0305735695231006
   Frego RJD, 1999, J RES MUSIC EDUC, V47, P31, DOI 10.2307/3345826
   Frijda NH, 2007, SOC SCI INFORM, V46, P433, DOI 10.1177/05390184070460030112
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Gabrielsson A, 2003, MUSIC SCI, V7, P157, DOI 10.1177/102986490300700201
   Gabrielsson A., 1995, Psychomusicol. J. Res. Music Cogn, V14, P94, DOI DOI 10.1037/H0094089
   Gabrielsson A., 2010, HDB MUSIC EMOTION TH, P367, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0014
   Gabrielsson A, 2001, MUSIC SCI, V5, P123, DOI 10.1177/10298649020050S105
   Gagnon L, 2003, COGNITION EMOTION, V17, P25, DOI 10.1080/02699930302279
   Gagnon L, 2000, BRAIN COGNITION, V43, P206
   GERARDI GM, 1995, MUSIC PERCEPT, V12, P279
   Geringer JM, 1996, J RES MUSIC EDUC, V44, P240, DOI 10.2307/3345597
   Gfeller K., 1991, PSYCHOMUSICOLOGY, V10, P31
   Gfeller K., 1991, PSYCHOL MUSIC, V19, P128, DOI DOI 10.1177/0305735691192004
   Gilboa A, 2006, J MUSIC THER, V43, P198, DOI 10.1093/jmt/43.3.198
   GIOMO CJ, 1993, PSYCHOL MUSIC, V21, P141, DOI DOI 10.1177/030573569302100204
   Gloeckner N., 2006, P 9 INT C MUS PERC C, P95
   Gomez P, 2004, INT J PSYCHOPHYSIOL, V53, P91, DOI 10.1016/j.ijpsycho.2004.02.002
   Gomez P, 2007, EMOTION, V7, P377, DOI 10.1037/1528-3542.7.2.377
   Gorn G, 2001, J CONSUM PSYCHOL, V11, P43, DOI 10.1207/S15327663JCP1101_4
   Gosselin N, 2005, BRAIN, V128, P628, DOI 10.1093/brain/awh420
   Gosselin N, 2007, NEUROPSYCHOLOGIA, V45, P236, DOI 10.1016/j.neuropsychologia.2006.07.012
   Gosselin N, 2006, BRAIN, V129, P2585, DOI 10.1093/brain/awl240
   Goydke KN, 2004, COGNITIVE BRAIN RES, V21, P351, DOI 10.1016/j.cogbrainres.2004.06.009
   Green AC, 2008, NEUROREPORT, V19, P711, DOI 10.1097/WNR.0b013e3282fd0dd8
   Gregory A. H., 1996, PSYCHOL MUSIC, V24, P47, DOI [10.1177/0305735696241005, DOI 10.1177/0305735696241005]
   Grewe O, 2007, EMOTION, V7, P774, DOI 10.1037/1528-3542.7.4.774
   Grewe O, 2007, MUSIC PERCEPT, V24, P297, DOI 10.1525/MP.2007.24.3.297
   Hargreaves DJ., 1999, PSYCHOL MUSIC, V27, P71, DOI DOI 10.1177/0305735699271007
   HERZ R. S., 1998, EMPIR STUD ARTS, V16, P137
   Hevner K, 1936, AM J PSYCHOL, V48, P246, DOI 10.2307/1415746
   Holbrook M.B., 1992, EMPIR STUD ARTS, V10, P19
   Hoshino E., 1996, PSYCHOL MUSIC, V24, P29, DOI [DOI 10.1177/0305735696241004, 10.1177/0305735696241004]
   Hubbard T.L, 1998, PSYCHOMUSICOLOGY J R, V17, P36, DOI DOI 10.1037/H0094060
   Hunter PG, 2008, COGNITION EMOTION, V22, P327, DOI 10.1080/02699930701438145
   Hunter PG, 2010, PSYCHOL AESTHET CREA, V4, P47, DOI 10.1037/a0016873
   Huron D, 2008, EMPIR MUSICOL REV, V3, P59, DOI 10.18061/1811/31940
   Husain G, 2002, MUSIC PERCEPT, V20, P151, DOI 10.1525/mp.2002.20.2.151
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Iwaki T, 1997, PERCEPT MOTOR SKILL, V84, P515, DOI 10.2466/pms.1997.84.2.515
   Iwanaga M, 1998, PERCEPT MOTOR SKILL, V86, P31, DOI 10.2466/pms.1998.86.1.31
   Izard CE, 2007, PERSPECT PSYCHOL SCI, V2, P260, DOI [10.1111/j.1745-6916.2007.00044.x, 10.1111/j.1745-6916.2007.00053.x]
   Juslin, 1997, PSYCHOMUSICOLOGY, V16, P77, DOI DOI 10.1037/H0094065
   Juslin P. N., 2000, MUSICAE SCI, V4, P151, DOI DOI 10.1177/102986490000400202
   Juslin P. N., 2011, HDB MUSIC EMOTION TH
   Juslin P. N., 1996, PSYCHOL MUSIC, V24, P68, DOI [10.1177/0305735696241007, DOI 10.1177/0305735696241007]
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2008, EMOTION, V8, P668, DOI 10.1037/a0013505
   Juslin PN, 2001, MUSIC SCI, V5, P3, DOI 10.1177/10298649020050S101
   Juslin PN, 2001, MUSIC SCI, V5, P63, DOI 10.1177/10298649020050S104
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Juslin PN, 1999, MUSIC PERCEPT, V17, P197
   Juslin PN, 1997, MUSIC PERCEPT, V14, P383
   Juslin PN, 1997, MUSIC SCI, V1, P225, DOI DOI 10.1177/102986499700100205
   Kabuto M, 1993, Nihon Eiseigaku Zasshi, V48, P807
   Kallinen K, 2004, PERS INDIV DIFFER, V37, P275, DOI 10.1016/j.paid.2003.09.002
   Kallinen K., 2005, Psychology of Music, V33, P373, DOI DOI 10.1177/0305735605056147
   Kallinen K, 2006, MUSIC SCI, V10, P191, DOI 10.1177/102986490601000203
   Kamenetsky S.B., 1997, PSYCHOL MUSIC, V25, P149
   KASTNER MP, 1990, MUSIC PERCEPT, V8, P189
   Khalfa S, 2005, NEUROREPORT, V16, P1981, DOI 10.1097/00001756-200512190-00002
   Khalfa S, 2002, NEUROSCI LETT, V328, P145, DOI 10.1016/S0304-3940(02)00462-7
   Khalfa S, 2008, INT J PSYCHOPHYSIOL, V68, P17, DOI 10.1016/j.ijpsycho.2007.12.001
   Khalfa S, 2008, MUSIC PERCEPT, V25, P295, DOI 10.1525/MP.2008.25.4.295
   Kim J, 2008, IEEE T PATTERN ANAL, V30, P2067, DOI 10.1109/TPAMI.2008.26
   Kinsella G, 1990, Arch Clin Neuropsychol, V5, P359, DOI 10.1016/0887-6177(90)90015-H
   Kivy P., 1990, Music Alone: Philosophical Reflections on the Purely Musical Experience
   Koelsch S, 2005, ANN NY ACAD SCI, V1060, P412, DOI 10.1196/annals.1360.034
   Koelsch S, 2006, HUM BRAIN MAPP, V27, P239, DOI 10.1002/hbm.20180
   Koelsch S, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0002631
   Koelsch S, 2008, NEUROREPORT, V19, P1815, DOI 10.1097/WNR.0b013e32831a8722
   Konecni V. J., 2008, Psychol. Aesthetics, Creativity, Arts, V2, P115, DOI DOI 10.1037/1931-3896.2.2.115
   Konecni VJ, 2008, PSYCHOL MUSIC, V36, P289, DOI 10.1177/0305735607082621
   Konecni VJ, 2007, AM J PSYCHOL, V120, P619, DOI 10.2307/20445428
   Korhonen MD, 2006, IEEE T SYST MAN CY B, V36, P588, DOI 10.1109/TSMCB.2005.862491
   Kreutz G, 2004, J BEHAV MED, V27, P623, DOI 10.1007/s10865-004-0006-9
   Kreutz G, 2002, MUSIC SCI, V6, P257, DOI 10.1177/102986490200600207
   Kreutz G, 2008, PSYCHOL MUSIC, V36, P101, DOI 10.1177/0305735607082623
   Krumhansl CL, 1997, CAN J EXP PSYCHOL, V51, P336, DOI 10.1037/1196-1961.51.4.336
   Krumhansl CL, 1998, MUSIC PERCEPT, V16, P119
   Lang P.J., 1999, The center for research in psychophysiology
   Larsen R. J., 1992, Emotion: Review of Personality and Social Psychology, P25, DOI DOI 10.1177/0004867420943943
   Lartillot O., 2007, P INT C DIG AUD EFF, DOI DOI 10.1007/978-3-540-78246-9_31
   Laukka P., 2007, J Happiness Stud, V8, P215, DOI [10.1007/s10902-006-9024-3, DOI 10.1007/S10902-006-9024-3]
   Leman M, 2005, J NEW MUSIC RES, V34, P39, DOI 10.1080/09298210500123978
   Lerdahl F., 2001, Tonal Pitch Space
   Lesiuk T., 2005, PSYCHOL MUSIC, V33, P173, DOI DOI 10.1177/0305735605050650
   Lindström E, 2006, MUSIC SCI, V10, P85, DOI 10.1177/102986490601000105
   Lindström E, 2003, J NEW MUSIC RES, V32, P269, DOI 10.1076/jnmr.32.3.269.16865
   Lindstrom E, 2001, MUSIC EMOTION THEORY, P235
   Lindstrom E, 2003, RES STUDIES MUSIC ED, V20, P23, DOI DOI 10.1177/1321103X030200010201
   Livingstone SR, 2007, DIGIT CREAT, V18, P43, DOI 10.1080/14626260701253606
   London J, 2001, MUSIC SCI, V5, P23, DOI 10.1177/10298649020050S102
   Lowis MJ, 2002, CREATIVITY RES J, V14, P351, DOI 10.1207/S15326934CRJ1434_6
   Lu L, 2006, IEEE T AUDIO SPEECH, V14, P5, DOI 10.1109/TSA.2005.860344
   Luck G., 2006, Nord. J. Music Ther, V15, P30, DOI DOI 10.1080/08098130609478149
   Luck G, 2008, PSYCHOL MUSIC, V36, P25, DOI 10.1177/0305735607079714
   Lundqvist LO, 2009, PSYCHOL MUSIC, V37, P61, DOI 10.1177/0305735607086048
   MacDonald R. A. R., 2003, Psychology of Music, V31, P187, DOI DOI 10.1177/0305735603031002294
   MacDorman KF, 2007, J NEW MUSIC RES, V36, P281, DOI 10.1080/09298210801927846
   Madison G, 2000, J NEW MUSIC RES, V29, P335, DOI 10.1080/09298210008565466
   Madsen C. K., 1997, Psychomusicology, V16, P59
   Madsen CK, 1998, J RES MUSIC EDUC, V46, P546, DOI 10.2307/3345350
   Madsen CK, 1997, J MUSIC THER, V34, P187, DOI 10.1093/jmt/34.3.187
   MADSEN CK, 1993, J MUSIC THER, V30, P46, DOI 10.1093/jmt/30.1.46
   Makris I, 2003, AM J PSYCHOL, V116, P581, DOI 10.2307/1423661
   Mancini M, 2007, IEEE T AUDIO SPEECH, V15, P1833, DOI 10.1109/TASL.2007.899256
   Martin MA, 1997, ART PSYCHOTHER, V24, P447, DOI 10.1016/S0197-4556(97)00020-8
   Matsuura M., 1998, JAPANESE J PHYSL PSY, V16, P13
   Mauss I, 2009, COGNITION EMOTION, V23, P209, DOI 10.1080/02699930802204677
   McAdams S, 2004, MUSIC PERCEPT, V22, P297, DOI 10.1525/mp.2004.22.2.297
   McEvilly DK, 1999, MUSIC PERCEPT, V16, P457
   MCFARLAND RA, 1989, BIOFEEDBACK SELF-REG, V14, P281, DOI 10.1007/BF00999119
   MCFARLAND RA, 1989, PERCEPT MOTOR SKILL, V68, P435, DOI 10.2466/pms.1989.68.2.435
   McNair DM., 1981, Manual for the Profile of Mood States (POMS): Technical manual
   Meyer LB., 1956, Emotion and meaning in music
   Meyer RK, 1998, MUSIC PERCEPT, V16, P135
   Miller M.M., 2002, Psychology of Music, V30, P8, DOI [10.1177/0305735602301004, DOI 10.1177/0305735602301004]
   Mitterschiffthaler MT, 2007, HUM BRAIN MAPP, V28, P1150, DOI 10.1002/hbm.20337
   MOROZOV VP, 1996, LOGOP PHONIATR VOCO, V21, P49, DOI DOI 10.3109/14015439609099203
   Morton J.B., 2007, PSYCHOL MUSIC, V35, P629, DOI [DOI 10.1177/0305735607076445, 10.1177/0305735607076445]
   Mulder J, 2010, PSYCHOL MUSIC, V38, P67, DOI 10.1177/0305735609104349
   Nagel F, 2008, MUSIC SCI, V12, P101, DOI 10.1177/102986490801200106
   Nagel F, 2007, BEHAV RES METHODS, V39, P283, DOI 10.3758/BF03193159
   Napoles J, 2008, INT J MUSIC EDUC, V26, P63, DOI 10.1177/0255761407085650
   Nater UM, 2006, INT J PSYCHOPHYSIOL, V62, P300, DOI 10.1016/j.ijpsycho.2006.05.011
   Nawrot ES., 2003, Psychol. Music, V31, P75, DOI DOI 10.1177/0305735603031001325
   NIELZEN S, 1993, PSYCHOPATHOLOGY, V26, P13, DOI 10.1159/000284795
   North AC, 2004, MUSIC PERCEPT, V22, P41, DOI 10.1525/mp.2004.22.1.41
   North AC, 1997, SCAND J PSYCHOL, V38, P45, DOI 10.1111/1467-9450.00008
   Nussbaum Charles O., 2007, MUSICAL REPRESENTATI
   Nyklicek I, 1997, J PSYCHOPHYSIOL, V11, P304
   Ockelford A, 2005, J ROY MUSIC ASSN, V130, P74, DOI 10.1093/jrma/fki002
   ORTONY A, 1990, PSYCHOL REV, V97, P315, DOI 10.1037/0033-295X.97.3.315
   Pallesen KJ, 2005, ANN NY ACAD SCI, V1060, P450, DOI 10.1196/annals.1360.047
   Panksepp J, 1995, MUSIC PERCEPT, V13, P171
   PANKSEPP J, 1992, PSYCHOL REV, V99, P554, DOI 10.1037/0033-295X.99.3.554
   Panksepp J., 2004, Affective Neuroscience
   Panksepp J., 1997, INT J ART MED, V5, P18
   Pelletier CL, 2004, J MUSIC THER, V41, P192, DOI 10.1093/jmt/41.3.192
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   Peretz I, 1999, NEUROCASE, V5, P21, DOI 10.1093/neucas/5.1.21
   Peretz I, 2001, BRAIN, V124, P928, DOI 10.1093/brain/124.5.928
   Peretz I., 2013, HDB MUSIC EMOTION TH, P99, DOI [10.1093/acprof:oso/9780199230143.003.0005, DOI 10.1093/ACPROF:OSO/9780199230143.003.0005]
   PIGNATIELLO M, 1989, J MUSIC THER, V26, P140, DOI 10.1093/jmt/26.3.140
   Posner J, 2005, DEV PSYCHOPATHOL, V17, P715, DOI 10.1017/S0954579405050340
   Ravaja N, 2004, SCAND J PSYCHOL, V45, P231, DOI 10.1111/j.1467-9450.2004.00399.x
   Rawlings D, 2008, PSYCHOL MUSIC, V36, P269, DOI 10.1177/0305735607086042
   Resnicow JE, 2004, MUSIC PERCEPT, V22, P145, DOI 10.1525/mp.2004.22.1.145
   Rickard N. S., 2004, Psychology of Music, V32, P371, DOI [10.1177%2F0305735604046096, DOI 10.1177/0305735604046096, 10.1177/0305735604046096]
   RITOSSA D.A., 2004, PSYCHOL MUSIC, V32, P5, DOI DOI 10.1177/0305735604039281
   ROBAZZA C, 1994, PERCEPT MOTOR SKILL, V79, P939, DOI 10.2466/pms.1994.79.2.939
   Roy M, 2008, PAIN, V134, P140, DOI 10.1016/j.pain.2007.04.003
   Roy M, 2009, INT J PSYCHOPHYSIOL, V71, P37, DOI 10.1016/j.ijpsycho.2008.07.010
   Rozin A, 2004, MUSIC PERCEPT, V22, P15, DOI 10.1525/mp.2004.22.1.15
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   RUSSELL JA, 1983, J PERS SOC PSYCHOL, V45, P1281, DOI 10.1037/0022-3514.45.6.1281
   Salomonsson B., 1989, SCANDINAVIAN PSYCHOA, V12, P126
   Sammler D, 2007, PSYCHOPHYSIOLOGY, V44, P293, DOI 10.1111/j.1469-8986.2007.00497.x
   Särkämö T, 2008, BRAIN, V131, P866, DOI 10.1093/brain/awn013
   Schellenberg E. G., 2007, Psychology of Music, V35, P5, DOI [DOI 10.1177/0305735607068885, 10.1177/0305735607068885]
   Schellenberg EG, 2008, COGNITION EMOTION, V22, P218, DOI 10.1080/02699930701350753
   Schellenberg EG, 2000, MUSIC PERCEPT, V18, P155
   Scherer K. R., 2001, MUSIC EMOTION THEORY, P361, DOI DOI 10.1080/0929821042000317822
   Scherer KR, 2001, MUSIC SCI, V5, P149, DOI 10.1177/10298649020050S106
   Scherer KR, 2004, J NEW MUSIC RES, V33, P239, DOI 10.1080/0929821042000317822
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   Schimmack U, 2000, EUR J PERSONALITY, V14, P325, DOI 10.1002/1099-0984(200007/08)14:4<325::AID-PER380>3.0.CO;2-I
   Schmidt LA, 2001, COGNITION EMOTION, V15, P487, DOI 10.1080/0269993004200187
   Schubert E, 2004, MUSIC PERCEPT, V21, P561, DOI 10.1525/mp.2004.21.4.561
   Schubert E, 2003, PERCEPT MOTOR SKILL, V96, P1117, DOI 10.2466/PMS.96.4.1117-1122
   Schubert E, 1999, AUST J PSYCHOL, V51, P154, DOI 10.1080/00049539908255353
   Schubert E., 1996, PSYCHOL MUSIC, V24, P18, DOI DOI 10.1177/0305735696241003
   Schubert E., 2007, Psychology of Music, V35, P499, DOI [10.1177/0305735607072657, DOI 10.1177/0305735607072657]
   Schubert E, 2001, MUSIC SCI, V5, P213, DOI 10.1177/10298649020050S108
   Schutz M, 2008, EMPIR MUSICOL REV, V3, P126, DOI 10.18061/1811/34103
   SIEGWART H, 1995, J VOICE, V9, P249, DOI 10.1016/S0892-1997(05)80232-2
   Silvia PJ, 2002, COGNITION EMOTION, V16, P845, DOI 10.1080/02699930143000671
   Sloboda J. A., 2001, MUSIC EMOTION THEORY, P415
   Sloboda J. A., 1991, Psychology of Music, V19, P110, DOI [10.1177/0305735691192002, DOI 10.1177/0305735691192002]
   Sloboda JA, 2001, MUSIC PERCEPT, V19, P87, DOI 10.1525/mp.2001.19.1.87
   Sloboda JA, 2001, MUSIC SCI, V5, P237, DOI 10.1177/10298649020050S109
   Sousou SD, 1997, PERCEPT MOTOR SKILL, V85, P31, DOI 10.2466/pms.1997.85.1.31
   Spreckelmeyer KN, 2006, BRAIN RES, V1070, P160, DOI 10.1016/j.brainres.2005.11.075
   Steinbeis N, 2006, J COGNITIVE NEUROSCI, V18, P1380, DOI 10.1162/jocn.2006.18.8.1380
   Stratton V. N., 1994, Empir. Stud. Arts, V12, P173, DOI [10.2190/35T0-U4DT-N09Q-LQHW, DOI 10.2190/35T0-U4DT-N09Q-LQHW]
   Suda M, 2008, NEUROREPORT, V19, P75, DOI 10.1097/WNR.0b013e3282f3476f
   Sundberg J., 1994, STL QPSR, V35, P217
   Tan SL, 2007, MUSIC PERCEPT, V25, P135, DOI 10.1525/MP.2007.25.2.135
   Terwogt M. M., 1991, PSYCHOL MUSIC, V19, P99, DOI DOI 10.1177/0305735691192001
   TERWOGT MM, 1988, PERCEPT MOTOR SKILL, V67, P697, DOI 10.2466/pms.1988.67.3.697
   THAUT MH, 1993, J MUSIC THER, V30, P210, DOI 10.1093/jmt/30.4.210
   Thayer JF, 2001, ANN NY ACAD SCI, V930, P452, DOI 10.1111/j.1749-6632.2001.tb05768.x
   Thayer RE., 1990, The Biopsychology of Mood and Activation
   Thoma M., 2006, P 9 INT C MUS PERC C, P1088
   Thompson W., 1992, Empirical Studies of the Arts, V10, P79, DOI DOI 10.2190/NBNY-AKDK-GW58-MTEL
   Thompson WF, 2001, PSYCHOL SCI, V12, P248, DOI 10.1111/1467-9280.00345
   Thompson WF, 2008, COGNITION EMOTION, V22, P1457, DOI 10.1080/02699930701813974
   Timmers R, 2007, MUSIC PERCEPT, V25, P117, DOI 10.1525/MP.2007.25.2.117
   Trehub SE, 2001, MUSIC SCI, V5, P37, DOI 10.1177/10298649020050S103
   Tugade MM, 2004, J PERS, V72, P1161, DOI 10.1111/j.1467-6494.2004.00294.x
   Unwin MM., 2002, Psychology of Music, V30, P175, DOI [10.1177/0305735602302004, DOI 10.1177/0305735602302004]
   VAITL D, 1993, STRUCTURE EMOTION PS, P169
   van Eijck K, 2001, SOC FORCES, V79, P1163, DOI 10.1353/sof.2001.0017
   VANDERARK SD, 1993, PERCEPT MOTOR SKILL, V77, P227, DOI 10.2466/pms.1993.77.1.227
   Västfjäll D, 2001, MUSIC SCI, V5, P173
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   Vines BW, 2005, ANN NY ACAD SCI, V1060, P462, DOI 10.1196/annals.1360.052
   Vink A., 2001, NORD J MUSIC THER, V10, P144
   Volpe, 2006, PSYCHOL MUSIC, V34, P481, DOI [DOI 10.1177/0305735606067165, 10.1177/0305735606067165]
   Vuoskoski JK, 2011, CORTEX, V47, P1099, DOI 10.1016/j.cortex.2011.04.011
   Waterman M., 1996, Psychology of Music, V24, P53, DOI [10.1177/0305735696241006, DOI 10.1177/0305735696241006]
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Watson D, 1999, J PERS SOC PSYCHOL, V76, P820, DOI 10.1037/0022-3514.76.5.820
   WEDIN L, 1972, SCAND J PSYCHOL, V13, P241, DOI 10.1111/j.1467-9450.1972.tb00072.x
   WELLS A, 1991, JOURNALISM QUART, V68, P445, DOI 10.1177/107769909106800315
   Witvliet CVO, 2007, COGNITION EMOTION, V21, P3, DOI 10.1080/02699930601000672
   Woody R. H., 2002, MUSIC EDUC RES, V4, P213, DOI DOI 10.1080/1461380022000011920
   Yang YH, 2008, IEEE T AUDIO SPEECH, V16, P448, DOI 10.1109/TASL.2007.911513
   ZAJONC RB, 1980, AM PSYCHOL, V35, P151, DOI 10.1037/0003-066X.35.2.151
   Zanon P, 2003, COMPUT MUSIC J, V27, P29, DOI 10.1162/01489260360613326
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 295
TC 221
Z9 257
U1 10
U2 101
PU UNIV CALIFORNIA PRESS
PI OAKLAND
PA 155 GRAND AVE, SUITE 400, OAKLAND, CA 94612-3758 USA
SN 0730-7829
J9 MUSIC PERCEPT
JI Music Percept.
PD FEB
PY 2013
VL 30
IS 3
BP 307
EP 340
DI 10.1525/mp.2012.30.3.307
PG 34
WC Music; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music; Psychology
GA 152MT
UT WOS:000319536500006
OA Green Published
DA 2024-01-09
ER

PT J
AU Kumar, M
   Abhayapala, TD
   Samarasinghe, P
AF Kumar, Manish
   Abhayapala, Thushara D.
   Samarasinghe, Prasanga
TI A Preliminary Investigation on Frequency Dependant Cues for Human
   Emotions
SO ACOUSTICS
LA English
DT Article
DE emotion recognition; emotion cues; pure tone; frequency dependent
   relationship
ID VOCAL EXPRESSION; RECOGNITION; SPEECH; AUDIO; MUSIC
AB The recent advances in Human-Computer Interaction and Artificial Intelligence have significantly increased the importance of identifying human emotions from different sensory cues. Hence, understanding the underlying relationships between emotions and sensory cues have become a subject of study in many fields including Acoustics, Psychology, Psychiatry, Neuroscience and Biochemistry. This work is a preliminary step towards investigating cues for human emotion on a fundamental level by aiming to establish relationships between tonal frequencies of sound and emotions. For that, an online perception test is conducted, in which participants are asked to rate the perceived emotions corresponding to each tone. The results show that a crossover point for four primary emotions lies in the frequency range of 417-440 Hz, thus consolidating the hypothesis that the frequency range of 432-440 Hz is neutral from human emotion perspective. It is also observed that the frequency dependant relationships between emotion pairs Happy-Sad, and Anger-Calm are approximately mirrored symmetric in nature.
C1 [Kumar, Manish; Abhayapala, Thushara D.; Samarasinghe, Prasanga] Australian Natl Univ, Sch Engn, Audio & Acoust Signal Proc Grp, Canberra, ACT 2601, Australia.
C3 Australian National University
RP Kumar, M; Abhayapala, TD; Samarasinghe, P (corresponding author), Australian Natl Univ, Sch Engn, Audio & Acoust Signal Proc Grp, Canberra, ACT 2601, Australia.
EM manish.kumar@anu.edu.au; thushara.abhayapala@anu.edu.au;
   prasanga.samarasinghe@anu.edu.au
OI Abhayapala, Thushara/0000-0001-6937-7218; Kumar,
   Manish/0000-0001-9589-7858
CR Adolphs R, 2002, EMOTION, V2, P23, DOI 10.1037/1528-3542.2.1.23
   Alías F, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6050143
   Alm M, 2014, J ACOUST SOC AM, V136, P2816, DOI 10.1121/1.4896464
   Anaya EM, 2016, J ACOUST SOC AM, V140, P2074, DOI 10.1121/1.4962628
   [Anonymous], 2002, DES J
   [Anonymous], 2013, HUMAN EMOTIONS
   Aouani Hadhami, 2020, Procedia Computer Science, V176, P251, DOI 10.1016/j.procs.2020.08.027
   Asutay E, 2012, J AUDIO ENG SOC, V60, P21
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Brumm H, 2011, BEHAVIOUR, V148, P1173, DOI 10.1163/000579511X605759
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   Castellano G, 2008, LECT NOTES COMPUT SC, V4868, P92, DOI 10.1007/978-3-540-85099-1_8
   Choi Y, 2015, BEHAV RES METHODS, V47, P1076, DOI 10.3758/s13428-014-0525-4
   Davidson L.S, 2018, J ACOUST SOC AM, V143, P1721, DOI [10.1121/1.5035607, DOI 10.1121/1.5035607]
   Fangfang ZZ, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062343
   Gangemi A, 2014, CURR ISS THINK REASO, P44
   Goudbeek M, 2010, J ACOUST SOC AM, V128, P1322, DOI 10.1121/1.3466853
   Hinkle B.M., 1923, RE CREATING INDIVIDU
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kao F-C, 2015, ISAA, V12, P1263
   Liu HR, 2021, FRONT COMPUT NEUROSC, V15, DOI 10.3389/fncom.2021.758212
   Liu SH, 2021, J ACOUST SOC AM, V149, P1338, DOI 10.1121/10.0003530
   Luo X, 2016, J ACOUST SOC AM, V140, pEL497, DOI 10.1121/1.4971758
   Ma F, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12010527
   Ma F, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10207239
   Mengmeng Liu, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015. Proceedings: LNCS 8936, P470, DOI 10.1007/978-3-319-14442-9_52
   Mittal Trisha, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14222, DOI 10.1109/CVPR42600.2020.01424
   Niu Y., 2017, ARXIV
   Nordström H, 2019, J ACOUST SOC AM, V145, P3058, DOI 10.1121/1.5108601
   Ooi CS, 2014, EXPERT SYST APPL, V41, P5858, DOI 10.1016/j.eswa.2014.03.026
   Palmblad S, 2018, THESIS SKOVDE U SKOV
   Paquette S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00509
   Pereira C., 2013, INT J SCI RES, V5, P761
   Picard Rosalind W, 2000, Affective Computing
   RUSSELL JA, 1989, J PERS SOC PSYCHOL, V57, P848, DOI 10.1037/0022-3514.57.5.848
   Saganowski S, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11030496
   Scherer KR, 2007, EMOTION, V7, P158, DOI 10.1037/1528-3542.7.1.158
   Shu L, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072074
   Steidl S, 2005, INT CONF ACOUST SPEE, P317
   Vastfjall D., 2012, Psychology, V3, P606, DOI DOI 10.4236/PSYCH.2012.38091
   Västfjäll D, 2001, MUSIC SCI, V5, P173
   VITZ PC, 1972, PERCEPT PSYCHOPHYS, V11, P84, DOI 10.3758/BF03212689
   Wiercinski T, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22082980
   WILLIAMSON DF, 1989, ANN INTERN MED, V110, P916, DOI 10.7326/0003-4819-110-11-916
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zielinski SK, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9091724
NR 46
TC 0
Z9 0
U1 1
U2 5
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2624-599X
J9 ACOUSTICS-BASEL
JI Acoustics
PD JUN
PY 2022
VL 4
IS 2
BP 460
EP 468
DI 10.3390/acoustics4020028
PG 9
WC Acoustics
WE Emerging Sources Citation Index (ESCI)
SC Acoustics
GA 2N4JA
UT WOS:000818346200001
OA gold, Green Submitted
DA 2024-01-09
ER

PT J
AU Jaakkola, I
AF Jaakkola, Inkeri
TI Vocal characterisation of the dramatis personae in Paavo Heininen's
   Silkkirumpu op. 45 and Kaija Saariaho's Adriana mater
SO COGENT ARTS & HUMANITIES
LA English
DT Article
DE contemporary opera; vocal characterisation; Paavo Heininen; Kaija
   Saariaho
ID MUSIC
AB This article discusses the composer's contribution to the vocal characterisation of the dramatis personae in contemporary opera. The composer can formulate the musical and expressive content of the soloists' vocal parts to create a distinctive musical identity for each character. Throughout the course of the drama, the characters' changing attitudes, emotions and moods are expressed through transformed constructions of their vocal parts, and the meanings are mediated to the audience largely through the combined effect of the various components in their vocal characterisation. By observing the vocal characterisation, as indicated by the composer in the score, vocal parts must thus be approached as compound analytical objects, in which various dimensions combine to create the appropriate musical and dramatic effect. This article describes the vocal characterisation of the dramatis personae in Paavo Heininen's opera Silkkirumpu (The Damask Drum) op. 45 (1981-1983) and in Kaija Saariaho's Adriana Mater (2005). Heininen's The Autumns (1970) for mixed choir and Reality (1978) for soprano and instrumental ensemble are introduced as pre-works of Silkkirumpu. The examination of vocal writing in these pieces thus extends the discussion to vocal music other than opera. Following a brief description of the concept of vocal characterisation in general and an introduction of the analytical approach, the text focuses on musical examples. In conclusion, it is suggested that the analytical approach could be extended to include the unique aspects of vocal performances.
C1 [Jaakkola, Inkeri] Univ Arts Helsinki, Sibelius Acad, Dept Mus Theory & Composit, Tervaskatu 42, Lahti 15240, Finland.
C3 University of the Arts Helsinki
RP Jaakkola, I (corresponding author), Univ Arts Helsinki, Sibelius Acad, Dept Mus Theory & Composit, Tervaskatu 42, Lahti 15240, Finland.
EM inkeri.jaakkola@uniarts.fi
CR AGAWU K, 1992, MUSIC ANAL, V11, P3, DOI 10.2307/854301
   [Anonymous], 2010, EXPRESSION PERFORMIN
   Behler Ernst, 1990, Irony and the Discourse of Modernity
   Cavarero Adriana., 2005, For More Than One Voice: Toward a Philosophy of Vocal Expression
   Cicali G, 2009, CAMB COMPANION MUSIC, P85
   Colebrook C., 2004, Irony: The New Critical Idiom
   CONE Edward T., 1974, The Composer's Voice
   Duncan M., 2004, CAMB OPERA J, V16, P283, DOI DOI 10.1017/S0954586704001879
   Everett Y. U., 2015, Reconfiguring Myth and Narrative in Contemporary Opera: Osvaldo Golijov, Kaija Saariaho
   Everett Y. U., 2013, MUSIC NARRATIVE 1900, P29
   Everett Y. U., 2006, MUSIC L ANDRIESSEN, DOI [https://doi.org/10.1017/CBO9780511482007, DOI 10.1017/CBO9780511482007]
   Everett YU, 2009, MUSIC THEOR SPECTRUM, V31, P26, DOI 10.1525/mts.2009.31.1.26
   Frymoyer J, 2017, MUSIC THEOR SPECTRUM, V39, P83, DOI 10.1093/mts/mtx004
   Grant M. J., 2001, Serial Music, Serial Aesthetics: Compositional Theory in Post-War Europe
   Halliwell Stephen, 1987, Poetics
   Hanninen DA, 2012, MUSIC THEOR SPECTRUM, V34, P11, DOI 10.1525/mts.2012.34.1.11
   Hare T. B., 1986, Zeami's Style: The noh Plays of Zeami Motokiyo
   Haringer Andrew, 2014, The Oxford Handbook o f Topic Theory, P194, DOI [10.1093/oxfordhb/9780199841578.013.008, DOI 10.1093/OXFORDHB/9780199841578.013.008]
   Hatten R., 2019, THEORY VIRTUAL AGENC, DOI [10.2307/j.ctv512trj, DOI 10.2307/J.CTV512TRJ]
   Heile B, 2006, MUSIC LETT, V87, P72, DOI 10.1093/ml/gci179
   Heininen P., 1989, SILKKIRUMPU DAMASK D
   Heininen P., 1984, SILKKIRUMPU KONSERTT
   Heininen P., 1989, AUTUMNS 22 MIXED CHO
   Heininen P., 1990, SILKKIRUMPU 45 DAMAS
   Heininen P., 1998, SAVELLYS JA MUSIIKIN, V1998
   Heininen P., 1978, FENNICA NOVA FEN01
   Heininen P., 1978, REALITY OP 41 SOPRAN, V2010
   Heininen P., 1981, SILKKIRUMPU DAMASK D, V1983
   Hirst L., 2000, Cambridge Companion to Singing, P192, DOI https://doi.org/10.1017/CCOL9780521622257.017
   Howe B, 2016, MUSIC THEOR SPECTRUM, V38, P218, DOI 10.1093/mts/mtw014
   Howland P, 2015, MUSIC THEOR SPECTRUM, V37, P71, DOI 10.1093/mts/mtv011
   Jaa V., 2021, ARTISTS OFFICIAL INT
   Jaakkola I., 2020, STUDIA MUSICA
   Jander O., 2001, GROVE MUSIC ONLINE, DOI [10.1093/gmo/9781561592630.001.0001/omo-9781561592630-e-0000002551?rskey=A59VfY&result=1, DOI 10.1093/GMO/9781561592630.001.0001/OMO-9781561592630-E-0000002551?RSKEY=A59VFY&RESULT=1]
   Kaipainen J., 1989, FINLANDIA RECORDS FA
   Klein ML, 2009, J MUSIC THEORY, V53, P95, DOI 10.1215/00222909-2009-022
   Kloiber R., 2016, Handbuch der Oper, V14th, revised
   Kurki-Suonio S., 2009, THESIS SIBELIUS ACAD
   Lennard J., 2002, The Drama Handbook: A Guide to Reading Plays
   Leydon R., 2013, MUSIC NARRATIVE 1900, P29
   Magee B., 2000, Wagner and Philosophy
   Manning J., 1986, NEW VOCAL REPERTOIRE, DOI [https://doi.org/10.1007/978-1-349-18494-1, DOI 10.1007/978-1-349-18494-1]
   Manning J., 1998, NEW VOCAL REPERTOIRE, V2
   Mason D, 2000, The Cambridge Companion to Singing, P204
   MEYER Leonard B., 1989, Style and Music: Theory, History, and Ideology
   Mitchells K., 1970, Proceedings of the Royal Musical Association, V97, P47
   Monelle Raymond., 2000, The Sense of Music: Semiotic Essays
   Morris C., 2002, Reading Opera Between the Lines: Orchestral Interludes and Cultural Meaning from Wagner to Berg
   MORRIS RD, 1993, MUSIC THEOR SPECTRUM, V15, P205, DOI 10.1525/mts.1993.15.2.02a00040
   Nair G., 2007, The Craft of Singing
   Nogami T., 2005, JAPANESE NOH PLAYS
   Novak J., 2015, POSTOPERA REINVENTIN, DOI [https://doi.org/10.4324/9781315601717, DOI 10.4324/9781315601717]
   Pettitt S, 2006, OPERA, V57, P285
   Pugliese R. M., 2004, Cambridge Opera Journal, V16, P23, DOI https://doi.org/10.1017/S0954586704001776
   Puumala V.-M., 2015, ANNA LIISA OPERA 3 A
   Richard S., 1983, CURR MUSICOLOGY, V36, P151
   Rimski-Korsakov N., 1964, Principles of Orchestration: With Musical Examples Drawn from His Own Works
   Rosselli J., 2000, The Cambridge Companion to Singing, P83, DOI 10.1017/CCOL9780521622257.008
   Rosselli J., 2000, The Cambridge Companion to Singing, P96, DOI https://doi.org/10.1017/CCOL9780521622257.009
   Rothstein W., 2008, MUSIC THEORY ONLINE, V3, P824, DOI [https://doi.org/10.30535/mto.14.1.3, DOI 10.30535/MTO.14.1.3]
   Rupprecht Philip, 2001, BRITTENS MUSICAL LAN
   Saariaho K., 2005, FULL SCORE
   Saariaho K., 2005, ADRIANA MAT OPERA 7
   Saariaho K., 1987, Contemporary Music Review, V111, P93, DOI [DOI 10.1080/07494468708567055, https://doi.org/10.1080/07494468708567055]
   Schneider M. T., 2013, LEGACY OPERA READING, P103, DOI [https://doi.org/10.1163/9789401209502_009, DOI 10.1163/9789401209502_009]
   Sheinberg Esti, 2000, Irony, Satire, Parody and the Grotesque in the Music of Shostakovich: A Theory of Musical Incongruities
   Stacey P., 1987, Boulez and the Modern Concept
   Stacey P., 1989, Contemporary Tendencies in the Relationship of Music to Text with Special Reference to "Pli selon Pli" (Boulez) and "Laborintus II"
   Stark James A., 1999, Bel Canto: A History of Vocal Pedagogy
   Stoianova I., 2007, WOHER WOHIN KOMPONIS, P37
   Straus J., 2005, Introduction to Post-Tonal Theory, V3rd
   SUURPAA Lauri, 2014, Death in Winterreise: Musico-Poetic Associations in Schubert's Song Cycle
   Symonds D., 2013, LEGACY OPERA READING, DOI [https://doi.org/10.1163/9789401209502, DOI 10.1163/9789401209502]
   Taruskin Richard., 2005, OXFORD HIST W MUSIC
   Weigel-Kramer J., 2012, THESIS HAMBURG U
   WELTEN R, 1996, TEMPO, V196, P21
   Williams A. E., 2000, Perspectives of New Music, V38, P77
   Willier S. A., 2002, OXFORD MUSIC ONLINE
   WISHART T, 1980, MUSIC TIMES, V121, P313, DOI 10.2307/963728
NR 79
TC 0
Z9 0
U1 0
U2 0
PU TAYLOR & FRANCIS AS
PI OSLO
PA KARL JOHANS GATE 5, NO-0154 OSLO, NORWAY
SN 2331-1983
J9 COGENT ARTS HUMANITE
JI Cogent Art Humanities
PD DEC 31
PY 2023
VL 10
IS 1
AR 2229974
DI 10.1080/23311983.2023.2229974
PG 26
WC Humanities, Multidisciplinary
WE Emerging Sources Citation Index (ESCI)
SC Arts & Humanities - Other Topics
GA N2MC3
UT WOS:001035405600001
OA gold
DA 2024-01-09
ER

PT J
AU Kopylov, A
   Seredin, O
   Filin, A
   Tyshkevich, B
AF Kopylov, Andrei
   Seredin, Oleg
   Filin, Andrei
   Tyshkevich, Boris
TI Detection of interactive voice response (IVR) in phone call records
SO INTERNATIONAL JOURNAL OF SPEECH TECHNOLOGY
LA English
DT Article
DE IVR; SVM; Gradient boosting; CNN; Speech analysis; GeMAPS;
   Log-spectrogram; Gammatonegram
ID EMOTION RECOGNITION
AB Separation of pre-recorded messages (Interactive Voice Response, IVR) from live speech fragments in real-time plays a significant role in speech emotion recognition (SER) systems, unwanted calls filtering, automatic detection of answering machine responses, reduction of stored record sizes, voice mail spam filtration, etc. The problem complexity is that, unlike with silent, music, and noise fragments studied by the conventional voice activity recognition (VAD), IVR usually contains speech. Three classifiers for live speech fragments detection in phone call records are considered: based on the support vector machine (SVM), gradient boosting (XGBoost) and convolutional neural network (CNN). The Geneva Minimalistic Acoustic Parameter Set for XGBoost and SVM, and log-spectrograms and gammatonegrams for CNN were used for feature representation of audio fragments. Experiments with a dataset of phone calls demonstrate comparable quality (around 0.96 according to the F1-averaged measure) of the considered algorithms with CNN having a advantage (0.98).
C1 [Kopylov, Andrei; Seredin, Oleg; Filin, Andrei] Tula State Univ, Tula, Russia.
   [Filin, Andrei; Tyshkevich, Boris] ITooLabs, Tula, Russia.
C3 Tula State University
RP Filin, A (corresponding author), Tula State Univ, Tula, Russia.; Filin, A (corresponding author), ITooLabs, Tula, Russia.
EM And.Kopylov@gmail.com; oseredin@yandex.ru; afilin@itoolabs.com;
   bvt@itoolabs.com
RI Kopylov, Andrei V/L-5993-2017; Filin, Andrei/HKF-1925-2023; Seredin,
   Oleg S/L-6282-2017
OI Kopylov, Andrei V/0000-0003-3193-583X; Seredin, Oleg
   S/0000-0003-0410-7705; Filin, Andrei/0000-0003-1028-0926
FU Tula State University [NIR_2018_20]
FX The results of the research project are published with the financial
   support of Tula State University within the framework of the scientific
   project NIR_2018_20.
CR Acero A, 2011, DETECTING ANSWERING
   Agbinya JI, 1996, TENCON IEEE REGION, P514, DOI 10.1109/TENCON.1996.608394
   Chen T., 2016, KDD16 P 22 ACM, P785, DOI DOI 10.1145/2939672.2939785
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Dahake PP, 2016, 2016 INTERNATIONAL CONFERENCE ON AUTOMATIC CONTROL AND DYNAMIC OPTIMIZATION TECHNIQUES (ICACDOT), P1080, DOI 10.1109/ICACDOT.2016.7877753
   Deng J, 2016, IEEE ACCESS, V4, P4299, DOI 10.1109/ACCESS.2016.2591442
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Eyben F., 2013, P 21 ACM INT C MULT, P835, DOI 10.1145/2502081.2502224
   Eyben F., 2009, AFFECTIVE COMPUTING, P1, DOI [DOI 10.1109/ACII.2009.5349350, 10.1109/ACII.2009.5349350]
   Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417
   Fayek HM, 2017, NEURAL NETWORKS, V92, P60, DOI 10.1016/j.neunet.2017.02.013
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Ju YC, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1902
   Kim JW, 2018, INTERSPEECH, P937, DOI 10.21437/Interspeech.2018-1132
   Koolagudi SG, 2012, INT J SPEECH TECHNOL, V15, P495, DOI 10.1007/s10772-012-9150-8
   Kopylov A., 2017, 18 ALL RUSS C INT PA, P132
   Lim WL, 2016, COMPUT INTEL NEUROSC, V2016, P1, DOI DOI 10.1109/APSIPA.2016.7820699
   Makarova V., 2002, 7 INT C SPOK LANG PR, P2041
   Meier M, 2016, INT CONF COGN INFO, P97, DOI 10.1109/CogInfoCom.2016.7804532
   MU Y, 2017, DESTECH TRANS COMP, V15, P341
   Pathak S., 2016, INT J ADV RES COMPUT, V5, P447
   Peng ZC, 2017, ASIAPAC SIGN INFO PR, P1750, DOI 10.1109/APSIPA.2017.8282316
   Poria S, 2019, IEEE ACCESS, V7, P100943, DOI 10.1109/ACCESS.2019.2929050
   Prasomphan S, 2015, PROCEEDINGS OF THE 2015 IEEE INTERNATIONAL CONFERENCE ON DATA SCIENCE AND ADVANCED ANALYTICS (IEEE DSAA 2015), P113
   Sainath TN, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P297, DOI 10.1109/ASRU.2013.6707746
   Savargiv M, 2016, 2016 ARTIFICIAL INTELLIGENCE AND ROBOTICS (IRANOPEN), P72, DOI 10.1109/RIOS.2016.7529493
   Seehapoch T., 2013, INT C KNOWL SMART TE, P86, DOI DOI 10.1109/KST.2013.6512793
   Shiota S, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P239
   Siegert I, 2017, ELEKTRONISCHE SPRACH, V86, P17
   Tabibi S, 2017, J NEUROSCI METH, V277, P63, DOI 10.1016/j.jneumeth.2016.12.004
   Vapnik VN, 1998, INTERPRETING
   Wen ZY, 2018, J MACH LEARN RES, V19
   Zhang LH, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P57, DOI 10.1145/3133956.3133962
   Zhang YS, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P2098
NR 34
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1381-2416
EI 1572-8110
J9 INT J SPEECH TECHNOL
JI Int. J. Speech Technol.
PD DEC
PY 2020
VL 23
IS 4
SI SI
BP 907
EP 915
DI 10.1007/s10772-020-09754-3
EA NOV 2020
PG 9
WC Engineering, Electrical & Electronic
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA OW1GK
UT WOS:000590237400001
DA 2024-01-09
ER

PT J
AU Snow, S
   Bernardi, NF
   Sabet-Kassouf, N
   Moran, D
   Lehmann, A
AF Snow, Shelley
   Bernardi, Nicolo Francesco
   Sabet-Kassouf, Nilufar
   Moran, Daniel
   Lehmann, Alexandre
TI Exploring the Experience and Effects of Vocal Toning
SO JOURNAL OF MUSIC THERAPY
LA English
DT Article
DE toning; voice; singing; music therapy; qualitative; mixed methods;
   interventions
ID MUSIC-THERAPY
AB Background: Toning is a form of vocalizing that utilizes the natural voice to express sounds ranging from cries, grunts, and groans to open vowel sounds and humming on the full exhalation of the breath. Music therapists are increasingly utilizing toning in their clinical practice for a variety of therapeutic aims. Yet the effects of toning are not widely understood, with limited research to date.
   Objective: To gather and analyze descriptive data to better understand the experience and effects of self-administered toning. Primary aims were to: 1) understand participants' experiences with toning, and any effects resulting from their experiences; 2) measure participants' emotional response to toning and singing; and 3) examine similarities and differences across the two datasets.
   Methods: Participants were 20 adults, ages 20-40 years, who were non-musicians. We conducted semi-structured interviews and used qualitative content analysis to identify major themes and subcategories related to participants' toning experiences. Participants also completed a 48-item questionnaire on music and emotions. Results from the interview and questionnaire data were then compared and contrasted.
   Results: Results indicate that shifts in attention, awareness, and consciousness frequently occurred when individuals engaged in toning. "Meditative," "calm," and "relaxed" were the three most common descriptors of toning. In contrast, singing evoked stronger emotions and associations than toning, with the three most common descriptors including "nostalgia," "tenderness," and "joyful activation." Findings also suggest that the physical experience with vibrations and the sound of one's own voice may be attributes of toning that likely contribute to its success in inducing altered states of awareness, attention, and consciousness.
   Conclusions: This study significantly expands our understanding of the experience and effects of toning, and has direct implications for clinical practice, including the identification of effective strategies to successfully engage adults in toning.
C1 [Snow, Shelley] Concordia Univ, Ctr Arts Human Dev, 7079 Terrebonne, Montreal, PQ, Canada.
   [Bernardi, Nicolo Francesco; Sabet-Kassouf, Nilufar] McGill Univ, Montreal, PQ, Canada.
   [Moran, Daniel] Concordia Univ, Montreal, PQ, Canada.
   [Lehmann, Alexandre] McGill Univ, Int Lab Brain Mus & Sound Res, Montreal, PQ, Canada.
   [Lehmann, Alexandre] McGill Univ, Ctr Res Brain Language & Mus, Montreal, PQ, Canada.
C3 Concordia University - Canada; McGill University; Concordia University -
   Canada; McGill University; Universite de Montreal; McGill University
RP Snow, S (corresponding author), Concordia Univ, Ctr Arts Human Dev, 7079 Terrebonne, Montreal, PQ, Canada.
EM shelley.snow@concordia.ca
FU Centre for the Arts in Human Development, Concordia University
FX Centre for the Arts in Human Development, Concordia University.
CR [Anonymous], SOUND HLTH MUSIC SOU
   [Anonymous], 2006, The art and science of mindfulness: Integrating mindfulness into psychology and the helping professions, DOI [DOI 10.1037/11885-007, 10.1037/11885-007]
   [Anonymous], 1997, MUSIC THERAPY PEDIAT
   [Anonymous], MEDITATION SELF REGU
   [Anonymous], 1993, HEALING VOICE TRADIT
   [Anonymous], 2006, INTERACTIVE MUSIC TH
   [Anonymous], MUSIC THERAPY HLTH E
   Austin D., 2009, THEORY PRACTICE VOCA
   BENSON H, 1974, PSYCHIATRY, V37, P37, DOI 10.1080/00332747.1974.11023785
   Bernardi L, 2001, BRIT MED J, V323, P1446, DOI 10.1136/bmj.323.7327.1446
   Bernardi NF, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-07171-2
   Boyce-Tillman June., 2000, Constructing Musical Healing: The Wounds that Sing
   Bradt J., 2013, GUIDELINES MUSIC THE
   Campbell D., 1989, ROAR SILENCE HEALING
   CLARK ME, 1990, BIOFEEDBACK SELF-REG, V15, P273, DOI 10.1007/BF01011109
   Clements-Cortés A, 2016, COMPLEMENT THER CLIN, V23, P125, DOI 10.1016/j.ctcp.2015.04.004
   CROWE BJ, 1996, MUSIC THERAPY PERSPE, V14, P21, DOI [10.1093/mtp/14.1.21, DOI 10.1093/MTP/14.1.21]
   Dileo C., 1999, Music therapy and medicine: Theoretical and clinical applications, P181
   Gardner, 1997, SOUNDING INNER LANDS
   Garfield M., 1987, SOUND MED HEALING MU
   Ghetti C.M., 2016, MUSIC THERAPY RES
   Goldman J., 2008, 7 SECRETS SOUND HEAL
   Goldman J., 1992, HEALING SOUNDS POWER
   Hilliard RE, 2006, ART PSYCHOTHER, V33, P395, DOI 10.1016/j.aip.2006.06.002
   Hsieh HF, 2005, QUAL HEALTH RES, V15, P1277, DOI 10.1177/1049732305276687
   Iliya YA, 2011, MUSIC THER PERSPECT, V29, P14, DOI 10.1093/mtp/29.1.14
   Keyes L., 1973, TONING CREATIVE POWE
   Koole S, 2009, COGNITION EMOTION, V23, P4, DOI 10.1080/02699930802619031
   MacDonald RAR, 2014, PSYCHOL WELL-BEING, V4, DOI 10.1186/s13612-014-0020-9
   MacIntosh HB, 2003, ART PSYCHOTHER, V30, P17, DOI 10.1016/S0197-4556(02)00229-0
   Magee WL., 2007, AUSTR J MUSIC THERAP, V18, P20
   Magill L., 2010, PSYCHO-ONCOLOGY, P22
   Magill L, 2009, J PALLIAT CARE, V25, P68, DOI 10.1177/082585970902500114
   McClellan R., 2000, HEALING FORCES MUSIC
   OCallaghan C, 2016, OXFORD HDB MUSIC THE, P112
   Pollack S., 2016, SITTING ESSENTIAL SK
   Pothoulaki M, 2012, J MUSIC THER, V49, P45, DOI 10.1093/jmt/49.1.45
   Purce J., 1987, REVISION, V10, P21
   RIDER M., 1991, APPL MUSIC MED, P73
   Snow S., 2011, THESIS
   Soanes C., 2005, OXFORD DICT ENGLISH
   Stige B, 2009, QUAL HEALTH RES, V19, P1504, DOI 10.1177/1049732309348501
   Tart C. T., 1972, Altered states of consciousness
   Van der Kolk B., 2016, PSYCHOTHERAPY 2 0 ON
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 45
TC 6
Z9 9
U1 0
U2 12
PU OXFORD UNIV PRESS INC
PI CARY
PA JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA
SN 0022-2917
EI 2053-7395
J9 J MUSIC THER
JI J. Music Ther.
PD SUM
PY 2018
VL 55
IS 2
BP 221
EP 250
DI 10.1093/jmt/thy003
PG 30
WC Music; Rehabilitation
WE Social Science Citation Index (SSCI)
SC Music; Rehabilitation
GA GI9VB
UT WOS:000434874200004
PM 29800304
DA 2024-01-09
ER

PT J
AU Chen, W
AF Chen, Wei
TI Application and Analysis of Emotion in Teaching of Conducting of Chorus
SO AGRO FOOD INDUSTRY HI-TECH
LA English
DT Article
DE emotion; chorus; conducting teaching; application
AB Chorus is a kind of artistic expression which expresses emotions through music. It is also a kind of common music carrier, representing emotional sustenance in an overall and perfect way. Chorus not only unifies sounds but also emotions. Put it another way, emotions are the expression core of the chorus music. Therefore, in conducting of chorus, transfer of emotions is of great importance. The conductor needs to use vivid body language or eye contact to transfer the emotions that the music creator wants to transfer and the conductor should be excellent in both voice and feeling. This essay aims to promote the perfect show of conducting and music's emotions in chorus by analyzing the necessity and application of emotion in teaching of conducting of chorus and clarifying the effective way to play the role of emotion.
C1 [Chen, Wei] TaiZhou Univ, Mus Coll, Taizhou, Jiangsu, Peoples R China.
C3 Taizhou University - Jiangsu
RP Chen, W (corresponding author), TaiZhou Univ, Mus Coll, Taizhou, Jiangsu, Peoples R China.
CR He Shigang, 2016, LIT LIFE, V8, P94
   Kang Yudan, 2015, J WUVI U, V34, P57
   Lan Zhongbing, 2016, ART ED, V23, P99
   Ren Chuyao, 2014, MUSIC TIMES, V4, P119
   Ren Yuanchun, 2016, NO MUSIC, V36, P63
   Sun Jingna, 2011, BIG STAGE, V18, P57
   Wang Daliang, 2014, BIG STAGE, V21, P114
   Wang Xiangping, 2013, COMPUTER LIT QUALITY, V7, P126
NR 8
TC 0
Z9 0
U1 0
U2 8
PU TEKNOSCIENZE PUBL
PI MILANO
PA VIALE BRIANZA 22, 20127 MILANO, ITALY
SN 1722-6996
EI 2035-4606
J9 AGRO FOOD IND HI TEC
JI Agro Food Ind. Hi-Tech
PD MAY-JUN
PY 2017
VL 28
IS 3
BP 3401
EP 3403
PG 3
WC Biotechnology & Applied Microbiology; Food Science & Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biotechnology & Applied Microbiology; Food Science & Technology
GA FB2SJ
UT WOS:000405993200360
DA 2024-01-09
ER

PT J
AU Kuriki, S
   Tamura, Y
   Igarashi, M
   Kato, N
   Nakano, T
AF Kuriki, Shinji
   Tamura, Yuri
   Igarashi, Miki
   Kato, Nobumasa
   Nakano, Tamami
TI Similar impressions of humanness for human and artificial singing voices
   in autism spectrum disorders
SO COGNITION
LA English
DT Article
DE Autism; Artificial voice; Humanness; Music
ID MIND PERCEPTION; CHILDREN; MUSIC; ALEXITHYMIA; INSULA; INDIVIDUALS;
   EMOTIONS; ROBOTS
AB People with autism spectrum disorder (ASD) exhibit impairments in the perception of and orientation to social information related to humans, and some people with ASD show higher preference toward human-like robots than other humans. We speculated that this behavioural bias in people with ASD is caused by a weakness in their perception of humanness. To address this issue, we investigated whether people with ASD detect a subtle difference between the same song sung by human and artificial voices even when the lyrics, melody and rhythm are identical. People without ASD answered that the songs sung by a human voice evoked more impressions of humanness (human-likeness, animateness, naturalness, emotion) and more positive feelings (warmth, familiarity, comfort) than those sung by an artificial voice. In contrast, people with ASD had similar impressions of humanness and positive feelings for the songs sung by the human and artificial voices. The evaluations of musical characteristics (complexity, regularity, brightness) did not differ between people with and without ASD. These results suggest that people with ASD are weak in their ability to perceive psychological attributes of humanness. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Kuriki, Shinji; Tamura, Yuri; Nakano, Tamami] Osaka Univ, Sch Med, Dept Brain Physiol, 2-2 Yamadaoka, Suita, Osaka 5650871, Japan.
   [Igarashi, Miki; Kato, Nobumasa] Showa Univ, Sch Med, Dept Psychiat, Tokyo, Japan.
   [Nakano, Tamami] Osaka Univ, Grad Sch Frontiers Biosci, 1-3 Yamadaoka, Suita, Osaka 5650871, Japan.
C3 Osaka University; Showa University; Osaka University
RP Nakano, T (corresponding author), Osaka Univ, Grad Sch Frontiers Biosci, 1-3 Yamadaoka, Suita, Osaka 5650871, Japan.
EM tamami_nakano@fbs.osaka-u.ac.jp
FU Ministry of Education, Culture, Sports, Science and Technology, Japan
   [251195040]; Grants-in-Aid for Scientific Research [15K12620] Funding
   Source: KAKEN
FX This work was supported by the Grant-in-Aid for Scientific Research on
   Innovative Areas 251195040 "Constructive Developmental Science" from the
   Ministry of Education, Culture, Sports, Science and Technology, Japan to
   T.N.
CR Alcántara JI, 2004, J CHILD PSYCHOL PSYC, V45, P1107, DOI 10.1111/j.1469-7610.2004.t01-1-00303.x
   Allen R, 2013, J AUTISM DEV DISORD, V43, P432, DOI 10.1007/s10803-012-1587-8
   Bamiou DE, 2003, BRAIN RES REV, V42, P143, DOI 10.1016/S0165-0173(03)00172-3
   Baron-Cohen S, 2001, J AUTISM DEV DISORD, V31, P5, DOI 10.1023/A:1005653411471
   Baron-Cohen S, 2006, PROG NEURO-PSYCHOPH, V30, P865, DOI 10.1016/j.pnpbp.2006.01.010
   Bird G, 2013, TRANSL PSYCHIAT, V3, DOI 10.1038/tp.2013.61
   Bird G, 2010, BRAIN, V133, P1515, DOI 10.1093/brain/awq060
   Broadbent E, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0072589
   Dawson G, 1998, J AUTISM DEV DISORD, V28, P479, DOI 10.1023/A:1026043926488
   Diehl JJ, 2012, RES AUTISM SPECT DIS, V6, P249, DOI 10.1016/j.rasd.2011.05.006
   Gebauer L, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00192
   Gray HM, 2007, SCIENCE, V315, P619, DOI 10.1126/science.1134475
   Gray K, 2012, COGNITION, V125, P125, DOI 10.1016/j.cognition.2012.06.007
   Gray K, 2011, P NATL ACAD SCI USA, V108, P477, DOI 10.1073/pnas.1015493108
   Haslam N, 2006, PERS SOC PSYCHOL REV, V10, P252, DOI 10.1207/s15327957pspr1003_4
   Heaton P, 1999, PSYCHOL MED, V29, P1405, DOI 10.1017/S0033291799001221
   Heaton P, 2008, BRIT J DEV PSYCHOL, V26, P171, DOI 10.1348/026151007X206776
   Jemel B, 2006, J AUTISM DEV DISORD, V36, P91, DOI 10.1007/s10803-005-0050-5
   Molnar-Szakacs I, 2012, ANN NY ACAD SCI, V1252, P318, DOI 10.1111/j.1749-6632.2012.06465.x
   Molnar-Szakacs Istvan, 2009, Mcgill J Med, V12, P87
   Mori M., 1970, Energy, V7, P33, DOI DOI 10.1109/MRA.2012.2192811
   Nakano T, 2010, P ROY SOC B-BIOL SCI, V277, P2935, DOI 10.1098/rspb.2010.0587
   Pierno AC, 2008, NEUROPSYCHOLOGIA, V46, P448, DOI 10.1016/j.neuropsychologia.2007.08.020
   Remedios R, 2009, J NEUROSCI, V29, P1034, DOI 10.1523/JNEUROSCI.4089-08.2009
   Tamura Y, 2015, SCI REP-UK, V5, DOI 10.1038/srep08799
   Thompson JC, 2011, PERCEPTION, V40, P695, DOI 10.1068/p6900
NR 26
TC 12
Z9 13
U1 1
U2 43
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD AUG
PY 2016
VL 153
BP 1
EP 5
DI 10.1016/j.cognition.2016.04.004
PG 5
WC Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA DQ9VZ
UT WOS:000379558700001
PM 27107740
DA 2024-01-09
ER

PT J
AU Trevor, C
   Devaney, J
   Huron, D
AF Trevor, Caitlyn
   Devaney, Johanna
   Huron, David
TI MUSICIANS CAN RELIABLY DISCRIMINATE BETWEEN STRING REGISTER LOCATIONS ON
   THE VIOLONCELLO
SO MUSIC PERCEPTION
LA English
DT Article
DE vocal range location; register; violoncello; timbre; string register
   location
ID PITCH LOCATION; PERCEPTION; SIMILARITY; EXPRESSION; VIBRATO; VIOLIN;
   TIMBRE
AB VOCAL RANGE LOCATION IS AN IMPORTANT VOCAL affective signal. Humans use different areas of their vocal range to communicate emotional intensity. Consequently, humans are good at identifying where someone is speaking within their vocal range. Research on music and emotion has demonstrated that musical expressive behaviors often reflect or take inspiration from vocal expressive behaviors. Is it possible for musicians to utilize range-related signals on their instrument similarly to how humans use vocal range-related signals? Might musicians therefore be similarly sensitive to instrumental range location? We present two experiments that investigate musicians' ability to hear instrumental range location, specifically string register location on the violoncello. Experiment 1 is a behavioral study that tests whether musicians can reliably distinguish between higher and lower string register locations. In Experiment 2, we analyze acoustic features that could be impacted by string register location. Our results support the conjecture that musicians can reliably discriminate between string register locations, although perhaps only when vibrato is utilized. Our results also suggest that higher string register locations have a darker timbre and possibly a wider and faster vibrato. Further research on whether musicians can effectively imitate vocal range location signals with their instruments is warranted.
C1 [Trevor, Caitlyn; Devaney, Johanna; Huron, David] Ohio State Univ, Columbus, OH 43210 USA.
C3 University System of Ohio; Ohio State University
RP Trevor, C (corresponding author), Dept Psychol, Binzmuehlestr 14,Box 1, CH-8050 Zurich, Switzerland.
EM caitlyn.trevor@psychologie.uzh.ch
FU European Union's Horizon 2020 research and innovation program under the
   Marie Sklodowska-Curie Grant [835682]; Marie Curie Actions (MSCA)
   [835682] Funding Source: Marie Curie Actions (MSCA)
FX C. T. received funding from the European Union's Horizon 2020 research
   and innovation program under the Marie Sklodowska-Curie Grant Agreement
   (No. 835682). The authors thank the members of the Cognitive and
   Systematic Musicology Laboratory at The Ohio State University for their
   feedback and support. They also thank Mark Rudoff, David Clampitt,
   Arkady Konovalov, Frank Russo, and two anonymous reviewers for their
   helpful insights and suggestions.
CR ALLEN M., 2009, J STRING RES, V4, P27
   Bänziger T, 2005, SPEECH COMMUN, V46, P252, DOI 10.1016/j.specom.2005.02.016
   Bishop J, 2012, J ACOUST SOC AM, V132, P1100, DOI 10.1121/1.4714351
   BLACK D, 1998, ESSENTIAL DICT ORCHE, V2nd
   Boersma P., 2020, Praat: Doing phonetics by computer: Version 6.1.28
   CHUDY M, 2016, DISCRIMINATING MUSIC
   de Leeuw JR, 2015, BEHAV RES METHODS, V47, P1, DOI 10.3758/s13428-014-0458-y
   Dromey C, 2015, J VOICE, V29, P170, DOI 10.1016/j.jvoice.2014.06.007
   Dubnov S, 2004, IEEE SIGNAL PROC LET, V11, P698, DOI 10.1109/LSP.2004.831663
   Eerola T, 2013, MUSIC PERCEPT, V30, P307, DOI [10.1525/mp.2012.30.3.307, 10.1525/MP.2012.30.1.49]
   GERINGER J. M., 2010, STRING RES J, V1, P7
   Geringer JM, 2004, J RES MUSIC EDUC, V52, P167, DOI 10.2307/3345438
   Honorof DN, 2005, J ACOUST SOC AM, V117, P2193, DOI 10.1121/1.1841751
   Huron D., 2015, SIGNATA ANN SEMIOT, V6, P331, DOI DOI 10.4000/SIGNATA.1115
   Huron D, 2016, EMPIR MUSICOL REV, V11, P261
   JASP Team, 2018, JASP
   Juslin P. N., 1996, PSYCHOL MUSIC, V24, P68, DOI [10.1177/0305735696241007, DOI 10.1177/0305735696241007]
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   MacLeod RB, 2008, J RES MUSIC EDUC, V56, P43, DOI 10.1177/0022429408323070
   McAdams S, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00153
   McFee B, 2015, P 14 PYTH SCI C, P18, DOI [DOI 10.25080/MAJORA-7B98E3ED-003, 10.25080/majora-7b98e3ed-003]
   Meyer J., 2009, Acoustics and the Performance of Music
   Patterson RD, 2010, SPRINGER HANDB AUDIT, V36, P13, DOI 10.1007/978-1-4419-6114-3_2
   Peeters G, 2011, J ACOUST SOC AM, V130, P2902, DOI 10.1121/1.3642604
   Plazak J., 2017, PSYCHOMUSICOLOGY, V27, P1, DOI [10.1037/pmu0000172, DOI 10.1037/PMU0000172]
   POPE D. A, 2012, STRING RES J, V3, P51
   R Core Team, 2018, R: A Language and Environment for Statistical Computing
   Reymore L, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.560877
   Sauter DA, 2010, Q J EXP PSYCHOL, V63, P2251, DOI 10.1080/17470211003721642
   Schubert E, 2019, EMPIR STUD ARTS, V37, P92, DOI 10.1177/0276237418763657
   Siedenburg K, 2021, J ACOUST SOC AM, V149, P3715, DOI 10.1121/10.0005088
   Trevor C, 2020, J ACOUST SOC AM, V147, pEL540, DOI 10.1121/10.0001459
   Trevor C, 2018, EMPIR MUSICOL REV, V13, P66
   Warrenburg LA, 2020, PSYCHOMUSICOLOGY, V30, P1, DOI 10.1037/pmu0000247
   Woods KJP, 2017, ATTEN PERCEPT PSYCHO, V79, P2064, DOI 10.3758/s13414-017-1361-2
NR 35
TC 0
Z9 0
U1 0
U2 1
PU UNIV CALIFORNIA PRESS
PI OAKLAND
PA 155 GRAND AVE, SUITE 400, OAKLAND, CA 94612-3758 USA
SN 0730-7829
J9 MUSIC PERCEPT
JI Music Percept.
PD SEP
PY 2022
VL 40
IS 1
BP 27
EP 38
DI 10.1525/MP.2022.40.1.27
PG 12
WC Music; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music; Psychology
GA 4H2QY
UT WOS:000849727700004
OA Green Submitted, Bronze
DA 2024-01-09
ER

PT J
AU Ding, J
AF Ding, Jun
TI Application of Big Data Mining Technology in the Digital Construction of
   Vocal Music Teaching Resource Library
SO WIRELESS COMMUNICATIONS & MOBILE COMPUTING
LA English
DT Article
AB In recent years, vocal music is becoming more and more important to daily life, which can cultivate emotion and adjust pressure, but at present, vocal music teaching is faced with an increasingly serious shortage of teacher resources. Therefore, it is particularly important to develop a vocal music teaching system using the computer-aided teaching function. First, the algorithm flow of the system is designed in detail according to the principle of computer neural network technology, the performance characteristics of vocal music are extracted by using Fourier transform and its improved function, and the key modules of the system are designed according to the system frame structure and data processing flow and gave the key design code. Finally, taking piano performance as an example, players with different steel bar grades were selected to test the accuracy of the system evaluation. The test results show that the system can reflect the real level of the performers, which is beneficial to vocal music teaching. The improvement of the vocal music teaching system is of great practical significance to adjust the traditional music teaching mode and make the education system more reasonable.
C1 [Ding, Jun] Zhumadian Vocat & Tech Coll, Coll Teacher Educ, Zhumadian 463000, Peoples R China.
RP Ding, J (corresponding author), Zhumadian Vocat & Tech Coll, Coll Teacher Educ, Zhumadian 463000, Peoples R China.
EM budingzhun@163.com
FU subject of teacher education curriculum reform of Henan Provincial
   Department of education [2022-jsjyzd-079]
FX The research is supported by the subject of teacher education curriculum
   reform of Henan Provincial Department of education, the title of the
   subject is "construction and practical exploration of aesthetic
   education system for high-quality normal students under the background
   of double reduction", subject project (no. 2022-jsjyzd-079).
CR de Soto NA, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-55911-3
   Annika L., 2020, PLOS ONE, V15, P293
   Chen X., 2021, COMPUT INTEL NEUROSC, V31, P66
   Choe H, 2021, HORM BEHAV, V132, DOI 10.1016/j.yhbeh.2021.104978
   Cristina R.-S., 2022, ISCIENCE, V25, P132
   Daniel M. L., 2021, MEDRXIV, V11, P127
   Grace S.-V., 2021, ANIM BEHAV, V40, P155
   Horner W, 2022, AM J OBSTET GYNECOL, V226, pS1351
   Jack G., 2021, ELIFE, V43, P101
   James LS, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-58983-8
   Kazuya Y., 2021, J SOUND VIB, V514, P27
   Kist AM, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-77216-6
   Manuela A., 2021, J NEUROL SCI, V429, P659
   Philippsen A, 2021, KUNSTL INTELL, V35, P53, DOI 10.1007/s13218-021-00704-y
   Po-Yu Y., 2022, J DENT SCI, V17, P123
   Shikhara B.A., 2022, ANIM BEHAV
   Tsui SY, 2018, FOLIA PHONIATR LOGO, V70, P174, DOI 10.1159/000492327
   Van Hirtum A, 2022, J SOUND VIB, V516, DOI 10.1016/j.jsv.2021.116504
   Wright T.F., 2020, NEUROSCI BIOBEHAV R, V43, P96
   Yuki T., 2022, BIOCHEM BIOPH RES CO, V16, P582
NR 20
TC 0
Z9 0
U1 2
U2 7
PU WILEY-HINDAWI
PI LONDON
PA ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND
SN 1530-8669
EI 1530-8677
J9 WIREL COMMUN MOB COM
JI Wirel. Commun. Mob. Comput.
PD JUL 29
PY 2022
VL 2022
AR 3197118
DI 10.1155/2022/3197118
PG 9
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA 4L8QL
UT WOS:000852894500007
OA gold
DA 2024-01-09
ER

PT J
AU Wang, D
AF Wang, Di
TI Sensibility and Rationality in Vocal Music: The Issue of Intonation
SO MUSICA HODIE
LA English
DT Article
DE control; experiment; intonation control; singing; vocal apparatus
ID EMOTION
AB The purpose of this article was to assess the effectiveness of intonation control among first-year students majoring in vocal music. The study was performed during the 2018-2019 in on one of Beijing conservatories (China). Research sample comprised of 300 first-year students, 100 of which made up the control group, another 100 - the experimental group 1, and the last 100 - experimental group 2. Higher results of students from EGs than those of CG participants resulted from systematic and constant work on intonation improvement. The total number of individuals with poor educational achievements decreased in view of the innovative training methodology introduction that provoked the overall enhancement of academic outcomes. An inverse correlation was found between intonation control and health vocal apparatus: -0.89 for CG, 0.78 for EG1, and 0.81 for EG2. The application of the developed methodology allowed students to preserve vocal cords' health and improve singing abilities.
C1 [Wang, Di] Hubei Polytech Univ, Art Acad, Huang Shi, Peoples R China.
C3 Hubei Polytechnic University
RP Wang, D (corresponding author), Hubei Polytech Univ, Art Acad, Huang Shi, Peoples R China.
EM diwang422@yahoo.com
CR Amir N, 2006, BIOMED SIGNAL PROCES, V1, P144, DOI 10.1016/j.bspc.2006.06.002
   AVROY Frank, 2015, ALONE TOGETHER VOCAL
   Bertero D, 2017, INT CONF ACOUST SPEE, P5115, DOI 10.1109/ICASSP.2017.7953131
   D'Amario S, 2017, PSYCHOMUSICOL MUSIC, V27, P229, DOI DOI 10.1037/PMU0000184
   D'Amario S, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01208
   D'Amario S, 2019, LOGOP PHONIATR VOCO, V44, P143, DOI 10.1080/14015439.2018.1452977
   D'AMARIO Sara, 2020, J VOICE, V34, P159
   DAFFERN Helena, 2017, J VOICE, V31, P385
   Delic V, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/4368036
   Devaney J., 2011, PSYCHOMUSICOLOGY MUS, V21, P108, DOI DOI 10.1037/H0094008
   Ginsborg J, 2012, MUSIC SCI, V16, P148, DOI 10.1177/1029864911435733
   GONTARENKO N. B., 2007, SOLO SINGING SECRETS, V2nd
   HAVROY Frank, 2013, MUSIC PRACTICE, V1, P1
   Howard D.M., 2017, ACOUSTICS PSYCHOACOU
   Howard DM, 2007, LOGOP PHONIATR VOCO, V32, P87, DOI 10.1080/14015430600865607
   Kerkeni L, 2019, INTECHOPEN, V1
   Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391
   Markoff John, 2019, New York Times
   Muhammad G, 2014, BIOMED SIGNAL PROCES, V11, P1, DOI 10.1016/j.bspc.2014.02.001
   Mukesh K., 2015, INT J ADV RES ELECT, V4, P2508
   Muniz A. L. M., 2019, 2019 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC), DOI 10.1109/CLEOE-EQEC.2019.8873106
   Polrolniczak E., 2011, METOD INFORM STOSOW, V4, P259
   Poorna SS, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTERS, COMMUNICATIONS, AND SYSTEMS (ICCCS), P217, DOI 10.1109/CCOMS.2015.7562904
   Scherer KR, 2015, COMPUT SPEECH LANG, V29, P218, DOI 10.1016/j.csl.2013.10.002
   Sezgin MC, 2012, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2012-16
   Zaporowski S, 2020, LECT NOTES COMPUT SC, V12117, P225, DOI 10.1007/978-3-030-59491-6_21
   Zaporowski S, 2019, ADV INTELL SYST COMP, V833, P490, DOI 10.1007/978-3-319-98678-4_49
   Zhang XY, 2021, NEURAL REGEN RES, V16, P375, DOI 10.4103/1673-5374.290909
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
   ZWAN Pawel, 2006, AUDIO ENG SOC CONVEN, V1, P446
NR 30
TC 3
Z9 3
U1 0
U2 2
PU UNIV FEDERAL GOIAS
PI GOIANIA GO
PA ESCOLA MUSICA ARTES CIENCIAS, PROG POT-GRAD MUSICA, CAIXA POSTAL 131,
   CAMPUS II-SAMAMBAIA, GOIANIA GO, CEP74001-970, BRAZIL
SN 1676-3939
J9 MUSICA HODIE
JI Musica Hodie
PY 2021
VL 21
AR e66429
DI 10.5216/mh.v21.66429
PG 19
WC Music
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music
GA TM0HI
UT WOS:000675235800001
OA gold
DA 2024-01-09
ER

PT J
AU Riabzev, A
   Bensimon, M
   Moore, KS
   Jacobsen, SL
AF Riabzev, Aviya
   Bensimon, Moshe
   Sena Moore, Kimberly
   Jacobsen, Stine Lindahl
TI A Qualitative Investigation of Self-Compassion in Music Therapy Group
   Voicework With Women Coping With Incest
SO JOURNAL OF MUSIC THERAPY
LA English
DT Article; Early Access
DE group music therapy; voicework; trauma; incest; self-compassion
ID POSTTRAUMATIC-STRESS-DISORDER; TRAUMA
AB Incest occurs worldwide in all socioeconomic classes. To the best of our knowledge, literature on music processes with incest survivors is scarce, and studies focusing on voicework as a main technique for incest survivors in group settings have not been found. The current study aimed to explore incest survivors' expectations regarding the use of their voice before participating in a vocal group therapy, and their lived experience of using their voice following the therapeutic process. Seventeen women living in an inpatient alternative center, coping with complex posttraumatic stress disorder due to incest, participated in a voicework group led by two music therapists. The women were divided into two groups of eight and nine women each and participated in eight sessions. Data were collected through focus groups before and after the therapeutic experience. Interpretative phenomenological analysis yielded themes indicating that before the therapeutic process, participants' expectations regarding the use of their voice reflected low self-esteem, self-criticism, loneliness, shame, fear of exposure, and avoidance of singing. Following the therapeutic process, participants experienced their voice in a way that enabled them to feel self-acceptance and courage to sing, togetherness, bonding, belonging, a strengthening of existing relationships and ability to establish new ones, and awareness of body and emotions in the "here and now." An overall examination of the findings indicates that participants progressed from experiencing lack of self-compassion before the therapeutic experience to enhanced self-compassion at its completion. The findings are interpreted via the self-compassion concept and implications are presented.
C1 [Riabzev, Aviya] Bar Ilan Univ, Dept Mus, Ramat Gan, Israel.
   [Bensimon, Moshe] Bar Ilan Univ, Dept Criminol, IL-5290002 Ramat Gan, Israel.
C3 Bar Ilan University; Bar Ilan University
RP Bensimon, M (corresponding author), Bar Ilan Univ, Dept Criminol, IL-5290002 Ramat Gan, Israel.
EM moshe.bensimon@biu.ac.il
OI Bensimon, Moshe/0000-0002-0008-035X
CR [Anonymous], 2009, SEX CRIMES
   Austin D., 2001, MUSIC THER PERSPECT, V19, P22, DOI DOI 10.1093/MTP/19.1.22
   Austin D., 2008, THEORY PRACTICE VOCA
   Baker F., 2011, VOICEWORK MUSIC THER
   Baker F, 2009, NORD J MUSIC THER, V18, P32, DOI 10.1080/08098130802496373
   Bauer ME, 2010, NEUROIMMUNOMODULAT, V17, P192, DOI 10.1159/000258721
   Bendall S, 2011, FAMILY MATTERS, P53
   Bensimon M., 2023, TRAUMA INFORM MUSIC, P150
   Bensimon M, 2020, NORD J MUSIC THER, V29, P300, DOI 10.1080/08098131.2019.1703210
   Bensimon M, 2017, AGGRESS VIOLENT BEH, V35, P44, DOI 10.1016/j.avb.2017.06.002
   Berke JD, 2018, NAT NEUROSCI, V21, P787, DOI 10.1038/s41593-018-0152-y
   Bernstein B, 2019, AM J DANCE THER, V41, P193, DOI 10.1007/s10465-019-09310-w
   Buckley EM, 2014, NEUROPHOTONICS, V1, DOI 10.1117/1.NPh.1.1.011009
   Carter J, 2020, EUR J CRIM POLICY RE, V26, P547, DOI 10.1007/s10610-019-09415-5
   Cohen E, 2010, INFANT MENT HEALTH J, V31, P159, DOI 10.1002/imhj.20250
   Coughlin SS, 2011, OPEN CARDIOVASC MED, V5, P164, DOI 10.2174/1874192401105010164
   Denzin N.K., 2011, SAGE HDB QUALITATIVE, DOI DOI 10.1017/CBO9781107415324.004
   Estes LS, 2002, FAM PRACT, V19, P36, DOI 10.1093/fampra/19.1.36
   Ferguson CJ, 2008, CRIM JUSTICE BEHAV, V35, P311, DOI 10.1177/0093854807311719
   Flynn C, 2021, ART PSYCHOTHER, V76, DOI 10.1016/j.aip.2021.101858
   Fraenkel P., 2019, INTEGRATIVE COUPLE F, P47, DOI [10.1037/0000151-003, DOI 10.1037/0000151-003]
   Franco F., 2021, J HLTH SERVICE PSYCH, V47, P85, DOI DOI 10.1007/S42843-021-00038-1
   Garcia-Falgueras A., 2019, Encyclopedia of Evolutionary Psychological Science, P1
   Gur A., 2019, FOREIGN BODIES EATIN
   Herman Judith., 2015, Trauma and Recovery: The Aftermath of Violence from Domestic Violence to Political Terror, DOI DOI 10.1093/MED:PSYCH/9780195308501.001.0001
   Holanda F. W. N., 2017, PSICOL USP, V28, P287, DOI [10.1590/0103-656420160050, DOI 10.1590/0103-656420160050]
   Husserl E., 1960, Cartesian Meditations
   Iliya YA, 2011, MUSIC THER PERSPECT, V29, P14, DOI 10.1093/mtp/29.1.14
   Janesick V. J., 2015, BLACKWELL ENCY SOCIO, DOI DOI 10.1002/9781405165518.WBEOSP014.PUB2
   Kelly S.E, 2010, The SAGE Handbook of Qualitative Methods in Health Research, DOI [DOI 10.4135/9781446268247.N17, 10.4135/9781446268247.n17]
   Kennedy AC, 2018, TRAUMA VIOLENCE ABUS, V19, P512, DOI 10.1177/1524838016673601
   Kheirandish A., 2015, INDIAN J FUNDAM APPL, V5, P1483
   Kim YS, 2004, J MUSIC THER, V41, P321, DOI 10.1093/jmt/41.4.321
   Lagasse P., 2009, COLUMBIA ELECT ENCY, V6th ed.
   Lester S., 2010, 57 BERN LEER FDN
   Lewis G., 2017, VOICES WORLD FORUM M, V17, DOI DOI 10.15845/VOICES.V17I2.859
   Lincoln YS., 1985, Naturalistic inquiry, DOI DOI 10.1016/0147-1767(85)90062-8
   Lotter C, 2022, SAJP-S AFR J PSYCHI, V28, DOI 10.4102/sajpsychiatry.v28i0.1884
   MacIntosh HB, 2003, ART PSYCHOTHER, V30, P17, DOI 10.1016/S0197-4556(02)00229-0
   McKinnon D., 2018, THESIS U PRETORIA
   Neff K, 2003, SELF IDENTITY, V2, P85, DOI 10.1080/15298860390129863
   Neff KD, 2016, MINDFULNESS, V7, P264, DOI 10.1007/s12671-015-0479-3
   Nesterko Y, 2020, CONFL HEALTH, V14, DOI 10.1186/s13031-020-00291-z
   Norris M. S., 2019, LINES CRITICAL MULTI
   Novotny S., 2007, IDEA FITNESS J, V4, P36
   Orth J., 2005, VOICES WORLD FORUM M, V5, DOI [10.15845/voices.v5i2.227, DOI 10.15845/VOICES.V5I2.227]
   Pavlicevic M, 2000, J MUSIC THER, V37, P269, DOI 10.1093/jmt/37.4.269
   Pellis S., 2009, The playful brain: Ventures to the limits of neuroscience
   Peres JFP, 2009, CURR PAIN HEADACHE R, V13, P350, DOI 10.1007/s11916-009-0057-2
   Porges SW, 2007, BIOL PSYCHOL, V74, P116, DOI 10.1016/j.biopsycho.2006.06.009
   Rattner J., 2012, COMPOSE SINGING DEPT
   Reyes K. T., 2018, DANCE MOVEMENT THERA, V39
   Riabzev A., 2022, VOICES WORLD FORUM M, V22
   Ridder H.M., 2005, Nordic Journal of Music Therapy, V14, P91, DOI DOI 10.1080/08098130509478132
   Robarts Jacqueline, 2006, Clin Child Psychol Psychiatry, V11, P249, DOI 10.1177/1359104506061418
   Rumney Philip N.S., 2008, J. CRIM. L., V72, P67
   Scoglio AAJ, 2018, J INTERPERS VIOLENCE, V33, P2016, DOI 10.1177/0886260515622296
   Seligman Z., 2004, CRITICAL CLIN PERSPE, P164
   Shaked E, 2021, J CHILD SEX ABUS, V30, P847, DOI 10.1080/10538712.2021.1970680
   Smith J., 2009, Interpretative phenomenological analysis: Theory, Method and research, DOI DOI 10.1080/14780880903340091
   Staufenbiel SM, 2013, PSYCHONEUROENDOCRINO, V38, P1220, DOI 10.1016/j.psyneuen.2012.11.015
   Stewart D. W., 2007, Focus groups: Theory and practice
   Stige B, 2009, QUAL HEALTH RES, V19, P1504, DOI 10.1177/1049732309348501
   Strehlow G, 2009, NORD J MUSIC THER, V18, P167, DOI 10.1080/08098130903062397
   Talmon A, 2017, PSYCHOL WOMEN QUART, V41, P325, DOI 10.1177/0361684317702503
   Taylor JE, 2009, AGGRESS VIOLENT BEH, V14, P273, DOI 10.1016/j.avb.2009.03.006
   Thompson S, 2007, BRIT J MUSIC THER, V21, P43, DOI 10.1177/135945750702100202
   Tong A, 2007, INT J QUAL HEALTH C, V19, P349, DOI 10.1093/intqhc/mzm042
   Trevarthen C., 2000, NORD J MUSIC THER, V9, P3, DOI [DOI 10.1080/08098130009477996, 10.1080/08098130009477996]
   Uhlig S., 2011, VOICEWORK MUSIC THER, P63
   Wiess C, 2020, NORD J MUSIC THER, V29, P174, DOI 10.1080/08098131.2019.1695281
   Wilkinson S., 2015, FOCUS GROUPS QUALITA, V3rd
   WILLNER D, 1983, MAN, V18, P134, DOI 10.2307/2801768
   Wollast R, 2021, SELF IDENTITY, V20, P930, DOI 10.1080/15298868.2020.1787220
   Yildirim A, 2014, MED SCI MONITOR, V20, P693, DOI 10.12659/MSM.890361
   Zeidan F, 2016, ANN NY ACAD SCI, V1373, P114, DOI 10.1111/nyas.13153
NR 76
TC 0
Z9 0
U1 1
U2 1
PU OXFORD UNIV PRESS INC
PI CARY
PA JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA
SN 0022-2917
EI 2053-7395
J9 J MUSIC THER
JI J. Music Ther.
PD 2023 SEP 2
PY 2023
DI 10.1093/jmt/thad020
EA SEP 2023
PG 30
WC Music; Rehabilitation
WE Social Science Citation Index (SSCI)
SC Music; Rehabilitation
GA Q4TE8
UT WOS:001057453300001
PM 37658806
DA 2024-01-09
ER

PT J
AU Ying, C
   Hui, W
AF Ying, Cui
   Hui, Wang
TI Film song translation: Verbal, vocal, and visual dimensions On the
   Chinese translation of <i>Amazing Grace</i> in the film <i>Forever
   Young</i>
SO BABEL-REVUE INTERNATIONALE DE LA TRADUCTION-INTERNATIONAL JOURNAL OF
   TRANSLATION
LA English
DT Article
DE film song; translation; verbal; visual; vocal
AB As films are distributed across the globe, film song translation has become a subject of study, which entails considering multi-modal factors. This paper aims to explore the major dimensions and parameters involved in film song translation. Based on previous research on music and translation, this paper proposes a framework for studying film song translation from verbal, vocal, and visual dimensions. The verbal dimension involves semantic meaning, metaphors, images, mood, and emotion. The vocal dimension includes the number of syllables and musical notes, the length of musical notes, rhyme and parallelism, the rise and fall of the melody, and the segmentation of a line. The visual dimension covers the plot, characters, and background pictures. This paper uses this framework to analyze the Chinese translation of Amazing Grace in the film Forever Young to demonstrate how film song translation can be flexible in tackling verbal, vocal, and visual restrictions and possibilities.
C1 [Ying, Cui] Guangdong Univ Foreign Studies, Sch Interpreting & Translat Studies, 2 Baiyun Ave North, Guangzhou, Guangdong, Peoples R China.
   [Hui, Wang] Xian Jiaotong Liverpool Univ, Sch Humanities & Social Sci, Dept Translat & Interpreting, Xian, Peoples R China.
C3 Guangdong University of Foreign Studies; Xi'an Jiaotong-Liverpool
   University
RP Ying, C (corresponding author), Guangdong Univ Foreign Studies, Sch Interpreting & Translat Studies, 2 Baiyun Ave North, Guangzhou, Guangdong, Peoples R China.
EM cuiyingcui@163.com; hui.wang@xjtlu.edu.cn
RI wang, yinhui/JGD-1669-2023
FU National Social Science Fund of China [17CYY002]; Research Development
   Fund of Xi'an Jiaotong-Liverpool University [RDF-16-01-59]
FX This work was supported by the National Social Science Fund of China
   under Grant 17CYY002, and the Research Development Fund of Xi'an
   Jiaotong-Liverpool University under Grant RDF-16-01-59.
CR [Anonymous], 2013, MUSIC TEXT TRANSLATI
   Bailes F, 2009, SOUNDS IN TRANSLATION: INTERSECTIONS OF MUSIC, TECHNOLOGY AND SOCIETY, P41
   Bosseaux Charlotte., 2011, OXFORD HDB TRANSLATI, P183
   Bosseaux Charlotte, 2013, MUSIC TEXT TRANSLATI, P81, DOI [10.5040/9781472541994, DOI 10.5040/9781472541994]
   Carroll Ryall., 2007, PSYCHOLINGUISTIC PHE, P221
   DEMOOIJ M, 2004, TRANSLATOR, V10, P179, DOI DOI 10.1080/13556509.2004.10799176
   Demorest SM, 2008, MUSIC PERCEPT, V25, P213, DOI 10.1525/MP.2008.25.3.213
   Di Giovanni E, 2008, TRANSLATOR, V14, P295, DOI 10.1080/13556509.2008.10799260
   Franzon J., 2008, The Translator, V14, P373, DOI [10.1080/13556509.2008.10799263, DOI 10.1080/13556509.2008.10799263]
   Franzon Johan, 2005, SONG SIGNIFICANCE VI, P263
   GOLOMB H, 2005, SONG SIGNIFICANCE VI, P121
   Gorlee Dinda L., 2005, APPROACHES TRANSLATI, V25, P7
   Gorlee DindaL., 2005, SONG SIGNIFICANCE VI, P17, DOI DOI 10.1163/9789401201544_003
   Huang Renzhong., 2006, J GUANGXI U NATL, P126
   Hubscher-Davidson Severine, 2018, Translation and emotion: A psychological perspective
   Liu Yang., 2012, WENXUE YISHU, P99
   Low P., 2005, Song and Significance: Virtues and Vices of Vocal Translation, P185
   Low P., 2013, MUSIC TEXT TRANSLATI, P69, DOI [10.5040/9781472541994, DOI 10.5040/9781472541994]
   Minors HelenJulia., 2013, MUSIC TEXT TRANSLATI, P107
   Minors HelenJulia., 2013, MUSIC TEXT TRANSLATI, P1
   Nida Eugene A, 1964, Towards a science of translation, with special reference to principles and procedures involved in Bible translating
   Palmer Judi, 2013, MUSIC TEXT TRANSLATI, P21
   PERLOFF M, 2009, SOUND POETRY POETRY, P1
   Shrum LJ, 2012, INT J RES MARK, V29, P275, DOI 10.1016/j.ijresmar.2012.03.002
   Stewart Susan, 2009, The Sound of Poetry/The Poetry of Sound, P29
   Susam-Sarajeva S, 2008, TRANSLATOR, V14, P187
   Waldrop Rosmarie., 2009, SOUND POETRY POETRY, P60, DOI DOI 10.7208/CHICAGO/9780226657448.003.0006
   Wikipedia, 2018, AMAZING GRACE
   Wikipedia, 2018, FOR YOUNG
NR 29
TC 0
Z9 0
U1 14
U2 34
PU JOHN BENJAMINS PUBLISHING CO
PI AMSTERDAM
PA PO BOX 36224, 1020 ME AMSTERDAM, NETHERLANDS
SN 0521-9744
EI 1569-9668
J9 BABEL-AMSTERDAM
JI Babel
PD NOV 4
PY 2022
VL 68
IS 4
BP 565
EP 585
DI 10.1075/babel.00280.cui
PG 21
WC Linguistics; Language & Linguistics
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Linguistics
GA 5Y0MO
UT WOS:000878986500005
DA 2024-01-09
ER

PT J
AU Lima, CF
   Brancatisano, O
   Fancourt, A
   Müllensiefen, D
   Scott, SK
   Warren, JD
   Stewart, L
AF Lima, Cesar F.
   Brancatisano, Olivia
   Fancourt, Amy
   Mullensiefen, Daniel
   Scott, Sophie K.
   Warren, Jason D.
   Stewart, Lauren
TI Impaired socio-emotional processing in a developmental music disorder
SO SCIENTIFIC REPORTS
LA English
DT Article
ID CONGENITAL AMUSIA; VOCAL EXPRESSION; TONE-DEAFNESS; EFFECT SIZE;
   EMOTIONS; PITCH; BRAIN; RECOGNITION; IDENTIFICATION; SENSITIVITY
AB Some individuals show a congenital deficit for music processing despite normal peripheral auditory processing, cognitive functioning, and music exposure. This condition, termed congenital amusia, is typically approached regarding its profile of musical and pitch difficulties. Here, we examine whether amusia also affects socio-emotional processing, probing auditory and visual domains. Thirteen adults with amusia and 11 controls completed two experiments. In Experiment 1, participants judged emotions in emotional speech prosody, nonverbal vocalizations (e.g., crying), and (silent) facial expressions. Target emotions were: amusement, anger, disgust, fear, pleasure, relief, and sadness. Compared to controls, amusics were impaired for all stimulus types, and the magnitude of their impairment was similar for auditory and visual emotions. In Experiment 2, participants listened to spontaneous and posed laughs, and either inferred the authenticity of the speaker's state, or judged how much laughs were contagious. Amusics showed decreased sensitivity to laughter authenticity, but normal contagion responses. Across the experiments, mixed-effects models revealed that the acoustic features of vocal signals predicted socio-emotional evaluations in both groups, but the profile of predictive acoustic features was different in amusia. These findings suggest that a developmental music disorder can affect socio-emotional cognition in subtle ways, an impairment not restricted to auditory information.
C1 [Lima, Cesar F.] UCL, Inst Cognit Neuroci, London, England.
   [Brancatisano, Olivia; Fancourt, Amy; Mullensiefen, Daniel; Stewart, Lauren] Goldsmiths Univ London, Dept Psychol, London, England.
   [Warren, Jason D.] UCL, Inst Neurol, Dementia Res Ctr, London, England.
   [Stewart, Lauren] Aarhus Univ, Dept Clin Med, Ctr Mus Brain, Aarhus, Denmark.
   [Stewart, Lauren] Royal Acad Mus, Aarhus, Denmark.
C3 University of London; University College London; University of London;
   Goldsmiths University London; University of London; University College
   London; Aarhus University
RP Lima, CF (corresponding author), UCL, Inst Cognit Neuroci, London, England.; Stewart, L (corresponding author), Goldsmiths Univ London, Dept Psychol, London, England.; Stewart, L (corresponding author), Aarhus Univ, Dept Clin Med, Ctr Mus Brain, Aarhus, Denmark.; Stewart, L (corresponding author), Royal Acad Mus, Aarhus, Denmark.
EM c.lima@ucl.ac.uk; l.stewart@gold.ac.uk
RI Scott, Sophie K/A-1843-2010; Stewart, Lauren/HHC-2911-2022; Lima, Cesar
   F./HSF-6972-2023
OI Scott, Sophie K/0000-0001-7510-6297; Lima, Cesar F./0000-0003-3058-7204;
   stewart, lauren/0000-0002-6221-6064; Warren, Jason/0000-0002-5405-0826
FU British Academy/Leverhulme Research Grant [SG130465]; Portuguese
   Foundation for Science and Technology [SFRH/BPD/77189/2011]; Danish
   National Research Foundation [DNRF117]; Wellcome Trust [WT090961MA];
   Fundação para a Ciência e a Tecnologia [SFRH/BPD/77189/2011] Funding
   Source: FCT
FX We thank the authors of the Geneva Multimodal Emotion Portrayals, Tanja
   Banziger, Marcello Mortillaro, and Klaus Scherer, for sharing the facial
   expression videos used in this study. This work was funded by a British
   Academy/Leverhulme Research Grant (grant number SG130465 awarded to L.
   Stewart and C.F. Lima). During the planning and execution of this
   project, C.F. Lima was supported by a postdoctoral fellowship from the
   Portuguese Foundation for Science and Technology (grant number
   SFRH/BPD/77189/2011). The Center for Music in the Brain, which partly
   supports L. Stewart, is funded by the Danish National Research
   Foundation (DNRF117). The preparation of auditory laughter stimuli was
   funded by a Wellcome Trust Senior Research Fellowship (grant number
   WT090961MA) awarded to S.K. Scott.
CR Aguinis H, 2013, ORGAN RES METHODS, V16, P270, DOI 10.1177/1094428112470848
   Albouy P, 2013, BRAIN, V136, P1639, DOI 10.1093/brain/awt082
   Ayotte J, 2002, BRAIN, V125, P238, DOI 10.1093/brain/awf028
   Bänziger T, 2012, EMOTION, V12, P1161, DOI 10.1037/a0025827
   Bakeman R, 2005, BEHAV RES METHODS, V37, P379, DOI 10.3758/BF03192707
   Barbey AK, 2014, SOC COGN AFFECT NEUR, V9, P265, DOI 10.1093/scan/nss124
   Bigand E, 2006, COGNITION, V100, P100, DOI 10.1016/j.cognition.2005.11.007
   Borod JC, 2000, COGNITION EMOTION, V14, P193, DOI 10.1080/026999300378932
   Burnham K.P., 1998, Model Selection and MultiModel Inference
   Clark CN, 2015, SOC COGN AFFECT NEUR, V10, P444, DOI 10.1093/scan/nsu079
   Clark CN, 2014, CURR BIOL, V24, pR234, DOI 10.1016/j.cub.2014.02.013
   Duchaine B, 2007, SOC COGN AFFECT NEUR, V2, P104, DOI 10.1093/scan/nsm003
   Frith CD, 2012, ANNU REV PSYCHOL, V63, P287, DOI 10.1146/annurev-psych-120710-100449
   Gerry D, 2012, DEVELOPMENTAL SCI, V15, P398, DOI 10.1111/j.1467-7687.2012.01142.x
   Gosselin N, 2005, BRAIN, V128, P628, DOI 10.1093/brain/awh420
   Gosselin N, 2015, CORTEX, V71, P171, DOI 10.1016/j.cortex.2015.06.022
   Henry MJ, 2010, MUSIC PERCEPT, V27, P413, DOI 10.1525/mp.2010.27.5.413
   Herbet G, 2014, BRAIN, V137, P944, DOI 10.1093/brain/awt370
   Hutchins S, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00236
   Hyde KL, 2007, J NEUROSCI, V27, P13028, DOI 10.1523/JNEUROSCI.3039-07.2007
   Hyde KL, 2011, CEREB CORTEX, V21, P292, DOI 10.1093/cercor/bhq094
   Johnson PCD, 2014, METHODS ECOL EVOL, V5, P944, DOI 10.1111/2041-210X.12225
   Jones JL, 2009, J COMMUN DISORD, V42, P226, DOI 10.1016/j.jcomdis.2009.01.001
   Juslin PN, 2001, EMOTION, V1, P381, DOI 10.1037//1528-3542.1.4.381
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   KALMUS H, 1980, ANN HUM GENET, V43, P369, DOI 10.1111/j.1469-1809.1980.tb01571.x
   Lavan N, 2015, COGNITION EMOTION, V29, P935, DOI 10.1080/02699931.2014.957656
   Lima CF, 2013, BEHAV RES METHODS, V45, P1234, DOI 10.3758/s13428-013-0324-3
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Liu F, 2015, NEUROPSYCHOLOGIA, V66, P111, DOI 10.1016/j.neuropsychologia.2014.11.001
   Liu F, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030374
   Liu F, 2010, BRAIN, V133, P1682, DOI 10.1093/brain/awq089
   Lolli SL, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01340
   Loui P, 2009, J NEUROSCI, V29, P10215, DOI 10.1523/JNEUROSCI.1701-09.2009
   Lu XJ, 2016, NEUROIMAGE, V135, P142, DOI 10.1016/j.neuroimage.2016.04.043
   McDonald C, 2008, MUSIC PERCEPT, V25, P345, DOI 10.1525/MP.2008.25.4.345
   McGettigan C, 2015, CEREB CORTEX, V25, P246, DOI 10.1093/cercor/bht227
   Müllensiefan D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089642
   Nakagawa S, 2013, METHODS ECOL EVOL, V4, P133, DOI 10.1111/j.2041-210x.2012.00261.x
   Nan Y, 2010, BRAIN, V133, P2635, DOI 10.1093/brain/awq178
   Nelson Hazel E., 1991, National Adult Reading Test (NART)
   Olejnik S, 2003, PSYCHOL METHODS, V8, P434, DOI 10.1037/1082-989X.8.4.434
   Park M, 2015, FRONT HUM NEUROSCI, V8, DOI [10.3389/fnhurn.2014.01049, 10.3389/fnhum.2014.01049]
   Paul Boersma and David Weenink, 2015, PRAAT DOING PHONETIC
   Peelen MV, 2010, J NEUROSCI, V30, P10127, DOI 10.1523/JNEUROSCI.2161-10.2010
   Perani D, 2010, P NATL ACAD SCI USA, V107, P4758, DOI 10.1073/pnas.0909074107
   Peretz I, 2005, ANN NEUROL, V58, P478, DOI 10.1002/ana.20606
   Peretz I, 2003, ANN NY ACAD SCI, V999, P58, DOI 10.1196/annals.1284.006
   Peretz I, 2002, NEURON, V33, P185, DOI 10.1016/S0896-6273(01)00580-3
   Peretz I, 2007, AM J HUM GENET, V81, P582, DOI 10.1086/521337
   Peretz I, 2009, BRAIN, V132, P1277, DOI 10.1093/brain/awp055
   Riediger M, 2011, COGNITION EMOTION, V25, P968, DOI 10.1080/02699931.2010.540812
   Sauter DA, 2013, BRIT J DEV PSYCHOL, V31, P97, DOI 10.1111/j.2044-835X.2012.02081.x
   Sauter DA, 2010, Q J EXP PSYCHOL, V63, P2251, DOI 10.1080/17470211003721642
   Sauter DA, 2010, P NATL ACAD SCI USA, V107, P2408, DOI 10.1073/pnas.0908239106
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   Schurz M, 2014, NEUROSCI BIOBEHAV R, V42, P9, DOI 10.1016/j.neubiorev.2014.01.009
   Scott SK, 2010, HBK BEHAV NEUROSCI, V19, P187, DOI 10.1016/B978-0-12-374593-4.00019-X
   Scott SK, 2009, NAT REV NEUROSCI, V10, P295, DOI 10.1038/nrn2603
   Siu TSC, 2016, DEVELOPMENTAL SCI, V19, P933, DOI 10.1111/desc.12348
   Stewart L, 2011, Q J EXP PSYCHOL, V64, P625, DOI 10.1080/17470218.2011.552730
   Thompson WF, 2012, P NATL ACAD SCI USA, V109, P19027, DOI 10.1073/pnas.1210344109
   Trehub SE, 2003, NAT NEUROSCI, V6, P669, DOI 10.1038/nn1084
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   Vuvan DT, 2015, CORTEX, V69, P186, DOI 10.1016/j.cortex.2015.05.002
   Warren JE, 2006, J NEUROSCI, V26, P13067, DOI 10.1523/JNEUROSCI.3907-06.2006
   Wechsler D., 1997, WAIS-IV: Administration and scoring manual
   Williamson VJ, 2011, BRAIN COGNITION, V76, P70, DOI 10.1016/j.bandc.2011.02.016
   Zentner M, 2010, P NATL ACAD SCI USA, V107, P5768, DOI 10.1073/pnas.1000121107
NR 69
TC 27
Z9 30
U1 0
U2 23
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD OCT 11
PY 2016
VL 6
AR 34911
DI 10.1038/srep34911
PG 13
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Science & Technology - Other Topics
GA DY4IB
UT WOS:000385061100001
PM 27725686
OA Green Published, Green Accepted, Green Submitted, gold
DA 2024-01-09
ER

PT J
AU Drapeau, J
   Gosselin, N
   Peretz, I
   McKerral, M
AF Drapeau, Joanie
   Gosselin, Nathalie
   Peretz, Isabelle
   McKerral, Michelle
TI Emotional recognition from dynamic facial, vocal and musical expressions
   following traumatic brain injury
SO BRAIN INJURY
LA English
DT Article
DE Traumatic brain injury; mild; complicated mild; moderate; severe;
   emotions; faces; non-linguistic vocalizations; music
ID IMPAIRED RECOGNITION; MILD; DEFICITS; PERCEPTION; DAMAGE; CONCUSSION;
   RECOVERY; MODERATE; PEOPLE; SCARY
AB Objectives: To assess emotion recognition from dynamic facial, vocal and musical expressions in sub-groups of adults with traumatic brain injuries (TBI) of different severities and identify possible common underlying mechanisms across domains.Methods: Forty-one adults participated in this study: 10 with moderate-severe TBI, nine with complicated mild TBI, 11 with uncomplicated mild TBI and 11 healthy controls, who were administered experimental (emotional recognition, valence-arousal) and control tasks (emotional and structural discrimination) for each domain.Results: Recognition of fearful faces was significantly impaired in moderate-severe and in complicated mild TBI sub-groups, as compared to those with uncomplicated mild TBI and controls. Effect sizes were medium-large. Participants with lower GCS scores performed more poorly when recognizing fearful dynamic facial expressions. Emotion recognition from auditory domains was preserved following TBI, irrespective of severity. All groups performed equally on control tasks, indicating no perceptual disorders. Although emotional recognition from vocal and musical expressions was preserved, no correlation was found across auditory domains.Conclusions: This preliminary study may contribute to improving comprehension of emotional recognition following TBI. Future studies of larger samples could usefully include measures of functional impacts of recognition deficits for fearful facial expressions. These could help refine interventions for emotional recognition following a brain injury.
C1 [Drapeau, Joanie; McKerral, Michelle] CRLB, CRIR, 2275 Ave Laurier Est, Montreal, PQ H2N 2N8, Canada.
   [Drapeau, Joanie; Gosselin, Nathalie; McKerral, Michelle] Ctr Rech Neuropsychol & Cognit CERNEC, Montreal, PQ, Canada.
   [Drapeau, Joanie; Gosselin, Nathalie; Peretz, Isabelle] CRBLM, Montreal, PQ, Canada.
   [Drapeau, Joanie; Gosselin, Nathalie; Peretz, Isabelle] Int Lab Brain Mus & Sound Res BRAMS, Montreal, PQ, Canada.
   [Drapeau, Joanie; Gosselin, Nathalie; Peretz, Isabelle; McKerral, Michelle] Univ Montreal, Dept Psychol, Montreal, PQ, Canada.
C3 Universite de Montreal; Universite de Montreal; Universite de Montreal;
   Universite de Montreal
RP McKerral, M (corresponding author), CRLB, CRIR, 2275 Ave Laurier Est, Montreal, PQ H2N 2N8, Canada.
EM michelle.mckerral@umontreal.ca
FU National Science and Engineering Research Council of Canada; Centre de
   readaptation Lucie-Bruneau; Canada Research Chair; Fonds de recherche du
   Quebec-Sante; Faculte des etudes superieures et postdoctorales de
   l'Universite de Montreal
FX This study was supported by the National Science and Engineering
   Research Council of Canada and the Centre de readaptation Lucie-Bruneau
   (grants to M.M.), a Canada Research Chair (to I.P.), the Fonds de
   recherche du Quebec-Sante and the Faculte des etudes superieures et
   postdoctorales de l'Universite de Montreal (scholarships to J.D.). The
   authors report no conflicts of interest. The authors alone are
   responsible for the content and writing of the paper.
CR Adolphs R, 2002, CURR OPIN NEUROBIOL, V12, P169, DOI 10.1016/S0959-4388(02)00301-X
   ADOLPHS R, 1994, NATURE, V372, P669, DOI 10.1038/372669a0
   Ambadar Z, 2005, PSYCHOL SCI, V16, P403, DOI 10.1111/j.0956-7976.2005.01548.x
   [Anonymous], 2011, HDB MUSIC EMOTION TH
   [Anonymous], NEUROSURG FOCUS, DOI DOI 10.3171/2012.10.F0CUS12253
   [Anonymous], 2000, NEUROPSYCHOLOGY EMOT
   Arlinghaus K, 2011, TXB TRAUMATIC BRAIN, P55
   Arnal LH, 2015, CURR BIOL, V25, P2051, DOI 10.1016/j.cub.2015.06.043
   Aubé W, 2015, SOC COGN AFFECT NEUR, V10, P399, DOI 10.1093/scan/nsu067
   Babbage DR, 2011, NEUROPSYCHOLOGY, V25, P277, DOI 10.1037/a0021908
   Beauchamp MH, 2011, INT J DEV NEUROSCI, V29, P137, DOI 10.1016/j.ijdevneu.2010.12.003
   Beck AT, 2013, MANUAL BECK DEPRESSI
   Belin P, 2004, TRENDS COGN SCI, V8, P129, DOI 10.1016/j.tics.2004.01.008
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Bigler ED, 2011, TXB TRAUMATIC BRAIN, P73, DOI DOI 10.1177/1753193410381840
   Borg J, 2004, J REHABIL MED, V36, P61, DOI 10.1080/16501960410023822
   Borgaro SR, 2003, BRAIN INJURY, V17, P189, DOI 10.1080/0269905021000013183
   Broglio SP, 2011, INT J PSYCHOPHYSIOL, V82, P16, DOI 10.1016/j.ijpsycho.2011.02.010
   Callahan BL, 2011, BRAIN COGNITION, V77, P412, DOI 10.1016/j.bandc.2011.08.017
   Carlozzi NE, 2015, CLIN NEUROPSYCHOL, V29, P21, DOI 10.1080/13854046.2015.1005677
   Croker V, 2005, BRAIN INJURY, V19, P787, DOI 10.1080/02699050500110033
   Deguise E, 2008, J HEAD TRAUMA REHAB, V23, P294, DOI 10.1097/01.HTR.0000336842.53338.f4
   Dellacherie D, 2011, NEUROPSYCHOLOGIA, V49, P618, DOI 10.1016/j.neuropsychologia.2010.11.008
   Dimoska A, 2010, J INT NEUROPSYCH SOC, V16, P1
   Eierud C, 2014, NEUROIMAGE-CLIN, V4, P283, DOI 10.1016/j.nicl.2013.12.009
   Ellemberg D, 2009, J NEUROTRAUM, V26, P2365, DOI 10.1089/neu.2009.0906
   Genova HM, 2015, SOC NEUROSCI-UK, V10, P27, DOI 10.1080/17470919.2014.959618
   Gosselin N, 2005, BRAIN, V128, P628, DOI 10.1093/brain/awh420
   Gosselin N, 2007, NEUROPSYCHOLOGIA, V45, P236, DOI 10.1016/j.neuropsychologia.2006.07.012
   Gosselin N, 2011, CORTEX, V47, P1116, DOI 10.1016/j.cortex.2011.05.012
   Green REA, 2004, NEUROPSYCHOLOGIA, V42, P133, DOI 10.1016/j.neuropsychologia.2003.07.005
   Hawk ST, 2009, EMOTION, V9, P293, DOI 10.1037/a0015178
   Hopkins MJ, 2002, BRAIN INJURY, V16, P245, DOI 10.1080/02699050110103346
   Ietswaart M, 2008, NEUROPSYCHOLOGIA, V46, P148, DOI 10.1016/j.neuropsychologia.2007.08.002
   Iverson GL, 2006, BRAIN INJURY, V20, P1335, DOI 10.1080/02699050601082156
   Iverson GL, 2011, MANUAL OF TRAUMATIC BRAIN INJURY MANAGEMENT, P43
   Knox L, 2009, BRAIN COGNITION, V69, P442, DOI 10.1016/j.bandc.2008.09.009
   Koelsch S, 2014, NAT REV NEUROSCI, V15, P170, DOI 10.1038/nrn3666
   Lachapelle J, 2008, BRAIN INJURY, V22, P265, DOI 10.1080/02699050801938983
   Lange RT, 2009, BRAIN INJURY, V23, P83, DOI 10.1080/02699050802635281
   Lovell MR, 2006, APPL NEUROPSYCHOL, V13, P166, DOI 10.1207/s15324826an1303_4
   Mayer AR, 2011, HUM BRAIN MAPP, V32, P1825, DOI 10.1002/hbm.21151
   McDonald S, 2005, J INT NEUROPSYCH SOC, V11, P392, DOI 10.1017/S1355617705050447
   McDonald S, 2011, BRAIN IMPAIR, V12, P165
   Milders M, 2008, J INT NEUROPSYCH SOC, V14, P318, DOI 10.1017/S1355617708080351
   Neumann D, 2016, BRAIN IMAGING BEHAV, V10, P569, DOI 10.1007/s11682-015-9415-3
   Peretz I., 2013, EVOLUTION EMOTIONAL, P277
   Peretz I., 2010, HDB MUSIC EMOTION TH
   Phillips ML, 2003, BIOL PSYCHIAT, V54, P504, DOI 10.1016/S0006-3223(03)00168-9
   Rosenberg H, 2014, J INT NEUROPSYCH SOC, V20, P994, DOI 10.1017/S1355617714000940
   Roy S, STOIC DATABASE DYNAM
   Rymarczyk K, 2011, INT J PSYCHOPHYSIOL, V79, P330, DOI 10.1016/j.ijpsycho.2010.11.001
   Särkämö T, 2008, BRAIN, V131, P866, DOI 10.1093/brain/awn013
   Särkämö T, 2012, ANN NY ACAD SCI, V1252, P266, DOI 10.1111/j.1749-6632.2011.06405.x
   Särkämö T, 2010, J COGNITIVE NEUROSCI, V22, P2716, DOI 10.1162/jocn.2009.21376
   Scott SK, 1997, NATURE, V385, P254, DOI 10.1038/385254a0
   Spell LA, 2000, J NONVERBAL BEHAV, V24, P285, DOI 10.1023/A:1006675230193
   Spikman JM, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0065581
   Temkin NR, 2009, J HEAD TRAUMA REHAB, V24, P460, DOI 10.1097/HTR.0b013e3181c13413
   Trautmann SA, 2009, BRAIN RES, V1284, P100, DOI 10.1016/j.brainres.2009.05.075
   Vandekerckhove M, 2014, NEUROPSYCHOLOGY, V28, P605, DOI 10.1037/neu0000057
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   Wechsler D., 1997, WAIS-IV: Administration and scoring manual
   WILLIAMS DH, 1990, NEUROSURGERY, V27, P422, DOI 10.1227/00006123-199009000-00014
   Yeo RA, 2011, J NEUROTRAUM, V28, P1, DOI 10.1089/neu.2010.1578
   Zupan B, 2014, BRAIN INJURY, V28, P1087, DOI 10.3109/02699052.2014.901560
NR 66
TC 14
Z9 16
U1 0
U2 6
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0269-9052
EI 1362-301X
J9 BRAIN INJURY
JI Brain Inj.
PY 2017
VL 31
IS 2
BP 221
EP 229
DI 10.1080/02699052.2016.1208846
PG 9
WC Neurosciences; Rehabilitation
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Neurosciences & Neurology; Rehabilitation
GA EM2RO
UT WOS:000395163500010
PM 28067551
DA 2024-01-09
ER

PT J
AU Xi, C
AF Xi, Chen
TI Music Emotion Analysis Based on PSO-BP Neural Network and Big Data
   Analysis
SO COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE
LA English
DT Article
ID SENTIMENT ANALYSIS
AB The current music teaching can effectively improve students' music emotional expression indirectly. How to use the PSO-BP neural network to realize the quantitative research of music emotional expression is the current development trend. Based on this, this paper studies the influence factors of music emotion expression based on PSO-BP neural network and big data analysis. Firstly, a music emotion expression analysis model based on PSO-BP neural network algorithm is proposed. The autocorrelation function is used to simulate the emotion expression information in music. Through the maximum value of the autocorrelation function curve in the detection process, the vocal music signal is restored, and then the emotion expressed is analyzed. Secondly, the influence factors of PSO-BP neural network algorithm in music emotion expression are analyzed. The improved PSO-BP neural network algorithm and multidimensional data model are used for comprehensive analysis to accurately analyze the emotion in music expression, and the fuzzy evaluation method and analytic hierarchy process are used for quality evaluation. Finally, the validity of the music emotion analysis model is verified by many experiments.
C1 [Xi, Chen] Shaanxi Normal Univ, Sch Mus, Xian 710119, Shaanxi, Peoples R China.
C3 Shaanxi Normal University
RP Xi, C (corresponding author), Shaanxi Normal Univ, Sch Mus, Xian 710119, Shaanxi, Peoples R China.
EM xichen0710@snnu.edu.cn
RI Xi, Chen/IUO-9516-2023
CR Alarifi A, 2020, J SUPERCOMPUT, V76, P4414, DOI 10.1007/s11227-018-2398-2
   Amplayo RK, 2018, INFORM SCIENCES, V454, P200, DOI 10.1016/j.ins.2018.04.079
   Bibault JE, 2016, CANCER LETT, V382, P110, DOI 10.1016/j.canlet.2016.05.033
   Cai X, 2021, EXPERT SYST APPL, V171, DOI 10.1016/j.eswa.2021.114629
   Carvalho J, 2021, ARTIF INTELL REV, V54, P1887, DOI 10.1007/s10462-020-09895-6
   Chen MC, 2021, APPL MATH LETT, V121, DOI 10.1016/j.aml.2021.107417
   Deng W, 2022, IEEE T INTELL TRANSP, V23, P1737, DOI 10.1109/TITS.2020.3025796
   Hirschfeld L, 2020, J CHEM INF MODEL, V60, P3770, DOI 10.1021/acs.jcim.0c00502
   Höpken W, 2021, J TRAVEL RES, V60, P998, DOI 10.1177/0047287520921244
   Huang CX, 2020, MATH METHOD APPL SCI, V43, P6093, DOI 10.1002/mma.6350
   Huang FR, 2019, KNOWL-BASED SYST, V167, P26, DOI 10.1016/j.knosys.2019.01.019
   Liu JG, 2021, IEEE T INTELL TRANSP, V22, P6583, DOI 10.1109/TITS.2020.3010296
   Liu XL, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/5609885
   Peng HY, 2018, KNOWL-BASED SYST, V148, P167, DOI 10.1016/j.knosys.2018.02.034
   Sakaki M, 2019, COGNITION, V187, P108, DOI 10.1016/j.cognition.2019.02.011
   Samek W, 2021, P IEEE, V109, P247, DOI 10.1109/JPROC.2021.3060483
   Sanglerdsinlapachai N, 2021, ARTIF INTELL MED, V113, DOI 10.1016/j.artmed.2021.102033
   Schouten K, 2018, IEEE T CYBERNETICS, V48, P1263, DOI 10.1109/TCYB.2017.2688801
   Selvi RT, 2021, J AMB INTEL HUM COMP, V12, P6129, DOI 10.1007/s12652-020-02181-x
   Sze V., 2020, SYNTH LECT COMPUT AR, V15, P1, DOI DOI 10.2200/S01004ED1V01Y202004CAC050
   Tang SY, 2021, J SUPERCOMPUT, V77, P3870, DOI 10.1007/s11227-020-03422-8
   Wang JK, 2019, FUEL, V254, DOI 10.1016/j.fuel.2019.115621
   Wang W, 2020, IEEE NETWORK, V34, P295, DOI 10.1109/MNET.011.2000250
   Wang Z, 2020, IEEE T MAGN, V56, DOI 10.1109/TMAG.2019.2953986
   Zhou S, 2019, OPT EXPRESS, V27, P31874, DOI 10.1364/OE.27.031874
   Zhou XK, 2021, IEEE T IND INFORM, V17, P3469, DOI 10.1109/TII.2020.3022432
   Zielonka A, 2021, IEEE T IND INFORM, V17, P4308, DOI 10.1109/TII.2020.3009094
NR 27
TC 7
Z9 7
U1 7
U2 41
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1687-5265
EI 1687-5273
J9 COMPUT INTEL NEUROSC
JI Comput. Intell. Neurosci.
PD SEP 6
PY 2021
VL 2021
AR 6592938
DI 10.1155/2021/6592938
PG 9
WC Mathematical & Computational Biology; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Mathematical & Computational Biology; Neurosciences & Neurology
GA XQ3MJ
UT WOS:000731452000009
PM 34527043
OA gold, Green Published
DA 2024-01-09
ER

PT J
AU Heaton, P
   Ridley, E
   Makhmood, S
   Riby, DM
AF Heaton, Pamela
   Ridley, Ellen
   Makhmood, Sonya
   Riby, Deborah M.
TI Hearing the feeling: Auditory emotion perception in Williams syndrome
SO RESEARCH IN DEVELOPMENTAL DISABILITIES
LA English
DT Article
DE Williams syndrome; Auditory processing; Emotion processing
ID SOCIAL PHENOTYPE; MUSICAL EMOTION; RECOGNITION; BRAIN; INDIVIDUALS;
   MODULARITY; AUTISM; HYPERSOCIABILITY; EXPRESSIONS; PERFORMANCE
AB Background: Studies investigating recognition of facial expressions of emotions in Williams syndrome (WS) have reported difficulties in recognising negative expressions of emotion and a reliance on atypically developing underlying processes during task performance.
   Aim: The aim of the study was to extend these findings to the recognition of emotions in auditory domains.
   Method and procedures: Children and adolescents with WS, together with chronological (CA) and verbal mental age matched (VMA) typically developing (TD) comparison groups, were asked to judge expressions of happiness, sadness, anger, and fear in vocal and musical conditions.
   Outcomes and results: Total emotion recognition scores did not differ between WS and VMA matched groups but profiles of discrimination across emotion categories were markedly different. For all groups, the accessibility of emotion category cues differed across music and speech domains. The results suggested that emotion discrimination is more strongly linked with cognitive ability in WS than in TD.
   Conclusions and implications: Although WS and TD groups showed a significantly different profile of discrimination across emotion categories, similarities in the pattern of discrimination across domains and in the correlates of auditory emotion processing were observed. The results are discussed in the context of typical and atypical developmental trajectories and compensatory mechanisms in WS.
C1 [Heaton, Pamela; Makhmood, Sonya] Goldsmiths Univ London, Psychol, London SE14 6NW, England.
   [Ridley, Ellen; Riby, Deborah M.] Univ Durham, Dept Psychol, South Rd, Durham DH1 3LE, England.
C3 University of London; Goldsmiths University London; Durham University
RP Heaton, P (corresponding author), Goldsmiths Univ London, Psychol, London SE14 6NW, England.
EM P.Heaton@gold.ac.uk; ellen.ridley@durham.ac.uk; S.Makhmood@gold.ac.uk;
   deborah.riby@durham.ac.uk
RI Riby, Deborah M/G-8474-2013; Ridley, Ellen/AAO-9723-2020
OI Riby, Deborah M/0000-0001-5747-8441; Ridley, Ellen/0000-0002-2617-1145
FU Baily Thomas Charitable Fund [TRUST/RNA/AC/SG/3546/6300]
FX This work was supported by the Baily Thomas Charitable Fund
   (TRUST/RNA/AC/SG/3546/6300).
CR Allgood R, 2015, BRIT J DEV PSYCHOL, V33, P398, DOI 10.1111/bjdp.12097
   Annaz D, 2009, J EXP CHILD PSYCHOL, V102, P456, DOI 10.1016/j.jecp.2008.11.005
   [Anonymous], 1990, Manual for the Raven's Progressive Matrices and Vocabulary Scales
   [Anonymous], 1994, Atypical cognitive deficits in developmental disorders: Implications for brain function
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Brown S, 2000, ORIGINS OF MUSIC, P271
   Capitao L, 2011, RES DEV DISABIL, V32, P2767, DOI 10.1016/j.ridd.2011.05.033
   Dankovicová J, 2007, LANG SPEECH, V50, P177, DOI 10.1177/00238309070500020201
   Dodd HF, 2010, COGN NEUROPSYCHIATRY, V15, P549, DOI 10.1080/13546801003737157
   Donnai D, 2000, AM J MED GENET, V97, P164, DOI 10.1002/1096-8628(200022)97:2<164::AID-AJMG8>3.0.CO;2-F
   Doyle TF, 2004, AM J MED GENET A, V124A, P263, DOI 10.1002/ajmg.a.20416
   Dunn Lloyd M., 1997, Peabody Picture Vocabulary Test, Fifth Edition: Manual
   Dykens EM, 2005, AM J MENT RETARD, V110, P346, DOI 10.1352/0895-8017(2005)110[346:MAAIWS]2.0.CO;2
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   Fodor J., 1983, MODULARITY MIND
   FODOR JA, 1985, BEHAV BRAIN SCI, V8, P1, DOI 10.1017/S0140525X0001921X
   Gagliardi C, 2003, NEUROPSYCHOLOGIA, V41, P733, DOI 10.1016/S0028-3932(02)00178-1
   Gosselin N, 2005, BRAIN, V128, P628, DOI 10.1093/brain/awh420
   Haas BW, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00186
   Haas BW, 2009, J NEUROSCI, V29, P1132, DOI 10.1523/JNEUROSCI.5324-08.2009
   Heaton P, 2008, BRIT J DEV PSYCHOL, V26, P171, DOI 10.1348/026151007X206776
   Järvinen A, 2016, DEV PSYCHOBIOL, V58, P17, DOI 10.1002/dev.21335
   Järvinen A, 2015, NEUROPSYCHOLOGIA, V73, P127, DOI 10.1016/j.neuropsychologia.2015.04.035
   Järvinen A, 2013, CURR OPIN NEUROBIOL, V23, P414, DOI 10.1016/j.conb.2012.12.006
   Jarrold C, 1999, NEUROPSYCHOLOGIA, V37, P637, DOI 10.1016/S0028-3932(98)00128-6
   Järvinen-Pasley A, 2008, DEV PSYCHOPATHOL, V20, P1, DOI 10.1017/S0954579408000011
   Järvinen-Pasley A, 2010, NEUROPSYCHOLOGIA, V48, P456, DOI 10.1016/j.neuropsychologia.2009.10.003
   Johnson MH, 2011, DEV COGN NEUROS-NETH, V1, P7, DOI 10.1016/j.dcn.2010.07.003
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Karmiloff-Smith A, 2004, J CHILD PSYCHOL PSYC, V45, P1258, DOI 10.1111/j.1469-7610.2004.00322.x
   Karmiloff-Smith A, 1998, TRENDS COGN SCI, V2, P389, DOI 10.1016/S1364-6613(98)01230-3
   Karmiloff-Smith A., 2011, NEURODEVELOPMENTAL D, P37
   Karmiloff-Smith A. Cam, 1998, MODULARITY DEV PERSP
   KarmiloffSmith A, 1997, CHILD DEV, V68, P246, DOI 10.1111/j.1467-8624.1997.tb01938.x
   Knösche TR, 2005, HUM BRAIN MAPP, V24, P259, DOI 10.1002/hbm.20088
   Koelsch S, 2002, NEUROIMAGE, V17, P956, DOI 10.1016/S1053-8119(02)91154-7
   Lacroix A, 2009, RES DEV DISABIL, V30, P976, DOI 10.1016/j.ridd.2009.02.002
   Laukka P, 2007, MOTIV EMOTION, V31, P182, DOI 10.1007/s11031-007-9063-z
   Levitin DJ, 1998, MUSIC PERCEPT, V15, P357
   Maess B, 2001, NAT NEUROSCI, V4, P540, DOI 10.1038/87502
   Martens MA, 2008, J CHILD PSYCHOL PSYC, V49, P576, DOI 10.1111/j.1469-7610.2008.01887.x
   Martens MA, 2009, NEUROPSYCHOLOGIA, V47, P2446, DOI 10.1016/j.neuropsychologia.2009.04.017
   Martínez-Castilla P, 2015, CHILD NEUROPSYCHOL, V21, P668, DOI 10.1080/09297049.2014.945408
   Martínez-Castilla P, 2014, BRAIN SCI, V4, P376, DOI 10.3390/brainsci4020376
   Mervis CB, 2003, DEV NEUROPSYCHOL, V23, P243, DOI 10.1207/S15326942DN231&2_11
   Meyer-Lindenberg A, 2005, NAT NEUROSCI, V8, P991, DOI 10.1038/nn1494
   MORRIS CA, 1988, J PEDIATR-US, V113, P318, DOI 10.1016/S0022-3476(88)80272-5
   Nowicki S, 2001, LEA SER PER CLIN PSY, P183
   Patel A. D., 2008, Music, Language, and the Brain
   Paterson SJ, 1999, SCIENCE, V286, P2355, DOI 10.1126/science.286.5448.2355
   Peretz I, 2003, NAT NEUROSCI, V6, P688, DOI 10.1038/nn1083
   PINKER S, 1991, SCIENCE, V253, P530, DOI 10.1126/science.1857983
   Plesa-Skwerer D, 2006, AM J MENT RETARD, V111, P15, DOI 10.1352/0895-8017(2006)111[15:PFAVEO]2.0.CO;2
   Porter MA, 2007, NEUROPSYCHOLOGIA, V45, P2839, DOI 10.1016/j.neuropsychologia.2007.05.006
   Porter MA, 2010, COGN NEUROPSYCHIATRY, V15, P505, DOI 10.1080/13546801003644486
   Quintin EM, 2011, J AUTISM DEV DISORD, V41, P1240, DOI 10.1007/s10803-010-1146-0
   Reiss AL, 2004, J NEUROSCI, V24, P5009, DOI 10.1523/JNEUROSCI.5272-03.2004
   Riby DM, 2008, NEUROPSYCHOLOGIA, V46, P2855, DOI 10.1016/j.neuropsychologia.2008.05.003
   Riby DM, 2009, J AUTISM DEV DISORD, V39, P421, DOI 10.1007/s10803-008-0641-z
   Sauter DA, 2006, THESIS
   Sauter DA, 2013, BRIT J DEV PSYCHOL, V31, P97, DOI 10.1111/j.2044-835X.2012.02081.x
   Schlaug G, 2005, ANN NY ACAD SCI, V1060, P219, DOI 10.1196/annals.1360.015
   Schön D, 2004, PSYCHOPHYSIOLOGY, V41, P341, DOI 10.1111/1469-8986.00172.x
   Skwerer DP, 2009, SOC COGN AFFECT NEUR, V4, P93, DOI 10.1093/scan/nsn041
   Skwerer DP, 2006, COGN NEUROPSYCHOL, V23, P338, DOI 10.1080/02643290542000076
   Stromme P, 2002, J CHILD NEUROL, V17, P269, DOI 10.1177/088307380201700406
   Tassabehji M, 2003, HUM MOL GENET, V12, pR229, DOI 10.1093/hmg/ddg299
   Thakur D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02203
   Thomas M, 2002, BEHAV BRAIN SCI, V25, P727, DOI 10.1017/S0140525X02000134
   Thomas M. S., 2013, OXFORD HDB DEV PSYCH
   Thomas MSC, 2009, J SPEECH LANG HEAR R, V52, P336, DOI 10.1044/1092-4388(2009/07-0144)
   Tillmann B, 2003, COGNITIVE BRAIN RES, V16, P145, DOI 10.1016/S0926-6410(02)00245-8
   Westermann G, 2007, DEVELOPMENTAL SCI, V10, P75, DOI 10.1111/j.1467-7687.2007.00567.x
NR 73
TC 0
Z9 0
U1 1
U2 6
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0891-4222
J9 RES DEV DISABIL
JI Res. Dev. Disabil.
PD AUG
PY 2020
VL 103
AR 103660
DI 10.1016/j.ridd.2020.103660
PG 9
WC Education, Special; Rehabilitation
WE Social Science Citation Index (SSCI)
SC Education & Educational Research; Rehabilitation
GA MH8WZ
UT WOS:000547003900001
PM 32447244
OA Green Accepted
DA 2024-01-09
ER

PT J
AU Noad, B
   Barton, G
AF Noad, Betty
   Barton, Georgina
TI Emotion Resonance and Divergence: a semiotic analysis of music and sound
   in "The Lost Thing" an animated short film and "Elizabeth" a film
   trailer
SO SOCIAL SEMIOTICS
LA English
DT Article
DE Music; sound; semiotics; meaning; multimodality; emotion; filmtrailer;
   animated movie
ID EXPRESSION
AB Music and sound contributions of interpersonal meaning to film narratives may be different from or similar to meanings made by language and image, and dynamic interactions between several modalities may generate new story messages. Such interpretive potentials of music and voice sound in motion pictures are rarely considered in social semiotic investigations of intermodality. This paper therefore shares two semiotic studies of distinct and combined music, English speech and image systems in an animated short film and a promotional filmtrailer. The paper considers the impact of music and voice sound on interpretations of film narrative meanings. A music system relevant to the analysis of filmic emotion is proposed. Examples show how music and intonation contribute meaning to lexical, visual and gestural elements of the cinematic spaces. Also described are relations of divergence and resonance between emotion types in various couplings of music, intonation, words and images across story phases. The research is relevant to educational knowledge about sound, and semiotic studies of multimodality.
C1 [Noad, Betty] Univ New England, Fac Humanities Arts Social Sci & Educ, Armidale, NSW, Australia.
   [Barton, Georgina] Univ Southern Queensland, Sch Teacher Educ & Early Childhood, Springfield, Australia.
C3 University of New England; University of Southern Queensland
RP Noad, B (corresponding author), Univ New England, Fac Humanities Arts Social Sci & Educ, Armidale, NSW, Australia.
EM bnoad3@une.edu.au
OI Noad, Betty/0000-0001-5623-7531
CR ACARA (Australian Curriculum Assessment and Reporting Authority), 2016, V8 3 AUSTR CURR GEN
   [Anonymous], LITERACY LEARNING MI
   [Anonymous], 2010, Handbook of Music and Emotion
   [Anonymous], 2003, SOCIAL SEMIOTICS
   [Anonymous], THE LOST THING
   [Anonymous], 2001, MUSIC EMOTION THEORY
   [Anonymous], MUSIC EMOTION THEORY
   [Anonymous], 1967, Intonation and grammar in British English
   [Anonymous], 2013, FILM ART INTRO
   [Anonymous], 2003, MANUEL SCI AFFECTIVE
   Barton G., 2018, MUSIC LEARNING TEACH
   Barton G., 2017, The Palgrave handbook of global arts education, P221
   Barton G, 2014, AUST J LANG LIT, V37, P3
   Bateman JA, 2017, DISCOURSE CONTEXT ME, V20, P160, DOI 10.1016/j.dcm.2017.06.009
   Bednarek M, 2008, EMOTION TALK ACROSS CORPORA, P1, DOI 10.1057/9780230285712
   Bolivar VJ., 1994, Psychomusicology: A Journal of Research in Music Cognition, V13, P28, DOI [10.1037/h0094102, DOI 10.1037/H0094102]
   Boltz MG, 2004, MEM COGNITION, V32, P1194, DOI 10.3758/BF03196892
   Brannigan E., 2013, NARRATIVE COMPREHENS
   Carroll N., 1999, PASSIONATE VIEWS FIL, P1
   Cohen AJ., 2011, MUSIC EMOTION THEORY, P1099, DOI [DOI 10.1093/ACPROF:OSO/9780199230143.003.0031, 10.1093/acprof:oso/9780199230143.003.0031]
   COOK N, 1998, ANAL MUSIC MULTIMEDI
   Crystal D, 1976, PROSODIC SYSTEMS INT
   Davies Stephen, 2010, Handbook of music and emotion: Theory, research, applications, P15
   Duncam Paul., 2004, STUD ART EDUC, V45, P252, DOI [10.1080/00393541.2004.11651771, DOI 10.1080/00393541.2004.11651771]
   Ekman P, 1978, FACIAL AFFECT CODING
   Ellis RJ., 2005, Psychomusicology, V19, P15, DOI [DOI 10.1037/H0094042, 10.1037/h0094042]
   Feng DZ, 2013, SEMIOTICA, V197, P79, DOI 10.1515/sem-2013-0082
   Feng DZ, 2012, J PRAGMATICS, V44, P2067, DOI 10.1016/j.pragma.2012.10.003
   Frijda N., 1986, The emotions: Studies in emotion and social interaction
   Frijda Nico H., 2007, The laws of emotion
   Gabrielsson A, 2003, SER AFFECTIVE SCI, P503
   Gabrielsson A., 2010, HDB MUSIC EMOTION TH, P367, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0014
   Gorbman Claudia, 1987, Unheard Melodies: Narrative
   Gundlach RH, 1935, AM J PSYCHOL, V47, P624, DOI 10.2307/1416007
   Halliday M. A. K., 2008, Intonation in the grammar of English
   Ighigeanu D, 2008, ENERGY ENVIRON ENG S, P112
   Jewitt Carey, 2009, The handbook of multimodal analysis
   Kalinak Kathryn, 1992, Settling the Score: Music and the Classical Hollywood Film
   Kapur Shekhar, 2007, Elizabeth: The Golden Age
   Kress Gunther., 2009, Multimodality: Exploring Contemporary Methods of Communication
   Lemke J. L., 2015, International Handbook of Semiotics, P589
   Magliano JP, 1996, DISCOURSE PROCESS, V22, P199, DOI 10.1080/01638539609544973
   MARSHALL SK, 1988, MUSIC PERCEPT, V6, P95
   Martin JR, 2016, WORD, V62, P35, DOI 10.1080/00437956.2016.1141939
   Martin J. R., 2007, WORKING DISCOURSE ME, V2da
   Martin J. R., 2005, The Language of Evaluation, V2
   Martinec R, 2001, SEMIOTICA, V135, P117
   McDonald E., 2010, SEMIOTIC MARGINS REC, P102
   Nattiez J. -J., 1990, MUSIC DISCOURSE SEMI
   Noad B., 2016, THESIS
   O'Halloran KL, 2008, VISUAL COMMUN-US, V7, P443, DOI 10.1177/1470357208096210
   Oatley K., 2006, Understanding Emotions
   Painter Claire, 2013, Reading visual narratives, DOI 10.1075/aral.38.1.05bir
   Sadie Stanley, 2001, The New Grove Dictionary of Music and Musicians
   Scherer KR, 2003, SER AFFECTIVE SCI, P433
   Sinclair D., 1994, PSYCHOMUSICOLOGY, V13, P9, DOI DOI 10.1037/H0094103
   Sloboda J.A., 2010, Handbook of music and emotion: Theory, research, applications, P73
   Sloboda JA., 2001, MUSIC EMOTION THEORY, P71
   Smith GM., 2003, Film structure and the emotion system
   Smith Jeff., 1999, PASSIONATE VIEWS FIL, P146
   Tan S., 1996, EMOTION STRUCTURE NA
   Tan SL, 2007, MUSIC PERCEPT, V25, P135, DOI 10.1525/MP.2007.25.2.135
   Tench P., 1996, INTONATION SYSTEMS E
   Van Leeuwen Theo., 2009, ROUTLEDGE HDB MULTIM, P68
   Van Leeuwen Theo, 2005, Introducing social semiotics
   Van Leeuwen Theo, 1999, SPEECH SOUND MUSIC
   Veronesi D, 2014, SOC SEMIOT, V24, P369, DOI 10.1080/10350330.2014.929379
   Walsh M, 2015, ENGL AUST, V50, P67
NR 68
TC 3
Z9 3
U1 4
U2 36
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1035-0330
EI 1470-1219
J9 SOC SEMIOT
JI Soc. Semiot.
PD MAR 14
PY 2020
VL 30
IS 2
BP 206
EP 224
DI 10.1080/10350330.2018.1543115
PG 19
WC Humanities, Multidisciplinary; Communication; Linguistics
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Arts & Humanities - Other Topics; Communication; Linguistics
GA KQ5PA
UT WOS:000516972900004
DA 2024-01-09
ER

PT J
AU Taruffi, L
   Allen, R
   Downing, J
   Heaton, P
AF Taruffi, Liila
   Allen, Rory
   Downing, John
   Heaton, Pamela
TI INDIVIDUAL DIFFERENCES IN MUSIC-PERCEIVED EMOTIONS: THE INFLUENCE OF
   EXTERNALLY ORIENTED THINKING
SO MUSIC PERCEPTION
LA English
DT Article
DE music-perceived emotions; alexithymia; empathy; personality traits;
   musical expertise
ID TORONTO-ALEXITHYMIA-SCALE; SAD MUSIC; DEVELOPMENTAL-CHANGE; FACIAL
   EXPRESSIONS; DIMENSIONAL MODELS; FACTORIAL VALIDITY; NEGATIVE EMOTION;
   PERCEPTION; RECOGNITION; EMPATHY
AB PREVIOUS MUSIC AND EMOTION RESEARCH SUGGESTS that individual differences in empathy, alexithymia, personality traits, and musical expertise might play a role in music-perceived emotions. In this study, we investigated the relationship between these individual characteristics and the ability of participants to recognize five basic emotions (happiness, sadness, tenderness, fear, and anger) conveyed by validated excerpts of film music. One hundred and twenty participants were recruited through an online platform and completed an emotion recognition task as well as the IRI (Interpersonal Reactivity Index), TAS-20 (Toronto Alexithymia Scale), BFI (Big Five Inventory), and Gold-MSI (Goldsmiths Musical Sophistication Index). While participants recognized the emotions depicted by the music at levels that were better than chance, their performance accuracy was negatively associated with the externally oriented thinking subscale from the TAS-20. Our results suggest that alexithymia, previously linked to a deficit in perception of facial and vocal expressions of emotion, is also associated with difficulties in perception of emotions conveyed by music.
C1 [Taruffi, Liila] Free Univ Berlin, Berlin, Germany.
   [Allen, Rory; Downing, John; Heaton, Pamela] Goldsmiths, London, England.
C3 Free University of Berlin; University of London; Goldsmiths University
   London
RP Taruffi, L (corresponding author), Free Univ Berlin, Dept Educ Sci & Psychol, Habelschwerdter Alle 45, D-14195 Berlin, Germany.
EM liilataruffi@zedat.fu-berlin.de
RI Allen, Rory/E-8660-2011; Taruffi, Liila/IAP-4169-2023
OI Allen, Rory/0000-0003-3434-9772; Taruffi, Liila/0000-0002-6580-9164
CR ALLEN R, 1993, INT J NEUROSCI, V68, P33, DOI 10.3109/00207459308994257
   Allen R, 2013, J AUTISM DEV DISORD, V43, P432, DOI 10.1007/s10803-012-1587-8
   Allen R, 2010, MUSIC PERCEPT, V27, P251, DOI 10.1525/MP.2010.27.4.251
   Allgood R, 2015, BRIT J DEV PSYCHOL, V33, P398, DOI 10.1111/bjdp.12097
   BAGBY RM, 1994, J PSYCHOSOM RES, V38, P23, DOI 10.1016/0022-3999(94)90005-1
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Berthoz S, 2005, EUR PSYCHIAT, V20, P291, DOI 10.1016/j.eurpsy.2004.06.013
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Bigand E, 2006, COGNITION, V100, P100, DOI 10.1016/j.cognition.2005.11.007
   BOUHUYS AL, 1995, J AFFECT DISORDERS, V33, P215, DOI 10.1016/0165-0327(94)00092-N
   Bowles DC, 2009, COGN NEUROPSYCHOL, V26, P423, DOI 10.1080/02643290903343149
   BRITON NJ, 1995, SEX ROLES, V32, P79, DOI 10.1007/BF01544758
   BROSGOLE L, 1995, INT J NEUROSCI, V82, P169, DOI 10.3109/00207459508999800
   CUNNINGHAM JG, 1988, MOTIV EMOTION, V12, P399, DOI 10.1007/BF00992362
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Davis M. H., 1980, JSAS Catalog of Selected Documents in Psychology, V10, P85
   Davydov DM, 2013, INT J PSYCHOPHYSIOL, V87, P152, DOI 10.1016/j.ijpsycho.2012.12.003
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   EKMAN P, 1979, ANNU REV PSYCHOL, V30, P527, DOI 10.1146/annurev.ps.30.020179.002523
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Gabrielsson A, 2001, MUSIC SCI, V5, P123, DOI 10.1177/10298649020050S105
   Gallese Vittorio, 2005, Phenomenology Cog Sci, V4, P23
   Garrido S, 2013, MUSIC SCI, V17, P147, DOI 10.1177/1029864913478305
   Garrido S, 2011, MUSIC PERCEPT, V28, P279, DOI 10.1525/MP.2011.28.3.279
   Goldman AI, 2005, COGNITION, V94, P193, DOI 10.1016/j.cognition.2004.01.005
   Goodman Nelson., 1968, Language of Art: An Approach to a Theory of Symbols
   Guttman HA, 2000, FAM PROCESS, V39, P345, DOI 10.1111/j.1545-5300.2000.39306.x
   Heaton P, 2012, PSYCHOL MED, V42, P2453, DOI 10.1017/S0033291712000621
   Heaton P, 2008, BRIT J DEV PSYCHOL, V26, P171, DOI 10.1348/026151007X206776
   Hooker CI, 2010, BRAIN RES, V1308, P100, DOI 10.1016/j.brainres.2009.10.006
   Huron D, 2011, MUSIC SCI, V15, P146, DOI 10.1177/1029864911401171
   ISEN AM, 1982, SOC PSYCHOL QUART, V45, P58, DOI 10.2307/3033676
   Jessimer M, 1997, BRAIN COGNITION, V34, P246, DOI 10.1006/brcg.1997.0900
   John O. P., 1999, HDB PERSONALITY THEO, V2nd ed., P102
   Jonason PK, 2013, PERS INDIV DIFFER, V55, P532, DOI 10.1016/j.paid.2013.04.027
   Juslin P. N., 2010, HDB MUSIC EMOTION TH, P3
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN., 2001, Music and Emotion, P309, DOI 10.1093/oso/9780192631886.003.0014
   KASTNER MP, 1990, MUSIC PERCEPT, V8, P189
   Kawakami A, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00311
   Kiss I, 2001, Appl Neuropsychol, V8, P251, DOI 10.1207/09084280152829110
   Kokkonen P, 2001, COMPR PSYCHIAT, V42, P471, DOI 10.1053/comp.2001.27892
   Kooiman CG, 2002, J PSYCHOSOM RES, V53, P1083, DOI 10.1016/S0022-3999(02)00348-3
   Krumhansl CL, 1997, CAN J EXP PSYCHOL, V51, P336, DOI 10.1037/1196-1961.51.4.336
   Ladinig O, 2012, PSYCHOL AESTHET CREA, V6, P146, DOI 10.1037/a0024671
   Lander GC, 2012, PERS INDIV DIFFER, V52, P45, DOI 10.1016/j.paid.2011.08.027
   Lane RD, 1996, PSYCHOSOM MED, V58, P203, DOI 10.1097/00006842-199605000-00002
   Leising D, 2009, J RES PERS, V43, P707, DOI 10.1016/j.jrp.2009.03.009
   Luminet O, 2004, COGNITION EMOTION, V18, P741, DOI 10.1080/02699930341000275
   Luminet O, 2000, COGNITION EMOTION, V14, P661, DOI 10.1080/02699930050117666
   Lumley MA, 2000, J PSYCHOSOM RES, V48, P561, DOI 10.1016/S0022-3999(00)00096-9
   Lumley MA, 2000, J PSYCHOSOM RES, V49, P51, DOI 10.1016/S0022-3999(00)00161-6
   Machin GC, 2009, PERS INDIV DIFFER, V46, P412, DOI 10.1016/j.paid.2008.11.010
   Matthews G, 2015, J PSYCHOEDUC ASSESS, V33, P68, DOI 10.1177/0734282914550386
   Mattila AK, 2006, J PSYCHOSOM RES, V61, P629, DOI 10.1016/j.jpsychores.2006.04.013
   Meins E, 2008, PERS INDIV DIFFER, V45, P146, DOI 10.1016/j.paid.2008.03.013
   Mitterschiffthaler MT, 2007, HUM BRAIN MAPP, V28, P1150, DOI 10.1002/hbm.20337
   MIURA M, 1993, JPN J PSYCHOL, V63, P409, DOI 10.4992/jjpsy.63.409
   Moriguchi Y, 2007, CEREB CORTEX, V17, P2223, DOI 10.1093/cercor/bhl130
   Müllensiefan D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089642
   Nawrot ES., 2003, Psychol. Music, V31, P75, DOI DOI 10.1177/0305735603031001325
   Nemiah JC., 1976, Modern Trends in Psychosomatic Medicine, V3, P430
   Niedenthal PM, 2007, SCIENCE, V316, P1002, DOI 10.1126/science.1136930
   Orbelo DM, 2005, J GERIATR PSYCH NEUR, V18, P25, DOI 10.1177/0891988704272214
   Palermo R, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068126
   Parker JDA, 2003, J PSYCHOSOM RES, V55, P269, DOI 10.1016/S0022-3999(02)00578-0
   PARKER JDA, 1993, EUR J PERSONALITY, V7, P221, DOI 10.1002/per.2410070403
   Parker PD, 2005, J PERS, V73, P1087, DOI 10.1111/j.1467-6494.2005.00339.x
   Paulmann S, 2008, BRAIN LANG, V104, P262, DOI 10.1016/j.bandl.2007.03.002
   Preacher KJ, 2005, PSYCHOL METHODS, V10, P178, DOI 10.1037/1082-989X.10.2.178
   Reniers RLEP, 2011, J PERS ASSESS, V93, P84, DOI 10.1080/00223891.2010.528484
   Resnicow JE, 2004, MUSIC PERCEPT, V22, P145, DOI 10.1525/mp.2004.22.1.145
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Rusting CL, 1998, PSYCHOL BULL, V124, P165, DOI 10.1037/0033-2909.124.2.165
   Salminen JK, 1999, J PSYCHOSOM RES, V46, P75, DOI 10.1016/S0022-3999(98)00053-1
   Schimmack U, 2000, EUR J PERSONALITY, V14, P325, DOI 10.1002/1099-0984(200007/08)14:4<325::AID-PER380>3.0.CO;2-I
   Silani G, 2008, SOC NEUROSCI-UK, V3, P97, DOI 10.1080/17470910701577020
   Singer T, 2004, SCIENCE, V303, P1157, DOI 10.1126/science.1093535
   Singer T, 2009, ANN NY ACAD SCI, V1156, P81, DOI 10.1111/j.1749-6632.2009.04418.x
   Srivastava S, 2003, J PERS SOC PSYCHOL, V84, P1041, DOI 10.1037/0022-3514.84.5.1041
   TARUFFI L., 2017, SAD MUSIC ENGA UNPUB
   Taruffi L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0110490
   Taylor GJ, 2004, PSYCHOTHER PSYCHOSOM, V73, P68, DOI 10.1159/000075537
   Thompson W.F., 2010, Handbook of music and emotion: Theory, research, and applications, P755
   Vorst HCM, 2001, PERS INDIV DIFFER, V30, P413, DOI 10.1016/S0191-8869(00)00033-7
   Vuoskoski JK, 2012, PSYCHOL AESTHET CREA, V6, P204, DOI 10.1037/a0026937
   Vuoskoski JK, 2012, MUSIC PERCEPT, V29, P311, DOI 10.1525/MP.2012.29.3.311
   Vuoskoski JK, 2011, CORTEX, V47, P1099, DOI 10.1016/j.cortex.2011.04.011
   Wöllner C, 2012, PSYCHOL AESTHET CREA, V6, P214, DOI 10.1037/a0027392
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 93
TC 24
Z9 28
U1 1
U2 61
PU UNIV CALIFORNIA PRESS
PI OAKLAND
PA 155 GRAND AVE, SUITE 400, OAKLAND, CA 94612-3758 USA
SN 0730-7829
J9 MUSIC PERCEPT
JI Music Percept.
PD FEB
PY 2017
VL 34
IS 3
BP 253
EP 266
DI 10.1525/MP.2017.34.3.253
PG 14
WC Music; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music; Psychology
GA EJ5JR
UT WOS:000393254800001
OA Green Accepted
DA 2024-01-09
ER

PT J
AU Alexander, SC
   Garner, DK
   Somoroff, M
   Gramling, DJ
   Norton, SA
   Gramling, R
AF Alexander, Stewart C.
   Garner, David Kirkland
   Somoroff, Matthew
   Gramling, David J.
   Norton, Sally A.
   Gramling, Robert
TI Using music[al] knowledge to represent expressions of emotions
SO PATIENT EDUCATION AND COUNSELING
LA English
DT Article
DE Empathic Opportunities; Emotions; Music; Music notation;
   Patient-provider communication
ID VOCAL EXPRESSION; COMMUNICATION; SPEECH; VISITS
AB Objective: Being able to identify expressions of emotion is crucial to effective clinical communication research. However, traditional linguistic coding systems often cannot represent emotions that are expressed nonlexically or phonologically (i.e., not through words themselves but through vocal pitch, speed/rhythm/tempo, and volume).
   Methods: Using audio recording of a palliative care consultation in the natural hospital setting, two experienced music scholars employed Western musical notation, as well as the graphic realization of a digital audio program (Piano roll visualization), to visually represent the sonic features of conversation where a patient has an emotional "choke" moment.
   Results: Western musical notation showed the ways that changes in pitch and rate correspond to the patient's emotion: rising sharply in intensity before slowly fading away. Piano roll visualization is a helpful supplement.
   Conclusions: Using musical notation to illustrate palliative care conversations in the hospital setting can render visible for analysis several aspects of emotional expression that researchers otherwise experience as intuitive or subjective. Various forms and formats of musical notation techniques and sonic visualization technologies should be considered as fruitful and complementary alternatives to traditional coding tools in clinical communications research.
   Practice implications: Musical notation offers opportunity for both researchers and learners to "see" how communication evolves in clinical encounters, particularly where the lexical and phonological features of interpersonal communication are concordant and discordant with one another. (C) 2015 Published by Elsevier Ireland Ltd.
C1 [Alexander, Stewart C.] Purdue Univ, Dept Consumer Sci, W Lafayette, IN 47907 USA.
   [Alexander, Stewart C.] Duke Univ, Med Ctr, Dept Med, Durham, NC 27710 USA.
   [Alexander, Stewart C.] Durham VA Med Ctr, Hlth Serv Res & Dev Serv, Durham, NC USA.
   [Garner, David Kirkland; Somoroff, Matthew] Duke Univ, Dept Mus, Durham, NC USA.
   [Gramling, David J.] Univ Arizona, Dept German Studies, Tucson, AZ 85721 USA.
   [Norton, Sally A.; Gramling, Robert] Univ Rochester, Sch Nursing, Rochester, NY 14627 USA.
   [Norton, Sally A.; Gramling, Robert] Univ Rochester, Dept Family Med, Rochester, NY 14627 USA.
C3 Purdue University System; Purdue University; Purdue University West
   Lafayette Campus; Duke University; US Department of Veterans Affairs;
   Veterans Health Administration (VHA); Durham VA Medical Center; Duke
   University; University of Arizona; University of Rochester; University
   of Rochester
RP Alexander, SC (corresponding author), 3335 Whirlaway Court, W Lafayette, IN 47906 USA.
EM alexa045@mc.duke.edu
OI Norton, Sally/0000-0001-7686-6327
CR Alexander SC, 2006, ACAD MED, V81, P1008, DOI 10.1097/01.ACM.0000242580.83851.ad
   Alexander SC, 2014, J PALLIAT MED, V17, P579, DOI 10.1089/jpm.2013.0551
   Alexander SC, 2011, SUPPORT CARE CANCER, V19, P155, DOI 10.1007/s00520-010-0996-5
   ALPERT M, 1986, BEHAV RES METH INSTR, V18, P267, DOI 10.3758/BF03201035
   Anderson WG, 2008, SUPPORT CARE CANCER, V16, P803, DOI 10.1007/s00520-007-0350-8
   [Anonymous], HDB AFFECTIVE SCI
   Bachorowski J, 2010, HDB EMOTION, P196
   BACHOROWSKI JA, 1995, PSYCHOL SCI, V6, P219, DOI 10.1111/j.1467-9280.1995.tb00596.x
   Back AL, 2007, ARCH INTERN MED, V167, P453, DOI 10.1001/archinte.167.5.453
   Baile W F, 1997, J Cancer Educ, V12, P166
   Baile WF, 2012, J PALLIAT MED, V15, P1006, DOI 10.1089/jpm.2012.0030
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Boersma P., 2021, Glot International
   Cameron D., 2000, Good to talk? Living and working in a communication culture
   Cassell E, 1985, MIT PRESS SERIES HUM, V1
   Cohen AS, 2009, BEHAV RES METHODS, V41, P204, DOI 10.3758/BRM.41.1.204
   Collier G, 2014, VOCAL CHANGES EMOTIO
   Del Piccolo L, 2011, PATIENT EDUC COUNS, V82, P149, DOI 10.1016/j.pec.2010.02.024
   Erickson F., 2004, TALK SOCIAL THEORY E
   Erickson Frederich, 1982, ANAL DISCOURSE TEXT, P43
   FELD S, 1994, ANNU REV ANTHROPOL, V23, P25, DOI 10.1146/annurev.an.23.100194.000325
   FRICK RW, 1985, PSYCHOL BULL, V97, P412, DOI 10.1037/0033-2909.97.3.412
   Gee JP, 2014, INTRO DISCOURSE ANAL
   Gramling R, 2013, J PALLIAT MED, V16, P653, DOI 10.1089/jpm.2012.0381
   Haskard KB, 2008, J NONVERBAL BEHAV, V32, P1, DOI 10.1007/s10919-007-0038-2
   Jefferson G., 2004, Glossary of Transcript Symbols, P13, DOI [DOI 10.1075/PBNS.125.02JEF, 10.1075/pbns.125.02jef]
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kappas A, 1991, VOICE EMOTION FUNDAM, P220
   Kennifer SL, 2009, PATIENT EDUC COUNS, V76, P51, DOI 10.1016/j.pec.2008.10.003
   KLASMEYER G, 1999, VOICE QUALITY MEASUR, P339
   Laukka P, 2005, COGNITION EMOTION, V19, P633, DOI 10.1080/02699930441000445
   McHenry M, 2012, SUPPORT CARE CANCER, V20, P1073, DOI 10.1007/s00520-011-1187-8
   Pollak KI, 2007, J CLIN ONCOL, V25, P5748, DOI 10.1200/JCO.2007.12.4180
   Roter DL, 2006, J GEN INTERN MED, V21, pS28, DOI 10.1111/j.1525-1497.2006.00306.x
   Tulsky JA, 2011, ANN INTERN MED, V155, P593, DOI 10.7326/0003-4819-155-9-201111010-00007
   Wennerstrom Ann, 2001, MUSIC EVERYDAY SPEEC
NR 36
TC 7
Z9 8
U1 0
U2 12
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0738-3991
J9 PATIENT EDUC COUNS
JI Patient Educ. Couns.
PD NOV
PY 2015
VL 98
IS 11
BP 1339
EP 1345
DI 10.1016/j.pec.2015.04.019
PG 7
WC Public, Environmental & Occupational Health; Social Sciences,
   Interdisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Public, Environmental & Occupational Health; Social Sciences - Other
   Topics
GA DB2IS
UT WOS:000368332100006
PM 26160038
DA 2024-01-09
ER

PT J
AU Blasi, A
   Mercure, E
   Lloyd-Fox, S
   Thomson, A
   Brammer, M
   Sauter, D
   Deeley, Q
   Barker, GJ
   Renvall, V
   Deoni, S
   Gasston, D
   Williams, SCR
   Johnson, MH
   Simmons, A
   Murphy, DGM
AF Blasi, Anna
   Mercure, Evelyne
   Lloyd-Fox, Sarah
   Thomson, Alex
   Brammer, Michael
   Sauter, Disa
   Deeley, Quinton
   Barker, Gareth J.
   Renvall, Ville
   Deoni, Sean
   Gasston, David
   Williams, Steven C. R.
   Johnson, Mark H.
   Simmons, Andrew
   Murphy, Declan G. M.
TI Early Specialization for Voice and Emotion Processing in the Infant
   Brain
SO CURRENT BIOLOGY
LA English
DT Article
ID HUMAN AUDITORY-CORTEX; NEURAL RESPONSES; TEMPORAL-LOBE; PERCEPTION;
   SPEECH; VOCALIZATIONS; ACTIVATION; PROSODY; PREFER; SLEEP
AB Human voices play a fundamental role in social communication, and areas of the adult "social brain" show specialization for processing voices and their emotional content (superior temporal sulcus, inferior prefrontal cortex, premotor cortical regions, amygdala, and insula) [1-8]. However, it is unclear when this specialization develops. Functional magnetic resonance (fMRI) studies suggest that the infant temporal cortex does not differentiate speech from music or backward speech [9, 10], but a prior study with functional near-infrared spectroscopy revealed preferential activation for human voices in 7-month-olds, in a more posterior location of the temporal cortex than in adults [11]. However, the brain networks involved in processing nonspeech human vocalizations in early development are still unknown. To address this issue, in the present fMRI study, 3- to 7-month-olds were presented with adult nonspeech vocalizations (emotionally neutral, emotionally positive, and emotionally negative) and nonvocal environmental sounds. Infants displayed significant differential activation in the anterior portion of the temporal cortex, similarly to adults [1]. Moreover, sad vocalizations modulated the activity of brain regions involved in processing affective stimuli such as the orbitofrontal cortex [12] and insula [7, 8]. These results suggest remarkably early functional specialization for processing human voice and negative emotions.
C1 [Blasi, Anna; Thomson, Alex; Deeley, Quinton; Murphy, Declan G. M.] Kings Coll London, Inst Psychiat, Dept Forens & Neurodev Sci, London SE5 8AF, England.
   [Mercure, Evelyne] UCL, Inst Cognit Neurosci, London WC1N 3AR, England.
   [Lloyd-Fox, Sarah; Johnson, Mark H.] Univ London Birkbeck Coll, Ctr Brain & Cognit Dev, London WC1E 7HX, England.
   [Brammer, Michael; Barker, Gareth J.; Deoni, Sean; Gasston, David; Williams, Steven C. R.; Simmons, Andrew] Kings Coll London, Inst Psychiat, Dept Neuroimaging, London SE5 8AF, England.
   [Sauter, Disa] Max Planck Inst Psycholinguist, NL-6500 AH Nijmegen, Netherlands.
   [Renvall, Ville] Aalto Univ Sch Sci, Low Temp Lab, Brain Res Unit, FI-00076 Espoo, Finland.
   [Deoni, Sean] Brown Univ, Sch Engn, Adv Baby Imaging Lab, Providence, RI 02912 USA.
   [Williams, Steven C. R.; Simmons, Andrew; Murphy, Declan G. M.] NIHR Biomed Res Ctr Mental Hlth S London, London SE5 8AZ, England.
   [Williams, Steven C. R.; Simmons, Andrew; Murphy, Declan G. M.] Maudsley NHS Fdn Trust, London SE5 8AZ, England.
   [Williams, Steven C. R.; Simmons, Andrew; Murphy, Declan G. M.] Kings Coll London, Inst Psychiat, London SE5 8AZ, England.
C3 University of London; King's College London; University of London;
   University College London; University of London; Birkbeck University
   London; University of London; King's College London; Max Planck Society;
   Aalto University; Brown University; University of London; King's College
   London; South London & Maudsley NHS Trust; University of London; King's
   College London
RP Blasi, A (corresponding author), Kings Coll London, Inst Psychiat, Dept Forens & Neurodev Sci, London SE5 8AF, England.
EM anna.blasi@kcl.ac.uk; e.mercure@ucl.ac.uk
RI Deeley, Quinton/B-4992-2011; Sauter, Disa/AAF-9557-2022; Barker, Gareth
   J/C-9616-2009; Williams, Steve C/D-6979-2011; Mercure,
   Evelyne/JGD-2078-2023; Renvall, Ville/M-4165-2013; Simmons,
   Andrew/B-8848-2008; Lloyd-Fox, Sarah/J-5408-2019; Sauter,
   Disa/AFK-2268-2022; Johnson, Mark/ISV-5042-2023; Brammer, Michael
   J/B-7128-2012
OI Barker, Gareth J/0000-0002-5214-7421; Williams, Steve
   C/0000-0003-4299-1941; Renvall, Ville/0000-0002-4070-7030; Simmons,
   Andrew/0000-0003-2306-5811; Lloyd-Fox, Sarah/0000-0001-6742-9889;
   Johnson, Mark/0000-0003-4229-2585; Brammer, Michael
   J/0000-0001-9800-2052; opoku, anita/0000-0001-7243-8157; Deeley,
   Quinton/0000-0001-5306-0769; Murphy, Declan/0000-0002-6664-7451;
   Mercure, Evelyne/0000-0003-1645-902X
FU Medical Research Council (MRC UK); MAC UK AIMS network [G0400061/69344];
   NIHR Biomedical Research Centre for Mental Health at South London;
   Maudsley NHS Foundation Trust; Institute of Psychiatry, King's College
   London; MRC [G0701484]; Economic and Social Research Council
   [ES/G017603/1] Funding Source: researchfish; Medical Research Council
   [G0701484, G0400120] Funding Source: researchfish; ESRC [ES/G017603/1]
   Funding Source: UKRI; MRC [G0400120, G0701484] Funding Source: UKRI
FX Funding was provided by the Medical Research Council (MRC UK), the MAC
   UK AIMS network (G0400061/69344, D.G.M.M., principal investigator), and
   the NIHR Biomedical Research Centre for Mental Health at South London
   and Maudsley NHS Foundation Trust and Institute of Psychiatry, King's
   College London. M.H.J. and S.L.-F. were supported by MRC grant G0701484.
   We would like to thank Ghislaine Dehaene-Lambertz for her valuable input
   on infant MRI scanning and the team of Joe Piven.
CR Altman NR, 2001, RADIOLOGY, V221, P56, DOI 10.1148/radiol.2211010074
   Bahrick LE, 1998, CHILD DEV, V69, P1263, DOI 10.2307/1132264
   Barr R. G., 2000, CRYING SIGN SYMPTOM
   Belin P, 2003, NEUROREPORT, V14, P2105, DOI 10.1097/00001756-200311140-00019
   Belin P, 2004, TRENDS COGN SCI, V8, P129, DOI 10.1016/j.tics.2004.01.008
   Belin P, 2002, COGNITIVE BRAIN RES, V13, P17, DOI 10.1016/S0926-6410(01)00084-2
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Belin P, 2010, NEURON, V65, P733, DOI 10.1016/j.neuron.2010.03.018
   Czisch M, 2002, NEUROIMAGE, V16, P251, DOI 10.1006/nimg.2002.1071
   DECASPER AJ, 1980, SCIENCE, V208, P1174, DOI 10.1126/science.7375928
   Dehaene-Lambertz G, 2010, BRAIN LANG, V114, P53, DOI 10.1016/j.bandl.2009.09.003
   Dehaene-Lambertz G, 2002, SCIENCE, V298, P2013, DOI 10.1126/science.1077066
   Fecteau S, 2005, J NEUROPHYSIOL, V94, P2251, DOI 10.1152/jn.00329.2005
   Fecteau S, 2004, NEUROIMAGE, V23, P840, DOI 10.1016/j.neuroimage.2004.09.019
   Fecteau S, 2007, NEUROIMAGE, V36, P480, DOI 10.1016/j.neuroimage.2007.02.043
   Grandjean D, 2005, NAT NEUROSCI, V8, P145, DOI 10.1038/nn1392
   Grossmann T, 2005, NEUROREPORT, V16, P1825, DOI 10.1097/01.wnr.0000185964.34336.b1
   Grossmann T, 2010, NEURON, V65, P852, DOI 10.1016/j.neuron.2010.03.001
   Kriegstein KV, 2004, NEUROIMAGE, V22, P948, DOI 10.1016/j.neuroimage.2004.02.020
   Kringelbach ML, 2005, NAT REV NEUROSCI, V6, P691, DOI 10.1038/nrn1747
   Latinus M, 2011, CURR BIOL, V21, pR143, DOI 10.1016/j.cub.2010.12.033
   Leppänen JM, 2009, NAT REV NEUROSCI, V10, P37, DOI 10.1038/nrn2554
   Lloyd-Fox S, 2010, NEUROSCI BIOBEHAV R, V34, P269, DOI 10.1016/j.neubiorev.2009.07.008
   MOON C, 1993, INFANT BEHAV DEV, V16, P495, DOI 10.1016/0163-6383(93)80007-U
   Morris JS, 1999, NEUROPSYCHOLOGIA, V37, P1155, DOI 10.1016/S0028-3932(99)00015-9
   Redcay E, 2007, NEUROIMAGE, V38, P696, DOI 10.1016/j.neuroimage.2007.08.005
   Sander K, 2001, COGNITIVE BRAIN RES, V12, P181, DOI 10.1016/S0926-6410(01)00045-3
   Scott SK, 2008, TRENDS COGN SCI, V12, P323, DOI 10.1016/j.tics.2008.06.003
   von Kriegstein K, 2003, COGNITIVE BRAIN RES, V17, P48, DOI 10.1016/S0926-6410(03)00079-X
   WALKERANDREWS AS, 1991, INFANT BEHAV DEV, V14, P131, DOI 10.1016/0163-6383(91)90001-9
   Warren JE, 2006, J NEUROSCI, V26, P13067, DOI 10.1523/JNEUROSCI.3907-06.2006
NR 32
TC 167
Z9 193
U1 0
U2 56
PU CELL PRESS
PI CAMBRIDGE
PA 600 TECHNOLOGY SQUARE, 5TH FLOOR, CAMBRIDGE, MA 02139 USA
SN 0960-9822
J9 CURR BIOL
JI Curr. Biol.
PD JUL 26
PY 2011
VL 21
IS 14
BP 1220
EP 1224
DI 10.1016/j.cub.2011.06.009
PG 5
WC Biochemistry & Molecular Biology; Biology; Cell Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Life Sciences & Biomedicine - Other
   Topics; Cell Biology
GA 799XN
UT WOS:000293320000024
PM 21723130
OA Green Published, hybrid
DA 2024-01-09
ER

PT J
AU Farmer, E
   Jicol, C
   Petrini, K
AF Farmer, Eliot
   Jicol, Crescent
   Petrini, Karin
TI MUSICIANSHIP ENHANCES PERCEPTION BUT NOT FEELING OF EMOTION FROM OTHERS'
   SOCIAL INTERACTION THROUGH SPEECH PROSODY
SO MUSIC PERCEPTION
LA English
DT Article
DE music expertise; emotion perception; emotional feeling; social
   interaction; multisensory facilitation
ID POINT-LIGHT DISPLAYS; AUDIOVISUAL INTEGRATION; VISUAL-PERCEPTION; VOCAL
   EXPRESSION; MUSIC; BODY; RECOGNITION; LIFE; COMMUNICATION; METAANALYSIS
AB MUSIC EXPERTISE HAS BEEN SHOWN TO ENHANCE emotion recognition from speech prosody. Yet, it is currently unclear whether music training enhances the recognition of emotions through other communicative modalities such as vision and whether it enhances the feeling of such emotions. Musicians and nonmusicians were presented with visual, auditory, and audiovisual clips consisting of the biological motion and speech prosody of two agents interacting. Participants judged as quickly as possible whether the expressed emotion was happiness or anger, and subsequently indicated whether they also felt the emotion they had perceived. Measures of accuracy and reaction time were collected from the emotion recognition judgements, while yes/no responses were collected as indication of felt emotions. Musicians were more accurate than nonmusicians at recognizing emotion in the auditory-only condition, but not in the visual-only or audiovisual conditions. Although music training enhanced recognition of emotion through sound, it did not affect the felt emotion. These findings indicate that emotional processing in music and language may use overlapping but also divergent resources, or that some aspects of emotional processing are less responsive to music training than others. Hence music training may be an effective rehabilitative device for interpreting others' emotion through speech.
C1 [Farmer, Eliot; Jicol, Crescent; Petrini, Karin] Univ Bath, Bath, Avon, England.
C3 University of Bath
RP Farmer, E (corresponding author), Univ Bath, Bath, Avon, England.
OI Petrini, Karin/0000-0001-5354-5600
CR Alais D, 2004, CURR BIOL, V14, P257, DOI 10.1016/j.cub.2004.01.029
   ASMUS EP, 1990, J RES MUSIC EDUC, V38, P258, DOI 10.2307/3345223
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Bhatara A, 2011, J EXP PSYCHOL HUMAN, V37, P921, DOI 10.1037/a0021922
   Boebinger D, 2015, J ACOUST SOC AM, V137, P378, DOI 10.1121/1.4904537
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Brattico E, 2016, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00676
   Castro SL, 2014, MUSIC PERCEPT, V32, P125, DOI 10.1525/MP.2014.32.2.125
   Cauldwell R. T, 2000, ISCA TUT RES WORKSH
   Chartrand JP, 2006, NEUROSCI LETT, V405, P164, DOI 10.1016/j.neulet.2006.06.053
   Clarke TJ, 2005, PERCEPTION, V34, P1171, DOI 10.1068/p5203
   Collignon O, 2008, BRAIN RES, V1242, P126, DOI 10.1016/j.brainres.2008.04.023
   Costafreda SG, 2008, BRAIN RES REV, V58, P57, DOI 10.1016/j.brainresrev.2007.10.012
   Dahl S, 2007, MUSIC PERCEPT, V24, P433, DOI 10.1525/MP.2007.24.5.433
   DANESH HB, 1977, AM J PSYCHIAT, V134, P1109
   Deng HK, 2018, FRONT CELL INFECT MI, V8, DOI 10.3389/fcimb.2018.00431
   Di Mauro M, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02168
   Dittrich WH, 1996, PERCEPTION, V25, P727, DOI 10.1068/p250727
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   GABRIELSSON A, 2002, MUSIC SCI, V6, P123, DOI [10.3389/fpsyg.2013.00837, DOI 10.3389/FPSYG.2013.00837]
   Gardiner MF, 2008, BEHAV BRAIN SCI, V31, P580, DOI 10.1017/S0140525X08005359
   Good A, 2017, EAR HEARING, V38, P455, DOI 10.1097/AUD.0000000000000402
   Hatfield E., 1993, CURR DIR PSYCHOL SCI, V2, P96, DOI [10.1111/1467-8721.ep10770953, DOI 10.1111/1467-8721.EP10770953]
   Hausen M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00566
   Hauser MD, 2003, NAT NEUROSCI, V6, P663, DOI 10.1038/nn1080
   Herholz SC, 2012, NEURON, V76, P486, DOI 10.1016/j.neuron.2012.10.011
   Hill H, 2003, PERCEPTION, V32, P561, DOI 10.1068/p3435
   Jeffreys H., 1998, Theory of Probability
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Johnstone T, 2006, SOC COGN AFFECT NEUR, V1, P242, DOI 10.1093/scan/nsl027
   Juslin PN, 2014, PSYCHOL MUSIC, V42, P599, DOI 10.1177/0305735613484548
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kishon-Rabin Liat, 2001, Journal of Basic and Clinical Physiology and Pharmacology, V12, P125
   Kleiner M, 2007, PERCEPTION, V36, P14
   Knoll MA, 2009, SPEECH COMMUN, V51, P210, DOI 10.1016/j.specom.2008.08.001
   Korpilahti P, 2007, J AUTISM DEV DISORD, V37, P1539, DOI 10.1007/s10803-006-0271-2
   Lee H, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00868
   Lee H, 2011, P NATL ACAD SCI USA, V108, pE1441, DOI 10.1073/pnas.1115267108
   Lima CF, 2016, SCI REP-UK, V6, DOI 10.1038/srep34911
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Lima CF, 2011, COGNITION EMOTION, V25, P585, DOI 10.1080/02699931.2010.502449
   Lindstrom E, 2003, RES STUDIES MUSIC ED, V20, P23, DOI DOI 10.1177/1321103X030200010201
   Livingstone SR, 2010, COMPUT MUSIC J, V34, P41, DOI 10.1162/comj.2010.34.1.41
   Lu YF, 2014, PLOS ONE, V9, P3
   Ma YL, 2006, BEHAV RES METHODS, V38, P134, DOI 10.3758/BF03192758
   MADSEN S. M. K., 2019, SCI REPORTS
   Moreno S, 2009, CEREB CORTEX, V19, P712, DOI 10.1093/cercor/bhn120
   Munzer S., 2002, Psychologische Beitrage, V44, P187
   Musacchia G, 2007, P NATL ACAD SCI USA, V104, P15894, DOI 10.1073/pnas.0701498104
   Neumann R, 2000, J PERS SOC PSYCHOL, V79, P211, DOI 10.1037//0022-3514.79.2.211
   Palmer C, 1997, ANNU REV PSYCHOL, V48, P115, DOI 10.1146/annurev.psych.48.1.115
   Parbery-Clark A, 2013, J NEUROSCI, V33, P16741, DOI 10.1523/JNEUROSCI.5700-12.2013
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   Petrini K, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019165
   Petrini K, 2011, NEUROIMAGE, V56, P1480, DOI 10.1016/j.neuroimage.2011.03.009
   Petrini K, 2010, J VISION, V10, DOI 10.1167/10.5.2
   Petrini K, 2010, BRAIN RES, V1323, P139, DOI 10.1016/j.brainres.2010.02.012
   Petrini K, 2009, EXP BRAIN RES, V198, P339, DOI 10.1007/s00221-009-1817-2
   Phan KL, 2002, NEUROIMAGE, V16, P331, DOI 10.1006/nimg.2002.1087
   Pichon S, 2008, SOC NEUROSCI-UK, V3, P199, DOI 10.1080/17470910701394368
   Pisanski K, 2014, ANIM BEHAV, V95, P89, DOI 10.1016/j.anbehav.2014.06.011
   Piwek L, 2016, BEHAV RES METHODS, V48, P1285, DOI 10.3758/s13428-015-0654-4
   Piwek L, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00611
   Pollick FE, 2001, COGNITION, V82, pB51, DOI 10.1016/S0010-0277(01)00147-0
   Proverbio AM, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00376
   Roseman I. J., 2001, APPRAISAL PROCESSES, P3, DOI DOI 10.1080/02699939108411034
   Rouder JN, 2009, PSYCHON B REV, V16, P225, DOI 10.3758/PBR.16.2.225
   Scherer K.R., 1999, HDB COGNITION EMOTIO, P637, DOI DOI 10.1002/0470013494.CH30
   SCHERER KR, 1986, MOTIV EMOTION, V10, P295, DOI 10.1007/BF00992106
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   Schönbrodt FD, 2018, PSYCHON B REV, V25, P128, DOI 10.3758/s13423-017-1230-y
   Seibt B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01122
   Sharda M, 2018, TRANSL PSYCHIAT, V8, DOI 10.1038/s41398-018-0287-3
   SHAVER P, 1987, J PERS SOC PSYCHOL, V52, P1061, DOI 10.1037/0022-3514.52.6.1061
   Strait DL, 2014, CEREB CORTEX, V24, P2512, DOI 10.1093/cercor/bht103
   Strait DL, 2009, ANN NY ACAD SCI, V1169, P209, DOI 10.1111/j.1749-6632.2009.04864.x
   Swaminathan S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-27571-2
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Trimmer CG, 2008, EMOTION, V8, P838, DOI 10.1037/a0014080
   Vines BW, 2011, COGNITION, V118, P157, DOI 10.1016/j.cognition.2010.11.010
   Wu CH, 2011, IEEE T AFFECT COMPUT, V2, P10, DOI 10.1109/T-AFFC.2010.16
   Zatorre RJ, 2007, NAT REV NEUROSCI, V8, P547, DOI 10.1038/nrn2152
   Zellner A., 1980, Trab. Estad. E Investig. Oper., V31, P585, DOI [10.1007/BF02888369, DOI 10.1007/BF02888369]
NR 88
TC 6
Z9 7
U1 2
U2 17
PU UNIV CALIFORNIA PRESS
PI OAKLAND
PA 155 GRAND AVE, SUITE 400, OAKLAND, CA 94612-3758 USA
SN 0730-7829
J9 MUSIC PERCEPT
JI Music Percept.
PD APR
PY 2020
VL 37
IS 4
BP 323
EP 338
DI 10.1525/MP.2020.37.4.323
PG 16
WC Music; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music; Psychology
GA NT9RQ
UT WOS:000573279700004
OA Green Submitted
DA 2024-01-09
ER

PT J
AU Aubé, W
   Peretz, I
   Armony, JL
AF Aube, William
   Peretz, Isabelle
   Armony, Jorge L.
TI The effects of emotion on memory for music and vocalisations
SO MEMORY
LA English
DT Article
DE Music; Fear; Emotion; Memory; Vocal expressions
ID EXPRESSION; BRAIN; NEUROSCIENCE; PERCEPTION; RESPONSES; AMYGDALA; TIMBRE
AB Music is a powerful tool for communicating emotions which can elicit memories through associative mechanisms. However, it is currently unknown whether emotion can modulate memory for music without reference to a context or personal event. We conducted three experiments to investigate the effect of basic emotions (fear, happiness, and sadness) on recognition memory for music, using short, novel stimuli explicitly created for research purposes, and compared them with nonlinguistic vocalisations. Results showed better memory accuracy for musical clips expressing fear and, to some extent, happiness. In the case of nonlinguistic vocalisations we confirmed a memory advantage for all emotions tested. A correlation between memory accuracy for music and vocalisations was also found, particularly in the case of fearful expressions. These results confirm that emotional expressions, particularly fearful ones, conveyed by music can influence memory as has been previously shown for other forms of expressions, such as faces and vocalisations.
C1 [Aube, William; Peretz, Isabelle; Armony, Jorge L.] Int Lab Brain Mus & Sound Res BRAMS, Montreal, PQ, Canada.
   [Aube, William; Peretz, Isabelle] Univ Montreal, Dept Psychol, Montreal, PQ H3C 3J7, Canada.
   [Armony, Jorge L.] McGill Univ, Dept Psychiat, Montreal, PQ, Canada.
   [Armony, Jorge L.] McGill Univ, Douglas Mental Hlth Inst, Montreal, PQ, Canada.
C3 Universite de Montreal; Universite de Montreal; McGill University;
   McGill University
RP Armony, JL (corresponding author), Douglas Inst Res, 6875 LaSalle Blvd, Verdun, PQ H4H 1R3, Canada.
EM jorge.armony@mcgill.ca
FU Canadian Institutes of Health Research Funding Source: Medline
CR Armony JL, 2007, PSYCHOL SCI, V18, P1027, DOI 10.1111/j.1467-9280.2007.02019.x
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Bowling DL, 2010, J ACOUST SOC AM, V127, P491, DOI 10.1121/1.3268504
   Dehaene S, 2007, NEURON, V56, P384, DOI 10.1016/j.neuron.2007.10.004
   Dolcos F, 2002, COGN AFFECT BEHAV NE, V2, P252, DOI 10.3758/CABN.2.3.252
   Fecteau S, 2005, APPL NEUROPSYCHOL, V12, P40, DOI 10.1207/s15324826an1201_7
   Fecteau S, 2007, NEUROIMAGE, V36, P480, DOI 10.1016/j.neuroimage.2007.02.043
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Glasberg BR, 2002, J AUDIO ENG SOC, V50, P331
   Hailstone JC, 2009, Q J EXP PSYCHOL, V62, P2141, DOI 10.1080/17470210902765957
   Hevner K, 1935, AM J PSYCHOL, V47, P103, DOI 10.2307/1416710
   Janata P, 2007, MEMORY, V15, P845, DOI 10.1080/09658210701734593
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Koelsch S, 2010, TRENDS COGN SCI, V14, P131, DOI 10.1016/j.tics.2010.01.002
   LaBar KS, 2006, NAT REV NEUROSCI, V7, P54, DOI 10.1038/nrn1825
   Lartillot O., 2008, DATA ANAL MACHINE LE, P216
   LeDoux JE, 2000, ANNU REV NEUROSCI, V23, P155, DOI 10.1146/annurev.neuro.23.1.155
   Marozeau J, 2003, J ACOUST SOC AM, V114, P2946, DOI 10.1121/1.1618239
   Peelen M. V., 2010, J NEUROSCIENCE, V30
   Perani D, 2010, P NATL ACAD SCI USA, V107, P4758, DOI 10.1073/pnas.0909074107
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   Peretz I., 2013, HDB MUSIC EMOTION TH, P99, DOI [10.1093/acprof:oso/9780199230143.003.0005, DOI 10.1093/ACPROF:OSO/9780199230143.003.0005]
   Sah P, 2008, NATURE, V454, P589, DOI 10.1038/454589a
   Salimpoor VN, 2011, NAT NEUROSCI, V14, P257, DOI 10.1038/nn.2726
   Sergerie K, 2005, NEUROIMAGE, V24, P580, DOI 10.1016/j.neuroimage.2004.08.051
   Sergerie K, 2006, J COGNITIVE NEUROSCI, V18, P1359, DOI 10.1162/jocn.2006.18.8.1359
   Sharot T, 2004, NAT NEUROSCI, V7, P1376, DOI 10.1038/nn1353
   SNODGRASS JG, 1988, J EXP PSYCHOL GEN, V117, P34, DOI 10.1037/0096-3445.117.1.34
   Vieillard S., 2010, PSYCHOL RES, V76, P641
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
NR 31
TC 18
Z9 21
U1 0
U2 33
PU PSYCHOLOGY PRESS
PI HOVE
PA 27 CHURCH RD, HOVE BN3 2FA, EAST SUSSEX, ENGLAND
SN 0965-8211
EI 1464-0686
J9 MEMORY
JI Memory
PD NOV 1
PY 2013
VL 21
IS 8
BP 981
EP 990
DI 10.1080/09658211.2013.770871
PG 10
WC Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA 250QR
UT WOS:000326868500006
PM 23418992
DA 2024-01-09
ER

PT J
AU Yamauchi, T
   Xiao, KC
AF Yamauchi, Takashi
   Xiao, Kunchen
TI Reading Emotion From Mouse Cursor Motions: Affective Computing Approach
SO COGNITIVE SCIENCE
LA English
DT Article
DE Mouse cursor motion analysis; Affective computing; Choice reaching
   trajectory; Emotion and motor control
ID INDIVIDUAL-DIFFERENCES; CATEGORY LABELS; MOTOR-RESPONSES; MOVEMENT;
   ANXIETY; STATE; AMYGDALA; PERCEPTION; ATTENTION; INFERENCE
AB Affective computing research has advanced emotion recognition systems using facial expressions, voices, gaits, and physiological signals, yet these methods are often impractical. This study integrates mouse cursor motion analysis into affective computing and investigates the idea that movements of the computer cursor can provide information about emotion of the computer user. We extracted 16-26 trajectory features during a choice-reaching task and examined the link between emotion and cursor motions. Participants were induced for positive or negative emotions by music, film clips, or emotional pictures, and they indicated their emotions with questionnaires. Our 10-fold cross-validation analysis shows that statistical models formed from known participants (training data) could predict nearly 10%-20% of the variance of positive affect and attentiveness ratings of unknown participants, suggesting that cursor movement patterns such as the area under curve and direction change help infer emotions of computer users.
C1 [Yamauchi, Takashi; Xiao, Kunchen] Texas A&M Univ, Dept Psychol & Brain Sci, College Stn, TX 77843 USA.
C3 Texas A&M University System; Texas A&M University College Station
RP Yamauchi, T (corresponding author), Texas A&M Univ, Dept Psychol & Brain Sci, College Stn, TX 77843 USA.
EM takashi-yamauchi@tamu.edu
RI Yamauchi, Takashi/GXM-8197-2022
OI Yamauchi, Takashi/0000-0002-6372-1118
CR Abernethy B., 2007, Handbook of sport psychology, P245, DOI [10.1002/9781118270011.ch11, DOI 10.1002/9781118270011.CH11, DOI 10.1002/978111827]
   Accot J., 1997, P ACM SIGCHI C HUM F, P295, DOI DOI 10.1145/258549.258760
   Accot J., 1999, P SIGCHI C HUM FACT, P446
   Aldao A, 2010, CLIN PSYCHOL REV, V30, P217, DOI 10.1016/j.cpr.2009.11.004
   Anderson AK, 2001, NATURE, V411, P305, DOI 10.1038/35077083
   Anderson J. R., 1990, The adaptive character of thought, DOI [10.4324/9780203771730, DOI 10.4324/9780203771730]
   [Anonymous], 2013, Principles of neural science
   [Anonymous], 2015, Misc Functions of the Department of Statistics, Probability Theory Group
   [Anonymous], 2001, CHI 01 EXTENDED ABST, DOI DOI 10.1145/634067.634233
   Azcarraga J., 2012, PRICAI 2012 TRENDS A, V7458, P728, DOI [DOI 10.1007/978-3-642-32695-0_64, 10.1007/978-3-642-32695-0_64]
   Barrett L. F., 2013, HDB EMOTION REGULATI, P447
   Barrett LF, 2015, NAT REV NEUROSCI, V16, P419, DOI 10.1038/nrn3950
   Barrett LF, 2014, EMOT REV, V6, P292, DOI 10.1177/1754073914534479
   Barsalou LW, 1999, BEHAV BRAIN SCI, V22, P577, DOI 10.1017/S0140525X99532147
   Barsalou LW, 2003, PSYCHOL LEARN MOTIV, V43, P43, DOI 10.1016/S0079-7421(03)01011-9
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bishop S, 2004, NAT NEUROSCI, V7, P184, DOI 10.1038/nn1173
   Bishop S, 2013, CAMBRIDGE HDB HUMAN, P553, DOI DOI 10.1017/CBO9780511843716.031
   Bishop SJ, 2004, J NEUROSCI, V24, P10364, DOI 10.1523/JNEUROSCI.2550-04.2004
   Björklund A, 2007, TRENDS NEUROSCI, V30, P194, DOI 10.1016/j.tins.2007.03.006
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Bradley M. M., 2007, Handbook of Emotion Elicitation and Assessment, P29, DOI DOI 10.1037/0021-9010.69.1.85
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cahill L, 2006, NAT REV NEUROSCI, V7, P477, DOI 10.1038/nrn1909
   Calluso C, 2015, EXP BRAIN RES, V233, P3597, DOI 10.1007/s00221-015-4427-1
   Calvo R. A., 2015, OXFORD HDB AFFECTIVE, P1, DOI DOI 10.1093/OXFORDHB/9780199942237.013.040
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   CARD SK, 1978, ERGONOMICS, V21, P601, DOI 10.1080/00140137808931762
   Chapman CS, 2010, COGNITION, V116, P168, DOI 10.1016/j.cognition.2010.04.008
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477
   Coombes SA, 2005, J MOTOR BEHAV, V37, P425, DOI 10.3200/JMBR.37.6.425-436
   Coombes SA, 2007, PSYCHOL SCI, V18, P938, DOI 10.1111/j.1467-9280.2007.02005.x
   Coombes SA, 2007, EMOTION, V7, P275, DOI 10.1037/1528-3542.7.2.275
   Coombes SA, 2009, J ANXIETY DISORD, V23, P1072, DOI 10.1016/j.janxdis.2009.07.009
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   D'Mello S, 2012, COGNITION EMOTION, V26, P362, DOI 10.1080/02699931.2011.575767
   D'Mello SK, 2010, USER MODEL USER-ADAP, V20, P147, DOI 10.1007/s11257-010-9074-4
   Dale R, 2007, MEM COGNITION, V35, P15, DOI 10.3758/BF03195938
   De Martino B, 2009, CEREB CORTEX, V19, P127, DOI 10.1093/cercor/bhn062
   Dominguez-Borras J, 2013, CAMBRIDGE HDB HUMAN, P331, DOI [DOI 10.1017/CBO9780511843716.018, 10.1017/CBO9780511843716.018]
   Eich E., 2007, HDB EMOTION ELICITAT, P124, DOI DOI 10.1016/J.ENCEP.2006.08.003
   Ekman P, 2011, EMOT REV, V3, P364, DOI 10.1177/1754073911410740
   Elliot AJ, 2013, EMOT REV, V5, P308, DOI 10.1177/1754073913477517
   Epp C, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P715
   Etkin A, 2004, NEURON, V44, P1043, DOI 10.1016/j.neuron.2004.12.006
   Farmer TA, 2007, J MEM LANG, V57, P570, DOI 10.1016/j.jml.2007.04.003
   Flykt A, 2006, COGNITION EMOTION, V20, P1075, DOI 10.1080/02699930500381405
   Freeman JB, 2011, SOC NEUROSCI-UK, V6, P139, DOI 10.1080/17470919.2010.490674
   Freeman JB, 2010, BEHAV RES METHODS, V42, P226, DOI 10.3758/BRM.42.1.226
   Freeman JB, 2010, J EXP SOC PSYCHOL, V46, P179, DOI 10.1016/j.jesp.2009.10.002
   Freeman JB, 2009, PSYCHOL SCI, V20, P1183, DOI 10.1111/j.1467-9280.2009.02422.x
   Gallivan JP, 2016, J NEUROPHYSIOL, V115, P3113, DOI 10.1152/jn.00951.2015
   Gasper K, 2002, PSYCHOL SCI, V13, P34, DOI 10.1111/1467-9280.00406
   Glover S, 2004, BEHAV BRAIN SCI, V27, P3
   Glowinski D, 2011, LECT NOTES COMPUT SC, V6974, P527, DOI 10.1007/978-3-642-24600-5_56
   Grimes M., 2013, EXPLORING EFFECT ARO
   Gross JJ, 2003, J PERS SOC PSYCHOL, V85, P348, DOI 10.1037/0022-3514.85.2.348
   GROSS JJ, 1995, COGNITION EMOTION, V9, P87, DOI 10.1080/02699939508408966
   Guo Q, 2008, P 31 ANN INT ACM SIG, P707, DOI [10.1145/1390334.1390462, DOI 10.1145/1390334.1390462]
   Hahn U., 2001, SIMILARITY CATEGORIZ
   Hanin Y. L., 2007, Handbook of sport psychology, V3th, P31
   Hariri A. R., 2013, CAMBRIDGE HDB HUMAN, P575
   Harris CM, 1998, NATURE, V394, P780, DOI 10.1038/29528
   Hehman E, 2015, GROUP PROCESS INTERG, V18, P384, DOI 10.1177/1368430214538325
   Hibbeln M, 2017, MIS QUART, V41, P1
   Hodges N. J., 2007, HDB SPORT PSYCHOL, P159
   ISEN AM, 1984, J PERS SOC PSYCHOL, V47, P1206, DOI 10.1037/0022-3514.47.6.1206
   ISEN AM, 1987, J PERS SOC PSYCHOL, V52, P1122, DOI 10.1037/0022-3514.52.6.1122
   Kaklauskas A, 2011, ENG APPL ARTIF INTEL, V24, P928, DOI 10.1016/j.engappai.2011.04.006
   Kaklauskas A, 2009, ICALT: 2009 IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, P189, DOI 10.1109/ICALT.2009.130
   Kapoor A, 2007, INT J HUM-COMPUT ST, V65, P724, DOI 10.1016/j.ijhcs.2007.02.003
   KIMCHI R, 1982, J EXP PSYCHOL HUMAN, V8, P521, DOI 10.1037/0096-1523.8.4.521
   Kording KP, 2006, TRENDS COGN SCI, V10, P319, DOI 10.1016/j.tics.2006.05.003
   Körding KP, 2004, NATURE, V427, P244, DOI 10.1038/nature02169
   Kuhn M, 2013, APPL PREDICTIVE MODE
   Lang P. J., 2005, Technical Report A-8, DOI 10.1016/j.epsr.2006.03.016
   Lang PJ, 2010, BIOL PSYCHOL, V84, P437, DOI 10.1016/j.biopsycho.2009.10.007
   LeDoux J., 2015, Anxious: The Modern Mind in the Age of Anxiety
   Lindquist KA, 2013, EMOT REV, V5, P356, DOI 10.1177/1754073913489750
   Maehr W, 2008, EMotion: Estimation of User's Emotional State by Mouse Motions
   Marr D., 1981, VISION
   Mattek AM, 2016, EMOTION, V16, P929, DOI 10.1037/emo0000148
   Mendoza J. E., 2008, CLIN NEUROANATOMY NE
   Mink J. W., 2008, FUNDAMENTAL NEUROSCI, P725
   Moors A, 2013, EMOT REV, V5, P119, DOI 10.1177/1754073912468165
   Mukherjee K, 2010, PSYCHOL REV, V117, P243, DOI 10.1037/a0017884
   NEWELL A, 1980, COGNITIVE SCI, V4, P135, DOI 10.1016/S0364-0213(80)80015-2
   Orbán G, 2011, CURR OPIN NEUROBIOL, V21, P629, DOI 10.1016/j.conb.2011.05.026
   Panksepp J, 2011, EMOT REV, V3, P387, DOI 10.1177/1754073911410741
   Paulus MP, 2012, TRENDS COGN SCI, V16, P476, DOI 10.1016/j.tics.2012.07.009
   Rabey Jose Martin, 2007, Handb Clin Neurol, V83, P435, DOI 10.1016/S0072-9752(07)83020-X
   Russell JA, 2003, PSYCHOL REV, V110, P145, DOI 10.1037/0033-295X.110.1.145
   Salmeron-Majadas S, 2014, PROCEDIA COMPUT SCI, V35, P691, DOI 10.1016/j.procs.2014.08.151
   Scheirer J, 2002, INTERACT COMPUT, V14, P93, DOI 10.1016/S0953-5438(01)00059-5
   Schmitz TW, 2009, J NEUROSCI, V29, P7199, DOI 10.1523/JNEUROSCI.5387-08.2009
   Schneider IK, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00996
   Schwabe L, 2011, NEUROPSYCHOLOGIA, V49, P416, DOI 10.1016/j.neuropsychologia.2010.12.037
   Scott MacKenzie I., 2001, P SIGCHI C HUM FACT, P9, DOI [DOI 10.1145/365024.365028, 10.1145/365024.365028, 10.1145/365024. 365028]
   SHEPARD RN, 1987, SCIENCE, V237, P1317, DOI 10.1126/science.3629243
   SIMON HA, 1990, ANNU REV PSYCHOL, V41, P1, DOI 10.1146/annurev.ps.41.020190.000245
   Song JH, 2008, COGNITION, V106, P994, DOI 10.1016/j.cognition.2007.03.014
   Song JH, 2009, TRENDS COGN SCI, V13, P360, DOI 10.1016/j.tics.2009.04.009
   Spielberger CG., 1983, MANUAL STATE TRAIT A, DOI DOI 10.1002/9780470479216.CORPSY0943
   Spivey M., 2007, The continuity of mind
   Spivey MJ, 2004, PSYCHOL LEARN MOTIV, V45, P87, DOI 10.1016/S0079-7421(03)45003-2
   Spivey MJ, 2005, P NATL ACAD SCI USA, V102, P10393, DOI 10.1073/pnas.0503903102
   Sun D, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P61, DOI 10.1145/2556288.2557243
   THELEN E, 1995, AM PSYCHOL, V50, P79, DOI 10.1037/0003-066X.50.2.79
   Thrasher M, 2011, LECT NOTES COMPUT SC, V6974, P377, DOI 10.1007/978-3-642-24600-5_41
   Watson D., 1999, The PANAS-X: Manual for the positive and negative affect schedule-expanded form, DOI [10.17077/48vt-m4t2, DOI 10.17077/48VT-M4T2]
   Weintraub Daniel, 2007, Handb Clin Neurol, V83, P421, DOI 10.1016/S0072-9752(07)83019-3
   Wojnowicz MT, 2009, PSYCHOL SCI, V20, P1428, DOI 10.1111/j.1467-9280.2009.02448.x
   Wolpert DM, 2000, NAT NEUROSCI, V3, P1212, DOI 10.1038/81497
   Wolpert DM, 2012, CURR OPIN NEUROBIOL, V22, P996, DOI 10.1016/j.conb.2012.05.003
   WOLPERT DM, 1995, SCIENCE, V269, P1880, DOI 10.1126/science.7569931
   Xiao KC, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0178740
   Xiao KC, 2015, CONSCIOUS COGN, V38, P88, DOI 10.1016/j.concog.2015.09.013
   Xiao K, 2014, CONSCIOUS COGN, V27, P42, DOI 10.1016/j.concog.2014.04.004
   Yamauchi T, 2000, J EXP PSYCHOL LEARN, V26, P776, DOI 10.1037/0278-7393.26.3.776
   Yamauchi T., 2015, P 37 ANN C COGN SCI, P2721
   Yamauchi T., 2017, INSIGHTS PSYCHOL, V1, P1
   Yamauchi T, 2007, MEM COGNITION, V35, P852, DOI 10.3758/BF03193460
   Yamauchi T, 2015, INT CONF AFFECT, P56, DOI 10.1109/ACII.2015.7344551
   Yamauchi T, 2015, INT J HUM-COMPUT INT, V31, P911, DOI 10.1080/10447318.2015.1072787
   Yamauchi T, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P221, DOI 10.1109/ICDMW.2014.131
   Yamauchi T, 2013, INT CONF AFFECT, P399, DOI 10.1109/ACII.2013.72
   Yamauchi T, 2009, J EXP THEOR ARTIF IN, V21, P155, DOI [10.1080/09528130X02113299, 10.1080/09528130802113299]
   Yu NY, 2008, J COGN SCI, V9, P89
   Yu NY, 2010, COGNITIVE SCI, V34, P1574, DOI 10.1111/j.1551-6709.2010.01122.x
   Zimmermann P., 2008, THESIS
   Zimmermann Philippe, 2003, Int J Occup Saf Ergon, V9, P539
NR 132
TC 30
Z9 32
U1 5
U2 21
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0364-0213
EI 1551-6709
J9 COGNITIVE SCI
JI Cogn. Sci.
PD APR
PY 2018
VL 42
IS 3
BP 771
EP 819
DI 10.1111/cogs.12557
PG 49
WC Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA GF5BQ
UT WOS:000431980400002
PM 29131372
OA Bronze
DA 2024-01-09
ER

PT J
AU Bach, R
AF Bach, Rebecca
TI <i>Beware the Cat</i> within a short history of human and nonhuman
   animal voice
SO TEXTUAL PRACTICE
LA English
DT Article
DE Voice; creatures; Cartesian; William Baldwin; William Shakespeare;
   Margaret Cavendish
AB In this essay, I contend that Beware the Cat belongs to an earlier world in which almost all mortal creatures were thought of as having voices. Musicians, naturalists, hunters, and literary authors agreed that birds and other creatures had voices and expressed emotions. In the course of history, as knowledge became specialised and Descartes's mistaken ideas about nonhuman animals gained acceptance, people began to be thought of as the only creatures who had voices. In addition, a large body of voice-related words, including chattering, howling, and bawling, which used to apply to human and nonhuman creatures have become confined to one domain or another. I trace the histories of some of these words and show how the Oxford English Dictionary often displays the logic system of a post-Cartesian world. In the essay, I place Baldwin's text within a literary tradition of thinking about nonhuman animal voice that includes Shakespeare and Margaret Cavendish.
C1 [Bach, Rebecca] Univ Alabama Birmingham, Dept English, Birmingham, AL 35294 USA.
C3 University of Alabama System; University of Alabama Birmingham
RP Bach, R (corresponding author), Univ Alabama Birmingham, Dept English, Birmingham, AL 35294 USA.
EM rbach@uab.edu
CR alliedmarketresearch, about us
   [Anonymous], 1645, DESCARTES ELISABETH
   [Anonymous], 2013, ACCOMODATED ANIMAL C
   [Anonymous], 2019, MAMAS LAST HUG ANIMA
   Austern Linda Phyllis, 2001, MUSIC THEORY NATURAL, P30
   Austern LP, 1998, J AM MUSIC SOC, V51, P1, DOI 10.1525/jams.1998.51.1.03a00010
   Bach Rebecca Ann, 2018, BIRDS OTHER CREATURE, P3
   Baldwin William, 1988, BEWARE CAT
   Bekoff Marc, 2007, The Emotional Lives of Animals: A Leading Scientist Explores Animal Joy, Sorrow, and Empathy-and Why They Matter
   Benjamin Walter, 1969, Illuminations, P253
   Bloom G, 2007, MATER TEXTS, P1
   Boehrer Bruce Thomas, 2000, ANIMAL CHARACTERS NO, P8
   Borlik TA, 2011, ROUT STUD RENAIS LIT, P1
   Bowerbank Sylvia, 2004, Speaking for Nature: Women and Ecologies of Early Modern England
   Brown LF, 2003, SIXTEENTH CENT J, V34, P953
   Bruckner LD, 2011, LIT CULT ENVIRON, P15
   Cavendish Margaret, 1668, POEMS SEVERAL FANCIE
   Cavendish Margaret, 2018, Poems and Fancies with The Animal Parliament
   Cavendish Margaret, 1668, OBSERVATIONS EXPT PH
   De Waal F., 2016, ARE WE SMART ENOUGH, DOI DOI 10.1126/SCIENCE.AAX3100
   Douland John, 1609, ANDREAS ORNITHOPARCH, P6
   Fudge Erica, 2006, BRUTAL REASONING ANI, P75
   Greenblatt Stephen, 2016, The Norton Shakespeare, V3rd
   Harrison Thomas P., 1972, FOWLES HEAVEN HIST B, pXix
   iep, INTERNET ENCY PHILOS
   Ihde Don, 1976, LISTENING VOICE PHEN, P4
   kfgo, US
   Latour B, 2018, CRIT INQUIRY, V44, P213, DOI 10.1086/695376
   Maplet John, 1567, GREENE FOREST NATURA, P96
   Markham Gervase, 1621, HUNGERS PREUENTION W, P203
   Mendelson S, 2014, GOD AND NATURE IN THE THOUGHT OF MARGARET CAVENDISH, P27
   PBS, ABOUT US
   plato, STANFORD ENCY PHILOS
   project, About us
   Raber K, 2008, EARLY MOD CULT STUD, P93
   Shakespeare, 2001, SHAKESPEARES NOISE, P1
   Shannon Laurie, 2013, ACCOMODATED ANIMAL C, P78
   Shapiro Lisa, 2007, CORRES PRINCESS ELIS, P92
   Stengers Isabelle, 2015, CATASTROPHIC TIMES R, P91
   Stengers Isabelle, 2015, CATASTROPHIC TIMES R, P41
   Stenner Rachel, 2017, FALLEN ANIMALS ART R, P89
   Suzuki M, 2015, SEVENTEENTH CENT, V30, P229, DOI 10.1080/0268117X.2015.1046702
   Thomas Keith, 1983, MAN NATURAL WORLD HI, P128
   Topsell Edward, 1972, FOWLES HEAUEN HIST B, P22
   Topsell Edward, 1972, FOWLES HEAUEN HIST B, P52
   Topsell Edward, 1607, HIST 4 FOOTED BEASTS, P21
   van Orden Kate, 2002, MUSIC SENSATION SENS, P17
NR 47
TC 0
Z9 0
U1 0
U2 0
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 0950-236X
EI 1470-1308
J9 TEXTUAL PRACT
JI Textual Pract.
PD JUL 3
PY 2023
VL 37
IS 7
SI SI
BP 1047
EP 1062
DI 10.1080/0950236X.2023.2223432
EA JUL 2023
PG 16
WC Literature
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Literature
GA N0GJ3
UT WOS:001021912200001
DA 2024-01-09
ER

PT J
AU Huang, IS
   Lu, YH
   Shafiq, M
   Laghari, AA
   Yadav, R
AF Huang, I-Sheng
   Lu, Yu-Hsuan
   Shafiq, Muhammad
   Laghari, Asif Ali
   Yadav, Rahul
TI A Generative Adversarial Network Model Based on Intelligent Data
   Analytics for Music Emotion Recognition under IoT
SO MOBILE INFORMATION SYSTEMS
LA English
DT Article
ID ALGORITHM
AB The popularity of the Internet has brought the rapid development of artificial intelligence, affective computing, Internet of things (IoT), and other technologies. Particularly, the development of IoT provides more references for the realization of smart home. However, when people have achieved a certain amount of material satisfaction, they are more likely to want to communicate emotionally. Music contains a lot of emotion information. Music data is an important communication way between people and a better way to convey emotions. Therefore, it has become one of the most convenient and natural interactive ways expected by people in intelligent hwnan-computer interaction. Traditional music emotion recognition methods have some demerits such as low recognition rate and time-consuming. So, we propose a generative adversarial network (GAN) model based on intelligent data analytics for music emotion recognition under loT. Driven by the double-channel fusion strategy, the GAN can effectively extract the local and global features of the image or voice. Meanwhile, in order to increase the feature difference between the emotional voices, the feature data matrix of the Meyer frequency cepstrum coefficient of the music signals is transformed to improve the expression ability of the GAN. The experiment results show that the proposed model can effectively recognize the music emotion. Compared with other state-of-the-art approaches, the error recognition rate of proposed music music data recognition is greatly reduced. In terms of the accuracy, it exceeds 87% which is higher than that of other methods.
C1 [Huang, I-Sheng] Huaiyin Normal Univ, Coll Mus, Huaian 223300, Jiangsu, Peoples R China.
   [Lu, Yu-Hsuan] Univ North Texas, Coll Mus, Denton, TX 76201 USA.
   [Shafiq, Muhammad] Guangzhou Univ, Cyberspace Inst Adv Technol, Guangzhou, Peoples R China.
   [Laghari, Asif Ali] Sindh Madressatul Islam Univ, Dept Comp Sci, Karachi, Pakistan.
   [Yadav, Rahul] Peng Cheng Lab, Shenzhen, Peoples R China.
C3 Huaiyin Normal University; University of North Texas System; University
   of North Texas Denton; Guangzhou University; Peng Cheng Laboratory
RP Shafiq, M (corresponding author), Guangzhou Univ, Cyberspace Inst Adv Technol, Guangzhou, Peoples R China.
EM srsshafiq@gmail.com
RI Nasarian, Elham/ISB-6863-2023; Laghari, Asif Ali/AAF-5893-2020; Yadav,
   Rahul/S-3599-2018
OI Laghari, Asif Ali/0000-0001-5831-5943; Yadav, Rahul/0000-0001-7514-4517;
   Shafiq, Muhammad/0000-0003-1909-9373
CR Arjovsky M, 2017, PR MACH LEARN RES, V70
   Chaudhary D, 2019, INT J SPEECH TECHNOL, V22, P551, DOI 10.1007/s10772-019-09629-2
   Chen CF, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/4606027
   Chen PL, 2016, PROCEEDINGS OF 2016 12TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P323, DOI [10.1109/CIS.2016.0079, 10.1109/CIS.2016.78]
   Deng Y., 2017, Comput. Eng. Des, V38, P1029, DOI [10.16208/j.issn1000-7024.2017.04.034, DOI 10.16208/J.ISSN1000-7024.2017.04.034]
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Grekow J, 2020, LECT NOTES COMPUT SC, V12117, P150, DOI 10.1007/978-3-030-59491-6_14
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hizlisoy S, 2021, ENG SCI TECHNOL, V24, P760, DOI 10.1016/j.jestch.2020.10.009
   Huang YM, 2019, IEEE ACCESS, V7, P142009, DOI 10.1109/ACCESS.2019.2944386
   Karras T., 2017, PROGR GROWING GANS I
   Lin JC, 2012, IEEE T MULTIMEDIA, V14, P142, DOI 10.1109/TMM.2011.2171334
   Maheshwari D, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104428
   Miyato T., 2018, P ICLR, DOI DOI 10.48550/ARXIV.1802.05957
   Nantasri P., P 2020 17 INT C EL E, P41, DOI [10.1109/ECTI-CON49241.2020.9158221, DOI 10.1109/ECTI-CON49241.2020.9158221]
   Pan FD, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217040
   Radford A., 2016, C TRACK P, DOI DOI 10.48550/ARXIV.1511.06434
   Rajapakshe T., NOVEL POLICY PRETRAI
   Savery R, 2019, IEEE ROMAN, DOI 10.1109/ro-man46459.2019.8956386
   Shafiq M, 2021, IEEE INTERNET THINGS, V8, P3242, DOI 10.1109/JIOT.2020.3002255
   Shafiq M, 2020, COMPUT SECUR, V94, DOI 10.1016/j.cose.2020.101863
   Shafiq M, 2020, FUTURE GENER COMP SY, V107, P433, DOI 10.1016/j.future.2020.02.017
   Shafiq SM, 2020, SUSTAIN CITIES SOC, V60, DOI 10.1016/j.scs.2020.102177
   Sun Y, 2019, IEEE ACCESS, V7, P99254, DOI 10.1109/ACCESS.2019.2926816
   Vander Wal JS, 2020, J EAT DISORD, V8, DOI 10.1186/s40337-020-00304-5
   Wang JC, 2015, IEEE T AFFECT COMPUT, V6, P56, DOI 10.1109/TAFFC.2015.2397457
   [武随烁 Wu Suishuo], 2020, [计算机科学与探索, Journal of Frontiers of Computer Science & Technology], V14, P833
   Xu R., 2013, J COMPUTATIONAL INFO, V9, P2209
   Yang XY, 2018, MULTIMEDIA SYST, V24, P365, DOI 10.1007/s00530-017-0559-4
   Yang YH, 2008, IEEE T AUDIO SPEECH, V16, P448, DOI 10.1109/TASL.2007.911513
   Yin SL, 2020, SENS IMAGING, V21, DOI 10.1007/s11220-020-00314-2
   Yin SL, 2019, INT J DISTRIB SENS N, V15, DOI 10.1177/1550147719852036
   Yu J, 2020, J APPL SCI ENG, V23, P31, DOI 10.6180/jase.202003_23(1).0004
   Zhao J, 2016, 2016 IEEE MTT-S INTERNATIONAL WIRELESS SYMPOSIUM (IWS), DOI 10.1109/ICSSSM.2016.7538614
NR 34
TC 8
Z9 8
U1 1
U2 8
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1574-017X
EI 1875-905X
J9 MOB INF SYST
JI Mob. Inf. Syst.
PD NOV 2
PY 2021
VL 2021
AR 3561829
DI 10.1155/2021/3561829
PG 8
WC Computer Science, Information Systems; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 0Y7US
UT WOS:000790592500002
OA gold
DA 2024-01-09
ER

PT J
AU Kragness, HE
   Eitel, MJ
   Baksh, AM
   Trainor, LJ
AF Kragness, Haley E.
   Eitel, Matthew J.
   Baksh, Ammaarah M.
   Trainor, Laurel J.
TI Evidence for early arousal-based differentiation of emotions in
   children's musical production
SO DEVELOPMENTAL SCIENCE
LA English
DT Article
DE articulation; emotion; loudness; music; production; tempo
ID INFANTS DISCRIMINATION; FACIAL EXPRESSIONS; VOCAL EXPRESSION;
   RECOGNITION; PERFORMANCE; TEMPO; COMMUNICATION; PERCEPTION; HAPPY; SAD
AB Accurate perception and production of emotional states is important for successful social interactions across the lifespan. Previous research has shown that when identifying emotion in faces, preschool children are more likely to confuse emotions that share valence, but differ in arousal (e.g. sadness and anger) than emotions that share arousal, but differ on valence (e.g. anger and joy). Here, we examined the influence of valence and arousal on children's production of emotion in music. Three-, 5- and 7-year-old children recruited from the greater Hamilton area (N = 74) 'performed' music to produce emotions using a self-pacing paradigm, in which participants controlled the onset and offset of each chord in a musical sequence by repeatedly pressing and lifting the same key on a MIDI piano. Key press velocity controlled the loudness of each chord. Results showed that (a) differentiation of emotions by 5-year-old children was mainly driven by arousal of the target emotion, with differentiation based on both valence and arousal at 7 years and (b) tempo and loudness were used to differentiate emotions earlier in development than articulation. The results indicate that the developmental trajectory of emotion understanding in music may differ from the developmental trajectory in other domains.
C1 [Kragness, Haley E.; Eitel, Matthew J.; Baksh, Ammaarah M.; Trainor, Laurel J.] McMaster Univ, Dept Psychol, Hamilton, ON, Canada.
   [Trainor, Laurel J.] McMaster Univ, McMaster Inst Mus & Mind, Hamilton, ON, Canada.
   [Trainor, Laurel J.] Baycrest Hosp, Rotman Res Inst, Toronto, ON, Canada.
C3 McMaster University; McMaster University; University of Toronto;
   Baycrest
RP Trainor, LJ (corresponding author), McMaster Univ, Psychol Bldg,1280 Main St West, Hamilton, ON L8S 4K1, Canada.
EM ljt@mcmaster.ca
RI Eitel, Matthew/JOK-2437-2023; Eitel, Matthew/IAQ-1306-2023
OI Trainor, Laurel/0000-0003-3397-2079; Kragness, Haley/0000-0003-3137-7655
FU Canadian Institute for Advanced Research; Canadian Institutes of Health
   Research [MOP 42554]; Natural Sciences and Engineering Research Council
   of Canada [RGPIN-2014-0470]
FX Canadian Institute for Advanced Research; Canadian Institutes of Health
   Research, Grant/Award Number: CIHR Operating Grant MOP 42554; Natural
   Sciences and Engineering Research Council of Canada, Grant/Award Number:
   NSERC Discovery Grant RGPIN-2014-0470
CR Adachi M, 2004, JPN PSYCHOL RES, V46, P322, DOI 10.1111/j.1468-5584.2004.00264.x
   Adachi M, 2000, MUSIC PERCEPT, V18, P213
   Adachi M., 1998, PSYCHOL MUSIC, V26, P133, DOI [DOI 10.1177/0305735698262003, 10.1177/0305735698262003]
   [Anonymous], PYSCHOL MUSIC, DOI DOI 10.1177/0305735603031001325
   [Anonymous], PSYCHOL MUSIC, DOI [10.1177/0305735600282007, DOI 10.1177/0305735600282007]
   Balkwill LL, 2004, JPN PSYCHOL RES, V46, P337, DOI 10.1111/j.1468-5584.2004.00265.x
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Behrens Gene Ann, 1993, Psychology of Music, V21, P20, DOI DOI 10.1177/030573569302100102
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   BULLOCK M, 1984, INT J BEHAV DEV, V7, P193, DOI 10.1177/016502548400700207
   Castro SL, 2014, MUSIC PERCEPT, V32, P125, DOI 10.1525/MP.2014.32.2.125
   Cirelli LK, 2020, J COGNITIVE NEUROSCI, V32, P1213, DOI 10.1162/jocn_a_01402
   Corbeil M, 2016, INFANCY, V21, P373, DOI 10.1111/infa.12114
   CUNNINGHAM JG, 1988, MOTIV EMOTION, V12, P399, DOI 10.1007/BF00992362
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Dunn LM., 2007, PPVT 4 PEABODY PICTU, V4
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   Flom R, 2012, INFANT BEHAV DEV, V35, P697, DOI 10.1016/j.infbeh.2012.07.022
   Flom R, 2008, INFANT BEHAV DEV, V31, P716, DOI 10.1016/j.infbeh.2008.04.004
   Franco F, 2017, PSYCHOL MUSIC, V45, P131, DOI 10.1177/0305735616652954
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Gagnon L, 2003, COGNITION EMOTION, V17, P25, DOI 10.1080/02699930302279
   Gentile D. A., 1998, DISSERTATION ABSTR B, V59, P2454
   GIOMO CJ, 1993, PSYCHOL MUSIC, V21, P141, DOI DOI 10.1177/030573569302100204
   Hedden D., 2012, UPDATE APPL RES MUSI, V30, P52, DOI DOI 10.1177/8755123312438516
   Hevner K, 1935, AM J PSYCHOL, V47, P103, DOI 10.2307/1416710
   Hevner K, 1937, AM J PSYCHOL, V49, P621, DOI 10.2307/1416385
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Juslin P. N., 1996, PSYCHOL MUSIC, V24, P68, DOI [10.1177/0305735696241007, DOI 10.1177/0305735696241007]
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Juslin PN, 1997, MUSIC PERCEPT, V14, P383
   Kragness HE., 2019, Music Sci, V2, p205920431983494, DOI [10.1177/2059204319834943, DOI 10.1177/2059204319834943]
   Laukka P, 2013, EMOTION, V13, P434, DOI 10.1037/a0031388
   Lindström E, 2006, MUSIC SCI, V10, P85, DOI 10.1177/102986490601000105
   Lindstrom E, 2003, RES STUDIES MUSIC ED, V20, P23, DOI DOI 10.1177/1321103X030200010201
   Mohn C, 2011, PSYCHOL MUSIC, V39, P503, DOI 10.1177/0305735610378183
   Morton JB, 2001, CHILD DEV, V72, P834, DOI 10.1111/1467-8624.00318
   Mote J, 2011, EMOTION, V11, P618, DOI 10.1037/a0022573
   Nawrot ES., 2003, Psychol. Music, V31, P75, DOI DOI 10.1177/0305735603031001325
   Nygaard LC, 2008, J EXP PSYCHOL HUMAN, V34, P1017, DOI 10.1037/0096-1523.34.4.1017
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   Pons F., 2000, Test of Emotion Comprehension-TEC
   Provasi JL, 2003, INT J BEHAV DEV, V27, P220, DOI 10.1080/01650250244000290
   RIBORDY SC, 1988, J CLIN CHILD PSYCHOL, V17, P322, DOI 10.1207/s15374424jccp1704_4
   Rock AML, 1999, DEV PSYCHOL, V35, P527, DOI 10.1037/0012-1649.35.2.527
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Schellenberg E. G., 2007, Psychology of Music, V35, P5, DOI [DOI 10.1177/0305735607068885, 10.1177/0305735607068885]
   Scherer K., 1977, MOTIV EMOTION, V1, P331, DOI [DOI 10.1007/BF00992539, 10.1007/bf00992539]
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   Schubert E, 1999, AUST J PSYCHOL, V51, P154, DOI 10.1080/00049539908255353
   Shenfield T., 2003, Psychol. Music, V31, P365, DOI DOI 10.1177/03057356030314002
   Sievers B, 2013, P NATL ACAD SCI USA, V110, P70, DOI 10.1073/pnas.1209023110
   Song YD, 2016, MUSIC PERCEPT, V33, P472, DOI 10.1525/MP.2016.33.4.472
   SORCE JF, 1985, DEV PSYCHOL, V21, P195, DOI 10.1037/0012-1649.21.1.195
   Terwogt M. M., 1991, PSYCHOL MUSIC, V19, P99, DOI DOI 10.1177/0305735691192001
   Thompson WF, 2006, SEMIOTICA, V158, P407, DOI 10.1515/SEM.2006.017
   Tottenham N, 2009, PSYCHIAT RES, V168, P242, DOI 10.1016/j.psychres.2008.05.006
   Trainor LJ, 2015, PHILOS T R SOC B, V370, P25, DOI 10.1098/rstb.2014.0089
   Trehub S. E., 1998, Advances in Infancy Research, V12, P43
   Tsang CD, 2010, INFANT BEHAV DEV, V33, P96, DOI 10.1016/j.infbeh.2009.11.006
   Vidas D., 2018, MUSIC SCI, V1, p205920431876265, DOI [10.1177/2059204318762650, DOI 10.1177/2059204318762650]
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   Widen S. C., 2008, HDB EMOTIONS, P348
   Widen SC, 2004, COGNITIVE DEV, V19, P111, DOI 10.1016/j.cogdev.2003.11.004
   Widen SC, 2003, DEV PSYCHOL, V39, P114, DOI 10.1037//0012-1649.39.1.114
   Widen SC, 2002, MERRILL PALMER QUART, V48, P248, DOI 10.1353/mpq.2002.0013
   Widen SC, 2010, BRIT J DEV PSYCHOL, V28, P565, DOI 10.1348/026151009X457550d
NR 70
TC 1
Z9 1
U1 0
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1363-755X
EI 1467-7687
J9 DEVELOPMENTAL SCI
JI Dev. Sci.
PD JAN
PY 2021
VL 24
IS 1
AR e12982
DI 10.1111/desc.12982
EA MAY 2020
PG 11
WC Psychology, Developmental; Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA PI9LT
UT WOS:000534965200001
PM 32358988
DA 2024-01-09
ER

PT J
AU Tallet, C
   Spinka, M
   Maruscáková, I
   Simecek, P
AF Tallet, Celine
   Spinka, Marek
   Maruscakova, Iva
   Simecek, Petr
TI Human Perception of Vocalizations of Domestic Piglets and Modulation by
   Experience With Domestic Pigs (<i>Sus scrofa</i>)
SO JOURNAL OF COMPARATIVE PSYCHOLOGY
LA English
DT Article
DE pig; interspecific communication; vocal signals; emotions; learning
ID VOCAL COMMUNICATION; ACOUSTIC PARAMETERS; RELIABLE INDICATOR; MUSIC
   PERFORMANCE; EMOTION; EXPRESSION; INFORMATION; RECOGNITION; RESPONSES;
   CALLS
AB Interspecific communication between humans and pets is possible through vocal cues. We studied how humans with differing experience with domestic pigs (Sus scrofa) interpret pig vocalizations. Forty-eight ethologists studying pigs, 31 pig-caretakers and 54 naive students evaluated the emotional intensity and valence (negative/positive) of recordings from two negative (castration, isolation) and two positive (reunion with the sow, postsuckling) contexts. They also identified the context in which the recordings were made. Castration vocalizations were evaluated as highly intense and unpleasant. The positive contexts were evaluated as low in intensity and positive in valence, and isolation fell in the middle for both intensity and valence. Compared with the other two groups, pig-caretakers evaluated the intensity of vocalizations as lower, and ethologists evaluated the valence as more negative. The level of successful classification exceeded that expected by chance for all four contexts but was especially accurate for castration. Ethologists achieved better recognition than students. Classifying (fight context) and understanding the emotional content (valence, intensity) of pig vocalizations is thus a general ability of humans, although it varies according to an individual's experience with pigs.
C1 [Tallet, Celine; Spinka, Marek] Inst Anim Sci, Dept Ethol, Prague, Czech Republic.
   [Maruscakova, Iva] Charles Univ Prague, Fac Nat Sci, Dept Zool, CR-11636 Prague 1, Czech Republic.
   [Simecek, Petr] Inst Anim Sci, Biometr Unit, Prague, Czech Republic.
C3 Czech Research Institute of Animal Science; Charles University Prague;
   Czech Research Institute of Animal Science
RP Tallet, C (corresponding author), INRA, SENAH UMR1079, F-35590 St Gilles, France.
EM celine.tallet@rennes.inra.fr
RI Simecek, Petr/G-6366-2014; Simecek, Petr/R-3449-2019; Simecek,
   Petr/ABG-4683-2021; Spinka, Marek/E-2395-2011; Simecek, Petr/G-2585-2013
OI Simecek, Petr/0000-0002-2922-7183; Simecek, Petr/0000-0002-2922-7183;
   Spinka, Marek/0000-0002-2506-9552; tallet, celine/0000-0002-1899-9233
CR Agresti A., 2003, CATEGORICAL DATA ANA, P267, DOI [10.1002/0471249688.ch7, DOI 10.1002/0471249688.CH7]
   Anderson AK, 2003, NAT NEUROSCI, V6, P196, DOI 10.1038/nn1001
   AOYAMA M, 2005, P 35 C INT SOC APPL, P143
   AUBIN T, 1991, BEHAV PROCESS, V23, P103, DOI 10.1016/0376-6357(91)90061-4
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Belin P, 2008, P ROY SOC B-BIOL SCI, V275, P473, DOI 10.1098/rspb.2007.1460
   BEST CT, 1994, J EXP PSYCHOL HUMAN, V20, P751, DOI 10.1037/0096-1523.20.4.751
   Blumstein DT, 2005, ANIM BEHAV, V69, P353, DOI 10.1016/j.anbehav.2004.10.001
   Bradbury Jack W., 1998, pi
   BRADY CA, 1981, ANIM BEHAV, V29, P649, DOI 10.1016/S0003-3472(81)80001-2
   Budde C, 2003, MAMM BIOL, V68, P42, DOI 10.1078/1616-5047-00060
   Calder AJ, 2000, J EXP PSYCHOL HUMAN, V26, P527, DOI 10.1037/0096-1523.26.2.527
   Canli T, 1998, NEUROREPORT, V9, P3233, DOI 10.1097/00001756-199810050-00019
   Charlton BD, 2007, ANIM BEHAV, V74, P707, DOI 10.1016/j.anbehav.2006.09.021
   Cheng MF, 2004, ANN NY ACAD SCI, V1016, P611, DOI 10.1196/annals.1298.019
   Darwin C., 1872, P374
   Dayan P, 2000, NAT NEUROSCI, V3, P1218, DOI 10.1038/81504
   Dziobek I, 2008, J AUTISM DEV DISORD, V38, P464, DOI 10.1007/s10803-007-0486-x
   Feighny JA, 2006, J MAMMAL, V87, P1072, DOI 10.1644/06-MAMM-A-079R2.1
   Fichtel C, 2002, ETHOLOGY, V108, P763, DOI 10.1046/j.1439-0310.2002.00816.x
   Fischer J, 2002, FOLIA PRIMATOL, V73, P32, DOI 10.1159/000060417
   Fischer J, 2002, J ACOUST SOC AM, V111, P1465, DOI 10.1121/1.1433807
   Fischer J, 2001, ANIM BEHAV, V61, P925, DOI 10.1006/anbe.2000.1687
   Guarino L, 2007, CURR PSYCHOL, V26, P37, DOI 10.1007/s12144-007-9004-8
   Illmann G, 2002, BEHAVIOUR, V139, P487, DOI 10.1163/15685390260135970
   Illmann G, 2001, BEHAVIOUR, V138, P431, DOI 10.1163/156853901750382098
   JENSEN P, 1984, APPL ANIM ETHOL, V11, P237, DOI 10.1016/0304-3762(84)90030-0
   Johnstone T., 2004, HDB EMOTIONS, P220
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Laukka P, 2005, COGNITION EMOTION, V19, P633, DOI 10.1080/02699930441000445
   Lawrence EJ, 2004, PSYCHOL MED, V34, P911, DOI 10.1017/S0033291703001624
   Liu EH, 2008, J COMP PSYCHOL, V122, P132, DOI 10.1037/0735-7036.122.2.132
   Manteuffel G, 2004, APPL ANIM BEHAV SCI, V88, P163, DOI 10.1016/j.applanim.2004.02.012
   Marchant JN, 2001, APPL ANIM BEHAV SCI, V72, P23, DOI 10.1016/S0168-1591(00)00190-8
   Marx G, 2003, J SOUND VIB, V266, P687, DOI 10.1016/S0022-460X(03)00594-7
   Maynard Smith J. M., 2003, Animal signals
   McClure EB, 2000, PSYCHOL BULL, V126, P424, DOI 10.1037/0033-2909.126.3.424
   Miklósi A, 2003, CURR BIOL, V13, P763, DOI 10.1016/S0960-9822(03)00263-X
   Molnár C, 2006, BEHAV PROCESS, V73, P76, DOI 10.1016/j.beproc.2006.03.014
   MORTON ES, 1977, AM NAT, V111, P855, DOI 10.1086/283219
   Nicastro N, 2003, J COMP PSYCHOL, V117, P44, DOI 10.1037/0735-7036.117.1.44
   Nygaard LC, 2008, J EXP PSYCHOL HUMAN, V34, P1017, DOI 10.1037/0096-1523.34.4.1017
   Owings D. H., 1998, Animal vocal communication: A new approach
   Paul ES, 2000, VET REC, V146, P269, DOI 10.1136/vr.146.10.269
   Paulmann S, 2008, BRAIN LANG, V104, P262, DOI 10.1016/j.bandl.2007.03.002
   Pfefferle D, 2006, ANIM BEHAV, V72, P43, DOI 10.1016/j.anbehav.2005.08.021
   Pongrácz P, 2005, J COMP PSYCHOL, V119, P136, DOI 10.1037/0735-7036.119.2.136
   Pongrácz P, 2006, APPL ANIM BEHAV SCI, V100, P228, DOI 10.1016/j.applanim.2005.12.004
   Proverbio AM, 2007, SCAND J PSYCHOL, V48, P477, DOI 10.1111/j.1467-9450.2007.00616.x
   Robbins RL, 2000, BEHAVIOUR, V137, P1271, DOI 10.1163/156853900501926
   Russell JA, 1999, J PERS SOC PSYCHOL, V76, P805, DOI 10.1037/0022-3514.76.5.805
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Rutherford MD, 2008, J EXP PSYCHOL HUMAN, V34, P27, DOI 10.1037/0096-1523.34.1.27
   Schehka S, 2007, J COMP PHYSIOL A, V193, P845, DOI 10.1007/s00359-007-0236-8
   Schrader L, 1998, ETHOLOGY, V104, P859, DOI 10.1111/j.1439-0310.1998.tb00036.x
   Seyfarth RM, 2003, ANN NY ACAD SCI, V1000, P32, DOI 10.1196/annals.1280.004
   Simon D, 2008, PAIN, V135, P55, DOI 10.1016/j.pain.2007.05.008
   Soltis J, 2005, ANIM BEHAV, V70, P589, DOI 10.1016/j.anbehav.2004.11.016
   Talling JC, 1998, APPL ANIM BEHAV SCI, V58, P255, DOI 10.1016/S0168-1591(97)00142-1
   Vannoni E, 2007, ETHOLOGY, V113, P223, DOI 10.1111/j.1439-0310.2006.01323.x
   Watts JM, 2000, APPL ANIM BEHAV SCI, V67, P15, DOI 10.1016/S0168-1591(99)00108-2
   Weary DM, 1997, APPL ANIM BEHAV SCI, V53, P249, DOI 10.1016/S0168-1591(96)01173-2
   Zentall TR, 2005, BEHAV PROCESS, V69, P1, DOI 10.1016/j.beproc.2005.01.004
NR 64
TC 23
Z9 25
U1 0
U2 40
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0735-7036
EI 1939-2087
J9 J COMP PSYCHOL
JI J. Comp. Psychol.
PD FEB
PY 2010
VL 124
IS 1
BP 81
EP 91
DI 10.1037/a0017354
PG 11
WC Behavioral Sciences; Psychology; Psychology, Multidisciplinary; Zoology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Behavioral Sciences; Psychology; Zoology
GA 566QY
UT WOS:000275389300008
PM 20175599
DA 2024-01-09
ER

PT J
AU Umbert, M
   Bonada, J
   Goto, M
   Nakano, T
   Sundberg, J
AF Umbert, Marti
   Bonada, Jordi
   Goto, Masataka
   Nakano, Tomoyasu
   Sundberg, Johan
TI Expression Control in Singing Voice Synthesis
SO IEEE SIGNAL PROCESSING MAGAZINE
LA English
DT Article
ID MUSIC PERFORMANCE; FUTURE; AI
AB In the context of singing voice synthesis, expression control manipulates a set of voice features related to a particular emotion, style, or singer. Also known as performance modeling, it has been approached from different perspectives and for different purposes, and different projects have shown a wide extent of applicability. The aim of this article is to provide an overview of approaches to expression control in singing voice synthesis. We introduce some musical applications that use singing voice synthesis techniques to justify the need for an accurate control of expression. Then, expression is defined and related to speech and instrument performance modeling. Next, we present the commonly studied set of voice parameters that can change perceptual aspects of synthesized voices. After that, we provide an up-to-date classification, comparison, and description of a selection of approaches to expression control. Then, we describe how these approaches are currently evaluated and discuss the benefits of building a common evaluation framework and adopting perceptually-motivated objective measures. Finally, we discuss the challenges that we currently foresee.
C1 [Umbert, Marti; Bonada, Jordi] UPF, Dept Informat & Commun Technol, Music Technol Grp, Barcelona, Spain.
   [Goto, Masataka; Nakano, Tomoyasu] Natl Inst Adv Ind Sci & Technol, Informat Technol Res Inst, Media Interact Grp, Tokyo, Japan.
   [Sundberg, Johan] KTH Royal Inst Technol, Dept Speech Music & Hearing TMH, Voice Res Grp, Stockholm, Sweden.
C3 Pompeu Fabra University; National Institute of Advanced Industrial
   Science & Technology (AIST); Royal Institute of Technology
RP Umbert, M (corresponding author), UPF, Dept Informat & Commun Technol, Music Technol Grp, Barcelona, Spain.
EM marti.umbert@upf.edu; jordi.bonada@upf.edu; m.goto@aist.go.jp;
   t.nakano@aist.go.jp; jsu@csc.kth.se
RI Bonada, Jordi/D-5954-2014; Nakano, Tomoyasu/A-8670-2013; Goto,
   Masataka/K-8205-2012
OI Bonada, Jordi/0000-0002-8671-0729; Nakano, Tomoyasu/0000-0001-8014-2209;
   Goto, Masataka/0000-0003-1167-0977
FU Core Research for Evolutional Science and Technology
FX We would like to thank Alastair Porter for proofreading and Merlijn
   Blaauw for reviewing the article. Some works presented in the article
   were supported in part by the Core Research for Evolutional Science and
   Technology funding program provided by the Japan Science and Technology
   Agency.
CR Alonso M., 2005, THESIS
   [Anonymous], 2012, MULTIMODAL MUSICPROC
   [Anonymous], 2003, Psychology of Music, DOI [DOI 10.1177/03057356030313003, 10.1177/03057356030313003]
   [Anonymous], 2006, P INTERSPEECH
   [Anonymous], 2001, EUROSPEECH 2001 7 EU
   Bonada J., 2008, THESIS
   Bonada J, 2013, P STOCKH MUS AC C SM, P315
   Bonada J, 2007, IEEE SIGNAL PROC MAG, V24, P67, DOI 10.1109/MSP.2007.323266
   Bresin R, 2000, COMPUT MUSIC J, V24, P44, DOI 10.1162/014892600559515
   Campbell D, 2009, SIGNAL PROCESS, V89, P1489, DOI 10.1016/j.sigpro.2009.02.015
   Canazza S, 2004, P IEEE, V92, P686, DOI 10.1109/JPROC.2004.825889
   Cook PR, 1996, COMPUT MUSIC J, V20, P38, DOI 10.2307/3680822
   de Mantaras RL, 2002, AI MAG, V23, P43
   Doi H., 2012, PROC APSIPA ASC, P1
   Friberg A., 2006, ADV COGN PSYCHOL, V2, P145, DOI [DOI 10.2478/V10053-008-0052-X, 10.2478/v10053-008-0052-x]
   Goto M, 2012, INT CONF ACOUST SPEE, P5393, DOI 10.1109/ICASSP.2012.6289140
   Janer J., 2006, P 9 INT C DIG AUD EF, V6, P42
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Katayose H, 2012, J NEW MUSIC RES, V41, P299, DOI 10.1080/09298215.2012.745579
   Kawahara H, 2009, INT CONF ACOUST SPEE, P3905, DOI 10.1109/ICASSP.2009.4960481
   Kenmochi H., 2007, P 8 ANN C INT SPEECH
   Kirke A., 2013, GUIDE COMPUTING EXPR
   Kob M, 2004, ACTA ACUST UNITED AC, V90, P649
   Lesaffre M., 2005, THESIS
   Loscos A., 2004, P INT C DIG AUD EFF, P49
   Marinescu M. C., 2011, P INT C COMP COMP IN, V31, P311
   MERON Y, 1999, THESIS
   Möller S, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1325
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Nakano T., 2009, P SOUND MUS COMP C, P343
   Nakano T, 2011, INT CONF ACOUST SPEE, P453
   Oura K., 2010, PROC ISCA, P211
   Plack CJ, 2005, SPR HDB AUD, V24, P1
   Rodet X., 2002, P 1 IEEE BEN WORKSH, P99
   Saino K, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2894
   Saitou T., 2007, P WORKSH APPL SIGN P, P215, DOI [10. 1109/ASPAA. 2007. 4393001, DOI 10.1109/ASPAA.2007.4393001]
   Salamon J, 2014, IEEE SIGNAL PROC MAG, V31, P118, DOI 10.1109/MSP.2013.2271648
   Scheirer ED, 1998, J ACOUST SOC AM, V103, P588, DOI 10.1121/1.421129
   Schröder M, 2009, AFFECTIVE INFORMATION PROCESSING, P111, DOI 10.1007/978-1-84800-306-4_7
   Sundberg J., 2006, Adv. Cognit. Psychol., V2, P131
   Sundberg J., 1981, P S VEN, P145
   Sundberg J, 2007, J VOICE, V21, P285, DOI 10.1016/j.jvoice.2006.01.003
   SUNDBERG Johan, 1987, The science of singing voice
   Ternstrom S., 2002, P 143 AC SOC AM ASA
   Thalen M, 2001, Logoped Phoniatr Vocol, V26, P82
   Umbert Marti, 2013, P INT SPEECH COMM AS, P213
   Widmer G, 2004, J NEW MUSIC RES, V33, P203, DOI 10.1080/0929821042000317804
   Widmer G, 2001, AI COMMUN, V14, P149
   YOSHIMURA T, 1999, P EUROSPEECH, V5, P2347
NR 49
TC 23
Z9 24
U1 2
U2 21
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1053-5888
EI 1558-0792
J9 IEEE SIGNAL PROC MAG
JI IEEE Signal Process. Mag.
PD NOV
PY 2015
VL 32
IS 6
BP 55
EP 73
DI 10.1109/MSP.2015.2424572
PG 19
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA CU0WI
UT WOS:000363239200006
OA Green Accepted
DA 2024-01-09
ER

PT J
AU Globerson, E
   Amir, N
   Golan, O
   Kishon-Rabin, L
   Lavidor, M
AF Globerson, Eitan
   Amir, Noam
   Golan, Ofer
   Kishon-Rabin, Liat
   Lavidor, Michal
TI Psychoacoustic abilities as predictors of vocal emotion recognition
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Psychoacoustics; Music cognition; Sound recognition; Audition
ID INDIVIDUAL-DIFFERENCES; PROSODIC COMPREHENSION; FUNDAMENTAL-FREQUENCY;
   SPEECH; MUSIC; ADULTS; CUES; CHILDREN; MIND; COMMUNICATION
AB Prosodic attributes of speech, such as intonation, influence our ability to recognize, comprehend, and produce affect, as well as semantic and pragmatic meaning, in vocal utterances. The present study examines associations between auditory perceptual abilities and the perception of prosody, both pragmatic and affective. This association has not been previously examined. Ninety-seven participants (49 female and 48 male participants) with normal hearing thresholds took part in two experiments, involving both prosody recognition and psychoacoustic tasks. The prosody recognition tasks included a vocal emotion recognition task and a focus perception task requiring recognition of an accented word in a spoken sentence. The psychoacoustic tasks included a task requiring pitch discrimination and three tasks also requiring pitch direction (i.e., high/low, rising/falling, changing/steady pitch). Results demonstrate that psychoacoustic thresholds can predict 31% and 38% of affective and pragmatic prosody recognition scores, respectively. Psychoacoustic tasks requiring pitch direction recognition were the only significant predictors of prosody recognition scores. These findings contribute to a better understanding of the mechanisms underlying prosody recognition and may have an impact on the assessment and rehabilitation of individuals suffering from deficient prosodic perception.
C1 [Globerson, Eitan; Lavidor, Michal] Bar Ilan Univ, Gonda Multidisciplinary Brain Res Ctr, IL-52900 Jerusalem, Israel.
   [Globerson, Eitan] Acad Mus & Dance, Jerusalem, Israel.
   [Amir, Noam; Kishon-Rabin, Liat] Tel Aviv Univ, Sackler Fac Med, Dept Commun Disorders, IL-69978 Tel Aviv, Israel.
   [Golan, Ofer] Bar Ilan Univ, Dept Psychol, IL-52900 Ramat Gan, Israel.
C3 Bar Ilan University; Tel Aviv University; Sackler Faculty of Medicine;
   Bar Ilan University
RP Globerson, E (corresponding author), Bar Ilan Univ, Gonda Multidisciplinary Brain Res Ctr, IL-52900 Jerusalem, Israel.
EM gleitan@zahav.net.il; noama@post.tau.ac.il; golano1@mail.biu.ac.il;
   lrabin@post.tau.ac.il; michal.lavidor@gmail.com
RI Kishon-Rabin, Liat/Y-3198-2019
OI Amir, Noam/0000-0002-1704-8444
FU NARSAD; Israel Science Foundation [474/06]
FX This study was supported by the NARSAD independent investigator award
   and by grant no. 474/06 from the Israel Science Foundation awarded to M.
   Lavidor. We are indebted to all participants in the tests for devoting
   their time and effort to this study. Special thanks to Dr. Michal Ben
   Shachar for her help and support and to Adi Hoyben and Atal Harush for
   their assistance in performing the second experiment.
CR Adolphs R, 2003, NAT REV NEUROSCI, V4, P165, DOI 10.1038/nrn1056
   Amir N., 2008, SPEECH PROSODY 2008
   ANSI, 1996, ANSI S3.6-1996
   Bänziger T, 2005, SPEECH COMMUN, V46, P252, DOI 10.1016/j.specom.2005.02.016
   Dankovicová J, 2007, LANG SPEECH, V50, P177, DOI 10.1177/00238309070500020201
   Delhommeau K, 2005, JARO-J ASSOC RES OTO, V6, P171, DOI 10.1007/s10162-005-5055-4
   Demany L, 2002, J ACOUST SOC AM, V111, P1377, DOI 10.1121/1.1445791
   Demany L, 2009, J ACOUST SOC AM, V126, P1342, DOI 10.1121/1.3179675
   EADY SJ, 1986, LANG SPEECH, V29, P233, DOI 10.1177/002383098602900304
   FENSTER CA, 1977, J COMMUN DISORD, V10, P301, DOI 10.1016/0021-9924(77)90028-4
   Fisher RA, 1914, BIOMETRIKA, V10, P507
   Golan O, 2007, J AUTISM DEV DISORD, V37, P1096, DOI 10.1007/s10803-006-0252-5
   Gordon T G, 1987, ASHA Monogr, P108
   Harnmerschmidt K, 2007, J VOICE, V21, P531, DOI 10.1016/j.jvoice.2006.03.002
   HASEGAWA Y, 1992, LANG SPEECH, V35, P87, DOI 10.1177/002383099203500208
   Hawkey DJC, 2004, NAT NEUROSCI, V7, P1055, DOI 10.1038/nn1315
   Irvine DRF, 2000, J ACOUST SOC AM, V108, P2964, DOI 10.1121/1.1323465
   JOHNSON DM, 1987, J ACOUST SOC AM, V81, P427, DOI 10.1121/1.394907
   Johnsrude IS, 2000, BRAIN, V123, P155, DOI 10.1093/brain/123.1.155
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Karni A, 1997, CURR OPIN NEUROBIOL, V7, P530, DOI 10.1016/S0959-4388(97)80033-5
   Kidd GR, 2007, J ACOUST SOC AM, V122, P418, DOI 10.1121/1.2743154
   Kishon-Rabin Liat, 2001, Journal of Basic and Clinical Physiology and Pharmacology, V12, P125
   Kleinman J, 2001, J AUTISM DEV DISORD, V31, P29, DOI 10.1023/A:1005657512379
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   LIEBERMAN P, 1962, J ACOUST SOC AM, V34, P922, DOI 10.1121/1.1918222
   Magne C, 2006, J COGNITIVE NEUROSCI, V18, P199, DOI 10.1162/089892906775783660
   Mathias SR, 2010, J ACOUST SOC AM, V127, P3026, DOI 10.1121/1.3365252
   Micheyl C, 2006, HEARING RES, V219, P36, DOI 10.1016/j.heares.2006.05.004
   Monnot M, 2003, ANN NY ACAD SCI, V1000, P288, DOI 10.1196/annals.1280.027
   Moore B. C. J., 2013, An introduction to the psychology of hearing, V6th
   Most T, 2007, J DEAF STUD DEAF EDU, V12, P350, DOI 10.1093/deafed/enm012
   MURPHY D, 1990, J NEUROL NEUROSUR PS, V53, P727, DOI 10.1136/jnnp.53.9.727
   Pell MD, 1997, BRAIN LANG, V57, P195, DOI 10.1006/brln.1997.1736
   Roth Daphne Ari-Even, 2004, Journal of Basic and Clinical Physiology and Pharmacology, V15, P15
   Rutherford MD, 2002, J AUTISM DEV DISORD, V32, P189, DOI 10.1023/A:1015497629971
   SCHERER KR, 1984, J ACOUST SOC AM, V76, P1346, DOI 10.1121/1.391450
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   Schön D, 2004, PSYCHOPHYSIOLOGY, V41, P341, DOI 10.1111/1469-8986.00172.x
   Semal C, 2006, J ACOUST SOC AM, V120, P3907, DOI 10.1121/1.2357708
   Sobin C, 1999, J PSYCHOLINGUIST RES, V28, P347, DOI 10.1023/A:1023237014909
   Steinhauer K, 1999, NAT NEUROSCI, V2, P191, DOI 10.1038/5757
   Surprenant AM, 2001, J ACOUST SOC AM, V110, P2085, DOI 10.1121/1.1404973
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Trimmer CG, 2008, EMOTION, V8, P838, DOI 10.1037/a0014080
   Wright BA, 2001, P NATL ACAD SCI USA, V98, P12307, DOI 10.1073/pnas.211220498
   Xu Y, 2005, J PHONETICS, V33, P159, DOI 10.1016/j.wocn.2004.11.001
   Xu Y., 2011, P 17 INT C PHON SCI
NR 49
TC 18
Z9 19
U1 0
U2 23
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD NOV
PY 2013
VL 75
IS 8
BP 1799
EP 1810
DI 10.3758/s13414-013-0518-x
PG 12
WC Psychology; Psychology, Experimental
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Psychology
GA 281KA
UT WOS:000329098800016
PM 23893469
OA Bronze
DA 2024-01-09
ER

PT J
AU Plate, RC
   Jones, C
   Zhao, S
   Flum, MW
   Steinberg, J
   Daley, G
   Corbett, N
   Neumann, C
   Waller, R
AF Plate, R. C.
   Jones, C.
   Zhao, S.
   Flum, M. W.
   Steinberg, J.
   Daley, G.
   Corbett, N.
   Neumann, C.
   Waller, R.
TI "But not the music": psychopathic traits and difficulties recognising
   and resonating with the emotion in music
SO COGNITION & EMOTION
LA English
DT Article
DE Psychopathy; emotion perception; emotion categorisation; music
ID VOCAL EXPRESSIONS; RECOGNITION; CHILDREN; RESPONSES; ADOLESCENTS;
   PERCEPTION; COGNITION; PATTERNS; THERAPY; CORTEX
AB Recognising and responding appropriately to emotions is critical to adaptive psychological functioning. Psychopathic traits (e.g. callous, manipulative, impulsive, antisocial) are related to differences in recognition and response when emotion is conveyed through facial expressions and language. Use of emotional music stimuli represents a promising approach to improve our understanding of the specific emotion processing difficulties underlying psychopathic traits because it decouples recognition of emotion from cues directly conveyed by other people (e.g. facial signals). In Experiment 1, participants listened to clips of emotional music and identified the emotional content (Sample 1, N = 196) or reported on their feelings elicited by the music (Sample 2, N = 197). Participants accurately recognised (t(195) = 32.78, p < .001, d = 4.69) and reported feelings consistent with (t(196) = 7.84, p < .001, d = 1.12) the emotion conveyed in the music. However, psychopathic traits were associated with reduced emotion recognition accuracy (F(1, 191) = 19.39, p < .001) and reduced likelihood of feeling the emotion (F(1, 193) = 35.45, p < .001), particularly for fearful music. In Experiment 2, we replicated findings for broad difficulties with emotion recognition (Sample 3, N = 179) and emotional resonance (Sample 4, N = 199) associated with psychopathic traits. Results offer new insight into emotion recognition and response difficulties that are associated with psychopathic traits.
C1 [Plate, R. C.; Jones, C.; Zhao, S.; Flum, M. W.; Steinberg, J.; Daley, G.; Corbett, N.; Waller, R.] Univ Penn, Dept Psychol, Stephen A Levin Bldg, Philadelphia, PA 19104 USA.
   [Neumann, C.] Univ North Texas, Dept Psychol, Denton, TX USA.
C3 University of Pennsylvania; University of North Texas System; University
   of North Texas Denton
RP Waller, R (corresponding author), Univ Penn, Dept Psychol, Stephen A Levin Bldg, Philadelphia, PA 19104 USA.
EM rwaller@sas.upenn.edu
OI STEINBERG, JOSHUA/0000-0002-8920-3415; Waller,
   Rebecca/0000-0002-5069-1183; Plate, Rista/0000-0003-4754-2459
FU University of Pennsylvania; MindCORE Postdoctoral Fellowship at the
   University of Pennsylvania
FX The research was supported by institutional funding from the University
   of Pennsylvania. R.C.P was funded by a MindCORE Postdoctoral Fellowship
   at the University of Pennsylvania.
CR Allen, 2005, COMMUNICATION DISORD, V26, P131, DOI DOI 10.1177/15257401050260030201
   [Anonymous], 2001, MUSIC EMOTION THEORY
   Balkwill LL, 2004, JPN PSYCHOL RES, V46, P337, DOI 10.1111/j.1468-5584.2004.00265.x
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Barrett LF, 2019, PSYCHOL SCI PUBL INT, V20, P1, DOI 10.1177/1529100619832930
   Bates D, 2014, Arxiv, DOI arXiv:1406.5823
   Bigliassi M, 2015, PERCEPT MOTOR SKILL, V120, P202, DOI 10.2466/27.24.PMS.120v12x5
   Bizzego A, 2020, BEHAV SCI-BASEL, V10, DOI 10.3390/bs10010011
   Blagov PS, 2019, PSYCHOL MUSIC, V47, P821, DOI 10.1177/0305735619864630
   Blair RJR, 2013, NAT REV NEUROSCI, V14, P786, DOI 10.1038/nrn3577
   Blair RJR, 2001, J ABNORM CHILD PSYCH, V29, P491, DOI 10.1023/A:1012225108281
   Blair RJR, 1997, PSYCHOPHYSIOLOGY, V34, P192
   Blair RJR, 2004, BRAIN COGNITION, V55, P198, DOI 10.1016/s0278-2626(03)00276-8
   Bowes SM, 2018, PERS INDIV DIFFER, V129, P33, DOI 10.1016/j.paid.2018.03.009
   Brown LS, 2017, J MUSIC THER, V54, P55, DOI 10.1093/jmt/thw017
   Campbell IG, 1942, AM J PSYCHOL, V55, P1, DOI 10.2307/1417020
   Carr C, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0070252
   Casey LS, 2017, SAGE OPEN, V7, DOI 10.1177/2158244017712774
   Chaplin TM., 2005, DEV PSYCHOPATHOL, P49, DOI [10.4135/9781452231655.n3, DOI 10.4135/9781452231655.N3]
   Cowen AS, 2020, P NATL ACAD SCI USA, V117, P1924, DOI 10.1073/pnas.1910704117
   Davies Stephen, 2010, Handbook of music and emotion: Theory, research, applications, P15
   Dawel A, 2012, NEUROSCI BIOBEHAV R, V36, P2288, DOI 10.1016/j.neubiorev.2012.08.006
   de Witte M, 2022, HEALTH PSYCHOL REV, V16, P134, DOI 10.1080/17437199.2020.1846580
   Decety Jean, 2004, Behav Cogn Neurosci Rev, V3, P71, DOI 10.1177/1534582304267187
   Dukes D, 2021, NAT HUM BEHAV, V5, P816, DOI 10.1038/s41562-021-01130-8
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   Fachner J, 2013, BRAIN TOPOGR, V26, P338, DOI 10.1007/s10548-012-0254-x
   Gold C, 2004, J CHILD PSYCHOL PSYC, V45, P1054, DOI 10.1111/j.1469-7610.2004.t01-1-00298.x
   Gold C, 2007, PSYCHOTHER RES, V17, P292, DOI 10.1080/10503300600607886
   GOLDSTEIN A, 1980, PHYSIOL PSYCHOL, V8, P126
   Gullapalli AR, 2021, J RES PERS, V92, DOI 10.1016/j.jrp.2021.104093
   Hare RD, 2009, CAMBRIDGE HANDBOOK OF PERSONALITY PSYCHOLOGY, P660
   Hastings ME, 2008, PERS INDIV DIFFER, V44, P1474, DOI 10.1016/j.paid.2008.01.004
   Hunter PG, 2010, PSYCHOL AESTHET CREA, V4, P47, DOI 10.1037/a0016873
   JOHNS JH, 1962, J CONSULT PSYCHOL, V26, P217, DOI 10.1037/h0048399
   Juslin P. N., 2011, HDB MUSIC EMOTION TH
   Juslin PN, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00596
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Katagiri J, 2009, J MUSIC THER, V46, P15, DOI 10.1093/jmt/46.1.15
   Khalfa S, 2008, NEUROPSYCHOLOGIA, V46, P2485, DOI 10.1016/j.neuropsychologia.2008.04.009
   Kim Y. E., 2010, 35 INT C INFRARED MI, P12
   Knott D, 2020, MUSIC THER PERSPECT, V38, P151, DOI 10.1093/mtp/miaa017
   Krumhansl CL, 2002, CURR DIR PSYCHOL SCI, V11, P45, DOI 10.1111/1467-8721.00165
   Laukka P, 2007, MOTIV EMOTION, V31, P182, DOI 10.1007/s11031-007-9063-z
   Long LS, 2007, COGNITION EMOTION, V21, P119, DOI 10.1080/02699930600551766
   Ludecke Daniel, 2023, CRAN
   Lundqvist LO, 2009, PSYCHOL MUSIC, V37, P61, DOI 10.1177/0305735607086048
   Mier D, 2014, WORLD J BIOL PSYCHIA, V15, P479, DOI 10.3109/15622975.2014.902541
   Moore KS, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00572
   Nagel MG, 2018, PERSONAL DISORD, V9, P484, DOI 10.1037/per0000287
   Nawrot ES., 2003, Psychol. Music, V31, P75, DOI DOI 10.1177/0305735603031001325
   Neumann CS, 2015, J PERS, V83, P678, DOI 10.1111/jopy.12127
   Nyklicek I, 1997, J PSYCHOPHYSIOL, V11, P304
   Omar R, 2010, BRAIN, V133, P1200, DOI 10.1093/brain/awp345
   Panda R, 2023, IEEE T AFFECT COMPUT, V14, P68, DOI 10.1109/TAFFC.2020.3032373
   Panksepp J, 1995, MUSIC PERCEPT, V13, P171
   Patrick CJ, 2009, DEV PSYCHOPATHOL, V21, P913, DOI 10.1017/S0954579409000492
   Paulhus D.L., 2017, Self-Report Psychopathy Scale 4th Edition (SRP 4) Manual
   Plate RC, 2022, J PERS, V90, P631, DOI 10.1111/jopy.12687
   Pollak SD, 2019, DEV PSYCHOL, V55, P1801, DOI 10.1037/dev0000789
   Punkanen M., 2011, Music and Medicine, V3, P114, DOI [DOI 10.1177/1943862110395597, https://doi.org/10.1177/1943862110395597, 10.1177/1943862110395597]
   Quintin EM, 2011, J AUTISM DEV DISORD, V41, P1240, DOI 10.1007/s10803-010-1146-0
   R Core Team, 2018, R: A Language and Environment for Statistical Computing
   ROBAZZA C, 1994, PERCEPT MOTOR SKILL, V79, P939, DOI 10.2466/pms.1994.79.2.939
   Russell JA, 2003, ANNU REV PSYCHOL, V54, P329, DOI 10.1146/annurev.psych.54.101601.145102
   Sammler D, 2007, PSYCHOPHYSIOLOGY, V44, P293, DOI 10.1111/j.1469-8986.2007.00497.x
   Scherer KR, 2004, J NEW MUSIC RES, V33, P239, DOI 10.1080/0929821042000317822
   Schmidt LA, 2001, COGNITION EMOTION, V15, P487, DOI 10.1080/0269993004200187
   Schubert E, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00837
   Schutte NS, 2001, J SOC PSYCHOL, V141, P523, DOI 10.1080/00224540109600569
   Schwarz Florian, 2018, OSF
   Seara-Cardoso A, 2013, PERS INDIV DIFFER, V55, P328, DOI 10.1016/j.paid.2013.03.011
   Sloboda J. A., 1991, Psychology of Music, V19, P110, DOI [10.1177/0305735691192002, DOI 10.1177/0305735691192002]
   SLOBODA JA, 1986, PSYCHOL BELG, V26, P199
   Sloboda JA., 2001, MUSIC EMOTION THEORY, P71
   Southam-Gerow MA, 2000, J CLIN CHILD PSYCHOL, V29, P319, DOI 10.1207/S15374424JCCP2903_3
   Stone AA, 2019, COMPUT HUM BEHAV, V94, P1, DOI 10.1016/j.chb.2018.12.042
   Trilla I, 2021, PSYCHOL RES-PSYCH FO, V85, P1005, DOI 10.1007/s00426-020-01314-3
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   Waller R, 2019, NEUROSCI BIOBEHAV R, V107, P656, DOI 10.1016/j.neubiorev.2019.10.005
   Warrenburg L. A., 2020, Music Sci, V3, p205920432097738, DOI [10.1177/2059204320977384, DOI 10.1177/2059204320977384]
   Warrenburg LA, 2020, J NEW MUSIC RES, V49, P373, DOI 10.1080/09298215.2020.1784956
   Waterman M., 1996, Psychology of Music, V24, P53, DOI [10.1177/0305735696241006, DOI 10.1177/0305735696241006]
   Wickham H., 2016, ggplot2: Elegant Graphics for Data Analysis, DOI [DOI 10.1007/978-3-319-24277-4, 10.1007/978-3-319-24277-4]
   Wickham H., 2019, J OPEN SOURCE SOFTW, V4, DOI [DOI 10.21105/JOSS.01686, 10.21105, 10.21105/joss.01686]
   Witvliet CVO, 2007, COGNITION EMOTION, V21, P3, DOI 10.1080/02699930601000672
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 87
TC 0
Z9 0
U1 5
U2 8
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 0269-9931
EI 1464-0600
J9 COGNITION EMOTION
JI Cogn. Emot.
PD MAY 19
PY 2023
VL 37
IS 4
BP 748
EP 762
DI 10.1080/02699931.2023.2205105
EA APR 2023
PG 15
WC Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA J5MB6
UT WOS:000977746400001
PM 37104122
DA 2024-01-09
ER

PT J
AU Daido, R
   Ito, M
   Makino, S
   Ito, A
AF Daido, Ryunosuke
   Ito, Masashi
   Makino, Shozo
   Ito, Akinori
TI Automatic evaluation of singing enthusiasm for karaoke
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Singing enthusiasm; Singing voice; Perception of singing voice; Karaoke
ID VOICE; EXPRESSION; MUSIC; PERFORMANCE; EMOTIONS; CODE
AB Evaluation of singing skill is a popular function of karaoke machines. Here, we introduce a different aspect of evaluating the singing voice of an amateur singer: "singing enthusiasm". First, we investigated whether human listeners can evaluate singing enthusiasm consistently and whether the listener's perception matches the singer's intended enthusiasm. We then identified three acoustic features relevant to the perception of singing enthusiasm: A-weighted power, "fall-down", and vibrato extent. Finally, we developed a method for combining the selected three features to estimate the value of singing enthusiasm, and obtained a correlation coefficient of 0.65 between the estimated value and human evaluation. (C) 2012 Elsevier Ltd. All rights reserved.
C1 [Daido, Ryunosuke; Ito, Akinori] Tohoku Univ, Grad Sch Engn, Aoba Ku, Sendai, Miyagi 9800011, Japan.
   [Ito, Masashi] Tohoku Inst Technol, Taihaku Ku, Sendai, Miyagi 9828577, Japan.
   [Makino, Shozo] Tohoku Bunka Gakuen Univ, Aoba Ku, Sendai, Miyagi 9808551, Japan.
C3 Tohoku University; Tohoku Institute Technology
RP Ito, A (corresponding author), Tohoku Univ, Grad Sch Engn, Aoba Ku, 6-6-05 Aramaki Aza Aoba, Sendai, Miyagi 9800011, Japan.
EM ryunosuke@spcom.ecei.tohoku.ac.jp; itojin@tohtech.ac.jp;
   makino@ait.tbgu.ac.jp; aito@spcom.ecei.tohoku.ac.jp
RI Ito, Akinori/AAC-3116-2019
OI Ito, Akinori/0000-0002-8835-7877
CR [Anonymous], 1988, J VOICE
   Arroabarren I., 2001, P IEEE INSTR MEAS TE, V3, P1529
   Cao C., 2008, P 9 ANN C INT SPEECH
   Chong HJ, 2010, ART PSYCHOTHER, V37, P120, DOI 10.1016/j.aip.2010.01.001
   Daido R., 2011, P ISMIR 2011, P31
   GRAMMING P, 1991, J VOICE, V5, P144, DOI 10.1016/S0892-1997(05)80178-X
   HOLLAND PW, 1977, COMMUN STAT A-THEOR, V6, P813, DOI 10.1080/03610927708827533
   Hollien H, 2000, J VOICE, V14, P287, DOI 10.1016/S0892-1997(00)80038-7
   Int. Electrotechnical Commission, 2002, 616721 IEC
   Int. Telecommunication Union, 2003, ITU-R Recommendation BS. 1284-1, Patent No. 5434949
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   KLEINGINNA P R JR, 1981, Motivation and Emotion, V5, P345, DOI 10.1007/BF00992553
   KUWANO S, 1989, NOISE CONTROL ENG, V33, P107, DOI 10.3397/1.2827748
   Mayor O., 2006, P AES CONV
   Minematsu N., 2002, P INT C LANG RES EV, P896
   Mitsui Toru, 1998, Karaoke Around the World: Global Technology, Local Singing
   Nakano T, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1706
   Omori K, 1996, J VOICE, V10, P228, DOI 10.1016/S0892-1997(96)80003-8
   Park C. S., 1996, US Patent, Patent No. [5,567,162, 5567162]
   Pawate B., 1998, U.S. Patent, Patent No. [5,719,344, 5804752]
   Pawate Basavaraj, 1998, US Patent, Patent No. [5,719,344, 5719344]
   PRAME E, 1994, J ACOUST SOC AM, V96, P1979, DOI 10.1121/1.410141
   Prame E, 1997, J ACOUST SOC AM, V102, P616, DOI 10.1121/1.419735
   RAPOPORT E, 1996, J NEW MUSIC RES, V25, P109, DOI 10.1080/09298219608570700
   Scherer KR, 2004, J NEW MUSIC RES, V33, P239, DOI 10.1080/0929821042000317822
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Schoen M, 1922, PSYCHOL MONOGR, V31, P230, DOI 10.1037/h0093165
   Seashore CE, 1923, P NATL ACAD SCI USA, V9, P323, DOI 10.1073/pnas.9.9.323
   Sj_olander K, 1997, SNACK SOUND TOOLKIT
   Sone T., 1998, U.S. Patent, Patent No. [5,804,752, 5889224]
   SUNDBERG J, 1974, J ACOUST SOC AM, V55, P838, DOI 10.1121/1.1914609
   SUNDBERG J, 1977, SCI AM, V236, P82, DOI 10.1038/scientificamerican0377-82
   Sundberg J, 1999, PSYCHOL MUSIC, P171, DOI DOI 10.1016/8978-012213564-4/50007-X
   Suzuki M., 2008, J SYSTEMICS CYBERN I, V6, P83
   Takeuchi H., 2010, IEEE T ELECT INFORM, V130, P1042
   Tsai W.-H., 2011, P INT C AUD SPEECH S, P1520
   Wapnick J, 1997, J VOICE, V11, P429, DOI 10.1016/S0892-1997(97)80039-2
   Welham NV, 2003, J VOICE, V17, P21, DOI 10.1016/S0892-1997(03)00033-X
NR 38
TC 9
Z9 9
U1 0
U2 17
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD MAR
PY 2014
VL 28
IS 2
SI SI
BP 501
EP 517
DI 10.1016/j.csl.2012.07.007
PG 17
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 285SN
UT WOS:000329415400010
DA 2024-01-09
ER

PT J
AU Ong, JH
   Leung, FYN
   Liu, F
AF Ong, Jia Hoong
   Leung, Florence Yik Nam
   Liu, Fang
TI The Reading Everyday Emotion Database (REED): a set of audio-visual
   recordings of emotions in music and language
SO LANGUAGE RESOURCES AND EVALUATION
LA English
DT Article; Early Access
DE Emotion; Database; Audio-visual; Stimulus set; Speech; Song
ID FACIAL EXPRESSIONS; MOVING FACES; RECOGNITION; VOICE; VALIDATION; SPEECH
AB Most audio-visual (AV) emotion databases consist of clips that do not reflect real-life emotion processing (e.g., professional actors in bright studio-like environment), contain only spoken clips, and none have sung clips that express complex emotions. Here, we introduce a new AV database, the Reading Everyday Emotion Database (REED), which directly addresses those gaps. We recorded the faces of everyday adults with a diverse range of acting experience expressing 13 emotions-neutral, the six basic emotions (angry, disgusted, fearful, happy, sad, surprised), and six complex emotions (embarrassed, hopeful, jealous, proud, sarcastic, stressed)-in two auditory domains (spoken and sung) using everyday recording devices (e.g., laptops, mobile phones, etc.). The recordings were validated by an independent group of raters. We found that: intensity ratings of the recordings were positively associated with recognition accuracy; and the basic emotions, as well as the Neutral and Sarcastic emotions, were recognised more accurately than the other complex emotions. Emotion recognition accuracy also differed by utterance. Exploratory analysis revealed that recordings of those with drama experience were better recognised than those without. Overall, this database will benefit those who need AV clips with natural variations in both emotion expressions and recording environment.
C1 [Ong, Jia Hoong; Leung, Florence Yik Nam; Liu, Fang] Univ Reading, Sch Psychol & Clin Language Sci, Harry Pitt Bldg Earley Gate, Reading RG6 6AL, England.
   [Ong, Jia Hoong] Nottingham Trent Univ, Sch Social Sci, Dept Psychol, Nottingham, England.
   [Leung, Florence Yik Nam] Univ Bath, Dept Psychol, Bath, England.
C3 University of Reading; Nottingham Trent University; University of Bath
RP Liu, F (corresponding author), Univ Reading, Sch Psychol & Clin Language Sci, Harry Pitt Bldg Earley Gate, Reading RG6 6AL, England.
EM f.liu@reading.ac.uk
OI Leung, Florence Yik Nam/0000-0001-9136-1263; Ong, Jia
   Hoong/0000-0003-1503-8311
FU European Research Council (ERC) [CAASD, 678733]; European Union [887283]
FX This work was supported by a European Research Council (ERC) Starting
   Grant (CAASD, 678733) awarded to FL. JHO was supported by the European
   Union's Horizon 2020 research and innovation programme under the Marie
   Sklodowska-Curie grant agreement No. 887283.
CR Allen R, 2010, MUSIC PERCEPT, V27, P251, DOI 10.1525/MP.2010.27.4.251
   [Anonymous], 2019, DaVinci Resolve
   Anwyl-Irvine AL, 2020, BEHAV RES METHODS, V52, P388, DOI 10.3758/s13428-019-01237-x
   Bänziger T, 2012, EMOTION, V12, P1161, DOI 10.1037/a0025827
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Battocchi A., 2005, P 7 INT C MULTIMODAL, P214, DOI [10.1145/1088463.1088501, DOI 10.1145/1088463.1088501]
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Benda MS, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0228248
   Bhullar N, 2013, CURR PSYCHOL, V32, P186, DOI 10.1007/s12144-013-9173-6
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Cosker D, 2011, IEEE I CONF COMP VIS, P2296, DOI 10.1109/ICCV.2011.6126510
   Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26
   Douglas-Cowie E, 2011, COGN TECHNOL, P243, DOI 10.1007/978-3-642-15184-2_14
   Ekman P., 1999, Handbook of Cognition and Emotion, V98, P45, DOI 10.1002/0470013494.ch3
   Ekman P, 1976, Pictures of facial affect
   Fox J., 2019, An R Companion to Applied Regression, V3rd ed
   Golan O, 2006, J AUTISM DEV DISORD, V36, P169, DOI 10.1007/s10803-005-0057-y
   Griffiths PE, 1997, WHAT EMOTIONS REALLY, DOI [10.7208/chicago/9780226308760.001.0001, DOI 10.7208/CHICAGO/9780226308760.001.0001]
   Haq S., 2009, P AUD VIS SPEECH PRO, P53
   Jürgens R, 2015, J NONVERBAL BEHAV, V39, P195, DOI 10.1007/s10919-015-0209-5
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Katagiri J, 2009, J MUSIC THER, V46, P15, DOI 10.1093/jmt/46.1.15
   Kim J, 2012, VIS COGN, V20, P902, DOI 10.1080/13506285.2012.713874
   Krumhuber EG, 2017, EMOT REV, V9, P280, DOI 10.1177/1754073916670022
   Krumhuber EG, 2013, EMOT REV, V5, P41, DOI 10.1177/1754073912451349
   Lassalle A, 2019, BEHAV RES METHODS, V51, P493, DOI 10.3758/s13428-018-1048-1
   Laukka P., 2010, P LREC 2010 WORKSHOP, P53
   Lefcheck J., 2014, R-squared for generalized linear mixed-effects models (0.2-4)
   Lenth Russell V, 2023, CRAN
   Lin JC, 2012, IEEE T MULTIMEDIA, V14, P142, DOI 10.1109/TMM.2011.2171334
   Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391
   Livingstone SR, 2015, Q J EXP PSYCHOL, V68, P952, DOI 10.1080/17470218.2014.971034
   Ma YX, 2019, INFORM FUSION, V46, P184, DOI 10.1016/j.inffus.2018.06.003
   Massaro DW, 1996, PSYCHON B REV, V3, P215, DOI 10.3758/BF03212421
   Montagne B, 2007, PERCEPT MOTOR SKILL, V104, P589, DOI 10.2466/PMS.104.2.589-598
   Navas E., 2004, LREC, V2004, P1387
   Nordström H, 2019, J ACOUST SOC AM, V145, P3058, DOI 10.1121/1.5108601
   O'Reilly H, 2016, BEHAV RES METHODS, V48, P567, DOI 10.3758/s13428-015-0601-4
   O'Toole AJ, 2005, IEEE T PATTERN ANAL, V27, P812, DOI 10.1109/TPAMI.2005.90
   Pell MD, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027256
   Praveen RG, 2022, IEEE COMPUT SOC CONF, P2485, DOI 10.1109/CVPRW56347.2022.00278
   R Core Team, 2018, R: A Language and Environment for Statistical Computing
   Rigoulot S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00367
   Ringeval F, 2013, IEEE INT CONF AUTOMA
   Roy S., 2007, STOIC: A database of dynamic and static faces expressing highly recognizable emotions
   Schoneveld L, 2021, PATTERN RECOGN LETT, V146, P1, DOI 10.1016/j.patrec.2021.03.007
   Thompson WF, 2012, P NATL ACAD SCI USA, V109, P19027, DOI 10.1073/pnas.1210344109
   Tottenham N, 2009, PSYCHIAT RES, V168, P242, DOI 10.1016/j.psychres.2008.05.006
   van der Schalk J, 2011, EMOTION, V11, P907, DOI 10.1037/a0023853
   Wingenbach TSH, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0147112
   Wu CH, 2014, APSIPA TRANS SIGNAL, V3, DOI 10.1017/ATSIP.2014.11
   Yin LJ, 2008, IEEE INT CONF AUTOMA, P116
   Young A., 2002, Facial expression of emotion: Stimuli and tests (FEEST)
NR 54
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1574-020X
EI 1574-0218
J9 LANG RESOUR EVAL
JI Lang. Resour. Eval.
PD 2023 NOV 20
PY 2023
DI 10.1007/s10579-023-09698-5
EA NOV 2023
PG 23
WC Computer Science, Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Y2PX2
UT WOS:001103748000002
OA Green Submitted, hybrid
DA 2024-01-09
ER

PT J
AU Castro, SL
   Lima, CF
AF Castro, Sao Luis
   Lima, Cesar F.
TI AGE AND MUSICAL EXPERTISE INFLUENCE EMOTION RECOGNITION IN MUSIC
SO MUSIC PERCEPTION
LA English
DT Article
DE aging; musical emotions; musical expertise; neural deterioration;
   positivity effect
ID INDIVIDUAL-DIFFERENCES; IMPAIRED RECOGNITION; FACIAL EXPRESSIONS; VOCAL
   EXPRESSIONS; COGNITIVE CONTROL; BRAIN PLASTICITY; PERFORMANCE;
   RESPONSES; PROSODY; PERCEPTION
AB WE INVESTIGATED HOW AGE AND MUSICAL EXPERTISE influence emotion recognition in music. Musically trained and untrained participants from two age cohorts, young and middle-aged adults (N = 80), were presented with music excerpts expressing happiness, peacefulness, sadness, and fear/threat. Participants rated how much each excerpt expressed the four emotions on 10-point scales. The intended emotions were consistently perceived, but responses varied across groups. Advancing age was associated with selective decrements in the recognition of sadness and fear/threat, a finding consistent with previous research (Lima & Castro, 2011a); the recognition of happiness and peacefulness remained stable. Years of music training were associated with enhanced recognition accuracy. These effects were independent of domain-general cognitive abilities and personality traits, but they were echoed in differences in how efficiently music structural cues (e.g., tempo, mode) were relied upon. Thus, age and musical expertise are experiential factors explaining individual variability in emotion recognition in music.
C1 [Castro, Sao Luis; Lima, Cesar F.] Univ Porto, P-4100 Oporto, Portugal.
C3 Universidade do Porto
RP Castro, SL (corresponding author), Univ Porto, Fac Psychol & Educ, Rua Alfredo Allen, P-4200135 Oporto, Portugal.
EM slcastro@fpce.up.pt
RI Lima, Cesar F./HSF-6972-2023; Castro, Sao Luis/E-5518-2017; Castro, Sao
   Luis/ISV-1010-2023
OI Lima, Cesar F./0000-0003-3058-7204; Castro, Sao
   Luis/0000-0002-1487-3596; Castro, Sao Luis/0000-0002-1487-3596
CR Abboud H., 2006, SUPERLAB STIMULUS PR
   Adolphs R, 2001, NEUROPSYCHOLOGY, V15, P396, DOI 10.1037//0894-4105.15.3.396
   Adolphs R, 2002, EMOTION, V2, P23, DOI 10.1037/1528-3542.2.1.23
   [Anonymous], 2010, HDB MUSIC EMOTION TH
   [Anonymous], HDB SOCIAL NEUROSCIE
   [Anonymous], 2010, HDB EMOTIONS
   Ashwin C, 2006, SOC NEUROSCI-UK, V1, P349, DOI 10.1080/17470910601040772
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Baron-Cohen S, 2001, J AUTISM DEV DISORD, V31, P5, DOI 10.1023/A:1005653411471
   Barrett LF, 2006, PERS SOC PSYCHOL REV, V10, P20, DOI 10.1207/s15327957pspr1001_2
   Barrett LF, 2009, COGNITION EMOTION, V23, P1284, DOI 10.1080/02699930902985894
   Bhatara A, 2011, J EXP PSYCHOL HUMAN, V37, P921, DOI 10.1037/a0021922
   Bialystok E, 2009, J EXP PSYCHOL HUMAN, V35, P565, DOI 10.1037/a0012735
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Bigand E, 2006, COGNITION, V100, P100, DOI 10.1016/j.cognition.2005.11.007
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Cacioppo J. T., 2011, SOCIAL NEUROSCIENCE, P249, DOI DOI 10.1093/ACPROF:OSO/9780195316872.003.0017
   Calder AJ, 2003, NEUROPSYCHOLOGIA, V41, P195, DOI 10.1016/S0028-3932(02)00149-5
   Carstensen LL, 2005, CURR DIR PSYCHOL SCI, V14, P117, DOI 10.1111/j.0963-7214.2005.00348.x
   Castro SL, 2003, CLIN NEUROPSYCHOL, V17, P104
   Charles S. T., 2007, HDB EMOTION REGULATI, P307
   Charles ST, 2003, J EXP PSYCHOL GEN, V132, P310, DOI 10.1037/0096-3445.132.2.310
   Charles ST, 2010, ANNU REV PSYCHOL, V61, P383, DOI 10.1146/annurev.psych.093008.100448
   Cremers HR, 2010, NEUROIMAGE, V49, P963, DOI 10.1016/j.neuroimage.2009.08.023
   Curiati PK, 2009, AM J NEURORADIOL, V30, P1850, DOI 10.3174/ajnr.A1727
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Dellacherie D, 2011, PSYCHOPHYSIOLOGY, V48, P337, DOI 10.1111/j.1469-8986.2010.01075.x
   Di Martino A, 2009, AM J PSYCHIAT, V166, P891, DOI 10.1176/appi.ajp.2009.08121894
   Drapeau J, 2009, ANN NY ACAD SCI, V1169, P342, DOI 10.1111/j.1749-6632.2009.04768.x
   Eugène F, 2003, NEUROIMAGE, V19, P354, DOI 10.1016/S1053-8119(03)00121-6
   Forgeard Marie, 2008, PLoS One, V3, pe3566, DOI 10.1371/journal.pone.0003566
   Fozard J.L., 2001, Handbook of the Psychology of Aging, P241
   Freitas S, 2011, J CLIN EXP NEUROPSYC, V33, P989, DOI 10.1080/13803395.2011.589374
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Gabrielsson A., 2009, OXFORD HDB MUSIC PSY
   Gabrielsson A., 2010, HDB MUSIC EMOTION TH, P367, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0014
   Gaser C, 2003, J NEUROSCI, V23, P9240
   Giorgio A, 2010, NEUROIMAGE, V51, P943, DOI 10.1016/j.neuroimage.2010.03.004
   Gosling SD, 2003, J RES PERS, V37, P504, DOI 10.1016/S0092-6566(03)00046-1
   Gosselin N, 2005, BRAIN, V128, P628, DOI 10.1093/brain/awh420
   Gosselin N, 2007, NEUROPSYCHOLOGIA, V45, P236, DOI 10.1016/j.neuropsychologia.2006.07.012
   Grady C, 2012, NAT REV NEUROSCI, V13, P491, DOI 10.1038/nrn3256
   Habib M, 2009, MUSIC PERCEPT, V26, P279, DOI 10.1525/MP.2009.26.3.279
   Hamann S, 2004, CURR OPIN NEUROBIOL, V14, P233, DOI 10.1016/j.conb.2004.03.010
   Hamel R, 2006, EDUC PSYCHOL MEAS, V66, P1039, DOI 10.1177/0013164406288169
   Hedden T, 2004, NAT REV NEUROSCI, V5, P87, DOI 10.1038/nrn1323
   Herholz SC, 2012, NEURON, V76, P486, DOI 10.1016/j.neuron.2012.10.011
   Hunter PG, 2008, COGNITION EMOTION, V22, P327, DOI 10.1080/02699930701438145
   Hunter PG, 2011, J EXP CHILD PSYCHOL, V110, P80, DOI 10.1016/j.jecp.2011.04.001
   Hyde KL, 2009, J NEUROSCI, V29, P3019, DOI 10.1523/JNEUROSCI.5118-08.2009
   Isaacowitz DM, 2007, PSYCHOL AGING, V22, P147, DOI 10.1037/0882-7974.22.1.147
   Isaacowitz DM, 2011, J NONVERBAL BEHAV, V35, P261, DOI 10.1007/s10919-011-0113-6
   Juslin P. N., 2010, Handbook of music and emotion: Theory, research, applications, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0022
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Juslin PN, 1997, MUSIC SCI, V1, P225, DOI DOI 10.1177/102986499700100205
   Keightley ML, 2006, PSYCHOL AGING, V21, P558, DOI 10.1037/0882-7974.21.3.558
   Kisley MA, 2007, PSYCHOL SCI, V18, P838, DOI 10.1111/j.1467-9280.2007.01988.x
   Knight M, 2007, EMOTION, V7, P705, DOI 10.1037/1528-3542.7.4.705
   Koch K, 2007, NEUROPSYCHOLOGIA, V45, P2744, DOI 10.1016/j.neuropsychologia.2007.04.012
   Koelsch S, 2006, HUM BRAIN MAPP, V27, P239, DOI 10.1002/hbm.20180
   Koelsch S, 2010, TRENDS COGN SCI, V14, P131, DOI 10.1016/j.tics.2010.01.002
   Kramer AF, 2004, J GERONTOL A-BIOL, V59, P940
   Lambrecht L, 2012, EMOTION, V12, P529, DOI 10.1037/a0026827
   Laukka P, 2007, MOTIV EMOTION, V31, P182, DOI 10.1007/s11031-007-9063-z
   Laukka P, 2013, EMOTION, V13, P434, DOI 10.1037/a0031388
   LIMA C. F., 2009, TIPI INVENTARIO PERS
   LIMA C. F., 2009, QA QUOCIENTE ESPECTR
   Lima CF, 2014, EMOTION, V14, P145, DOI 10.1037/a0034287
   Lima CF, 2013, J CLIN EXP NEUROPSYC, V35, P373, DOI 10.1080/13803395.2013.776518
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Lima CF, 2011, COGNITION EMOTION, V25, P585, DOI 10.1080/02699931.2010.502449
   Livingstone SR, 2010, COMPUT MUSIC J, V34, P41, DOI 10.1162/comj.2010.34.1.41
   Mather M, 2005, TRENDS COGN SCI, V9, P496, DOI 10.1016/j.tics.2005.08.005
   Mather M, 2005, PSYCHOL AGING, V20, P554, DOI 10.1037/0882-7974.20.4.554
   Mill A, 2009, EMOTION, V9, P619, DOI 10.1037/a0016562
   Mitchell RLC, 2007, COGNITION EMOTION, V21, P1435, DOI 10.1080/02699930601133994
   Mitchell RLC, 2011, PSYCHOL AGING, V26, P406, DOI 10.1037/a0021861
   Mitterschiffthaler MT, 2007, HUM BRAIN MAPP, V28, P1150, DOI 10.1002/hbm.20337
   Moreno S, 2011, PSYCHOL SCI, V22, P1425, DOI 10.1177/0956797611416999
   Moreno S, 2009, CEREB CORTEX, V19, P712, DOI 10.1093/cercor/bhn120
   Mu QW, 1999, AM J NEURORADIOL, V20, P207
   Orbelo DM, 2005, J GERIATR PSYCH NEUR, V18, P25, DOI 10.1177/0891988704272214
   Orgeta V, 2010, J GERONTOL B-PSYCHOL, V65, P323, DOI 10.1093/geronb/gbq007
   Patel A. D., 2008, Music, Language, and the Brain
   Paulmann S, 2008, BRAIN LANG, V104, P262, DOI 10.1016/j.bandl.2007.03.002
   Peelle JE, 2012, NEUROIMAGE, V60, P1503, DOI 10.1016/j.neuroimage.2011.12.086
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   Peretz I., 2010, HDB MUSIC EMOTION TH
   Péron J, 2010, NEUROPSYCHOLOGIA, V48, P1053, DOI 10.1016/j.neuropsychologia.2009.12.003
   Poljac E, 2013, AUTISM, V17, P668, DOI 10.1177/1362361312455703
   Raz N, 2003, AM J NEURORADIOL, V24, P1849
   Raz N, 2005, CEREB CORTEX, V15, P1676, DOI 10.1093/cercor/bhi044
   Reed AE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00339
   Resnicow JE, 2004, MUSIC PERCEPT, V22, P145, DOI 10.1525/mp.2004.22.1.145
   Riediger M, 2011, COGNITION EMOTION, V25, P968, DOI 10.1080/02699931.2010.540812
   Ruffman T, 2008, NEUROSCI BIOBEHAV R, V32, P863, DOI 10.1016/j.neubiorev.2008.01.001
   Ruffman T, 2009, J GERONTOL B-PSYCHOL, V64, P696, DOI 10.1093/geronb/gbp072
   Ryan M, 2010, EXP AGING RES, V36, P1, DOI 10.1080/03610730903418372
   Salimpoor VN, 2011, NAT NEUROSCI, V14, P257, DOI 10.1038/nn.2726
   Salimpoor VN, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0007487
   Salthouse TA, 2009, NEUROBIOL AGING, V30, P507, DOI 10.1016/j.neurobiolaging.2008.09.023
   Sauter DA, 2010, Q J EXP PSYCHOL, V63, P2251, DOI 10.1080/17470211003721642
   Schellenberg EG, 2006, J EDUC PSYCHOL, V98, P457, DOI 10.1037/0022-0663.98.2.457
   Simoes M., 2007, MONTREAL COGNITIVE A
   Stewart L, 2003, NEUROIMAGE, V20, P71, DOI 10.1016/S1053-8119(03)00248-9
   STJACQUES P, 2008, NEUROBIOL AGING, V31, P315
   Sullivan S, 2004, BRIT J PSYCHOL, V95, P1, DOI 10.1348/000712604322779424
   Trenerry M. R, 1995, STROOP NEUROPSYCHOLO
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   Vieillard S, 2012, EXP AGING RES, V38, P422, DOI 10.1080/0361073X.2012.699371
   von dem Hagen EAH, 2011, CEREB CORTEX, V21, P493, DOI 10.1093/cercor/bhq062
   WAGNER HL, 1993, J NONVERBAL BEHAV, V17, P3, DOI 10.1007/BF00987006
   Walhovd KB, 2005, NEUROBIOL AGING, V26, P1261, DOI 10.1016/j.neurobiolaging.2005.05.020
   Walhovd KB, 2011, NEUROBIOL AGING, V32, P916, DOI 10.1016/j.neurobiolaging.2009.05.013
   Williams LM, 2006, J NEUROSCI, V26, P6422, DOI 10.1523/JNEUROSCI.0022-06.2006
   Williams LM, 2009, J CLIN EXP NEUROPSYC, V31, P257, DOI 10.1080/13803390802255635
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 119
TC 38
Z9 40
U1 2
U2 45
PU UNIV CALIFORNIA PRESS
PI OAKLAND
PA 155 GRAND AVE, SUITE 400, OAKLAND, CA 94612-3758 USA
SN 0730-7829
J9 MUSIC PERCEPT
JI Music Percept.
PD DEC
PY 2014
VL 32
IS 2
BP 125
EP 142
DI 10.1525/MP.2014.32.2.125
PG 18
WC Music; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music; Psychology
GA AX4BT
UT WOS:000346879800002
OA Green Published
DA 2024-01-09
ER

PT J
AU Juslin, PN
   Lindström, E
AF Juslin, Patrik N.
   Lindstrom, Erik
TI MUSICAL EXPRESSION OF EMOTIONS: MODELLING LISTENERS' JUDGEMENTS OF
   COMPOSED AND PERFORMED FEATURES
SO MUSIC ANALYSIS
LA English
DT Article
ID VOCAL EXPRESSION; CUE UTILIZATION; COMMUNICATION; PITCH; RECOGNITION;
   PERCEPTION
AB Music is commonly regarded as expressive of emotions that can be perceived by listeners. Nevertheless, the specific characteristics of this perceptual process are not well understood. This study aims to investigate the relationships between various features of musical structure and the emotions perceived by listeners, with a focus on the role of interactions among such features. Eight musical features (pitch, mode, melodic progression, rhythm, tempo, sound level, articulation and timbre) were systematically manipulated in a factorial design through synthesis. Ten musically trained listeners judged the resulting 384 pieces of music on five emotion scales. The relationships between musical features and listener judgements were modelled by means of multiple regression analysis. The results (1) confirmed empirically based predictions from previous post hoc analyses with respect to which musical features are associated with each emotion; (2) suggested that different musical features were important for different emotions; (3) indicated that some features (e. g. tempo) were more powerful than others overall; and (4) revealed that interactions made significant but small contributions to the predictive power of the regression models.
C1 [Juslin, Patrik N.; Lindstrom, Erik] Uppsala Univ, Uppsala, Sweden.
C3 Uppsala University
RP Juslin, PN (corresponding author), Uppsala Univ, Uppsala, Sweden.
CR Adachi M., 1998, PSYCHOL MUSIC, V26, P133, DOI [DOI 10.1177/0305735698262003, 10.1177/0305735698262003]
   [Anonymous], MUSIC EXPRESSION
   [Anonymous], EMOTION REV IN PRESS
   [Anonymous], EXPT DESIGN PROCEDUR
   [Anonymous], OXFORD COMPANION EMO
   [Anonymous], P 17 C INT ASS EMP A
   [Anonymous], 2001, Music and Emotion, DOI DOI 10.1525/MP.2004.21.4.561
   [Anonymous], 1994, Stolen Time, History of Tempo Rubato
   [Anonymous], 1986, SCI BEHAV INTRO METH
   Bach C. P. E., 1992, VERSUCH WAHRE ART CL
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Boersma P., 1999, PRAAT 3 8 24 COMPUTE
   Bresin R, 2000, COMPUT MUSIC J, V24, P44, DOI 10.1162/014892600559515
   Brunswik E., 1956, Perception and the representative design of psychological experiments, V2nd
   Budd M., 1985, Music and the Emotions: The Philosophical Theories
   COHEN J, 1978, PSYCHOL BULL, V85, P858, DOI 10.1037/0033-2909.85.4.858
   Cohen J., 2002, Applied Multiple Correlation/Regression Analysis for the Behavioral Sciences, V3rd, DOI [DOI 10.1002/0471264385.WEI0219, 10.1002/0471264385.wei0219, 10.4324/9780203774441]
   Cooke, 1959, LANGUAGE MUSIC
   Cooksey R. W., 1996, Judgment Analysis: Theory, Methods, and Applications
   Downey June E., 1897, J PSYCHOL, V9/i, P63
   Farnell Andy, 2008, DESIGNING SOUND
   Ferguson CJ, 2009, PROF PSYCHOL-RES PR, V40, P532, DOI 10.1037/a0015808
   FONAGY I, 1978, LANG SPEECH, V21, P34, DOI 10.1177/002383097802100102
   FRIBERG A, 2002, P INT COMP MUS C GOT, P365
   Gabrielsson A, 2003, SER AFFECTIVE SCI, P503
   Gabrielsson A., 1995, Psychomusicol. J. Res. Music Cogn, V14, P94, DOI DOI 10.1037/H0094089
   GILMAN BI, 1892, AM J PSYCHOL, V4, P558, DOI DOI 10.2307/1410803
   Hair J. F., 2017, Multivariate data analysis, V2nd
   Harrigan J. A., 2005, NEW HDB METHODS NONV, P65, DOI DOI 10.1093/ACPROF:OSO/9780198529620.003.0003
   HATTEN Robert S., 1994, Musical Meaning in Beethoven: Markedness, Correlation, and Interpretation
   Hevner K, 1935, PSYCHOL REV, V42, P186, DOI 10.1037/h0054832
   Hevner K, 1937, AM J PSYCHOL, V49, P621, DOI 10.2307/1416385
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   IMBERTY M, 1979, ENTENDRE MUSIQUE SEM
   Juslin P., 2010, Handbook of Music and Emotion: Theory, Research, Applications, P453, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0017
   Juslin P. N., 2000, MUSICAE SCI, V4, P151, DOI DOI 10.1177/102986490000400202
   Juslin P. N., 2011, Music and the mind: Essays in honour of John Sloboda, P113
   Juslin P. N., 1996, PSYCHOL MUSIC, V24, P68, DOI [10.1177/0305735696241007, DOI 10.1177/0305735696241007]
   Juslin P. N., 2004, MUSICAL EXCELLENCE S, P247
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2006, J EXP PSYCHOL-APPL, V12, P79, DOI 10.1037/1076-898X.12.2.79
   Juslin PN, 2001, EMOTION, V1, P381, DOI 10.1037//1528-3542.1.4.381
   Juslin Patrik N., 2003, 5 C EUR SOC COGN SCI
   Juslin Patrik N., 1998, COMPREHENSIVE SUMMAR, V78, P1
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Juslin PN, 1999, MUSIC PERCEPT, V17, P197
   Juslin PN, 1997, MUSIC PERCEPT, V14, P383
   Juslin PN., 2001, Music and Emotion, P309, DOI 10.1093/oso/9780192631886.003.0014
   Juslin PN, 1997, MUSIC SCI, V1, P225, DOI DOI 10.1177/102986499700100205
   Kalawski JP, 2010, MOTIV EMOTION, V34, P158, DOI 10.1007/s11031-010-9164-y
   Kotlyar G.M., 1976, SOV PHYS ACOUST, V22, P370
   Krumhansl CL, 1997, CAN J EXP PSYCHOL, V51, P336, DOI 10.1037/1196-1961.51.4.336
   Leech- Wilkinson Daniel, 2006, NORDISK ESTETISK TID, V33, P50
   Lindström E, 2006, MUSIC SCI, V10, P85, DOI 10.1177/102986490601000105
   Lindström E, 2003, J NEW MUSIC RES, V32, P269, DOI 10.1076/jnmr.32.3.269.16865
   Lindstrom Erik, 1999, M SOC MUS PERC COGN
   Makris I, 2003, AM J PSYCHOL, V116, P581, DOI 10.2307/1423661
   Peeters G., 2004, tech. report
   Pierce CA, 2004, EDUC PSYCHOL MEAS, V64, P916, DOI 10.1177/0013164404264848
   Resnicow JE, 2004, MUSIC PERCEPT, V22, P145, DOI 10.1525/mp.2004.22.1.145
   Rigg M. G., 1940, J MUSICOLOGY, V2, P49
   RIGG MG, 1942, PHILOS ESSAYS HONOR, P279
   Russ Martin, 2008, SOUND SYNTHESIS SAMP
   Schellenberg EG, 2000, MUSIC PERCEPT, V18, P155
   Scherer K., 1977, MOTIV EMOTION, V1, P331, DOI [DOI 10.1007/BF00992539, 10.1007/bf00992539]
   SHAVER P, 1987, J PERS SOC PSYCHOL, V52, P1061, DOI 10.1037/0022-3514.52.6.1061
   SPENCER H, 1857, FRASERS MAGAZINE, V56, P396, DOI DOI 10.1017/S0140525X08005293
   Thompson W.F., 2010, Handbook of music and emotion: Theory, research, and applications, P755
   WEDIN L, 1972, SCAND J PSYCHOL, V13, P241, DOI 10.1111/j.1467-9450.1972.tb00072.x
   Wieczorkowska Alicja A., 2010, ADV MUSIC INFORM RET
NR 71
TC 63
Z9 71
U1 1
U2 38
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0262-5245
EI 1468-2249
J9 MUSIC ANAL
JI Music Anal.
PD MAR-OCT
PY 2010
VL 29
IS 1-3
SI SI
BP 334
EP 364
DI 10.1111/j.1468-2249.2011.00323.x
PG 31
WC Music
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music
GA 846MY
UT WOS:000296909100015
DA 2024-01-09
ER

PT J
AU Coutinho, E
   Dibben, N
AF Coutinho, Eduardo
   Dibben, Nicola
TI Psychoacoustic cues to emotion in speech prosody and music
SO COGNITION & EMOTION
LA English
DT Article
DE Emotion; Arousal and valence; Music; Speech prosody; Psychoacoustics;
   Neural networks
ID VOCAL EXPRESSION; MODEL; COMMUNICATION; PERFORMANCE; RESPONSES;
   CORRELATE; WESTERN
AB There is strong evidence of shared acoustic profiles common to the expression of emotions in music and speech, yet relatively limited understanding of the specific psychoacoustic features involved. This study combined a controlled experiment and computational modelling to investigate the perceptual codes associated with the expression of emotion in the acoustic domain. The empirical stage of the study provided continuous human ratings of emotions perceived in excerpts of film music and natural speech samples. The computational stage created a computer model that retrieves the relevant information from the acoustic stimuli and makes predictions about the emotional expressiveness of speech and music close to the responses of human subjects. We show that a significant part of the listeners' second-by-second reported emotions to music and speech prosody can be predicted from a set of seven psychoacoustic features: loudness, tempo/speech rate, melody/prosody contour, spectral centroid, spectral flux, sharpness, and roughness. The implications of these results are discussed in the context of cross-modal similarities in the communication of emotion in the acoustic domain.
C1 [Coutinho, Eduardo] Univ Geneva, Swiss Ctr Affect Sci, CH-1205 Geneva, Switzerland.
   [Coutinho, Eduardo] Univ Liverpool, Sch Mus, Liverpool L69 3BX, Merseyside, England.
   [Dibben, Nicola] Univ Sheffield, Mus Dept, Sheffield, S Yorkshire, England.
C3 University of Geneva; University of Liverpool; University of Sheffield
RP Coutinho, E (corresponding author), Univ Geneva, Swiss Ctr Affect Sci, 7 Rue Battoirs, CH-1205 Geneva, Switzerland.
EM eduardo.coutinho@unige.ch
RI Coutinho, Eduardo/K-1391-2019
OI Coutinho, Eduardo/0000-0001-5234-1497; Dibben,
   Nicola/0000-0002-9250-5035
CR [Anonymous], 2004, CAHIERS I LINGUISTIQ
   [Anonymous], 2007, P AUD MOSTL C
   [Anonymous], 2010, Handbook of Music and Emotion
   [Anonymous], 1999, CIN CENT MUS CEL 100
   [Anonymous], COMMUNICATION
   [Anonymous], 2001, THESIS U CALIFORNIA
   [Anonymous], 1999, PSYCHOACOUSTICS FACT, DOI DOI 10.1007/978-3-662-09562-1
   [Anonymous], 1999, THESIS U NEW S WALES
   [Anonymous], 1997, SCI FI MOVIES
   [Anonymous], 2009, SIMPLY SOUNDTRACKS
   [Anonymous], 2004, COMMUNICATION
   [Anonymous], 1999, SIMPLY FILM THEMES
   [Anonymous], 2005, PSYCTESTS DATASET, DOI DOI 10.1037/T66667-000
   [Anonymous], COMMUNICATION
   Arendt Erich, ORPHISCHE BUCHT
   AURES W, 1985, ACUSTICA, V58, P268
   Bachorowski JA, 2003, ANN NY ACAD SCI, V1000, P244, DOI 10.1196/annals.1280.012
   Bachorowski JA, 2001, PSYCHOL SCI, V12, P252, DOI 10.1111/1467-9280.00346
   Balkwill LL, 2004, JPN PSYCHOL RES, V46, P337, DOI 10.1111/j.1468-5584.2004.00265.x
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Brunswik E., 1956, Perception and the representative design of psychological experiments, V2nd
   Chalupper J, 2002, ACTA ACUST UNITED AC, V88, P378
   Colibazzi T, 2010, EMOTION, V10, P377, DOI 10.1037/a0018484
   Coutinho E., 2010, ADV COGNITIVE SYSTEM, P331
   Coutinho E., 2010, P 11 INT C MUS PERC, P53
   Coutinho E, 2011, EMOTION, V11, P921, DOI 10.1037/a0024700
   Coutinho E, 2009, MUSIC PERCEPT, V27, P1, DOI 10.1525/MP.2009.27.1.1
   Daniel P, 1997, ACUSTICA, V83, P113
   de Jong NH, 2009, BEHAV RES METHODS, V41, P385, DOI 10.3758/BRM.41.2.385
   Dixon S., 2006, MIREX 2006 AUDIO BEA
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   EKMAN P, 1992, PSYCHOL SCI, V3, P34, DOI 10.1111/j.1467-9280.1992.tb00253.x
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   FRICK RW, 1985, PSYCHOL BULL, V97, P412, DOI 10.1037/0033-2909.97.3.412
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Gabrielsson A, 2003, SER AFFECTIVE SCI, P503
   Gabrielsson A., 2010, HDB MUSIC EMOTION TH, P367, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0014
   Gabrielsson A, 2001, MUSIC SCI, V5, P123, DOI 10.1177/10298649020050S105
   Grewe O, 2007, EMOTION, V7, P774, DOI 10.1037/1528-3542.7.4.774
   HUTCHINSON W, 1978, INTERFACE-J NEW MUS, V7, P1, DOI 10.1080/09298217808570246
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Ilie G, 2011, MUSIC PERCEPT, V28, P247, DOI 10.1525/MP.2011.28.3.247
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 1997, MUSIC PERCEPT, V14, P383
   Konzack Andreas, LEHRE VIER TEMPERAME
   Larsen JT, 2011, J PERS SOC PSYCHOL, V100, P1095, DOI 10.1037/a0021846
   Lumet Sidney, 1976, COMMUNICATION
   Owren MJ, 1997, PERSP ETHOL, V12, P299
   Patel AD, 1998, BRAIN LANG, V61, P123, DOI 10.1006/brln.1997.1862
   Patel AD, 2010, MUSIC LANGUAGE BRAIN
   Peretz I, 2001, ANN NY ACAD SCI, V930, P153, DOI 10.1111/j.1749-6632.2001.tb05731.x
   ROCHE CJ, COMMUNICATION
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Schachner A, 2011, DEV PSYCHOL, V47, P19, DOI 10.1037/a0020740
   Scheirer E, 1997, INT CONF ACOUST SPEE, P1331, DOI 10.1109/ICASSP.1997.596192
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   SCHERER KR, 1982, SOC SCI INFORM, V21, P555, DOI 10.1177/053901882021004004
   Schubert E, 1999, AUST J PSYCHOL, V51, P154, DOI 10.1080/00049539908255353
   Sethares W. A., 2004, Tuning, timbre, spectrum, scale
   Thompson WF, 2006, SEMIOTICA, V158, P407, DOI 10.1515/SEM.2006.017
   TOLKMITT F, 1982, J COMMUN DISORD, V15, P209, DOI 10.1016/0021-9924(82)90034-X
   Trainor LJ, 1998, INFANT BEHAV DEV, V21, P77, DOI 10.1016/S0163-6383(98)90055-8
   VONDONNERSMARCK FH, 2006, LEBEN ANDEREN
   Webster GD, 2005, MOTIV EMOTION, V29, P19, DOI 10.1007/s11031-005-4414-0
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 68
TC 65
Z9 69
U1 0
U2 44
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 0269-9931
EI 1464-0600
J9 COGNITION EMOTION
JI Cogn. Emot.
PD JUN 1
PY 2013
VL 27
IS 4
BP 658
EP 684
DI 10.1080/02699931.2012.732559
PG 27
WC Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Psychology
GA 146QV
UT WOS:000319106500006
PM 23057507
DA 2024-01-09
ER

PT J
AU Tang, Y
   Zeng, XL
AF Tang, Yu
   Zeng, Xiaoli
TI Application of intelligent audio data based on hash storage in vocal
   music teaching platform
SO SOFT COMPUTING
LA English
DT Article; Early Access
DE Hash storage; Intelligent audio data; DTW algorithm; Vocal platform
ID SYSTEM
AB In this paper, the fast algorithm of audio retrieval is more about the template matching process of audio feature parameters. Nowadays, people regard vocal music learning as a way to relax the mood, because vocal music not only helps people vent their emotions and convey their heartfelt thoughts, but also helps regulate our body and mind. Aiming at these problems, this paper designs a vocal self-study assistant system. The vocal self-study assistant system introduces the latest technology, which can enable people to learn vocal music anywhere and anytime. First of all, the search time is reduced through the hash structure, and the search efficiency is improved. The index structure proposed in this paper includes two parts: the surface layer of the hash table and the tree layer of the hash tree. A hash tree structure that can perfectly adapt to changes in the amount of data is also proposed. In addition, this article also introduces the efficient search algorithm built by the hash tree index. According to the experimental results, it can be found that the intelligent audio data rapid retrieval algorithm using the image registration method is similar to the intelligent audio retrieval algorithm based on the DTW algorithm. Compared with the former, it is more accurate. Therefore, the retrieval algorithm in this article can be applied to intelligent audio retrieval technology based on content and semantics.
C1 [Tang, Yu] Aba Teachers Univ, Sch Mus & Dance, Aba 623002, Sichuan, Peoples R China.
   [Zeng, Xiaoli] Sichuan Inst Ind Technol, Sch Educ, Deyang 621000, Sichuan, Peoples R China.
C3 Aba Teachers University
RP Zeng, XL (corresponding author), Sichuan Inst Ind Technol, Sch Educ, Deyang 621000, Sichuan, Peoples R China.
EM 13550640360@163.com
RI zhang, yue/JAC-3705-2023
CR Debnath S. K., 2019, Indones. J. Electr. Eng. Comput. Sci, V15, P743, DOI DOI 10.11591/IJEECS.V15.I2.PP743-749
   Dyganova EA, 2015, PROCD SOC BEHV, V191, P1750, DOI 10.1016/j.sbspro.2015.04.718
   Gorbunova IB., 2019, INT J INNOV CREAT CH, V9, P683
   Hamidi M, 2018, BIOMED SIGNAL PROCES, V39, P351, DOI 10.1016/j.bspc.2017.08.002
   Kossaifi J, 2021, IEEE T PATTERN ANAL, V43, P1022, DOI 10.1109/TPAMI.2019.2944808
   Lyu D, 2021, INT J EMERG TECHNOL, V16, P171, DOI 10.3991/ijet.v16i18.25665
   Murphy D, 2021, EXP ASTRON, V52, P1, DOI 10.1007/s10686-021-09767-z
   Ren YJ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010207
   Rifaioglu AS, 2019, BRIEF BIOINFORM, V20, P1878, DOI 10.1093/bib/bby061
   Sun YX, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12136713
   Del Rio-Guerra MS, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9214527
   Vavrek J, 2018, J INTELL INF SYST, V51, P439, DOI 10.1007/s10844-018-0499-2
   Xu Cuiping., 2022, Computer-Aided Design and Applications, V19, P119, DOI [https://doi.org/10.14733/CADAPS.2022.S3.119-129, DOI 10.14733/CADAPS.2022.S3.119-129, 10.14733/cadaps.2022.S3.119-129]
   Zeng DH, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3387164
NR 14
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1432-7643
EI 1433-7479
J9 SOFT COMPUT
JI Soft Comput.
PD 2023 AUG 11
PY 2023
DI 10.1007/s00500-023-09118-4
EA AUG 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O9XL4
UT WOS:001047273000002
DA 2024-01-09
ER

PT S
AU Agustus, JL
   Mahoney, CJ
   Downey, LE
   Omar, R
   Cohen, M
   White, MJ
   Scott, SK
   Mancini, L
   Warren, JD
AF Agustus, Jennifer L.
   Mahoney, Colin J.
   Downey, Laura E.
   Omar, Rohani
   Cohen, Miriam
   White, Mark J.
   Scott, Sophie K.
   Mancini, Laura
   Warren, Jason D.
BE Bigand, E
   Tillmann, B
   Peretz, I
   Zatorre, RJ
   Lopez, L
   Majno, M
TI Functional MRI of music emotion processing in frontotemporal dementia
SO NEUROSCIENCES AND MUSIC V: COGNITIVE STIMULATION AND REHABILITATION
SE Annals of the New York Academy of Sciences
LA English
DT Article; Proceedings Paper
CT Conference on Neurosciences and Music V
CY MAY 29-JUN 01, 2014
CL Dijon, FRANCE
DE music; voice; emotion; fMRI; bvFTD; musicophilia
ID SELECTIVE LOSS; BRAIN; PERCEPTION; REWARD; CORTEX; RECOGNITION;
   DISSONANCE; RESPONSES; DISEASE; VARIANT
AB Frontotemporal dementia is an important neurodegenerative disorder of younger life led by profound emotional and social dysfunction. Here we used fMRI to assess brain mechanisms of music emotion processing in a cohort of patients with frontotemporal dementia (n=15) in relation to healthy age-matched individuals (n=11). In a passive-listening paradigm, we manipulated levels of emotion processing in simple arpeggio chords (mode versus dissonance) and emotion modality (music versus human emotional vocalizations). A complex profile of disease-associated functional alterations was identified with separable signatures of musical mode, emotion level, and emotion modality within a common, distributed brain network, including posterior and anterior superior temporal and inferior frontal cortices and dorsal brainstem effector nuclei. Separable functional signatures were identified post-hoc in patients with and without abnormal craving for music (musicophilia): a model for specific abnormal emotional behaviors in frontotemporal dementia. Our findings indicate the potential of music to delineate neural mechanisms of altered emotion processing in dementias, with implications for future disease tracking and therapeutic strategies.
C1 [Agustus, Jennifer L.; Mahoney, Colin J.; Downey, Laura E.; Omar, Rohani; Cohen, Miriam; Warren, Jason D.] UCL, Dementia Res Ctr, UCL Inst Neurol, London WC1N 3BG, England.
   [White, Mark J.; Mancini, Laura] UCL, Neuroradiol Acad Unit, UCL Inst Neurol, Dept Brain Repair & Rehabil, London WC1N 3BG, England.
   [White, Mark J.; Mancini, Laura] Natl Hosp Neurol & Neurosurg, Lysholm Dept Neuroradiol, London WC1N 3BG, England.
   [Scott, Sophie K.] UCL, Inst Cognit Neurosci, London WC1N 3BG, England.
C3 University of London; University College London; University of London;
   University College London; University of London; University College
   London; UCL Medical School; University College London Hospitals NHS
   Foundation Trust; University of London; University College London
RP Warren, JD (corresponding author), UCL, Dementia Res Ctr, UCL Inst Neurol, 8-11 Queen Sq, London WC1N 3BG, England.
EM jason.warren@ucl.ac.uk
RI Downey, Laura/AAQ-7913-2021; Scott, Sophie K/A-1843-2010; Mahoney,
   Colin/AAJ-5384-2021
OI Scott, Sophie K/0000-0001-7510-6297; Mahoney, Colin/0000-0002-5878-3859;
   Downey, Laura/0000-0002-9563-7113; Mancini, Laura/0000-0002-4596-3551;
   Warren, Jason/0000-0002-5405-0826
FU Alzheimers Research UK [ART-PhD2011-10] Funding Source: researchfish;
   Medical Research Council Funding Source: Medline; Wellcome Trust
   [090961, 091673, 091673/Z/10/Z] Funding Source: Medline; Wellcome Trust
   [091673/Z/10/Z] Funding Source: Wellcome Trust
CR Abrams DA, 2013, P NATL ACAD SCI USA, V110, P12060, DOI 10.1073/pnas.1302982110
   Ashburner J, 2007, NEUROIMAGE, V38, P95, DOI 10.1016/j.neuroimage.2007.07.007
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Brattico E, 2009, J COGNITIVE NEUROSCI, V21, P2230, DOI 10.1162/jocn.2008.21144
   Clark C.N., 2014, SOC COGN AFFECT NEUR
   Dara C, 2013, NEUROCASE, V19, P521, DOI 10.1080/13554794.2012.701641
   Dobek CE, 2014, J PAIN, V15, P1057, DOI 10.1016/j.jpain.2014.07.006
   Downey LE, 2013, CORTEX, V49, P1844, DOI 10.1016/j.cortex.2012.09.011
   Fletcher PD, 2014, BRAIN, V137, DOI 10.1093/brain/awu145
   Fletcher PD, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00347
   Fujisawa TX, 2011, BRAIN IMAGING BEHAV, V5, P109, DOI 10.1007/s11682-011-9116-5
   Goll JC, 2012, NEUROIMAGE, V61, P170, DOI 10.1016/j.neuroimage.2012.02.045
   Gosselin N, 2006, BRAIN, V129, P2585, DOI 10.1093/brain/awl240
   Green AC, 2008, NEUROREPORT, V19, P711, DOI 10.1097/WNR.0b013e3282fd0dd8
   Griffiths TD, 2004, J NEUROL NEUROSUR PS, V75, P344
   Griffiths TD, 2002, TRENDS NEUROSCI, V25, P348, DOI 10.1016/S0166-2236(02)02191-4
   Halpern AR, 2008, MUSIC PERCEPT, V25, P181, DOI 10.1525/MP.2008.25.3.181
   HALPERN AR, 1984, MEM COGNITION, V12, P163, DOI 10.3758/BF03198430
   Hsieh S, 2012, NEUROPSYCHOLOGIA, V50, P1814, DOI 10.1016/j.neuropsychologia.2012.04.006
   Keane J, 2002, NEUROPSYCHOLOGIA, V40, P655, DOI 10.1016/S0028-3932(01)00156-7
   Khalfa S, 2005, NEUROREPORT, V16, P1981, DOI 10.1097/00001756-200512190-00002
   Koelsch S, 2006, HUM BRAIN MAPP, V27, P239, DOI 10.1002/hbm.20180
   Koelsch S, 2014, NAT REV NEUROSCI, V15, P170, DOI 10.1038/nrn3666
   Koelsch S, 2013, NEUROIMAGE, V81, P49, DOI 10.1016/j.neuroimage.2013.05.008
   Kreifelts B, 2009, NEUROPSYCHOLOGIA, V47, P3059, DOI 10.1016/j.neuropsychologia.2009.07.001
   Leaver AM, 2004, MUSIC PERCEPT, V22, P117, DOI 10.1525/mp.2004.22.1.117
   Lehne M, 2014, SOC COGN AFFECT NEUR, V9, P1515, DOI 10.1093/scan/nst141
   Mizuno T, 2007, NEUROREPORT, V18, P1651, DOI 10.1097/WNR.0b013e3282f0b787
   Omar R, 2011, NEUROIMAGE, V56, P1814, DOI 10.1016/j.neuroimage.2011.03.002
   Pallesen KJ, 2005, ANN NY ACAD SCI, V1060, P450, DOI 10.1196/annals.1360.047
   Peelen MV, 2010, J NEUROSCI, V30, P10127, DOI 10.1523/JNEUROSCI.2161-10.2010
   Pereira CS, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027241
   Peretz I, 2001, BRAIN, V124, P928, DOI 10.1093/brain/124.5.928
   Rascovsky K, 2011, BRAIN, V134, P2456, DOI 10.1093/brain/awr179
   Salimpoor VN, 2013, SCIENCE, V340, P216, DOI 10.1126/science.1231059
   Satoh M, 2011, NEUROCASE, V17, P410, DOI 10.1080/13554794.2010.532139
   Sauter DA, 2010, Q J EXP PSYCHOL, V63, P2251, DOI 10.1080/17470211003721642
   Stewart L, 2006, BRAIN, V129, P2533, DOI 10.1093/brain/awl171
   Trainor LJ, 2002, MUSIC PERCEPT, V20, P187, DOI 10.1525/mp.2002.20.2.187
   Virtala P, 2011, NEUROSCI LETT, V487, P406, DOI 10.1016/j.neulet.2010.10.066
   Warren JD, 2013, TRENDS NEUROSCI, V36, P561, DOI 10.1016/j.tins.2013.06.007
   Warren JD, 2013, BMJ-BRIT MED J, V347, DOI 10.1136/bmj.f4827
   Watson R, 2014, J NEUROSCI, V34, P6813, DOI 10.1523/JNEUROSCI.4478-13.2014
   Zatorre RJ, 2013, P NATL ACAD SCI USA, V110, P10430, DOI 10.1073/pnas.1301228110
   Zhou J, 2014, BIOL PSYCHIAT, V75, P565, DOI 10.1016/j.biopsych.2014.01.020
NR 45
TC 16
Z9 17
U1 1
U2 37
PU BLACKWELL SCIENCE PUBL
PI OXFORD
PA OSNEY MEAD, OXFORD OX2 0EL, ENGLAND
SN 0077-8923
J9 ANN NY ACAD SCI
JI Ann.NY Acad.Sci.
PY 2015
VL 1337
BP 232
EP 240
DI 10.1111/nyas.12620
PG 9
WC Clinical Neurology; Psychology; Psychology, Experimental; Rehabilitation
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH); Science Citation Index Expanded (SCI-EXPANDED)
SC Neurosciences & Neurology; Psychology; Rehabilitation
GA BC3ER
UT WOS:000351580900031
PM 25773639
OA hybrid, Green Published
DA 2024-01-09
ER

PT J
AU Petrini, K
   McAleer, P
   Pollick, F
AF Petrini, Karin
   McAleer, Phil
   Pollick, Frank
TI Audiovisual integration of emotional signals from music improvisation
   does not depend on temporal correspondence
SO BRAIN RESEARCH
LA English
DT Article
DE Audiovisual integration; Emotion; Music; Psychophysics
ID SYNCHRONY PERCEPTION; VOICE; EXPRESSION; SPEECH; INFORMATION; MOVEMENT;
   FACE
AB In the present study we applied a paradigm often used in face voice affect perception to solo music improvisation to examine how the emotional valence of sound and gesture are integrated when perceiving an emotion. Three brief excerpts expressing emotion produced by a drummer and three by a saxophonist were selected. From these bimodal congruent displays the audio-only, visual-only, and audiovisually incongruent conditions (obtained by combining the two signals both within and between instruments) were derived. In Experiment 1 twenty musical novices judged the perceived emotion and rated the strength of each emotion. The results indicate that sound dominated the visual signal in the perception of affective expression, though this was more evident for the saxophone. In Experiment 2 a further sixteen musical novices were asked to either pay attention to the musicians' movements or to the sound when judging the perceived emotions. The results showed no effect of visual information when judging the sound. On the contrary, when judging the emotional content of the visual information, a worsening in performance was obtained for the incongruent condition that combined different emotional auditory and visual information for the same instrument. The effect of emotionally discordant information thus became evident only when the auditory and visual signals belonged to the same categorical event despite their temporal mismatch. This suggests that the integration of emotional information may be reinforced by its semantic attributes but might be independent from temporal features. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Petrini, Karin; McAleer, Phil; Pollick, Frank] Univ Glasgow, Dept Psychol, Glasgow G12 8QB, Lanark, Scotland.
C3 University of Glasgow
RP Petrini, K (corresponding author), Univ Glasgow, Dept Psychol, 58 Hillhead St, Glasgow G12 8QB, Lanark, Scotland.
EM karin@psy.gla.ac.uk
RI Pollick, Frank/F-3186-2011; McAleer, Phil/A-8178-2011
OI Pollick, Frank/0000-0002-7212-4622; McAleer, Phil/0000-0002-4523-2097;
   Petrini, Karin/0000-0001-5354-5600
FU ESRC [RES-060-25-0010]; Economic and Social Research Council
   [ES/E020933/1] Funding Source: researchfish; Medical Research Council
   [MC_G1001214] Funding Source: researchfish; ESRC [ES/E020933/1] Funding
   Source: UKRI; MRC [MC_G1001214] Funding Source: UKRI
FX This work was supported by grants from the ESRC (RES-060-25-0010). We
   would also like to thank the two musicians Simon Pauley and Szymon
   Ostasz for their valuable contribution.
CR [Anonymous], PSYCHOL MUSIC, DOI [10.1177/0305735600282007, DOI 10.1177/0305735600282007]
   Arrighi R, 2006, J VISION, V6, P260, DOI 10.1167/6.3.6
   Behrens Gene Ann, 1993, Psychology of Music, V21, P20, DOI DOI 10.1177/030573569302100102
   BERTELSON P, 2004, SPACE CROSSMODAL ATT, P141
   Broughton M, 2009, PSYCHOL MUSIC, V37, P137, DOI 10.1177/0305735608094511
   Campanella S, 2007, TRENDS COGN SCI, V11, P535, DOI 10.1016/j.tics.2007.10.001
   Castellano G, 2008, MUSIC PERCEPT, V26, P103, DOI 10.1525/MP.2008.26.2.103
   Collignon O, 2008, BRAIN RES, V1242, P126, DOI 10.1016/j.brainres.2008.04.023
   Dahl S, 2007, MUSIC PERCEPT, V24, P433, DOI 10.1525/MP.2007.24.5.433
   Davidson J., 1994, J HUMAN MOVEMENT STU, V6, P279
   Davidson JW., 1993, PSYCHOL MUSIC, V21, P103, DOI [10.1177/030573569302100201, DOI 10.1177/030573569302100201]
   de Gelder B, 2000, COGNITION EMOTION, V14, P289, DOI 10.1080/026999300378824
   Ekman P., 1975, Unmasking the Face
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Ernst MO, 2004, TRENDS COGN SCI, V8, P162, DOI 10.1016/j.tics.2004.02.002
   HIETANEN JK, 2008, EUR J COGN PSYCHOL, V16, P769
   Juslin P. N., 2011, HDB MUSIC EMOTION TH
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kreifelts B, 2007, NEUROIMAGE, V37, P1445, DOI 10.1016/j.neuroimage.2007.06.020
   LANDY MS, 1995, VISION RES, V35, P389, DOI 10.1016/0042-6989(94)00176-M
   Massaro DW, 1996, PSYCHON B REV, V3, P215, DOI 10.3758/BF03212421
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Petrini K, 2009, EXP BRAIN RES, V198, P339, DOI 10.1007/s00221-009-1817-2
   Petrini K, 2009, COGNITION, V110, P432, DOI 10.1016/j.cognition.2008.11.015
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   SCHUTZ M, 2008, J ACOUST SOC AM, V123, P3412
   Stein B. E., 1993, MERGING SENSES
   Thompson WF, 2008, COGNITION EMOTION, V22, P1457, DOI 10.1080/02699930701813974
   Vatakis A, 2006, NEUROSCI LETT, V393, P40, DOI 10.1016/j.neulet.2005.09.032
   Vatakis A, 2008, ACTA PSYCHOL, V127, P12, DOI 10.1016/j.actpsy.2006.12.002
   Vatakis A, 2007, PERCEPT PSYCHOPHYS, V69, P744, DOI 10.3758/BF03193776
   Vatakis A, 2006, BRAIN RES, V1111, P134, DOI 10.1016/j.brainres.2006.05.078
   Vines BW, 2006, COGNITION, V101, P80, DOI 10.1016/j.cognition.2005.09.003
NR 33
TC 28
Z9 32
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0006-8993
EI 1872-6240
J9 BRAIN RES
JI Brain Res.
PD APR 6
PY 2010
VL 1323
BP 139
EP 148
DI 10.1016/j.brainres.2010.02.012
PG 10
WC Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Neurosciences & Neurology
GA 583MJ
UT WOS:000276680300015
PM 20153297
DA 2024-01-09
ER

PT J
AU Ngo, T
   Spreadborough, K
AF Ngo, Thu
   Spreadborough, Kristal
TI Exploring a systemic functional semiotics approach to understanding
   emotional expression in singing performance: Implications for music
   education
SO RESEARCH STUDIES IN MUSIC EDUCATION
LA English
DT Article
DE emotion; expressivity; lyrics; music literacy education; popular music;
   sung voice; systemic functional semiotics
ID SONGS
AB Engagement with songs through performance and analysis is a key component of music curricula worldwide. Music learning has a significant impact on a number of student competencies. including enhancing students' communicative abilities as they learn to manipulate, express, and share sound in both voice qualities and lyrics. However, common analyses of singing performance rarely focus exclusively on voice quality, and there is no systematic framework which considers how emotional meaning in lyrics interacts with emotional meaning in voice quality. Drawing on systemic functional semiotics, this article proposes a unified theoretical framework for examining how emotional meaning is co-constructed in the voice and lyrics in singing performance. This framework provides a novel approach for discussing and teaching song analysis and performance. The framework will be illustrated through the analysis of the interaction between voice quality and lyrics in the song "Someone Like You" performed by Adele.
C1 [Ngo, Thu] Australian Catholic Univ, Language & Literacy Educ, Strathfield, NSW, Australia.
   [Spreadborough, Kristal] Univ Melbourne, Melbourne Data Analyt Platform, Melbourne, Vic, Australia.
C3 Australian Catholic University; Australian Catholic University -
   Strathfield Campus; University of Melbourne
RP Ngo, T (corresponding author), Australian Catholic Univ, Fac Arts & Educ, Language & Literacy, Sch Educ, Level 2-Off 613-1-44,St Edmund Bldg,25A Barker Rd, Strathfield, NSW 2135, Australia.
EM thu.ngo@acu.edu.au
OI Ngo, Thu/0000-0002-6101-2684
CR Adkins A., 2011, SOMEONE YOU ADELE 21
   American Academy of Teachers of Singing, 2008, J SINGING, V65, P7
   [Anonymous], 2000, READING POP APPROACH
   [Anonymous], 2010, READING SONG LYRICS
   [Anonymous], 2015, FUNCTIONAL LINGUISTI, DOI DOI 10.1186/S40554-015-0013-X
   [Anonymous], 2000, THESIS U LIVERPOOL
   Ashley M., 2015, SINGING LOWER SECOND
   Ashtiani F.T., 2015, ADV LANGUAGE LIT STU, V6, P225
   Australian Curriculum, LEARN MUS STRUCT
   Bonshor M, 2017, BRIT J MUSIC EDUC, V34, P115, DOI 10.1017/S0265051716000437
   Canadian Department of Education, MUS ED FRAM
   Clark M.R., 2002, SINGING ACTING MOVEM
   Clarke E., 2005, Ways of listening: An ecological approach to the perception of musical meaning
   Coffin B., 1987, SOUNDS SINGING VOCAL
   Cox Arnie, 2011, MUSIC THEORY ONLINE, V17, DOI DOI 10.30535/MTO.17.2.1
   Dalladay C, 2017, BRIT J MUSIC EDUC, V34, P321, DOI 10.1017/S0265051717000110
   Davis GM, 2017, ELT J, V71, P445, DOI 10.1093/elt/ccw097
   Eerola T, 2013, MUSIC PERCEPT, V30, P307, DOI [10.1525/mp.2012.30.3.307, 10.1525/MP.2012.30.1.49]
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   English Department for Education, 2011, IMP MUS NAT PLAN MUS
   Fant G, 1970, ACOUSTIC THEORY SPEE
   GREEN L., 2008, Music, Informal Learning and the School: A New Classroom Pedagogy
   Hansen D., 2014, The music and literacy connection
   Heidemann K, 2016, MUSIC THEORY ONLINE, V22
   Hoch M., 2017, VOICE SPEECH REV, V11, P308, DOI DOI 10.1080/23268263.2017.1395591
   Hoch M., 2019, VOICE SPEECH REV, V13, P43, DOI DOI 10.1080/23268263.2018.1527585
   Hood S, 2010, APPRAISING RESEARCH: EVALUATION IN ACADEMIC WRITING, P1
   Hu Y., 2009, P 10 INT SOC MUS INF
   Hughes D., 2007, THESIS U W SYDNEY
   Ida Bagus Nyoman M., 2018, INT J LINGUISTICS LI, V4, P69, DOI [10.21744/ijllc.v4n4.268, DOI 10.21744/IJLLC.V4N4.268]
   Johnstone T., 2000, Handbook of Emotions, V2nd ed., P220
   Juslin P. N., 2010, Handbook of music and emotion: Theory, research, applications, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0022
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Keskinen A., 2013, THESIS U ARTS HELSIN
   Knudsen BT, 2015, AFFECTIVE METHODOLOGIES: DEVELOPING CULTURAL RESEARCH STRATEGIES FOR THE STUDY OF AFFECT, P1
   Lloyd, 2003, READING ONLINE, V6, P22
   Logan B, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P827, DOI 10.1109/ICME.2004.1394328
   Martin JR, 2017, VESTN ROSS UNIV DRUZ, V21, P22, DOI 10.22363/2312-9182-2017-21-1-22-47
   Martin JR, 2007, LANGUAGE OF EVALUATION: APPRAISAL IN ENGLISH, P1
   Nanayakkara C. V., 2016, International Journal of Digital Information and Wireless Communications, V6, P260
   New York State School Music Association, 2012, ARTS STAND IMPL RES
   Ngo T., 2021, Modelling Paralanguage using Systemic Functional Semiotics
   Nichols B.E., 2017, GEN MUSIC TODAY, V30, P13, DOI [DOI 10.1177/1048371317690864, 10.1177/1048371317690864 ty, DOI 10.1177/1048371317690864TY]
   Nishikawa N., 2011, P 1 INT ACM WORKSH M
   O'Callaghan C, 2009, ART PSYCHOTHER, V36, P320, DOI 10.1016/j.aip.2009.09.004
   ODonnell Michael, 2012, The UAM Corpus Tool: Software for Corpus Annotation and Exploration (version 3.3)
   Painter Claire, 2013, Reading visual narratives, DOI 10.1075/aral.38.1.05bir
   Parada-Cabaleiro E., 2018, P 19 INT SOC MUS INF, DOI [10.5281/zenodo.1492429, DOI 10.5281/ZENODO.1492429]
   Pettijohn TF, 2009, J LANG SOC PSYCHOL, V28, P297, DOI 10.1177/0261927X09335259
   Phillips K.H., 2015, MENC HDB RES MUSIC L, P176, DOI [10.1093/acprof:osobl/9780199754397.003.0005, DOI 10.1093/ACPROF:OSOBL/9780199754397.003.0005]
   Pihkanen T., 2011, FINNISH J MUSIC ED, V14, P41
   Poyatos F., 2002, Nonverbal communication across disciplines
   Reed S.A., 2005, THESIS U PITTSBURGH
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   RUSSELL JA, 1991, J PERS SOC PSYCHOL, V60, P37, DOI 10.1037/0022-3514.60.1.37
   Scherer KR, 2015, COMPUT SPEECH LANG, V29, P218, DOI 10.1016/j.csl.2013.10.002
   Sell Karen, 2005, DISCIPLINES VOCAL PE
   SIEGWART H, 1995, J VOICE, V9, P249, DOI 10.1016/S0892-1997(05)80232-2
   Singaporean Ministry of Education, 2016, MUS TEACH LEARN SYLL
   Smith J., 2006, MUSIC EDUC J, V93, P28, DOI DOI 10.1177/002743210609300217
   Spreadborough, MUSIC THEORY ONLINE
   Spreadborough K., 2018, THESIS U NEW ENGLAND, DOI [10.6084/m9.figshare.7636886.v1, DOI 10.6084/M9.FIGSHARE.7636886.V1]
   Spreadborough KL, 2019, PSYCHOL MUSIC, V47, P407, DOI 10.1177/0305735617753996
   Sundberg J., 1989, The Science of the Singing Voice
   Tagg Philip, 2003, 10 LITTLE TITLE TUNE
   The Official UK Charts Company, 2020, OFF SINGL CHARTS
   Ngo T, 2018, AUST J LANG LIT, V41, P30
   Väkevä L, 2006, INT J MUSIC EDUC, V24, P126, DOI 10.1177/0255761406065473
   Van Leeuwen Theo, 1999, SPEECH SOUND MUSIC
   Waddelow C.S., 2016, CANADIAN J MUSIC THE, V22
   Weekly EM, 2009, J VOICE, V23, P367, DOI 10.1016/j.jvoice.2007.10.012
   Wicks, 2015, AUSTR VOICE, V17, P30
   Yang D., 2009, P 2009 11 IEEE S MUL, DOI [10.1109/ISM.2009.123, DOI 10.1109/ISM.2009.123]
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 74
TC 1
Z9 2
U1 0
U2 6
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1321-103X
EI 1834-5530
J9 RES STUD MUSIC EDUC
JI Res. Stud. Music Educ.
PD OCT
PY 2022
VL 44
IS 3
BP 451
EP 474
DI 10.1177/1321103X211034694
EA DEC 2021
PG 24
WC Music
WE Emerging Sources Citation Index (ESCI)
SC Music
GA 4S4NJ
UT WOS:000727947200001
DA 2024-01-09
ER

PT J
AU Chen, DD
AF Chen, Dandan
TI The influence of classical poetry on the transmission of vocal music
   teaching in Chinese universities
SO VOPROSY ISTORII
LA English
DT Article
DE China; classical poetry; teaching; music teaching
AB Classical Chinese poetry and songs have a rich cultural connotation and are a combination of the life experiences and emotions of the people who created them. In recent years, with the introduction of the concept of cultural confidence, people have begun to realize the important value of traditional culture.
C1 [Chen, Dandan] Qiqihar Univ, Qiqihar, Heilongjiang, Peoples R China.
C3 Qiqihar University
RP Chen, DD (corresponding author), Qiqihar Univ, Qiqihar, Heilongjiang, Peoples R China.
EM 13339427688@163.com
CR BAN L.M., 2012, J JIAMUSI ED I
   FANGHENG W, 2017, P 2017 3 INT C EC SO, P1087
   TONG Z, 2015, INT C ED
   ZHU Q, 2013, J GUIZHOU NORMAL COL
NR 4
TC 0
Z9 0
U1 1
U2 2
PU VOPROSY ISTORII
PI MOSCOW
PA VOPROSY ISTORII, MOSCOW, 00000, RUSSIA
SN 0042-8779
EI 1938-2561
J9 VOP ISTORII
JI Vopr. Istor.
PY 2023
VL 3
IS 1
BP 234
EP 239
DI 10.31166/VoprosyIstorii202303Statyi11
PG 6
WC History
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC History
GA 9Z9IE
UT WOS:000951445400028
DA 2024-01-09
ER

PT J
AU Bonin, TL
   Trainor, LJ
   Belyk, M
   Andrews, PW
AF Bonin, Tanor L.
   Trainor, Laurel J.
   Belyk, Michel
   Andrews, Paul W.
TI The source dilemma hypothesis: Perceptual uncertainty contributes to
   musical emotion
SO COGNITION
LA English
DT Article
DE Auditory scene analysis; Dissonance; Emotion; Evolution; Music;
   Perceptual uncertainty
ID EXPRESSION; RESPONSES; FUSION; BRAIN; EXPERIENCE; TIMBRE; RULES; VOICE;
   HAPPY
AB Music can evoke powerful emotions in listeners. Here we provide the first empirical evidence that the principles of auditory scene analysis and evolutionary theories of emotion are critical to a comprehensive theory of musical emotion. We interpret these data in light of a theoretical framework termed "the source dilemma hypothesis," which predicts that uncertainty in the number, identity or location of sound objects elicits unpleasant emotions by presenting the auditory system with an incoherent percept, thereby motivating listeners to resolve the auditory ambiguity. We describe two experiments in which source location and timbre were manipulated to change uncertainty in the auditory scene. In both experiments, listeners rated tonal and atonal melodies with congruent auditory scene cues as more pleasant than melodies with incongruent auditory scene cues. These data suggest that music's emotive capacity relies in part on the perceptual uncertainty it produces regarding the auditory scene. (C) 2016 Published by Elsevier B.V.
C1 [Bonin, Tanor L.; Trainor, Laurel J.; Belyk, Michel; Andrews, Paul W.] McMaster Univ, Dept Psychol Neurosci & Behav, 1280 Main St West, Hamilton, ON L8S 4K1, Canada.
   [Trainor, Laurel J.] McMaster Inst Mus & Mind, 1280 Main St West, Hamilton, ON L8S 4K1, Canada.
   [Trainor, Laurel J.] Baycrest Hosp, Rotman Res Inst, Toronto, ON, Canada.
C3 McMaster University; University of Toronto; Baycrest
RP Andrews, PW (corresponding author), McMaster Univ, Dept Psychol Neurosci & Behav, 1280 Main St West, Hamilton, ON L8S 4K1, Canada.
EM paul.andrews@psychology.mcmaster.ca
OI Trainor, Laurel/0000-0003-3397-2079; Andrews, Paul/0000-0002-5794-1747;
   Belyk, Michel/0000-0002-3270-8666
FU McMaster Science and Engineering Research Board; NSERC [RGPIN-2014-0470]
FX Alan Rheaume, Juan Lopez Tiboni, Danielle Mogyoros, Marley Russell, and
   Victoria Walaszczyk are gratefully acknowledged for assistance in
   various aspects of data collection and preparation. We also thank the
   anonymous reviewers for comments that greatly improved the manuscript.
   This research was funded by a grant from the McMaster Science and
   Engineering Research Board to PWA and an NSERC Discovery Grant to LJT
   (RGPIN-2014-0470).
CR Andrews PW, 2009, PSYCHOL REV, V116, P620, DOI 10.1037/a0016242
   [Anonymous], 1987, CONTEMP MUSIC REV, DOI DOI 10.1080/07494468708567054
   [Anonymous], 2012, BSDA BASIC STAT DATA
   [Anonymous], 1982, MUSIC MIND BRAIN
   [Anonymous], 2001, Music and Emotion, DOI DOI 10.1525/MP.2004.21.4.561
   [Anonymous], 1996, P NORDIC ACOUSTICAL
   Balkwill LL, 2004, JPN PSYCHOL RES, V46, P337, DOI 10.1111/j.1468-5584.2004.00265.x
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Behne K.-E., 1997, PERCEPTION COGNITION, P143
   Blood AJ, 1999, NAT NEUROSCI, V2, P382, DOI 10.1038/7299
   Bonin T. L., 2015, ATTEN PERCEPT PSYCHO, P1
   Bregman A. S., 1990, AUDITORY SCENE ANAL, DOI DOI 10.1121/1.408434
   BREGMAN AS, 1984, PERCEPT PSYCHOPHYS, V36, P251, DOI 10.3758/BF03206366
   BREGMAN AS, 1978, CAN J PSYCHOL, V32, P19, DOI 10.1037/h0081664
   Caclin A, 2005, J ACOUST SOC AM, V118, P471, DOI 10.1121/1.1929229
   CARVER CS, 1990, PSYCHOL REV, V97, P19, DOI 10.1037/0033-295X.97.1.19
   CULLING JF, 1993, PERCEPT PSYCHOPHYS, V54, P303, DOI 10.3758/BF03205265
   DANNENBRING GL, 1978, PERCEPT PSYCHOPHYS, V24, P369, DOI 10.3758/BF03204255
   DEWITT LA, 1987, PERCEPT PSYCHOPHYS, V41, P73, DOI 10.3758/BF03208216
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Fay R. R., 2000, Hearing Research, V149, P1, DOI 10.1016/S0378-5955(00)00168-4
   FRIJDA NH, 1993, COGNITION EMOTION, V7, P357, DOI 10.1080/02699939308409193
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Gagnon L, 2003, COGNITION EMOTION, V17, P25, DOI 10.1080/02699930302279
   GREGORY AH, 1994, MUSIC PERCEPT, V12, P161
   Hevner K, 1936, AM J PSYCHOL, V48, P246, DOI 10.2307/1415746
   Huron D, 2001, MUSIC PERCEPT, V19, P1, DOI 10.1525/mp.2001.19.1.1
   Huron David., 2006, SWEET ANTICIPATION M, DOI DOI 10.7551/MITPRESS/6575.001.0001
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Juslin PN., 2001, Music and Emotion, P309, DOI 10.1093/oso/9780192631886.003.0014
   Koelsch S, 2005, ANN NY ACAD SCI, V1060, P412, DOI 10.1196/annals.1360.034
   Koelsch S, 2014, NAT REV NEUROSCI, V15, P170, DOI 10.1038/nrn3666
   Krumhansl CL, 1997, CAN J EXP PSYCHOL, V51, P336, DOI 10.1037/1196-1961.51.4.336
   Levenson RW, 1999, COGNITION EMOTION, V13, P481, DOI 10.1080/026999399379159
   Lundqvist LO, 2009, PSYCHOL MUSIC, V37, P61, DOI 10.1177/0305735607086048
   Maxwell S.E., 2004, DESIGNING EXPT ANAL
   McAdams S., 1979, Computer Music Journal, V3, P26
   McDermott JH, 2010, CURR BIOL, V20, P1035, DOI 10.1016/j.cub.2010.04.019
   Meyer LB., 1956, Emotion and meaning in music
   Mitterschiffthaler MT, 2007, HUM BRAIN MAPP, V28, P1150, DOI 10.1002/hbm.20337
   Moore B. C. J., 2013, An introduction to the psychology of hearing, V6th
   MORTON ES, 1977, AM NAT, V111, P855, DOI 10.1086/283219
   Näätänen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   North AC., 1995, PSYCHOMUSICOLOGY, V14, P77, DOI [10.1037/h0094090, DOI 10.1037/H0094090]
   Nyklicek I, 1997, J PSYCHOPHYSIOL, V11, P304
   OHALA JJ, 1984, PHONETICA, V41, P1, DOI 10.1159/000261706
   Panksepp J, 2002, BEHAV PROCESS, V60, P133, DOI 10.1016/S0376-6357(02)00080-3
   Peretz I., 2001, Music and emotion: Theory and research, P105
   PLOMP R, 1965, J ACOUST SOC AM, V38, P548, DOI 10.1121/1.1909741
   R Core Team, 2018, R: A Language and Environment for Statistical Computing
   Rickard N. S., 2004, Psychology of Music, V32, P371, DOI [10.1177%2F0305735604046096, DOI 10.1177/0305735604046096, 10.1177/0305735604046096]
   Salimpoor VN, 2011, NAT NEUROSCI, V14, P257, DOI 10.1038/nn.2726
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Sloboda J. A., 2001, MUSIC EMOTION THEORY, P415
   Sloboda J. A., 1991, Psychology of Music, V19, P110, DOI [10.1177/0305735691192002, DOI 10.1177/0305735691192002]
   Sloboda John A., 2005, Exploring the Musical Mind Cognition, Emotion, Ability, Function
   Terwogt M. M., 1991, PSYCHOL MUSIC, V19, P99, DOI DOI 10.1177/0305735691192001
   Thornhill R., 1989, SOCIOBIOLOGY SOCIAL, P73
   TOOBY J, 1990, ETHOL SOCIOBIOL, V11, P375, DOI 10.1016/0162-3095(90)90017-Z
   Trainor L J., 2015, OXFORD HDB MUSIC PSY, P285
   Trainor L.J., 2015, PHILOS T ROYAL SOC B, V370
   Trainor Laurel J., 2003, COGNITIVE NEUROSCIEN, P310
   Woods DL, 2001, J EXP PSYCHOL HUMAN, V27, P65, DOI 10.1037/0096-1523.27.1.65
   Zillmann D., 1997, SOCIAL PSYCHOL MUSIC, P161
NR 65
TC 11
Z9 12
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD SEP
PY 2016
VL 154
BP 174
EP 181
DI 10.1016/j.cognition.2016.05.021
PG 8
WC Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Psychology
GA DS2JT
UT WOS:000380596500019
PM 27318599
DA 2024-01-09
ER

PT J
AU Mammarella, N
   Fairfield, B
   Frisullo, E
   Di Domenico, A
AF Mammarella, Nicola
   Fairfield, Beth
   Frisullo, Elisa
   Di Domenico, Alberto
TI Saying it with a natural child's voice! When affective auditory
   manipulations increase working memory in aging
SO AGING & MENTAL HEALTH
LA English
DT Article
DE aging; affective and auditory factors; working memory
ID OWN-AGE BIAS; OLDER-ADULTS; HEARING-LOSS; AUTOBIOGRAPHICAL MEMORY; FACE
   RECOGNITION; MUSIC; DISTRACTION; INFORMATION; COGNITION; EMOTION
AB Objectives: Working memory functions and their relations with affective auditory factors, have not been extensively investigated in aging yet.
   Method: In this study, younger and older participants completed a classical working memory test (a running working memory task) pronounced by three different voices. In particular, in Experiment 1 the natural voices of a 3-year-old child, a 26-year-old young adult and an 86-year-old older adult were used for task presentation. In Experiment 2 stimuli were morphed in order to better control for sound properties across the three voices.
   Results: Results showed that working memory increased for older adults compared to younger adults when the task was presented with natural voices and especially so when the task was presented in a child's voice. However, the child-voice effect disappeared with morphed voices.
   Conclusion: Data confirm the importance of studying the relationship between auditory features and emotional variations as a possible practical means of reducing typical age-related working memory deficits.
C1 [Mammarella, Nicola; Fairfield, Beth; Frisullo, Elisa; Di Domenico, Alberto] Univ G dAnnunzio, Dept Psychol Sci, Chieti, Italy.
C3 G d'Annunzio University of Chieti-Pescara
RP Mammarella, N (corresponding author), Univ G dAnnunzio, Dept Psychol Sci, Chieti, Italy.
EM n.mammarella@unich.it
RI Di Domenico, Alberto/AIB-7965-2022; Di Domenico, Alberto/O-2111-2015;
   Fairfield, Beth/HHM-4985-2022
OI Di Domenico, Alberto/0000-0002-9962-2891; Di Domenico,
   Alberto/0000-0002-9962-2891; Mammarella, Nicola/0000-0003-1240-702X
CR [Anonymous], 1974, Working memory: the psychology of learning and motivation, DOI DOI 10.1016/S0079-7421(08)60452-1
   Baddeley A, 2003, NAT REV NEUROSCI, V4, P829, DOI 10.1038/nrn1201
   Banbury SP, 2001, HUM FACTORS, V43, P12, DOI 10.1518/001872001775992462
   Baumeister R. F., 2001, Rev. Gen. Psychol, V5, P323, DOI [DOI 10.1037/1089-2680.5.4.323, 10.1037/1089-2680.5.4.323]
   Bisiacchi, 2003, ESAME NEUROPSICOLOGI
   BOWER GH, 1981, AM PSYCHOL, V36, P129, DOI 10.1037/0003-066X.36.2.129
   Carstensen LL, 2005, CURR DIR PSYCHOL SCI, V14, P117, DOI 10.1111/j.0963-7214.2005.00348.x
   Cervera TC, 2009, CAN J EXP PSYCHOL, V63, P216, DOI 10.1037/a0014321
   CROWDER RG, 1969, J VERB LEARN VERB BE, V8, P524, DOI 10.1016/S0022-5371(69)80098-8
   Ebner NC, 2008, BEHAV RES METHODS, V40, P130, DOI [10.3758/BRM.40.1.130, 10.3738/BRM.40.1.130]
   Fabiani M, 2006, J COGNITIVE NEUROSCI, V18, P637, DOI 10.1162/jocn.2006.18.4.637
   Ferguson SH, 2012, J SPEECH LANG HEAR R, V55, P779, DOI 10.1044/1092-4388(2011/10-0342)
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   He Y, 2011, SOC COGNITION, V29, P97, DOI 10.1521/soco.2011.29.1.97
   Hummert ML, 2002, PSYCHOL AGING, V17, P482, DOI 10.1037//0882-7974.17.3.482
   Irish M, 2006, DEMENT GERIATR COGN, V22, P108, DOI 10.1159/000093487
   Mammarella N., 2011, INT PSYCHOGERIATR, V12, P1
   Mammarella N., 2009, HDB COGNITIVE AGING
   Mammarella N., 2013, GERONTOLOGY, DOI 10.1159/000346357
   Mammarella N, 2007, AGING CLIN EXP RES, V19, P394
   Mammarella N, 2006, Q J EXP PSYCHOL, V59, P1701, DOI 10.1080/17470210600822514
   Mammarella N, 2012, GERIATR GERONTOL INT, V12, P722, DOI 10.1111/j.1447-0594.2012.00836.x
   Mammarella N, 2012, SCHIZOPHR RES, V138, P99, DOI 10.1016/j.schres.2012.03.028
   Mather M, 2005, TRENDS COGN SCI, V9, P496, DOI 10.1016/j.tics.2005.08.005
   Mikels JA, 2005, PSYCHOL AGING, V20, P542, DOI 10.1037/0882-7974.20.4.542
   Moè A, 2011, INT J PSYCHOL, V46, P97, DOI 10.1080/00207594.2010.519778
   Murphy DR, 1999, PSYCHOL AGING, V14, P44, DOI 10.1037/0882-7974.14.1.44
   Pichora-Fuller A. M. K., 2003, INT J AUDIOLOGY, V42, p2S26
   Pichora-Fuller MK, 2008, INT J AUDIOL, V47, pS72, DOI 10.1080/14992020802307404
   RABBITT P, 1991, ACTA OTO-LARYNGOL, P167
   Reilly J, 2007, BEHAV RES METHODS, V39, P667, DOI 10.3758/BF03193038
   Reuter-Lorenz P. A., 2005, Cognitive Neuroscience of Aging: Linking Cognitive and Cerebral Aging, P186, DOI DOI 10.1093/ACPROF:OSO/9780195156744.003.0003
   Rhodes MG, 2012, PSYCHOL BULL, V138, P146, DOI 10.1037/a0025750
   Rodero E, 2011, J VOICE, V25, pE25, DOI 10.1016/j.jvoice.2010.02.002
   SALTHOUSE TA, 1995, J GERONTOL B-PSYCHOL, V50, pP297, DOI 10.1093/geronb/50B.6.P297
   Schellenberg EG, 2005, CURR DIR PSYCHOL SCI, V14, P317, DOI 10.1111/j.0963-7214.2005.00389.x
   Schulkind MD, 1999, MEM COGNITION, V27, P948, DOI 10.3758/BF03201225
   Sherratt K, 2004, AGING MENT HEALTH, V8, P3, DOI 10.1080/13607860310001613275
   Shiota MN., 2006, J POSIT PSYCHOL, V1, P61, DOI DOI 10.1080/17439760500510833
   Thompson WF, 2001, PSYCHOL SCI, V12, P248, DOI 10.1111/1467-9280.00345
   Tun PA, 2009, PSYCHOL AGING, V24, P761, DOI 10.1037/a0014802
   Van Dillen LF, 2007, EMOTION, V7, P715, DOI 10.1037/1528-3542.7.4.715
   Verdonck-de Leeuw Irma M, 2004, J Voice, V18, P193, DOI 10.1016/j.jvoice.2003.10.002
   WALLACE WT, 1994, J EXP PSYCHOL LEARN, V20, P1471, DOI 10.1037/0278-7393.20.6.1471
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Weger UW, 2007, PSYCHON B REV, V14, P517, DOI 10.3758/BF03194100
   Wingfield A, 2005, CURR DIR PSYCHOL SCI, V14, P144, DOI 10.1111/j.0963-7214.2005.00356.x
   Wingfield A, 2007, J AM ACAD AUDIOL, V18, P548, DOI 10.3766/jaaa.18.7.3
NR 48
TC 17
Z9 19
U1 0
U2 17
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1360-7863
EI 1364-6915
J9 AGING MENT HEALTH
JI Aging Ment. Health
PD SEP 1
PY 2013
VL 17
IS 7
BP 853
EP 862
DI 10.1080/13607863.2013.790929
PG 10
WC Geriatrics & Gerontology; Gerontology; Psychiatry
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Geriatrics & Gerontology; Psychiatry
GA 205WX
UT WOS:000323476600011
PM 23607371
DA 2024-01-09
ER

PT J
AU Weiss, MW
   Sharda, M
   Lense, M
   Hyde, KL
   Trehub, SE
AF Weiss, Michael W.
   Sharda, Megha
   Lense, Miriam
   Hyde, Krista L.
   Trehub, Sandra E.
TI Enhanced Memory for Vocal Melodies in Autism Spectrum Disorder and
   Williams Syndrome
SO AUTISM RESEARCH
LA English
DT Article
DE autism; Williams syndrome; vocalization; music; memory
ID VERBAL MEMORY; CHILDREN; MUSIC; INDIVIDUALS; PITCH; PERCEPTION;
   DISCRIMINATION; SENSITIVITY; PHENOTYPE; EMOTION
AB Adults and children with typical development (TD) remember vocal melodies (without lyrics) better than instrumental melodies, which is attributed to the biological and social significance of human vocalizations. Here we asked whether children with autism spectrum disorder (ASD), who have persistent difficulties with communication and social interaction, and adolescents and adults with Williams syndrome (WS), who are highly sociable, even indiscriminately friendly, exhibit a memory advantage for vocal melodies like that observed in individuals with TD. We tested 26 children with ASD, 26 adolescents and adults with WS of similar mental age, and 26 children with TD on their memory for vocal and instrumental (piano, marimba) melodies. After exposing them to 12 unfamiliar folk melodies with different timbres, we required them to indicate whether each of 24 melodies (half heard previously) was old (heard before) or new (not heard before) during an unexpected recognition test. Although the groups successfully distinguished the old from the new melodies, they differed in overall memory. Nevertheless, they exhibited a comparable advantage for vocal melodies. In short, individuals with ASD and WS show enhanced processing of socially significant auditory signals in the context of music.
   Lay summary Typically developing children and adults remember vocal melodies better than instrumental melodies. In this study, we found that children with Autistic Spectrum Disorder, who have severe social processing deficits, and children and adults with Williams syndrome, who are highly sociable, exhibit comparable memory advantages for vocal melodies. The results have implications for musical interventions with these populations.
C1 [Weiss, Michael W.; Sharda, Megha; Hyde, Krista L.] Int Lab Brain Mus & Sound Res, Montreal, PQ, Canada.
   [Weiss, Michael W.; Sharda, Megha] Univ Montreal, Dept Psychol, Montreal, PQ, Canada.
   Vanderbilt Univ, Med Ctr, Dept Otolaryngol Head & Neck Surg, Nashville, TN USA.
   [Lense, Miriam] Vanderbilt Brain Inst, Vanderbilt Kennedy Ctr, Nashville, TN USA.
   [Hyde, Krista L.] McGill Univ, Fac Med, Montreal, PQ, Canada.
   [Trehub, Sandra E.] Univ Toronto Mississauga, Dept Psychol, Mississauga, ON, Canada.
C3 Universite de Montreal; Universite de Montreal; Vanderbilt University;
   Vanderbilt University; McGill University; University of Toronto;
   University Toronto Mississauga
RP Weiss, MW (corresponding author), Univ Montreal, Dept Psychol, Montreal, PQ, Canada.
EM michael.weiss@umontreal.ca
OI Lense, Miriam/0000-0003-4362-3032; Weiss, Michael/0000-0001-5208-9957
FU Canadian Institutes of Health Research; Fonds de Recherche du Quebec
   Sante; Fonds de Recherche du Quebec Nature et Technologies; Vanderbilt
   Kennedy Center/ACM Lifting Lives Williams Syndrome Camp
FX Funded by Canadian Institutes of Health Research (K.H.), fellowships
   from Fonds de Recherche du Quebec Sante (M.S.), and Fonds de Recherche
   du Quebec Nature et Technologies (M.W.W), and the Vanderbilt Kennedy
   Center/ACM Lifting Lives Williams Syndrome Camp.
CR Abrams DA, 2019, ELIFE, V8, DOI 10.7554/eLife.39906
   American Psychiatric Association, 2000, Text revision (DSM-IV-TR), DOI [10.1176/dsm10.1176/appi.books.9780890420249.dsm-iv-tr, DOI 10.1176/DSM10.1176/APPI.BOOKS.9780890420249.DSM-IV-TR]
   Angulo-Perkins A, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0222796
   Association A. P., 2013, DIAGN STAT MAN MENT, DOI [10.1176/appi.books.9780890425596, DOI 10.1176/APPI.BOOKS.9780890425596]
   Bidet-Caulet A, 2017, J NEURODEV DISORD, V9, DOI 10.1186/s11689-017-9194-9
   Boddaert N, 2004, AM J PSYCHIAT, V161, P2117, DOI 10.1176/appi.ajp.161.11.2117
   Bonnel A, 2003, J COGNITIVE NEUROSCI, V15, P226, DOI 10.1162/089892903321208169
   Chowdhury R, 2017, PERCEPTION, V46, P1298, DOI 10.1177/0301006617718715
   Conard NJ, 2009, NATURE, V460, P737, DOI 10.1038/nature08169
   Courchesne V, 2019, J AUTISM DEV DISORD, V49, P845, DOI 10.1007/s10803-018-3786-4
   der Nederlanden CMV, 2020, NEUROIMAGE, V214, DOI 10.1016/j.neuroimage.2020.116767
   Deruelle C, 2005, NEUROREPORT, V16, P631, DOI 10.1097/00001756-200504250-00023
   Don AJ, 1999, CHILD NEUROPSYCHOL, V5, P154, DOI 10.1076/chin.5.3.154.7337
   Dunning BA, 2015, RES DEV DISABIL, V36, P565, DOI 10.1016/j.ridd.2014.10.032
   Elsabbagh M, 2010, AJIDD-AM J INTELLECT, V115, P128, DOI 10.1352/1944-7558-115.2.128
   Foxton JM, 2003, BRAIN, V126, P2703, DOI 10.1093/brain/awg274
   Germain E, 2019, CHILD NEUROPSYCHOL, V25, P445, DOI 10.1080/09297049.2018.1488954
   Gervais H, 2004, NAT NEUROSCI, V7, P801, DOI 10.1038/nn1291
   Gudmundsdottir H, 2018, PSYCHOL MUSIC, V46, P281, DOI 10.1177/0305735617711762
   Heaton P, 2005, J AUTISM DEV DISORD, V35, P787, DOI 10.1007/s10803-005-0024-7
   Heaton P, 2003, J CHILD PSYCHOL PSYC, V44, P543, DOI 10.1111/1469-7610.00143
   Hopyan T, 2001, CHILD NEUROPSYCHOL, V7, P42, DOI 10.1076/chin.7.1.42.3147
   Järvinen A, 2016, DEV PSYCHOBIOL, V58, P17, DOI 10.1002/dev.21335
   Järvinen-Pasley A, 2010, NEUROPSYCHOLOGIA, V48, P1047, DOI 10.1016/j.neuropsychologia.2009.12.002
   Jamey K, 2019, RES AUTISM SPECT DIS, V64, P1, DOI 10.1016/j.rasd.2018.11.013
   Jarvinen Anna, 2012, Front Psychol, V3, P343, DOI 10.3389/fpsyg.2012.00343
   Kaufman A.S., 2004, Kaufman Brief Intelligence Test, Second Edition (KBIT-2), Vsecond
   Lai G, 2012, BRAIN, V135, P961, DOI 10.1093/brain/awr335
   Lense Miriam D, 2020, Music Sci (Lond), V3, DOI 10.1177/2059204320933080
   Lense MD, 2014, SOC COGN AFFECT NEUR, V9, P529, DOI 10.1093/scan/nst017
   Levitin DJ, 2004, CHILD NEUROPSYCHOL, V10, P223, DOI 10.1080/09297040490909288
   Martens MA, 2008, J CHILD PSYCHOL PSYC, V49, P576, DOI 10.1111/j.1469-7610.2008.01887.x
   Martens MA, 2011, NEUROPSYCHOLOGIA, V49, P3093, DOI 10.1016/j.neuropsychologia.2011.07.016
   Martens MA, 2010, NEUROPSYCHOLOGIA, V48, P2602, DOI 10.1016/j.neuropsychologia.2010.05.007
   Mehr SA, 2019, SCIENCE, V366, P970, DOI 10.1126/science.aax0868
   Mottron L, 2000, J CHILD PSYCHOL PSYC, V41, P1057, DOI 10.1111/1469-7610.00693
   Paul A, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00555
   Pinheiro AP, 2011, RES DEV DISABIL, V32, P133, DOI 10.1016/j.ridd.2010.09.011
   Plesa-Skwerer D, 2006, AM J MENT RETARD, V111, P15, DOI 10.1352/0895-8017(2006)111[15:PFAVEO]2.0.CO;2
   Rutter M., 2003, The social communication questionnaire
   Savage PE, 2015, P NATL ACAD SCI USA, V112, P8987, DOI 10.1073/pnas.1414495112
   Schelinski S, 2019, J AUTISM DEV DISORD, V49, P68, DOI 10.1007/s10803-018-3681-z
   Schelinski S, 2017, AUTISM RES, V10, P155, DOI 10.1002/aur.1639
   Schelinski S, 2016, SOC COGN AFFECT NEUR, V11, P1812, DOI 10.1093/scan/nsw089
   Sharda M, 2019, LANCET CHILD ADOLESC, V3, P759, DOI 10.1016/S2352-4642(19)30265-2
   Sharda M, 2015, AUTISM RES, V8, P174, DOI 10.1002/aur.1437
   Simpson K, 2013, RES AUTISM SPECT DIS, V7, P1489, DOI 10.1016/j.rasd.2013.08.013
   Slavin S., 2007, PSYSCRIPT VERSION 2
   Stanutz S, 2014, AUTISM, V18, P137, DOI 10.1177/1362361312462905
   Tager-Flusberg H, 2006, SOC COGN AFFECT NEUR, V1, P175, DOI 10.1093/scan/nsl035
   Thakur D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02203
   Thompson GA, 2018, AUTISM RES, V11, P732, DOI 10.1002/aur.1930
   Thurman AJ, 2015, INT REV RES DEV DISA, V49, P191, DOI 10.1016/bs.irrdd.2015.06.002
   Weiss MW, 2019, BRAIN COGNITION, V129, P35, DOI 10.1016/j.bandc.2018.11.011
   Weiss MW, 2017, MUSIC PERCEPT, V34, P313, DOI 10.1525/MP.2017.34.3.313
   Weiss MW, 2016, J EXP PSYCHOL HUMAN, V42, P1061, DOI 10.1037/xhp0000226
   Weiss MW, 2015, Q J EXP PSYCHOL, V68, P866, DOI 10.1080/17470218.2015.1020818
   Weiss MW, 2015, DEV PSYCHOL, V51, P370, DOI 10.1037/a0038784
   Weiss MW, 2012, PSYCHOL SCI, V23, P1074, DOI 10.1177/0956797612442552
   Zarchi O, 2015, PSYCHOPHYSIOLOGY, V52, P782, DOI 10.1111/psyp.12407
NR 60
TC 7
Z9 8
U1 0
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1939-3792
EI 1939-3806
J9 AUTISM RES
JI Autism Res.
PD JUN
PY 2021
VL 14
IS 6
BP 1127
EP 1133
DI 10.1002/aur.2462
EA JAN 2021
PG 7
WC Behavioral Sciences; Psychology, Developmental
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Behavioral Sciences; Psychology
GA SP5YF
UT WOS:000604533000001
PM 33398938
DA 2024-01-09
ER

PT J
AU Dibben, N
   Coutinho, E
   Vilar, JA
   Estévez-Pérez, G
AF Dibben, Nicola
   Coutinho, Eduardo
   Vilar, Jose A.
   Estevez-Perez, Graciela
TI Do Individual Differences Influence Moment-by-Moment Reports of Emotion
   Perceived in Music and Speech Prosody?
SO FRONTIERS IN BEHAVIORAL NEUROSCIENCE
LA English
DT Article
DE emotion; music; prosody; individual differences; continuous; dimensional
ID VOCAL EXPRESSION; RECOGNITION; INTELLIGENCE; PERSONALITY; PERFORMANCE;
   PERCEPTION; MODELS; CUES; LISTENERS; MOOD
AB Comparison of emotion perception in music and prosody has the potential to contribute to an understanding of their speculated shared evolutionary origin. Previous research suggests shared sensitivity to and processing of music and speech, but less is known about how emotion perception in the auditory domain might be influenced by individual differences. Personality, emotional intelligence, gender, musical training and age exert some influence on discrete, summative judgments of perceived emotion in music and speech stimuli. However, music and speech are temporal phenomena, and little is known about whether individual differences influence moment-by-moment perception of emotion in these domains. A behavioral study collected two main types of data: continuous ratings of perceived emotion while listening to extracts of music and speech, using a computer interface which modeled emotion on two dimensions (arousal and valence), and demographic information including measures of personality (TIPI) and emotional intelligence (TEIQue-SF). Functional analysis of variance on the time series data revealed a small number of statistically significant differences associated with Emotional Stability, Agreeableness, musical training and age. The results indicate that individual differences exert limited influence on continuous judgments of dynamic, naturalistic expressions. We suggest that this reflects a reliance on acoustic cues to emotion in moment-by-moment judgments of perceived emotions and is further evidence of the shared sensitivity to and processing of music and speech.
C1 [Dibben, Nicola] Univ Sheffield, Dept Mus, Sheffield, S Yorkshire, England.
   [Coutinho, Eduardo] Univ Liverpool, Dept Mus, Liverpool, Merseyside, England.
   [Vilar, Jose A.; Estevez-Perez, Graciela] Univ A Coruna, Dept Math, La Coruna, Spain.
C3 University of Sheffield; University of Liverpool; Universidade da Coruna
RP Coutinho, E (corresponding author), Univ Liverpool, Dept Mus, Liverpool, Merseyside, England.
EM e.coutinho@imperial.ac.uk
RI Vilar, Jose A./B-9729-2015; Coutinho, Eduardo/K-1391-2019
OI Vilar, Jose A./0000-0001-5494-171X; Coutinho,
   Eduardo/0000-0001-5234-1497; Dibben, Nicola/0000-0002-9250-5035
FU Portuguese Foundation for Science and Technology [SFRH/BPD/62850/2009];
   Calouste Gulbenkian Foundation; Swiss National Science Foundation
   [IZK0Z1_147589]; Fundação para a Ciência e a Tecnologia
   [SFRH/BPD/62850/2009] Funding Source: FCT; Swiss National Science
   Foundation (SNF) [IZK0Z1_147589] Funding Source: Swiss National Science
   Foundation (SNF)
FX This research was partially supported by the Portuguese Foundation for
   Science and Technology under Grant SFRH/BPD/62850/2009; the Calouste
   Gulbenkian Foundation under a Small Research Grant; and the Swiss
   National Science Foundation under Grant IZK0Z1_147589.
CR Aarts H, 2007, J PERS SOC PSYCHOL, V92, P165, DOI 10.1037/0022-3514.92.2.165
   [Anonymous], 2014, Psychomusicology: Music, Mind, and Brain, DOI [10.1037/pmu0000036, DOI 10.1037/PMU0000036]
   Balte F.R., 2014, Psychomusicology: Music, Mind, and Brain, V24, P58, DOI [DOI 10.1037/PMU0000030, 10.1037/pmu0000030]
   Barrett LF, 1997, PERS SOC PSYCHOL B, V23, P1100, DOI 10.1177/01461672972310010
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bigand E, 2006, COGNITION, V100, P100, DOI 10.1016/j.cognition.2005.11.007
   Brackett MA, 2004, PERS INDIV DIFFER, V36, P1387, DOI 10.1016/S0191-8869(03)00236-8
   Brattico E, 2009, ANN NY ACAD SCI, V1169, P308, DOI 10.1111/j.1749-6632.2009.04843.x
   BRITTIN RV, 1995, J RES MUSIC EDUC, V43, P36, DOI 10.2307/3345790
   Brittin RV, 1997, J RES MUSIC EDUC, V45, P245, DOI 10.2307/3345584
   Brück C, 2011, NEUROIMAGE, V58, P259, DOI 10.1016/j.neuroimage.2011.06.005
   Burton L, 2013, CURR PSYCHOL, V32, P275, DOI [10.1007/s12144-013-9167-4, 10.1007/s12144-013-9181-6]
   Cherniss C, 2010, IND ORGAN PSYCHOL-US, V3, P110, DOI 10.1111/j.1754-9434.2010.01231.x
   Clarke E. F, 2005, WAYS LISTENING ECOLO, DOI [10.1093/acprof:oso/9780195151947.001, DOI 10.1093/ACPROF:OSO/9780195151947.001]
   Costa P. T., 1992, Revised NEO Personality Inventory (NEO PI-R) and NEO Five-Factor Inventory (NEO-FFI): Professional Manual
   Coutinho E, 2013, COGNITION EMOTION, V27, P658, DOI 10.1080/02699931.2012.732559
   Coutinho E, 2011, EMOTION, V11, P921, DOI 10.1037/a0024700
   Coutinho E, 2009, MUSIC PERCEPT, V27, P1, DOI 10.1525/MP.2009.27.1.1
   Duke RA, 2001, J RES MUSIC EDUC, V49, P330, DOI 10.2307/3345616
   Edgar C, 2012, PERS INDIV DIFFER, V52, P295, DOI 10.1016/j.paid.2011.10.024
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   Estévez-Pérez G, 2013, ENVIRON ECOL STAT, V20, P495, DOI 10.1007/s10651-012-0231-2
   Fan J., 1996, Local Polynomial Modelling and Its Applications
   Gabrielsson A., 2010, HDB MUSIC EMOTION TH, P367, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0014
   Gabrielsson A, 2001, MUSIC SCI, V5, P123, DOI 10.1177/10298649020050S105
   Gosling SD, 2003, J RES PERS, V37, P504, DOI 10.1016/S0092-6566(03)00046-1
   Grewe O, 2007, EMOTION, V7, P774, DOI 10.1037/1528-3542.7.4.774
   Grewe O, 2007, MUSIC PERCEPT, V24, P297, DOI 10.1525/MP.2007.24.3.297
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Ilie G, 2011, MUSIC PERCEPT, V28, P247, DOI 10.1525/MP.2011.28.3.247
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Knyazev GG, 2008, PERS INDIV DIFFER, V44, P1093, DOI 10.1016/j.paid.2007.11.001
   Lang Peter J, 2005, International Affective Picture System (IAPS): Affective Ratings of Pictures and Instruction Manual
   Larsen JT, 2011, J PERS SOC PSYCHOL, V100, P1095, DOI 10.1037/a0021846
   Laukka P, 2007, MOTIV EMOTION, V31, P182, DOI 10.1007/s11031-007-9063-z
   Lima CF, 2014, EMOTION, V14, P145, DOI 10.1037/a0034287
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Lima CF, 2011, COGNITION EMOTION, V25, P585, DOI 10.1080/02699931.2010.502449
   Livingstone SR, 2010, COMPUT MUSIC J, V34, P41, DOI 10.1162/comj.2010.34.1.41
   Magne C, 2016, BRAIN LANG, V153, P13, DOI 10.1016/j.bandl.2016.01.001
   Mather M, 2005, TRENDS COGN SCI, V9, P496, DOI 10.1016/j.tics.2005.08.005
   Mitchell RLC, 2011, PSYCHOL AGING, V26, P406, DOI 10.1037/a0021861
   Patel AD, 2014, HEARING RES, V308, P98, DOI 10.1016/j.heares.2013.08.011
   Paulmann S, 2008, BRAIN LANG, V104, P262, DOI 10.1016/j.bandl.2007.03.002
   Perlovsky L, 2010, PHYS LIFE REV, V7, P2, DOI 10.1016/j.plrev.2009.11.001
   Petrides KV, 2006, PSICOTHEMA, V18, P101
   Petrides KV, 2006, J APPL SOC PSYCHOL, V36, P552, DOI 10.1111/j.0021-9029.2006.00019.x
   Petrides KV, 2000, SEX ROLES, V42, P449, DOI 10.1023/A:1007006523133
   Petrides KV, 2004, PERS INDIV DIFFER, V36, P277, DOI 10.1016/S0191-8869(03)00084-9
   Ramos D, 2011, BRAZ J MED BIOL RES, V44, P165, DOI 10.1590/S0100-879X2010007500148
   Resnicow JE, 2004, MUSIC PERCEPT, V22, P145, DOI 10.1525/mp.2004.22.1.145
   Ruffman T, 2008, NEUROSCI BIOBEHAV R, V32, P863, DOI 10.1016/j.neubiorev.2008.01.001
   Rusting CL, 1998, PSYCHOL BULL, V124, P165, DOI 10.1037/0033-2909.124.2.165
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   Schubert E, 2004, MUSIC PERCEPT, V21, P561, DOI 10.1525/mp.2004.21.4.561
   Schubert E., 2010, Handbook of music and emotion: Theory, research, applications, P223, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0009
   Schubert E, 2013, PSYCHOL MUSIC, V41, P350, DOI 10.1177/0305735611430079
   Sze JA, 2012, PSYCHOL AGING, V27, P940, DOI 10.1037/a0029367
   Taruffi L, 2017, MUSIC PERCEPT, V34, P253, DOI 10.1525/MP.2017.34.3.253
   Thompson AE, 2014, COGNITION EMOTION, V28, P1164, DOI 10.1080/02699931.2013.875889
   Thompson W.F., 2010, Handbook of music and emotion: Theory, research, and applications, P755
   Thompson WF, 2006, SEMIOTICA, V158, P407, DOI 10.1515/SEM.2006.017
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Trimmer CG, 2008, EMOTION, V8, P838, DOI 10.1037/a0014080
   Vieillard S, 2012, EXP AGING RES, V38, P422, DOI 10.1080/0361073X.2012.699371
   Vuoskoski JK, 2011, CORTEX, V47, P1099, DOI 10.1016/j.cortex.2011.04.011
   Weninger F, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00292
NR 67
TC 7
Z9 8
U1 1
U2 21
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5153
J9 FRONT BEHAV NEUROSCI
JI Front. Behav. Neurosci.
PD AUG 27
PY 2018
VL 12
AR 184
DI 10.3389/fnbeh.2018.00184
PG 13
WC Behavioral Sciences; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Behavioral Sciences; Neurosciences & Neurology
GA GR6KK
UT WOS:000442758800001
PM 30210316
OA Green Accepted, Green Published, gold
DA 2024-01-09
ER

PT J
AU Parada-Cabaleiro, E
   Batliner, A
   Zentner, M
   Schedl, M
AF Parada-Cabaleiro, Emilia
   Batliner, Anton
   Zentner, Marcel
   Schedl, Markus
TI Exploring emotions in Bach chorales: a multi-modal perceptual and
   data-driven study
SO ROYAL SOCIETY OPEN SCIENCE
LA English
DT Article
DE multi-modality; emotion; symbolics; acoustics; linguistics; sacred music
ID SINGING VOICE; MUSIC; EXPRESSION; RELIABILITY; EXPERIENCE; AGREEMENT;
   RESPONSES
AB The relationship between music and emotion has been addressed within several disciplines, from more historico-philosophical and anthropological ones, such as musicology and ethnomusicology, to others that are traditionally more empirical and technological, such as psychology and computer science. Yet, understanding the link between music and emotion is limited by the scarce interconnections between these disciplines. Trying to narrow this gap, this data-driven exploratory study aims at assessing the relationship between linguistic, symbolic and acoustic features-extracted from lyrics, music notation and audio recordings-and perception of emotion. Employing a listening experiment, statistical analysis and unsupervised machine learning, we investigate how a data-driven multi-modal approach can be used to explore the emotions conveyed by eight Bach chorales. Through a feature selection strategy based on a set of more than 300 Bach chorales and a transdisciplinary methodology integrating approaches from psychology, musicology and computer science, we aim to initiate an efficient dialogue between disciplines, able to promote a more integrative and holistic understanding of emotions in music.
C1 [Parada-Cabaleiro, Emilia; Schedl, Markus] Johannes Kepler Univ Linz, Inst Computat Percept, Linz, Austria.
   [Parada-Cabaleiro, Emilia; Schedl, Markus] Linz Inst Technol LIT, AI Lab, Human Ctr AI Grp, Linz, Austria.
   [Parada-Cabaleiro, Emilia] Nuremberg Univ Mus, Dept Mus Pedag, Nurnberg, Germany.
   [Batliner, Anton] Univ Augsburg, Chair Embedded Intelligence Hlth Care & Wellbeing, Augsburg, Germany.
   [Zentner, Marcel] Univ Innsbruck, Dept Psychol, Innsbruck, Austria.
C3 Johannes Kepler University Linz; University of Augsburg; University of
   Innsbruck
RP Schedl, M (corresponding author), Johannes Kepler Univ Linz, Inst Computat Percept, Linz, Austria.; Schedl, M (corresponding author), Linz Inst Technol LIT, AI Lab, Human Ctr AI Grp, Linz, Austria.
EM markus.schedl@jku.at
FU Austrian Science Fund
FX We would like to thank all our students who took part in the listening
   experiment for their time and interest. Without them, this study would
   have not been possible. We would also like to acknowledge the effort by
   Mark Gotham and an anonymous reviewer in providing high quality feedback
   on an earlier version of the manuscript. Their constructive and
   thoughtful guidelines were crucial in further developing this work.
CR Agrawal A., 2018, P 27 INT C COMPUTATI, P950
   Akkermans J, 2019, COGNITION EMOTION, V33, P1099, DOI 10.1080/02699931.2018.1541312
   Ali SO., 2006, Psychology of Music, V34, P511, DOI DOI 10.1177/0305735606067168
   Aljanaki A, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0173392
   Apel W., 2003, The Harvard dictionary of music
   Battcock A, 2021, J NEW MUSIC RES, V50, P447, DOI 10.1080/09298215.2021.1979050
   Battcock A, 2019, MUSIC PERCEPT, V37, P66, DOI 10.1525/MP.2019.37.1.66
   Bowan K., 2019, The Routledge handbook of reenactment studies, P106
   Broyles ME., 1968, Belg. J. Musicol, V22, P64, DOI [10.2307/3686310, DOI 10.2307/3686310]
   Cespedes-Guevara J, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00215
   Cowen AS, 2020, P NATL ACAD SCI USA, V117, P1924, DOI 10.1073/pnas.1910704117
   Duan ZY, 2010, IEEE T AUDIO SPEECH, V18, P2121, DOI 10.1109/TASL.2010.2042119
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   Ekman P., 1999, Handbook of Cognition and Emotion, V98, P45, DOI 10.1002/0470013494.ch3
   Eyben F., 2010, P 18 ACM INT C MULT, P1459, DOI [DOI 10.1145/1873951.1874246, 10.1145/1873951.1874246]
   Fancourt D, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00778
   Gabrielsson A., 2010, Handbook of music and emotion: theory, research, and applications, P187
   Gómez-Cañón JS, 2021, IEEE SIGNAL PROC MAG, V38, P106, DOI 10.1109/MSP.2021.3106232
   Graubart M, 2000, MUSIC TIMES, V141, P8, DOI 10.2307/1004392
   Greene DB., 2012, The spirituality of Mozart's Mass in C minor, Bach's Mass in B minor, and Messiaen's 'Quartet for the end of time': when hearing sacred music is relating to God
   Gwet KL, 2008, BRIT J MATH STAT PSY, V61, P29, DOI 10.1348/000711006X126600
   Han DH, 2022, FRONT COMPUT SCI-CHI, V16, DOI 10.1007/s11704-021-0569-4
   Hevner K, 1936, AM J PSYCHOL, V48, P246, DOI 10.2307/1415746
   Hripcsak G, 2002, J BIOMED INFORM, V35, P99, DOI 10.1016/S1532-0464(02)00500-2
   Hutto C., 2014, P ICWSM, P216, DOI [10.1609/icwsm.v8i1.14550, DOI 10.1609/ICWSM.V8I1.14550]
   Isemonger I., 2018, Transdiscipl. J. Eng. Sci, V9, P116, DOI [10.22545/2018/00105, DOI 10.22545/2018/00105]
   Juslin P., 2010, Handbook of Music and Emotion: Theory, Research, Applications, P453, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0017
   Juslin P., 2019, Musical Emotions Explained, DOI DOI 10.1093/OSO
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Karant-Nunn SC., 2012, The reformation of feeling: shaping the religious emotions in early modern Germany
   Kivy P., 2002, Introduction to a philosophy of music, P31
   Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012
   Kostka S., 2017, Tonal harmony: with an introduction to post-tonal music
   LeDoux JE, 2018, CURR OPIN BEHAV SCI, V19, P67, DOI 10.1016/j.cobeha.2017.09.011
   Lundqvist LO, 2009, PSYCHOL MUSIC, V37, P61, DOI 10.1177/0305735607086048
   Madell MG., 2019, Philosophy, music and emotion
   McClelland C., 2012, Ombra: supernatural music in the eighteenth century, P163
   McKay C., 2018, P INT SOC MUS INF RE, P348
   McVicar M., 2011, P INT SOC MUS INF RE, P783
   Meredith D., 2016, Modern methods for musicology, P1
   Meyer LB., 1956, Emotion and meaning in music
   Mohammad SM, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P174
   Paltoglou G, 2013, IEEE T AFFECT COMPUT, V4, P106, DOI 10.1109/T-AFFC.2012.26
   Panda R., 2013, P INT S COMP MUS MUL, P1
   Panda R, 2023, IEEE T AFFECT COMPUT, V14, P68, DOI 10.1109/TAFFC.2020.3032373
   Panda R, 2020, IEEE T AFFECT COMPUT, V11, P614, DOI 10.1109/TAFFC.2018.2820691
   Parada-Cabaleiro E., 2023, Zenodo, DOI [10.5281/zenodo.10053401, DOI 10.5281/ZENODO.10053401]
   Parada-Cabaleiro E, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0281079
   Parada-Cabaleiro E, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19020994
   Parada-Cabaleiro E, 2017, ACM INT CONF PR SER, P29, DOI 10.1145/3144749.3144756
   Quinto L., 2013, Psychomusicology, V23, P137, DOI [10.1037/a0034775, DOI 10.1037/A0034775]
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Schedl M, 2018, IEEE T AFFECT COMPUT, V9, P507, DOI 10.1109/TAFFC.2017.2663421
   Scherer KR, 2017, J ACOUST SOC AM, V142, P1805, DOI 10.1121/1.5002886
   Shen TC, 2020, AAAI CONF ARTIF INTE, V34, P206
   Shukla Stuti, 2017, 2017 International Conference on Infocom Technologies and Unmanned Systems (Trends and Future Directions) (ICTUS), P777, DOI 10.1109/ICTUS.2017.8286111
   Sun SH, 2017, EMPIR MUSICOL REV, V12, P327
   Susino M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0241196
   Swain JP., 2016, Historical dictionary of sacred music
   Swijghuisen Reigersberg ME, 2013, Performing gender, place, and emotion in music: global perspectives, P85
   Tris Atmaja Bagus, 2020, 2020 IEEE Region 10 Conference (TENCON), P1081, DOI 10.1109/TENCON50793.2020.9293899
   Viera AJ, 2005, FAM MED, V37, P360
   Warriner AB, 2013, BEHAV RES METHODS, V45, P1191, DOI 10.3758/s13428-012-0314-x
   Yang XY, 2018, MULTIMEDIA SYST, V24, P365, DOI 10.1007/s00530-017-0559-4
   Zentner M., 2010, Handbook of music and emotion: theory, research, and applications, P367, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0008
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 67
TC 0
Z9 0
U1 0
U2 0
PU ROYAL SOC
PI LONDON
PA 6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND
SN 2054-5703
J9 ROY SOC OPEN SCI
JI R. Soc. Open Sci.
PD DEC 20
PY 2023
VL 10
IS 12
AR 230574
DI 10.1098/rsos.230574
PG 30
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA CV1R8
UT WOS:001127925500010
PM 38126059
DA 2024-01-09
ER

PT J
AU Bodner, E
AF Bodner, Ehud
TI Emotion Recognition in Improvised Music: The Case of the Multicultural
   Israeli Society
SO JOURNAL OF CROSS-CULTURAL PSYCHOLOGY
LA English
DT Article
DE emotions; musical instruments; music; multiculturalism; musical
   improvisations
ID COMMUNICATION; PERFORMANCE; SONGS
AB The current study explored whether people of different cultures within the same country differ in emotion recognition, when recognizing emotions in improvisations played on different instruments. Participants (n = 202) from several cultures in Israel (i.e., Israeli-born Jews [IBJs], Israeli-Russian immigrants, and Israeli-Arabs and Druze) listened to 40 pieces conveying five emotions (anger, fear, sadness, happiness, and serenity) and decoded their emotional content. The improvisations were performed by four IBJ musicians on four instruments (piano, darbuka, voice, and kazoo). No differences were found between the groups regarding four of the emotions and three of the instruments. However, IBJs were more accurate in identifying fear and emotions conveyed by kazoo. These findings demonstrate that people from different cultures within the same country have a similar ability to recognize emotions expressed through different musical instruments, with the exception of specific emotions and mediums. The results of this study also emphasize the potential of communication of emotions through musical intercultural encounters. Nevertheless, since the study was not based on a balanced factorial design, its findings should be interpreted with caution. Future studies that are based on an orthogonal study design need to examine the replicability of its findings.
C1 [Bodner, Ehud] Bar Ilan Univ, IL-5290002 Ramat Gan, Israel.
C3 Bar Ilan University
RP Bodner, E (corresponding author), Bar Ilan Univ, Interdisciplinary Dept Social Sci, Dept Mus, IL-5290002 Ramat Gan, Israel.
EM ehud.bodner@biu.ac.il
CR Adachi M, 2004, JPN PSYCHOL RES, V46, P322, DOI 10.1111/j.1468-5584.2004.00264.x
   [Anonymous], 2006, PATRIOTISM ISRAELS N
   [Anonymous], PSYCHOL MUSIC, DOI [10.1177/0305735600282007, DOI 10.1177/0305735600282007]
   Balkwill LL, 2004, JPN PSYCHOL RES, V46, P337, DOI 10.1111/j.1468-5584.2004.00265.x
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Behrens Gene Ann, 1993, Psychology of Music, V21, P20, DOI DOI 10.1177/030573569302100102
   Bensimon M, 2009, GROUP PROCESS INTERG, V12, P397, DOI 10.1177/1368430209102851
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Bodner E., 2006, NORD J MUSIC THER, V15, P3, DOI [10.1080/08098130609478147, DOI 10.1080/08098130609478147]
   Bodner E, 2009, MUSIC SCI, V13, P85, DOI 10.1177/1029864909013001004
   Brudzynski SM, 2009, ILAR J, V50, P43, DOI 10.1093/ilar.50.1.43
   COLLINS EJ, 1987, AM MUSIC, V5, P176, DOI 10.2307/3052161
   Davis Ruth F., 2004, MALUF REFLECTIONS AR
   EKMAN P, 1994, PSYCHOL BULL, V115, P268, DOI 10.1037/0033-2909.115.2.268
   Fischer AH, 2004, EMOTION, V4, P87, DOI 10.1037/1528-3542.4.1.87
   Gilboa A, 2006, J MUSIC THER, V43, P198, DOI 10.1093/jmt/43.3.198
   Gnoli Claudio, 1995, Hystrix, V7, P289
   Juslin, 1997, PSYCHOMUSICOLOGY, V16, P77, DOI DOI 10.1037/H0094065
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Juslin PN, 1997, MUSIC SCI, V1, P225, DOI DOI 10.1177/102986499700100205
   KEESING RM, 1974, ANNU REV ANTHROPOL, V3, P73, DOI 10.1146/annurev.an.03.100174.000445
   Krumhansl CL, 2000, COGNITION, V76, P13, DOI 10.1016/S0010-0277(00)00068-8
   Krumhansl CL, 1999, MUSIC PERCEPT, V17, P151
   Laitin D., 2004, J TRANSNATIONAL STUD, V13, P5
   Laukka P, 2013, EMOTION, V13, P434, DOI 10.1037/a0031388
   Mak AS, 1999, INT J INTERCULT REL, V23, P77, DOI 10.1016/S0147-1767(98)00026-1
   NOAM G, 1994, IMMIGRANT ABSORPTION
   Nyklicek I, 1997, J PSYCHOPHYSIOL, V11, P304
   Okun BS, 1996, J MARRIAGE FAM, V58, P469, DOI 10.2307/353510
   Rapoport T, 2002, BRIT J SOCIOL EDUC, V23, P233, DOI 10.1080/01425690220137738
   Remennick L, 2004, ETHNIC RACIAL STUD, V27, P431, DOI 10.1080/01491987042000189213
   Remennick Larisa, 2011, J JEWISH IDENTITIES, V4, P1
   Siegel D., 1998, GREAT IMMIGRATION RU
   Weingrod A, 2006, ANTHROPOL QUART, V79, P691, DOI 10.1353/anq.2006.0057
   Zacharopoulou K., 2009, J INTERDISCIP MUSIC, V3, P1
NR 35
TC 1
Z9 1
U1 0
U2 18
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0022-0221
EI 1552-5422
J9 J CROSS CULT PSYCHOL
JI J. Cross-Cult. Psychol.
PD MAY
PY 2014
VL 45
IS 4
BP 618
EP 627
DI 10.1177/0022022113519854
PG 10
WC Psychology, Social
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Psychology
GA AE3OS
UT WOS:000333886400007
DA 2024-01-09
ER

PT J
AU Kopec, J
   Hillier, A
   Frye, A
AF Kopec, Justin
   Hillier, Ashleigh
   Frye, Alice
TI THE VALENCY OF MUSIC HAS DIFFERENT EFFECTS ON THE EMOTIONAL RESPONSES OF
   THOSE WITH AUTISM SPECTRUM DISORDERS AND A COMPARISON GROUP
SO MUSIC PERCEPTION
LA English
DT Article
DE Asperger's syndrome; autism; music perception; valence; emotional
   response
ID BASIC EMOTIONS; ALEXITHYMIA; FACES; FELT; CHILDREN; RECOGNITION;
   CONVERGENT; ABILITIES; VALIDITY; ADULTS
AB EMOTION PERCEPTION DEFICITS ARE COMMONLY observed in individuals with autism spectrum disorders (ASD). Numerous studies have documented deficits in emotional recognition of social stimuli among those with ASD, such as faces and voices, while far fewer have investigated emotional recognition of nonsocial stimuli in this population. In this study, participants with ASD and a comparison group of typically developing (TD) control participants listened to song clips that varied in levels of pleasantness (valence) and arousal. Participants then rated emotions they felt or perceived in the music, using a list of eight emotion words for each song. Results showed that individuals with ASD gave significantly lower ratings of negative emotions in both the felt and perceived categories compared to TD controls, but did not show significant differences in ratings of positive emotions. These findings suggest that deficits in processing emotions in music among those with ASD may be valence specific.
C1 [Kopec, Justin; Hillier, Ashleigh; Frye, Alice] Univ Massachusetts Lowell, Lowell, MA 01854 USA.
C3 University of Massachusetts System; University of Massachusetts Lowell
RP Hillier, A (corresponding author), Univ Massachusetts Lowell, Dept Psychol, 131 Wilder St,Suite 300, Lowell, MA 01854 USA.
EM Ashleigh_Hillier@uml.edu
CR Adolphs R, 2001, J COGNITIVE NEUROSCI, V13, P232, DOI 10.1162/089892901564289
   Ali SO, 2010, MUSIC PERCEPT, V27, P177, DOI 10.1525/MP.2010.27.3.177
   Allen R, 2013, FRONT PSYCHOL, V4, DOI [10.3389/fpsyg.2013.00156, 10.3389/fpsyg.2013.00890]
   Allen R, 2013, J AUTISM DEV DISORD, V43, P432, DOI 10.1007/s10803-012-1587-8
   Allen R, 2009, AUTISM, V13, P21, DOI 10.1177/1362361307098511
   Ashwin C, 2006, SOC NEUROSCI-UK, V1, P349, DOI 10.1080/17470910601040772
   BAGBY RM, 1994, J PSYCHOSOM RES, V38, P33, DOI 10.1016/0022-3999(94)90006-X
   Baron-Cohen S, 2001, J AUTISM DEV DISORD, V31, P5, DOI 10.1023/A:1005653411471
   Baron-Cohen S, 2002, TRENDS COGN SCI, V6, P248, DOI 10.1016/S1364-6613(02)01904-6
   Baron-Cohen S., 2000, UNDERSTANDING OTHER, V2nd
   Berthoz S, 2005, EUR PSYCHIAT, V20, P291, DOI 10.1016/j.eurpsy.2004.06.013
   Bird G, 2010, BRAIN, V133, P1515, DOI 10.1093/brain/awq060
   Boraston Z, 2007, NEUROPSYCHOLOGIA, V45, P1501, DOI 10.1016/j.neuropsychologia.2006.11.010
   CAPPS L, 1992, J CHILD PSYCHOL PSYC, V33, P1169, DOI 10.1111/j.1469-7610.1992.tb00936.x
   Caria A, 2011, CEREB CORTEX, V21, P2838, DOI 10.1093/cercor/bhr084
   Fidell L. S., 2007, EXPT DESIGNS USING A
   Gabrielsson A, 2001, MUSIC SCI, V5, P123, DOI 10.1177/10298649020050S105
   Gilliam J. E, 2001, Gilliam asperger's disorder scale manual
   Gross TF, 2004, J ABNORM CHILD PSYCH, V32, P469, DOI 10.1023/B:JACP.0000037777.17698.01
   Heaton P, 1999, PSYCHOL MED, V29, P1405, DOI 10.1017/S0033291799001221
   Hill E, 2004, J AUTISM DEV DISORD, V34, P229, DOI 10.1023/B:JADD.0000022613.41399.14
   HOBSON RP, 1989, BRIT J DEV PSYCHOL, V7, P237, DOI 10.1111/j.2044-835X.1989.tb00803.x
   Howard MA, 2000, NEUROREPORT, V11, P2931, DOI 10.1097/00001756-200009110-00020
   Huron D, 2001, ANN NY ACAD SCI, V930, P43, DOI 10.1111/j.1749-6632.2001.tb05724.x
   Iwanaga M, 1996, J MUSIC THER, V33, P219, DOI 10.1093/jmt/33.3.219
   Kallinen K, 2006, MUSIC SCI, V10, P191, DOI 10.1177/102986490601000203
   KAWAKAMI A., 2012, P 12 INT C MUS PERC, P52
   Kawakami A, 2013, MUSIC PERCEPT, V30, P407, DOI 10.1525/MP.2013.30.4.407
   Lang P. J., 2008, A7 U FLOR
   Levitin Daniel, 2006, This is Your Brain on Music: The Science of a Human Obsession
   Mottron L, 2000, J CHILD PSYCHOL PSYC, V41, P1057, DOI 10.1111/1469-7610.00693
   Neumann D, 2006, SOC COGN AFFECT NEUR, V1, P194, DOI 10.1093/scan/nsl030
   Patel A. D., 2008, Music, Language, and the Brain
   Pelphrey KA, 2002, J AUTISM DEV DISORD, V32, P249, DOI 10.1023/A:1016374617369
   Quintin EM, 2011, J AUTISM DEV DISORD, V41, P1240, DOI 10.1007/s10803-010-1146-0
   Rogers J, 2006, PSYCHOL MED, V36, P1789, DOI 10.1017/S0033291706008853
   Schubert E, 2007, J MUSIC THER, V44, P344, DOI 10.1093/jmt/44.4.344
   SIFNEOS PE, 1973, PSYCHOTHER PSYCHOSOM, V22, P255, DOI 10.1159/000286529
   Silani G, 2008, SOC NEUROSCI-UK, V3, P97, DOI 10.1080/17470910701577020
   Vorst HCM, 2001, PERS INDIV DIFFER, V30, P413, DOI 10.1016/S0191-8869(00)00033-7
   Wallace GL, 2011, J AUTISM DEV DISORD, V41, P1475, DOI 10.1007/s10803-010-1170-0
NR 41
TC 6
Z9 6
U1 0
U2 29
PU UNIV CALIFORNIA PRESS
PI OAKLAND
PA 155 GRAND AVE, SUITE 400, OAKLAND, CA 94612-3758 USA
SN 0730-7829
J9 MUSIC PERCEPT
JI Music Percept.
PD JUN
PY 2014
VL 31
IS 5
BP 436
EP 443
DI 10.1525/MP.2014.31.5.436
PG 8
WC Music; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music; Psychology
GA AI8YM
UT WOS:000337212900003
DA 2024-01-09
ER

PT J
AU McPherson, MJ
   Lopez-Gonzalez, M
   Rankin, SK
   Limb, CJ
AF McPherson, Malinda J.
   Lopez-Gonzalez, Monica
   Rankin, Summer K.
   Limb, Charles J.
TI The Role of Emotion in Musical Improvisation: An Analysis of Structural
   Features
SO PLOS ONE
LA English
DT Article
ID AFFECTIVE CHARACTER; CUE UTILIZATION; PERCEPTION; MODE; EXPRESSION;
   ACCURACY; TEMPO; VOICE
AB One of the primary functions of music is to convey emotion, yet how music accomplishes this task remains unclear. For example, simple correlations between mode (major vs. minor) and emotion (happy vs. sad) do not adequately explain the enormous range, subtlety or complexity of musically induced emotions. In this study, we examined the structural features of unconstrained musical improvisations generated by jazz pianists in response to emotional cues. We hypothesized that musicians would not utilize any universal rules to convey emotions, but would instead combine heterogeneous musical elements together in order to depict positive and negative emotions. Our findings demonstrate a lack of simple correspondence between emotions and musical features of spontaneous musical improvisation. While improvisations in response to positive emotional cues were more likely to be in major keys, have faster tempos, faster key press velocities and more staccato notes when compared to negative improvisations, there was a wide distribution for each emotion with components that directly violated these primary associations. The finding that musicians often combine disparate features together in order to convey emotion during improvisation suggests that structural diversity may be an essential feature of the ability of music to express a wide range of emotion.
C1 [McPherson, Malinda J.; Lopez-Gonzalez, Monica; Rankin, Summer K.; Limb, Charles J.] Johns Hopkins Univ, Sch Med, Dept Otolaryngol Head & Neck Surg, Baltimore, MD 21205 USA.
   [Lopez-Gonzalez, Monica; Limb, Charles J.] Johns Hopkins Univ, Baltimore, MD USA.
C3 Johns Hopkins University; Johns Hopkins University
RP McPherson, MJ (corresponding author), Johns Hopkins Univ, Sch Med, Dept Otolaryngol Head & Neck Surg, Baltimore, MD 21205 USA.
EM mmcpherson@jhu.edu
RI Rankin, Summer K/J-5753-2014
OI Rankin, Summer K/0000-0002-6886-3983
FU Dana Foundation; Brain Science Institute of Johns Hopkins University
   School of Medicine; Department of Biomedical Engineering, Johns Hopkins
   University [T32-DC000023]
FX This project was funded by the Dana Foundation and the Brain Science
   Institute of Johns Hopkins University School of Medicine, as well as a
   Training Grant (T32-DC000023) from the Department of Biomedical
   Engineering, Johns Hopkins University. The funders had no role in study
   design, data collection and analysis, decision to publish, or
   preparation of the manuscript.
CR [Anonymous], PSYCHOL MUSIC, DOI [10.1177/0305735600282007, DOI 10.1177/0305735600282007]
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Baraldi FB, 2006, J NEW MUSIC RES, V35, P197, DOI 10.1080/09298210601045575
   Barrett LF, 2007, TRENDS COGN SCI, V11, P327, DOI 10.1016/j.tics.2007.06.003
   Bowling DL, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00464
   Chapin H, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0013812
   Costa M, 2004, MUSIC PERCEPT, V22, P1, DOI 10.1525/mp.2004.22.1.1
   COSTANZO FS, 1969, J COUNS PSYCHOL, V16, P267, DOI 10.1037/h0027355
   Cross I., 2008, MUSIC SCI, V12, P147, DOI [DOI 10.1177/1029864908012001071, 10.1177/1029864908012001071]
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Denckla BF, 1997, DYNAMIC INTONATION S
   DEXTER F, 1995, ANESTHESIOLOGY, V82, P896, DOI 10.1097/00000542-199504000-00012
   EEROLA T., 2004, MIDI toolbox: MATLAB tools for music research
   Eerola T, 2013, MUSIC PERCEPT, V30, P307, DOI [10.1525/mp.2012.30.3.307, 10.1525/MP.2012.30.1.49]
   EKMAN P, 1992, PHILOS T ROY SOC B, V335, P63, DOI 10.1098/rstb.1992.0008
   Gabrielsson A, 1995, PSYCHOMUSICOLOGY, V14
   Gagnon L, 2003, COGNITION EMOTION, V17, P25, DOI 10.1080/02699930302279
   Goebl W, 2003, J ACOUST SOC AM, V114, P2273, DOI 10.1121/1.1605387
   Halpern AR, 2008, MUSIC PERCEPT, V25, P181, DOI 10.1525/MP.2008.25.3.181
   Hevner K, 1935, AM J PSYCHOL, V47, P103, DOI 10.2307/1416710
   Huron D, 2010, ICMPC C SEATTL WASH
   HURON DAVID, 2006, SWEET ANTICIPATION M, P148, DOI DOI 10.7551/MITPRESS/6575.001.0001
   Juslin P. N., 1996, PSYCHOL MUSIC, V24, P68, DOI [10.1177/0305735696241007, DOI 10.1177/0305735696241007]
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Juslin PN, 2003, ANN NY ACAD SCI, V1000, P279, DOI 10.1196/annals.1280.025
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Kamenetsky S.B., 1997, PSYCHOL MUSIC, V25, P149
   KASTNER MP, 1990, MUSIC PERCEPT, V8, P189
   KRUMHANSL CL, 1990, MUSIC PERCEPT, V7, P309
   KRUMHANSL CL, 1982, PSYCHOL REV, V89, P334, DOI 10.1037/0033-295X.89.4.334
   Krumhansl CL, 1998, MUSIC PERCEPT, V16, P119
   Krumhansl CL, 1986, MATH PSYCH M
   Laukka P, 2000, INT J PSYCHOL, V35, P288
   Livingstone SR, 2010, COMPUT MUSIC J, V34, P41, DOI 10.1162/comj.2010.34.1.41
   McAdams S, 2004, MUSIC PERCEPT, V22, P265
   MESQUITA B, 1992, PSYCHOL BULL, V112, P179, DOI 10.1037/0033-2909.112.2.179
   Panksepp J., 2004, Affective Neuroscience
   Paul B, 2010, EMPIR MUSICOL REV, V5, P27, DOI 10.18061/1811/46747
   Rigg MG, 1940, J EXP PSYCHOL, V27, P566, DOI 10.1037/h0058652
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Scherer KR., 1981, SPEECH EVALUATION PS, V1, P460
   Spencer H, 1928, ESSAYS ED KINDRED SU, Vxxi
   Steblin Rita, 2002, HIST KEY CHARACTERIS
   Tao Y., 2014, P NATL ACAD SCI
   Timmers R, 2007, MUSIC PERCEPT, V25, P117, DOI 10.1525/MP.2007.25.2.117
NR 45
TC 14
Z9 16
U1 0
U2 19
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD AUG 21
PY 2014
VL 9
IS 8
AR e105144
DI 10.1371/journal.pone.0105144
PG 11
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Science & Technology - Other Topics
GA AO1WL
UT WOS:000341106100041
PM 25144200
OA gold, Green Published, Green Submitted
DA 2024-01-09
ER

PT J
AU Yang, Q
   Yu, C
AF Yang, Qi
   Yu, Chao
TI Fusion of Emotional Thinking and Mental Health of Students in Vocal
   Music Teaching
SO OCCUPATIONAL THERAPY INTERNATIONAL
LA English
DT Article
AB Vocal psychology belongs to the branch of music psychology, which is the cross-study of vocal art and psychology, and is also a new discipline with both theory and application. Vocal singing uses a thinking, conscious person as an instrument that is necessarily governed by the psyche over the physiology, relying on the brain to direct the movement of the singing muscles and the coordination of the vocal organs. The purpose of this thesis is to explore the application of vocal psychology in vocal singing and teaching, to explain the generation and development of various psychological phenomena in singing activities, to reveal the role and significance of various psychological factors, to provide singers with a theoretical basis for psychological aspects, and to correctly understand the scientific laws of the inner psychology of vocal singing. The effectiveness of classroom teaching is reflected in effective and efficient aspects. The effectiveness of a vocal lesson can be measured by the criteria of whether the teaching is oriented, scientific, artistic, and efficient. Effective teaching design is the basis of teaching effectiveness, elaborate teaching organization is the guarantee of teaching effectiveness, and flexible teaching methods are the root of teaching effectiveness; all three need to be closely combined and organically unified. Effective teaching design is a holistic thinking before the implementation of teaching; all factors related to teaching, practice, and evaluation should be fully considered in the teaching design; teachers should take the learning effect of students and the cultivation of employability as the starting point for effective teaching design; and the classroom teaching of "vocal music" is a "process" and teachers should teach in accordance with the teaching design. They should focus on guiding students to experience and cultivate their abilities in a series of "processes" such as the emotion of vocal music, the teaching situation, the effect of listening, the creation of expression, and the aesthetic value. In addition, teachers should combine the teaching methods of transmission and inspiration, classroom teaching, and after-school training and combine relatively fixed teaching methods with flexible teaching methods to maximize the effectiveness of teaching.
C1 [Yang, Qi] Guangxi Normal Univ Nationalities, Sch Art, Chongzuo 532200, Peoples R China.
   [Yu, Chao] Anhui Univ Technol, Student Affairs Off, Maanshan 243002, Peoples R China.
C3 Guangxi Normal University for Nationalities; Anhui University of
   Technology
RP Yu, C (corresponding author), Anhui Univ Technol, Student Affairs Off, Maanshan 243002, Peoples R China.
EM yangqi@gxnun.edu.cn; yc8307@ahut.edu.cn
CR Awais M, 2021, IEEE INTERNET THINGS, V8, P16863, DOI 10.1109/JIOT.2020.3044031
   Aydin Y, 2020, PAMUKKALE U EGIT FAK, P180, DOI 10.9779/pauefd.584565
   Cravero A., 2020, CAREER DEV TRANSIT E, V77, P159
   Daly DK, 2022, INT J MUSIC EDUC, V40, P105, DOI 10.1177/02557614211028600
   Fan J, 2019, EKOLOJI, V28, P3281
   Fidyk A, 2019, EDUCATION-CANADA, V25, P51
   Fishbach A, 2022, ANNU REV ORGAN PSYCH, V9, P339, DOI 10.1146/annurev-orgpsych-012420-091122
   Hartley J., 2020, J DIVERS HIGH EDUC, V17, P6
   Hess J, 2020, INT J MUSIC EDUC, V38, P441, DOI 10.1177/0255761420917226
   Holmgren C., 2020, NORD RES MUSIC ED, V1, P103, DOI [10.23865/nrme.v1.2635, DOI 10.23865/NRME.V1.2635]
   Joseph D, 2019, LEISURE STUD, V38, P74, DOI 10.1080/02614367.2018.1544655
   Lee D., 2022, 4 IND REV, V2, P9
   Qian K, 2021, IEEE INTERNET THINGS, V8, P16035, DOI 10.1109/JIOT.2021.3067605
   Savage S, 2021, J SOC POLIT PSYCHOL, V9, P490, DOI 10.5964/jspp.7037
   Schaefer Erin E., 2018, Computers and Composition, V50, P78, DOI 10.1016/j.compcom.2018.07.002
   Sydykova R. S., 2020, J INTELLECTUAL DISAB, V8, P485, DOI [10.6000/2292-2598.2020.08.03.26, DOI 10.6000/2292-2598.2020.08.03.26]
   Ye JY, 2021, J AFFECT DISORDERS, V295, P904, DOI 10.1016/j.jad.2021.08.090
   Zhao SC, 2021, IEEE SIGNAL PROC MAG, V38, P59, DOI 10.1109/MSP.2021.3106895
   Zheng JB, 2018, IEEE ACCESS, V6, P49103, DOI 10.1109/ACCESS.2018.2867880
   Zhou Y., 2019, Review of Educational Theory, V2, P1, DOI [10.30564/ret.v2i3.1114, DOI 10.30564/RET.V2I3.1114]
NR 20
TC 0
Z9 0
U1 7
U2 14
PU WILEY-HINDAWI
PI LONDON
PA ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND
SN 0966-7903
EI 1557-0703
J9 OCCUP THER INT
JI Occup. Ther. Int.
PD MAR 24
PY 2023
VL 2023
AR 4604885
DI 10.1155/2023/4604885
PG 10
WC Rehabilitation
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Rehabilitation
GA C4SE0
UT WOS:000961822200002
PM 37007280
OA gold
DA 2024-01-09
ER

PT J
AU Yang, WL
   Makita, K
   Nakao, T
   Kanayama, N
   Machizawa, MG
   Sasaoka, T
   Sugata, A
   Kobayashi, R
   Hiramoto, R
   Yamawaki, S
   Iwanaga, M
   Miyatani, M
AF Yang, Wanlu
   Makita, Kai
   Nakao, Takashi
   Kanayama, Noriaki
   Machizawa, Maro G.
   Sasaoka, Takafumi
   Sugata, Ayako
   Kobayashi, Ryota
   Hiramoto, Ryosuke
   Yamawaki, Shigeto
   Iwanaga, Makoto
   Miyatani, Makoto
TI Affective auditory stimulus database: An expanded version of the
   International Affective Digitized Sounds (IADS-E)
SO BEHAVIOR RESEARCH METHODS
LA English
DT Article
DE Emotion; Affective auditory stimuli; Affective ratings; International
   Affective Digitized Sounds; SAM
ID AFFECTIVE PICTURE SYSTEM; EMOTION PERCEPTION; VALIDATED SET; MUSIC;
   ADAPTATION; COMMUNICATION; PORTUGUESE; EXPRESSION; ATTENTION; RESPONSES
AB Using appropriate stimuli to evoke emotions is especially important for researching emotion. Psychologists have provided several standardized affective stimulus databases-such as the International Affective Picture System (IAPS) and the Nencki Affective Picture System (NAPS) as visual stimulus databases, as well as the International Affective Digitized Sounds (IADS) and the Montreal Affective Voices as auditory stimulus databases for emotional experiments. However, considering the limitations of the existing auditory stimulus database studies, research using auditory stimuli is relatively limited compared with the studies using visual stimuli. First, the number of sample sounds is limited, making it difficult to equate across emotional conditions and semantic categories. Second, some artificially created materials (music or human voice) may fail to accurately drive the intended emotional processes. Our principal aim was to expand existing auditory affective sample database to sufficiently cover natural sounds. We asked 207 participants to rate 935 sounds (including the sounds from the IADS-2) using the Self-Assessment Manikin (SAM) and three basic-emotion rating scales. The results showed that emotions in sounds can be distinguished on the affective rating scales, and the stability of the evaluations of sounds revealed that we have successfully provided a larger corpus of natural, emotionally evocative auditory stimuli, covering a wide range of semantic categories. Our expanded, standardized sound sample database may promote a wide range of research in auditory systems and the possible interactions with other sensory modalities, encouraging direct reliable comparisons of outcomes from different researchers in the field of psychology.
C1 [Yang, Wanlu; Nakao, Takashi; Kobayashi, Ryota; Hiramoto, Ryosuke; Miyatani, Makoto] Hiroshima Univ, Grad Sch Educ, Dept Psychol, 1-1-1 Kagamiyama, Higashihiroshima 7390046, Japan.
   [Makita, Kai; Kanayama, Noriaki; Machizawa, Maro G.; Sasaoka, Takafumi; Yamawaki, Shigeto] Hiroshima Univ, Grad Sch Biomed Hlth Sci, Dept Psychiat & Neurosci, Hiroshima, Japan.
   [Makita, Kai] Univ Fukui, Res Ctr Child Mental Dev, Fukui, Japan.
   [Sugata, Ayako] Ogaki Womens Coll, Gifu, Japan.
   [Sugata, Ayako; Iwanaga, Makoto] Hiroshima Univ, Grad Sch Integrated Arts & Sci, Hiroshima, Japan.
C3 Hiroshima University; Hiroshima University; University of Fukui;
   Hiroshima University
RP Yang, WL (corresponding author), Hiroshima Univ, Grad Sch Educ, Dept Psychol, 1-1-1 Kagamiyama, Higashihiroshima 7390046, Japan.
EM yangwanlu0710@gmail.com
RI Machizawa, Maro G./B-5918-2008; Sasaoka, Takafumi/W-3965-2017; Kanayama,
   Noriaki/N-1472-2018; nakao, takashi/U-7188-2017
OI Machizawa, Maro G./0000-0002-5727-1421; Sasaoka,
   Takafumi/0000-0002-9110-6243; Kanayama, Noriaki/0000-0002-5576-4791;
   nakao, takashi/0000-0002-2227-4526; Kobayashi, Ryota/0000-0001-6842-246X
FU Center of Innovation Program of the Japan Science and Technology Agency
   (JST); Grants-in-Aid for Scientific Research [16K02228] Funding Source:
   KAKEN
FX This research was supported by the Center of Innovation Program of the
   Japan Science and Technology Agency (JST). In addition, we thank
   Syouichi Shiota, Madoca Miyagi, and Shiho Kashihara for their kind
   advice on the manuscript and analysis. Special thanks to Yuko Sonobe,
   Shogo Aida, Narumi Yamagata, Masashi Nishijima, Aiko Nagao, and Noriko
   Miura for their assistance with the experiments and data collection.
CR [Anonymous], 2008, A8 U FLORIDA
   Armony JL, 2015, NEUROSCI LETT, V593, P35, DOI 10.1016/j.neulet.2015.03.011
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Baumgartner T, 2006, INT J PSYCHOPHYSIOL, V60, P34, DOI 10.1016/j.ijpsycho.2005.04.007
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Bradley M., 1999, The International affective digitized sounds (IADS): stimuli, instruction manual and affective ratings
   Bradley M.M., 2007, B3 NIMH U FLOR CTR S
   Bradley M. M., 2007, C1 U FLOR CTR RES PS
   Bradley MM, 2000, PSYCHOPHYSIOLOGY, V37, P204, DOI 10.1111/1469-8986.3720204
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Buodo G, 2017, COGNITION EMOTION, V31, P127, DOI 10.1080/02699931.2015.1089842
   Castonguay AL, 2014, BODY IMAGE, V11, P126, DOI 10.1016/j.bodyim.2013.12.006
   Castro SL, 2010, BEHAV RES METHODS, V42, P74, DOI 10.3758/BRM.42.1.74
   Choi Y, 2016, BEHAV RES METHODS, V48, P827, DOI 10.3758/s13428-015-0596-x
   Choi Y, 2015, ACTA ACUST UNITED AC, V101, P134, DOI 10.3813/AAA.918811
   Czigler I, 2007, NEUROSCI LETT, V420, P251, DOI 10.1016/j.neulet.2007.05.007
   da Silva SP, 2015, PSYCHOPHYSIOLOGY, V52, P1099, DOI 10.1111/psyp.12432
   Drace S, 2013, PSIHOLOGIJA, V46, P17, DOI 10.2298/PSI1301017D
   Droit-Volet S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00417
   Dufey M, 2011, UNIV PSYCHOL, V10, P521, DOI 10.11144/Javeriana.upsy10-2.asce
   EKMAN P, 1992, PSYCHOL REV, V99, P550, DOI 10.1037/0033-295X.99.3.550
   Esslen M, 2004, NEUROIMAGE, V21, P1189, DOI 10.1016/j.neuroimage.2003.10.001
   Fabiani M, 1996, PSYCHOPHYSIOLOGY, V33, P462, DOI 10.1111/j.1469-8986.1996.tb01072.x
   Fazio RH, 2001, COGNITION EMOTION, V15, P115, DOI 10.1080/02699930125908
   Gerdes ABM, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01351
   Iacobucci D, 2003, J CONSUM PSYCHOL, V13, P478, DOI 10.1207/S15327663JCP1304_14
   Iwata N, 2000, J PERS ASSESS, V74, P48, DOI 10.1207/S15327752JPA740104
   Jaquet L, 2014, PSYCHOL MUSIC, V42, P51, DOI 10.1177/0305735612456583
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Krosnick JA, 2010, HANDBOOK OF SURVEY RESEARCH, 2ND EDITION, P263
   Lang P. J., 1997, A1 NIMH U FLOR CTR S
   Lang Peter, 1980, Technology in mental health care delivery systems, P119, DOI DOI 10.1111/J.1469-8986.1993.TB03352.X
   LANG PJ, 1993, PSYCHOPHYSIOLOGY, V30, P261, DOI 10.1111/j.1469-8986.1993.tb03352.x
   Lindquist KA, 2012, BEHAV BRAIN SCI, V35, P121, DOI 10.1017/S0140525X11000446
   Liu P, 2012, BEHAV RES METHODS, V44, P1042, DOI 10.3758/s13428-012-0203-3
   Lolli SL, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01340
   Marchewka A, 2014, BEHAV RES METHODS, V46, P596, DOI 10.3758/s13428-013-0379-1
   Marin MM, 2012, EMOTION, V12, P618, DOI 10.1037/a0025020
   Mikels JA, 2005, BEHAV RES METHODS, V37, P626, DOI 10.3758/BF03192732
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Pell MD, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027256
   Redondo J, 2008, BEHAV RES METHODS, V40, P784, DOI 10.3758/BRM.40.3.784
   Schindler S, 2016, HUM BRAIN MAPP, V37, P3575, DOI 10.1002/hbm.23261
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   SHIMIZU H, 1981, JAPANESE J ED PSYCHO, V29, P62
   Shuman V, 2017, COGNITION EMOTION, V31, P47, DOI 10.1080/02699931.2015.1075964
   Soares AP, 2013, BEHAV RES METHODS, V45, P1168, DOI 10.3758/s13428-012-0310-1
   Spielberger C.D., 1970, The State-Trait Anxiety Inventory ("Self-evaluation questionnaire")
   Stevenson RA, 2008, BEHAV RES METHODS, V40, P315, DOI 10.3758/BRM.40.1.315
   Suk HJ, 2010, COLOR RES APPL, V35, P64, DOI 10.1002/col.20554
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   ZILLMANN D, 1988, AM BEHAV SCI, V31, P327, DOI 10.1177/000276488031003005
NR 52
TC 54
Z9 60
U1 2
U2 34
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1554-351X
EI 1554-3528
J9 BEHAV RES METHODS
JI Behav. Res. Methods
PD AUG
PY 2018
VL 50
IS 4
BP 1415
EP 1429
DI 10.3758/s13428-018-1027-6
PG 15
WC Psychology, Mathematical; Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA GO9WP
UT WOS:000440459100007
PM 29520632
OA Bronze
DA 2024-01-09
ER

PT J
AU Tay, RYL
   Ng, BC
AF Tay, Rosabel Yu Ling
   Ng, Bee Chin
TI Effects of affective priming through music on the use of emotion words
SO PLOS ONE
LA English
DT Article
ID CIRCUMPLEX MODEL; VOCAL EXPRESSION; NEGATIVITY BIAS; SPEECH RATE; TEMPO;
   PERCEPTION; RESPONSES; PERSONALITY; AROUSAL; FELT
AB Understanding how music can evoke emotions and in turn affect language use has significant implications not only in clinical settings but also in the emotional development of children. The relationship between music and emotion is an intricate one that has been closely studied. However, how the use of emotion words can be influenced by auditory priming is a question which is still not known. The main interest in this study was to examine how manipulation of mode and tempo in music affects the emotions induced and the subsequent effects on the use of emotion words. Fifty university students in Singapore were asked to select emotion words after exposure to various music excerpts. The results showed that major modes and faster tempos elicited greater responses for positive words and high arousal words respectively, while minor modes elicited more high arousal words and original tempos resulted in more positive words being selected. In the Major-Fast, Major-Slow and Minor-Slow conditions, positive correlations were found between the number of high arousal words and their rated intensities. Upon further analysis, categorization of emotion words differed from the circumplex model. Taken together, the findings highlight the prominence of affective auditory priming and allow us to better understand our emotive responses to music.
C1 [Tay, Rosabel Yu Ling; Ng, Bee Chin] Nanyang Technol Univ, Sch Humanities, Linguist & Multilingual Studies, Singapore, Singapore.
C3 Nanyang Technological University & National Institute of Education (NIE)
   Singapore; Nanyang Technological University
RP Ng, BC (corresponding author), Nanyang Technol Univ, Sch Humanities, Linguist & Multilingual Studies, Singapore, Singapore.
EM MBCNg@ntu.edu.sg
OI Ng, Bee Chin/0000-0001-9189-5898
FU AcRF Tier 1 grant from the Ministry of Education [M4011842]
FX This project was partially funded by AcRF Tier 1 grant M4011842, to B.C.
   Ng, from the Ministry of Education. The funders had no role in study
   design, data collection and analysis, decision to publish, or
   preparation of the manuscript.
CR [Anonymous], 2012, P 13 INT SOC MUSIC I
   Argstatter H, 2016, PSYCHOL MUSIC, V44, P674, DOI 10.1177/0305735615589214
   Audacity Team, 2021, AUD FREE AUD ED REC, DOI DOI 10.1080/00224545.1934.9921582
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Bänziger T, 2005, SPEECH COMMUN, V46, P252, DOI 10.1016/j.specom.2005.02.016
   Bigand E, 2005, ANN NY ACAD SCI, V1060, P429, DOI 10.1196/annals.1360.036
   Bowling DL, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0031942
   Brans K, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0092410
   Breitenstein C, 2001, COGNITION EMOTION, V15, P57, DOI 10.1080/0269993004200114
   BRETHERTON I, 1982, DEV PSYCHOL, V18, P906, DOI 10.1037/0012-1649.18.6.906
   Canazza S, 2011, ZENODO, DOI [10.5281/zenodo.849917, DOI 10.5281/ZENODO.849917]
   Carminati MN, 2013, P 35 ANN M COGN SCI, P1976
   Carpentier FRD, 2007, MEDIA PSYCHOL, V10, P339, DOI 10.1080/15213260701533045
   CRANDALL JE, 1975, J SOC PSYCHOL, V95, P109, DOI 10.1080/00224545.1975.9923241
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Daltrozzo J, 2009, J COGNITIVE NEUROSCI, V21, P1882, DOI 10.1162/jocn.2009.21113
   DESIMONE R, 1995, ANNU REV NEUROSCI, V18, P193, DOI 10.1146/annurev-psych-122414-033400
   DIENER E, 1991, J PERS SOC PSYCHOL, V61, P492, DOI 10.1037/0022-3514.61.3.492
   Dingle GA, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00859
   Droit-Volet S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00417
   Eerola T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00487
   Fedorenko E, 2009, MEM COGNITION, V37, P1, DOI 10.3758/MC.37.1.1
   FEHR B, 1984, J EXP PSYCHOL GEN, V113, P464, DOI 10.1037/0096-3445.113.3.464
   Fernández-Sotos A, 2016, FRONT COMPUT NEUROSC, V10, DOI 10.3389/fncom.2016.00080
   Ferré P, 2014, PSICOLOGICA, V35, P117
   Ford BQ, 2014, COGNITION EMOTION, V28, P311, DOI 10.1080/02699931.2013.823381
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Gabrielsson A., 2011, HDB MUSIC EMOTION TH
   Gabrielsson A, 2001, MUSIC SCI, V5, P123, DOI 10.1177/10298649020050S105
   Gagnon L, 2003, COGNITION EMOTION, V17, P25, DOI 10.1080/02699930302279
   Goerlich KS, 2012, J COGNITIVE NEUROSCI, V24, P1725, DOI 10.1162/jocn_a_00213
   Grossmann T, 2005, NEUROREPORT, V16, P1825, DOI 10.1097/01.wnr.0000185964.34336.b1
   HAMILTON DL, 1972, J EXP RES PERS, V6, P204
   Hareli S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01501
   Hsu MH, 2015, BMC GERIATR, V15, DOI 10.1186/s12877-015-0082-4
   Hu, 2010, ENCOUNTERING CHINESE
   Hu, 2014, ICONFERENCE 2014 P, P259, DOI [DOI 10.9776/14081, 10.9776/14081]
   Hurless N., 2013, IMPULSE, P1
   Husain G, 2002, MUSIC PERCEPT, V20, P151, DOI 10.1525/mp.2002.20.2.151
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Jiménez-Ortega L, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0033718
   Juslin P. N., 2016, Psychomusicology: Music, Mind and Brain, V26, P293, DOI [DOI 10.1037/PMU0000161, 10.1037/pmu0000161]
   Juslin PN, 2010, MUSIC ANAL, V29, P334, DOI 10.1111/j.1468-2249.2011.00323.x
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   KASTNER MP, 1990, MUSIC PERCEPT, V8, P189
   Kawakami A, 2013, MUSIC PERCEPT, V30, P407, DOI 10.1525/MP.2013.30.4.407
   Kehoe EG, 2012, SOC COGN AFFECT NEUR, V7, P858, DOI 10.1093/scan/nsr059
   Kensinger EA, 2003, EMOTION, V3, P378, DOI 10.1037/1528-3542.3.4.378
   Khalfa S, 2002, NEUROSCI LETT, V328, P145, DOI 10.1016/S0304-3940(02)00462-7
   Kim J, 2009, AUTISM, V13, P389, DOI 10.1177/1362361309105660
   Kim J, 2019, PSYCHOL MUSIC, V47, P392, DOI 10.1177/0305735618754688
   Koelsch S, 2006, HUM BRAIN MAPP, V27, P239, DOI 10.1002/hbm.20180
   Koelsch S, 2005, TRENDS COGN SCI, V9, P12
   Kreutzer NJ, 1991, APPL RES MUSIC ED, V10, P19, DOI [10.1177/875512339101000105, DOI 10.1177/875512339101000105]
   Ladinig O, 2012, PSYCHOL AESTHET CREA, V6, P146, DOI 10.1037/a0024671
   Lesta B., 2006, Australian Journal of Music Therapy, V17, P2
   March DJ, 2010, THESIS
   MARKUS HR, 1991, PSYCHOL REV, V98, P224, DOI 10.1037/0033-295X.98.2.224
   Martín-Loeches M, 2012, NEUROPSYCHOLOGIA, V50, P3262, DOI 10.1016/j.neuropsychologia.2012.09.010
   Maslennikova AV., 2013, NEUROSCI BEHAV PHYSL, V43, P670, DOI DOI 10.1007/S11055-013-9790-4
   Matsumoto D, 2010, INTERNATIONAL HANDBOOK OF ANGER, P125, DOI 10.1007/978-0-387-89676-2_8
   Mesquita B., 2015, INT ENCY SOCIAL BEHA, P542, DOI DOI 10.1016/B978-0-08-097086-8.24012-9
   Parncutt R, 2014, MUSIC SCI, V18, P324, DOI 10.1177/1029864914542842
   Ramos D, 2011, BRAZ J MED BIOL RES, V44, P165, DOI 10.1590/S0100-879X2010007500148
   Remington NA, 2000, J PERS SOC PSYCHOL, V79, P286, DOI 10.1037//0022-3514.79.2.286
   Rozin P, 2001, PERS SOC PSYCHOL REV, V5, P296, DOI 10.1207/S15327957PSPR0504_2
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   RUSSELL JA, 1983, J PERS SOC PSYCHOL, V45, P1281, DOI 10.1037/0022-3514.45.6.1281
   SHAVER P, 1987, J PERS SOC PSYCHOL, V52, P1061, DOI 10.1037/0022-3514.52.6.1061
   Siakaluk PD, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01157
   SMITH BL, 1975, LANG SPEECH, V18, P145, DOI 10.1177/002383097501800203
   Sollberger B, 2003, MUSIC PERCEPT, V20, P263, DOI 10.1525/mp.2003.20.3.263
   Steinbeis N, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0002226
   Steinbeis N, 2011, J COGNITIVE NEUROSCI, V23, P604, DOI 10.1162/jocn.2009.21383
   Takahashi T, 2006, J MUSIC THER, V43, P317, DOI 10.1093/jmt/43.4.317
   TAYLOR SE, 1991, PSYCHOL BULL, V110, P67, DOI 10.1037/0033-2909.110.1.67
   Thompson WF, 2010, HDB MUSIC EMOTION TH
   Tobin RM, 2000, J PERS SOC PSYCHOL, V79, P656, DOI 10.1037//0022-3514.79.4.656
   Trainor LJ, 2000, PSYCHOL SCI, V11, P188, DOI 10.1111/1467-9280.00240
   Trehub S, 2010, HDB MUSIC EMOTION TH
   van der Zwaag MD, 2011, MUSIC SCI, V15, P250, DOI 10.1177/1029864911403364
   Webster GD, 2005, MOTIV EMOTION, V29, P19, DOI 10.1007/s11031-005-4414-0
   WELLMAN HM, 1995, COGNITION EMOTION, V9, P117, DOI 10.1080/02699939508409005
   Wierzbicka A., 2005, EMOTIONS LANGUAGES C
   Wong PCM, 2009, MUSIC PERCEPT, V27, P81, DOI 10.1525/MP.2009.27.2.81
   Zentner MR, 1998, INFANT BEHAV DEV, V21, P483, DOI 10.1016/S0163-6383(98)90021-2
NR 87
TC 10
Z9 10
U1 5
U2 21
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD APR 16
PY 2019
VL 14
IS 4
AR e0214482
DI 10.1371/journal.pone.0214482
PG 26
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Science & Technology - Other Topics
GA HT6TE
UT WOS:000464696100009
PM 30990819
OA Green Submitted, Green Published, gold
DA 2024-01-09
ER

PT J
AU Schlenker, P
AF Schlenker, Philippe
TI Prolegomena to Music Semantics
SO REVIEW OF PHILOSOPHY AND PSYCHOLOGY
LA English
DT Article
ID COMMUNICATION; MOVEMENT; EMOTIONS; LANGUAGE; SOUND
AB We argue that a formal semantics for music can be developed, although it will be based on very different principles from linguistic semantics and will yield less precise inferences. Our framework has the following tenets: (i) Music cognition is continuous with normal auditory cognition. (ii) In both cases, the semantic content derived from an auditory percept can be identified with the set of inferences it licenses on its causal sources, analyzed in appropriately abstract ways (e.g. as voices' in some Western music). (iii) What is special about music semantics is that it aggregates inferences based on normal auditory cognition with further inferences drawn on the basis of the behavior of voices in tonal pitch space (through more or less stable positions, for instance). (iv) This makes it possible to define an inferential semantics but also a truth-conditional semantics for music. In particular, a voice undergoing a musical movement m is true of an object undergoing a series of events e just in case there is a certain structure-preserving map between m and e. (v) Aspects of musical syntax (notably Lerdahl and Jackendoff's time-span reductions') might be derivable on semantic grounds from an event mereology (partology'), which also explains some cases in which tree structures are inadequate for music (overlap, ellipsis). (vi) Intentions and emotions may be attributed at several levels (the source, the musical narrator, the musician), and we speculate on possible explanations of the special relation between music and emotions.
C1 [Schlenker, Philippe] PSL Res Univ, ENS EHESS, CNRS, Inst Jean Nicod,UMR 8129, F-75005 Paris, France.
   [Schlenker, Philippe] NYU, Dept Linguist, New York, NY 10003 USA.
C3 Centre National de la Recherche Scientifique (CNRS); CNRS - Institute
   for Humanities & Social Sciences (INSHS); Universite PSL; Ecole Normale
   Superieure (ENS); New York University
RP Schlenker, P (corresponding author), PSL Res Univ, ENS EHESS, CNRS, Inst Jean Nicod,UMR 8129, F-75005 Paris, France.; Schlenker, P (corresponding author), NYU, Dept Linguist, New York, NY 10003 USA.
EM philippe.schlenker@gmail.com
FU European Research Council under European Union/ERC [324115-FRONTSEM]; 
   [ANR-10-LABX-0087 IEC];  [ANR-10-IDEX-0001-02 PSL*]
FX The research leading to these results received funding from the European
   Research Council under the European Union's Seventh Framework Programme
   (FP/2007-2013)/ERC Grant Agreement No324115-FRONTSEM (PI: Schlenker).
   Research was conducted at Institut d'Etudes Cognitives, Ecole Normale
   Superieure - PSL Research University. Institut d'Etudes Cognitives is
   supported by grants ANR-10-LABX-0087 IEC et ANR-10-IDEX-0001-02 PSL*.
CR [Anonymous], 2010, Musical gestures: Sound, movement and meaning
   [Anonymous], 2010, Handbook of Music and Emotion
   [Anonymous], 2012, BRAIN MUSIC
   [Anonymous], 1990, AUDITORY SCENE ANAL
   [Anonymous], 1990, MUSIC ALONE
   Arnal LH, 2015, CURR BIOL, V25, P2051, DOI 10.1016/j.cub.2015.06.043
   Atkin A., 2013, The Stanford Encyclopedia of Philosophy
   Aucouturier JJ, 2016, P NATL ACAD SCI USA, V113, P948, DOI 10.1073/pnas.1506552113
   Bernstein Leonard, 1967, TELEVISION SERIES
   Blumstein DT, 2012, BIOL LETTERS, V8, P744, DOI 10.1098/rsbl.2012.0374
   Bonin TL, 2016, COGNITION, V154, P174, DOI 10.1016/j.cognition.2016.05.021
   Bowling DL, 2010, J ACOUST SOC AM, V127, P491, DOI 10.1121/1.3268504
   Bowling DL, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0031942
   Charnavel Isabelle, 2016, 1STEPS GENERATIVE TH
   Clarke Eric F., 2001, MUSIC SCI, V5, P213, DOI DOI 10.1177/102986490100500205
   Cohn N, 2014, NEUROPSYCHOLOGIA, V64, P63, DOI 10.1016/j.neuropsychologia.2014.09.018
   Cook ND, 2007, MUSIC PERCEPT, V24, P315, DOI 10.1525/MP.2007.24.3.315
   Davidson Donald, 1967, The Logic of Decision and Action, P81, DOI DOI 10.1093/0199246270.003.0006
   de Vries M, 2013, LINGUA, V134, P149, DOI 10.1016/j.lingua.2013.07.005
   DESAIN P, 1996, P 1996 INT COMP MUS, P458
   Eitan Z, 2006, MUSIC PERCEPT, V23, P221, DOI 10.1525/mp.2006.23.3.221
   Evans P, 2008, MUSIC SCI, V12, P75, DOI 10.1177/102986490801200105
   Fitch WT, 2001, P ROY SOC B-BIOL SCI, V268, P1669, DOI 10.1098/rspb.2001.1704
   FORTE A, 1959, J MUSIC THEORY, V3, P1, DOI DOI 10.2307/842996
   Gabrielsson A., 2010, HDB MUSIC EMOTION TH, P367, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0014
   Gabrielsson A, 2001, MUSIC SCI, V5, P123, DOI 10.1177/10298649020050S105
   Granroth-Wilding M, 2014, J NEW MUSIC RES, V43, P355, DOI 10.1080/09298215.2014.910532
   Greenberg G, 2013, PHILOS REV, V122, P215, DOI 10.1215/00318108-1963716
   GRICE HP, 1957, PHILOS REV, V66, P377, DOI 10.2307/2182440
   Heider F, 1944, AM J PSYCHOL, V57, P243, DOI 10.2307/1416950
   Heim Irene., 1998, Semantics in generative grammar
   Honing H, 2003, COMPUT MUSIC J, V27, P66, DOI 10.1162/014892603322482538
   Huron D, 2015, MUSIC MEANING ANN SE
   HURON DAVID, 2006, SWEET ANTICIPATION M, P148, DOI DOI 10.7551/MITPRESS/6575.001.0001
   Huron David, 2016, VOICE LEADING SCI MU
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Ives Charles, 1908, FOREWORD UNANSWERED
   Jackendoff R, 2009, MUSIC PERCEPT, V26, P195, DOI 10.1525/MP.2009.26.3.195
   JACKENDOFF RS, 1982, SEMANTICS COGNITION
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Knight, 2008, PREHISTORY LANGUAGE, P113
   Koelsch S, 2004, NAT NEUROSCI, V7, P302, DOI 10.1038/nn1197
   Koelsch S, 2011, PHYS LIFE REV, V8, P89, DOI 10.1016/j.plrev.2011.04.004
   Kominsky JF, 2017, PSYCHOL SCI, V28, P1649, DOI 10.1177/0956797617719930
   Kracht M., 2003, MATH LANGUAGE STUDIE
   Larsen Joakim Berg, 2017, THESIS
   Larson R, 1995, INVITATION COGNITIVE, VI
   LARSON Steve, 2012, Musical Forces: Motion, Metaphor, and Meaning in Music
   Lemasson A, 2010, NATURWISSENSCHAFTEN, V97, P1023, DOI 10.1007/s00114-010-0715-6
   Lerdahl F., 2001, Tonal Pitch Space
   Lerdahl F, 2007, MUSIC PERCEPT, V24, P329, DOI 10.1525/MP.2007.24.4.329
   Lerdahl Fred, 1983, A generative theory of tonal music
   LEWIS D, 1979, PHILOS REV, V88, P513, DOI 10.2307/2184843
   Lewis D., 1986, On the Plurality of Worlds
   Lewis David., 1983, Philosophical Papers, V1, P189
   Longuet-Higgins H.C., 1962, MUSIC REV, V23, P271
   Longuet-Higgins H.C., 1962, The MusicReview, V23, P244
   MAUS FE, 1988, MUSIC THEOR SPECTRUM, V10, P56, DOI 10.1525/mts.1988.10.1.02a00050
   McDermott JH, 2010, CURR BIOL, V20, P1035, DOI 10.1016/j.cub.2010.04.019
   Meyer LB., 1956, Emotion and meaning in music
   Monahan S, 2013, J MUSIC THEORY, V57, P321, DOI 10.1215/00222909-2323497
   Napoli Donna Jo, LEONARDO, DOI [10. 1162/LEON_a_01079, DOI 10.1162/LE0N_A_01079]
   Nudds Matthew, 2007, AUDITORY PERCEPTION
   Ohala J. J., 1994, Sound Symbolism, DOI DOI 10.1017/CBO9780511751806.022
   Pankhurst T, 2008, SCHENKERGUIDE BRIEF
   Patel-Grosz Pritty, 2017, COMMUNICATION
   Peirce Charles S., 1867, Proceedings of the American Academy of Arts and Sciences, V7, P287, DOI DOI 10.2307/20179567
   Pesetsky David, 2009, IDENTITY THESIS MUSI
   Rohrmeier M, 2011, J MATH MUSIC, V5, P35, DOI 10.1080/17459737.2011.573676
   Rooth Mats., 1996, Handbook of contemporary semantic theory, P271
   ROSNER BS, 1992, MUSIC PERCEPT, V9, P383
   Saslaw J, 1996, J MUSIC THEORY, V40, P217, DOI 10.2307/843889
   Schlenker P, 2010, LINGUISTICS ENCY, P462
   Schlenker P, 2017, MUSIC PERCEPT, V35, P3, DOI 10.1525/MP.2017.35.1.3
   Schlenker P, 2013, LINGUIST PHILOS, V36, P91, DOI 10.1007/s10988-013-9129-1
   Schlenker Philippe, 2011, SEMANTICS INT HDB NA, P1561
   Schlenker Philippe, NATURAL LANGUAGE LIN
   Schwarzschild Roger., 1999, NAT LANG SEMANT, V7, P141, DOI [DOI 10.1023/A:1008370902407, 10.1023/A:1008370902407]
   Sievers B, 2013, P NATL ACAD SCI USA, V110, P70, DOI 10.1073/pnas.1209023110
   Sportiche D., 2014, An introduction to syntactic analysis and theory
   THOMPSON WF, 1992, MUSIC PERCEPT, V9, P427
   Varzi A., 2015, STANFORD ENCY PHILOS
   Wolff F., 2015, FAYARD
   Zacks JM, 2001, J EXP PSYCHOL GEN, V130, P29, DOI 10.1037//0096-3445.130.1.29
NR 84
TC 11
Z9 11
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1878-5158
EI 1878-5166
J9 REV PHILOS PSYCHOL
JI Rev. Philos. Psychol.
PD MAR
PY 2019
VL 10
IS 1
BP 35
EP 111
DI 10.1007/s13164-018-0384-5
PG 77
WC Psychology, Multidisciplinary
WE Emerging Sources Citation Index (ESCI)
SC Psychology
GA HM1PL
UT WOS:000459224400002
OA Green Submitted
DA 2024-01-09
ER

PT J
AU Kösemihal, E
   Yüksel, M
   Cesur, S
   Çiprut, A
AF Kosemihal, Ebru
   Yueksel, Mustafa
   Cesur, Sidika
   ciprut, Ayca
TI Musical Mistuning Perception and Appraisal in Cochlear Implant
   Recipients
SO OTOLOGY & NEUROTOLOGY
LA English
DT Article
DE Cochlear implant; Mistuning perception; Music-related quality of life
ID MELODIC CONTOUR IDENTIFICATION; SPEECH CODING STRATEGY; FINE-STRUCTURE;
   IMPAIRED PERCEPTION; PITCH PERCEPTION; RECOGNITION; TIMBRE; USERS;
   STIMULATION; EXPERIENCE
AB ObjectiveMusic is a very crucial art form that can evoke emotions, and the harmonious presence of the human voice in music is an impactful part of this process. As a result, vocals have had some significant effects on contemporary music. The mechanism behind the cochlear implant (CI) recipients perceiving different aspects of music is clear; however, how well they perceive vocal tuning within music it is not well known. Hence, this study evaluated the mistuning perception of CI recipients and compared their performance with normal-hearing (NH) listeners.Study Design, Setting, and PatientsA total of 16 CI users (7 cisgender men, 9 cisgender women) and 16 sex-matched NH controls with an average age of 30.2 (+/- 10.9; range, 19-53) years and 23.5 (+/- 6.1; range, 20-37) years, respectively, were enrolled in this study. We evaluated the mistuning ability using the mistuning perception test (MPT) and assessed self-perceived music perception and engagement using the music-related quality-of-life questionnaire. Test performance was measured and reported on the item-response theory metric with a z score ranging from -4 to +4.ResultsA significant difference in the MPT scores was found between NH and CI recipients, whereas a significant correlation was noted between the music-related quality-of-life questionnaire-frequency subscale and MPT scores. No significant correlations were found between age, CI age, and CI usage duration and MPT performance.ConclusionsThis study revealed that musical mistuning perception is a limitation for CI recipients, similar to previously evaluated aspects of music perception. Hence, it is important to consider this aspect in the assessment of music perception, enjoyment, and music-based auditory interventions in CI recipients, as vocals are paramount in music perception and recreation. The MPT is a convenient and accessible tool for mistuning assessment in CI and hearing-aid users.
C1 [Kosemihal, Ebru] Near East Univ, Fac Hlth Sci, Audiol Dept, Nicosia, Cyprus.
   [Yueksel, Mustafa] Ankara Medipol Univ, Sch Hlth Sci, Speech & Language Therapy Dept, Ankara, Turkiye.
   [Cesur, Sidika] Istanbul Medeniyet Univ, Fac Hlth Sci, Audiol Dept, Istanbul, Turkiye.
   [ciprut, Ayca] Marmara Univ, Sch Med, Dept Otolaryngol, Subdept Audiol, Istanbul, Turkiye.
   [Kosemihal, Ebru] Near East Univ, Fac Hlth Sci, Audiol Dept, Yakin Dogu Bulvari, CY-99138 Nicosia, Cyprus.
C3 Near East University; Ankara Medipol University; Istanbul Medeniyet
   University; Marmara University; Near East University
RP Kösemihal, E (corresponding author), Near East Univ, Fac Hlth Sci, Audiol Dept, Yakin Dogu Bulvari, CY-99138 Nicosia, Cyprus.
EM ebru.kosemihal@neu.edu.tr; mustafa.yuksel@ankaramedipol.edu.tr;
   sdkacesur@gmail.com; aycaciprut1@yahoo.com
RI Yüksel, Mustafa/AAD-6835-2019
OI Yüksel, Mustafa/0000-0002-9092-7541
CR Akbulut AA, 2022, EUR ARCH OTO-RHINO-L, V279, P685, DOI 10.1007/s00405-021-06693-w
   Arnoldner C, 2007, ACTA OTO-LARYNGOL, V127, P1298, DOI 10.1080/00016480701275261
   Buyens W., 2017, 25 EUR SIGN PROC C E
   Buyens W, 2014, INT J AUDIOL, V53, P294, DOI 10.3109/14992027.2013.873955
   Caldwell MT, 2016, OTOL NEUROTOL, V37, P229, DOI 10.1097/MAO.0000000000000960
   Cooper WB, 2008, EAR HEARING, V29, P618, DOI 10.1097/AUD.0b013e318174e787
   Cullington HE, 2011, EAR HEARING, V32, P16, DOI 10.1097/AUD.0b013e3181edfbd2
   Drennan WR, 2008, J REHABIL RES DEV, V45, P779, DOI 10.1682/JRRD.2007.08.0118
   Drennan WR, 2015, INT J AUDIOL, V54, P114, DOI 10.3109/14992027.2014.948219
   Dritsakis G, 2017, AM J AUDIOL, V26, P268, DOI 10.1044/2017_AJA-16-0120
   Dritsakis Giorgos, 2017, Cochlear Implants Int, V18, P207, DOI 10.1080/14670100.2017.1303892
   Fuller C, 2022, COCHLEAR IMPLANTS IN, V23, P1, DOI 10.1080/14670100.2021.1948716
   Gajecki T, 2018, J ACOUST SOC AM, V143, P3602, DOI 10.1121/1.5042056
   Galvin JJ, 2007, EAR HEARING, V28, P302, DOI 10.1097/01.aud.0000261689.35445.20
   Galvin JJ, 2009, ANN NY ACAD SCI, V1169, P518, DOI 10.1111/j.1749-6632.2009.04551.x
   Galvin JJ, 2009, J ACOUST SOC AM, V125, pEL98, DOI 10.1121/1.3062148
   Gauer J, 2019, EUR SIGNAL PR CONF, DOI 10.23919/eusipco.2019.8902740
   Gfeller K, 2003, J MUSIC THER, V40, DOI 10.1093/jmt/40.2.78
   Gfeller K, 2008, J AM ACAD AUDIOL, V19, P120, DOI 10.3766/jaaa.19.2.3
   Gfeller K, 2007, EAR HEARING, V28, P412, DOI 10.1097/AUD.0b013e3180479318
   Gfeller Kate, 2002, J Am Acad Audiol, V13, P132
   Gfeller Kate, 2002, Cochlear Implants Int, V3, P29, DOI 10.1179/cim.2002.3.1.29
   Giraud AL, 2001, AUDIOL NEURO-OTOL, V6, P381, DOI 10.1159/000046847
   Heng J, 2011, HEARING RES, V280, P192, DOI 10.1016/j.heares.2011.05.017
   Hickson L., 2004, INT C SER 8 INT COCH
   Hutchins S, 2012, MUSIC PERCEPT, V30, P147, DOI 10.1525/MP.2012.30.2.147
   Illg A, 2014, OTOL NEUROTOL, V35, pE240, DOI 10.1097/MAO.0000000000000529
   Kong YY, 2006, J ACOUST SOC AM, V120, P2830, DOI 10.1121/1.2346009
   Kong YY, 2012, EAR HEARING, V33, P645, DOI 10.1097/AUD.0b013e318252caae
   Kong YY, 2004, EAR HEARING, V25, P173, DOI 10.1097/01.AUD.0000120365.97792.2F
   Kumar A., 2018, P 19 ISMIR C PAR FRA
   Larrouy-Maestri P, 2019, BEHAV RES METHODS, V51, P663, DOI 10.3758/s13428-019-01225-1
   Larrouy-Maestri P, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0135394
   Larrouy-Maestri P, 2013, J VOICE, V27, DOI 10.1016/j.jvoice.2012.11.003
   Lassaletta L, 2007, ACTA OTO-LARYNGOL, V127, P682, DOI 10.1080/00016480601002112
   Limb CJ, 2023, LARYNGOSCOPE, V133, P938, DOI 10.1002/lary.30324
   Looi Valerie, 2012, Seminars in Hearing, V33, P307, DOI 10.1055/s-0032-1329222
   Macherey O, 2013, EAR HEARING, V34, P426, DOI 10.1097/AUD.0b013e31827535f8
   McDermott HJ, 1997, J ACOUST SOC AM, V101, P1622, DOI 10.1121/1.418177
   Moore BCJ, 2003, OTOL NEUROTOL, V24, P243, DOI 10.1097/00129492-200303000-00019
   Nagathil A, 2018, J ACOUST SOC AM, V144, P1, DOI 10.1121/1.5044514
   Nagathil A, 2016, IEEE-ACM T AUDIO SPE, V24, DOI 10.1109/TASLP.2015.2511623
   Oxenham Andrew J, 2008, Trends Amplif, V12, P316, DOI 10.1177/1084713808325881
   Pfordresher PQ, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00271
   Pons J, 2016, J ACOUST SOC AM, V140, P4338, DOI 10.1121/1.4971424
   Prevoteau C, 2018, AURIS NASUS LARYNX, V45, P895, DOI 10.1016/j.anl.2017.11.008
   Riss D, 2008, OTOL NEUROTOL, V29, P784, DOI 10.1097/MAO.0b013e31817fe00f
   Rocca Christine, 2012, Seminars in Hearing, V33, P425, DOI 10.1055/s-0032-1329229
   Sandmann P, 2010, CLIN NEUROPHYSIOL, V121, P2070, DOI 10.1016/j.clinph.2010.04.032
   Tahmasebi S, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00434
   Thompson WF., 2013, PSYCHOL MUSIC, V3rd ed.
   TOWNSHEND B, 1987, IEEE T BIO-MED ENG, V34, P891, DOI 10.1109/TBME.1987.326102
   Vurma A, 2006, MUSIC PERCEPT, V23, P331, DOI 10.1525/mp.2006.23.4.331
   Wang WQ, 2011, INT J AUDIOL, V50, P270, DOI 10.3109/14992027.2010.542490
   Warren RA, 2015, MUSIC PERCEPT, V33, P135, DOI 10.1525/MP.2015.33.2.135
   Warrier CM, 2002, PERCEPT PSYCHOPHYS, V64, P198, DOI 10.3758/BF03195786
   Witt S, 2002, ANN OTO RHINOL LARYN, V111, P349, DOI 10.1177/000348940211100412
   Wright R, 2012, J AM ACAD AUDIOL, V23, P350, DOI 10.3766/jaaa.23.5.6
   Xu L, 2003, J ACOUST SOC AM, V114, P3024, DOI 10.1121/1.1623786
   Xu L, 2002, J ACOUST SOC AM, V112, P247, DOI 10.1121/1.1487843
   Yüksel M, 2020, J AM ACAD AUDIOL, V31, P740, DOI 10.1055/s-0040-1719132
   Yüksel M, 2020, INT J PEDIATR OTORHI, V131, DOI 10.1016/j.ijporl.2020.109865
   Zeng FG, 2002, HEARING RES, V174, P101, DOI 10.1016/S0378-5955(02)00644-5
   Zimmer V, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00466
NR 64
TC 0
Z9 0
U1 4
U2 5
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 1531-7129
EI 1537-4505
J9 OTOL NEUROTOL
JI Otol. Neurotol.
PD JUN
PY 2023
VL 44
IS 5
BP E281
EP E286
DI 10.1097/MAO.0000000000003860
PG 6
WC Clinical Neurology; Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Neurosciences & Neurology; Otorhinolaryngology
GA G1FC9
UT WOS:000986689600003
PM 36922018
DA 2024-01-09
ER

PT J
AU Eerola, T
AF Eerola, Tuomas
TI Modeling Listeners' Emotional Response to Music
SO TOPICS IN COGNITIVE SCIENCE
LA English
DT Article
DE Computational model; Affect; Emotion; Dimensions; Acoustic analysis;
   Feature extraction
ID COMPUTATIONAL MODELS; VOCAL EXPRESSION; COMMUNICATION; PERCEPTION;
   PERFORMANCE; RETRIEVAL; COGNITION; SPEECH; CLASSIFICATION; PREDICTION
AB An overview of the computational prediction of emotional responses to music is presented. Communication of emotions by music has received a great deal of attention during the last years and a large number of empirical studies have described the role of individual features (tempo, mode, articulation, timbre) in predicting the emotions suggested or invoked by the music. However, unlike the present work, relatively few studies have attempted to model continua of expressed emotions using a variety of musical features from audio-based representations in a correlation design. The construction of the computational model is divided into four separate phases, with a different focus for evaluation. These phases include the theoretical selection of relevant features, empirical assessment of feature validity, actual feature selection, and overall evaluation of the model. Existing research on music and emotions and extraction of musical features is reviewed in terms of these criteria. Examples drawn from recent studies of emotions within the context of film soundtracks are used to demonstrate each phase in the construction of the model. These models are able to explain the dominant part of the listeners self-reports of the emotions expressed by music and the models show potential to generalize over different genres within Western music. Possible applications of the computational models of emotions are discussed.
C1 Univ Jyvaskyla, Dept Mus, Finnish Ctr Excellence Interdisciplinary Mus Res, Jyvaskyla 40014, Finland.
C3 University of Jyvaskyla
RP Eerola, T (corresponding author), Univ Jyvaskyla, Dept Mus, Finnish Ctr Excellence Interdisciplinary Mus Res, Jyvaskyla 40014, Finland.
EM tuomas.eerola@jyu.fi
RI Eerola, Tuomas/K-7596-2019; Eerola, Tuomas/I-6190-2013; Campailla,
   Jasmin/AAK-2420-2021
OI Eerola, Tuomas/0000-0002-2896-929X; Eerola, Tuomas/0000-0002-2896-929X; 
CR Altenmüller E, 2002, NEUROPSYCHOLOGIA, V40, P2242, DOI 10.1016/S0028-3932(02)00107-0
   [Anonymous], FDN COGNITIVE SCI
   [Anonymous], 1999, The performance of music. The psychology of music, DOI DOI 10.1016/B978-012213564-4/50015-9
   [Anonymous], 2007, ISMIR
   Bartsch MA, 2005, IEEE T MULTIMEDIA, V7, P96, DOI 10.1109/TMM.2004.840597
   Bello JP, 2005, IEEE T SPEECH AUDI P, V13, P1035, DOI 10.1109/TSA.2005.851998
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Casey MA, 2008, P IEEE, V96, P668, DOI 10.1109/JPROC.2008.916370
   Chen JD, 2003, SPEECH COMMUN, V41, P469, DOI 10.1016/S0167-6393(03)00016-5
   Clarke E., 2004, EMPIRICAL MUSICOLOGY
   Clarke E. F., 1999, The Psychology of Music, V2nd ed., P473, DOI DOI 10.1016/B978-012213564-4/50014-7
   Coutinho E, 2009, MUSIC PERCEPT, V27, P1, DOI 10.1525/MP.2009.27.1.1
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Dibben N, 2004, MUSIC PERCEPT, V22, P79, DOI 10.1525/mp.2004.22.1.79
   Downie J., 2005, SC 05, P71
   Eck D, 2002, PSYCHOL RES-PSYCH FO, V66, P18, DOI 10.1007/s004260100070
   Eerola T., 2009, Proceedings of the International Conference on Music Information Retrieval ISMIR, P621
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   Essid S, 2006, IEEE T AUDIO SPEECH, V14, P68, DOI 10.1109/TSA.2005.860351
   Evans P, 2008, MUSIC SCI, V12, P75, DOI 10.1177/102986490801200105
   Fodor J. A., 2001, MIND DOESNT WORK WAY
   Foote JT, 2003, PROC SPIE, V5021, P167, DOI 10.1117/12.476302
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Gabrielsson A., 2010, HDB MUSIC EMOTION TH, P367, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0014
   Gabrielsson A, 2001, MUSIC SCI, V5, P123, DOI 10.1177/10298649020050S105
   Gjerdingen Robert O., 1988, A Classic Turn of Phrase: Music and the Psychology of Convention
   Gomez P, 2004, INT J PSYCHOPHYSIOL, V53, P91, DOI 10.1016/j.ijpsycho.2004.02.002
   Gomez P, 2007, EMOTION, V7, P377, DOI 10.1037/1528-3542.7.2.377
   Hair J. F., 2006, MULTIVARIATE DATA AN
   Hevner K, 1935, PSYCHOL REV, V42, P186, DOI 10.1037/h0054832
   Hevner K, 1936, AM J PSYCHOL, V48, P246, DOI 10.2307/1415746
   Honing H, 2006, MUSIC PERCEPT, V23, P365, DOI 10.1525/mp.2006.23.5.365
   Honing H, 2006, EMPIR MUSICOL REV, V1, P2, DOI 10.18061/1811/21901
   Honing Henkjan, 2004, TIJDSCHRIFT MUZIEKTH, V9, P241
   HURON DAVID, 2006, SWEET ANTICIPATION M, P148, DOI DOI 10.7551/MITPRESS/6575.001.0001
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2006, J EXP PSYCHOL-APPL, V12, P79, DOI 10.1037/1076-898X.12.2.79
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Juslin PN, 1997, MUSIC PERCEPT, V14, P383
   Kallinen K, 2004, PERS INDIV DIFFER, V37, P275, DOI 10.1016/j.paid.2003.09.002
   Kallinen K., 2005, Psychology of Music, V33, P373, DOI DOI 10.1177/0305735605056147
   Klapuri AP, 2004, J NEW MUSIC RES, V33, P269, DOI 10.1080/0929821042000317840
   Korhonen MD, 2006, IEEE T SYST MAN CY B, V36, P588, DOI 10.1109/TSMCB.2005.862491
   KRUMHANSL CL, 1982, PSYCHOL REV, V89, P334, DOI 10.1037/0033-295X.89.4.334
   Lartillot O., 2007, P INT C DIG AUD EFF, DOI DOI 10.1007/978-3-540-78246-9_31
   Lartillot O., 2008, ISMIR, P521
   Leman M, 2000, MUSIC PERCEPT, V17, P481
   Leman M, 2005, J NEW MUSIC RES, V34, P39, DOI 10.1080/09298210500123978
   Leman M., 2008, SYSTEMATIC COMP MUSI, V24, P89
   LEMAN M., 2008, Embodied Music Cognition and Mediation Technology
   Leman M., 2001, MIKROPOLYPHONIE ONLI
   Leman Marc, 2003, J MUSIC MEANING, V1
   Lerdahl Fred, 2004, TONAL PITCH SPACE
   Lesaffre M., 2004, P 5 INT C MUSIC INFO, P64
   Lesaffre M, 2008, J AM SOC INF SCI TEC, V59, P695, DOI 10.1002/asi.20731
   Lu L, 2006, IEEE T AUDIO SPEECH, V14, P5, DOI 10.1109/TSA.2005.860344
   MacDorman KF, 2007, J NEW MUSIC RES, V36, P281, DOI 10.1080/09298210801927846
   McAdams S, 2004, MUSIC PERCEPT, V22, P297, DOI 10.1525/mp.2004.22.2.297
   Müller M, 2010, INT J PSYCHOPHYSIOL, V76, P40, DOI 10.1016/j.ijpsycho.2010.02.002
   Purwins H., 2000, P IEEE INNS ENNS INT, V6, P6270
   Purwins H, 2008, PHYS LIFE REV, V5, P151, DOI 10.1016/j.plrev.2008.03.004
   Purwins H, 2008, PHYS LIFE REV, V5, P169, DOI 10.1016/j.plrev.2008.03.005
   Rink John, 1995, The Practice of Performance: Studies in Musical Interpretation
   RUSSELL JA, 1989, J PERS SOC PSYCHOL, V57, P493, DOI 10.1037/0022-3514.57.3.493
   Schellenberg EG, 2005, CURR DIR PSYCHOL SCI, V14, P317, DOI 10.1111/j.0963-7214.2005.00389.x
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   Schimmack U, 2002, EMOTION, V2, P412, DOI 10.1037//1528-3542.2.4.412
   Schubert E, 2004, MUSIC PERCEPT, V21, P561, DOI 10.1525/mp.2004.21.4.561
   Sottek R, 2005, AEU-INT J ELECTRON C, V59, P157, DOI 10.1016/j.aeue.2005.03.016
   Temperley D., 2007, Music and probability
   Thayer RE., 1990, The Biopsychology of Mood and Activation
   Turnbull D, 2008, IEEE T AUDIO SPEECH, V16, P467, DOI 10.1109/TASL.2007.913750
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Tzanetakis G., 2000, Organised Sound, V4
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   Vuoskoski J. K., MUSIC PERCE IN PRESS
   Vuoskoski JK, 2011, CORTEX, V47, P1099, DOI 10.1016/j.cortex.2011.04.011
   Wiggins G., 2002, 7 INT C MUS PERC COG, P35
   Wiggins GA, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P477, DOI 10.1109/ISM.2009.36
   Yang YH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P208
   Zentner M., 2010, Handbook of music and emotion: theory, research, and applications, P367, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0008
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 86
TC 16
Z9 19
U1 1
U2 53
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1756-8757
EI 1756-8765
J9 TOP COGN SCI
JI Top. Cogn. Sci.
PD OCT
PY 2012
VL 4
IS 4
BP 607
EP 624
DI 10.1111/j.1756-8765.2012.01188.x
PG 18
WC Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA 019NZ
UT WOS:000309747900010
PM 22389191
OA Bronze
DA 2024-01-09
ER

PT J
AU Zhang, JF
   Yang, TX
   Bao, Y
   Li, H
   Pöppel, E
   Silveira, S
AF Zhang, Jinfan
   Yang, Taoxi
   Bao, Yan
   Li, Hui
   Poeppel, Ernst
   Silveira, Sarita
TI Sadness and happiness are amplified in solitary listening to music
SO COGNITIVE PROCESSING
LA English
DT Article
DE Emotion; Music perception; Social context; Attention; Sadness; Happiness
ID SELF-FOCUSED ATTENTION; EMOTIONAL RESPONSES; EXPERIENCE; REALITY; FRAME;
   FELT
AB Previous studies have shown that music is a powerful means to convey affective states, but it remains unclear whether and how social context shape the intensity and quality of emotions perceived in music. Using a within-subject design, we studied this question in two experimental settings, i.e. when subjects were alone versus in company of others without direct social interaction or feedback. Non-vocal musical excerpts of the emotional qualities happiness or sadness were rated on arousal and valence dimensions. We found evidence for an amplification of perceived emotion in the solitary listening condition, i.e. happy music was rated as happier and more arousing when nobody else was around and, in an analogous manner, sad music was perceived as sadder. This difference might be explained by a shift of attention in the presence of others. The observed interaction of perceived emotion and social context did not differ for stimuli of different cultural origin.
C1 [Zhang, Jinfan; Yang, Taoxi; Bao, Yan; Li, Hui; Poeppel, Ernst] Peking Univ, Sch Psychol & Cognit Sci, 5 Yiheyuan Rd, Beijing 100871, Peoples R China.
   [Zhang, Jinfan; Yang, Taoxi; Bao, Yan; Li, Hui; Poeppel, Ernst] Peking Univ, Beijing Key Lab Behaviour & Mental Hlth, 5 Yiheyuan Rd, Beijing 100871, Peoples R China.
   [Zhang, Jinfan; Yang, Taoxi; Bao, Yan; Li, Hui; Poeppel, Ernst; Silveira, Sarita] Ludwig Maximilians Univ Munchen, Inst Med Psychol, D-80336 Munich, Germany.
   [Zhang, Jinfan; Yang, Taoxi; Bao, Yan; Li, Hui; Poeppel, Ernst; Silveira, Sarita] Ludwig Maximilians Univ Munchen, Human Sci Ctr, D-80336 Munich, Germany.
C3 Peking University; Peking University; University of Munich; University
   of Munich
RP Bao, Y (corresponding author), Peking Univ, Sch Psychol & Cognit Sci, 5 Yiheyuan Rd, Beijing 100871, Peoples R China.; Bao, Y (corresponding author), Peking Univ, Beijing Key Lab Behaviour & Mental Hlth, 5 Yiheyuan Rd, Beijing 100871, Peoples R China.; Bao, Y (corresponding author), Ludwig Maximilians Univ Munchen, Inst Med Psychol, D-80336 Munich, Germany.; Bao, Y (corresponding author), Ludwig Maximilians Univ Munchen, Human Sci Ctr, D-80336 Munich, Germany.
EM baoyan@pku.edu.cn
RI Zhang, Jinfan/JPK-7588-2023
FU National Natural Science Foundation of China [91120004, 31371018];
   German Academic Exchange Service (DAAD); Hanns Seidel Foundation; China
   Scholarship Council [[2014]3026, [2009]3003]
FX This work was supported by the National Natural Science Foundation of
   China (No. 91120004 and 31371018) to Yan Bao, the German Academic
   Exchange Service (DAAD) to Yan Bao, Hanns Seidel Foundation to Jinfan
   Zhang and Sarita Silveira, and the China Scholarship Council to Taoxi
   Yang (No. [2014]3026) and Hui Li (No. [2009]3003).
CR Allport GW, 1985, Handbook of Social psychology
   Balkwill LL, 2004, JPN PSYCHOL RES, V46, P337, DOI 10.1111/j.1468-5584.2004.00265.x
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Bao Y, 2015, PSYCH J, V4, P243, DOI 10.1002/pchj.119
   Bao Y, 2012, NEUROSCI BIOBEHAV R, V36, P2143, DOI 10.1016/j.neubiorev.2012.06.008
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Chentsova-Dutton YE, 2010, J PERS SOC PSYCHOL, V98, P507, DOI 10.1037/a0018534
   Cialdini RB, 2004, ANNU REV PSYCHOL, V55, P591, DOI 10.1146/annurev.psych.55.090902.142015
   Echterhoff G, 2009, PERSPECT PSYCHOL SCI, V4, P496, DOI 10.1111/j.1745-6924.2009.01161.x
   Eerola T, 2013, MUSIC PERCEPT, V30, P307, DOI [10.1525/mp.2012.30.3.307, 10.1525/MP.2012.30.1.49]
   Egermann H, 2011, MUSIC SCI, V15, P307, DOI 10.1177/1029864911399497
   Egermann H, 2009, ANN NY ACAD SCI, V1169, P346, DOI 10.1111/j.1749-6632.2009.04789.x
   Evans P, 2008, MUSIC SCI, V12, P75, DOI 10.1177/102986490801200105
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Gabrielsson A, 2003, MUSIC SCI, V7, P157, DOI 10.1177/102986490300700201
   Gabrielsson A., 2010, HDB MUSIC EMOTION TH, P367, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0014
   Gabrielsson A, 2001, MUSIC SCI, V5, P123, DOI 10.1177/10298649020050S105
   Garrido S., 2017, Why are we attracted to sad music?
   Juslin P. N., 2011, HDB MUSIC EMOTION TH
   Juslin P. N., 1996, PSYCHOL MUSIC, V24, P68, DOI [10.1177/0305735696241007, DOI 10.1177/0305735696241007]
   Juslin PN, 2008, EMOTION, V8, P668, DOI 10.1037/a0013505
   Kawakami A, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00431
   Kreutz G, 2008, PSYCHOL MUSIC, V36, P101, DOI 10.1177/0305735607082623
   Larsen JT, 2011, EMOTION, V11, P1469, DOI 10.1037/a0024081
   Liljeström S, 2013, PSYCHOL MUSIC, V41, P579, DOI 10.1177/0305735612440615
   McDermott JH, 2016, NATURE, V535, P547, DOI 10.1038/nature18635
   Park M, 2015, FRONT HUM NEUROSCI, V8, DOI [10.3389/fnhurn.2014.01049, 10.3389/fnhum.2014.01049]
   Park M, 2014, NEUROSCI LETT, V566, P120, DOI 10.1016/j.neulet.2014.02.041
   Park M, 2013, BRAIN RES, V1523, P68, DOI 10.1016/j.brainres.2013.05.042
   POPPEL E, 1989, LEONARDO, V22, P83, DOI 10.2307/1575145
   Russell JA, 1999, J PERS SOC PSYCHOL, V76, P805, DOI 10.1037/0022-3514.76.5.805
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Sachs ME, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00404
   Salganik MJ, 2006, SCIENCE, V311, P854, DOI 10.1126/science.1121066
   SCHEIER MF, 1977, J PERS SOC PSYCHOL, V35, P625, DOI 10.1037/0022-3514.35.9.625
   Scherer K. R., 2013, EMOTIONAL POWER MUSI, P121, DOI [DOI 10.1093/ACPROF:OSO/9780199654888.003.0010, 10.1093/acprof:oso/9780199654888.003.0016, DOI 10.1093/ACPROF:OSO/9780199654888.003.0016]
   Schubert E, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00312
   Schubert E, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00837
   Silveira S, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00528
   Silveira S, 2015, EUR J SOC PSYCHOL, V45, P255, DOI 10.1002/ejsp.2076
   Silveira S, 2012, PERCEPTION, V41, P569, DOI 10.1068/p7191
   Sloboda J. A., 1991, Psychology of Music, V19, P110, DOI [10.1177/0305735691192002, DOI 10.1177/0305735691192002]
   Taruffi L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0110490
   Vuilleumier P, 2005, TRENDS COGN SCI, V9, P585, DOI 10.1016/j.tics.2005.10.011
   Wilson M, 2002, PSYCHON B REV, V9, P625, DOI 10.3758/BF03196322
   ZAJONC RB, 1965, SCIENCE, V149, P269, DOI 10.1126/science.149.3681.269
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
   Ziv N, 2004, P 8 INT C MUS PERC C, P571
NR 48
TC 9
Z9 12
U1 9
U2 40
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1612-4782
EI 1612-4790
J9 COGN PROCESS
JI Cogn. Process.
PD FEB
PY 2018
VL 19
IS 1
BP 133
EP 139
DI 10.1007/s10339-017-0832-7
PG 7
WC Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA FV5YE
UT WOS:000424657500014
PM 28986700
DA 2024-01-09
ER

PT J
AU Bugos, J
   DeMarie, D
   Torres, M
   Fuller, N
AF Bugos, Jennifer
   DeMarie, Darlene
   Torres, Miranda
   Fuller, Nicole
TI Face the music: Children's facial affect in musical imitation and
   improvisation tasks
SO PSYCHOLOGY OF MUSIC
LA English
DT Article
DE facial affect; music training; improvisation; singing; children
ID EMOTION; EXPRESSIONS; DISTINCTION; COMPETENCE; APPARENT; REAL
AB The purpose of this study was to examine facial affect of young children who completed a singing task that included imitation and improvisation. Eighty-nine children (4-6 years: 45 male and 44 female participants) completed three singing conditions from a standard singing test battery (i.e., Advancing Interdisciplinary Research in Singing-Test Battery of Singing Skills [AIRS-TBSS]). These included singing a favorite song, imitating a song, and improvising a song ending. Facial affect was analyzed with Noldus FaceReader software, and subjective responses also were collected. Results revealed children exhibited a happy emotion most prominently during the improvisation and favorite song conditions compared with the imitation condition. However, a higher percentage of surprised emotions were found during the imitation condition. Frequency analysis revealed a significantly different range and final note for the improvisation condition compared with imitation. Children's self-reported ratings of happiness were related to their displayed facial affect (i.e., happiness) scores in FaceReader (p < .05). Qualitative data analysis revealed three emerging themes of song familiarity, object association, and song preference. Children exhibited more positive affect when singing a favorite song or improvising. Based on the type of vocal performance task, it is necessary to consider how young children respond to vocal tasks.
C1 [Bugos, Jennifer; DeMarie, Darlene; Torres, Miranda; Fuller, Nicole] Univ S Florida, Tampa, FL 33620 USA.
C3 State University System of Florida; University of South Florida
RP Bugos, J (corresponding author), Univ S Florida, Tampa, FL 33620 USA.
EM bugosj@usf.edu
OI Bugos, Jennifer/0000-0001-8061-3752
FU Research: Art Works program at the National Endowment for the Arts
   [16-3800-7013]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This
   project was supported in part or in whole by an award from the Research:
   Art Works program at the National Endowment for the Arts:
   Grant#16-3800-7013.
CR Adachi M, 2000, MUSIC PERCEPT, V18, P213
   [Anonymous], 2011, PSYCHOMUSICOLOGY MUS, DOI [DOI 10.1037/H0094005, 10.1037/h0094005]
   Barrett LF, 2019, PSYCHOL SCI PUBL INT, V20, P1, DOI 10.1177/1529100619832930
   Boersma, 2019, PRAAT SYSTEM DOING P
   Brandt A, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00327
   Buchanan H, 2010, CHILD CARE HLTH DEV, V36, P534, DOI 10.1111/j.1365-2214.2009.01033.x
   CAMPOS JJ, 1994, MONOGR SOC RES CHILD, V59, P284, DOI 10.2307/1166150
   Castro VL, 2018, EMOTION, V18, P260, DOI 10.1037/emo0000354
   Cohen AJ, 2015, MUSIC SCI, V19, P238, DOI 10.1177/1029864915599599
   Cohen J, 1988, STAT POWER ANAL BEHA
   DeMarie D, 2020, HLTH DEV YOUNG CHILD, P151
   Denham SA, 2003, CHILD DEV, V74, P238, DOI 10.1111/1467-8624.00533
   Durbin CE, 2010, EMOTION, V10, P519, DOI 10.1037/a0019008
   Erickson K, 2003, BRAIN COGNITION, V52, P52, DOI 10.1016/S0278-2626(03)00008-3
   Fong FTK, 2020, J EXP CHILD PSYCHOL, V198, DOI 10.1016/j.jecp.2020.104879
   Franco F, 2017, PSYCHOL MUSIC, V45, P131, DOI 10.1177/0305735616652954
   GOETZE M, 1989, B COUN RES MUSIC ED, P57
   Gosselin P, 2002, J GENET PSYCHOL, V163, P479, DOI 10.1080/00221320209598697
   GREEN GA, 1994, J RES MUSIC EDUC, V42, P105, DOI 10.2307/3345495
   Grossard C, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00446
   Hedden D, 2012, NATL ASS MUSIC ED, V30, P52, DOI [10.1177/8755123312438516, DOI 10.1177/8755123312438516]
   Heller SS, 2012, EARLY EDUC DEV, V23, P919, DOI 10.1080/10409289.2011.626387
   Ilari B, 2018, PSYCHOL MUSIC, V46, P500, DOI 10.1177/0305735617715515
   Ilari B, 2015, MUSIC SCI, V19, P265, DOI 10.1177/1029864915597566
   Ilari BS, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00062
   Izard C. E., 1991, The psychology of emotions, DOI DOI 10.1007/S12094-019-02067-1
   Izard C.E., 1997, ANN REV GERONTOLOGY, VVol. 17, P1
   Jones DE, 2015, AM J PUBLIC HEALTH, V105, P2283, DOI 10.2105/AJPH.2015.302630
   Kirschner S, 2010, EVOL HUM BEHAV, V31, P354, DOI 10.1016/j.evolhumbehav.2010.04.004
   Lewinski P, 2014, J NEUROSCI PSYCHOL E, V7, P227, DOI 10.1037/npe0000028
   Malloch S, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01680
   Marsh K., 2016, CHILD MUSICIAN HDB M, V2nd, P462
   McPherson MJ, 2016, SCI REP-UK, V6, DOI 10.1038/srep18460
   McPherson MJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0105144
   Misailidi P, 2006, SOC BEHAV PERSONAL, V34, P1285, DOI 10.2224/sbp.2006.34.10.1285
   Nili A, 2017, ACIS 2017 P, V99
   Noldus, 2019, AUTHOR
   Over H, 2013, CHILD DEV PERSPECT, V7, P6, DOI 10.1111/cdep.12006
   PEKRUN R, 1992, APPL PSYCHOL-INT REV, V41, P359, DOI 10.1111/j.1464-0597.1992.tb00712.x
   Pergola J, 2014, MUSIC ED CRISIS
   Picardo R, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0145643
   Rutkowski J, 2015, MUSIC PERCEPT, V32, P283, DOI 10.1525/MP.2015.32.3.283
   Shuster MM, 2020, COGNITION EMOTION, V34, P359, DOI 10.1080/02699931.2019.1611542
   Sosic-Vasic Z, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00146
   Stadler Elmer S., 2011, PSYCHOMUSICOLOGY, V21, P13, DOI [DOI 10.1037/H0094001, 10.1037/h0094001]
   Thompson R. A, 2006, BLACKWELL HDB EARLY, P317, DOI [DOI 10.1002/9780470757703.CH16, 10.1002/9780470757703.ch16]
   Veloso AL, 2012, SEMPRE STUD PSYCHOL, P73
   Welch G, 2012, JAPANESE J MUSIC ED, V39, P38
NR 48
TC 5
Z9 6
U1 1
U2 7
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0305-7356
EI 1741-3087
J9 PSYCHOL MUSIC
JI Psychol. Music
PD MAR
PY 2022
VL 50
IS 2
BP 460
EP 474
AR 03057356211003320
DI 10.1177/03057356211003320
EA APR 2021
PG 15
WC Psychology, Educational; Psychology, Applied; Music; Psychology,
   Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Psychology; Music
GA ZR6AQ
UT WOS:000644052600001
DA 2024-01-09
ER

PT J
AU Choi, Y
   Lee, S
   Jung, S
   Choi, IM
   Park, YK
   Kim, C
AF Choi, Youngimm
   Lee, Sungjun
   Jung, SungSoo
   Choi, In-Mook
   Park, Yon-Kyu
   Kim, Chobok
TI Development of an auditory emotion recognition function using
   psychoacoustic parameters based on the International Affective Digitized
   Sounds
SO BEHAVIOR RESEARCH METHODS
LA English
DT Article
DE Psychoacoustic parameters; Emotion recognition; Auditory emotion
   recognition; IADS-2; Emotional adjectives
ID MODELS; EXPRESSIONS; FEATURES; SIGNALS; SPEECH; AUDIO
AB The purpose of this study was to develop an auditory emotion recognition function that could determine the emotion caused by sounds coming from the environment in our daily life. For this purpose, sound stimuli from the International Affective Digitized Sounds (IADS-2), a standardized database of sounds intended to evoke emotion, were selected, and four psychoacoustic parameters (i.e., loudness, sharpness, roughness, and fluctuation strength) were extracted from the sounds. Also, by using an emotion adjective scale, 140 college students were tested to measure three basic emotions (happiness, sadness, and negativity). From this discriminant analysis to predict basic emotions from the psychoacoustic parameters of sound, a discriminant function with overall discriminant accuracy of 88.9 % was produced from training data. In order to validate the discriminant function, the same four psychoacoustic parameters were extracted from 46 sound stimuli collected from another database and substituted into the discriminant function. The results showed that an overall discriminant accuracy of 63.04 % was confirmed. Our findings provide the possibility that daily-life sounds, beyond voice and music, can be used in a human-machine interface.
C1 [Choi, Youngimm; Lee, Sungjun; Jung, SungSoo; Choi, In-Mook; Park, Yon-Kyu] Korea Res Inst Stand & Sci, Daejeon, South Korea.
   [Choi, Youngimm] Chungnam Natl Univ, Dept Psychol, Daejeon, South Korea.
   [Kim, Chobok] Kyungpook Natl Univ, Dept Psychol, Taegu 702701, South Korea.
C3 Korea Research Institute of Standards & Science (KRISS); Chungnam
   National University; Kyungpook National University
RP Kim, C (corresponding author), Kyungpook Natl Univ, Dept Psychol, 80 Daehak Ro, Taegu 702701, South Korea.
EM ckim@knu.ac.kr
FU Converging Research Center Program - Ministry of Education, Science and
   Technology [2012K001326]; Next Generation Fire Protection & Safety Core
   Technology Development Program - National Emergency Management Agency
   [NEMA-NG-2014-53]
FX This research was supported by the Converging Research Center Program
   funded by the Ministry of Education, Science and Technology (No.
   2012K001326) and the Next Generation Fire Protection & Safety Core
   Technology Development Program funded by the National Emergency
   Management Agency (No. NEMA-NG-2014-53).
CR Adolphs R, 2002, EMOTION, V2, P23, DOI 10.1037/1528-3542.2.1.23
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Bradley M.M., 2007, IADS-2): Affective Ratings of Sounds and Instruction Manual (Technical Report B- 3), V2nd
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   Castellano G, 2008, LECT NOTES COMPUT SC, V4868, P92, DOI 10.1007/978-3-540-85099-1_8
   Charest I, 2009, BMC NEUROSCI, V10, DOI 10.1186/1471-2202-10-127
   Dellaert F., 1996, 4 INT C SPOK LANG IC
   EKMAN P, 1983, SCIENCE, V221, P1208, DOI 10.1126/science.6612338
   Ekman P., 1973, Darwin and Facial Expression: A Century of Research in Review, P169, DOI DOI 10.1371/J0URNAL.P0NE.0014679
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Fastl H, 2005, COMMUNICATION ACOUSTICS, P139, DOI 10.1007/3-540-27437-5_6
   Fu ZY, 2011, IEEE T MULTIMEDIA, V13, P303, DOI 10.1109/TMM.2010.2098858
   Gerhard D., 2003, WORKING PAPER
   Jack RE, 2014, CURR BIOL, V24, P187, DOI 10.1016/j.cub.2013.11.064
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kalat JW, 2007, Emotion
   Katsis CD, 2008, IEEE T SYST MAN CY A, V38, P502, DOI 10.1109/TSMCA.2008.918624
   Kweon O., 2009, KOEAN J SCI EMOTION, V12, P403
   LANG PJ, 1994, PSYCHOL REV, V101, P211, DOI 10.1037/0033-295X.101.2.211
   Lee C. M., 2001, IEEE WORKSH AUT SPEE, DOI 10.1109/ASRU.2001.1034632
   Matos S, 2006, IEEE T BIO-MED ENG, V53, P1078, DOI 10.1109/TBME.2006.873548
   Navas E, 2006, IEEE T AUDIO SPEECH, V14, P1117, DOI 10.1109/TASL.2006.876121
   Pal P., 2006, IEEE INT C AC SPEECH
   Paquette S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00509
   Power MJ, 2006, COGNITION EMOTION, V20, P694, DOI 10.1080/02699930500367925
   SCHACHTER S, 1962, PSYCHOL REV, V69, P379, DOI 10.1037/h0046234
   Scherer KR, 2007, EMOTION, V7, P158, DOI 10.1037/1528-3542.7.1.158
   Steidl S., 2005, ICASSP 2005 PHIL PA
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   ZWICKER E, 1957, J ACOUST SOC AM, V29, P548, DOI 10.1121/1.1908963
NR 30
TC 6
Z9 7
U1 0
U2 27
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1554-351X
EI 1554-3528
J9 BEHAV RES METHODS
JI Behav. Res. Methods
PD DEC
PY 2015
VL 47
IS 4
BP 1076
EP 1084
DI 10.3758/s13428-014-0525-4
PG 9
WC Psychology, Mathematical; Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA CV8ED
UT WOS:000364511400014
PM 25319038
OA Bronze
DA 2024-01-09
ER

PT J
AU Ollivier, R
   Goupil, L
   Liuni, M
   Aucouturier, JJ
AF Ollivier, Rosalie
   Goupil, Louise
   Liuni, Marco
   Aucouturier, Jean-Julien
TI ENJOY THE VIOLENCE: IS APPRECIATION FOR EXTREME MUSIC THE RESULT OF
   COGNITIVE CONTROL OVER THE THREAT RESPONSE SYSTEM?
SO MUSIC PERCEPTION
LA English
DT Article
DE music; emotion; metal; threat; cognitive load
ID BRAIN; LOAD; ATTENTION; AROUSAL; SOUND; FEAR; COMMUNICATION; EMOTIONS;
   REGIONS; SCREAMS
AB TRADITIONAL NEUROBIOLOGICAL THEORIES OF musical emotions explain well why extreme music such as punk, hardcore, or metal-whose vocal and instrumental characteristics share much similarity with acoustic threat signals-should evoke unpleasant feelings for a large proportion of listeners. Why it doesn't for metal music fans, however, is controversial: metal fans may differ from non-fans in how they process threat signals at the sub-cortical level, showing deactivated responses that differ from controls. Alternatively, appreciation for metal may depend on the inhibition by cortical circuits of a normal low-order response to auditory threat. In a series of three experiments, we show here that, at a sensory level, metal fans actually react equally negatively, equally fast, and even more accurately to cues of auditory threat in vocal and instrumental contexts than non-fans; conversely, we tested the hypothesis that cognitive load reduced fans' appreciation of metal to the level experienced by non-fans, but found only limited support that it was the case. Nevertheless, taken together, these results are not compatible with the idea that extreme music lovers do so because of a different sensory response to threat, and highlight a potential contribution of controlled cognitive processes in their aesthetic experience.
C1 [Ollivier, Rosalie; Goupil, Louise; Liuni, Marco; Aucouturier, Jean-Julien] Sorbonne Univ, IRCAM, CNRS, Paris, France.
C3 Sorbonne Universite; Centre National de la Recherche Scientifique (CNRS)
RP Aucouturier, JJ (corresponding author), Sorbonne Univ, IRCAM, CNRS, STMS, 1 Pl Igor Stravinsky, F-75004 Paris, France.
EM aucouturier@gmail.com
RI Goupil, Louise/AAJ-9207-2021
OI Goupil, Louise/0000-0003-4342-9408
FU ERC StG CREAM [335536]; European Research Council (ERC) [335536] Funding
   Source: European Research Council (ERC)
FX This work was funded by ERC StG CREAM (335536) to JJA.
CR ABBEY E. J., HARDCORE PUNK OTHER
   Abitbol R, 2015, J NEUROSCI, V35, P2308, DOI 10.1523/JNEUROSCI.1878-14.2015
   Anikin A, 2018, J NONVERBAL BEHAV, V42, P53, DOI 10.1007/s10919-017-0267-y
   [Anonymous], 2000, ARCANA MUSICIANS MUS
   Arnal LH, 2015, CURR BIOL, V25, P2051, DOI 10.1016/j.cub.2015.06.043
   Asutay E, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-09975-8
   Barrett LF, 2017, SOC COGN AFFECT NEUR, V12, P1, DOI 10.1093/scan/nsw154
   Belin P, 2015, CURR BIOL, V25, pR805, DOI 10.1016/j.cub.2015.07.027
   Bellogin A., 2013, P 7 INT AAAI C WEBL
   BLAIR ME, 1992, J ADVERTISING, V21, P35, DOI 10.1080/00913367.1992.10673358
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Blumstein DT, 2012, BIOL LETTERS, V8, P744, DOI 10.1098/rsbl.2012.0374
   Blumstein DT, 2009, ETHOLOGY, V115, P1074, DOI 10.1111/j.1439-0310.2009.01691.x
   Bodner E, 2015, PSYCHOL MUSIC, V43, P641, DOI 10.1177/0305735614532000
   Brattico E, 2017, BEHAV BRAIN SCI, V40, DOI 10.1017/S0140525X17001613
   Brown A., 2016, Global Metal Music and Culture: Current Directions in Metal Studies
   Bryant LR, 2013, PERS CONTIN PHILOS, P4
   Bryson B, 1996, AM SOCIOL REV, V61, P884, DOI 10.2307/2096459
   Cespedes-Guevara J, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00215
   Den ML, 2015, DEV PSYCHOBIOL, V57, P818, DOI 10.1002/dev.21330
   Diano M, 2017, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.02029
   Duncan J, 2000, TRENDS NEUROSCI, V23, P475, DOI 10.1016/S0166-2236(00)01633-7
   Erk S, 2007, NEUROIMAGE, V37, P623, DOI 10.1016/j.neuroimage.2007.05.006
   Escoffier N, 2013, HUM BRAIN MAPP, V34, P1796, DOI 10.1002/hbm.22029
   Fanselow MS, 2018, BEHAV RES THER, V100, P24, DOI 10.1016/j.brat.2017.10.012
   Feinstein JS, 2013, NAT NEUROSCI, V16, P270, DOI 10.1038/nn.3323
   Fitch WT, 2002, ANIM BEHAV, V63, P407, DOI 10.1006/anbe.2001.1912
   GENTILUCCI M., 2018, P INT COMP MUS C ICM
   GILBERT DT, 1993, J PERS SOC PSYCHOL, V65, P221, DOI 10.1037/0022-3514.65.2.221
   Gowensmith WN, 1997, J MUSIC THER, V34, P33, DOI 10.1093/jmt/34.1.33
   Greene JD, 2008, COGNITION, V107, P1144, DOI 10.1016/j.cognition.2007.11.004
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Labbé E, 2007, APPL PSYCHOPHYS BIOF, V32, P163, DOI 10.1007/s10484-007-9043-9
   LACHER KT, 1994, J CONSUM RES, V21, P366, DOI 10.1086/209404
   Lavie N, 2010, CURR DIR PSYCHOL SCI, V19, P143, DOI 10.1177/0963721410370295
   LeDoux JE, 2017, P NATL ACAD SCI USA, V114, pE2016, DOI 10.1073/pnas.1619316114
   LeDoux JE, 2016, AM J PSYCHIAT, V173, P1083, DOI 10.1176/appi.ajp.2016.16030353
   Lee YC, 2007, HUM FACTORS, V49, P721, DOI 10.1518/001872007X215791
   Ma WY, 2015, P NATL ACAD SCI USA, V112, P14563, DOI 10.1073/pnas.1515087112
   MCALPIN C., 1925, MUSICAL Q, V11, P427
   McCarthy L, 2017, ATTEN PERCEPT PSYCHO, V79, P352, DOI 10.3758/s13414-016-1201-9
   McCrory EJ, 2013, BRIT J PSYCHIAT, V202, P269, DOI 10.1192/bjp.bp.112.116624
   Menninghaus W, 2017, BEHAV BRAIN SCI, V40, DOI 10.1017/S0140525X17000309
   Miu AC, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030618
   Miyake A, 2000, COGNITIVE PSYCHOL, V41, P49, DOI 10.1006/cogp.1999.0734
   Oliva M, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-23265-x
   Olsen KN, 2018, MUSIC PERCEPT, V35, P527, DOI 10.1525/MP.2018.35.5.527
   Opolko F., 1989, MCGILL U MASTER SAMP
   PACHET F., 2000, P COMP ASS INF RETR
   Panksepp J., 2004, Affective Neuroscience: The Foundations of Human and Animal Emotions
   Patel AD, 2010, MUSIC LANGUAGE BRAIN
   Pessoa L, 2002, P NATL ACAD SCI USA, V99, P11458, DOI 10.1073/pnas.172403899
   Rea C., 2010, EMPORIA STATE RES ST, V46, P1
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   Schlenker P, 2017, MUSIC PERCEPT, V35, P3, DOI 10.1525/MP.2017.35.1.3
   Sharman L, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00272
   Siegel P, 2017, HUM BRAIN MAPP, V38, P2466, DOI 10.1002/hbm.23533
   STACK S, 1994, SUICIDE LIFE-THREAT, V24, P15
   SUN Y., 2017, NEUROREPORT, V30, P317
   Sun YN, 2019, ROY SOC OPEN SCI, V6, DOI 10.1098/rsos.181580
   Tassy S, 2012, SOC COGN AFFECT NEUR, V7, P282, DOI 10.1093/scan/nsr008
   THOMPSON W. F., 2018, PSYCHOL POP MEDIA, V8, P218, DOI DOI 10.1037/ppm0000184
   Thompson WF, 2018, PHYS LIFE REV, V25, P128, DOI 10.1016/j.plrev.2018.03.016
   Tsai CG, 2010, MUSIC PERCEPT, V27, P209, DOI 10.1525/MP.2010.27.3.209
   van der Wal RC, 2013, PSYCHOL SCI, V24, P1277, DOI 10.1177/0956797612471953
   van Dillen LF, 2018, COGN AFFECT BEHAV NE, V18, P447, DOI 10.3758/s13415-018-0579-3
   Van Dillen LF, 2009, NEUROIMAGE, V45, P1212, DOI 10.1016/j.neuroimage.2009.01.016
   Vuilleumier P, 2001, NEURON, V30, P829, DOI 10.1016/S0896-6273(01)00328-2
   Vuoskoski JK, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00439
   Vuoskoski JK, 2012, MUSIC PERCEPT, V29, P311, DOI 10.1525/MP.2012.29.3.311
   WEINSTEIN Deena, 2000, HEAVY METAL MUSIC IT
   Whalen PJ, 2004, SCIENCE, V306, P2061, DOI 10.1126/science.1103617
   Wilson-Mendenhall CD, 2013, PSYCHOL SCI, V24, P947, DOI 10.1177/0956797612464242
NR 75
TC 7
Z9 7
U1 0
U2 7
PU UNIV CALIFORNIA PRESS
PI OAKLAND
PA 155 GRAND AVE, SUITE 400, OAKLAND, CA 94612-3758 USA
SN 0730-7829
J9 MUSIC PERCEPT
JI Music Percept.
PD DEC
PY 2019
VL 37
IS 2
BP 95
EP 110
DI 10.1525/MP.2019.37.2.95
PG 16
WC Music; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music; Psychology
GA NT9RD
UT WOS:000573278100001
OA Green Published
DA 2024-01-09
ER

PT J
AU Castellary-López, M
   Muñoz, JRM
   Figueredo-Canosa, V
   Ortiz-Jiménez, L
AF Castellary-Lopez, Macarena
   Munoz Munoz, Juan Rafael
   Figueredo-Canosa, Victoria
   Ortiz-Jimenez, Luis
TI Implementation of an Intervention Plan for Emotional Development in
   People with Down Syndrome
SO INTERNATIONAL JOURNAL OF ENVIRONMENTAL RESEARCH AND PUBLIC HEALTH
LA English
DT Article
DE music; emotions; Down syndrome
AB The importance of music, as well as the different and diverse possibilities that it offers, favors the emotional development of any person. This research is based on the development and application of a set of activities, whose transversal axis is the use of music, to favor and promote the emotional development of people with Down syndrome. This application of activities was developed with a group of eight participants, between the ages of twenty and forty-five years old. Additionally, under a total duration of eight working sessions. In these sessions, listening, vocal, instrumental, and movement activities were developed. For each of the emotions worked on; joy, fear, anger, sadness, calm, and love, a story and a song from the story were selected for each one of them. The methodology used was qualitative, using program evaluation. For this purpose, on the one hand, the data obtained during the different sessions were analyzed, and on the other hand, the data collected in the two discussion groups carried out were analyzed. Finally, the data obtained were organized into six categories: image recognition, observation of emotions, experience of emotions, identification of emotions, recognition of emotions, and finally, enjoyment of emotions. It could be seen that, after the sessions, there was a significant improvement in the different categories. However, in the categories of identification of emotions and recognition of emotions, the results were more favorable compared to the rest.
C1 [Castellary-Lopez, Macarena; Munoz Munoz, Juan Rafael; Figueredo-Canosa, Victoria; Ortiz-Jimenez, Luis] Univ Almeria, Fac Educ, Dept Educ, Almeria 04120, Spain.
C3 Universidad de Almeria
RP Ortiz-Jiménez, L (corresponding author), Univ Almeria, Fac Educ, Dept Educ, Almeria 04120, Spain.
EM mcl142@ual.es; jrmunoz@ual.es; vfc310@ual.es; lortizj@ual.es
RI Jiménez, Luis LOJ Ortiz/U-2031-2017; FIGUEREDO CANOSA,
   VICTORIA/S-9283-2017
OI Jiménez, Luis LOJ Ortiz/0000-0002-3943-1989; FIGUEREDO CANOSA,
   VICTORIA/0000-0003-4857-9552; Castellary Lopez,
   Macarena/0000-0002-9463-1764
FU R + D + I project of the national call of the Spanish government
   [EDU2016-75574-P]
FX This research is funded by the R + D + I project of the national call of
   the Spanish government EDU2016-75574-P. "Study on the educational
   response to students with Specific Needs of Educational Support
   associated with Disability" and my doctoral thesis.
CR Amusategui C, 1996, EUFONIA, V4, P85
   [Anonymous], 2003, ED SIGLO
   [Anonymous], 1998, DIEZ CUARTO
   Arano Gisbert J.C, 1994, REV MEDIOS ED, V2, P65
   Bisquerra R., 2016, 1 JORN MAST RES CONF
   Cabedo-Mas P, 2020, INTERDISCIP SCI REV, V45, P158
   Carrion J.J., 2020, EDUCACION INCLUSIVA, P295
   Castellary Lopez M., 2020, THESIS U ALMERIA ALM
   CIF, 2011, CLAS INT FUNC DISC S
   Goleman D., 1996, La inteligencia emocional
   Angel NG, 2019, ACCION PSICOL, V16, P143, DOI 10.5944/ap.16.1.22555
   Jauset Berrocal J.A., 2008, MUSICA NEUROCIENCIA
   Jeffery T, 2020, PSYCHOL MUSIC, V48, P724, DOI 10.1177/0305735619827363
   Lacarcel Moreno J, 2005, REV U GRANADA, V35, P11
   Mayer J.D., 2015, MANUAL INTELIGENCIA, P25
   Nogaj AA, 2020, J RES MUSIC EDUC, V68, P78, DOI 10.1177/0022429420901513
   Prause-Weber M, 2006, EUFONIA, V37, P7
   Roch M, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00692
   Ruiz Rodriguez E., 2016, TODO MUNDO EMOCIONES
   Salvador Mata F., 2001, ENCICLOPEDIA PSICOPE
   Salvador Mata F., 2005, BASES PSICOPEDAGOGIC, P193
   Sanchez Palomino A., 2002, EDUCACION ESPECIAL C
   Siempre A., 2015, CORAZON
   UNESCO, 1990, Declaracion Mundial sobre Educacion para Todos y Marco de Accion para Satisfacer las Necesidades Basicas de Aprendizaje
   Verdugo M.A., 2001, AT DIV SIST ED
   Vivas Garcia M, 2003, REV U INVESTIG, V4, P1
   Ye J, 2020, REV ARGENT CLIN PSIC, V29, P322
NR 27
TC 0
Z9 0
U1 0
U2 4
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1660-4601
J9 INT J ENV RES PUB HE
JI Int. J. Environ. Res. Public Health
PD MAY
PY 2021
VL 18
IS 9
AR 4763
DI 10.3390/ijerph18094763
PG 12
WC Environmental Sciences; Public, Environmental & Occupational Health
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Environmental Sciences & Ecology; Public, Environmental & Occupational
   Health
GA SB8VO
UT WOS:000650264800001
PM 33947029
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Williams, D
AF Williams, Duncan
TI On the Affective Potential of the Recorded Voice
SO JOURNAL OF THE AUDIO ENGINEERING SOCIETY
LA English
DT Article
ID MUSICAL EMOTIONS; TEMPO; CLASSIFICATION; PERCEPTION; MECHANISMS;
   EXPRESSION; SPEECH; LEVEL; MODE; CUES
AB Affective science increasingly concludes that the voice is a powerful tool for emotional communication. The process of creating a finished product by means of studio recording gives listeners the opportunity to engage in experiences of the voice that are quite unlike that which would be achieved in a traditional concert hall or live performance and even more so when compared with day-to-day speech. The audio production chain, from sound capture using particular sound recording techniques, to specific effects processing affords the engineer (or the vocalist themself) unparalleled access to shape the recorded voice, and thereby enhance the affective impact of the voice for the listener. This paper expands upon previous work presented at the 139th AES Convention in New York [1] defining affective potential and considers a number of examples where one of the points in the production chain has been exploited to increase the affective impact of the voice (either deliberately or by happenstance), suggesting that the affective sciences might find the analysis of such applications of the recorded voice a fertile ground for future investigation of perceived affective correlates and their underlying musical, or more generally, acoustic, cues.
C1 [Williams, Duncan] Univ Plymouth, ICCMR, Mus Artificial Intelligence, Plymouth PL4 8AA, Devon, England.
C3 University of Plymouth
RP Williams, D (corresponding author), Univ Plymouth, ICCMR, Mus Artificial Intelligence, Plymouth PL4 8AA, Devon, England.
EM Duncan.williams@plymouth.ac.uk
OI Williams, Duncan/0000-0003-4793-8330
CR [Anonymous], 1996, CONT MUSIC REV, DOI DOI 10.1080/07494469608629693
   [Anonymous], 2006, P 1 ACM SIGCHISIGART, DOI DOI 10.1145/1121241.1121281
   [Anonymous], 2007, 20 CENTURY MUSIC
   [Anonymous], 1999, POP MUSIC
   [Anonymous], THE VOCODER
   Arizmendi TG, 2011, PSYCHOANAL PSYCHOL, V28, P405, DOI 10.1037/a0024176
   Bach DR, 2008, NEUROIMAGE, V42, P919, DOI 10.1016/j.neuroimage.2008.05.034
   Baum KM, 1998, J NONVERBAL BEHAV, V22, P89, DOI 10.1023/A:1022954014365
   Born G., 2013, Music, Sound and Space: Transformations of Public and Private Experience
   Braten S., 2007, BEING MOVED MIRROR N, V68
   Bratus Alessandro, 2016, ROCK MUSIC STUDIES, V3, P41, DOI DOI 10.1080/19401159.2015.1129112
   Brown Alan, 2007, Assessing the Intrinsic Impacts of a Live Performance
   Chau CJ, 2016, J AUDIO ENG SOC, V64, P918, DOI 10.17743/jaes.2016.0049
   Coutinho E, 2011, EMOTION, V11, P921, DOI 10.1037/a0024700
   Cowie R., 2009, AFFECTIVE COMPUTING, P1
   Crowell CR, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P3735, DOI 10.1109/IROS.2009.5354204
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Davies S., 2011, P 12 INT SOC MUS INF, P741
   den Brinker B, 2012, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2012-24
   Dickinson Kay, 2001, Popular Music, V20, P333, DOI DOI 10.1017/S0261143001001532
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   FRICK RW, 1985, PSYCHOL BULL, V97, P412, DOI 10.1037/0033-2909.97.3.412
   Gabrielsson A, 2001, MUSIC SCI, V5, P123, DOI 10.1177/10298649020050S105
   Gagnon L, 2003, COGNITION EMOTION, V17, P25, DOI 10.1080/02699930302279
   Garrard C, 2013, CONTEMP MUSIC REV, V32, P511, DOI 10.1080/07494467.2013.849878
   GOLD B, 1967, IEEE T ACOUST SPEECH, VAU15, P148, DOI 10.1109/TAU.1967.1161919
   Hedelin P., 1986, ICASSP 86 Proceedings. IEEE-IECEJ-ASJ International Conference on Acoustics, Speech and Signal Processing (Cat. No.86CH2243-4), P465
   Hevner K, 1937, AM J PSYCHOL, V49, P621, DOI 10.2307/1416385
   Hodgson J, 2010, POP MUSIC, V29, P283, DOI 10.1017/S0261143010000085
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Ishiguro MA, 2010, THESIS
   JOHNSON R, 1991, COMPUT MUSIC J, V15, P12, DOI 10.2307/3680912
   Josephson D., 1999, 107 CONV AUD ENG SOC
   Juslin P. N., 2010, Handbook of music and emotion: Theory, research, applications, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0022
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   KALLIOPUSKA M, 1986, PERCEPT MOTOR SKILL, V62, P187, DOI 10.2466/pms.1986.62.1.187
   KLEIJN WB, 1995, INT CONF ACOUST SPEE, P508, DOI 10.1109/ICASSP.1995.479640
   Knobloch S, 2002, J COMMUN, V52, P351, DOI 10.1093/joc/52.2.351
   Knox D, 2011, J ACOUST SOC AM, V130, P1673, DOI 10.1121/1.3621029
   Kopf B., 2002, UNDERCURR HIDDEN WIR, P141
   Lacasse S., 2000, PSYCHOMUSICOLOGY J R, V17, P56
   LaFrance M., 1982, Interaction rhythms: Periodicity in communicative behavior, P279
   Lamont A, 2011, MUSIC SCI, V15, P139, DOI 10.1177/1029864911403366
   Laurier C., 2008, P COMP MUS MOD RETR
   Lewisohn Mark, 1988, BEATLES RECORDING SE
   MASSENBURG G, 1972, J AUDIO ENG SOC, V20, P428
   Meyer L. B., 1956, IMPORTANT ATTEMPT DI, P256
   Molnar-Szakacs I, 2006, SOC COGN AFFECT NEUR, V1, P235, DOI 10.1093/scan/nsl029
   Nicolaou MA, 2011, IEEE T AFFECT COMPUT, V2, P92, DOI 10.1109/T-AFFC.2011.9
   Ruskin A., 2008, J ART REC PROD, V3
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Scherer K., 1977, MOTIV EMOTION, V1, P331, DOI [DOI 10.1007/BF00992539, 10.1007/bf00992539]
   Scherer KR, 2004, J NEW MUSIC RES, V33, P239, DOI 10.1080/0929821042000317822
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Schubert E, 2006, ACTA ACUST UNITED AC, V92, P820
   Scobie Stephen, 2000, Intricate Preparations: Writing Leonard Cohen
   Tamagawa R, 2011, INT J SOC ROBOT, V3, P253, DOI 10.1007/s12369-011-0100-4
   Taruffi L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0110490
   Thayer RE., 1990, The Biopsychology of Mood and Activation
   Toyka F., 2005, KRAFTWERK KONSTRUKTI
   Vickers E., 2010, 129 CONV AUD ENG SOC
   Vickers E, 2011, J AUDIO ENG SOC, V59, P346
   Visconti T., 2011, KEY TRACKS T VISCONT
   Vuoskoski JK, 2012, PSYCHOL AESTHET CREA, V6, P204, DOI 10.1037/a0026937
   Vuoskoski JK, 2012, MUSIC PERCEPT, V29, P311, DOI 10.1525/MP.2012.29.3.311
   Vuoskoski JK, 2011, MUSIC SCI, V15, P159, DOI 10.1177/1029864911403367
   Welch G. F., 2004, MUSICAL COMMUNICATIO, P239
   Williams D., 2014, PSYCHOL MUSIC, DOI 10.1177/0305735614543282
   Williams D., 2015, 139 CONV AUD ENG SOC
   WISHART T, 1988, COMPUT MUSIC J, V12, P21, DOI 10.2307/3680150
   Wright B., 2008, FILM HIST INTERDISCI, V38, P96
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 73
TC 1
Z9 3
U1 0
U2 9
PU AUDIO ENGINEERING SOC
PI NEW YORK
PA 60 E 42ND ST, NEW YORK, NY 10165-2520 USA
SN 1549-4950
J9 J AUDIO ENG SOC
JI J. Audio Eng. Soc.
PD JUN
PY 2016
VL 64
IS 6
BP 429
EP 437
DI 10.17743/jaes.2016.0019
PG 9
WC Acoustics; Engineering, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Acoustics; Engineering
GA DQ0WY
UT WOS:000378923700005
DA 2024-01-09
ER

PT J
AU Bugos, JA
   DeMarie, D
   Torres, MR
   Lamrani, D
   Gbadamosi, AA
AF Bugos, Jennifer A.
   DeMarie, Darlene
   Torres, Miranda Rose
   Lamrani, Darbi
   Gbadamosi, Ayo A.
TI The Effects of a Multimodal Music Program on Young Children's Facial
   Expressions During Controlled Singing Tasks
SO MUSICAE SCIENTIAE
LA English
DT Article
DE facial expression; children; music training; singing; improvisation;
   creativity
ID AIRS TEST BATTERY; EMOTION; IMPROVISATION; PERFORMANCE; VALIDATION;
   MELODY
AB Understanding children's emotional perceptions of creative tasks can contribute to the optimal design of music programs. Little is known of how young children perceive vocal tasks, and whether music training changes their emotional perceptions. This research examined children's facial expressions while performing vocal imitation and improvisation tasks before and after music training. Young children (N=79) aged four to six years were randomly assigned to a multimodal music program, Lego training, or a no-treatment control group. Their facial expressions while performing the tasks were analyzed, and learning outcomes were assessed by measuring participants' pitch accuracy and improvisation skills at pre-and post-training. The results yielded no significant differences among the groups' facial expressions. There was, however, a significant main effect of time such that participants showed more Surprise while performing vocal improvisation tasks. While participants in the multimodal music program scored higher on measures of pitch accuracy and improvisation skill, it may be necessary to increase the duration of early childhood music programs to reduce their feelings of apprehension when performing vocal improvisation tasks.
C1 [Bugos, Jennifer A.; Torres, Miranda Rose; Lamrani, Darbi; Gbadamosi, Ayo A.] Univ S Florida, Sch Music, 4202 E Fowler Ave,MUS 101, Tampa, FL 33620 USA.
   [DeMarie, Darlene] Univ S Florida, Dept Educ & Psychol Studies, Tampa, FL 33620 USA.
C3 State University System of Florida; University of South Florida; State
   University System of Florida; University of South Florida
RP Bugos, JA (corresponding author), Univ S Florida, Sch Music, 4202 E Fowler Ave,MUS 101, Tampa, FL 33620 USA.
EM Bugosj@usf.edu
FU National Endowment for the Arts [16-3800-7013]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This work
   was supported by the National Endowment for the Arts under Grant
   16-3800-7013. We would like to thank the NEA for their generous support.
   We would also like to thank Daisy Solis, Carla Formoso Pico, and
   Gisselle Palaca for testing assistance.
CR Adachi M, 2000, MUSIC PERCEPT, V18, P213
   [Anonymous], 1986, Primary measures of music audiation and the intermediate measures of music audiation
   [Anonymous], 2011, PSYCHOMUSICOLOGY MUS, DOI [DOI 10.1037/H0094005, 10.1037/h0094005]
   Bandura A., 1977, Social Learning Theory, V1
   Barrett MS, 2020, PSYCHOL MUSIC, V48, P120, DOI 10.1177/0305735618790355
   Beckstead, 2013, MUSIC EDUC J, V99, P69, DOI [10.1177/0027432112467822, DOI 10.1177/0027432112467822]
   Blasko G., 1987, B COUNCIL RES MUSIC, V91, P77
   Bolduc J, 2021, EARLY CHILD DEV CARE, V191, P1886, DOI 10.1080/03004430.2020.1781841
   Buchanan H, 2010, CHILD CARE HLTH DEV, V36, P534, DOI 10.1111/j.1365-2214.2009.01033.x
   Bugos J, 2022, PSYCHOL MUSIC, V50, P460, DOI 10.1177/03057356211003320
   Bugos JA, 2017, PSYCHOL MUSIC, V45, P855, DOI 10.1177/0305735617692666
   BUTTON S, 2006, MUSIC EDUC RES, V8, P417, DOI DOI 10.1080/14613800600957529
   Campbell P.S., 2014, MUSIC CHILDHOOD PRES, V4th ed.
   Chandler M. D., 2018, Update: Applications ofResearch in Music Education, V37, P42, DOI DOI 10.1177/8755123318763002
   Chorus America, 2019, CHOR IMP STUD SING L
   Cohen AJ, 2015, MUSIC SCI, V19, P301, DOI 10.1177/1029864915599598
   Cohen AJ, 2015, MUSIC SCI, V19, P238, DOI 10.1177/1029864915599599
   Coulson AN, 2013, INT J MUSIC EDUC, V31, P428, DOI 10.1177/0255761413495760
   Countryman J, 2016, MUSIC EDUC RES, V18, P1, DOI 10.1080/14613808.2015.1019440
   Persellin DC, 2006, B COUN RES MUSIC ED, P39
   Demorest SM, 2017, J RES MUSIC EDUC, V64, P405, DOI 10.1177/0022429416680096
   Diamond A, 2012, CURR DIR PSYCHOL SCI, V21, P335, DOI 10.1177/0963721412453722
   Dissanayake E., 2009, Cogn. Semiot, V5, P136, DOI [10.1515/cogsem.2009.5.fall2009.136, DOI 10.1515/COGSEM.2009.5.FALL2009.136]
   Dunn L. M., 2007, Peabody Picture Vocabulary Test
   Durbin CE, 2010, EMOTION, V10, P519, DOI 10.1037/a0019008
   Erickson K, 2003, BRAIN COGNITION, V52, P52, DOI 10.1016/S0278-2626(03)00008-3
   Frewen KG, 2010, J RES MUSIC EDUC, V57, P320, DOI 10.1177/0022429409351178
   Friesen E., 1978, Facialaction coding system: Manual, V3, P5, DOI DOI 10.1708/1069.11717
   Grossard C, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00446
   Ilari B, 2018, PSYCHOL MUSIC, V46, P500, DOI 10.1177/0305735617715515
   Ilari B, 2009, J RES MUSIC EDUC, V56, P357, DOI 10.1177/0022429408329107
   Innis, 2009, SUZANNE LANGER FOCUS
   Koutsoupidou T, 2009, PSYCHOL MUSIC, V37, P251, DOI 10.1177/0305735608097246
   Lamont A, 2008, J EARLY CHILD RES, V6, P246, DOI 10.1177/1476718X08094449
   Langer S., 1953, Feeling and form
   Larsson C, 2019, BRIT J MUSIC EDUC, V36, P49, DOI 10.1017/S026505171800013X
   Leighton G, 2006, MUSIC EDUC RES, V8, P311, DOI DOI 10.1080/14613800600957461
   Lewinski P, 2014, J NEUROSCI PSYCHOL E, V7, P227, DOI 10.1037/npe0000028
   MIZENER CP, 1993, J RES MUSIC EDUC, V41, P233, DOI 10.2307/3345327
   NAfME, 2014, NAT ASS MUS ED STAND
   Nath S, 2014, LEARN INSTR, V32, P73, DOI 10.1016/j.learninstruc.2014.01.006
   Noldus, 2019, FACEREADER 8 0 SOFTW
   Norgaard M, 2019, J RES MUSIC EDUC, V67, P339, DOI 10.1177/0022429419863038
   Plutchik R, 1988, Emotions and Psychopathology, P1, DOI DOI 10.1007/978-1-4757-1987-1_1
   Raju M, 2015, MUSIC SCI, V19, P282, DOI 10.1177/1029864915598663
   Rhoades BL, 2009, J APPL DEV PSYCHOL, V30, P310, DOI 10.1016/j.appdev.2008.12.012
   Rutkowski J, 2015, MUSIC PERCEPT, V32, P283, DOI 10.1525/MP.2015.32.3.283
   Saarikallio S, 2019, MUSIC EDUC RES, V21, P596, DOI 10.1080/14613808.2019.1670150
   Stöckli S, 2018, BEHAV RES METHODS, V50, P1446, DOI 10.3758/s13428-017-0996-1
   Swaminathan S, 2015, EMOT REV, V7, P189, DOI 10.1177/1754073914558282
   Taggart, 2005, DEV PRACTICAL APPL M, P399
   Timmers R, 2014, MUSIC PERCEPT, V31, P470, DOI 10.1525/MP.2014.31.5.470
   U.S. Department of Health  Human Services, 2015, AG REP HEAD START EA
   Welch GF, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00803
NR 54
TC 3
Z9 4
U1 1
U2 6
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1029-8649
EI 2045-4147
J9 MUSIC SCI
JI Music Sci.
PD MAR
PY 2023
VL 27
IS 1
BP 54
EP 69
AR 10298649211021463
DI 10.1177/10298649211021463
EA JUN 2021
PG 16
WC Music; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music; Psychology
GA 9F0AH
UT WOS:000665236300001
DA 2024-01-09
ER

PT J
AU Trevarthen, C
AF Trevarthen, Colwyn
TI Discovering Our Music With Infants
SO ENFANCE
LA English
DT Article
DE FEELING IN MUSIC; STORIES OF MELODY; BABY SONGS; CULTURE OF SONG;
   PRESCHOOL EDUCATION
ID CULTURE; SPEECH
AB Recordings of parents' sharing life with infants in the first year, and their detailed description, have led to the theory of human "communicative musicality", and recognition of the importance of melody for cultural learning. With advanced methods of computer graphics in studies of musical acoustics, affective qualities of the voice and rhythms in narrative patterns have been revealed in proto-conversations of mothers with infants in the first 6 months, and in motherese talk, songs and action-games that the mothers begin to share with infants at that time. It has been shown that the infant, even a newborn, discriminates and shares both the emotions evoked by different qualities of vocal or instrumental sounds, and their composition in narrative sequences of melody, with or without words. Babies learn to perform favourite games of song with actions with parents and siblings, sometimes making use of rituals invented by ancestors centuries ago. This ability to share and remember meanings and stories of vocal sounds, together with patterns of expression seen of face and hands, gives vital support to learning of all cultural patterns of behaviour, including use of tools for eating and toys for games, as well as first words in language. Both aesthetic and moral conventions are acquired with awareness of the feelings of life expressed in song, and used to enliven practical customs. Creative poetry of dance, song and story-telling, the "how" of expression, not just the "facts" referred to, are increasingly recognised as important in psychotherapy, as well as early education.
C1 [Trevarthen, Colwyn] Winton, Main St, Aberlodge EH32 0RA, East Lothian, Scotland.
RP Trevarthen, C (corresponding author), Winton, Main St, Aberlodge EH32 0RA, East Lothian, Scotland.
EM c.trevarthen@ed.ac.uk
CR [Anonymous], 1979, Before Speech: The Beginning of Interpersonal Communication
   [Anonymous], FORM PERSONAL
   [Anonymous], 1976, HOW MUSICAL IS MAN
   [Anonymous], 1968, FROM 2 TO 5
   [Anonymous], 1984, ADV PSYCHOL, DOI DOI 10.1016/S0166-4115(08)61374-6
   [Anonymous], RHYTHMS MUSICAL NARR
   [Anonymous], 1992, MUSE CREATIVITY COMM
   [Anonymous], 1972, KNOWLEDGE HUMAN INTE
   [Anonymous], 2009, COMMUNICATIVE MUSICA
   [Anonymous], 1979, Before Speech: The Beginning of Interpersonal Communication
   [Anonymous], 2009, COMMUNICATIVE MUSICA
   [Anonymous], 2002, J MACMURRAY CRITICAL
   [Anonymous], CONTEXTS YOUNG CHILD
   [Anonymous], 2000, INTERPERSONAL WORLD
   [Anonymous], NATURE CULTURE
   [Anonymous], MUSICAL BEGINNINGS
   [Anonymous], ESSAYS ED REFORMERS
   [Anonymous], 2005, EMOTIONAL DEV RECENT
   [Anonymous], ACQUIRING CULTURE ET
   [Anonymous], 2004, I THOU
   [Anonymous], 1979, The expression of emotions in animals and man
   Bernstein N., 1967, COORDINATION REGULAT
   Bernstein N.A., 1966, ACTIVE SEARCH INFORM
   Birdwhistell R. L., 1970, KINESICS AND CONTEXT
   BLACKING J, 1988, ACQUIRING CULTURE CR, P91
   Brazelton T.B., 1995, Neonatal behavioral assessment scale
   Bruner J.S., 1968, HEINZ WERNER LECT, V20
   Bruner Jerome, 2003, Making stories: law, literature, life
   Bruner Jerome, 1990, Acts of meaning
   CONDON WS, 1974, SCIENCE, V183, P99, DOI 10.1126/science.183.4120.99
   Damasio Antonio, 1999, The Feeling of What Happens: Body and Emotion in the Making of Consciousness
   Damasio AR, 2018, STRANGE ORDER THINGS
   Darwin C., 1859, ORIGIN SPECIES MEANS, DOI 10.5962/bhl.title.82303
   Darwin C., 1877, Mind, V2, P285, DOI [10.1093/mind/os-2.7.285, DOI 10.1093/MIND/OS-2.7.285]
   Delafield-Butt JT, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01157
   Deliege I., 1999, RHYTHM MUSICAL NARRA
   Di Cesare G, 2018, CEREB CORTEX, V28, P1348, DOI 10.1093/cercor/bhx051
   Friedman Maurice., 2002, Martin Buber: The Life of Dialogue, V4th ed.
   Goodrich B.G., 2015, ART AESTHETICS BRAIN
   Goodrich BG, 2010, REV NEUROSCIENCE, V21, P331
   GRATIER M, 2007, INT J DIALOGICAL SCI, V2, P169
   GRATIER M, 1999, MUSIC SCI, P93
   Gratier M, 2008, J CONSCIOUSNESS STUD, V15, P122
   HABERMAS J, 1970, RECENT SOCIOL, V12, P115
   Honing H, 2015, PHILOS T R SOC B, V370, P5, DOI 10.1098/rstb.2014.0088
   James W., 1890, The Principles of Psychology
   Kugiumutzakis G., 2015, INT ENCY SOCIAL BEHA, P481, DOI [10.1016/B978-0-08-097086-8.23160-7, DOI 10.1016/B978-0-08-097086-8.23160-7]
   Langer S., 1948, Philosophy in a New Key: A Study in the Symbolism ofReason, Rite, andArt
   Leboyer F., 1975, BIRTH VIOLENCE
   Macmurray J., 1959, FORM PERSONAL, VI
   Malloch S., 2009, COMMUNICATIVE MUSICA
   Malloch S, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01680
   Maratos O., 1982, REGRESSIONS MENTAL D, P81, DOI DOI 10.4324/9781315180922-4
   Merker B, 2000, ORIGINS OF MUSIC, P315
   Nadel J, 1999, EARLY SOCIAL COGNITION, P189
   Nadel J., 2005, EMOTIONAL DEV
   Nadel J., 2014, IMITATION BOOSTS DEV
   Nagy E, 2011, INFANT CHILD DEV, V20, P3, DOI 10.1002/icd.683
   Narvaez D., 2012, EVOLUTION EARLY EXPE, P202
   Osborne N., 2017, RHYTHMS RELATING CHI, P14
   Osborne R, 2009, ROUTL HIST ANC WORLD, P331
   PAPOUSEK H, 1983, J CHILD PSYCHOL PSYC, V24, P117, DOI 10.1111/j.1469-7610.1983.tb00109.x
   PAPOUSEK M, 1994, EARLY DEV PARENTING, V3, P5
   Papousek M., 1981, ADV INFANCY RES, P163
   PREISLER G, 1983, DEAF CHILDREN COMMUN
   Preisler G., 1986, PRECURSORS EARLY SPE, P269
   Reddy V., 2001, Enfance, V53, P247, DOI DOI 10.3917/ENF.533.0247
   Reddy V., 1991, Natural Theories of Mind: Evolution, Developmnet, and Simulation of Everyday Mindreading, P143
   Reddy V., 2004, Zero to Three, V24, P9
   Reddy V., 2008, How Infants Know Minds
   Reddy V, 2015, J CONSCIOUSNESS STUD, V22, P24
   Reissland N., 2015, FETAL DEV RES BRAIN
   Sander L.W., 2012, LIVING SYSTEMS EVOLV
   SANDER LW, 1964, J CHILD PSYCHOL PSYC, V3, P231, DOI 10.1016/S0002-7138(09)61920-8
   Schögler B, 2007, ADV CONSC RES, V68, P281
   Schogler B., 1999, MUSIC SCI, V3, P75, DOI DOI 10.1177/10298649000030S106
   Sherrington C.S., 1906, The integrative action of the nervous system
   Sherrington C.S., 1955, MAN HIS NATURE, P103
   Smith A, 1777, ESSAYS PHILOS SUBJEC, P176
   Smith Adam, 1976, The Theory of Moral Sentiments
   Stern D.N., 1995, Motherhood Constellation
   Stern D. N., 2010, Forms of Vitality, Exploring Dynamic Experience in Psychology, the Arts, Psychotherapy, and Development
   Stern D. N., 2004, The present moment in psychotherapy and everyday life
   STERN DN, 1974, J AM ACAD CHILD PSY, V13, P402, DOI 10.1016/S0002-7138(09)61348-0
   Trehub SE, 2003, NAT NEUROSCI, V6, P669, DOI 10.1038/nn1084
   TREVARTHEN C, 1975, RECHERCHE, V6, P447
   Trevarthen C., 2018, CHILDS CURRICULUM WO
   Trevarthen C., 2017, RHYTHMS RELATING CHI, P28
   Trevarthen C., 1999, Musicae Scientiae, V3, P155, DOI [10.1177/10298649000030S109, DOI 10.1177/10298649000030S109]
   Trevarthen C., 1993, NEW PERSPECTIVES EAR
   Trevarthen C., 1997, DEVENIR, V9, P73
   Trevarthen C., 2016, SPRINGER STUDIES BRA, P225
   Trevarthen C., 1974, New Scientist, V2, P230
   Trevarthen C., 1979, Before speech, P321
   Trevarthen C., 1990, SEMIOTIC WEB 1989, P689, DOI DOI 10.1515/9783110874099.689
   Trevarthen C., 2017, ANTHR BEAUTY AESTHET, P115
   Trevarthen Colin, 1993, NEW PERSPECTIVES EAR, P48, DOI DOI 10.4324/9781315111322-5
   Trevarthen C, 2017, POL PEDOG UNDER-THR, P17, DOI 10.1007/978-981-10-2275-3_2
   Trevarthen C, 2014, WIRES COGN SCI, V5, P173, DOI 10.1002/wcs.1276
   Trevarthen C, 2009, MUSIC THAT WORKS, P221, DOI 10.1007/978-3-211-75121-3_16
   Trevarthen Colwyn, 1982, SOCIAL COGNITION STU, P77
   van Rees S., 1993, SCHEYVENHOFWEG, V12, P6093
   Wallon H., 1941, EVOLUTION PSYCHOL LE
   Wallon Henri, 1934, Les Origines du caractere chez l'enfant
NR 104
TC 1
Z9 1
U1 2
U2 14
PU PRESSES UNIV FRANCE
PI PARIS CEDEX 14
PA 6 AVENUE REILLE, 75685 PARIS CEDEX 14, FRANCE
SN 0013-7545
EI 1969-6981
J9 ENFANCE
JI Enfance
PY 2020
IS 1
BP 17
EP 39
PG 23
WC Psychology, Developmental
WE Emerging Sources Citation Index (ESCI)
SC Psychology
GA LC3YF
UT WOS:000525260600003
DA 2024-01-09
ER

PT J
AU Brown, S
   Aplin, KL
   Jenkins, K
   Mander, S
   Walsh, C
   Williams, PD
AF Brown, Sally
   Aplin, Karen L.
   Jenkins, Katie
   Mander, Sarah
   Walsh, Claire
   Williams, Paul D.
TI Is there a Rhythm Of The Rain? An analysis of weather in popular music
SO WEATHER
LA English
DT Article
DE Music; songs; lyrics; keys; weather; sun; rain
AB Weather is frequently used in music to frame events and emotions, yet quantitative analyses are rare. From a collated base set of 759 weather-related songs, 419 were analysed based on listings from a karaoke database. This article analyses the 20 weather types described, frequency of occurrence, genre, keys, mimicry, lyrics and songwriters. Vocals were the principal means of communicating weather: sunshine was the most common, followed by rain, with weather depictions linked to the emotions of the song. Bob Dylan, John Lennon and Paul McCartney wrote the most weather-related songs, partly following their experiences at the time of writing.
C1 [Brown, Sally] Univ Southampton, Fac Engn & Environm, Southampton SO9 5NH, Hants, England.
   [Brown, Sally] Univ Southampton, Tyndall Ctr Climate Change Res, Southampton SO9 5NH, Hants, England.
   [Aplin, Karen L.] Univ Oxford, Dept Phys, Oxford OX1 2JD, England.
   [Jenkins, Katie] Univ Oxford, Oxford Ctr Environm, Environm Change Inst, Oxford OX1 2JD, England.
   [Jenkins, Katie; Walsh, Claire] Tyndall Ctr Climate Change Res, Norwich, Norfolk, England.
   [Mander, Sarah] Univ Manchester, Tyndall Ctr Climate Change Res, Manchester M13 9PL, Lancs, England.
   [Mander, Sarah] Univ Manchester, Sch Mech Aerosp & Civil Engn, Manchester M13 9PL, Lancs, England.
   [Walsh, Claire] Newcastle Univ, Sch Civil Engn & Geosci, Ctr Earth Syst Engn Res, Newcastle Upon Tyne NE1 7RU, Tyne & Wear, England.
   [Williams, Paul D.] Univ Reading, Dept Meteorol, Reading RG6 2AH, Berks, England.
   [Williams, Paul D.] Univ Reading, Natl Ctr Atmospher Sci, Reading RG6 2AH, Berks, England.
C3 University of Southampton; University of Southampton; University of
   Oxford; University of Oxford; University of East Anglia; University of
   Manchester; University of Manchester; Newcastle University - UK;
   University of Reading; UK Research & Innovation (UKRI); Natural
   Environment Research Council (NERC); NERC National Centre for
   Atmospheric Science; University of Reading
RP Brown, S (corresponding author), Univ Southampton, Fac Engn & Environm, Southampton SO9 5NH, Hants, England.
EM sb20@soton.ac.uk
RI Brown, Sally/I-2662-2014; Aplin, Karen/JRX-3816-2023; Jenkins,
   Katie/HLH-0239-2023; WALSH, CLAIRE L/B-7932-2008; Brown,
   Sally/AAD-6943-2020; Williams, Paul D/B-2432-2012; Aplin, Karen
   L/B-6078-2008
OI Brown, Sally/0000-0003-1185-1962; Aplin, Karen/0000-0003-0529-838X;
   Williams, Paul D/0000-0002-9713-9820; Jenkins,
   Katie/0000-0002-6740-5139; Walsh, Claire/0000-0002-4047-1216; Mander,
   Sarah/0000-0001-8492-6246
CR [Anonymous], 2013, UNDERSTANDING SOC PO
   Aplin KL, 2011, WEATHER, V66, P300, DOI 10.1002/wea.765
   Aplin KL, 2012, EOS T AM GEOPHYS UN, V93, P347, DOI [10. 1029/2012EO360007, DOI 10.1029/2012EO360007]
   Bäumer D, 2007, GEOPHYS RES LETT, V34, DOI 10.1029/2006GL028559
   Cavanagh D, 1995, SELECT           JUL, P40
   Cerveny RS, 1998, NATURE, V394, P561, DOI 10.1038/29043
   CHANGNON SA, 1992, CLIMATIC CHANGE, V22, P191, DOI 10.1007/BF00143027
   Epstein D. M., 2011, BALLAD B DYLAN PORTR
   Gedzelman DS., 1980, SCI WONDERS ATMOSPHE
   Harrison George, 1980, I ME MINE
   James A., 2007, BIT OF A BLUR
   McCartney Paul, 2000, BEATLES ANTHOLOGY
   Meteorological Office, 1971, MET OFF MONTHL WEATH, V88
   Meteorological Office, 1959, MONTHL WEATH REP MET, V76
   Meteorological Office, 1962, MONTHL WEATH REP MET, V79
   Robock A, 2005, B AM METEOROL SOC, V86, P483, DOI 10.1175/BAMS-86-4-483
   Rolling Stone, 2011, 500 GREAT SONGS ALL
   Rowley D., 2013, ALL TOGETHER NOW ABC
   Schellenberg EG, 2012, PSYCHOL AESTHET CREA, V6, P196, DOI 10.1037/a0028024
   Schmid R., 1989, WEATHERWISE, V42, P192
   Smiley SL, 2014, J GEOGR, V113, P238, DOI 10.1080/00221341.2013.877061
   Songfacts, 2014, SONGS WEATH COND TIT
   Turner Steve, 1999, A HARD DAYS WRITE
   Wagner AJ., 1972, WEATHERWISE, V25, P168
NR 24
TC 2
Z9 2
U1 1
U2 20
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0043-1656
EI 1477-8696
J9 WEATHER
JI Weather
PD JUL
PY 2015
VL 70
IS 7
BP 198
EP 204
DI 10.1002/wea.2464
PG 7
WC Meteorology & Atmospheric Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Meteorology & Atmospheric Sciences
GA CP4PY
UT WOS:000359865800008
OA Green Accepted
DA 2024-01-09
ER

PT J
AU Eerola, T
   Ferrer, R
   Alluri, V
AF Eerola, Tuomas
   Ferrer, Rafael
   Alluri, Vinoo
TI TIMBRE AND AFFECT DIMENSIONS: EVIDENCE FROM AFFECT AND SIMILARITY
   RATINGS AND ACOUSTIC CORRELATES OF ISOLATED INSTRUMENT SOUNDS
SO MUSIC PERCEPTION
LA English
DT Article
DE timbre; affect; emotion; instrument; monophonic
ID MUSIC PERFORMANCE; VOCAL EXPRESSION; EMOTION; COMMUNICATION;
   DISCRIMINATION; RECOGNITION; PERCEPTION; MODELS; SPACE; VOICE
AB Considerable Effort Has Been Made Towards understanding how acoustic and structural features contribute to emotional expression in music, but relatively little attention has been paid to the role of timbre in this process. Our aim was to investigate the role of timbre in the perception of affect dimensions in isolated musical sounds, by way of three behavioral experiments. In Experiment 1, participants evaluated perceived affects of 110 instrument sounds that were equal in duration, pitch, and dynamics using a three-dimensional affect model (valence, energy arousal, and tension arousal) and preference and emotional intensity. In Experiment 2, an emotional dissimilarity task was applied to a subset of the instrument sounds used in Experiment 1 to better reveal the underlying affect structure. In Experiment 3, the perceived affect dimensions as well as preference and intensity of a new set of 105 instrument sounds were rated by participants. These sounds were also uniform in pitch, duration, and playback dynamics but contained systematic manipulations in the dynamics of sound production, articulation, and ratio of high-frequency to low-frequency energy. The affect dimensions for all the experiments were then explained in terms of the three kinds of acoustic features extracted: spectral (e.g., ratio of high-frequency to low-frequency energy), temporal (e.g., attack slope), and spectrotemporal (e.g., spectral flux). High agreement among the participants' ratings across the experiments suggested that even isolated instrument sounds contain cues that indicate affective expression, and these are recognized as such by the listeners. A dominant portion (50-57%) of the two dimensions of affect (valence and energy arousal) could be predicted by linear combinations of few acoustic features such as ratio of high-frequency to low-frequency energy, attack slope, and spectral regularity. Links between these features and those observed in the vocal expression of affects and other sound phenomena are discussed. Received June 9, 2010, accepted November 17, 2011.
C1 [Eerola, Tuomas] Univ Jyvaskyla, Dept Mus, Jyvaskyla, Finland.
C3 University of Jyvaskyla
RP Eerola, T (corresponding author), Univ Jyvaskyla, Dept Mus, Jyvaskyla, Finland.
EM tuomas.eerola@jyu.fi
RI Eerola, Tuomas/I-6190-2013; Campailla, Jasmin/AAK-2420-2021; Eerola,
   Tuomas/K-7596-2019; Vuoskoski, Jonna K/B-4944-2018
OI Eerola, Tuomas/0000-0002-2896-929X; Eerola, Tuomas/0000-0002-2896-929X;
   Vuoskoski, Jonna K/0000-0003-0049-4373; Alluri,
   Vinoo/0000-0003-3689-1039
CR Al-Kandari NM, 2001, COMMUN STAT-SIMUL C, V30, P339, DOI 10.1081/SAC-100002371
   Alluri V, 2010, MUSIC PERCEPT, V27, P223, DOI 10.1525/mp.2010.27.3.223
   [Anonymous], 1955, ORCHESTRATION
   [Anonymous], 2009, J STAT SOFTW
   [Anonymous], 2010, Handbook of Music and Emotion
   [Anonymous], 1998, Tuning, Timbre, Spectrum, Scale
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Baraldi FB, 2006, J NEW MUSIC RES, V35, P197, DOI 10.1080/09298210601045575
   Barrett LF, 2001, COGNITION EMOTION, V15, P333, DOI 10.1080/02699930125711
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   BOX GEP, 1964, J ROY STAT SOC B, V26, P211, DOI 10.1111/j.2517-6161.1964.tb00553.x
   Bradley MM, 2000, PSYCHOPHYSIOLOGY, V37, P204, DOI 10.1111/1469-8986.3720204
   Bresin R, 2000, COMPUT MUSIC J, V24, P44, DOI 10.1162/014892600559515
   Burgoyne JA, 2008, LECT NOTES COMPUT SC, V4969, P181
   Caclin A, 2005, J ACOUST SOC AM, V118, P471, DOI 10.1121/1.1929229
   Caclin A, 2008, J COGNITIVE NEUROSCI, V20, P49, DOI 10.1162/jocn.2008.20001
   Caclin A, 2006, J COGNITIVE NEUROSCI, V18, P1959, DOI 10.1162/jocn.2006.18.12.1959
   Cox TF, 2001, MULTIDIMENSIONAL SCA
   Eerola T, 2008, MUSIC PERCEPT, V25, P253, DOI 10.1525/MP.2008.25.3.253
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   Filipic S, 2010, PSYCHON B REV, V17, P335, DOI 10.3758/PBR.17.3.335
   Fletcher NH, 1999, J ACOUST SOC AM, V105, P874, DOI 10.1121/1.426276
   Gabrielsson A., 1995, Psychomusicol. J. Res. Music Cogn, V14, P94, DOI DOI 10.1037/H0094089
   Gabrielsson A., 2010, HDB MUSIC EMOTION TH, P367, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0014
   Gjerdingen R, 2008, J NEW MUSIC RES, V37, P93, DOI 10.1080/09298210802479268
   Goydke KN, 2004, COGNITIVE BRAIN RES, V21, P351, DOI 10.1016/j.cogbrainres.2004.06.009
   GREY JM, 1977, J ACOUST SOC AM, V62, P454, DOI 10.1121/1.381508
   GREY JM, 1977, J ACOUST SOC AM, V61, P1270, DOI 10.1121/1.381428
   Hair J. F., 2006, MULTIVARIATE DATA AN
   HAJDA JM, 1997, PERCEPTION COGNITION, P253
   Haken L, 2007, MOD ACOUST SIGN PROC, P122, DOI 10.1007/978-0-387-32576-7_3
   Hamann SB, 1999, NEUROPSYCHOLOGIA, V37, P1135, DOI 10.1016/S0028-3932(99)00027-5
   Huron D, 2001, MUSIC PERCEPT, V19, P1, DOI 10.1525/mp.2001.19.1.1
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Jensen KK., 1999, THESIS U COPENHAGEN
   Johnstone T., 2000, Handbook of Emotions, V2nd ed., P220
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Juslin PN, 1997, MUSIC PERCEPT, V14, P383
   KENDALL RA, 1993, MUSIC PERCEPT, V10, P469
   Kidd GR, 2003, NOISE CONTROL ENG J, V51, P216, DOI 10.3397/1.2839717
   Kreutz G, 2008, PSYCHOL MUSIC, V36, P101, DOI 10.1177/0305735607082623
   Krumhansl CL, 2010, MUSIC PERCEPT, V27, P337, DOI 10.1525/mp.2010.27.5.337
   Lakatos S, 2000, PERCEPT PSYCHOPHYS, V62, P1426, DOI 10.3758/BF03212144
   Lartillot O., 2007, P INT C DIG AUD EFF, DOI DOI 10.1007/978-3-540-78246-9_31
   Laukka P, 2005, COGNITION EMOTION, V19, P633, DOI 10.1080/02699930441000445
   Laukka P, 2011, COMPUT SPEECH LANG, V25, P84, DOI 10.1016/j.csl.2010.03.004
   Leman M, 2005, J NEW MUSIC RES, V34, P39, DOI 10.1080/09298210500123978
   Maffiolo V., 1999, J ACOUST SOC AM, V105, P943, DOI [10.1121/1.425718, DOI 10.1121/1.425718]
   McAdams S, 1999, J ACOUST SOC AM, V105, P882, DOI 10.1121/1.426277
   MCADAMS S, 1995, PSYCHOL RES-PSYCH FO, V58, P177, DOI 10.1007/BF00419633
   McGraw KO, 1996, PSYCHOL METHODS, V1, P30, DOI 10.1037/1082-989X.1.1.30
   Menon V, 2002, NEUROIMAGE, V17, P1742, DOI 10.1006/nimg.2002.1295
   MIDDLEBROOKS JC, 1991, ANNU REV PSYCHOL, V42, P135, DOI 10.1146/annurev.ps.42.020191.001031
   Ohta K., 1999, Technology Reports of the Osaka University, V49, P189
   Opolko F., 2006, The McGill University Master Samples Collection on DVD
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   PITT MA, 1992, J EXP PSYCHOL HUMAN, V18, P728, DOI 10.1037/0096-1523.18.3.728
   Rawlings D, 2008, PSYCHOL MUSIC, V36, P269, DOI 10.1177/0305735607086042
   Read Gardner, 2004, ORCHESTRAL COMBINATI
   Redondo J, 2008, BEHAV RES METHODS, V40, P784, DOI 10.3758/BRM.40.3.784
   ROCCHESSO D., 2004, INTRO SOUNDING PROCE
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Schellenberg EG, 1999, PSYCHON B REV, V6, P641, DOI 10.3758/BF03212973
   Scherer K., 1977, MOTIV EMOTION, V1, P331, DOI [DOI 10.1007/BF00992539, 10.1007/bf00992539]
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Scherer KR, 2003, SER AFFECTIVE SCI, P433
   Schimmack U, 2000, EUR J PERSONALITY, V14, P325, DOI 10.1002/1099-0984(200007/08)14:4<325::AID-PER380>3.0.CO;2-I
   Schimmack U, 2002, EMOTION, V2, P412, DOI 10.1037//1528-3542.2.4.412
   Schutz M, 2008, EMPIR MUSICOL REV, V3, P126, DOI 10.18061/1811/34103
   Sloboda J.A., 2010, Handbook of music and emotion: Theory, research, applications, P73
   STREET JO, 1988, AM STAT, V42, P152, DOI 10.2307/2684491
   STRONG W., 1976, J ACOUST SOC AM, V41, P39
   Thayer RE., 1990, The Biopsychology of Mood and Activation
   Trainor LJ, 1997, INFANT BEHAV DEV, V20, P383, DOI 10.1016/S0163-6383(97)90009-6
   Tsang CD, 2002, INFANT BEHAV DEV, V25, P183, DOI 10.1016/S0163-6383(02)00120-0
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   von Bismarck G., 1974, Acustica, V30, P159
   Zentner M., 2010, Handbook of music and emotion: theory, research, and applications, P367, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0008
NR 83
TC 221
Z9 257
U1 10
U2 101
PU UNIV CALIFORNIA PRESS
PI OAKLAND
PA 155 GRAND AVE, SUITE 400, OAKLAND, CA 94612-3758 USA
SN 0730-7829
J9 MUSIC PERCEPT
JI Music Percept.
PD SEP
PY 2012
VL 30
IS 1
BP 49
EP 70
DI 10.1525/MP.2012.30.1.49
PG 22
WC Music; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music; Psychology
GA 003RP
UT WOS:000308629300004
OA Green Published
DA 2024-01-09
ER

PT J
AU Quinto, LR
   Thompson, WF
   Kroos, C
   Palmer, C
AF Quinto, Lena R.
   Thompson, William F.
   Kroos, Christian
   Palmer, Caroline
TI Singing emotionally: a study of pre-production, production, and
   post-production facial expressions
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE singing; emotional communication; point-light displays; face motion
ID POINT-LIGHT DISPLAYS; MUSIC PERFORMANCE; BODY MOVEMENT; PERCEPTION;
   RECOGNITION; MOTION; IDENTIFICATION; COMMUNICATION; INFORMATION;
   PIANISTS
AB Singing involves vocal production accompanied by a dynamic and meaningful use of facial expressions, which may serve as ancillary gestures that complement, disambiguate, or reinforce the acoustic signal. In this investigation, we examined the use of facial movements to communicate emotion, focusing on movements arising in three epochs: before vocalization (pre-production), during vocalization (production), and immediately after vocalization (post-production). The stimuli were recordings of seven vocalists' facial movements as they sang short (14 syllable) melodic phrases with the intention of communicating happiness, sadness, irritation, or no emotion. Facial movements were presented as point-light displays to 16 observers who judged the emotion conveyed. Experiment 1 revealed that the accuracy of emotional judgment varied with singer, emotion, and epoch. Accuracy was highest in the production epoch, however, happiness was well communicated in the pre-production epoch. In Experiment 2, observers judged point-light displays of exaggerated movements. The ratings suggested that the extent of facial and head movements was largely perceived as a gauge of emotional arousal. In Experiment 3, observers rated point-light displays of scrambled movements. Configural information was removed in these stimuli but velocity and acceleration were retained. Exaggerated scrambled movements were likely to be associated with happiness or irritation whereas unexaggerated scrambled movements were more likely to be identified as "neutral." An analysis of singers' facial movements revealed systematic changes as a function of the emotional intentions of singers. The findings confirm the central role of facial expressions in vocal emotional communication, and highlight individual differences between singers in the amount and intelligibility of facial movements made before, during, and after vocalization.
C1 [Quinto, Lena R.; Thompson, William F.; Kroos, Christian] Macquarie Univ, Dept Psychol, Sydney, NSW 2109, Australia.
   [Palmer, Caroline] McGill Univ, Dept Psychol, Montreal, PQ, Canada.
C3 Macquarie University; McGill University
RP Thompson, WF (corresponding author), Macquarie Univ, Dept Psychol, Australian Hearing Hub St,Balaclava Rd, Sydney, NSW 2109, Australia.
EM bill.thompson@mq.edu.au
OI Palmer, Caroline/0000-0003-4816-8067; Thompson,
   William/0000-0002-4256-1338
CR BASSILI JN, 1979, J PERS SOC PSYCHOL, V37, P2049, DOI 10.1037/0022-3514.37.11.2049
   BASSILI JN, 1978, J EXP PSYCHOL HUMAN, V4, P373, DOI 10.1037/0096-1523.4.3.373
   Behne KE, 2011, MUSIC SCI, V15, P324, DOI 10.1177/1029864911410955
   BERTENTHAL BI, 1994, PSYCHOL SCI, V5, P221, DOI 10.1111/j.1467-9280.1994.tb00504.x
   Blake R, 2007, ANNU REV PSYCHOL, V58, P47, DOI 10.1146/annurev.psych.57.102904.190152
   Brunswik E., 1956, Perception and the representative design of psychological experiments, V2nd
   Busso C, 2007, IEEE T AUDIO SPEECH, V15, P1075, DOI 10.1109/TASL.2006.885910
   Calvo MG, 2008, BEHAV RES METHODS, V40, P109, DOI 10.3758/BRM.40.1.109
   Castellano G, 2008, MUSIC PERCEPT, V26, P103, DOI 10.1525/MP.2008.26.2.103
   Ceaser Donovon Keith, 2009, Canadian Acoustics, V37, P29
   Chan LP, 2013, MUSIC PERCEPT, V30, P361, DOI 10.1525/MP.2013.30.4.361
   Clarke TJ, 2005, PERCEPTION, V34, P1171, DOI 10.1068/p5203
   Cunningham DW, 2009, J VISION, V9, DOI 10.1167/9.13.7
   Dahl S, 2007, MUSIC PERCEPT, V24, P433, DOI 10.1525/MP.2007.24.5.433
   Davidson J., 1995, MUSIC MIND MACHINE P, P105, DOI DOI 10.1007/978-3-642-79327-1_11
   Davidson J., 1994, J HUMAN MOVEMENT STU, V6, P279
   Davidson JW, 2012, PSYCHOL MUSIC, V40, P595, DOI 10.1177/0305735612449896
   Davidson JW., 1993, PSYCHOL MUSIC, V21, P103, DOI [10.1177/030573569302100201, DOI 10.1177/030573569302100201]
   Dittrich WH, 1996, PERCEPTION, V25, P727, DOI 10.1068/p250727
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   EKMAN P, 1976, ENVIRON PSYCH NONVER, V1, P56, DOI 10.1007/BF01115465
   Elfenbein HA, 2002, PSYCHOL BULL, V128, P203, DOI 10.1037//0033-2909.128.2.203
   Fiorentini C, 2012, PERCEPTION, V41, P532, DOI 10.1068/p7052
   GOWER JC, 1975, PSYCHOMETRIKA, V40, P33, DOI 10.1007/BF02291478
   Gutiérrez-Maldonado J, 2014, VIRTUAL REAL-LONDON, V18, P61, DOI 10.1007/s10055-013-0236-7
   Halovic S., 2009, S MENTAL STATES EMOT
   Hanser S., 2010, HDB MUSIC EMOTION TH, P49
   Hevner K, 1935, AM J PSYCHOL, V47, P103, DOI 10.2307/1416710
   Hiris E, 2007, J VISION, V7, DOI 10.1167/7.12.4
   JOHNSTONE T, 2000, HDB EMOTIONS, P226
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Kamachi M, 2001, PERCEPTION, V30, P875, DOI 10.1068/p3131
   Livingstone SR, 2009, MUSIC PERCEPT, V26, P475, DOI 10.1525/MP.2009.26.5.475
   Palmer C, 2013, PSYCHOLOGY OF MUSIC, THIRD EDITION, P405, DOI 10.1016/B978-0-12-381460-9.00010-9
   Platz F, 2012, MUSIC PERCEPT, V30, P71, DOI 10.1525/MP.2012.30.1.71
   Pollick FE, 2003, PERCEPTION, V32, P813, DOI 10.1068/p3319
   Ramsay J. O., 2005, Functional Data Analysis
   Recio G, 2013, COGNITION EMOTION, V27, P1486, DOI 10.1080/02699931.2013.794128
   Russell JA, 2003, ANNU REV PSYCHOL, V54, P329, DOI 10.1146/annurev.psych.54.101601.145102
   SALDANA HM, 1993, PERCEPT PSYCHOPHYS, V54, P406, DOI 10.3758/BF03205276
   Sato W, 2004, COGNITION EMOTION, V18, P701, DOI 10.1080/02699930341000176
   Scherer KR, 2003, SER AFFECTIVE SCI, P433
   Schubert E, 2004, MUSIC PERCEPT, V21, P561, DOI 10.1525/mp.2004.21.4.561
   Schutz M, 2007, PERCEPTION, V36, P888, DOI 10.1068/p5635
   Scotto di Carlo N, 2004, SEMIOTICA, V149, P37
   Slaney M., 1999, MAKEQTMOVIE CREATE Q
   Sloboda, 2010, MUSIC EMOTION, P368
   Thirkettle M, 2009, J VISION, V9, DOI 10.1167/9.3.28
   Thompson W.F., 2010, Handbook of music and emotion: Theory, research, and applications, P755
   Thompson WF, 2005, SEMIOTICA, V156, P203, DOI 10.1515/semi.2005.2005.156.203
   Thompson WF, 2007, PSYCHOL SCI, V18, P756, DOI 10.1111/j.1467-9280.2007.01973.x
   Thompson WF, 2010, PSYCHON B REV, V17, P317, DOI 10.3758/PBR.17.3.317
   Thompson WF, 2008, COGNITION EMOTION, V22, P1457, DOI 10.1080/02699930701813974
   Timmers R, 2007, MUSIC PERCEPT, V25, P117, DOI 10.1525/MP.2007.25.2.117
   Vines BW, 2006, COGNITION, V101, P80, DOI 10.1016/j.cognition.2005.09.003
   Wanderley MM, 2005, J NEW MUSIC RES, V34, P97, DOI 10.1080/09298210500124208
   Williamon A, 2002, MUSIC SCI, V6, P53, DOI 10.1177/102986490200600103
   Wöllner C, 2008, MUSIC SCI, V12, P249
NR 59
TC 7
Z9 7
U1 0
U2 15
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD APR 29
PY 2014
VL 5
AR 262
DI 10.3389/fpsyg.2014.00262
PG 15
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA AH2SE
UT WOS:000335970600001
PM 24808868
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Omar, R
   Henley, SMD
   Bartlett, JW
   Hailstone, JC
   Gordon, E
   Sauter, DA
   Frost, C
   Scott, SK
   Warren, JD
AF Omar, Rohani
   Henley, Susie M. D.
   Bartlett, Jonathan W.
   Hailstone, Julia C.
   Gordon, Elizabeth
   Sauter, Disa A.
   Frost, Chris
   Scott, Sophie K.
   Warren, Jason D.
TI The structural neuroanatomy of music emotion recognition: Evidence from
   frontotemporal lobar degeneration
SO NEUROIMAGE
LA English
DT Article
DE Music; Emotion; Dementia; Frontotemporal; FTLD; VBM
ID IMPAIRED RECOGNITION; ALZHEIMERS-DISEASE; SEMANTIC DEMENTIA; PREFRONTAL
   CORTEX; TEMPORAL VARIANTS; HUMAN AMYGDALA; BRAIN; DAMAGE; CONNECTIVITY;
   EXPERIENCE
AB Despite growing clinical and neurobiological interest in the brain mechanisms that process emotion in music, these mechanisms remain incompletely understood. Patients with frontotemporal lobar degeneration (FTLD) frequently exhibit clinical syndromes that illustrate the effects of breakdown in emotional and social functioning. Here we investigated the neuroanatomical substrate for recognition of musical emotion in a cohort of 26 patients with FTLD (16 with behavioural variant frontotemporal dementia, bvFTD, 10 with semantic dementia, SemD) using voxel-based morphometry. On neuropsychological evaluation, patients with FTLD showed deficient recognition of canonical emotions (happiness, sadness, anger and fear) from music as well as faces and voices compared with healthy control subjects. Impaired recognition of emotions from music was specifically associated with grey matter loss in a distributed cerebral network including insula, orbitofrontal cortex, anterior cingulate and medial prefrontal cortex, anterior temporal and more posterior temporal and parietal cortices, amygdala and the subcortical mesolimbic system. This network constitutes an essential brain substrate for recognition of musical emotion that overlaps with brain regions previously implicated in coding emotional value, behavioural context, conceptual knowledge and theory of mind. Musical emotion recognition may probe the interface of these processes, delineating a profile of brain damage that is essential for the abstraction of complex social emotions. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Omar, Rohani; Henley, Susie M. D.; Hailstone, Julia C.; Gordon, Elizabeth; Frost, Chris; Warren, Jason D.] UCL, Inst Neurol, Dementia Res Ctr, London WC1N 3BG, England.
   [Bartlett, Jonathan W.; Frost, Chris] London Sch Hyg & Trop Med, Dept Med Stat, London WC1, England.
   [Sauter, Disa A.] Max Planck Inst Psycholinguist, Nijmegen, Netherlands.
   [Scott, Sophie K.] UCL, Inst Cognit Neurosci, London WC1N 3BG, England.
C3 University of London; University College London; University of London;
   London School of Hygiene & Tropical Medicine; Max Planck Society;
   University of London; University College London
RP Warren, JD (corresponding author), UCL, Inst Neurol, Dementia Res Ctr, Queen Sq, London WC1N 3BG, England.
EM jwarren@drc.ion.ucl.ac.uk
RI Sauter, Disa/AAF-9557-2022; Sauter, Disa/AFK-2268-2022; Scott, Sophie
   K/A-1843-2010
OI Scott, Sophie K/0000-0001-7510-6297; Bartlett,
   Jonathan/0000-0001-7117-0195; Frost, Chris/0000-0003-0098-9915; Warren,
   Jason/0000-0002-5405-0826; Henley, Susie/0000-0002-5838-2932
FU Department of Health's NIHR Biomedical Research Centre; Wellcome Trust;
   UK Medical Research Council; Royal College of Physicians/Dunhill Medical
   Trust; MRC [G0801306] Funding Source: UKRI; Medical Research Council
   [G0801306] Funding Source: researchfish
FX We thank all the subjects for their participation. This work was
   undertaken at UCLH/UCL who received a proportion of funding from the
   Department of Health's NIHR Biomedical Research Centres funding scheme.
   The Dementia Research Centre is an Alzheimer's Research UK Co-ordinating
   Centre. This work was funded by the Wellcome Trust and by the UK Medical
   Research Council. RO is supported by a Royal College of
   Physicians/Dunhill Medical Trust Research Fellowship. JDW is supported
   by a Wellcome Trust Senior Clinical Fellowship.
CR Adenzato M, 2010, NEUROPSYCHOLOGIA, V48, P2, DOI 10.1016/j.neuropsychologia.2009.08.001
   ADOLPHS R, 1994, NATURE, V372, P669, DOI 10.1038/372669a0
   Anderson AK, 2000, NEUROPSYCHOLOGY, V14, P526, DOI 10.1037/0894-4105.14.4.526
   Baron-Cohen S, 2001, J CHILD PSYCHOL PSYC, V42, P241, DOI 10.1111/1469-7610.00715
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Boso M, 2006, FUNCT NEUROL, V21, P187
   Brown S, 2004, NEUROREPORT, V15, P2033, DOI 10.1097/00001756-200409150-00008
   Calder AJ, 2001, NAT REV NEUROSCI, V2, P352, DOI 10.1038/35072584
   Cardinal RN, 2002, NEUROSCI BIOBEHAV R, V26, P321, DOI 10.1016/S0149-7634(02)00007-6
   Carrington SJ, 2009, HUM BRAIN MAPP, V30, P2313, DOI 10.1002/hbm.20671
   Chan D, 2001, ANN NEUROL, V49, P433, DOI 10.1002/ana.92
   Critchley HD, 2009, INT J PSYCHOPHYSIOL, V73, P88, DOI 10.1016/j.ijpsycho.2009.01.012
   Dolan RJ, 2007, PHILOS T R SOC B, V362, P787, DOI 10.1098/rstb.2007.2088
   Drapeau J, 2009, ANN NY ACAD SCI, V1169, P342, DOI 10.1111/j.1749-6632.2009.04768.x
   EdwardsLee T, 1997, BRAIN, V120, P1027, DOI 10.1093/brain/120.6.1027
   Ekman P, 1976, Pictures of facial affect
   Eldar E, 2007, CEREB CORTEX, V17, P2828, DOI 10.1093/cercor/bhm011
   Eschrich S, 2008, BMC NEUROSCI, V9, DOI 10.1186/1471-2202-9-48
   Fernandez-Duque D, 2005, NEUROPSYCHOLOGIA, V43, P1673, DOI 10.1016/j.neuropsychologia.2005.01.005
   Freeborough PA, 1997, COMPUT METH PROG BIO, V53, P15, DOI 10.1016/S0169-2607(97)01803-8
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Gagnon L, 2009, NEUROPSYCHOLOGY, V23, P90, DOI 10.1037/a0013790
   Gallagher HL, 2003, TRENDS COGN SCI, V7, P77, DOI 10.1016/S1364-6613(02)00025-6
   Genovese CR, 2002, NEUROIMAGE, V15, P870, DOI 10.1006/nimg.2001.1037
   Good CD, 2001, NEUROIMAGE, V14, P21, DOI 10.1006/nimg.2001.0786
   Gosselin N, 2005, BRAIN, V128, P628, DOI 10.1093/brain/awh420
   Gosselin N, 2007, NEUROPSYCHOLOGIA, V45, P236, DOI 10.1016/j.neuropsychologia.2006.07.012
   Gosselin N, 2006, BRAIN, V129, P2585, DOI 10.1093/brain/awl240
   Griffiths TD, 2004, J NEUROL NEUROSUR PS, V75, P344
   HALPERN AR, 1995, PSYCHOL AGING, V10, P325, DOI 10.1037/0882-7974.10.3.325
   HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747
   Henley SMD, 2008, NEUROPSYCHOLOGIA, V46, P2152, DOI 10.1016/j.neuropsychologia.2008.02.025
   Hillis AE, 2007, NEUROLOGY, V69, P200, DOI 10.1212/01.wnl.0000265600.69385.6f
   Janes H, 2008, AM J EPIDEMIOL, V168, P89, DOI 10.1093/aje/kwn099
   Janes H, 2009, STATA J, V9, P17, DOI 10.1177/1536867X0900900102
   Johnsen EL, 2009, INT J PSYCHOPHYSIOL, V72, P24, DOI 10.1016/j.ijpsycho.2008.03.011
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Keane J, 2002, NEUROPSYCHOLOGIA, V40, P655, DOI 10.1016/S0028-3932(01)00156-7
   Koelsch S, 2006, HUM BRAIN MAPP, V27, P239, DOI 10.1002/hbm.20180
   Koelsch S, 2010, TRENDS COGN SCI, V14, P131, DOI 10.1016/j.tics.2010.01.002
   Liu W, 2004, NEUROLOGY, V62, P742, DOI 10.1212/01.WNL.0000113729.77161.C9
   MATTHEWS BR, 2009, NEUROCASE       0227, P1
   Menon V, 2005, NEUROIMAGE, V28, P175, DOI 10.1016/j.neuroimage.2005.05.053
   Mitterschiffthaler MT, 2007, HUM BRAIN MAPP, V28, P1150, DOI 10.1002/hbm.20337
   Molnar-Szakacs I, 2006, SOC COGN AFFECT NEUR, V1, P235, DOI 10.1093/scan/nsl029
   Neary D, 1998, NEUROLOGY, V51, P1546, DOI 10.1212/WNL.51.6.1546
   Omar R, 2010, BRAIN, V133, P1200, DOI 10.1093/brain/awp345
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   Ridgway GR, 2009, NEUROIMAGE, V44, P99, DOI 10.1016/j.neuroimage.2008.08.045
   Rolls ET, 2004, BRAIN COGNITION, V55, P11, DOI 10.1016/s0278-2626(03)00277-x
   Rosen HJ, 2004, DEMENT GERIATR COGN, V17, P277, DOI 10.1159/000077154
   Rosen HJ, 2002, BRAIN, V125, P2286, DOI 10.1093/brain/awf225
   Ross LA, 2010, NEUROIMAGE, V49, P3452, DOI 10.1016/j.neuroimage.2009.11.012
   Salimpoor VN, 2011, NAT NEUROSCI, V14, P257, DOI 10.1038/nn.2726
   SAUTER DA, 2010, Q J EXP PSYCHOL 0428, P1
   Saxe R, 2004, ANNU REV PSYCHOL, V55, P87, DOI 10.1146/annurev.psych.55.090902.142044
   Schroeter ML, 2008, NEUROBIOL AGING, V29, P418, DOI 10.1016/j.neurobiolaging.2006.10.023
   Seeley WW, 2006, ANN NEUROL, V60, P660, DOI 10.1002/ana.21055
   Seeley WW, 2007, J NEUROSCI, V27, P2349, DOI 10.1523/JNEUROSCI.5587-06.2007
   Seeley WW, 2009, NEURON, V62, P42, DOI 10.1016/j.neuron.2009.03.024
   Snowden JS, 2008, NEUROPSYCHOLOGIA, V46, P2638, DOI 10.1016/j.neuropsychologia.2008.04.018
   Snowden JS, 2001, J NEUROL NEUROSUR PS, V70, P323, DOI 10.1136/jnnp.70.3.323
   Steinbeis N, 2009, CEREB CORTEX, V19, P619, DOI 10.1093/cercor/bhn110
   Stewart L, 2006, BRAIN, V129, P2533, DOI 10.1093/brain/awl171
   Suzuki M, 2008, COGN AFFECT BEHAV NE, V8, P126, DOI 10.3758/CABN.8.2.126
   Whitwell JL, 2001, AM J NEURORADIOL, V22, P1483
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
   Zhou J, 2010, BRAIN, V133, P1352, DOI 10.1093/brain/awq075
NR 69
TC 113
Z9 128
U1 3
U2 45
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD JUN 1
PY 2011
VL 56
IS 3
BP 1814
EP 1821
DI 10.1016/j.neuroimage.2011.03.002
PG 8
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA 764RF
UT WOS:000290649300095
PM 21385617
OA hybrid, Green Published
DA 2024-01-09
ER

PT J
AU Deroche, MLD
   Felezeu, M
   Paquette, S
   Zeitouni, A
   Lehmann, A
AF Deroche, Mickael L. D.
   Felezeu, Mihaela
   Paquette, Sebastien
   Zeitouni, Anthony
   Lehmann, Alexandre
TI Neurophysiological Differences in Emotional Processing by Cochlear
   Implant Users, Extending Beyond the Realm of Speech
SO EAR AND HEARING
LA English
DT Article
DE Cochlear implants; Electroencephalography; Emotion; Music; Prosody
ID AUDITORY-EVOKED POTENTIALS; TEMPORAL PERIODICITY CUES; PERCEPTION;
   PITCH; RECOGNITION; RESPONSES; DISCRIMINATION; SENSITIVITY; MECHANISMS;
   ARTIFACT
AB Objective: Cochlear implants (CIs) restore a sense of hearing in deaf individuals. However, they do not transmit the acoustic signal with sufficient fidelity, leading to difficulties in recognizing emotions in voice and in music. The study aimed to explore the neurophysiological bases of these limitations. Design: Twenty-two adults (18 to 70 years old) with CIs and 22 age-matched controls with normal hearing participated. Event-related potentials (ERPs) were recorded in response to emotional bursts (happy, sad, or neutral) produced in each modality (voice or music) that were for the most part correctly identified behaviorally. Results: Compared to controls, the N1 and P2 components were attenuated and prolonged in CI users. To a smaller degree, N1 and P2 were also attenuated and prolonged in music compared to voice, in both populations. The N1-P2 complex was emotion-dependent (e.g., reduced and prolonged response to sadness), but this was also true in both populations. In contrast, the later portion of the response, between 600 and 850 ms, differentiated happy and sad from neutral stimuli in normal hearing but not in CI listeners. Conclusions: The early portion of the ERP waveform reflected primarily the general reduction in sensory encoding by CI users (largely due to CI processing itself), whereas altered emotional processing (by CI users) could be found in the later portion of the ERP and extended beyond the realm of speech.
C1 [Deroche, Mickael L. D.; Zeitouni, Anthony; Lehmann, Alexandre] McGill Univ, Dept Otolaryngol Head & Neck Surg, 1001 Decade Blvd, Montreal, PQ H3G 2A8, Canada.
   [Deroche, Mickael L. D.; Lehmann, Alexandre] McGill Univ, Ctr Res Brain Language & Mus, Montreal, PQ, Canada.
   [Deroche, Mickael L. D.; Felezeu, Mihaela; Paquette, Sebastien; Lehmann, Alexandre] Univ Montreal, Int Lab Brain Mus & Sound Res, Montreal, PQ, Canada.
   [Paquette, Sebastien] Harvard Med Sch, Beth Israel Deaconess Med Ctr, Neurol Dept, Boston, MA 02115 USA.
C3 McGill University; McGill University; Universite de Montreal; Harvard
   University; Harvard Medical School; Beth Israel Deaconess Medical Center
RP Deroche, MLD (corresponding author), McGill Univ, Dept Otolaryngol Head & Neck Surg, 1001 Decade Blvd, Montreal, PQ H3G 2A8, Canada.
EM mickael.deroche@mcgill.ca
RI Deroche, Mickael L. D./I-7516-2019
OI Deroche, Mickael L. D./0000-0002-8698-2249
FU Grammy Foundation
FX This study was supported by a grant from the Grammy Foundation (to
   A.L.). The funders had no role in study design, data collection and
   analysis, decision to publish, or preparation of the article. We are
   grateful to all the participants for their time and effort, as well as
   the Institut Raymond-Dewar and the MAB-Mackay center for their help in
   recruiting CI users.
CR Agrawal D, 2013, NEUROIMAGE-CLIN, V2, P229, DOI 10.1016/j.nicl.2013.01.001
   Ahmed DG, 2018, CLIN EEG NEUROSCI, V49, P143, DOI 10.1177/1550059417733386
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Carlyon RP, 2010, J ACOUST SOC AM, V127, P1469, DOI 10.1121/1.3291981
   Carlyon RP, 2002, J ACOUST SOC AM, V112, P621, DOI 10.1121/1.1488660
   Chatterjee M, 1998, J ACOUST SOC AM, V103, P2565, DOI 10.1121/1.422777
   Chatterjee M, 2015, HEARING RES, V322, P151, DOI 10.1016/j.heares.2014.10.003
   Debener S, 2008, PSYCHOPHYSIOLOGY, V45, P20, DOI 10.1111/j.1469-8986.2007.00610.x
   Deroche MLD, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-36393-1
   Deroche MLD, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00073
   Deroche MLD, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00282
   Eckert MA, 2011, FRONT NEUROSCI-SWITZ, V5, DOI 10.3389/fnins.2011.00025
   FERNALD A, 1989, J CHILD LANG, V16, P477, DOI 10.1017/S0305000900010679
   Galvin JJ, 2007, EAR HEARING, V28, P302, DOI 10.1097/01.aud.0000261689.35445.20
   Gaudrain E, 2017, JARO-J ASSOC RES OTO, V18, P387, DOI 10.1007/s10162-016-0586-4
   Geurts L, 2001, J ACOUST SOC AM, V109, P713, DOI 10.1121/1.1340650
   Gfeller K, 2000, J Am Acad Audiol, V11, P390
   Gilley PM, 2006, CLIN NEUROPHYSIOL, V117, P1772, DOI 10.1016/j.clinph.2006.04.018
   Gosselin N, 2015, CORTEX, V71, P171, DOI 10.1016/j.cortex.2015.06.022
   GREEN DM, 1960, J ACOUST SOC AM, V32, P1189, DOI 10.1121/1.1907882
   Green T, 2005, J ACOUST SOC AM, V118, P375, DOI 10.1121/1.1925827
   Green T, 2004, J ACOUST SOC AM, V116, P2298, DOI 10.1121/1.1785611
   Groenen PAP, 2001, SCAND AUDIOL, V30, P31, DOI 10.1080/010503901750069554
   HILLYARD SA, 1973, SCIENCE, V182, P177, DOI 10.1126/science.182.4108.177
   Hong RS, 2009, J ACOUST SOC AM, V126, P291, DOI 10.1121/1.3140592
   Honing H, 2015, PHILOS T R SOC B, V370, P5, DOI 10.1098/rstb.2014.0088
   Hopyan T, 2011, Cochlear Implants Int, V12, P21, DOI 10.1179/146701010X12677899497399
   Jiam NT, 2017, HEARING RES, V352, P30, DOI 10.1016/j.heares.2017.01.006
   Khing PP, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0082263
   Kong YY, 2004, EAR HEARING, V25, P173, DOI 10.1097/01.AUD.0000120365.97792.2F
   Levy DA, 2001, NEUROREPORT, V12, P2653, DOI 10.1097/00001756-200108280-00013
   Levy DA, 2003, PSYCHOPHYSIOLOGY, V40, P291, DOI 10.1111/1469-8986.00031
   Loizou PC, 1998, IEEE SIGNAL PROC MAG, V15, P101, DOI 10.1109/79.708543
   Looi Valerie, 2012, Seminars in Hearing, V33, P307, DOI 10.1055/s-0032-1329222
   Martin BA, 2007, J AM ACAD AUDIOL, V18, P126, DOI 10.3766/jaaa.18.2.5
   Mc Laughlin M, 2013, HEARING RES, V302, P84, DOI 10.1016/j.heares.2013.05.006
   Most T, 2009, J DEAF STUD DEAF EDU, V14, P449, DOI 10.1093/deafed/enp007
   Nakata T, 2012, J ACOUST SOC AM, V131, P1307, DOI 10.1121/1.3672697
   Palomba D, 1997, INT J PSYCHOPHYSIOL, V27, P55, DOI 10.1016/S0167-8760(97)00751-4
   Paquette S, 2018, HEARING RES, V370, P272, DOI 10.1016/j.heares.2018.08.009
   Paquette S, 2018, ANN NY ACAD SCI, V1423, P329, DOI 10.1111/nyas.13666
   Paquette S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00509
   Paulmann S, 2008, BRAIN LANG, V104, P262, DOI 10.1016/j.bandl.2007.03.002
   Paulmann S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00345
   Pell MD, 2015, BIOL PSYCHOL, V111, P14, DOI 10.1016/j.biopsycho.2015.08.008
   Peretz I, 2015, PHILOS T R SOC B, V370, P68, DOI 10.1098/rstb.2014.0090
   Picard, 1997, J SPEECH LANG PATHOL, V21, P301
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Pisoni DB, 2003, EAR HEARING, V24, p106S, DOI 10.1097/01.AUD.0000051692.05140.8E
   PISONI DB, 1973, PERCEPT PSYCHOPHYS, V13, P253, DOI 10.3758/BF03214136
   Ratcliff R, 2000, PSYCHON B REV, V7, P1, DOI 10.3758/BF03210723
   Rigoulot S, 2015, NEUROSCIENCE, V290, P175, DOI 10.1016/j.neuroscience.2015.01.033
   RITTER W, 1988, ELECTROEN CLIN NEURO, V69, P244, DOI 10.1016/0013-4694(88)90133-2
   Sandmann P, 2010, CLIN NEUROPHYSIOL, V121, P2070, DOI 10.1016/j.clinph.2010.04.032
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   Schupp HT, 2000, PSYCHOPHYSIOLOGY, V37, P257, DOI 10.1111/1469-8986.3720257
   Soderstrom M, 2003, J MEM LANG, V49, P249, DOI 10.1016/S0749-596X(03)00024-X
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Tang Q, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/4/046029
   Thiessen ED, 2005, INFANCY, V7, P53, DOI 10.1207/s15327078in0701_5
   VANDERPLOEG RD, 1987, INT J PSYCHOPHYSIOL, V5, P193, DOI 10.1016/0167-8760(87)90006-7
   Volkova Anna, 2013, Cochlear Implants Int, V14, P80, DOI 10.1179/1754762812Y.0000000004
   Winn MB, 2015, EAR HEARING, V36, pe153, DOI 10.1097/AUD.0000000000000145
   Xin Luo, 2007, Trends Amplif, V11, P301
   Zeng Fan-Gang, 2004, Trends Amplif, V8, P1, DOI 10.1177/108471380400800102
   Zeng FG, 2002, HEARING RES, V174, P101, DOI 10.1016/S0378-5955(02)00644-5
NR 66
TC 10
Z9 10
U1 0
U2 9
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0196-0202
EI 1538-4667
J9 EAR HEARING
JI Ear Hear.
PD SEP-OCT
PY 2019
VL 40
IS 5
BP 1197
EP 1209
DI 10.1097/AUD.0000000000000701
PG 13
WC Audiology & Speech-Language Pathology; Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Audiology & Speech-Language Pathology; Otorhinolaryngology
GA IV6HY
UT WOS:000484370700014
PM 30762600
DA 2024-01-09
ER

PT J
AU Castro, VL
   Camras, LA
   Halberstadt, AG
   Shuster, M
AF Castro, Vanessa L.
   Camras, Linda A.
   Halberstadt, Amy G.
   Shuster, Michael
TI Children's Prototypic Facial Expressions During Emotion-Eliciting
   Conversations With Their Mothers
SO EMOTION
LA English
DT Article
DE facial expression; prototypic expression; discrete emotions; children;
   development
ID VOCAL EXPRESSION; COHERENCE; EXPERIENCE; DISPLAYS; SOCIALIZATION;
   COMMUNICATION; ADJUSTMENT; SITUATION; SYSTEMS; MUSIC
AB Despite theoretical claims that emotions are primarily communicated through prototypic facial expressions, empirical evidence is surprisingly scarce. This study aimed to (a) test whether children produced more components of a prototypic emotional facial expression during situations judged or self-reported to involve the corresponding emotion than situations involving other emotions (termed "intersituational specificity"), (b) test whether children produced more components of the prototypic expression corresponding to a situation's judged or self-reported emotion than components of other emotional expressions (termed "intrasituational specificity"), and (c) examine coherence between children's self-reported emotional experience and observers' judgments of children's emotions. One hundred and 20 children (ages 7-9) were video-recorded during a discussion with their mothers. Emotion ratings were obtained for children in 441 episodes. Children's nonverbal behaviors were judged by observers and coded by FACS-trained researchers. Children's self-reported emotion corresponded significantly to observers' judgments of joy, anger, fear, and sadness but not surprise. Multilevel modeling results revealed that children produced joy facial expressions more in joy episodes than nonjoy episodes (supporting intersituational specificity for joy) and more joy and surprise expressions than other emotional expressions in joy and surprise episodes (supporting intrasituational specificity for joy and surprise). However, children produced anger, fear, and sadness expressions more in noncorresponding episodes and produced these expressions less than other expressions in corresponding episodes. Findings suggest that communication of negative emotion during social interactions-as indexed by agreement between self-report and observer judgments-may rely less on prototypic facial expressions than is often theoretically assumed.
C1 [Castro, Vanessa L.] Northeastern Univ, Dept Psychol, 125 Nightingale Hall, Boston, MA 02115 USA.
   [Camras, Linda A.; Shuster, Michael] Depaul Univ, Dept Psychol, Chicago, IL 60604 USA.
   [Halberstadt, Amy G.] North Carolina State Univ, Dept Psychol, Raleigh, NC USA.
C3 Northeastern University; DePaul University; North Carolina State
   University
RP Castro, VL (corresponding author), Northeastern Univ, Dept Psychol, 125 Nightingale Hall, Boston, MA 02115 USA.
EM v.castro@northeastern.edu
CR [Anonymous], M SOC RES CHILD DEV
   [Anonymous], 1983, A system for identifying affect expressions by holistic judgments (affex)
   Bachorowski JA, 1999, CURR DIR PSYCHOL SCI, V8, P53, DOI 10.1111/1467-8721.00013
   Bonanno G, 2004, COGNITION EMOTION, V18, P431, DOI 10.1080/02699930341000149
   Bonanno GA, 1997, J ABNORM PSYCHOL, V106, P126, DOI 10.1037/0021-843X.106.1.126
   Boone RT, 2001, J NONVERBAL BEHAV, V25, P21, DOI 10.1023/A:1006733123708
   BUCK R, 1994, BIOL PSYCHOL, V38, P95, DOI 10.1016/0301-0511(94)90032-9
   Campos B, 2013, COGNITION EMOTION, V27, P37, DOI 10.1080/02699931.2012.683852
   Campos J. J., 1984, Emotions, cognition, and behavior, P229
   CAMPOS JJ, 1994, MONOGR SOC RES CHILD, V59, P284, DOI 10.2307/1166150
   CAMRAS LA, 1992, COGNITION EMOTION, V6, P269, DOI 10.1080/02699939208411072
   Camras LA, 2006, EMOTION, V6, P103, DOI 10.1037/1528-3542.6.1.103
   Camras LA, 2011, EMOT REV, V3, P138, DOI 10.1177/1754073910387944
   Carroll JM, 1996, J PERS SOC PSYCHOL, V70, P205, DOI 10.1037/0022-3514.70.2.205
   Carroll JM, 1997, J PERS SOC PSYCHOL, V72, P164, DOI 10.1037/0022-3514.72.1.164
   CASEY RJ, 1993, DEV PSYCHOL, V29, P119, DOI 10.1037/0012-1649.29.1.119
   Castro VL, 2016, SOC DEV, V25, P602, DOI 10.1111/sode.12162
   Castro VL, 2015, INFANT CHILD DEV, V24, P1, DOI 10.1002/icd.1868
   Denham SA, 2003, CHILD DEV, V74, P238, DOI 10.1111/1467-8624.00533
   Dunsmore J C, 1997, New Dir Child Dev, P45
   Eisenberg N, 1998, PSYCHOL INQ, V9, P241, DOI 10.1207/s15327965pli0904_1
   Eisenberg N, 2002, ADV CHILD DEV BEHAV, V30, P189, DOI 10.1016/S0065-2407(02)80042-8
   EKMAN P, 1969, SCIENCE, V164, P86, DOI 10.1126/science.164.3875.86
   Ekman P., 1972, NEBRASKA S MOTIVATIO, P207, DOI DOI 10.1037/0022-3514.53.4.712
   Ekman P., 1978, Manual for the facial action coding system
   Ekman P, 2011, EMOT REV, V3, P364, DOI 10.1177/1754073911410740
   Ekman Paul, 1979, HUMAN ETHOLOGY CLAIM, P169, DOI DOI 10.1007/978-1-4020-2783-33
   Fernandez-Dols JM, 1997, J NONVERBAL BEHAV, V21, P163, DOI 10.1023/A:1024917530100
   Fernandez-Dols JM, 1995, EVERYDAY CONCEPTIONS, P505
   Fernández-Dols JM, 2011, J NONVERBAL BEHAV, V35, P63, DOI 10.1007/s10919-010-0097-7
   FRIDLUND AJ, 1991, BIOL PSYCHOL, V32, P3, DOI 10.1016/0301-0511(91)90003-Y
   FRIDLUND AJ, 1990, J NONVERBAL BEHAV, V14, P113, DOI 10.1007/BF01670438
   García-Higuera JA, 2015, SOC SCI INFORM, V54, P439, DOI 10.1177/0539018415596381
   Gunlicks-Stoessel ML, 2008, J RES ADOLESCENCE, V18, P621, DOI 10.1111/j.1532-7795.2008.00574.x
   HALBERSTADT AG, 1992, J NONVERBAL BEHAV, V16, P215, DOI 10.1007/BF01462003
   Halberstadt AG, 2001, SOC DEV, V10, P79, DOI 10.1111/1467-9507.00150
   Halberstadt AG, 2013, HANDB COMMUN SCI, V2, P93
   Harrigan J. A., 2005, NEW HDB METHODS NONV, P65, DOI DOI 10.1093/ACPROF:OSO/9780198529620.003.0003
   Hernández MM, 2016, EMOTION, V16, P553, DOI 10.1037/emo0000147
   HIATT SW, 1979, CHILD DEV, V50, P1020, DOI 10.1111/j.1467-8624.1979.tb02463.x
   Holodynski M, 2004, DEV PSYCHOL, V40, P16, DOI 10.1037/0012-1649.40.1.16
   Izard C E, 1978, Nebr Symp Motiv, V26, P163
   Izard C. E., 1987, HDB INFANT DEV, P494
   Izard CE, 2011, EMOT REV, V3, P371, DOI 10.1177/1754073911410737
   Izard CE, 2004, EMOTION, V4, P251, DOI 10.1037/1528-3542.4.3.251
   IZARD CE, 1984, CONTEMP PSYCHOL, V29, P457, DOI 10.1037/022933
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kahn JH, 2011, J COUNS PSYCHOL, V58, P257, DOI 10.1037/a0022680
   Manstead A. S. R., 2001, Appraisal Processes in Emotion, P221, DOI DOI 10.1037/1528-3542.1.1.51
   Matsumoto D, 2001, ASIAN J SOC PSYCHOL, V4, P113, DOI 10.1111/j.1467-839X.2001.00080.x
   Matsumoto D., 2008, Handbook of Emotions, P211, DOI DOI 10.1016/J.BRAT.2006.05.004
   Mauss IB, 2005, EMOTION, V5, P175, DOI 10.1037/1528-3542.5.2.175
   Muthen L. K., 1998, Mplus User's Guide, DOI 10.001316447803800111
   Noller P, 2001, LEA SER PER CLIN PSY, P243
   Park B, 2005, PERS SOC PSYCHOL REV, V9, P108, DOI 10.1207/s15327957pspr0902_2
   Pons F, 2004, EUR J DEV PSYCHOL, V1, P127, DOI 10.1080/17405620344000022
   Raudenbush SW., 2002, Hierarchical linear models: Applications and data analysis methods, DOI DOI 10.2307/2075823
   Reisenzein R, 2006, J PERS SOC PSYCHOL, V91, P295, DOI 10.1037/0022-3514.91.2.295
   Reisenzein R, 2013, EMOT REV, V5, P16, DOI 10.1177/1754073912457228
   Rogers ML, 2016, EMOTION, V16, P280, DOI 10.1037/emo0000142
   ROSENBERG EL, 1994, COGNITION EMOTION, V8, P201, DOI 10.1080/02699939408408938
   Ruiz-Belda MA, 2003, COGNITION EMOTION, V17, P315, DOI 10.1080/02699930302288
   Russell J. A., 1997, The psychology of facial expression, P295, DOI [DOI 10.1017/CBO9780511659911.015, 10.1017/cbo9780511659911.015]
   Saarni C., 1999, The development of emotional competence
   Sallquist J, 2012, EMOTION, V12, P304, DOI 10.1037/a0025238
   Welsh DP, 2005, J FAM PSYCHOL, V19, P62, DOI 10.1037/0893-3200.19.1.62
   Widen SC, 2013, PSYCHOL BULL, V139, P271, DOI 10.1037/a0031640
   Zeman J, 1996, CHILD DEV, V67, P957, DOI 10.1111/j.1467-8624.1996.tb01776.x
NR 68
TC 19
Z9 21
U1 1
U2 17
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 1528-3542
EI 1931-1516
J9 EMOTION
JI Emotion
PD MAR
PY 2018
VL 18
IS 2
BP 260
EP 276
DI 10.1037/emo0000354
PG 17
WC Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA GB1VV
UT WOS:000428839700010
PM 28714700
OA Green Accepted
DA 2024-01-09
ER

PT J
AU Osadcha, S
   Wei, LX
   Qiao, Z
   Chen, HY
   Cheng, S
AF Osadcha, Svitlana
   Wei, Lixian
   Qiao, Zhi
   Chen, Hongyu
   Cheng, Shuo
TI EMOTIVE-AXIOLOGICAL APPROACH IN MUSICOLOGY AND MODERN THEORY OF OPERA
   EXPERIENCE
SO AD ALTA-JOURNAL OF INTERDISCIPLINARY RESEARCH
LA English
DT Article
DE Opera emotions; opera theatre; opera poetics; opera plot;
   interpretation; opera image; opera melos
AB In the context of the art of vocal and stage performance, the issues of the influence of the musical factor on the process of impersonation of the singer-actor, the existential nature of the art of impersonation, the psychological mechanisms of understanding and appropriation of the text-consciousness of the character by the performer, the processuality of experiencing as an activity of the opera performer and character, musical stage images and forms are touched upon, along with the issues of internal and external action of the character, modality factors of vocal intonation, including the expected circumstances of the role. The syncretism of the opera text as an integral interdeterministic system of stage action meaning, which has an emotional impact on the audience and performers through all three channels of communication -visual, auditory, and verbal, makes it possible to define the opera within the framework of emotionalology as a new branch of social psychology. An attempt is made to show that personal and collective emotions generated by an opera performance are decisive in a syncretic opera text.
C1 [Osadcha, Svitlana; Wei, Lixian; Qiao, Zhi; Chen, Hongyu; Cheng, Shuo] Odessa Natl AV Nezhdanova Acad Mus, 63 Novoselskogo Str, UA-65000 Odessa, Ukraine.
C3 Odessa National A. V. Nezhdanova Academy of Music
RP Osadcha, S (corresponding author), Odessa Natl AV Nezhdanova Acad Mus, 63 Novoselskogo Str, UA-65000 Odessa, Ukraine.
EM svetikvick@gmail.com; willowleex@gmail.com; atlaoqiao@gmail.com;
   404746698@qq.com; cen9772l7@gmail.com
RI Chen, Hongyu/JGM-9228-2023
CR Bai Quan, 2017, THESIS ODESA NATL MU
   Dorfman L., 1997, EMOTIONS ART THEORET
   Izard K., 1999, PSYCHOL EMOTIONS
   Samoilenko O., 2020, PSYCHOL ART MODERN M
   Sheludyakova O., 2006, THESIS URAL STATE CO
   Vasilyuk F., 1984, PSYCHOL EXPERIENCE
   Vygotsky L., 1968, PSYCHOL ART
   Zorin A., 2016, NEW LIT REV
NR 8
TC 0
Z9 0
U1 0
U2 0
PU MAGNANIMITAS
PI HRADEC KRALOVE
PA CESKOSLOVENSKE ARMADY 300, HRADEC KRALOVE, 500 03, CZECH REPUBLIC
SN 1804-7890
J9 AD ALTA-INTERDISCIP
JI AD ALTA-J. Interdiscip. Res.
PY 2023
VL 13
IS 2
SI SI
BP 37
EP 39
PG 3
WC Multidisciplinary Sciences
WE Emerging Sources Citation Index (ESCI)
SC Science & Technology - Other Topics
GA M1QV8
UT WOS:001027993900006
DA 2024-01-09
ER

PT J
AU van Rooyen, A
   dos Santos, A
AF van Rooyen, Anrie
   dos Santos, Andeline
TI Exploring the lived experiences of teenagers in a children's home
   participating in a choir: A community music therapy perspective
SO INTERNATIONAL JOURNAL OF COMMUNITY MUSIC
LA English
DT Article
DE teenagers; children's home; community music therapy; choir;
   interpersonal growth; intrapersonal growth
ID POWER-RELATIONS; RESILIENCE; ADOLESCENTS; EDUCATION; RISK; SUPPORT;
   YOUTH
AB This study explored the lived experiences of teenagers in a children's home who participated in a choir that was facilitated from a community music therapy perspective in Pretoria, South Africa. Sixteen weekly choir sessions were held. These included a variety of interactive vocal techniques. A performance marked the end of the process, where songs selected by the teenagers were performed. Qualitative data were collected through fourteen semi-structured individual interviews at the end of the process. All interview transcripts were analysed through utilizing interpretative phenomenological analysis. The study concluded that participation in this community music therapy choir offered the teenagers perceived meaningful intra-and interpersonal experiences. At an intrapersonal level, the participants experienced discovering their musical voices; accessing inner strength to take action both in the here-and-now and in the future; increased self-awareness, self-esteem and self-confidence; as well as expressing and regulating emotions. In terms of interpersonal experiences, the teenagers experienced growth in relationships; improved social skills; and greater connection with the broader community.
C1 [van Rooyen, Anrie] Univ Pretoria, Lynnwood Rd, Pretoria, South Africa.
   [dos Santos, Andeline] Univ Pretoria, Mus Therapy Masters Programme, Lynnwood Rd, Pretoria, South Africa.
C3 University of Pretoria; University of Pretoria
RP van Rooyen, A (corresponding author), Univ Pretoria, Lynnwood Rd, Pretoria, South Africa.
EM anrie.vanrooyen@gmail.com; andeline.dossantos@up.ac.za
RI dos Santos, Andeline/M-4037-2016
OI dos Santos, Andeline/0000-0002-7536-0014
FU Touching Africa
FX The choir's concert was financially supported by Touching Africa. I
   would like to thank them for making this event possible and memorable.
CR Ahmadi M, 2012, THERAPEUTIC USES OF RAP AND HIP-HOP, P191
   AIGEN K, 2002, PLAYIN BAND QUALITAT
   Aigen K., 2004, COMMUNITY MUSIC THER, P186
   Aigen K, 2008, ART PSYCHOTHER, V35, P307, DOI 10.1016/j.aip.2008.06.001
   Amir D., 2004, COMMUNITY MUSIC THER
   Amir D, 2014, MUSIC HELPS MUSIC TH
   Amir D, 2010, MUSIC HELPS COMMUNIT, P161
   [Anonymous], 2004, COMMUNITY MUSIC THER
   [Anonymous], CANADIAN J MUSIC THE
   [Anonymous], 2005, RES GRASS ROOTS SOCI
   [Anonymous], 2005, International Journal of Music Education, DOI [10.1177/0255761405050927, DOI 10.1177/0255761405050927]
   [Anonymous], 2012, Qualitative research methods in mental health and psychotherapy: A guide for students and practitioners
   [Anonymous], 1994, HDB TREATMENT ATTACH
   [Anonymous], 2005, THEORY PRACTICE GROU
   [Anonymous], J SERVICE LEARNING H
   [Anonymous], 2008, PSYCHOL ORPHANS
   [Anonymous], J EARLY ADOLESC
   Ansdell, 2004, COMMUNITY MUSIC THER
   Ansdell G., 2005, VOICES WORLD FORUM M, V5, DOI [10.15845/VOICES.V5I3.229, DOI 10.15845/VOICES.V5I3.229]
   Ansdell G., 2015, OXFORD HDB MUSIC THE, P595
   Baker FA, 2017, INT J COMMUNITY MUSI, V10, P157, DOI 10.1386/ijcm.10.2.157_1
   Berridge D, 2007, CHILD FAM SOC WORK, V12, P1, DOI 10.1111/j.1365-2206.2006.00446.x
   Bicakci K, 2011, PROCEEDINGS OF THE 2011 NEW SECURITY PARADIGMS WORKSHOP (NSPW'11), P25
   Bolger L., 2015, QUALITATIVE INQUIRIE, V10, P77
   Bourdeau B., 2000, QUALITATIVE REPORT, V4, P1
   Bunt L, 2014, MUSIC THERAPY ART WO
   Chikwaiwa B. K., 2013, J SOCIAL DEV S AFRIC, V28, P23
   Cluver L, 2007, AIDS CARE, V19, P318, DOI 10.1080/09540120600986578
   Creswell J. W., 2016, QUAL INQ
   Crosnoe R, 2004, J FAM ISSUES, V25, P571, DOI 10.1177/0192513X03258307
   Dabback W, 2018, MUSIC EDUC RES, V20, P242, DOI 10.1080/14613808.2016.1257593
   Davey M, 2003, J ADOLESCENT RES, V18, P347, DOI 10.1177/0743558403018004002
   de Witt MW, 2010, TD-J TRANSDISCIPL RE, V6, P461
   Demorest SM, 2017, J RES MUSIC EDUC, V64, P405, DOI 10.1177/0022429416680096
   Donnenwerth AM, 2012, THERAPEUTIC USES OF RAP AND HIP-HOP, P275
   Dumont M, 1999, J YOUTH ADOLESCENCE, V28, P343, DOI 10.1023/A:1021637011732
   Elliott D. J., 1995, Music Matters
   Evans RM., 2005, Journal of Children Poverty, V11, P111
   Foster G, 2002, ACTA PAEDIATR, V91, P502, DOI 10.1080/080352502753711588
   GROSSMAN FK, 1992, J YOUTH ADOLESCENCE, V21, P529, DOI 10.1007/BF01537394
   Guerrero N., 2015, OXFORD HDB MUSIC THE, P282
   Gursoy F., 2012, INT J SOC SCI ED, V2, P56
   Hansen S., 2000, CHORAL J, V41, P75
   Howard KA, 2015, GEOSPHERE, V11, P1, DOI 10.1130/GES01059.1
   Humphrey R, 2019, INT J COMMUNITY MUSI, V12, P13, DOI 10.1386/ijcm.12.1.13_1
   Jampel P., 2011, VOICES WORLD FORUM M, V11, P1
   Karnieli-Miller O, 2009, QUAL HEALTH RES, V19, P279, DOI 10.1177/1049732308329306
   Laiho S., 2004, NORD J MUSIC THER, V13, P47, DOI DOI 10.1080/08098130409478097
   Lightstone AJ, 2012, THERAPEUTIC USES OF RAP AND HIP-HOP, P211
   Luhrs R., 2015, THESIS
   Luthar S., 2014, CHILD DEV, V62, P600
   MacDonald S, 2012, THERAPEUTIC USES OF RAP AND HIP-HOP, P153
   Matshalaga NR, 2002, BMJ-BRIT MED J, V324, P185, DOI 10.1136/bmj.324.7331.185
   McFerran K., 2011, VOICES WORLD FORUM M, V11
   McFerran K, 2012, THERAPEUTIC USES OF RAP AND HIP-HOP, P173
   McFerran KS, 2014, INT J COMMUNITY MUSI, V7, P75, DOI 10.1386/ijcm.7.1.75_1
   National Adoption Coalition South Africa, 2014, FACT SHEET CHILD AB
   O'Grady L, 2007, NORD J MUSIC THER, V16, P14, DOI 10.1080/08098130709478170
   Parker E. C., 2007, CHORAL J, V48, P26
   PIENAAR A, 2012, J SOCIAL ASPECTS HIV, V8, P128, DOI DOI 10.1080/17290376.2011.9724995
   Powell H., 2004, COMMUNITY MUSIC THER, P167
   Pringle Jan, 2011, Nurse Res, V18, P20
   Quas JA, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0181606
   REID GC, 2007, QUALITATIVE PSYCHOL, P52
   Reyland SA, 2002, AIDS CARE, V14, P285, DOI 10.1080/09540120120076977
   Ritchie J., 2003, A Guide for Social Science Students Researchers, P219
   Roche S, 2019, CHILD YOUTH SERV REV, V105, DOI 10.1016/j.childyouth.2019.104448
   Rolvsjord R, 2015, NORD J MUSIC THER, V24, P44, DOI 10.1080/08098131.2013.861502
   Rolvsjord R, 2006, BRIT J MUSIC THER, V20, P5, DOI 10.1177/135945750602000103
   Smeijsters H, 2008, NORD J MUSIC THER, V17, P19, DOI 10.1080/08098130809478192
   Stige B., 2012, INVITATION COMMUNITY
   Sun Jing, 2012, Int J Adolesc Med Health, V24, P281, DOI 10.1515/ijamh.2012.040
   Travis R, 2013, CHILD ADOLESC SOC WO, V30, P139, DOI 10.1007/s10560-012-0285-x
   Uhlig S, 2018, PSYCHOL MUSIC, V46, P568, DOI 10.1177/0305735617719154
   van Manen M., 2015, Researching lived experience
   Viega M, 2016, MUSIC THER PERSPECT, V34, P138, DOI 10.1093/mtp/miv035
   Wan CY, 2010, MUSIC PERCEPT, V27, P287, DOI 10.1525/MP.2010.27.4.287
   Wassenaar DR, 2006, RES PRACTICE APPL ME, P60
   Werner EE, 1997, ACTA PAEDIATR, V86, P103
   Whetten K, 2011, J TRAUMA STRESS, V24, P174, DOI 10.1002/jts.20625
   WHIDDEN C., 2008, GEMS GENDER ED MUSIC, V4, P1
   Wills R, 2011, INT J CHILD SPIRITUA, V16, P37, DOI 10.1080/1364436X.2010.540750
   Wood S., 2016, MATRIX COMMUNITY MUS
NR 83
TC 1
Z9 4
U1 4
U2 27
PU INTELLECT LTD
PI BRISTOL
PA THE MILL, PARNALL RD, BRISTOL, BS16 3JG, ENGLAND
SN 1752-6299
EI 1752-6302
J9 INT J COMMUNITY MUSI
JI Int. J. Community Music
PD MAY
PY 2020
VL 13
IS 1
BP 81
EP 101
DI 10.1386/ijcm_00011_1
PG 21
WC Music
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music
GA LX7UC
UT WOS:000540031500006
OA Green Submitted
DA 2024-01-09
ER

PT J
AU Restrepo, M
AF Restrepo, Margarita
TI A new genre arrives in Spain: the madrigal in vihuela collections
SO EARLY MUSIC
LA English
DT Article
DE madrigal; Spain; vihuela collections; intabulations; courts; urban
   centres; vihuela song
AB Six of the seven vihuela publications that came out of Spain between 1536 and 1576 contain a group of works distinguished by two elements that were new to Spanish music: the use of through-composed forms and hendecasyllabic verse. Since these features characterize the Italian madrigal, I argue that these works announce the arrival of this new genre into Spain, and represent the first attempt to adapt the foreign genre to Spanish sensibilities, for collections of vocal madrigals only begin to appear after 1550. Often overlooked because they appear in instrumental collections, the pieces in the first three collections show that vihuelists working at Italianate courts embraced the genre in the 1530s, but adapted it to a different medium, the vihuela song, and used both voice and vihuela to express the nuances of the fine poetry they chose to set. The later three, where intabulations predominate, represent the diffusion of the genre into urban centres and indicate the Italian madrigals that appealed to Spanish audiences, mainly those by the first generation of madrigalists, which although expressive of the content and emotion of the text, represent an approach that Spaniards identified with.
C1 [Restrepo, Margarita] Walnut Hill Sch Arts Natick, Mus Fac, Natick, MA 01760 USA.
RP Restrepo, M (corresponding author), Walnut Hill Sch Arts Natick, Mus Fac, Natick, MA 01760 USA.
EM mrestrepo@walnuthillarts.org
CR [Anonymous], 1570, VOCABULARIO LENGUAS
   [Anonymous], 1543, OBRAS BOSCAN ALGUNAS
   [Anonymous], 1979, MENDOZA FAMILY SPANI
   [Anonymous], 1546, MADRIGALI CINQUE VOC
   [Anonymous], 1540, VERDELOTTO TUTTI LI
   [Anonymous], 1565, ARTE TANER FANTASIA
   [Anonymous], 1981, MONUMENTOS MUSICA ES, V40, P11
   [Anonymous], 1973, ARTE TANER FANTASIA
   [Anonymous], 1754, VIAGGIO IN ISPAGNA
   [Anonymous], 1512, FRANCISCO PETRARCA C
   [Anonymous], 1485, MISSALE CESARAUGUSTA
   [Anonymous], 1580, OBRAS GARCILASO VEGA
   [Anonymous], 1582, EL PASTOR DE FILIDA
   [Anonymous], 1555, SACRAE CANTIONES
   [Anonymous], 1551, VILLANCICOS CANCIONE
   [Anonymous], 1611, TESORO LENGUA CASTEL
   [Anonymous], 1539, VERO 2 LIBRO MADRIGA
   [Anonymous], 1589, CANCIONES VILLANESCA
   [Anonymous], 1539, TERZO LIBRO MADRIGAL
   [Anonymous], 1576, EL PARNASSO
   Bermudo, 1555, DECLARACION
   Bermudo J., 1555, Declaracion de instrumentos musicales
   Bermudo Juan., 1957, DECLARACION INSTRUME
   Carreras J.J, 2005, ROYAL CHAPEL TIME HA, P83
   de Milan Luis, 1536, EL MAESTRO
   Duran's Domingo Marcos, 1492, LUX BELLA
   Einstein A, 1949, THE ITALIAN MADRIGAL, Vi, P104
   Freis W., 1995, REV MUSICOLOGIA, Vxviii, P61
   Gasser L, 1996, L MILAN 16 CENTURY P
   Gertrudix F, 2017, COMMUNICATION
   Godoy Gomez L.M, 2002, JUSTAS POETICAS SEVI
   Gomez Moreno A, 1988, IL DEMENDOZA OBRAS C, pxxxii
   Gonzalez Barrionuevo H, 2000, FRANCISCO GUERRERO
   GRIFFITHS J, 1995, EARLY MUSIC, V23, P437
   Griffiths J, 2001, DICCIONARIO MUSICA E, Vviii, P827
   Jacobs C, 1971, EL MAESTRO, P136
   KING Willard, 1960, PMLA, V75, P367
   McMurtry W, 1977, 16 CENTURY J, Viii, P17
   Navaggiero Andrea, 1754, VIAGGIO ISPAGNA OPER, P311
   Navarrete I, 1992, 16 CENTURY J, Vxxiii, P770
   Navarrete I, 1992, 16 CENTURY J, Vxxiii, P775
   Nelson B, 2004, EARLY MUSIC, V32, P195
   NUGENT G, 1988, J MUSICOLOGY, V6, P198
   Padron F.Morales, 1977, CIUDAD QUINIENTOS, P65
   Pike Ruth., 1966, Enterprise and Adventure. The Genoese in Seville and the Opening of the New World, P1
   Pinero P.M, 1985, LIBRO DESCRIPCION VE, P262
   Pujol E, 1965, MONUMENTOS MUSICA ES, V22, P38
   Querol Gavalda M, 1981, MONUMENTOS MUSICA ES, V40, P7
   Randel D.M, 1974, MUSICAL Q, Vlx, P61
   Rincon S. Aguirre, 2009, EARLY MUSIC, Vxxxvii, P385
   Roa Alonso F.J, 2016, REV MUSICOLOGIA, Vxxxix, P347
   Roa F, 2001, LIBRO MUSICA VIHUELA
   Roche J, 2001, NEW GROVE DICT MUSIC, Vxv, P570
   ROmEu FIGuERAS Jose, 1958, ANU MUSIC, VXIII, P25
   Jiménez JR, 2009, EARLY MUSIC, V37, P401, DOI 10.1093/em/cap063
   Sanchez J, 1961, ACAD LITERARIAS SIGL, P199
   Sannazaro's, 1547, ARCADIA
   Schwartz R, 2001, THESIS, P246
   sonetos De los, 1567, SONETOS CANCIONES MA
   Taricani J, 1992, REV BELGE MUSICOLOGI, Vxlvi, P55
   Trend J. B., 1925, P MUS ASS 52 SESS ST, P13
   Ward J.M, 1953, VIHUELA MANO ITS MUS, P290
NR 62
TC 0
Z9 0
U1 0
U2 1
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 0306-1078
EI 1741-7260
J9 EARLY MUSIC
JI Early Music
PD NOV
PY 2017
VL 45
IS 4
BP 573
EP +
DI 10.1093/em/cax085
PG 19
WC Music
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music
GA GA5UY
UT WOS:000428400600006
DA 2024-01-09
ER

PT J
AU Saeed, MH
AF Saeed, Mariwan Hama
TI Improved Speech Emotion Classification Using Deep Neural Network
SO CIRCUITS SYSTEMS AND SIGNAL PROCESSING
LA English
DT Article
DE Emotion classification; Deep learning; Deep neural network; Librosa
   library; MFCC; Mel-spectrogram frequency; Chroma; Poly features
ID RECOGNITION; MUSIC
AB Speech emotion recognition (SER), which has gained greater attention in recent years, is a key aspect of the human-computer interaction process. However, a wide range of strategies has been offered in SER, and these approaches have yet to increase performance. In this study, a deep neural network model for classifying voice emotions is suggested. It is divided into three stages: feature extraction, normalization, and emotion recognition. The Librosa Python Toolkit is used to acquire the MFCC, Mel-Spectrogram Frequency, Chroma, and Poly Features during feature extraction. Data augmentation for the minority class using SMOTE (synthetic minority oversampling technique) and the Min-Max scaler for the normalization process were used. The model was evaluated on three frequently used languages: German, English, and French, using the Berlin Emotional Speech Database (EMODB), Surrey Audio-Visual Expressed Emotion Dataset (SAVEE), and the Canadian French Emotional (CaFE) speech datasets. The recognition rates of unweighted accuracy of 95% on EMODB, 90% on SAVEE, and 92% on CaFE are gained in speaker-dependent experiments. The results show that the suggested method is capable of efficiently recognizing emotions and outperformed the other approaches utilized for comparison in terms of performance indicators.
C1 [Saeed, Mariwan Hama] Univ Halabja, Coll Basic Educ, Halabja, Iraq.
RP Saeed, MH (corresponding author), Univ Halabja, Coll Basic Educ, Halabja, Iraq.
EM mariwan.ahmedh@gmail.com
RI Hama Saeed, Mariwan Ahmed/ACL-5333-2022
OI Hama Saeed, Mariwan Ahmed/0000-0003-4962-4239
CR Ahmed MR, 2023, EXPERT SYST APPL, V218, DOI 10.1016/j.eswa.2023.119633
   Albon Ch, 2018, Machine learning with python cookbook: Practical solutions from preprocessing to deep learning
   Ancilin J, 2021, APPL ACOUST, V179, DOI 10.1016/j.apacoust.2021.108046
   Aouani Hadhami, 2020, Procedia Computer Science, V176, P251, DOI 10.1016/j.procs.2020.08.027
   Atmaja BT, 2022, SPEECH COMMUN, V140, P11, DOI 10.1016/j.specom.2022.03.002
   Brownlee J, 2020, Machine Learning Mastery
   Burkhardt F, 2005, 9 EUR C SPEECH COMM, V5, P1517, DOI [10.21437/Interspeech.2005-446, DOI 10.21437/INTERSPEECH.2005-446]
   Chauhan Krishna, 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P1176, DOI 10.1109/ICAIS50930.2021.9395844
   Chen LF, 2020, INFORM SCIENCES, V509, P150, DOI 10.1016/j.ins.2019.09.005
   Daneshfar F., 2021, P 2021 7 INT C SIGN, DOI [10.1109/ICSPIS54653.2021.9729337, DOI 10.1109/ICSPIS54653.2021.9729337]
   Degottex Gilles, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P960, DOI 10.1109/ICASSP.2014.6853739
   Do LN, 2021, J SUPERCOMPUT, V77, P10773, DOI 10.1007/s11227-021-03690-y
   Eyben F., 2015, ACM SIGMULTIMEDIA RE, V6
   Geron A, 2019, HANDS ON MACHINE LEA, DOI DOI 10.1201/9780367816377
   Goel S., 2020, ARXIV PREPRINT
   Guha S, 2020, IEEE ACCESS, V8, P182868, DOI 10.1109/ACCESS.2020.3028121
   Huang SH, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10232891
   Ibrahim H, 2022, MALAYS J COMPUT SCI, V35, P128, DOI 10.22452/mjcs.vol35no2.3
   Ibrahim H, 2021, IEEE ACCESS, V9, P122855, DOI 10.1109/ACCESS.2021.3107858
   Jackson Philip, 2014, SURREY AUDIO VISUAL
   Kanwal S, 2021, IEEE ACCESS, V9, P125830, DOI 10.1109/ACCESS.2021.3111659
   Kejriwal J, 2022, 2022 32ND INTERNATIONAL CONFERENCE RADIOELEKTRONIKA (RADIOELEKTRONIKA), P133, DOI 10.1109/RADIOELEKTRONIKA54537.2022.9764916
   Krothapalli S.R., 2013, EMOTION RECOGNITION, P67, DOI 10.1007/978-1-4614-5143-3_4
   Lerch A., 2012, INTRO AUDIO CONTENT, DOI [10.1002/9781118393550, DOI 10.1002/9781118393550]
   Liu N, 2021, IEEE ACCESS, V9, P95925, DOI 10.1109/ACCESS.2021.3094355
   Liu ZT, 2021, INFORM SCIENCES, V563, P309, DOI 10.1016/j.ins.2021.02.016
   Long L., 2022, BEGIN DEEP LEARN TEN, DOI [10.1007/978-1-4842-7915-1, DOI 10.1007/978-1-4842-7915-1]
   Mai SJ, 2021, IEEE-ACM T AUDIO SPE, V29, P1424, DOI 10.1109/TASLP.2021.3068598
   Maji B, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11091328
   McFee B, 2015, P 14 PYTH SCI C, P18, DOI [DOI 10.25080/MAJORA-7B98E3ED-003, 10.25080/majora-7b98e3ed-003]
   Müller M, 2021, IEEE SIGNAL PROC MAG, V38, P73, DOI 10.1109/MSP.2021.3052181
   Müller M, 2011, IEEE J-STSP, V5, P1088, DOI 10.1109/JSTSP.2011.2112333
   Mustaqeem, 2021, INT J INTELL SYST, V36, P5116, DOI 10.1002/int.22505
   Mustaqeem, 2020, IEEE ACCESS, V8, P79861, DOI 10.1109/ACCESS.2020.2990405
   Muthumari M., 2022, 2022 6th International Conference on Intelligent Computing and Control Systems (ICICCS), P1126, DOI 10.1109/ICICCS53718.2022.9788269
   Nallanthighal V.S., 2022, ICASSP IEEE INT C AC, P2505
   Pawar MD, 2021, MULTIMED TOOLS APPL, V80, P15563, DOI 10.1007/s11042-020-10329-2
   Pham M.H., 2021, 2021 IEEE 2 INT C SI, P182
   Pham N. Truong, 2021, ARXIV
   Pham NT., 2023, EXPERT SYST APPL, DOI [10.48550/arxiv.2109.09026, DOI 10.48550/ARXIV.2109.09026]
   Prasanna YL., 2023, INT C DISR TECHN MUL, V2, P185, DOI [10.1109/CENTCON56610.2022.10051557, DOI 10.1109/CENTCON56610.2022.10051557]
   Rao K.S., 2017, Speech recognition using articulatory and excitation source features, DOI DOI 10.1007/978-3-319-49220-9
   Rao KS., 2013, EMOTION RECOGNITION, DOI [10.1007/978-1-4614-5143-3, DOI 10.1007/978-1-4614-5143-3]
   Rowlands L., EMOTIONS HUMANS REGU
   Sahoo AK., 2020, NATURE INSPIRED COMP, P201, DOI DOI 10.1007/978-3-030-33820-6_8
   Sahoo KK, 2021, IEEE ACCESS, V9, P166518, DOI 10.1109/ACCESS.2021.3135658
   Seknedy El M., 2021, P 2021 IEEE 10 INT C, P361, DOI [10.1109/ICICIS52592.2021.9694246, DOI 10.1109/ICICIS52592.2021.9694246]
   Senthilkumar N, 2022, MATER TODAY-PROC, V57, P2180, DOI 10.1016/j.matpr.2021.12.246
   Sezgin MC, 2012, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2012-16
   Suman S., 2022, VISUALIZATION AUDIO, P409, DOI [10.1007/978-981-19-0182-9_41, DOI 10.1007/978-981-19-0182-9_41]
   Swain M, 2018, INT J SPEECH TECHNOL, V21, P93, DOI 10.1007/s10772-018-9491-z
   Tao HW, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24081025
   Thakur Anuja, 2022, International Journal of Information Technology, P3691, DOI 10.1007/s41870-022-00996-9
   Tomprou M, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0247655
   Tsai YHH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6558, DOI 10.18653/v1/p19-1656
   Zehra W, 2021, COMPLEX INTELL SYST, V7, P1845, DOI 10.1007/s40747-020-00250-4
   Zhang CH, 2021, IEEE ACCESS, V9, P51231, DOI 10.1109/ACCESS.2021.3069818
   Zhang HY, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11219897
NR 58
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER BIRKHAUSER
PI NEW YORK
PA 233 SPRING STREET, 6TH FLOOR, NEW YORK, NY 10013 USA
SN 0278-081X
EI 1531-5878
J9 CIRC SYST SIGNAL PR
JI Circuits Syst. Signal Process.
PD DEC
PY 2023
VL 42
IS 12
BP 7357
EP 7376
DI 10.1007/s00034-023-02446-8
EA JUL 2023
PG 20
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA U9DA5
UT WOS:001039315700001
DA 2024-01-09
ER

PT J
AU Falconer, E
AF Falconer, Emily
TI In harmony or out of tune: Affective and emotional geographies of
   all-male choirs in London, UK
SO EMOTION SPACE AND SOCIETY
LA English
DT Article
DE Choirs; Affect; Sound; Emotion; Masculinity
ID MEN
AB This article examines the growing popularity of weekly amateur choral singing for adult men, with a specific focus in London, UK. This paper moves away from discourses of social health and wellbeing to bring together critical studies of masculinity with emotional geographies of sound, to better understand the links between choirs as an affective space and the complex, symbolic relationship between men and their voices. Where research has shown that non-competitive group activity is central to men's sense of connection and provides a space for men to express emotions, friendship and intimacy, there is great potential to analyse how the role of sound (volume, vibrations) and use of choral voice work (softening, blending, harmonies) directly facilitates this connection. This paper remains cautious of presenting group singing as an automatic panacea to disconnection, exploring the exclusions for those who are 'out of tune' and (musically and socially) unable to harmonise with others.
C1 [Falconer, Emily] Univ Westminster, Sch Social Sci, Sociol, Room 401,Wells St, London W1B 2HW, England.
C3 University of Greenwich; University of Westminster
RP Falconer, E (corresponding author), Univ Westminster, Sch Social Sci, Sociol, Room 401,Wells St, London W1B 2HW, England.
EM e.falconer@westminster.ac.uk
CR Ahmed Sara., 2003, CULTURAL POLITICS EM
   Ahmed Sara, 2010, The promise of happiness, DOI DOI 10.1215/9780822392781
   Anderson E, 2018, J GENDER STUD, V27, P547, DOI 10.1080/09589236.2016.1245605
   [Anonymous], 2015, OXFORD HDB SOCIAL JU
   [Anonymous], 2012, RES ISSUES MUSIC ED
   Arauna N, 2020, YOUNG, V28, P32, DOI 10.1177/1103308819831473
   Armstrong G., 2000, Football culture: local conflicts, global visions., P173
   Ashley M, 2010, GENDER EDUC, V22, P47, DOI 10.1080/09540250802213164
   Brammal R., 2015, 5 INT INTERDISCIPLIN
   Bull M., 2003, AUDITORY CULTURE REA
   Clift SM, 2001, J R SOC PROMO HEALTH, V121, P248, DOI 10.1177/146642400112100409
   Connell Raewyn, 2005, Masculinities, V2nd
   Crowhurst I, 2020, MEN MASC, V23, P170, DOI 10.1177/1097184X18766578
   de Boise S, 2017, SOCIOL REV, V65, P779, DOI 10.1177/0038026116686500
   de Boise S, 2014, SOCIOL RES ONLINE, V19, DOI 10.5153/sro.3274
   Dingle G.A., 2019, MUSIC AND SCI
   Doughty K, 2022, EMOT SPACE SOC, V42, DOI 10.1016/j.emospa.2021.100867
   Doughty K, 2016, EMOT SPACE SOC, V20, P39, DOI 10.1016/j.emospa.2016.06.007
   Downes J, 2012, WOMEN STUD, V41, P204, DOI 10.1080/00497878.2012.636572
   Duffy L., 2007, Altitude: A Journal of Emerging Humanities Work, V8, P1
   Elorriaga A, 2011, INT J MUSIC EDUC, V29, P318, DOI 10.1177/0255761411421091
   Evers C, 2009, SOC CULT GEOGR, V10, P893, DOI 10.1080/14649360903305783
   Falconer E., 2021, SPACE TASTE AFFECT A
   Faulkner Robert, 2012, PERSPECTIVES MALES S, P215
   Flood M., 2017, Women's Studies Journal, V31, P48
   Freer Patrick K., 2012, PERSPECTIVES MALES S, V2012b, P13
   Garcia Felicia., 2016, Coping and Suicide Amongst the Lads: Expectations of Masculinity in Post-Traditional Ireland
   Green K., 2020, Contexts, V19, P10, DOI [https://doi.org/10.1177/1536504220920188, DOI 10.1177/1536504220920188]
   Harrington C, 2021, MEN MASC, V24, P345, DOI 10.1177/1097184X20943254
   Heasley Robert, 2005, MEN MASC, V7, P310, DOI DOI 10.1177/1097184X04272118
   Kyto M., 2011, Soccer and Society, V12, P77, DOI 10.1080/14660970.2011.530474
   Layton M., 2019, VOICES LOWER DECK FO
   Malbon B., 1999, Clubbing: Dancing, Ecstasy, Vitality. Critical Geographies
   May V, 2020, QUAL RES, V20, P127, DOI 10.1177/1468794119834186
   Munt SR, 2010, QUEER SPIRITUAL SPACES: SEXUALITY AND SACRED PLACES, P1
   Neal S, 2015, POPUL SPACE PLACE, V21, P463, DOI 10.1002/psp.1910
   O'Toole P., 2005, VISIONS RES MUSIC ED, V6
   Palkki J., 2015, Choral Journal, V56, P24
   Partridge C, 2006, CULT RELIG, V7, P41, DOI 10.1080/01438300600625408
   Pearce E, 2017, PSYCHOL MUSIC, V45, P496, DOI 10.1177/0305735616667543
   Pink S., 2015, Doing sensory ethnography
   Robertson-Gillam K., 2018, MUSIC HLTH WELLBEING
   Robinson S, 2019, MEN MASC, V22, P850, DOI 10.1177/1097184X17730386
   Rolvsjord R, 2013, ART PSYCHOTHER, V40, P420, DOI 10.1016/j.aip.2013.05.015
   Ryan-Flood R, 2010, TRANSFORM THINK FEM, P1
   Saldanha A, 2005, SOC CULT GEOGR, V6, P707, DOI 10.1080/14649360500258328
   Segal L, 2006, SLOW MOTION: CHANGING MASCULINITIES, CHANGING MEN, 3RD EDITION, P1, DOI 10.1057/9780230582521
   Taylor Y., 2014, ECCLESIAL PRACTICES, P229
   Taylor Y, 2015, SOC CULT GEOGR, V16, P43, DOI 10.1080/14649365.2014.939708
   Thurnell-Read T, 2012, MEN MASC, V15, P249, DOI 10.1177/1097184X12448465
NR 50
TC 0
Z9 0
U1 1
U2 3
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1755-4586
EI 1878-0040
J9 EMOT SPACE SOC
JI Emot. Space Soc.
PD NOV
PY 2022
VL 45
AR 100925
DI 10.1016/j.emospa.2022.100925
EA NOV 2022
PG 7
WC Geography; Social Sciences, Interdisciplinary
WE Social Science Citation Index (SSCI)
SC Geography; Social Sciences - Other Topics
GA 8B6IK
UT WOS:000917026500001
OA Green Published
DA 2024-01-09
ER

PT J
AU Robinson, J
   Hatten, RS
AF Robinson, Jenefer
   Hatten, Robert S.
TI Emotions in Music
SO MUSIC THEORY SPECTRUM
LA English
DT Article
DE emotion in music; musical expressiveness; the musical "persona"; Bach;
   Prelude in El; Minor; Well-Tempered Clavier; Brahms; Piano Quartet in C
   Minor; Opus 60
AB In this essay we argue that musical expressiveness is not confined to "emotion characteristics in appearances," i.e., musical gestures which are experienced as resembling gestures or behaviors characteristic" of a person in a particular emotional state, such as vocal expressions of sadness or anger (sighing, wailing, shouting, etc.) and behaviors expressive of joy (skipping lightly), or sadness (moving heavily and slowly as in a funeral procession). We claim that sometimes music can appropriately be heard as containing a "persona," a fictional or virtual agent whose emotions are expressed in the music, and that this persona can be experienced as expressing more complex emotions, such as hopefulness or resignation, as well as blends of emotion, and emotions that develop and change over time. A complex piece of music may have a composed expressive trajectory or musical "plot," which dramatizes a psychological journey by a persona. Moreover, listeners may be invited not only to recognize the emotions expressed in such music but also to experience those emotions themselves, either actually or in imagination, by empathizing with the musical persona as he or she travels on a psychological journey through the music. Such experiences are typically reinforced by the arousal of actual physiological states and action tendencies in listeners. We illustrate our argument by means of analyses of the Prelude in El, Minor from Book I of Bach's Well-Tempered Clavier and the third movement of Brahms's Piano Quartet in C Minor, Opus 60. Finally, we admit that not all listeners will approach music in the way we suggest, but we argue that listening in the way we recommend can significantly enrich our musical experiences.
C1 [Robinson, Jenefer] Univ Cincinnati, Cincinnati, OH 45221 USA.
   [Hatten, Robert S.] Univ Texas Austin, Butler Sch Mus, Austin, TX 78712 USA.
C3 University System of Ohio; University of Cincinnati; University of Texas
   System; University of Texas Austin
RP Robinson, J (corresponding author), Univ Cincinnati, Cincinnati, OH 45221 USA.
CR [Anonymous], 1971, CONCEPT EXPRESSION S
   [Anonymous], NEW YORK TIMES 0419
   [Anonymous], MUSICAL MEANING
   [Anonymous], 1984, BRAHMS PRINCIPLE DEV
   [Anonymous], 2003, EMOTIONS REVEALED RE
   [Anonymous], MUSIC MEANING
   [Anonymous], 1997, MUSIC MEANING
   [Anonymous], 1992, Emotion and Social Behavior
   [Anonymous], SEM 2009 SEM TIM P A
   [Anonymous], 1990, Music, Art, and Metaphysics
   [Anonymous], 2002, Introduction to a philosophy of music
   [Anonymous], PHILOSOPHERS MUSIC E
   Budd M., 1995, Values of Art: Pictures, Poetry and Music
   Butler Mark, 2006, Unlocking the Groove: Rhythm, Meter, and Musical Design in Electronic Dance Music
   Cone E., 1968, MUSICAL FORM MUSICAL
   CONE Edward T., 1974, The Composer's Voice
   Damasio A.R., 1994, Descartes' Error: Emotion, Reason and the Human Brain
   DANTO A, 1964, J PHILOS, V61, P571, DOI 10.2307/2022937
   Darwin Charles, 1998, EXPRESSION EMOTION M
   Davies S., 2011, Empathy: Philosophical and psychological perspectives, P134, DOI [10.1093/acprof:oso/9780199539956.003.0010, DOI 10.1093/ACPROF:OSO/9780199539956.003.0010]
   Davies S., 2006, Contemporary debates in aesthetics and the philosophy of art, P179, DOI 10.1093/acprof:oso/9780199608775.003.0002
   Davies Stephen, 1997, EMOTION ARTS, P95
   Davies Stephen, 1994, MUSICA MEANING EXPRE
   Dutton D., 2009, The Art Instinct: Beauty, Pleasure, Human Evolution
   Fisk Charles, 2001, Returning Cycles: Contexts for the Interpretation of Schubert's Impromptus and Last Sonatas
   Frijda N., 1986, The emotions: Studies in emotion and social interaction
   Goldman A. I., 2006, Simulating Minds
   Gombrich Ernst, 1963, Meditations on a Hobby Horse and Other Essays on the Theory of Art
   Goodman Nelson., 1968, Language of Art: An Approach to a Theory of Symbols
   Griffiths P., 2009, The Cambridge handbook of situated cognition, P437, DOI DOI 10.1017/CBO9780511816826.023
   Gritten Anthony, 2006, MUSIC GESTURE, P45, DOI DOI 10.4324/9781315091006-4
   Hatten RS, 2010, MUSIC ANAL, V29, P83, DOI 10.1111/j.1468-2249.2011.00327.x
   Hatten Robert S., 2013, OXFORD HDB IN PRESS
   HATTEN Robert S., 1994, Musical Meaning in Beethoven: Markedness, Correlation, and Interpretation
   HATTEN Robert S., 2004, Interpreting Musical Gestures, Topics, and Tropes
   Hatten Robert S., 1997, SEMIOTICS WORLD SYNT, V2, P627
   HURON DAVID, 2006, SWEET ANTICIPATION M, P148, DOI DOI 10.7551/MITPRESS/6575.001.0001
   James W., 1884, Mind, V9, P188, DOI DOI 10.1093/MIND/OS-IX.34.188
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN., 2001, Music and Emotion, P309, DOI 10.1093/oso/9780192631886.003.0014
   Karl G, 1997, MUSIC THEOR SPECTRUM, V19, P13, DOI 10.1525/mts.1997.19.1.02a00020
   Karl Gregory, 2012, YET ABSOLUTE P UNPUB
   Karl Gregory, 1997, MUSIC MEANING, P154
   Kivy P., 2009, ANTITHETICAL ARTS AN, P29
   Kivy P., 1990, Music Alone: Philosophical Reflections on the Purely Musical Experience
   Kivy P., 1989, Sound Sentiment: An Essay on the Musical Emotions
   Klein M, 2004, MUSIC THEOR SPECTRUM, V26, P23, DOI 10.1525/mts.2004.26.1.23
   Laird James D., 2007, Feelings: The Perception of Self
   LARSON Steve, 2012, Musical Forces: Motion, Metaphor, and Meaning in Music
   Lerdahl Fred, 1983, A generative theory of tonal music
   Levinson J., 2006, CONT DEBATES AESTHET, P192
   Levitin Daniel, 2006, This is Your Brain on Music: The Science of a Human Obsession
   Matravers D, 2011, ROUTL PHILOS COMPAN, P212
   Meyer LB., 1956, Emotion and meaning in music
   MEYER Leonard B., 1989, Style and Music: Theory, History, and Ideology
   MEYER Leonard B., 1973, Explaining music: Essays and explorations
   Monahan Seth., 2011, 34 ANN M SOC MUS THE
   Monelle Raymond., 2006, MUSICAL TOPIC HUNT M
   NEWCOMB A, 1984, NINETEEN CENT MUSIC, V7, P233
   Nussbaum Charles O., 2007, MUSICAL REPRESENTATI
   Overy K, 2009, MUSIC PERCEPT, V26, P489, DOI 10.1525/MP.2009.26.5.489
   Patel A. D., 2008, Music, Language, and the Brain
   Prinz J.J., 2004, Gut Reactions: A Perceptual Theory of Emotion
   Ratner Leonard G., 1980, Classic Music: Expression, Form, and Style
   ROBINSON J, 1995, J PHILOS, V92, P53, DOI 10.2307/2940940
   Robinson J., 2010, OXFORD HDB PHILOS EM, P651
   Robinson J., 2005, Deeper than Reason: Emotion and its Role in Literature, Music, and Art
   Robinson Jenefer, 1997, MUSIC MEANING
   Robinson Jenefer, 2007, PHILOS MUSIC EXPERIE, P149
   Rosen Charles, 1972, The Classical Style: Haydn, Mozart, Beethoven
   Scherer K.R., 2001, APPRAISAL PROCESSES, P369
   Sloboda J.A., 2010, Handbook of music and emotion: Theory, research, applications, P73
   Smith Peter H., 2005, Expressive Forms in Brahms's Instrumental Music; Structure and Meaning in His Werther Quartet
   STRACK F, 1988, J PERS SOC PSYCHOL, V54, P768, DOI 10.1037/0022-3514.54.5.768
   Walton K., 1997, EMOTION ARTS, P37
   Walton K., 2008, MARVELOUS IMAGES VAL
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 77
TC 36
Z9 48
U1 2
U2 28
PU OXFORD UNIV PRESS INC
PI CARY
PA JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA
SN 0195-6167
EI 1533-8339
J9 MUSIC THEOR SPECTRUM
JI Music Theory Spectr.
PD FAL
PY 2012
VL 34
IS 2
BP 71
EP 106
DI 10.1525/mts.2012.34.2.71
PG 36
WC Music
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music
GA 070UQ
UT WOS:000313538500004
DA 2024-01-09
ER

PT J
AU Duan, Y
AF Duan, Ying
TI Construction of Vocal Timbre Evaluation System Based on Classification
   Algorithm
SO SCIENTIFIC PROGRAMMING
LA English
DT Article
ID VOICE; IDENTIFICATION
AB With the continuous development of communication technology, computer technology, and network technology, a large amount of information such as images, videos, and audios has grown exponentially, and people have started to be exposed to massive multimedia contents, which can easily and quickly access the increasingly rich music resources, so new technologies are urgently needed for their effective management, and automatic classification of audio signals has become the focus of engineering and academic attention. Currently, music retrieval can be achieved by selecting song titles and singer names, but as people's living standards continue to improve, the spiritual realm is also enriched. People want to be able to select music with different types of emotional expressions with their emotions. It mainly includes the basic principles of audio classification, the analysis and extraction of music emotion features, and the selection of the best classifier. Two classification algorithms, hybrid Gaussian model and AdaBoost, are used to classify music emotions, and the two classifiers are combined. In this paper, we propose the Discrete Harmonic Transform (DHT), a sparse transform based on harmonic frequencies. This paper derives and proves the formula of Discrete Harmonic Transform and further analyzes the harmonic structure of musical tone signal and the accuracy of harmonic structure. Since the timbre of musical instruments depends on the harmonic structure, and similar instruments have similar harmonic structures, the discrete harmonic transform coefficients can be defined as objective indicators corresponding to the timbre of musical instruments, and thus the concept of timbre expression spectrum is proposed, and a specific construction algorithm is given in this paper. In the application of musical instrument recognition, the 53-dimensional combined features of LPCC, MFCC, and timbre expression spectrum are selected, and a nonlinear support vector machine is used as the classifier. The classification recognition rate is improved by reducing the number of feature dimensions.
C1 [Duan, Ying] Wuhan Conservatory Mus, Wuhan 430060, Hubei, Peoples R China.
C3 Wuhan Conservatory of Music
RP Duan, Y (corresponding author), Wuhan Conservatory Mus, Wuhan 430060, Hubei, Peoples R China.
EM 10362@whcm.edu.cn
FU project of General Project of Science and Technology Research Plan of
   Hubei Education Department (Research on Virtual Technology Application
   in Performing Arts) [B2021200]; Provincial Teaching Team Project of
   Hubei Education Department; Key Discipline Construction Project of Wuhan
   Conservatory of Music (Exploration and Research on the Path of
   "Creation, Editing and Performance" of Original Musical) [XK2021Y02]
FX )is work was supported by the project of General Project of Science and
   Technology Research Plan of Hubei Education Department (Research on
   Virtual Technology Application in Performing Arts, No. B2021200),
   Provincial Teaching Team Project of Hubei Education Department (Jazz
   Teaching Team), and Key Discipline Construction Project of Wuhan
   Conservatory of Music (Exploration and Research on the Path of
   "Creation, Editing and Performance" of Original Musical, No. XK2021Y02).
CR Al-Dhief FT, 2021, IEEE ACCESS, V9, P77293, DOI 10.1109/ACCESS.2021.3082565
   Gómez-García JA, 2019, BIOMED SIGNAL PROCES, V51, P181, DOI 10.1016/j.bspc.2018.12.024
   Ivry A, 2019, IEEE J-STSP, V13, P254, DOI 10.1109/JSTSP.2019.2909472
   Jahangir R, 2020, IEEE ACCESS, V8, P32187, DOI 10.1109/ACCESS.2020.2973541
   Lataifeh M, 2020, NEUROCOMPUTING, V418, P162, DOI 10.1016/j.neucom.2020.07.099
   Lella KK, 2022, ALEX ENG J, V61, P1319, DOI 10.1016/j.aej.2021.06.024
   Li R, 2019, CHEMISTRYSELECT, V4, P9817, DOI 10.1002/slct.201902068
   Mahmoud SS, 2020, IEEE J BIOMED HEALTH, V24, P3191, DOI 10.1109/JBHI.2020.3011104
   Mouawad Pauline, 2021, SN Comput Sci, V2, P34, DOI 10.1007/s42979-020-00422-6
   Murthy YVS, 2018, EXPERT SYST APPL, V106, P77, DOI 10.1016/j.eswa.2018.04.005
   Nam J, 2019, IEEE SIGNAL PROC MAG, V36, P41, DOI 10.1109/MSP.2018.2874383
   Narendra NP, 2020, IEEE ACCESS, V8, P67745, DOI 10.1109/ACCESS.2020.2986171
   Oung QW, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0877-2
   Panda R, 2020, IEEE T AFFECT COMPUT, V11, P614, DOI 10.1109/TAFFC.2018.2820691
   Park J, 2019, IEEE T IND INFORM, V15, P582, DOI 10.1109/TII.2018.2861739
   Peng Sun, 2020, Journal of Physics: Conference Series, V1533, DOI 10.1088/1742-6596/1533/2/022015
   Sajal Md Sakibur Rahman, 2020, Brain Inform, V7, P12, DOI 10.1186/s40708-020-00113-1
   Sakar CO, 2019, APPL SOFT COMPUT, V74, P255, DOI 10.1016/j.asoc.2018.10.022
   Salih A., 2021, Journal Of Soft Computing And Data Mining, V2, P31, DOI DOI 10.30880/JSCDM.2021.02.01.004
   Tunc HC, 2020, MED BIOL ENG COMPUT, V58, P2757, DOI 10.1007/s11517-020-02250-5
   Wen WH, 2020, IEEE T AFFECT COMPUT, V11, P100, DOI 10.1109/TAFFC.2018.2792000
NR 21
TC 0
Z9 0
U1 1
U2 3
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1058-9244
EI 1875-919X
J9 SCI PROGRAMMING-NETH
JI Sci. Program.
PD JUN 6
PY 2022
VL 2022
AR 6893128
DI 10.1155/2022/6893128
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2G9CA
UT WOS:000813896800002
OA gold
DA 2024-01-09
ER

PT J
AU Manno, FAM
   Cruces, RR
   Lau, C
   Barrios, FA
AF Manno, Francis A. M.
   Cruces, Raul R.
   Lau, Condon
   Barrios, Fernando A.
TI Uncertain Emotion Discrimination Differences Between Musicians and
   Non-musicians Is Determined by Fine Structure Association: Hilbert
   Transform Psychophysics
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE emotion; psychophysics; modulation; fine structure; envelope; frequency;
   amplitude
ID TEMPORAL ENVELOPE; STRUCTURE CUES; FUNDAMENTAL-FREQUENCY; SPEECH
   RECOGNITION; DECISION-PROCESSES; VOCAL PITCH; IDENTIFICATION;
   PERCEPTION; EXPRESSION; EVOLUTION
AB Humans perceive musical sound as a complex phenomenon, which is known to induce an emotional response. The cues used to perceive emotion in music have not been unequivocally elucidated. Here, we sought to identify the attributes of sound that confer an emotion to music and determine if professional musicians have different musical emotion perception than non-musicians. The objective was to determine which sound cues are used to resolve emotional signals. Happy or sad classical music excerpts modified in fine structure or envelope conveying different degrees of emotional certainty were presented. Certainty was determined by identification of the emotional characteristic presented during a forced-choice discrimination task. Participants were categorized as good or poor performers (n = 32, age 21.16 +/- 2.59 SD) and in a separate group as musicians in the first or last year of music education at a conservatory (n = 32, age 21.97 +/- 2.42). We found that temporal fine structure information is essential for correct emotional identification. Non-musicians used less fine structure information to discriminate emotion in music compared with musicians. The present psychophysical experiments revealed what cues are used to resolve emotional signals and how they differ between non-musicians and musically educated individuals.
C1 [Manno, Francis A. M.] Univ Sydney, Fac Engn, Sch Biomed Engn, Sydney, NSW, Australia.
   [Manno, Francis A. M.; Lau, Condon] City Univ Hong Kong, Dept Phys, Hong Kong, Peoples R China.
   [Cruces, Raul R.; Barrios, Fernando A.] Univ Nacl Autonoma Mexico, Inst Neurobiol, Queretaro, Mexico.
C3 University of Sydney; City University of Hong Kong; Universidad Nacional
   Autonoma de Mexico
RP Manno, FAM (corresponding author), Univ Sydney, Fac Engn, Sch Biomed Engn, Sydney, NSW, Australia.; Manno, FAM; Lau, C (corresponding author), City Univ Hong Kong, Dept Phys, Hong Kong, Peoples R China.; Barrios, FA (corresponding author), Univ Nacl Autonoma Mexico, Inst Neurobiol, Queretaro, Mexico.
EM Francis.Manno@Sydney.edu.au; condon.lau@cityu.edu.hk; fbarrios@unam.mx
RI Rodríguez-Cruces, Raúl/AAG-1161-2020; Barrios, Fernando
   Alejandro/D-1591-2016; Manno, Francis/AAA-5174-2019
OI Rodríguez-Cruces, Raúl/0000-0002-2917-1212; Barrios, Fernando
   Alejandro/0000-0002-5699-4222; Manno, Francis/0000-0002-0486-213X
FU Consejo Nacional de Ciencia y Tecnologia (CONACyT) [CB255462]
FX We thank the Consejo Nacional de Ciencia y Tecnologia (CONACyT) for the
   funding received via the grant CB255462 to FB.
CR [Anonymous], IRE T CIRCUITS SYST, DOI 10.1109/tct.1956.1086333
   Apoux F, 2013, J ACOUST SOC AM, V134, P2205, DOI 10.1121/1.4816413
   Barrett LF, 1998, COGNITION EMOTION, V12, P579, DOI 10.1080/026999398379574
   Baskent D, 2016, J ACOUST SOC AM, V139, pEL51, DOI 10.1121/1.4942628
   Bhatara A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0156855
   Binder JR, 2004, NAT NEUROSCI, V7, P295, DOI 10.1038/nn1198
   Coffey EBJ, 2017, HEARING RES, V352, P49, DOI 10.1016/j.heares.2017.02.006
   Coutinho E, 2013, COGNITION EMOTION, V27, P658, DOI 10.1080/02699931.2012.732559
   Davidson SA, 2009, J ACOUST SOC AM, V126, P1889, DOI 10.1121/1.3203996
   DRULLMAN R, 1995, J ACOUST SOC AM, V97, P585, DOI 10.1121/1.413112
   Drullman R, 1996, J ACOUST SOC AM, V99, P2358, DOI 10.1121/1.415423
   DRULLMAN R, 1994, J ACOUST SOC AM, V95, P1053, DOI 10.1121/1.408467
   Eerola T, 2012, TOP COGN SCI, V4, P607, DOI 10.1111/j.1756-8765.2012.01188.x
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   Fairbanks G, 1940, J ACOUST SOC AM, V11, P457, DOI 10.1121/1.1916060
   Fairbanks G, 1938, SCIENCE, V88, P382, DOI 10.1126/science.88.2286.382
   Fischer AH, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0190712
   Fitch WT, 2006, COGNITION, V100, P173, DOI 10.1016/j.cognition.2005.11.009
   Fogerty D, 2011, J ACOUST SOC AM, V129, P977, DOI 10.1121/1.3531954
   FRICK RW, 1985, PSYCHOL BULL, V97, P412, DOI 10.1037/0033-2909.97.3.412
   Gabrielsson A, 2010, HDB MUSIC EMOTION TH
   Gingras B, 2014, Q J EXP PSYCHOL, V67, P1428, DOI 10.1080/17470218.2013.863954
   Gosselin N, 2007, NEUROPSYCHOLOGIA, V45, P236, DOI 10.1016/j.neuropsychologia.2006.07.012
   Gosselin N, 2011, CORTEX, V47, P1116, DOI 10.1016/j.cortex.2011.05.012
   GREEN DM, 1960, J ACOUST SOC AM, V32, P1189, DOI 10.1121/1.1907882
   Hodges D. A, 2010, HDB MUSIC EMOTION TH
   Hopyan T, 2016, CHILD NEUROPSYCHOL, V22, P366, DOI 10.1080/09297049.2014.992400
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Khalfa S, 2008, NEUROPSYCHOLOGIA, V46, P2485, DOI 10.1016/j.neuropsychologia.2008.04.009
   King FW., 2009, Hilbert Transforms, Vvol 1
   Koelsch S, 2014, NAT REV NEUROSCI, V15, P170, DOI 10.1038/nrn3666
   Kotz SA, 2018, TRENDS COGN SCI, V22, P896, DOI 10.1016/j.tics.2018.08.002
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   LeDoux JE, 2000, ANNU REV NEUROSCI, V23, P155, DOI 10.1146/annurev.neuro.23.1.155
   Leinonen L, 1997, J ACOUST SOC AM, V102, P1853, DOI 10.1121/1.420109
   Liang C, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00464
   LICKLIDER JCR, 1946, J ACOUST SOC AM, V18, P429, DOI 10.1121/1.1916383
   LIEBERMAN P, 1962, J ACOUST SOC AM, V34, P922, DOI 10.1121/1.1918222
   LIEBERMAN P, 1964, J ACOUST SOC AM, V36, P1048
   Madsen SMK, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12937-9
   Manno FAM, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00516
   Meister H, 2016, J ACOUST SOC AM, V139, P3116, DOI 10.1121/1.4953022
   Micheyl C, 2006, HEARING RES, V219, P36, DOI 10.1016/j.heares.2006.05.004
   Moon IJ, 2014, J NEUROSCI, V34, P12145, DOI 10.1523/JNEUROSCI.1025-14.2014
   Musacchia G, 2007, P NATL ACAD SCI USA, V104, P15894, DOI 10.1073/pnas.0701498104
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Parbery-Clark A, 2009, J NEUROSCI, V29, P14100, DOI 10.1523/JNEUROSCI.3256-09.2009
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   Peretz I, 2001, BRAIN, V124, P928, DOI 10.1093/brain/124.5.928
   Pfeifer R, 1988, COGNITIVE PERSPECTIV, P287, DOI [DOI 10.1007/978-94-009-2792-6_12, DOI 10.1007/978-94-009-2792-6_]
   Phan KL, 2002, NEUROIMAGE, V16, P331, DOI 10.1006/nimg.2002.1087
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Schubert E, 2004, MUSIC PERCEPT, V21, P561, DOI 10.1525/mp.2004.21.4.561
   Schubert E, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00837
   Seymour B, 2008, NEURON, V58, P662, DOI 10.1016/j.neuron.2008.05.020
   Shamma S, 2013, J ACOUST SOC AM, V133, P2818, DOI 10.1121/1.4795783
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Smith ZM, 2002, NATURE, V416, P87, DOI 10.1038/416087a
   Stanislaw H, 1999, BEHAV RES METH INS C, V31, P137, DOI 10.3758/BF03207704
   Strait DL, 2010, HEARING RES, V261, P22, DOI 10.1016/j.heares.2009.12.021
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Swaminathan J, 2014, J ACOUST SOC AM, V135, P2078, DOI 10.1121/1.4865920
   Swaminathan J, 2012, J NEUROSCI, V32, P1747, DOI 10.1523/JNEUROSCI.4493-11.2012
   SWETS JA, 1961, PSYCHOL REV, V68, P301, DOI 10.1037/h0040547
   SWETS JA, 1961, J ACOUST SOC AM, V33, P1586, DOI 10.1121/1.1908507
   SWETS JA, 1986, PSYCHOL BULL, V99, P100, DOI 10.1037/0033-2909.99.1.100
   SWETS JA, 1961, SCIENCE, V134, P168, DOI 10.1126/science.134.3473.168
   Vasuki PRM, 2016, HEARING RES, V342, P112, DOI 10.1016/j.heares.2016.10.008
   Verde MF, 2006, PERCEPT PSYCHOPHYS, V68, P643, DOI 10.3758/BF03208765
   Waaramaa T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00344
   Wildgruber D, 2005, NEUROIMAGE, V24, P1233, DOI 10.1016/j.neuroimage.2004.10.034
   WILLIAMS CE, 1972, J ACOUST SOC AM, V52, P1238, DOI 10.1121/1.1913238
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   Zeng FG, 2005, P NATL ACAD SCI USA, V102, P2293, DOI 10.1073/pnas.0406460102
   Zeng FG, 2004, J ACOUST SOC AM, V116, P1351, DOI 10.1121/1.1777938
NR 76
TC 2
Z9 2
U1 0
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD SEP 18
PY 2019
VL 13
AR 902
DI 10.3389/fnins.2019.00902
PG 13
WC Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Neurosciences & Neurology
GA IY5BE
UT WOS:000486405900001
PM 31619943
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Zang, L
AF Zang, Lu
TI Investigation on the Extraction Methods of Timbre Features in Vocal
   Singing Based on Machine Learning
SO COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE
LA English
DT Article
ID EMOTION RECOGNITION; MUSIC; NETWORK; MODEL
AB With the continuous development of digital technology, music, as an important form of media, and its digital audio technology is also constantly developing, forcing the traditional music industry to start the road of digital transformation. What kind of method can be used to automatically retrieve music information effectively and quickly in vocal singing has become one of the current research topics that has attracted much attention. Aiming at this problem, it is of great research significance for the field of timbre feature recognition. With the in-depth research on timbre feature recognition, the research on timbre feature extraction by machine learning in vocal singing has also been gradually carried out, and its performance advantages are of great significance to solve the problem of automatic retrieval of music information. This paper aims to study the application of feature extraction algorithm based on machine learning in timbre feature extraction in vocal singing. Through the analysis and research of machine learning and feature extraction methods, it can be applied to the construction of timbre feature extraction algorithms to solve the problem of automatic retrieval of music information. This paper analyzed vocal singing, machine learning, and feature extraction, experimentally analyzed the performance of the method, and used related theoretical formulas to explain. The results have showed that the method for timbre feature extraction in the vocal singing environment was more accurate than the traditional method, the difference between the two was 24.27%, and the proportion of satisfied users was increased by 33%. It can be seen that this method can meet the needs of users for timbre feature extraction in the use of music software, and the work efficiency and user satisfaction are greatly improved.
C1 [Zang, Lu] Cent South Univ, Sch Architecture & Art, Changsha 410083, Hunan, Peoples R China.
C3 Central South University
RP Zang, L (corresponding author), Cent South Univ, Sch Architecture & Art, Changsha 410083, Hunan, Peoples R China.
EM luzang@csu.edu.cn
RI Zang, Lu/JFK-0902-2023
CR Al-Khanak EN, 2021, CMC-COMPUT MATER CON, V67, P3265, DOI 10.32604/cmc.2021.015409
   Bai JJ, 2017, INT J COGN INFORM NA, V11, P80, DOI 10.4018/IJCINI.2017100105
   Birajdar GK, 2019, MULTIMED TOOLS APPL, V78, P15141, DOI 10.1007/s11042-018-6899-z
   Chin YH, 2017, IET SIGNAL PROCESS, V11, P884, DOI 10.1049/iet-spr.2016.0021
   Dong YZ, 2019, IEEE T MULTIMEDIA, V21, P3150, DOI 10.1109/TMM.2019.2918739
   Gong X., 2021, CHMUSIC TRADITIONAL
   Hakak S, 2021, FUTURE GENER COMP SY, V117, P47, DOI 10.1016/j.future.2020.11.022
   Hong T, 2020, IEEE WIREL COMMUN, V27, P96, DOI 10.1109/MWC.001.1900186
   Jain V., 2021, FUSION PRACTICE APPL, V4, P5, DOI [10.54216/fpa.040101, DOI 10.54216/FPA.040101]
   Jenke R, 2014, IEEE T AFFECT COMPUT, V5, P327, DOI 10.1109/TAFFC.2014.2339834
   김상혁, 2017, 전기학회논문지, V66, P1092
   Khan I, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030800
   Lee K., 2020, P 5 INT C INFORM COM
   McFee B, 2019, IEEE SIGNAL PROC MAG, V36, P128, DOI 10.1109/MSP.2018.2875349
   Minowa Y., 2018, Journal of the Japanese Forest Society, V100, P208, DOI 10.4005/jjfs.100.208
   Müller M, 2019, IEEE SIGNAL PROC MAG, V36, P52, DOI 10.1109/MSP.2018.2868887
   Navarro M., 2018, ORIENTAL J COMPUTER, V11, P75, DOI [10.13005/ojcst11.02.02, DOI 10.13005/OJCST11.02.02]
   Panella M, 2019, IEEE CONSUM ELECTR M, V8, P25, DOI 10.1109/MCE.2018.2868109
   Silva DF, 2019, IEEE T MULTIMEDIA, V21, P29, DOI 10.1109/TMM.2018.2849563
   Skoki A, 2019, PATTERN RECOGN LETT, V128, P340, DOI 10.1016/j.patrec.2019.09.024
   Wang XJ, 2021, IEEE T MULTIMEDIA, V23, P692, DOI 10.1109/TMM.2020.2986583
   Yao P, 2022, SCI PROGRAMMING-NETH, V2022, DOI 10.1155/2022/9735392
   Yuan WT, 2019, IEEE SIGNAL PROC LET, V26, P1481, DOI 10.1109/LSP.2019.2935867
   Zhang Q, 2018, ADV AEROSPACE SCI AP, V8, P19
   Zhao YT, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/2674684
   Zhu YJ, 2020, IEEE T NEUR SYS REH, V28, P409, DOI 10.1109/TNSRE.2019.2953971
NR 26
TC 0
Z9 0
U1 2
U2 5
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1687-5265
EI 1687-5273
J9 COMPUT INTEL NEUROSC
JI Comput. Intell. Neurosci.
PD SEP 17
PY 2022
VL 2022
AR 5074829
DI 10.1155/2022/5074829
PG 11
WC Mathematical & Computational Biology; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Mathematical & Computational Biology; Neurosciences & Neurology
GA 5C7OS
UT WOS:000864445800007
PM 36164425
OA gold, Green Published
DA 2024-01-09
ER

PT J
AU Harding, EE
   Gaudrain, E
   Hrycyk, IJ
   Harris, RL
   Tillmann, B
   Maat, B
   Free, RH
   Baskent, D
AF Harding, Eleanor E.
   Gaudrain, Etienne
   Hrycyk, Imke J.
   Harris, Robert L.
   Tillmann, Barbara
   Maat, Bert
   Free, Rolien H.
   Baskent, Deniz
TI Musical Emotion Categorization with Vocoders of Varying Temporal and
   Spectral Content
SO TRENDS IN HEARING
LA English
DT Article
DE music emotion perception; vocoders; arousal; valence; cochlear implants
ID VOCAL-TRACT LENGTH; COCHLEAR IMPLANT; ELECTRICAL-STIMULATION;
   INDIVIDUAL-DIFFERENCES; SPEECH RECOGNITION; PERCEPTION; HEARING;
   ENJOYMENT; NOISE; PITCH
AB While previous research investigating music emotion perception of cochlear implant (CI) users observed that temporal cues informing tempo largely convey emotional arousal (relaxing/stimulating), it remains unclear how other properties of the temporal content may contribute to the transmission of arousal features. Moreover, while detailed spectral information related to pitch and harmony in music - often not well perceived by CI users- reportedly conveys emotional valence (positive, negative), it remains unclear how the quality of spectral content contributes to valence perception. Therefore, the current study used vocoders to vary temporal and spectral content of music and tested music emotion categorization (joy, fear, serenity, sadness) in 23 normal-hearing participants. Vocoders were varied with two carriers (sinewave or noise; primarily modulating temporal information), and two filter orders (low or high; primarily modulating spectral information). Results indicated that emotion categorization was above-chance in vocoded excerpts but poorer than in a non-vocoded control condition. Among vocoded conditions, better temporal content (sinewave carriers) improved emotion categorization with a large effect while better spectral content (high filter order) improved it with a small effect. Arousal features were comparably transmitted in non-vocoded and vocoded conditions, indicating that lower temporal content successfully conveyed emotional arousal. Valence feature transmission steeply declined in vocoded conditions, revealing that valence perception was difficult for both lower and higher spectral content. The reliance on arousal information for emotion categorization of vocoded music suggests that efforts to refine temporal cues in the CI user signal may immediately benefit their music emotion perception.
C1 [Harding, Eleanor E.; Gaudrain, Etienne; Hrycyk, Imke J.; Harris, Robert L.; Maat, Bert; Free, Rolien H.; Baskent, Deniz] Univ Groningen, Univ Med Ctr Groningen, Dept Otorhinolaryngol Head & Neck Surg, Groningen, Netherlands.
   [Harding, Eleanor E.; Hrycyk, Imke J.; Maat, Bert; Free, Rolien H.; Baskent, Deniz] Univ Groningen, Grad Sch Med Sci, Res Sch Behav & Cognit Neurosci, Groningen, Netherlands.
   [Harding, Eleanor E.; Harris, Robert L.] Hanze Univ Appl Sci, Groningen, Netherlands.
   [Gaudrain, Etienne; Tillmann, Barbara] Univ Lyon 1, Univ St Etienne, Lyon Neurosci Res Ctr, CNRS UMR5292,Inserm U1028, Lyon, France.
   [Maat, Bert; Free, Rolien H.] Univ Groningen, Univ Med Ctr Groningen, Cochlear Implant Ctr Northern Netherlands, Groningen, Netherlands.
   [Harding, Eleanor E.] Univ Med Ctr Groningen, Dept Otorhinolarynol, Hanzepl 1, NL-9713 GZ Groningen, Netherlands.
C3 University of Groningen; University of Groningen; Centre National de la
   Recherche Scientifique (CNRS); Institut National de la Sante et de la
   Recherche Medicale (Inserm); Universite Claude Bernard Lyon 1;
   Universite Jean Monnet; CNRS - National Institute for Biology (INSB);
   University of Groningen; University of Groningen
RP Harding, EE (corresponding author), Univ Med Ctr Groningen, Dept Otorhinolarynol, Hanzepl 1, NL-9713 GZ Groningen, Netherlands.
EM e.e.harding@rug.nl
RI Hrycyk, Imke/HSD-8229-2023; Gaudrain, Etienne/C-6713-2013
OI Harding, Eleanor/0000-0002-3244-9625; Gaudrain,
   Etienne/0000-0003-0490-0295; Baskent, Deniz/0000-0002-6560-1451; Maat,
   Bert/0000-0001-9856-7010
CR Ambert-Dahan E, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00181
   [Anonymous], 2001, Music and Emotion, DOI DOI 10.1525/MP.2004.21.4.561
   Bakeman R, 2005, BEHAV RES METHODS, V37, P379, DOI 10.3758/BF03192707
   Baskent D., 2016, SCI FDN AUDIOLOGY PE
   Bates Douglas M., 2018, Lme4: Linear mixed-effects models using S4 classes, DOI DOI 10.18637/JSS.V067.I01
   Benard MR, 2014, J ACOUST SOC AM, V136, P1344, DOI 10.1121/1.4892756
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Berg R.E., 2004, PHYS SOUND, V3rd ed.
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Bigand E, 1996, PERCEPT PSYCHOPHYS, V58, P125, DOI 10.3758/BF03205482
   Bingabr M, 2008, HEARING RES, V241, P73, DOI 10.1016/j.heares.2008.04.012
   Blamey P, 2013, AUDIOL NEURO-OTOL, V18, P36, DOI 10.1159/000343189
   Caldwell Meredith, 2015, Cochlear Implants Int, V16 Suppl 3, pS114, DOI 10.1179/1467010015Z.000000000265
   Caldwell MT, 2017, LARYNGOSCOPE INVEST, V2, P119, DOI 10.1002/lio2.71
   Caldwell MT, 2016, OTOL NEUROTOL, V37, P229, DOI 10.1097/MAO.0000000000000960
   Carlyon RP, 1997, J ACOUST SOC AM, V102, P1097, DOI 10.1121/1.419861
   Clark G., 2004, SPEECH PROCESSING AU, P58, DOI [10.1007/0-387-21575-1_8, DOI 10.1007/0-387-21575-1_8]
   Cooper WB, 2008, EAR HEARING, V29, P618, DOI 10.1097/AUD.0b013e318174e787
   Crew JD, 2012, J ACOUST SOC AM, V132, pEL429, DOI 10.1121/1.4758770
   D'Onofrio KL, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00114
   Davis MH, 2005, J EXP PSYCHOL GEN, V134, P222, DOI 10.1037/0096-3445.134.2.222
   de Balthasar C, 2003, HEARING RES, V182, P77, DOI 10.1016/S0378-5955(03)00174-6
   de Leeuw JR, 2015, BEHAV RES METHODS, V47, P1, DOI 10.3758/s13428-014-0458-y
   El Fata F, 2009, AUDIOL NEURO-OTOL, V14, P14, DOI 10.1159/000206491
   FELDMAN LA, 1995, J PERS SOC PSYCHOL, V69, P153, DOI 10.1037/0022-3514.69.1.153
   Filipic S, 2010, PSYCHON B REV, V17, P335, DOI 10.3758/PBR.17.3.335
   Fox J., 2011, An R Companion to Applied Regression
   Friesen LM, 2001, J ACOUST SOC AM, V110, P1150, DOI 10.1121/1.1381538
   Fu QJ, 2005, JARO-J ASSOC RES OTO, V6, P19, DOI 10.1007/s10162-004-5024-3
   Fuller C, 2022, COCHLEAR IMPLANTS IN, V23, P1, DOI 10.1080/14670100.2021.1948716
   Fuller C, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01050
   Galvin JJ, 2007, EAR HEARING, V28, P302, DOI 10.1097/01.aud.0000261689.35445.20
   Garrido S, 2011, MUSIC PERCEPT, V28, P279, DOI 10.1525/MP.2011.28.3.279
   Gaudrain E, 2018, EAR HEARING, V39, P226, DOI 10.1097/AUD.0000000000000480
   Gaudrain E, 2015, J ACOUST SOC AM, V137, P1298, DOI 10.1121/1.4908235
   Gfeller K, 2000, J Am Acad Audiol, V11, P390
   Gfeller Kate E, 2006, Audiol Neurootol, V11 Suppl 1, P12, DOI 10.1159/000095608
   Giannantonio S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0136685
   Green DM., 1966, New York Wiley, V12, P475
   GREENWOOD DD, 1990, J ACOUST SOC AM, V87, P2592, DOI 10.1121/1.399052
   Grewe O, 2005, ANN NY ACAD SCI, V1060, P446, DOI 10.1196/annals.1360.041
   Hopyan T, 2011, Cochlear Implants Int, V12, P21, DOI 10.1179/146701010X12677899497399
   Hunter PG, 2011, J EXP CHILD PSYCHOL, V110, P80, DOI 10.1016/j.jecp.2011.04.001
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Koelsch S, 2006, HUM BRAIN MAPP, V27, P239, DOI 10.1002/hbm.20180
   Lassaletta L, 2008, ACTA OTORRINOLAR ESP, V59, P228, DOI 10.1016/S0001-6519(08)73300-4
   Lawrence M. A., 2016, PACKAGE EZ COMPUTER
   Lehne M., 2014, Art Aesthet Brain, P545
   Lenth R., 2021, R PACKAGE VERSION, V1, P2018
   Lévêque Y, 2018, NEUROPSYCHOLOGY, V32, P880, DOI 10.1037/neu0000461
   Liégeois-Chauvel C, 2014, CORTEX, V60, P82, DOI 10.1016/j.cortex.2014.06.002
   Loizou PC, 1998, IEEE SIGNAL PROC MAG, V15, P101, DOI 10.1109/79.708543
   Macherey O, 2014, CURR BIOL, V24, pR878, DOI 10.1016/j.cub.2014.06.053
   Macmillan N. A., 2004, DETECTION THEORY USE, DOI DOI 10.4324/9781410611147
   Mazaheryazdi M, 2018, IRAN J CHILD NEUROL, V12, P41
   McKenna VS, 2018, J ACOUST SOC AM, V144, P1643, DOI 10.1121/1.5055234
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Niedenthal PM, 2007, SCIENCE, V316, P1002, DOI 10.1126/science.1136930
   Nieminen S, 2012, MUSIC SCI, V16, P372, DOI 10.1177/1029864912450454
   Paquette S, 2018, HEARING RES, V370, P272, DOI 10.1016/j.heares.2018.08.009
   Paquette S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00509
   Pralus A, 2020, CORTEX, V130, P78, DOI 10.1016/j.cortex.2020.05.015
   Sachs ME, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00404
   Scherer KR, 2004, J NEW MUSIC RES, V33, P239, DOI 10.1080/0929821042000317822
   Schubert E, 2004, MUSIC PERCEPT, V21, P561, DOI 10.1525/mp.2004.21.4.561
   SHANNON RV, 1992, J ACOUST SOC AM, V91, P2156, DOI 10.1121/1.403807
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   SHANNON RV, 1983, HEARING RES, V12, P1, DOI 10.1016/0378-5955(83)90115-6
   Temperley D, 2013, J NEW MUSIC RES, V42, P187, DOI 10.1080/09298215.2013.788039
   Tramo MJ, 2001, ANN NY ACAD SCI, V930, P92, DOI 10.1111/j.1749-6632.2001.tb05727.x
   van Wieringen A, 1999, EAR HEARING, V20, P89, DOI 10.1097/00003446-199904000-00001
   Versfeld NJ, 2000, J ACOUST SOC AM, V107, P1671, DOI 10.1121/1.428451
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
NR 73
TC 0
Z9 0
U1 2
U2 2
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 2331-2165
J9 TRENDS HEAR
JI Trends Hear.
PY 2023
VL 27
AR 23312165221141142
DI 10.1177/23312165221141142
PG 19
WC Audiology & Speech-Language Pathology; Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Audiology & Speech-Language Pathology; Otorhinolaryngology
GA H9CN2
UT WOS:000998856200001
PM 36628512
OA gold, Green Published
DA 2024-01-09
ER

PT J
AU Park, M
   Gutyrchik, E
   Welker, L
   Carl, P
   Poeppel, E
   Zaytseva, Y
   Meindl, T
   Blautzik, J
   Reiser, M
   Bao, Y
AF Park, Mona
   Gutyrchik, Evgeny
   Welker, Lorenz
   Carl, Petra
   Poeppel, Ernst
   Zaytseva, Yuliya
   Meindl, Thomas
   Blautzik, Janusch
   Reiser, Maximilian
   Bao, Yan
TI Sadness is unique: neural processing of emotions in speech prosody in
   musicians and non-musicians
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE functional magnetic resonance imaging; language processing; prosody;
   basic emotions; musical training; temporal processing
ID POSTERIOR CINGULATE CORTEX; MUSICAL TRAINING SHAPES; BRAINS DEFAULT
   NETWORK; VOCAL EXPRESSIONS; SOCIAL COGNITION; QUANTITATIVE METAANALYSIS;
   FUNCTIONAL NEUROANATOMY; RETROSPLENIAL CORTICES; OPERA HYPOTHESIS;
   LANGUAGE
AB Musical training has been shown to have positive effects on several aspects of speech processing, however, the effects of musical training on the neural processing of speech prosody conveying distinct emotions are yet to be better understood. We used functional magnetic resonance imaging (fMRI) to investigate whether the neural responses to speech prosody conveying happiness, sadness, and fear differ between musicians and non-musicians. Differences in processing of emotional speech prosody between the two groups were only observed when sadness was expressed. Musicians showed increased activation in the middle frontal gyrus, the anterior medial prefrontal cortex, the posterior cingulate cortex and the retrosplenial cortex. Our results suggest an increased sensitivity of emotional processing in musicians with respect to sadness expressed in speech, possibly reflecting empathic processes.
C1 [Park, Mona; Gutyrchik, Evgeny; Carl, Petra; Poeppel, Ernst; Zaytseva, Yuliya; Bao, Yan] Univ Munich, Inst Med Psychol, D-80539 Munich, Germany.
   [Park, Mona; Gutyrchik, Evgeny; Welker, Lorenz; Carl, Petra; Poeppel, Ernst; Zaytseva, Yuliya; Bao, Yan] Univ Munich, Human Sci Ctr, Munich, Germany.
   [Park, Mona; Gutyrchik, Evgeny; Poeppel, Ernst; Zaytseva, Yuliya; Bao, Yan] Parmenides Ctr Art & Sci, Pullach, Germany.
   [Welker, Lorenz] Univ Munich, Inst Musicol, Munich, Germany.
   [Park, Mona; Gutyrchik, Evgeny; Carl, Petra; Poeppel, Ernst; Zaytseva, Yuliya; Bao, Yan] Peking Univ, Dept Psychol, Beijing 100871, Peoples R China.
   [Poeppel, Ernst; Bao, Yan] Peking Univ, Key Lab Machine Percept MoE, Beijing 100871, Peoples R China.
   [Poeppel, Ernst] Chinese Acad Sci, Inst Psychol, Beijing 100101, Peoples R China.
   [Zaytseva, Yuliya] Moscow Res Inst Psychiat, Moscow, Russia.
   [Zaytseva, Yuliya] Charles Univ Prague, Fac Med 3, Prague Psychiat Ctr, Prague, Czech Republic.
   [Meindl, Thomas; Blautzik, Janusch; Reiser, Maximilian] Univ Munich, Inst Clin Radiol, Munich, Germany.
C3 University of Munich; University of Munich; University of Munich; Peking
   University; Peking University; Chinese Academy of Sciences; Institute of
   Psychology, CAS; Charles University Prague; University of Munich
RP Bao, Y (corresponding author), Peking Univ, Dept Psychol, 5 Yiheyuan Rd, Beijing 100871, Peoples R China.
EM baoyan@pku.edu.cn
RI Gutyrchik, Evgeny/A-3812-2013
OI Gutyrchik, Evgeny/0000-0003-0550-2547; Zaytseva,
   Yuliya/0000-0002-6560-8127
FU Bavarian State Ministry of Sciences, Research and the Arts, Germany;
   Oberfrankenstiltung, Germany; Chinese Academy of Sciences (CAS, Visiting
   Professorships for Senior International Scientists) [2013T1S0029];
   National Natural Science Foundation of China [31371018, 91120004]
FX This study was supported by the Bavarian State Ministry of Sciences,
   Research and the Arts, Germany, the Oberfrankenstiltung, Germany, the
   Chinese Academy of Sciences (CAS, Visiting Professorships for Senior
   International Scientists, 2013T1S0029), and the National Natural Science
   Foundation of China (Projects 31371018 and 91120004).
CR Abrams DA, 2011, CEREB CORTEX, V21, P1507, DOI 10.1093/cercor/bhq198
   Amodio DM, 2006, NAT REV NEUROSCI, V7, P268, DOI 10.1038/nrn1884
   Andrews F. A., 1976, Social indicators of well-being: America's perception of life quality
   Andrews-Hanna JR, 2010, NEURON, V65, P550, DOI 10.1016/j.neuron.2010.02.005
   [Anonymous], 1988, BEAUTY BRAIN BIOLOGI
   Bach DR, 2008, NEUROIMAGE, V42, P919, DOI 10.1016/j.neuroimage.2008.05.034
   Bao Y, 2013, COGNITION, V129, P579, DOI 10.1016/j.cognition.2013.08.019
   Bao Y, 2012, NEUROSCI BIOBEHAV R, V36, P2143, DOI 10.1016/j.neubiorev.2012.06.008
   Barrett KC, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00713
   Beauregard M, 1998, NEUROREPORT, V9, P3253, DOI 10.1097/00001756-199810050-00022
   Belyk M, 2014, SOC COGN AFFECT NEUR, V9, P1395, DOI 10.1093/scan/nst124
   Besson M, 2007, RESTOR NEUROL NEUROS, V25, P399
   Besson M, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00094
   Bhatara A, 2011, J EXP PSYCHOL HUMAN, V37, P921, DOI 10.1037/a0021922
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Brown S, 2004, NEUROREPORT, V15, P2033, DOI 10.1097/00001756-200409150-00008
   Brück C, 2011, PHYS LIFE REV, V8, P383, DOI 10.1016/j.plrev.2011.10.002
   Buchanan TW, 2000, COGNITIVE BRAIN RES, V9, P227, DOI 10.1016/S0926-6410(99)00060-9
   Buckner RL, 2008, ANN NY ACAD SCI, V1124, P1, DOI 10.1196/annals.1440.011
   Burkhardt F, 2005, 9 EUR C SPEECH COMM, V5, P1517, DOI [10.21437/Interspeech.2005-446, DOI 10.21437/INTERSPEECH.2005-446]
   Bush G, 2000, TRENDS COGN SCI, V4, P215, DOI 10.1016/S1364-6613(00)01483-2
   Cato MA, 2004, J COGNITIVE NEUROSCI, V16, P167, DOI 10.1162/089892904322984481
   Chandrasekaran B, 2010, PSYCHOPHYSIOLOGY, V47, P236, DOI 10.1111/j.1469-8986.2009.00928.x
   Chartrand JP, 2008, BRAIN RES, V1220, P191, DOI 10.1016/j.brainres.2008.01.014
   Chartrand JP, 2006, NEUROSCI LETT, V405, P164, DOI 10.1016/j.neulet.2006.06.053
   Cieslik EC, 2013, CEREB CORTEX, V23, P2677, DOI 10.1093/cercor/bhs256
   Curtis ME, 2010, EMOTION, V10, P335, DOI 10.1037/a0017928
   Decety J, 2006, CURR DIR PSYCHOL SCI, V15, P54, DOI 10.1111/j.0963-7214.2006.00406.x
   Escoffier N, 2013, HUM BRAIN MAPP, V34, P1796, DOI 10.1002/hbm.22029
   Ethofer T, 2012, CEREB CORTEX, V22, P191, DOI 10.1093/cercor/bhr113
   Etkin A, 2011, TRENDS COGN SCI, V15, P85, DOI 10.1016/j.tics.2010.11.004
   Frühholz S, 2014, PROG NEUROBIOL, V123, P1, DOI 10.1016/j.pneurobio.2014.09.003
   Fruehholz S, 2013, NEUROSCI BIOBEHAV R, V37, P2847, DOI 10.1016/j.neubiorev.2013.10.007
   Frühholz S, 2013, NEUROSCI BIOBEHAV R, V37, P24, DOI 10.1016/j.neubiorev.2012.11.002
   Frühholz S, 2012, CEREB CORTEX, V22, P1107, DOI 10.1093/cercor/bhr184
   Gerry D, 2012, DEVELOPMENTAL SCI, V15, P398, DOI 10.1111/j.1467-7687.2012.01142.x
   Gooding LF, 2011, J MUSIC THER, V48, P440, DOI 10.1093/jmt/48.4.440
   Grandjean D., 2013, EVOLUTION EMOTIONAL, P211
   Harrison NA, 2007, EMOTION, V7, P724, DOI 10.1037/1528-3542.7.4.724
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hyde KL, 2009, J NEUROSCI, V29, P3019, DOI 10.1523/JNEUROSCI.5118-08.2009
   Jäncke L, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00123
   Johnstone T, 2006, SOC COGN AFFECT NEUR, V1, P242, DOI 10.1093/scan/nsl027
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Koelsch S, 2004, NAT NEUROSCI, V7, P302, DOI 10.1038/nn1197
   Koelsch S., 2013, MUSIC MED, V5, P204, DOI [DOI 10.1177/1943862113508588, 10.1177/1943862113508588]
   Kotz SA, 2013, HUM BRAIN MAPP, V34, P1971, DOI 10.1002/hbm.22041
   Kotz SA, 2011, LANG LINGUIST COMPAS, V5, P108, DOI 10.1111/j.1749-818x.2010.00267.x
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Leech R, 2014, BRAIN, V137, P12, DOI 10.1093/brain/awt162
   Leech R, 2012, J NEUROSCI, V32, P215, DOI 10.1523/JNEUROSCI.3689-11.2012
   Leitman DI, 2011, FRONT HUM NEUROSCI, V5, DOI [10.3389/fnhum.2011.00096, 10.3389/fnhum.2010.00019]
   Levitin DJ, 2003, NEUROIMAGE, V20, P2142, DOI 10.1016/j.neuroimage.2003.08.016
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Linden M, 1996, NERVENARZT, V67, P205
   Maddock RJ, 1999, TRENDS NEUROSCI, V22, P310, DOI 10.1016/S0166-2236(98)01374-5
   Maddock RJ, 2003, HUM BRAIN MAPP, V18, P30, DOI 10.1002/hbm.10075
   Maess B, 2001, NAT NEUROSCI, V4, P540, DOI 10.1038/87502
   Magne C, 2006, J COGNITIVE NEUROSCI, V18, P199, DOI 10.1162/089892906775783660
   Mars RB, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00189
   Mayberg HS, 1999, AM J PSYCHIAT, V156, P675
   Mitchell JP, 2005, J COGNITIVE NEUROSCI, V17, P1306, DOI 10.1162/0898929055002418
   Mitchell RLC, 2013, CORTEX, V49, P1722, DOI 10.1016/j.cortex.2012.07.010
   Mitchell RLC, 2003, NEUROPSYCHOLOGIA, V41, P1410, DOI 10.1016/S0028-3932(03)00017-4
   Moreno S, 2005, ANN NY ACAD SCI, V1060, P93, DOI 10.1196/annals.1360.054
   Musacchia G, 2007, P NATL ACAD SCI USA, V104, P15894, DOI 10.1073/pnas.0701498104
   NILSONNE A, 1985, MUSIC PERCEPT, V2, P507
   Nomura M, 2003, NEUROSCI LETT, V348, P113, DOI 10.1016/S0304-3940(03)00768-7
   Ochsner KN, 2004, J COGNITIVE NEUROSCI, V16, P1746, DOI 10.1162/0898929042947829
   Panksepp J, 2005, CONSCIOUS COGN, V14, P30, DOI 10.1016/j.concog.2004.10.004
   Park M, 2014, NEUROSCI LETT, V566, P120, DOI 10.1016/j.neulet.2014.02.041
   Park M, 2013, BRAIN RES, V1523, P68, DOI 10.1016/j.brainres.2013.05.042
   Patel AD, 2003, NAT NEUROSCI, V6, P674, DOI 10.1038/nn1082
   Patel AD, 2014, HEARING RES, V308, P98, DOI 10.1016/j.heares.2013.08.011
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Pöppel E, 2009, PHILOS T R SOC B, V364, P1887, DOI 10.1098/rstb.2009.0015
   Poppel, 2011, CULTURE NEURAL FRAME, P215, DOI DOI 10.1007/978-3-642-15423-2_14
   POPPEL E, 1989, LEONARDO, V22, P83, DOI 10.2307/1575145
   Poppel E., 2014, Subjective time: The philosophy, psychology, and neuroscience of temporality, P241
   Raichle ME, 2001, P NATL ACAD SCI USA, V98, P676, DOI 10.1073/pnas.98.2.676
   Schilbach L, 2008, CONSCIOUS COGN, V17, P457, DOI 10.1016/j.concog.2008.03.013
   Schilbach L, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030920
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   Schön D, 2004, PSYCHOPHYSIOLOGY, V41, P341, DOI 10.1111/1469-8986.00172.x
   Steinbeis N, 2009, CEREB CORTEX, V19, P619, DOI 10.1093/cercor/bhn110
   Strait D, 2011, MUSIC PERCEPT, V29, P133, DOI 10.1525/MP.2011.29.2.133
   Strait DL, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00113
   Strait DL, 2009, ANN NY ACAD SCI, V1169, P209, DOI 10.1111/j.1749-6632.2009.04864.x
   Strait DL, 2009, EUR J NEUROSCI, V29, P661, DOI 10.1111/j.1460-9568.2009.06617.x
   Su YH, 2012, PSYCHOL RES-PSYCH FO, V76, P373, DOI 10.1007/s00426-011-0346-3
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Thompson WF, 2012, P NATL ACAD SCI USA, V109, P19027, DOI 10.1073/pnas.1210344109
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Vann SD, 2009, NAT REV NEUROSCI, V10, P792, DOI 10.1038/nrn2733
   Vogt BA, 2005, PROG BRAIN RES, V150, P205, DOI 10.1016/S0079-6123(05)50015-3
   Wildgruber D, 2006, PROG BRAIN RES, V156, P249, DOI 10.1016/S0079-6123(06)56013-3
   Wildgruber D, 2005, NEUROIMAGE, V24, P1233, DOI 10.1016/j.neuroimage.2004.10.034
   Witteman J, 2012, NEUROPSYCHOLOGIA, V50, P2752, DOI 10.1016/j.neuropsychologia.2012.07.026
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   Zatorre RJ, 2011, AUDITORY CORTEX, P657, DOI 10.1007/978-1-4419-0074-6_31
   Zaytseva Y, 2014, BRAIN COGNITION, V87, P104, DOI 10.1016/j.bandc.2014.03.012
NR 101
TC 19
Z9 20
U1 0
U2 35
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA PO BOX 110, EPFL INNOVATION PARK, BUILDING I, LAUSANNE, 1015,
   SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD JAN 30
PY 2015
VL 8
AR 1049
DI 10.3389/fnhurn.2014.01049
PG 8
WC Neurosciences; Psychology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Neurosciences & Neurology; Psychology
GA CA0XX
UT WOS:000348637800001
PM 25688196
DA 2024-01-09
ER

PT J
AU Halbauer, I
   Klarmann, M
AF Halbauer, Ingo
   Klarmann, Martin
TI How voice retailers can predict customer mood and how they can use that
   information
SO INTERNATIONAL JOURNAL OF RESEARCH IN MARKETING
LA English
DT Article
DE Voice shopping; Mood; Mood prediction; Choice architecture
ID POSITIVE MOOD; STORE ATMOSPHERE; SOCIAL SIGNALS; SATISFACTION;
   INCREASES; BEHAVIOR; EMOTION; WEATHER; STATES
AB In two studies we investigate how voice shopping may provide access to meaningful data on customer mood and how retailers may use such data. In Study 1 we explores the use of a machine learning approach to predict customer mood based on customer commands in the voice shopping process. We compare it to a heuristic approach to customer mood prediction based on situational correlates of mood that that a smart speaker can access (weather, music choice, day of week, and daylight). In Study 2 we explore how a voice retailer could use the potential capability to predict customer mood. Our results provide evidence that a customer's good mood is associated with purchases of higher-priced premium brands. In addition, retailers can use mood prediction to adapt the presentation of product information to fit customer mood, thus helping customers optimize their decisions. In a sensitivity analysis, we examine what accuracy of mood prediction could enable retailers to use the explored effects. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Halbauer, Ingo] WOLFF & MULLER Holding GmbH & Co KG, Schwieberdinger Str 107, D-70435 Stuttgart, Germany.
   [Klarmann, Martin] Karlsruhe Inst Technol KIT, Inst Informat Syst & Mkt IISM, Zirkel 2,Bldg 20-21,Room 105, D-76131 Karlsruhe, Germany.
C3 Helmholtz Association; Karlsruhe Institute of Technology
RP Halbauer, I (corresponding author), WOLFF & MULLER Holding GmbH & Co KG, Schwieberdinger Str 107, D-70435 Stuttgart, Germany.
EM ingo.halbauer@web.de; martin.klarmann@kit.edu
FU DFG; Karlsruhe Institute of Technology [INST_12138411-1_FUGG]
FX Studies 2a and 2b described in this paper were conducted in the
   Karlsruhe Decision & Design Lab (KD2Lab) , which was funded by the DFG
   and the Karlsruhe Institute of Technology (INST_12138411-1_FUGG) . The
   authors thank Martin Moos-brugger and Verena Sauter for their invaluable
   help in running the lab experiments described in this paper.
CR [Anonymous], 2018, P 1 INT WORKSH GEN I
   [Anonymous], 2005, P INTERSPEECH
   [Anonymous], 2006, P LREC
   [Anonymous], 1972, THEORY OPTIMAL EXPT
   AWS transcribe, 2019, AWS TRANSCR AUT SPEE
   BATRA R, 1990, J CONSUM RES, V17, P203, DOI 10.1086/208550
   Beedie CJ, 2005, COGNITION EMOTION, V19, P847, DOI 10.1080/02699930541000057
   Beukeboom CJ, 2006, J EXP SOC PSYCHOL, V42, P553, DOI 10.1016/j.jesp.2005.09.005
   Bohnet I, 2016, MANAGE SCI, V62, P1225, DOI 10.1287/mnsc.2015.2186
   BOUCHER J, 1969, J VERB LEARN VERB BE, V8, P1, DOI 10.1016/S0022-5371(69)80002-2
   BROSGOLE L, 1995, INT J NEUROSCI, V82, P169, DOI 10.3109/00207459508999800
   Capgemini, 2018, CONV COMM WHY CONS A
   Chen L, 2007, MEDIA PSYCHOL, V9, P695, DOI 10.1080/15213260701283293
   Cooil B, 2007, J MARKETING, V71, P67, DOI 10.1509/jmkg.71.1.67
   Day M, 2019, AMAZON IS WORKING DE
   Devaraj S, 2002, INFORM SYST RES, V13, P316, DOI 10.1287/isre.13.3.316.77
   Di Muro F, 2012, J CONSUM RES, V39, P574, DOI 10.1086/664040
   DONOVAN RJ, 1994, J RETAILING, V70, P283, DOI 10.1016/0022-4359(94)90037-X
   Erdem T., 1998, Journal of Consumer Psychology, V7, P131, DOI DOI 10.1207/S15327663JCP0702_02
   Etkin J, 2018, J CONSUM RES, V45, P208, DOI 10.1093/jcr/ucx121
   Eyben F., 2013, P 21 ACM INT C MULT, P835, DOI 10.1145/2502081.2502224
   Faraji-Rad A, 2017, J CONSUM RES, V44, P1, DOI 10.1093/jcr/ucw073
   Fedorikhin A, 2010, J CONSUM RES, V37, P698, DOI 10.1086/655665
   Forgas JP, 2010, SYD SYM SOC PSYCHOL, P141
   Gabrielsson A, 2003, SER AFFECTIVE SCI, P503
   GARDNER MP, 1985, J CONSUM RES, V12, P281, DOI 10.1086/208516
   Gartenberg C, 2019, ALL NEW FEATURES COM
   Gatignon H., 2016, J MARKETING BEHAV, V1, P293
   GOLDEN LL, 1986, ADV CONSUM RES, V13, P53
   Gorn G., 1993, J CONSUM PSYCHOL, V2, P237, DOI DOI 10.1016/S1057-7408(08)80016-2
   Gosztolya G, 2013, INTERSPEECH, P220
   HILL RP, 1987, ADV CONSUM RES, V14, P408
   ISEN AM, 1988, J PERS SOC PSYCHOL, V55, P710, DOI 10.1037/0022-3514.55.5.710
   ISEN AM, 1972, J PERS SOC PSYCHOL, V21, P384, DOI 10.1037/h0032317
   Johnson EJ, 2012, MARKET LETT, V23, P487, DOI 10.1007/s11002-012-9186-1
   Kinsella B, 2019, Smart spreaker consumer adoption report
   Morse CR, 2015, COMMUN RES, V42, P87, DOI 10.1177/0093650212465432
   Murray KB, 2010, J RETAIL CONSUM SERV, V17, P512, DOI 10.1016/j.jretconser.2010.08.006
   PERSINGER MA, 1983, PERCEPT MOTOR SKILL, V57, P868, DOI 10.2466/pms.1983.57.3.868
   Qiu C, 2008, J CONSUM RES, V34, P657, DOI 10.1086/522096
   Roehm HA, 2005, J CONSUM RES, V32, P330, DOI 10.1086/432242
   Salton G., 1986, Introduction to Modern Information Retrieval
   Scherer KR, 2003, SER AFFECTIVE SCI, P433
   Schuller B, 2013, INTERSPEECH, P148
   So A, 2021, AMAZONS FITNESS TRAC
   Spies K, 1997, INT J RES MARK, V14, P1, DOI 10.1016/S0167-8116(96)00015-8
   Steinwart I., 2017, 170206899 ARXIV
   Stone AA, 2012, J POSIT PSYCHOL, V7, P306, DOI 10.1080/17439760.2012.691980
   Taddy M, 2019, Business Data Science: Combining Machine Learning and Economics to Optimize, Automate, and Accelerate Business Decisions
   Völckner F, 2008, J ACAD MARKET SCI, V36, P359, DOI 10.1007/s11747-007-0076-7
   Zwebner Y, 2014, J CONSUM PSYCHOL, V24, P251, DOI 10.1016/j.jcps.2013.11.003
NR 51
TC 4
Z9 4
U1 6
U2 32
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8116
EI 1873-8001
J9 INT J RES MARK
JI Int. J. Res. Mark.
PD MAR
PY 2022
VL 39
IS 1
BP 77
EP 95
DI 10.1016/j.ijresmar.2021.09.008
EA FEB 2022
PG 19
WC Business
WE Social Science Citation Index (SSCI)
SC Business & Economics
GA ZI2OZ
UT WOS:000761467400005
DA 2024-01-09
ER

PT J
AU Agres, KR
   Dash, A
   Chua, P
AF Agres, Kat R. R.
   Dash, Adyasha
   Chua, Phoebe
TI AffectMachine-Classical: a novel system for generating affective
   classical music
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE automatic music generation system; algorithmic composition; music
   MedTech; emotion regulation; listener validation study; affective
   computing
ID VOCAL EXPRESSION; EMOTION; PERCEPTION; IMPACT; MOOD
AB This work introduces a new music generation system, called AffectMachine-Classical, that is capable of generating affective Classic music in real-time. AffectMachine was designed to be incorporated into biofeedback systems (such as brain-computer-interfaces) to help users become aware of, and ultimately mediate, their own dynamic affective states. That is, this system was developed for music-based MedTech to support real-time emotion self-regulation in users. We provide an overview of the rule-based, probabilistic system architecture, describing the main aspects of the system and how they are novel. We then present the results of a listener study that was conducted to validate the ability of the system to reliably convey target emotions to listeners. The findings indicate that AffectMachine-Classical is very effective in communicating various levels of Arousal (R-2 = 0.96) to listeners, and is also quite convincing in terms of Valence (R-2 = 0.90). Future work will embed AffectMachine-Classical into biofeedback systems, to leverage the efficacy of the affective music for emotional wellbeing in listeners.
C1 [Agres, Kat R. R.; Dash, Adyasha] Natl Univ Singapore, Yong Siew Toh Conservatory Mus, Singapore, Singapore.
   [Agres, Kat R. R.] Natl Univ Singapore, Ctr Mus & Hlth, Singapore, Singapore.
   [Chua, Phoebe] Natl Univ Singapore, Augmented Human Lab, DISA, Singapore, Singapore.
C3 National University of Singapore; National University of Singapore;
   National University of Singapore
RP Agres, KR (corresponding author), Natl Univ Singapore, Yong Siew Toh Conservatory Mus, Singapore, Singapore.; Agres, KR (corresponding author), Natl Univ Singapore, Ctr Mus & Hlth, Singapore, Singapore.
EM katagres@nus.edu.sg
CR Agres KR., 2021, MUSIC SCI, V4, P1, DOI [10.1177/2059204321997709, DOI 10.1177/2059204321997709]
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Briot JP, 2020, NEURAL COMPUT APPL, V32, P981, DOI 10.1007/s00521-018-3813-6
   Carnovalini F, 2020, FRONT ARTIF INTELL, V3, DOI 10.3389/frai.2020.00014
   Cohrdes C, 2020, MUSIC SCI, V24, P21, DOI 10.1177/1029864918765613
   Costa M, 2004, MUSIC PERCEPT, V22, P1, DOI 10.1525/mp.2004.22.1.1
   Costa M., 2000, PSYCHOL MUSIC, V28, P4, DOI [10.1177/0305735600281002, DOI 10.1177/0305735600281002]
   Costa M, 2020, MUSIC PERCEPT, V37, P298, DOI 10.1525/MP.2020.37.4.298
   Dash A., 2023, ARXIV PREPRINT ARXIV
   Di Mauro M, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02168
   Dong H.-W., 2018, P AAAI C ART INT, DOI [10.1609/aaai.v32i1.11312, DOI 10.1609/AAAI.V32I1.11312]
   Ehrlich SK, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0213516
   Fancourt D., 2019, WHAT IS EVIDENCE ROL
   Ferreri L, 2019, P NATL ACAD SCI USA, V116, P3793, DOI 10.1073/pnas.1811878116
   Gabrielsson A, 2003, SER AFFECTIVE SCI, P503
   Gabrielsson A., 2001, INFLUENCE MUSICAL ST
   Gabrielsson A., 2010, HDB MUSIC EMOTION TH, P367, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0014
   Gungormusler A., 2015, AUD ENG SOC C 56 INT
   Herremans D, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3108242
   Hevner K, 1937, AM J PSYCHOL, V49, P621, DOI 10.2307/1416385
   Hu ZJ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1189, DOI 10.1145/3394171.3414070
   Huang QQ, 2022, Arxiv, DOI arXiv:2208.12415
   Huang Qingqing, 2023, arXiv
   Hubbard T.L, 1998, PSYCHOMUSICOLOGY J R, V17, P36, DOI DOI 10.1037/H0094060
   Huron D, 2001, MUSIC PERCEPT, V19, P1, DOI 10.1525/mp.2001.19.1.1
   Huron D., 2008, Sweet Anticipation: Music and the Psychology of Expectation
   Johnson-Laird PN, 2002, MUSIC PERCEPT, V19, P415, DOI 10.1525/mp.2002.19.3.415
   Juslin, 1997, PSYCHOMUSICOLOGY, V16, P77, DOI DOI 10.1037/H0094065
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2013, PSYCHOLOGY OF MUSIC, THIRD EDITION, P583, DOI 10.1016/B978-0-12-381460-9.00015-8
   Juslin PN, 2001, EMOTION, V1, P381, DOI 10.1037//1528-3542.1.4.381
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Koh EY, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23010382
   Krumhansl CL, 1997, CAN J EXP PSYCHOL, V51, P336, DOI 10.1037/1196-1961.51.4.336
   Leung SO, 2011, J SOC SERV RES, V37, P412, DOI 10.1080/01488376.2011.580697
   Lindström E, 2006, MUSIC SCI, V10, P85, DOI 10.1177/102986490601000105
   LIVINGSTONE SR, 2005, P 2 AUSTR C INT ENT, P105, DOI DOI 10.13140/RG.2.1.3608.7841/1
   Lonsdale AJ, 2011, BRIT J PSYCHOL, V102, P108, DOI 10.1348/000712610X506831
   MacDonald R., 2012, Music, health, and wellbeing, DOI 10.1093/acprof:oso/9780199586974.003.0010
   McPherson MJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0105144
   Ramirez R, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00354
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Saarikallio S, 2012, MUSIC PERCEPT, V30, P97, DOI 10.1525/MP.2012.30.1.97
   Salimpoor VN, 2015, TRENDS COGN SCI, V19, P86, DOI 10.1016/j.tics.2014.12.001
   Scherer K., 1977, MOTIV EMOTION, V1, P331, DOI [DOI 10.1007/BF00992539, 10.1007/bf00992539]
   Schlaug G., 2013, MUSIC HLTH WELLBEING, P12
   SCHMUCKLER MA, 1989, MUSIC PERCEPT, V7, P109
   Schubert E, 2004, MUSIC PERCEPT, V21, P561, DOI 10.1525/mp.2004.21.4.561
   Sloboda John A., 2005, Exploring the Musical Mind Cognition, Emotion, Ability, Function
   Solis G., 2009, Musical Improvisation: Art, Education, and Society
   Swaminathan S, 2015, EMOT REV, V7, P189, DOI 10.1177/1754073914558282
   THAYER RE, 1994, J PERS SOC PSYCHOL, V67, P910, DOI 10.1037/0022-3514.67.5.910
   Wallis I., 2011, P 8 INT SOUND MUSIC, P156
   Williams D, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/3059005
   Yang XY, 2018, MULTIMEDIA SYST, V24, P365, DOI 10.1007/s00530-017-0559-4
   Yang YH, 2008, IEEE T AUDIO SPEECH, V16, P448, DOI 10.1109/TASL.2007.911513
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 59
TC 0
Z9 0
U1 5
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD JUN 6
PY 2023
VL 14
AR 1158172
DI 10.3389/fpsyg.2023.1158172
PG 13
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA J3ZC4
UT WOS:001009018800001
PM 37346414
OA Green Published, gold, Green Submitted
DA 2024-01-09
ER

PT J
AU Jeremic, B
   Simonji-Cernak, R
   Markov, Z
   Pantic, J
AF Jeremic, Biljana
   Simonji-Cernak, Ruzenka
   Markov, Zagorka
   Pantic, Jelena
TI The Effects of Applying the Vocal Performance Teaching Method on the
   Social-Emotional Competencies (SEC) of Children in Early Education
SO CROATIAN JOURNAL OF EDUCATION-HRVATSKI CASOPIS ZA ODGOJ I OBRAZOVANJE
LA English
DT Article
DE emotions; singing; teacher as a performer; teaching of Music Education
ID PITCH-MATCHING ACCURACY; MUSIC LESSONS; IQ; MEMORY
AB The authors of this study investigate the effects of applying the vocal performance teaching method on the social-emotional competencies (SEC) of second-grade pupils in elementary education. The study included a total of 89 pupils from Sombor and Kikinda, Serbia. The method of experimenting with parallel groups using initial and final tests was applied. A scale for the assessment of SEC and two-way mixed ANOVA were used to process the data. The experimental group (n=44) was subjected to the teaching method of learning songs by ear carried out by the music teacher, while the control group (n=45) learned the songs by ear based on the traditional model carried out by the class teacher for a period of one school year. The results showed significant differences in the level of SEC of students in the experimental group. By increasing the capacity for empathy, expression of pleasant emotions, better treatment of marginalized groups, collaboration with other students, the experimental teaching method has also encouraged the direction of the teaching process towards the goals, outcomes and effects, and not towards the adoption of ready-made knowledge.
C1 [Jeremic, Biljana; Simonji-Cernak, Ruzenka; Pantic, Jelena] Fac Educ Sombor, Podgoricka 4, Sombor 25000, Serbia.
   [Markov, Zagorka] Preschool Teacher Training Coll Appl Studies Kiki, Kikinda 23300, Serbia.
RP Jeremic, B (corresponding author), Fac Educ Sombor, Podgoricka 4, Sombor 25000, Serbia.
EM mrbiljana@gmail.com; cernak@stcable.rs; zaga60@beotel.net;
   avalon_yu@yahoo.com
RI Jeremic, Biljana S./R-4255-2019
OI Jeremic, Biljana/0000-0002-7893-5637
CR Alt Michael, 1968, DIDAKTIK DER MUSIK
   [Anonymous], 2005, Music Education Research
   [Anonymous], 1997, CREATIVE EXPRESSION
   [Anonymous], 2009, MUSIC WORKS CONTRIBU
   Aronson A. E., 1990, Clinical Voice Disorders, An Interdisciplinary Approach
   BARNASON S, 1995, HEART LUNG, V24, P124, DOI 10.1016/S0147-9563(05)80007-X
   Bjorn V., 2008, THESIS
   Bunch M, 1997, DYNAMICS SINGING VOI
   Callaghan W. J., 2000, VISUAL FEEDBACK TEAC
   Chan AS, 1998, NATURE, V396, P128, DOI 10.1038/24075
   Cohen AJ, 2009, ANN NY ACAD SCI, V1169, P112, DOI 10.1111/j.1749-6632.2009.04771.x
   Eerola PS, 2014, MUSIC EDUC RES, V16, P88, DOI 10.1080/14613808.2013.829428
   Elias M. J., 1997, Promoting social and emotional learning: guidelines for educators
   Gerling C. C., 2008, 28 INT SOC MUS ED WO
   Gratton M., 1992, MASTERS ABSTRACTS IN, V30
   GREEN GA, 1990, J RES MUSIC EDUC, V38, P225, DOI 10.2307/3345186
   GUZZETTA CE, 1989, HEART LUNG, V18, P609
   Hanser S., 2010, HDB MUSIC EMOTION TH, P49
   HANSER SB, 1994, J GERONTOL, V49, pP265, DOI 10.1093/geronj/49.6.P265
   Ho YC, 2003, NEUROPSYCHOLOGY, V17, P439, DOI 10.1037/0894-4105.17.3.439
   Jeremic B., 2012, TEMATSKI ZBORNIK NAU, P211
   Jeremic B., 2012, NASTAVA VASPITANJE, V2, P333
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Kostovic S., 2011, PEDAGOGIJA, V66, P365
   Lau W. C. M., 2005, REDESIGNING PEDAGOGY
   Mayer JD, 2000, EDUC PSYCHOL REV, V12, P163, DOI 10.1023/A:1009093231445
   Montgomery T., 1988, B COUNCIL RES MUSIC, P77
   Munro M., 2004, S AFRICAN J HIGHER E, V18, P288
   Nesic V., 2003, MUZIKA COVEK DRUSTVO
   Pantic J, 2009, NORMA, V14, P77
   Punkanen M, 2011, J AFFECT DISORDERS, V130, P118, DOI 10.1016/j.jad.2010.10.034
   Radulovic R., 2003, ENGRAMI, V25, P59
   RAUSCHER FH, 2002, IMPROVING ACAD ACHIE, P269
   Sakac M., 2012, NASTAVA VASPITANJE, V61, P221
   Schellenberg EG, 2006, J EDUC PSYCHOL, V98, P457, DOI 10.1037/0022-0663.98.2.457
   Schellenberg EG, 2012, EMOTION, V12, P887, DOI 10.1037/a0027971
   Schellenberg EG, 2011, MUSIC PERCEPT, V29, P185, DOI 10.1525/MP.2011.29.2.185
   Schellenberg EG, 2004, PSYCHOL SCI, V15, P511, DOI 10.1111/j.0956-7976.2004.00711.x
   SEEFELDT C, 1998, EARLY CHILDHOOD ED I
   Sims W. L., 1982, PSYCHOL MUSIC, P104
   SMALL AR, 1983, J RES MUSIC EDUC, V31, P227, DOI 10.2307/3345175
   Spodek B., 1984, MAINSTREAMING YOUNG
   Stankovic E., 2010, 6 K MUZ HUD ODB SLOV, P7
   Stengel I., 2000, VOICE SELF HDB PERSO
   Stosic A., 2008, PEDAGOGIJA, V63, P62
   Suzic N., 2005, PEDAGOGIJA 21 VIJEK
   Suzic N., 2004, PEDAGOSKA STVARNOST, V3-4, P173
   Timmers R, 2007, MUSIC SCI, V11, P237, DOI 10.1177/102986490701100205
   Welch G.F., 2005, MUSICAL COMMUNICATIO, P239, DOI DOI 10.1093/ACPROF:OSO/9780198529361.001.0001
   YARBROUGH C, 1992, J RES MUSIC EDUC, V40, P30, DOI 10.2307/3345772
   Zins J. E., 2001, CEIC REV, V10, P1
NR 51
TC 4
Z9 5
U1 1
U2 13
PU FAC TEACHER EDUCATION
PI ZAGREB
PA UNIV ZAGREB, SAVSKA CESTA 77, ZAGREB, 00000, CROATIA
SN 1848-5189
EI 1848-5197
J9 CROAT J EDUC
JI Croat. J. Educ.
PY 2015
VL 17
SI 3
BP 151
EP 185
DI 10.15516/cje.v17i0.1125
PG 35
WC Education & Educational Research
WE Social Science Citation Index (SSCI)
SC Education & Educational Research
GA DY2JM
UT WOS:000384918900007
DA 2024-01-09
ER

PT J
AU Filippa, M
   Monaci, MG
   Young, S
   Grandjean, D
   Nuti, G
   Nadel, J
AF Filippa, Manuela
   Monaci, Maria Grazia
   Young, Susan
   Grandjean, Didier
   Nuti, Gianni
   Nadel, Jacqueline
TI Shall We Play the Same? Pedagogical Perspectives on Infants' and
   Children's Imitation of Musical Gestures
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE imitation; gesture; action-perception coupling; children; music; sound
   exploration
ID EXPRESSIONS; SYNCHRONY; MOVEMENT; EMOTIONS; MOTOR
AB Imitation, both gestural and vocal, has been acknowledged to be at the origin of human communication (Donald, 1991). Music is often considered to be the first means of communication of emotion via both vocal and gestural synchronization (Malloch, 1999;Malloch and Trevarthen, 2009). Instrumental music is part of the human heritage for more than 35,000 years before our era (Aime et al., 2020). However, very little is known about the acquisition of gestures that produce sounds (i.e., musical gestures) and their role in the development of music and musicality. In the present paper, we propose that studying early synchronous imitation of musical gestures is essential both for investigating the development of the early action-perception system and for outlining early music interventions during infancy. We designed double musical objects which can be used in preschool music education for prompting synchronic imitation of musical gestures between adult and child, and between dyads of infants. We conclude by proposing a novel pedagogical perspective in music education for the early years which links the privileged orientation of infants and children towards sound discoveries with the development of perception-action coupling via imitation of musical gestures.
C1 [Filippa, Manuela; Grandjean, Didier] Univ Geneva, Swiss Ctr Affect Sci, Dept Psychol & Educ Sci, Neurosci Emot & Affect Dynam Lab, Geneva, Switzerland.
   [Filippa, Manuela] Univ Geneva, Dept Paediat Gynaecol & Obstet, Div Dev & Growth, Geneva, Switzerland.
   [Filippa, Manuela; Monaci, Maria Grazia; Nuti, Gianni] Univ Valle Aosta, Dept Social Sci, Aosta, Italy.
   [Young, Susan] Univ Roehampton London, London, England.
   [Nadel, Jacqueline] Sorbonne Univ, CNRS UMR 7225, Paris, France.
C3 University of Geneva; University of Geneva; Universita Della Valle
   D'aosta; Centre National de la Recherche Scientifique (CNRS); CNRS -
   National Institute for Biology (INSB); Sorbonne Universite
RP Filippa, M (corresponding author), Univ Geneva, Swiss Ctr Affect Sci, Dept Psychol & Educ Sci, Neurosci Emot & Affect Dynam Lab, Geneva, Switzerland.; Filippa, M (corresponding author), Univ Geneva, Dept Paediat Gynaecol & Obstet, Div Dev & Growth, Geneva, Switzerland.; Filippa, M (corresponding author), Univ Valle Aosta, Dept Social Sci, Aosta, Italy.
EM manuela.filippa@gmail.com
RI Monaci, Maria Grazia/AAW-1440-2020; FILIPPA, MANUELA/ABB-8975-2021;
   Filippa, Manuela/B-5493-2018
OI Filippa, Manuela/0000-0002-1310-8008
CR Addessi AR, 2011, LECT NOTES COMPUT SC, V6964, P15, DOI 10.1007/978-3-642-23985-4_3
   Aimé C, 2020, ENFANCE, P41
   Ambrosini E, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0067916
   [Anonymous], 2010, Musical gestures: Sound, movement and meaning
   [Anonymous], 2002, Musical identities
   [Anonymous], 2013, PLAY DREAMS IMITATIO
   [Anonymous], P INT C MUS PERC COG
   [Anonymous], 1957, Philosophy in a New Key: A Study in the Symbolism of Reason, Rite, and Art
   [Anonymous], DETERMINANTS BEHAV D
   Bänziger T, 2009, EMOTION, V9, P691, DOI 10.1037/a0017088
   Benenzon RO, 2007, NORD J MUSIC THER, V16, P148, DOI 10.1080/08098130709478185
   Buccino G, 2004, NEURON, V42, P323, DOI 10.1016/S0896-6273(04)00181-3
   Cirelli LK, 2014, DEVELOPMENTAL SCI, V17, P1003, DOI 10.1111/desc.12193
   Cross I., 2008, PREHISTORY LANGUAGE, P113, DOI DOI 10.1093/ACPROF:OSO/9780199545872.003.0005
   Delalande F., 2015, NASCITA MUSICA ESPLO
   Delaveau P, 2015, BRAIN, V138, DOI 10.1093/brain/awv060
   Dissanayake E., 2006, Music and Manipulation: On the Social Uses and Social Control of Music, P31
   Donald Merlin, 1991, ORIGINS MODERN MIND
   Dumas G, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0012166
   FIELD TM, 1982, SCIENCE, V218, P179, DOI 10.1126/science.7123230
   Filippa M, 2020, ENFANCE, P131
   Filippa M., 2015, NAISSANCE MUSIQUE EX
   Fitch WT, 2019, SCIENCE, V366, P944, DOI 10.1126/science.aay2214
   FLOHR JW, 1979, J RES MUSIC EDUC, V27, P143, DOI 10.2307/3344965
   Fogel A., 1993, NEW PERSPECTIVES EAR, P9, DOI DOI 10.4324/9781315111322-3
   Frühholz S, 2016, NEUROSCI BIOBEHAV R, V68, P96, DOI 10.1016/j.neubiorev.2016.05.002
   Gerson SA, 2015, J COGNITIVE NEUROSCI, V27, P1207, DOI 10.1162/jocn_a_00774
   Hove MJ, 2009, SOC COGNITION, V27, P949, DOI 10.1521/soco.2009.27.6.949
   Imberty M., 2003, CIRCUIT MUSIQUES CON, V13, P93
   Jones SS, 2009, PHILOS T R SOC B, V364, P2325, DOI 10.1098/rstb.2009.0045
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Kirschner S, 2010, EVOL HUM BEHAV, V31, P354, DOI 10.1016/j.evolhumbehav.2010.04.004
   Kokal I, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027272
   Kugiumutzakis G., 1998, INTERSUBJECTIVE COMM, P63
   Kugiumutzakis G., 2017, NEW PERSPECTIVES EAR, P23, DOI DOI 10.4324/9781315111322-4
   Kugiumutzakis G., 2015, INT ENCY SOCIAL BEHA, P481, DOI [10.1016/B978-0-08-097086-8.23160-7, DOI 10.1016/B978-0-08-097086-8.23160-7]
   Kuhl PK, 1996, J ACOUST SOC AM, V100, P2425, DOI 10.1121/1.417951
   Labbé C, 2014, MUSIC PERCEPT, V32, P170, DOI 10.1525/MP.2014.32.2.170
   Malloch S., 1999, Musicae Scientiae, P29, DOI [10.1177/10298649000030-104, DOI 10.1177/10298649000030S104]
   Malloch S., 2009, COMMUNICATIVE MUSICA
   Maratos O., 1998, DEV SENSORY MOTOR CO, P145
   MELTZOFF AN, 1983, CHILD DEV, V54, P702, DOI 10.2307/1130058
   Meltzoff AN, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12609
   Murray L., 1985, SOCIAL PERCEPTION IN, P177
   NADEL J, 1993, NEW PERSPECTIVES EAR, P139
   Nadel J., 2014, IMITATION BOOSTS DEV
   Nadel J., 2002, The imitative mind: Development, evolution, and brain bases, P42, DOI DOI 10.1017/CBO9780511489969
   Nadel J, 1999, DEVELOPMENTAL SCI, V2, P164, DOI 10.1111/1467-7687.00065
   NADELBRULFERT J, 1982, INT J BEHAV DEV, V5, P95, DOI 10.1177/016502548200500105
   Nagy E, 2005, PEDIATR RES, V58, P749, DOI 10.1203/01.PDR.0000180570.28111.D9
   Nettl B, 2000, ORIGINS OF MUSIC, P463
   Nuti G., 2016, NIDO SUONI
   Papousek M., 1989, FIRST LANG, V9, P137, DOI DOI 10.1177/014272378900900603
   Repp BH, 2013, PSYCHON B REV, V20, P403, DOI 10.3758/s13423-012-0371-2
   Schiavio A, 2016, MUSIC PERCEPT, V34, P21, DOI 10.1525/MP.2016.34.1.21
   Sievers B, 2013, P NATL ACAD SCI USA, V110, P70, DOI 10.1073/pnas.1209023110
   Simpson EA, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0289
   Soussignan R, 2011, DEVELOPMENTAL SCI, V14, P385, DOI 10.1111/j.1467-7687.2010.00984.x
   Tognoli E, 2007, P NATL ACAD SCI USA, V104, P8190, DOI 10.1073/pnas.0611453104
   Tomic ST, 2008, J ACOUST SOC AM, V124, P4024, DOI 10.1121/1.3006382
   Trehub S, 2000, ORIGINS OF MUSIC, P427
   TREHUB SE, 1993, INFANT BEHAV DEV, V16, P285, DOI 10.1016/0163-6383(93)80036-8
   Uzgiris I. C., 1999, Imitation in infancy, P186
   Varela FJ, 2016, EMBODIED MIND: COGNITIVE SCIENCE AND HUMAN EXPERIENCE, P1
   Wiltermuth SS, 2009, PSYCHOL SCI, V20, P1, DOI 10.1111/j.1467-9280.2008.02253.x
   Zentner M, 2010, P NATL ACAD SCI USA, V107, P5768, DOI 10.1073/pnas.1000121107
NR 66
TC 0
Z9 0
U1 2
U2 24
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD JUN 3
PY 2020
VL 11
AR 1087
DI 10.3389/fpsyg.2020.01087
PG 5
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA MC2JW
UT WOS:000543121000001
PM 32581943
OA gold, Green Published
DA 2024-01-09
ER

PT J
AU Xiao, XY
   Tan, JY
   Liu, XL
   Zheng, MP
AF Xiao, Xinyao
   Tan, Junying
   Liu, Xiaolin
   Zheng, Maoping
TI The dual effect of background music on creativity: perspectives of music
   preference and cognitive interference
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE background music; creativity; dual effect; emotional valence; cognitive
   interference; music preference
ID SAD MUSIC; EMOTIONAL RESPONSES; POSITIVE EMOTIONS; TEST-PERFORMANCE;
   BUILD THEORY; MOOD; EXPERIENCE; PERSONALITY; BROADEN; AROUSAL
AB Music, an influential environmental factor, significantly shapes cognitive processing and everyday experiences, thus rendering its effects on creativity a dynamic topic within the field of cognitive science. However, debates continue about whether music bolsters, obstructs, or exerts a dual influence on individual creativity. Among the points of contention is the impact of contrasting musical emotions-both positive and negative-on creative tasks. In this study, we focused on traditional Chinese music, drawn from a culture known for its 'preference for sadness,' as our selected emotional stimulus and background music. This choice, underrepresented in previous research, was based on its uniqueness. We examined the effects of differing music genres (including vocal and instrumental), each characterized by a distinct emotional valence (positive or negative), on performance in the Alternative Uses Task (AUT). To conduct this study, we utilized an affective arousal paradigm, with a quiet background serving as a neutral control setting. A total of 114 participants were randomly assigned to three distinct groups after completing a music preference questionnaire: instrumental, vocal, and silent. Our findings showed that when compared to a quiet environment, both instrumental and vocal music as background stimuli significantly affected AUT performance. Notably, music with a negative emotional charge bolstered individual originality in creative performance. These results lend support to the dual role of background music in creativity, with instrumental music appearing to enhance creativity through factors such as emotional arousal, cognitive interference, music preference, and psychological restoration. This study challenges conventional understanding that only positive background music boosts creativity and provides empirical validation for the two-path model (positive and negative) of emotional influence on creativity.
C1 [Xiao, Xinyao; Liu, Xiaolin; Zheng, Maoping] China Inst Mus Mental Hlth, Chongqing, Peoples R China.
   [Xiao, Xinyao; Zheng, Maoping] Southwest Univ, Sch Mus, Chongqing, Peoples R China.
   [Tan, Junying] Guizhou Univ Finance & Econ, Guiyang, Peoples R China.
   [Liu, Xiaolin] Southwest Univ, Sch Psychol, Chongqing, Peoples R China.
C3 Southwest University - China; Guizhou University of Finance & Economics;
   Southwest University - China
RP Zheng, MP (corresponding author), China Inst Mus Mental Hlth, Chongqing, Peoples R China.; Zheng, MP (corresponding author), Southwest Univ, Sch Mus, Chongqing, Peoples R China.
EM zhengswu@126.com
FU This study was supported by the Humanities and Social Sciences Youth
   Fund of the Ministry of Education of China (22YJC880066) and the Basic
   Research Business Fee Research Project of Central Universities
   (SWU2000147). [22YJC880066]; Humanities and Social Sciences Youth Fund
   of the Ministry of Education of China [SWU2000147]; Basic Research
   Business Fee Research Project of Central Universities
FX We would like to thank Jiang Yihe, Shu Yanyan, and Bai Shu for their
   insights and feedback during the development of this study. Parts of
   this study were presented at the Chinese Psychological Society's special
   committee on music psychology.r This study was supported by the
   Humanities and Social Sciences Youth Fund of the Ministry of Education
   of China (22YJC880066) and the Basic Research Business Fee Research
   Project of Central Universities (SWU2000147).
CR Abele-Brehm A., 1992, Polish Psychol Bull, V23, P187
   Ali SO., 2006, Psychology of Music, V34, P511, DOI DOI 10.1177/0305735606067168
   Alley TR, 2008, CURR PSYCHOL, V27, P277, DOI 10.1007/s12144-008-9040-z
   Andonova V, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1176697
   Basch R., 1996, Secrets of the super net searchers: The reflections, revelations, and hard-won wisdom of 35 of the world's top internet researchers
   Bateson P, 2013, PLAY, PLAYFULNESS, CREATIVITY AND INNOVATION, P1, DOI 10.1017/CBO9781139057691
   Beaman CP, 2007, APPL COGNITIVE PSYCH, V21, P1077, DOI 10.1002/acp.1315
   Benedek M, 2014, NEUROPSYCHOLOGIA, V56, P393, DOI 10.1016/j.neuropsychologia.2014.02.010
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Boer D, 2011, PERS SOC PSYCHOL B, V37, P1159, DOI 10.1177/0146167211407521
   Bolte A, 2003, PSYCHOL SCI, V14, P416, DOI 10.1111/1467-9280.01456
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Brattico E, 2016, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00676
   Brattico E, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00308
   Carretti B, 2009, LEARN INDIVID DIFFER, V19, P246, DOI 10.1016/j.lindif.2008.10.002
   Cassidy GG, 2010, SCAND J PSYCHOL, V51, P455, DOI 10.1111/j.1467-9450.2010.00830.x
   Chabris C. F., 1999, Cognitive and neuropsychological mechanisms of expertise: Studies with chess masters
   Chamorro-Premuzic T, 2007, BRIT J PSYCHOL, V98, P175, DOI 10.1348/000712606X111177
   Cowen AS, 2020, P NATL ACAD SCI USA, V117, P1924, DOI 10.1073/pnas.1910704117
   Cropley David., 2008, Psychology of Aesthetics, Creativity, and the Arts, V2, P155, DOI [10.1037/1931-3896.2.3.155, DOI 10.1037/1931-3896.2.3.155, 10.1037=1931-3896.2.3.155]
   Csikszentmihalyi M., 1997, Flow and the psychology of discovery and invention, V39, P1
   Day RF, 2009, COMPUT HUM BEHAV, V25, P130, DOI 10.1016/j.chb.2008.08.001
   De Dreu CKW, 2008, J PERS SOC PSYCHOL, V94, P739, DOI 10.1037/0022-3514.94.5.739
   Deliege I., 2006, Musical Creativity, Multidisciplinary Research in Theory and Practice
   Dobbs S, 2011, APPL COGNITIVE PSYCH, V25, P307, DOI 10.1002/acp.1692
   Doyle M, 2012, THINK SKILLS CREAT, V7, P1, DOI 10.1016/j.tsc.2011.09.002
   Dugosh KL, 2005, J EXP SOC PSYCHOL, V41, P313, DOI 10.1016/j.jesp.2004.05.009
   Eerola T, 2018, PHYS LIFE REV, V25, P100, DOI 10.1016/j.plrev.2017.11.016
   Fernández-Abascal EG, 2013, CREATIVITY RES J, V25, P213, DOI 10.1080/10400419.2013.783759
   Fink A, 2006, EUR J NEUROSCI, V23, P2241, DOI 10.1111/j.1460-9568.2006.04751.x
   Fink A, 2014, NEUROSCI BIOBEHAV R, V44, P111, DOI 10.1016/j.neubiorev.2012.12.002
   Fink A, 2010, NEUROIMAGE, V52, P1687, DOI 10.1016/j.neuroimage.2010.05.072
   Fink A, 2009, HUM BRAIN MAPP, V30, P734, DOI 10.1002/hbm.20538
   Fredrickson B.L., 2013, OXFORD HDB HAPPINESS, P17, DOI [DOI 10.1093/OXFORDHB/9780199557257.013.0003, 10.1093/oxfordhb/9780199557257.013.0003]
   Fredrickson B. L., 2003, Positive Organizational Scholarship, P163
   Fredrickson BL, 2005, COGNITION EMOTION, V19, P313, DOI 10.1080/02699930441000238
   Fredrickson BL, 2004, PHILOS T R SOC B, V359, P1367, DOI 10.1098/rstb.2004.1512
   Fredrickson BL, 2001, AM PSYCHOL, V56, P218, DOI 10.1037/0003-066X.56.3.218
   Frith E, 2021, J EXP PSYCHOL GEN, V150, P609, DOI 10.1037/xge0000958
   Furnham A, 1997, APPL COGNITIVE PSYCH, V11, P445
   Garrido S., 2017, Why are we attracted to sad music?
   Geist K., 2008, YC Young Child, V63, P20
   Gingras B, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00619
   Guilford JP., 1966, Theory Into Practice, V5, P185, DOI [10.1080/00405846609542023, DOI 10.1080/00405846609542023]
   Guilford JP, 1967, The Nature of Human Intelligence
   Hajcak G, 2010, DEV NEUROPSYCHOL, V35, P129, DOI 10.1080/87565640903526504
   He WJ, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1014612
   Hirt ER, 1997, J EXP SOC PSYCHOL, V33, P602, DOI 10.1006/jesp.1997.1335
   [胡卫平 Hu Weiping], 2015, [心理科学进展, Advances in Psychological Science], V23, P1869
   Huron D, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01060
   Huron D, 2014, EMPIR MUSICOL REV, V9, P29
   Huron D, 2011, MUSIC SCI, V15, P146, DOI 10.1177/1029864911401171
   Husain G, 2002, MUSIC PERCEPT, V20, P151, DOI 10.1525/mp.2002.20.2.151
   Jäncke L, 2014, BEHAV BRAIN FUNCT, V10, DOI 10.1186/1744-9081-10-10
   [江俊 Jiang Jun], 2020, [心理科学进展, Advances in Psychological Science], V28, P1133
   Jones DM, 2000, PSYCHON B REV, V7, P550, DOI 10.3758/BF03214370
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2013, PHYS LIFE REV, V10, P235, DOI 10.1016/j.plrev.2013.05.008
   Kämpfe J, 2011, PSYCHOL MUSIC, V39, P424, DOI 10.1177/0305735610376261
   Kaufman SB, 2016, J PERS, V84, P248, DOI 10.1111/jopy.12156
   Kenett YN, 2017, J EXP PSYCHOL LEARN, V43, P1470, DOI 10.1037/xlm0000391
   Kim J., 1998, The effects of creative dance instruction on creative and critical thinking of seventh-grade female students in Seoul, Korea
   Kreutz G, 2008, PSYCHOL MUSIC, V36, P101, DOI 10.1177/0305735607082623
   Ladinig O, 2021, MUSIC SCI, V25, P429, DOI 10.1177/1029864919890900
   Lassiter GD, 1996, PERS SOC PSYCHOL B, V22, P794, DOI 10.1177/0146167296228003
   Li YD, 2013, BRAIN RES, V1538, P61, DOI 10.1016/j.brainres.2013.09.021
   Liu X., 2022, J. Southwest Univ, V1, P181, DOI [10.13718/j.cnki.xdsk.2022.01.017, DOI 10.13718/J.CNKI.XDSK.2022.01.017]
   Liu XL, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.648062
   Lloyd-Cox J, 2022, CORTEX, V156, P90, DOI 10.1016/j.cortex.2022.08.008
   Lonsdale AJ, 2011, BRIT J PSYCHOL, V102, P108, DOI 10.1348/000712610X506831
   Loui P, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00675
   Marin MM, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3519/fnhum.2015.00536
   Marsh K, 2009, RES STUD MUSIC EDUC, V31, P96, DOI 10.1177/1321103X09103638
   Mayer R. E., 1999, Handbook of human creativity, P449, DOI DOI 10.1017/CBO9780511807916.024
   Mehta R., 2019, Consum. Psychol. Rev, V2, P30, DOI DOI 10.1002/ARCP.1044
   Mehta R, 2012, J CONSUM RES, V39, P784, DOI 10.1086/665048
   Merter S, 2017, DES J, V20, pS4519, DOI 10.1080/14606925.2017.1352948
   Miron-Spektor E, 2011, J APPL PSYCHOL, V96, P1065, DOI 10.1037/a0023593
   Mori K, 2014, PSYCHOL MUSIC, V42, P643, DOI 10.1177/0305735613483667
   Müllensiefen D, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01702
   Nantais KM, 1999, PSYCHOL SCI, V10, P370, DOI 10.1111/1467-9280.00170
   North AC., 1995, PSYCHOMUSICOLOGY, V14, P77, DOI [10.1037/h0094090, DOI 10.1037/H0094090]
   O'Hare A., 2011, Stud. Psychol. J, V2, P1
   Oleynick V. C., 2017, Openness/intellect: The core of the creative personality
   Paulus PB, 2003, Group creativity: innovation through collaboration
   Pell MD, 2015, BIOL PSYCHOL, V111, P14, DOI 10.1016/j.biopsycho.2015.08.008
   Pessoa L, 2012, BEHAV BRAIN SCI, V35, P158, DOI 10.1017/S0140525X11001567
   Pessoa L, 2010, FRONT NEUROSCI-SWITZ, V4, DOI 10.3389/fnins.2010.00017
   Radocy R. E., 2012, Psychological foundations of musical behavior
   Rawlings D, 2000, EUR J PERSONALITY, V14, P553
   Rawlings D., 1995, Psychol. Music, V23, P63, DOI [DOI 10.1177/0305735695231005, 10.1177/0305735695231005]
   Rentfrow PJ, 2003, J PERS SOC PSYCHOL, V84, P1236, DOI 10.1037/0022-3514.84.6.1236
   Ritter SM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182210
   Rowe G, 2007, P NATL ACAD SCI USA, V104, P383, DOI 10.1073/pnas.0605198104
   Runco M. A., 2004, CREATIVITY E MEETS W, P9, DOI [DOI 10.1142/9789812567192_0002, 10.1142/9789812567192_0002]
   Russ S. W., 1993, Affect and creativity: The role of affect and play in the creative process
   Sachs ME, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00404
   Salimpoor VN, 2011, NAT NEUROSCI, V14, P257, DOI 10.1038/nn.2726
   Sauter DA, 2010, J COGNITIVE NEUROSCI, V22, P474, DOI 10.1162/jocn.2009.21215
   Schäfer T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00511
   Schellenberg E. G., 2007, Psychology of Music, V35, P5, DOI [DOI 10.1177/0305735607068885, 10.1177/0305735607068885]
   Schellenberg EG, 2005, CURR DIR PSYCHOL SCI, V14, P317, DOI 10.1111/j.0963-7214.2005.00389.x
   Schellenberg EG, 2004, PSYCHOL SCI, V15, P511, DOI 10.1111/j.0956-7976.2004.00711.x
   Schmidt S, 2019, GEOGR COMPASS, V13, DOI 10.1111/gec3.12463
   Schwab D, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00310
   Shek V., 2009, Proceedings of the Second International Conference on Music Communication Science, P87
   Shih YN, 2012, WORK, V42, P573, DOI 10.3233/WOR-2012-1410
   Sternberg RJ, 1996, AM PSYCHOL, V51, P677, DOI 10.1037/0003-066X.51.7.677
   Stratton V. N., 1994, Empir. Stud. Arts, V12, P173, DOI [10.2190/35T0-U4DT-N09Q-LQHW, DOI 10.2190/35T0-U4DT-N09Q-LQHW]
   Suda M, 2008, NEUROREPORT, V19, P75, DOI 10.1097/WNR.0b013e3282f3476f
   Taruffi L, 2021, COGN AFFECT BEHAV NE, V21, P231, DOI 10.3758/s13415-020-00861-x
   Tavani JL, 2016, LEARN INDIVID DIFFER, V52, P197, DOI 10.1016/j.lindif.2014.11.026
   Thompson D. E., 2012, Gen. Music Today, V25, P54, DOI [10.1177/1048371311434639, DOI 10.1177/1048371311434639]
   Thompson WF, 2001, PSYCHOL SCI, V12, P248, DOI 10.1111/1467-9280.00345
   Threadgold E, 2019, APPL COGNITIVE PSYCH, V33, P873, DOI 10.1002/acp.3532
   Threadgold S., 2017, Youth, class and everyday struggles
   TORRANCE EP, 1971, GIFTED CHILD QUART, V15, P75, DOI 10.1177/001698627101500201
   TORRANCE EP, 1970, J EDUC PSYCHOL, V61, P72, DOI 10.1037/h0028767
   Tourva A, 2016, INTELLIGENCE, V54, P136, DOI 10.1016/j.intell.2015.12.001
   Van den Tol AJM, 2016, MUSIC SCI, V20, P68, DOI 10.1177/1029864915627844
   Vosburg S., 1999, Affect, Creative Experience, and Psychological Adjustment, P19
   Vuoskoski JK, 2012, PSYCHOL AESTHET CREA, V6, P204, DOI 10.1037/a0026937
   Vuoskoski JK, 2012, MUSIC PERCEPT, V29, P311, DOI 10.1525/MP.2012.29.3.311
   Wang Shuaishuai, 2020, Sheng Wu Yi Xue Gong Cheng Xue Za Zhi, V37, P587, DOI 10.7507/1001-5515.201907065
   Wang X, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12125787
   Williams F. E., 1993, CREATIVITY ASSESSMEN
   WILLIAMS FE, 1979, GIFTED CHILD QUART, V23, P748, DOI 10.1177/001698627902300406
   WILSON RC, 1953, PSYCHOL BULL, V50, P362, DOI 10.1037/h0060857
   Yao H. C. Y., 2018, Psychol. Res, V11, P243
   [张伟霞 Zhang Weixia], 2018, [心理学报, Acta Psychologica Sinica], V50, P1346
   Ziv N, 2009, CREATIVITY RES J, V21, P125, DOI 10.1080/10400410802633764
NR 131
TC 0
Z9 0
U1 18
U2 18
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD OCT 5
PY 2023
VL 14
AR 1247133
DI 10.3389/fpsyg.2023.1247133
PG 19
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA U7AF7
UT WOS:001086287000001
PM 37868605
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Roswandowitz, C
   Mathias, SR
   Hintz, F
   Kreitewolf, J
   Schelinski, S
   von Kriegstein, K
AF Roswandowitz, Claudia
   Mathias, Samuel R.
   Hintz, Florian
   Kreitewolf, Jens
   Schelinski, Stefanie
   von Kriegstein, Katharina
TI Two Cases of Selective Developmental Voice-Recognition Impairments
SO CURRENT BIOLOGY
LA English
DT Article
ID FACE MEMORY TEST; CONGENITAL AMUSIA; FAMILIAR VOICES; HUMAN BRAIN;
   PERCEPTION; PROSOPAGNOSIA; PITCH; DISCRIMINATION; IDENTIFICATION;
   INDIVIDUALS
AB Recognizing other individuals is an essential skill in humans and in other species [1-3]. Over the last decade, it has become increasingly clear that person-identity recognition abilities are highly variable. Roughly 2% of the population has developmental prosopagnosia, a congenital deficit in recognizing others by their faces [4]. It is currently unclear whether developmental phonagnosia, a deficit in recognizing others by their voices [5], is equally prevalent, or even whether it actually exists. Here, we aimed to identify cases of developmental phonagnosia. We collected more than 1,000 data sets from self-selected German individuals by using a web-based screening test that was designed to assess their voice-recognition abilities. We then examined potentially phonagnosic individuals by using a comprehensive laboratory test battery. We found two novel cases of phonagnosia: AS, a 32-year-old female, and SP, a 32-year-old male; both are otherwise healthy academics, have normal hearing, and show no pathological abnormalities in brain structure. The two cases have comparable patterns of impairments: both performed at least 2 SDs below the level of matched controls on tests that required learning new voices, judging the familiarity of famous voices, and discriminating pitch differences between voices. In both cases, only voice-identity processing per se was affected: face recognition, speech intelligibility, emotion recognition, and musical ability were all comparable to controls. The findings confirm the existence of developmental phonagnosia as a modality-specific impairment and allow a first rough prevalence estimate.
C1 [Roswandowitz, Claudia; Kreitewolf, Jens; Schelinski, Stefanie; von Kriegstein, Katharina] Max Planck Inst Human Cognit & Brain Sci, D-04103 Leipzig, Germany.
   [Roswandowitz, Claudia] Int Max Planck Res Sch Neurosci Commun, D-04103 Leipzig, Germany.
   [Mathias, Samuel R.] Yale Univ, Dept Psychiat, New Haven, CT 06511 USA.
   [Hintz, Florian] Max Planck Inst Psycholinguist, NL-6500 AH Nijmegen, Netherlands.
   [Hintz, Florian] Int Max Planck Res Sch Language Sci, NL-6500 AH Nijmegen, Netherlands.
   [von Kriegstein, Katharina] Humboldt Univ, Dept Psychol, D-12489 Berlin, Germany.
C3 Max Planck Society; Yale University; Max Planck Society; Max Planck
   Society; Humboldt University of Berlin
RP Roswandowitz, C (corresponding author), Max Planck Inst Human Cognit & Brain Sci, D-04103 Leipzig, Germany.
EM roswandowitz@cbs.mpg.de
RI von Kriegstein, Katharina/C-3135-2008
OI von Kriegstein, Katharina/0000-0001-7989-5860; Roswandowitz,
   Claudia/0000-0003-1688-6494; Hintz, Florian/0000-0002-2444-3303
FU Max Planck research group grant
FX We are grateful to AS and SP for their effort and for the time they took
   to participate in the extensive test battery and interviews. We thank
   Stefan Kiebel and Sonja Schall for helpful discussions. We thank Bjorn
   Herrmann and Molly Henry for providing the notched-noise test, and we
   thank Bjorn Herrmann additionally for help with analyzing the
   notched-noise test results. Further thanks go to Marc Bangert for
   implementing the web-based test, to Jason Warren for providing musical
   instrument stimuli, and to Beate Wendt for providing stimuli used in the
   vocal-emotion test. We thank three anonymous reviewers for helpful
   suggestions and comments. This work was funded by a Max Planck research
   group grant to K.v.K.
CR Albouy P, 2013, BRAIN, V136, P1639, DOI 10.1093/brain/awt082
   Andics A, 2014, CURR BIOL, V24, P574, DOI 10.1016/j.cub.2014.01.058
   Belin P, 2004, TRENDS COGN SCI, V8, P129, DOI 10.1016/j.tics.2004.01.008
   Blasi A, 2011, CURR BIOL, V21, P1220, DOI 10.1016/j.cub.2011.06.009
   Bowles DC, 2009, COGN NEUROPSYCHOL, V26, P423, DOI 10.1080/02643290903343149
   BUCHTEL HA, 1989, BRAIN LANG, V37, P12, DOI 10.1016/0093-934X(89)90098-9
   Crawford JR, 1998, CLIN NEUROPSYCHOL, V12, P482, DOI 10.1076/clin.12.4.482.7241
   Duchaine B, 2006, NEUROPSYCHOLOGIA, V44, P576, DOI 10.1016/j.neuropsychologia.2005.07.001
   Fitch WT, 1999, J ACOUST SOC AM, V106, P1511, DOI 10.1121/1.427148
   Garrido L, 2009, NEUROPSYCHOLOGIA, V47, P123, DOI 10.1016/j.neuropsychologia.2008.08.003
   Gaudrain E, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P152
   Gilaie-Dotan S, 2013, BRAIN, V136, P2784, DOI 10.1093/brain/awt214
   Hailstone JC, 2010, NEUROPSYCHOLOGIA, V48, P1104, DOI 10.1016/j.neuropsychologia.2009.12.011
   Henry MJ, 2010, MUSIC PERCEPT, V27, P413, DOI 10.1525/mp.2010.27.5.413
   Hyde KL, 2004, PSYCHOL SCI, V15, P356, DOI 10.1111/j.0956-7976.2004.00683.x
   KALMUS H, 1980, ANN HUM GENET, V43, P369, DOI 10.1111/j.1469-1809.1980.tb01571.x
   Kawahara H, 2008, INT CONF ACOUST SPEE, P3933, DOI 10.1109/ICASSP.2008.4518514
   Kennerknecht I, 2008, FRONT BIOSCI-LANDMRK, V13, P3150, DOI 10.2741/2916
   Kennerknecht I, 2006, AM J MED GENET A, V140A, P1617, DOI 10.1002/ajmg.a.31343
   Lavner Y, 2000, SPEECH COMMUN, V30, P9, DOI 10.1016/S0167-6393(99)00028-X
   Macmillan, 2004, DETECTION THEORY USE
   Marin MM, 2012, NEUROPSYCHOLOGIA, V50, P367, DOI 10.1016/j.neuropsychologia.2011.12.006
   Mathias SR, 2010, J ACOUST SOC AM, V127, P3026, DOI 10.1121/1.3365252
   McDermott JH, 2008, CURR OPIN NEUROBIOL, V18, P452, DOI 10.1016/j.conb.2008.09.005
   Neuner F, 2000, BRAIN COGNITION, V44, P342, DOI 10.1006/brcg.1999.1196
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Peretz I, 2003, ANN NY ACAD SCI, V999, P58, DOI 10.1196/annals.1284.006
   Peretz I, 2002, NEURON, V33, P185, DOI 10.1016/S0896-6273(01)00580-3
   Peretz I, 2008, MUSIC PERCEPT, V25, P331, DOI 10.1525/MP.2008.25.4.331
   Perrachione TK, 2011, SCIENCE, V333, P595, DOI 10.1126/science.1207327
   Perrodin C, 2011, CURR BIOL, V21, P1408, DOI 10.1016/j.cub.2011.07.028
   Schall S, 2013, NEUROIMAGE, V77, P237, DOI 10.1016/j.neuroimage.2013.03.043
   Sheffert SM, 2004, PERCEPT PSYCHOPHYS, V66, P352, DOI 10.3758/BF03194884
   Sidtis D, 2012, INTEGR PSYCHOL BEHAV, V46, P146, DOI 10.1007/s12124-011-9177-4
   Smith DRR, 2005, J ACOUST SOC AM, V117, P305, DOI 10.1121/1.1828637
   Van Lancker D R, 1982, Brain Cogn, V1, P185, DOI 10.1016/0278-2626(82)90016-1
   von Kriegstein K, 2008, P NATL ACAD SCI USA, V105, P6747, DOI 10.1073/pnas.0710826105
   Yardley L, 2008, J PSYCHOSOM RES, V65, P445, DOI 10.1016/j.jpsychores.2008.03.013
   Young AW, 2011, BRIT J PSYCHOL, V102, P959, DOI 10.1111/j.2044-8295.2011.02045.x
NR 39
TC 30
Z9 38
U1 0
U2 30
PU CELL PRESS
PI CAMBRIDGE
PA 600 TECHNOLOGY SQUARE, 5TH FLOOR, CAMBRIDGE, MA 02139 USA
SN 0960-9822
EI 1879-0445
J9 CURR BIOL
JI Curr. Biol.
PD OCT 6
PY 2014
VL 24
IS 19
BP 2348
EP 2353
DI 10.1016/j.cub.2014.08.048
PG 6
WC Biochemistry & Molecular Biology; Biology; Cell Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Life Sciences & Biomedicine - Other
   Topics; Cell Biology
GA AQ4FB
UT WOS:000342747600033
PM 25264258
OA hybrid
DA 2024-01-09
ER

PT J
AU Hollien, H
   Bahr, RH
   Harnsberger, JD
AF Hollien, Harry
   Bahr, Ruth Huntley
   Harnsberger, James D.
TI Issues in Forensic Voice
SO JOURNAL OF VOICE
LA English
DT Article
DE Forensic; Intelligibility; Surveillance; Recordings; Speech; Evaluation
   Systems; Identification; Psychoacoustics; Linguistics; Phonetics
ID HUMAN BRAIN-STEM; SPEAKER IDENTIFICATION; MUSICAL EXPERIENCE;
   ALCOHOL-INTOXICATION; SPEECH; RECOGNITION; STRESS; PITCH; DECEPTION;
   SENSORIMOTOR
AB The following article provides a general review of an area that can be referred to as Forensic Voice. Its goals will be outlined and that discussion will be followed by a description of its major elements. Considered are (1) the processing and analysis of spoken utterances, (2) distorted speech, (3) enhancement of speech intelligibility (re: surveillance and other recordings), (4) transcripts, (5) authentication of recordings, (6) speaker identification, and (7) the detection of deception, intoxication, and emotions in speech. Stress in speech and the psychological stress evaluation systems (that some individuals attempt to use as lie detectors) also will be considered. Points of entry will be suggested for individuals with the kinds of backgrounds possessed by professionals already working in the voice area.
C1 [Hollien, Harry; Harnsberger, James D.] Univ Florida, IASCP, Gainesville, FL USA.
   [Bahr, Ruth Huntley] Univ S Florida, Tampa, FL USA.
C3 State University System of Florida; University of Florida; State
   University System of Florida; University of South Florida
RP Hollien, H (corresponding author), 229 SW 43rd Terrace, Gainesville, FL 32607 USA.
EM hollien@ufl.edu
CR Aarts N, 1984, THESIS U FLORIDA
   Abroms BD, 2004, EXP CLIN PSYCHOPHARM, V12, P243, DOI 10.1037/1064-1297.12.4.243
   Anolli L, 1997, J NONVERBAL BEHAV, V21, P259, DOI 10.1023/A:1024916214403
   [Anonymous], J ACOUSTICAL SOC AM
   [Anonymous], 1996, FORENSIC LINGUISTICS
   [Anonymous], 1990, ACOUSTICS CRIME
   Aperman A, 1982, LEX KY P CARN C CRIM, P63
   ARBUCKLE TY, 1994, J STUD ALCOHOL, V55, P352, DOI 10.15288/jsa.1994.55.352
   ATAL BS, 1972, J ACOUST SOC AM, V52, P1687, DOI 10.1121/1.1913303
   Bahr R, 2002, PHONETICS ITS APPL, P89
   Beigi H, 2011, FUNDAMENTALS OF SPEAKER RECOGNITION, P1, DOI 10.1007/978-0-387-77592-0
   Betancourt KS, 2010, INT J SPEECH LANG LA, V17, P179, DOI 10.1558/ijsll.v17i2.179
   Bouten J, 2007, J AUDIO ENG SOC, V55, P257
   Brixen EB, 2007, VIENN AUSTR P AUD EN
   Broeders A, 1996, FORENSIC LINGUIST, V3, P1
   Broeders A. P. A., 1995, STUDIES FORENSIC PHO, P24
   Bronkhurst A., 2010, ACTA ACUST, V86, P117
   Brumlik J, 1970, NORMAL TREMOR COMP S
   Buckhout R, 1974, SOC ACTION LAW, V11, P1
   Bull R, 1984, EYEWITNESS TESTIMONY
   Campbell JP, 2009, IEEE SIGNAL PROC MAG, V26, P95, DOI 10.1109/MSP.2008.931100
   Chin S. B., 1997, Alcohol and Speech
   Cooney O. M., 1998, J ACOUST SOC AM, V103, P2895, DOI DOI 10.1121/1.421829
   CROSS JF, 1971, PERCEPT PSYCHOPHYS, V10, P393, DOI 10.3758/BF03210319
   Damphousse KR, 2007, 219031 U OKL
   Dean JD, 1980, UK HOME OFFICE POLIC, V35, P25
   DeJong G, 1998, THESIS U FLORIDA
   DePaulo BM, 2003, PSYCHOL BULL, V129, P74, DOI 10.1037//0033-2909.129.1.74
   GELFER MP, 1989, J PHONETICS, V17, P327, DOI 10.1016/S0095-4470(19)30448-6
   GOLDSTEIN DB, 1992, MED DIAGNOSIS TREATM, P25
   Harnsberger JD, 2009, J FORENSIC SCI, V54, P642, DOI 10.1111/j.1556-4029.2009.01026.x
   HAUTAMAKI V, 2010, NEW YORK NY INTERSPE, P1473
   Hecker MHL, 1971, ASHA MONOGRAPH, V16
   Hicks Jr JW, 1981, LEX KY P CARN C CRIM, P189
   HILL JC, 1990, J STUD ALCOHOL, V51, P108, DOI 10.15288/jsa.1990.51.108
   HINDMARCH I, 1991, ALCOHOL ALCOHOLISM, V26, P71
   Hollers H, 2009, PROINNO INNO METRICS, P1, DOI [10.1007/s12036-014-9303-z, DOI 10.1007/S12036-014-9303-Z]
   HOLLIEN H, 1977, J ACOUST SOC AM, V62, P975, DOI 10.1121/1.381592
   Hollien H., 1977, Proceedings of the 1977 International Conference on Crime CountermeasuresScience and Engineering, P21
   HOLLIEN H, 1983, J FORENSIC SCI, V28, P208
   HOLLIEN H, 1987, J FORENSIC SCI, V32, P405
   Hollien H, 2001, J ACOUST SOC AM, V110, P3198, DOI 10.1121/1.1413751
   HOLLIEN H, 1982, J PHONETICS, V10, P139, DOI 10.1016/S0095-4470(19)30953-2
   HOLLIEN H, 1993, FORENSIC SCI INT, V60, P97, DOI 10.1016/0379-0738(93)90097-T
   Hollien H., 1977, 1977 Carnahan Conference on Crime Countermeasures, P19
   Hollien H, 2006, FA4814040011 CIFA US
   Hollien H, 2002, Forensic Voice Identification
   Hollien H., 1996, FORENSIC LINGUIST, V3, P14
   Hollien H, 2010, J ACOUST SOC AM, V128, p2394A
   Hollien H, 2008, FORENSIC SCI, P1
   Hollien H, 1992, NIC FRANC ESCA P SPE, P167
   Hollien H, 1995, STUDIES FORENSIC PHO, V64, P87
   Hollien H, 2008, J FORENSIC SCI, V53, P183, DOI 10.1111/j.1556-4029.2007.00596.x
   Hollien H, 2009, J VOICE, V23, P552, DOI 10.1016/j.jvoice.2007.11.005
   Hollien Harry, 1995, Forensic Linguistics, V2, P143, DOI [10.1558/ijsll.v2i2.143, DOI 10.1558/IJSLL.V2I2.143]
   Hollien PA, 1984, P I AC POL APPL SP 1, P33
   HORVATH F, 1982, J FORENSIC SCI, V27, P340
   Horvath F, J FORENSIC IN PRESS
   Howard R, 1991, STRESS ANXIETY, V13, P178
   Jacewicz E, 2010, J ACOUST SOC AM, V128, P839, DOI 10.1121/1.3459842
   Jiang M, 1995, THESIS U FLORIDA
   JOHNSON CC, 1984, J PHONETICS, V12, P319, DOI 10.1016/S0095-4470(19)30893-9
   KALANT H, 1975, CAN MED ASSOC J, V112, P953
   KLINGHOLZ F, 1988, J ACOUST SOC AM, V84, P929, DOI 10.1121/1.396661
   Koval S, 1998, PRACTICE USAGE SPECT, V1998, P136
   Kovoor BC, 2009, J ACOUST SOC AM, V125, p2530(A)
   KRAUS N, 1995, EAR HEARING, V16, P19, DOI 10.1097/00003446-199502000-00003
   Kraus N, 2010, ACOUST TODAY, V3, P15
   Kraus N, 2009, ANN NY ACAD SCI, V1169, P543, DOI 10.1111/j.1749-6632.2009.04549.x
   Krishnan A, 2005, COGNITIVE BRAIN RES, V25, P161, DOI 10.1016/j.cogbrainres.2005.05.004
   Kubis J, 1973, COMP VOICE ANAL POLY
   LARIVIERE C, 1975, PHONETICA, V31, P185, DOI 10.1159/000259668
   LAZARUS RS, 1993, ANNU REV PSYCHOL, V44, P1, DOI 10.1146/annurev.ps.44.020193.000245
   Lee KY, 1998, SIGNAL PROCESS, V65, P373, DOI 10.1016/S0165-1684(97)00233-8
   LIPPOLD O, 1971, SCI AM, V224, P65, DOI 10.1038/scientificamerican0371-65
   Loftus E. F., 1996, EYEWITNESS TESTIMONY
   LYKKEN DT, 1981, TREMOR BLOOD
   Mayor D, 1989, SUBJECTIVE VOICE IDE, P1
   McGehee F, 1937, J GEN PSYCHOL, V17, P249, DOI 10.1080/00221309.1937.9917999
   Nolan F., 2003, INT J SPEECH LANGUAG, V10, P277, DOI DOI 10.1558/SLL.2003.10.2.277
   Nolan F, 2008, RES000222582 ESRC
   Parbery-Clark A, 2009, J NEUROSCI, V29, P14100, DOI 10.1523/JNEUROSCI.3256-09.2009
   Pihl RO, 2003, ALCOHOL CLIN EXP RES, V27, P773, DOI 10.1097/01.ALC.0000065434.92204.A1
   PISONI DB, 1989, ALCOHOL CLIN EXP RES, V13, P577, DOI 10.1111/j.1530-0277.1989.tb00381.x
   Ross DF, 2006, LAW HUMAN BEHAV, V30, P249, DOI 10.1007/s10979-006-9034-z
   Scherer KR, 1986, DYNAMICS STRESS PHYS, P157, DOI [DOI 10.1007/978-1-4684-5122-1, 10.1007/978-1-4684-5122-1_9, DOI 10.1007/978-1-4684-5122-1_9]
   SCHERER KR, 1981, SPEECH EVALUATION PS
   Schuster B, 2007, NIJ J, V258, P1
   Schweizer TA, 2004, ALCOHOL CLIN EXP RES, V28, P643, DOI 10.1097/01.ALC.0000121652.84754.30
   SHIPP T, 1981, J FORENSIC SCI, V26, P501
   Solomon N., 2012, VOIC SLEUTH 41 S CAR
   Steffen-Batog M, 1993, STUDIA PHONETIKA POS, V4, P73
   Strait DL, 2009, EUR J NEUROSCI, V29, P661, DOI 10.1111/j.1460-9568.2009.06617.x
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   VANWALLENDAEL LR, 1994, APPL COGNITIVE PSYCH, V8, P661, DOI 10.1002/acp.2350080705
   WALLGREN H, 1970, ACTIONS ALCOHOL, V2
   WALLGREN H, 1970, ACTIONS ALCOHOL, V1
   Wan EA, 1998, INT CONF ACOUST SPEE, P381, DOI 10.1109/ICASSP.1998.674447
   Wells GL, 2003, ANNU REV PSYCHOL, V54, P277, DOI 10.1146/annurev.psych.54.101601.145028
   WELLS GL, 1993, AM PSYCHOL, V48, P553, DOI 10.1037/0003-066X.48.5.553
   WOLF JJ, 1972, J ACOUST SOC AM, V51, P2044, DOI 10.1121/1.1913065
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   Yarmey AD, 2003, FORENSIC LINGUIST, V10, P62, DOI 10.1558/sll.2003.10.1.62
   Yarmey AD, 1995, PSYCHOL PUBLIC POL L, V1, P792
NR 104
TC 9
Z9 10
U1 1
U2 31
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0892-1997
EI 1873-4588
J9 J VOICE
JI J. Voice
PD MAR
PY 2014
VL 28
IS 2
BP 170
EP 184
DI 10.1016/j.jvoice.2013.06.011
PG 15
WC Audiology & Speech-Language Pathology; Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Audiology & Speech-Language Pathology; Otorhinolaryngology
GA AC3EY
UT WOS:000332399000006
PM 24176301
DA 2024-01-09
ER

PT J
AU Cespedes-Guevara, J
   Eerola, T
AF Cespedes-Guevara, Julian
   Eerola, Tuomas
TI Music Communicates Affects, Not Basic Emotions - A Constructionist
   Account of Attribution of Emotional Meanings to Music
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE music; basic emotions; dimensions; constructionism; perception of
   musical emotions; emotional expression in speech
ID SPONTANEOUS FACIAL EXPRESSIONS; VOCAL EXPRESSION; CORE AFFECT;
   CULTURAL-DIFFERENCES; DIMENSIONAL MODELS; SELF-REGULATION; PERCEPTION;
   RECOGNITION; PERFORMANCE; RESPONSES
AB Basic Emotion theory has had a tremendous influence on the affective sciences, including music psychology, where most researchers have assumed that music expressivity is constrained to a limited set of basic emotions. Several scholars suggested that these constrains to musical expressivity are explained by the existence of a shared acoustic code to the expression of emotions in music and speech prosody. In this article we advocate for a shift from this focus on basic emotions to a constructionist account. This approach proposes that the phenomenon of perception of emotions in music arises from the interaction of music's ability to express core affects and the influence of top-down and contextual information in the listener's mind. We start by reviewing the problems with the concept of Basic Emotions, and the inconsistent evidence that supports it. We also demonstrate how decades of developmental and cross-cultural research on music and emotional speech have failed to produce convincing findings to conclude that music expressivity is built upon a set of biologically pre-determined basic emotions. We then examine the cue-emotion consistencies between music and speech, and show how they support a parsimonious explanation, where musical expressivity is grounded on two dimensions of core affect (arousal and valence). Next, we explain how the fact that listeners reliably identify basic emotions in music does not arise from the existence of categorical boundaries in the stimuli, but from processes that facilitate categorical perception, such as using stereotyped stimuli and close-ended response formats, psychological processes of construction of mental prototypes, and contextual information. Finally, we outline our proposal of a constructionist account of perception of emotions in music, and spell out the ways in which this approach is able to make solve past conflicting findings. We conclude by providing explicit pointers about the methodological choices that will be vital to move beyond the popular Basic Emotion paradigm and start untangling the emergence of emotional experiences with music in the actual contexts in which they occur.
C1 [Cespedes-Guevara, Julian] ICESI Univ, Dept Estudios Psicol, Cali, Colombia.
   [Eerola, Tuomas] Univ Durham, Dept Mus, Durham, England.
C3 Universidad ICESI; Durham University
RP Cespedes-Guevara, J (corresponding author), ICESI Univ, Dept Estudios Psicol, Cali, Colombia.
EM jcespedes@icesi.edu.co
RI Eerola, Tuomas/K-7596-2019
OI Eerola, Tuomas/0000-0002-2896-929X; Cespedes Guevara,
   Julian/0000-0002-8816-3650
CR Adachi M., 1998, PSYCHOL MUSIC, V26, P133, DOI [DOI 10.1177/0305735698262003, 10.1177/0305735698262003]
   [Anonymous], CHILDREN AND EMOTION
   [Anonymous], 2005, MUSIC EDUC RES
   [Anonymous], 2009, OXFORD HDB MUSIC PSY, DOI DOI 10.1017/CBO9781107415324.004
   [Anonymous], PYSCHOL MUSIC, DOI DOI 10.1177/0305735603031001325
   [Anonymous], 2003, Psychology of Music, DOI [DOI 10.1177/03057356030313003, 10.1177/03057356030313003]
   [Anonymous], 2008, SOCIAL APPL PSYCHOL, DOI DOI 10.1093/ACPROF:OSO/9780198567424.001.0001
   Bachorowski JA, 1999, CURR DIR PSYCHOL SCI, V8, P53, DOI 10.1111/1467-8721.00013
   Bänziger T, 2014, J NONVERBAL BEHAV, V38, P31, DOI 10.1007/s10919-013-0165-x
   Balkwill LL, 2004, JPN PSYCHOL RES, V46, P337, DOI 10.1111/j.1468-5584.2004.00265.x
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Barrett LF, 2006, PERS SOC PSYCHOL REV, V10, P20, DOI 10.1207/s15327957pspr1001_2
   Barrett LF., 2011, PSIHOLOGIJSKE TEME, V20, P359
   Barrett LF, 2007, TRENDS COGN SCI, V11, P327, DOI 10.1016/j.tics.2007.06.003
   Barrett LF, 2006, PERSPECT PSYCHOL SCI, V1, P28, DOI 10.1111/j.1745-6916.2006.00003.x
   Barrett LF, 2011, CURR DIR PSYCHOL SCI, V20, P286, DOI 10.1177/0963721411422522
   BORMANNKISCHKEL C, 1990, INT J BEHAV DEV, V13, P355, DOI 10.1177/016502549001300308
   Bowling DL, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0031942
   Brosch T, 2010, COGNITION EMOTION, V24, P377, DOI 10.1080/02699930902975754
   BRUCE V, 1991, COGNITION, V38, P109, DOI 10.1016/0010-0277(91)90049-A
   Cabeza R, 1999, MEM COGNITION, V27, P139, DOI 10.3758/BF03201220
   Cacioppo J.T., 2000, The handbook of emotion, V2, P173
   Camras LA, 2002, EMOTION, V2, P179, DOI 10.1037//1528-3542.2.2.179
   Carroll JM, 1996, J PERS SOC PSYCHOL, V70, P205, DOI 10.1037/0022-3514.70.2.205
   Carroll JM, 1997, J PERS SOC PSYCHOL, V72, P164, DOI 10.1037/0022-3514.72.1.164
   Clarke E., 2005, Ways of listening: An ecological approach to the perception of musical meaning
   Clarke EF, 2014, MUSIC SCI, V18, P354, DOI 10.1177/1029864914533812
   Clayton M., 2016, OXFORD HDB MUSIC PSY, P47
   Cook N, 2001, MUSIC THEOR SPECTRUM, V23, P170, DOI 10.1525/mts.2001.23.2.170
   Costa M, 2004, MUSIC PERCEPT, V22, P1, DOI 10.1525/mp.2004.22.1.1
   Cross I, 2009, MUSIC SCI, P179
   CUNNINGHAM JG, 1988, MOTIV EMOTION, V12, P399, DOI 10.1007/BF00992362
   Curtis ME, 2010, EMOTION, V10, P335, DOI 10.1037/a0017928
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Davies S., 2003, THEMES PHILOS MUSIC, DOI [10.1093/mind/113.452.747, DOI 10.1093/MIND/113.452.747]
   Davies Stephen, 2010, Handbook of music and emotion: Theory, research, applications, P15
   de Fockert J, 2009, Q J EXP PSYCHOL, V62, P1716, DOI 10.1080/17470210902811249
   Demuru E, 2015, ANIM COGN, V18, P333, DOI 10.1007/s10071-014-0804-6
   DeNora T., 2003, AFTER ADORNO, DOI [10.1017/CBO9781107415324.004, DOI 10.1017/CBO9781107415324.004]
   Deva B. C., 1975, 2 SANG NAT AC IND MU
   Dibben N, 2001, Musucae Scientiae, V5, P161
   Dolgin KG., 1990, Psychol. Music, V18, P87, DOI DOI 10.1177/0305735690181007
   Eerola T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00487
   Eerola T, 2013, MUSIC PERCEPT, V30, P307, DOI [10.1525/mp.2012.30.3.307, 10.1525/MP.2012.30.1.49]
   Eerola T, 2011, J NEW MUSIC RES, V40, P349, DOI 10.1080/09298215.2011.602195
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   Egermann H, 2009, INT J INTERNET SCI, V4, P4
   Eitan Z, 2006, MUSIC PERCEPT, V23, P221, DOI 10.1525/mp.2006.23.3.221
   Eitan Z, 2011, PSYCHOL MUSIC, V39, P449, DOI 10.1177/0305735610377592
   Eitan Z, 2010, COGNITION, V114, P405, DOI 10.1016/j.cognition.2009.10.013
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   EKMAN P, 1983, SCIENCE, V221, P1208, DOI 10.1126/science.6612338
   Ekman P., 1984, EMOTION FACIAL ACTIO
   Ekman P, 2011, EMOT REV, V3, P364, DOI 10.1177/1754073911410740
   Elfenbein HA, 2003, CURR DIR PSYCHOL SCI, V12, P159, DOI 10.1111/1467-8721.01252
   Elfenbein HA, 2007, EMOTION, V7, P131, DOI 10.1037/1528-3542.7.1.131
   Escoffier N, 2013, HUM BRAIN MAPP, V34, P1796, DOI 10.1002/hbm.22029
   Esposito A, 2007, LECT NOTES COMPUT SC, V4775, P51
   Fabian D, 2003, MUSIC SCI, P49
   Fernandez-Dols JM, 1997, J NONVERBAL BEHAV, V21, P163, DOI 10.1023/A:1024917530100
   Flaig NK, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00072
   Fontaine JRJ, 2007, PSYCHOL SCI, V18, P1050, DOI 10.1111/j.1467-9280.2007.02024.x
   Franco F, 2017, PSYCHOL MUSIC, V45, P131, DOI 10.1177/0305735616652954
   Frank MG, 2001, J PERS SOC PSYCHOL, V80, P75, DOI 10.1037/0022-3514.80.1.75
   Fridlund A., 1994, Human facial expression: An evolutionary view
   Frijda N., 1986, The emotions: Studies in emotion and social interaction
   Frijda N. H., 2008, HDB EMOTIONS, P59
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Fröhlich M, 2016, ROY SOC OPEN SCI, V3, DOI 10.1098/rsos.160278
   GEEN TR, 1992, J RES PERS, V26, P273, DOI 10.1016/0092-6566(92)90044-5
   GERARDI GM, 1995, MUSIC PERCEPT, V12, P279
   GIOMO CJ, 1993, PSYCHOL MUSIC, V21, P141, DOI DOI 10.1177/030573569302100204
   Gomez P, 2007, EMOTION, V7, P377, DOI 10.1037/1528-3542.7.2.377
   GOSSELIN P, 1995, J PERS SOC PSYCHOL, V68, P83, DOI 10.1037/0022-3514.68.1.83
   Gregory A. H., 1996, PSYCHOL MUSIC, V24, P47, DOI [10.1177/0305735696241005, DOI 10.1177/0305735696241005]
   Gregory AH, 1996, MOTIV EMOTION, V20, P341, DOI 10.1007/BF02856522
   Gundlach RH, 1932, AM J PSYCHOL, V44, P133, DOI 10.2307/1414960
   Gundlach RH, 1935, AM J PSYCHOL, V47, P624, DOI 10.2307/1416007
   Harrigan J. A., 2005, NEW HDB METHODS NONV, P65, DOI DOI 10.1093/ACPROF:OSO/9780198529620.003.0003
   Hunter PG, 2011, J EXP CHILD PSYCHOL, V110, P80, DOI 10.1016/j.jecp.2011.04.001
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Ilie G, 2011, MUSIC PERCEPT, V28, P247, DOI 10.1525/MP.2011.28.3.247
   Izard C.E., 1977, HUMAN EMOTIONS, P43, DOI [DOI 10.1007/978-1-4899-2209-0_3, 10.1007/978-1-4899-2209-0_3]
   Izard C. E., 1987, HDB INFANT DEV, P494
   IZARD CE, 1992, PSYCHOL REV, V99, P561, DOI 10.1037/0033-295X.99.3.561
   Johnstone T., 2000, Handbook of Emotions, V2nd ed., P220
   Juslin P. N., 2010, HDB MUSIC EMOTION TH, P3
   Juslin P. N., 2010, Handbook of music and emotion: Theory, research, applications, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0022
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2016, PSYCHOL AESTHET CREA, V10, P157, DOI 10.1037/aca0000034
   Juslin PN, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00596
   Juslin PN, 2010, MUSIC ANAL, V29, P334, DOI 10.1111/j.1468-2249.2011.00323.x
   Juslin PN, 2001, EMOTION, V1, P381, DOI 10.1037//1528-3542.1.4.381
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 1997, MUSIC PERCEPT, V14, P383
   Juslin PN., 2001, Music and Emotion, P309, DOI 10.1093/oso/9780192631886.003.0014
   Kallinen K., 2005, Psychology of Music, V33, P373, DOI DOI 10.1177/0305735605056147
   KASTNER MP, 1990, MUSIC PERCEPT, V8, P189
   Kawase S, 2016, MUSIC SCI, V20, P163, DOI 10.1177/1029864915608682
   Kayyal MH, 2013, EMOTION, V13, P891, DOI 10.1037/a0033244
   Kivy P, 1999, BRIT J AESTHET, V39, P1, DOI 10.1093/bjaesthetics/39.1.1
   Koelsch S, 2014, NAT REV NEUROSCI, V15, P170, DOI 10.1038/nrn3666
   Kragel PA, 2013, EMOTION, V13, P681, DOI 10.1037/a0031820
   KRAUT RE, 1979, J PERS SOC PSYCHOL, V37, P1539, DOI 10.1037/0022-3514.37.9.1539
   Kreibig SD, 2010, BIOL PSYCHOL, V84, P394, DOI 10.1016/j.biopsycho.2010.03.010
   Krumhansl CL, 1997, CAN J EXP PSYCHOL, V51, P336, DOI 10.1037/1196-1961.51.4.336
   Lamont A., 2016, OXFORD HDB MUSIC PSY, P431
   Laukka P, 2005, EMOTION, V5, P277, DOI 10.1037/1528-3542.5.3.277
   Laukka P, 2005, COGNITION EMOTION, V19, P633, DOI 10.1080/02699930441000445
   Laukka P, 2013, EMOTION, V13, P434, DOI 10.1037/a0031388
   Leman M, 2005, J NEW MUSIC RES, V34, P39, DOI 10.1080/09298210500123978
   Lindquist KA, 2012, BEHAV BRAIN SCI, V35, P121, DOI 10.1017/S0140525X11000446
   Lindquist KA, 2009, EMOT REV, V1, P16, DOI 10.1177/1754073908097177
   Lindstrom E, 2003, RES STUDIES MUSIC ED, V20, P23, DOI DOI 10.1177/1321103X030200010201
   Matsumoto D., 2008, Handbook of Emotions, P211, DOI DOI 10.1016/J.BRAT.2006.05.004
   Mohn C, 2011, PSYCHOL MUSIC, V39, P503, DOI 10.1177/0305735610378183
   Morey R, 1940, J SOC PSYCHOL, V12, P333, DOI 10.1080/00224545.1940.9921477
   Mote J, 2011, EMOTION, V11, P618, DOI 10.1037/a0022573
   Motley MT., 1988, Western Journal of Speech Communication, V52, P1, DOI [10.1080/10570318809389622, DOI 10.1080/10570318809389622]
   Nawrot ES., 2003, Psychol. Music, V31, P75, DOI DOI 10.1177/0305735603031001325
   Nelson NL, 2013, EMOT REV, V5, P8, DOI 10.1177/1754073912457227
   Niedenthal PM, 2010, BEHAV BRAIN SCI, V33, P417, DOI 10.1017/S0140525X10000865
   ORTONY A, 1990, PSYCHOL REV, V97, P315, DOI 10.1037/0033-295X.97.3.315
   Panksepp J, 2007, PERSPECT PSYCHOL SCI, V2, P281, DOI 10.1111/j.1745-6916.2007.00045.x
   Panksepp Jaak, 2000, Handbook of emotions, V2nd, P137
   Parr LA, 2005, CURR OPIN NEUROBIOL, V15, P716, DOI 10.1016/j.conb.2005.10.017
   Plutchik R., 1980, EMOTION PSYCHOEVOLUT
   Quinto L, 2014, PSYCHOL MUSIC, V42, P503, DOI 10.1177/0305735613482023
   Raz G, 2016, COGN AFFECT BEHAV NE, V16, P709, DOI 10.3758/s13415-016-0425-4
   Rendall D, 2009, ANIM BEHAV, V78, P233, DOI 10.1016/j.anbehav.2009.06.007
   Ruiz-Belda MA, 2003, COGNITION EMOTION, V17, P315, DOI 10.1080/02699930302288
   Russell JA, 1999, J PERS SOC PSYCHOL, V76, P805, DOI 10.1037/0022-3514.76.5.805
   RUSSELL JA, 1994, PSYCHOL BULL, V115, P102, DOI 10.1037/0033-2909.115.1.102
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Russell JA, 2003, ANNU REV PSYCHOL, V54, P329, DOI 10.1146/annurev.psych.54.101601.145102
   Russell JA, 2003, PSYCHOL REV, V110, P145, DOI 10.1037/0033-295X.110.1.145
   Saarikallio S, 2011, PSYCHOL MUSIC, V39, P307, DOI 10.1177/0305735610374894
   Scarantino A, 2011, EMOT REV, V3, P444, DOI 10.1177/1754073911410745
   Scherer KR, 2007, EMOTION, V7, P113, DOI 10.1037/1528-3542.7.1.113
   Scherer KR, 2015, COMPUT SPEECH LANG, V29, P218, DOI 10.1016/j.csl.2013.10.002
   Scherer KR, 2011, INT J PSYCHOL, V46, P401, DOI 10.1080/00207594.2011.626049
   Scherer KR, 2009, PHILOS T R SOC B, V364, P3459, DOI 10.1098/rstb.2009.0141
   Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Scherer KR., 1994, The nature of emotion: fundamental questions, P25
   Schimmack U, 2000, EUR J PERSONALITY, V14, P325, DOI 10.1002/1099-0984(200007/08)14:4<325::AID-PER380>3.0.CO;2-I
   Schubert E, 2004, MUSIC PERCEPT, V21, P561, DOI 10.1525/mp.2004.21.4.561
   Schubert E, 1999, AUST J PSYCHOL, V51, P154, DOI 10.1080/00049539908255353
   Schubert E, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00837
   Schubert E, 2009, MUSIC SCI, P63, DOI 10.1177/1029864909013002051
   Sievers B, 2013, P NATL ACAD SCI USA, V110, P70, DOI 10.1073/pnas.1209023110
   SOLSO RL, 1981, BRIT J PSYCHOL, V72, P499, DOI 10.1111/j.2044-8295.1981.tb01779.x
   Stachó L, 2013, MUSIC SCI, V17, P495, DOI 10.1177/1029864913497617
   Stephens CL, 2010, BIOL PSYCHOL, V84, P463, DOI 10.1016/j.biopsycho.2010.03.014
   Szekely E., 2013, CHILDRENS EMOTIONAL
   Terwogt M. M., 1991, PSYCHOL MUSIC, V19, P99, DOI DOI 10.1177/0305735691192001
   THAYER RE, 1994, J PERS SOC PSYCHOL, V67, P910, DOI 10.1037/0022-3514.67.5.910
   Thompson WF, 2010, HDB MUSIC EMOTION TH
   Tomkins S. S., 1962, Affect Imagery Consciousness: Volume I: The Positive Affects, VI
   van Goethem A, 2011, MUSIC SCI, V15, P208, DOI 10.1177/1029864911401174
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   Vuoskoski J.K., 2015, PSYCHOMUSICOLOGY MUS, V25, P116, DOI DOI 10.1037/PMU0000096
   Watt R. J., 1998, MUSIC SCI, V2, P3, DOI [10.3389/fpsyg.2011.00393, DOI 10.3389/FPSYG.2011.00393]
   WEDIN L, 1972, SCAND J PSYCHOL, V13, P241, DOI 10.1111/j.1467-9450.1972.tb00072.x
   Weiner B., 1984, Emotions, cognition, and behavior, P167
   Weninger F, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00292
   Widen S. C., 2008, HDB EMOTIONS, P348
   Widen SC, 2013, EMOT REV, V5, P72, DOI 10.1177/1754073912451492
   Yang YH, 2015, ACM T INTERACT INTEL, V5, DOI 10.1145/2738220
   Young AW, 1997, COGNITION, V63, P271, DOI 10.1016/S0010-0277(97)00003-6
NR 173
TC 50
Z9 57
U1 3
U2 42
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD FEB 28
PY 2018
VL 9
AR 215
DI 10.3389/fpsyg.2018.00215
PG 19
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA FX7IL
UT WOS:000426262300001
PM 29541041
OA Green Accepted, Green Published, gold
DA 2024-01-09
ER

PT J
AU Rigoulot, S
   Armony, JL
AF Rigoulot, Simon
   Armony, Jorge L.
TI Early selectivity for vocal and musical sounds: electrophysiological
   evidence from an adaptation paradigm
SO EUROPEAN JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE ERPs; music; neural adaptation; neural selectivity; speech prosody;
   voice
ID EVENT-RELATED POTENTIALS; NEURAL ADAPTATION; TIME-COURSE; BRAIN;
   LANGUAGE; WORDS; REPETITION; RESPONSES; EMOTION; FACES
AB There is growing interest in characterizing the neural basis of music perception and, in particular, assessing how similar, or not, it is to that of speech. To further explore this question, we employed an EEG adaptation paradigm in which we compared responses to short sounds belonging to the same category, either speech (pseudo-sentences) or music (piano or violin), depending on whether they were immediately preceded by a same- or different-category sound. We observed a larger reduction in the N100 component magnitude in response to musical sounds when they were preceded by music (either the same or different instrument) than by speech. In contrast, the N100 amplitude was not affected by the preceding stimulus category in the case of speech. For P200 component, we observed a diminution of amplitude when speech sounds were preceded speech, compared to music. No such decrease was found when we compared the responses to music sounds. These differences in the processing of speech and music are consistent with the proposal that some degree of category selectivity for these two classes of complex stimuli already occurs at early stages of auditory processing, possibly subserved by partly separated neuronal populations.
C1 [Rigoulot, Simon; Armony, Jorge L.] Ctr Res Brain Language & Music CRBLM, Montreal, PQ, Canada.
   [Rigoulot, Simon; Armony, Jorge L.] Douglas Mental Hlth Univ Inst, Fac Med, Dept Psychiat, 6875 LaSalle Blvd, Montreal, PQ H4H 1R3, Canada.
RP Rigoulot, S (corresponding author), Ctr Res Brain Language & Music CRBLM, Montreal, PQ, Canada.; Rigoulot, S (corresponding author), Douglas Mental Hlth Univ Inst, Fac Med, Dept Psychiat, 6875 LaSalle Blvd, Montreal, PQ H4H 1R3, Canada.
EM simon.rigoulot@gmail.com
RI Rigoulot, Simon/ABF-5776-2020
FU Canadian Institutes of Health Research (CIHR); National Science and
   Engineering Research Council of Canada (NSERC)
FX We are grateful to Mihaela Felezeu, Joshua McCall and Laura Avigan for
   help with the EEG recording. We also thank William Aube and Bernard
   Bouchard for providing the musical stimuli, and Isabelle Peretz for
   helpful discussions. This research was funded by grants from the
   Canadian Institutes of Health Research (CIHR) and the National Science
   and Engineering Research Council of Canada (NSERC) to JLA.
CR Aguirre GK, 2007, NEUROIMAGE, V35, P1480, DOI 10.1016/j.neuroimage.2007.02.005
   Aguirre GK, 2011, NEUROIMAGE, V56, P1293, DOI 10.1016/j.neuroimage.2011.02.005
   Altmann CF, 2008, CEREB CORTEX, V18, P1350, DOI 10.1093/cercor/bhm166
   Amihai I, 2011, EXP BRAIN RES, V209, P193, DOI 10.1007/s00221-011-2546-x
   Angulo-Perkins A, 2014, CORTEX, V59, P126, DOI 10.1016/j.cortex.2014.07.013
   Armony JL, 2015, NEUROSCI LETT, V593, P35, DOI 10.1016/j.neulet.2015.03.011
   Asaridou SS, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00321
   Aubé W, 2015, SOC COGN AFFECT NEUR, V10, P399, DOI 10.1093/scan/nsu067
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Brattico E, 2006, BRAIN RES, V1117, P162, DOI 10.1016/j.brainres.2006.08.023
   Budd TW, 1998, INT J PSYCHOPHYSIOL, V31, P51, DOI 10.1016/S0167-8760(98)00040-3
   CADALBERT A, 1994, J CLIN EXP NEUROPSYC, V16, P664, DOI 10.1080/01688639408402679
   Caharel S, 2009, NEUROPSYCHOLOGIA, V47, P639, DOI 10.1016/j.neuropsychologia.2008.11.016
   Cao X, 2015, NEUROSCIENCE, V294, P21, DOI 10.1016/j.neuroscience.2015.03.009
   Cao XH, 2014, EXP BRAIN RES, V232, P3015, DOI 10.1007/s00221-014-3986-x
   Chakalov I, 2012, BMC NEUROSCI, V13, DOI 10.1186/1471-2202-13-72
   Crowley KE, 2004, CLIN NEUROPHYSIOL, V115, P732, DOI 10.1016/j.clinph.2003.11.021
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Eimer M, 2011, BRAIN RES, V1376, P76, DOI 10.1016/j.brainres.2010.12.046
   Fecteau S, 2007, NEUROIMAGE, V36, P480, DOI 10.1016/j.neuroimage.2007.02.043
   Fedorenko E, 2012, J NEUROPHYSIOL, V108, P3289, DOI 10.1152/jn.00209.2012
   Feuerriegel D, 2015, INT J PSYCHOPHYSIOL, V96, P8, DOI 10.1016/j.ijpsycho.2015.02.030
   Grill-Spector K, 2006, TRENDS COGN SCI, V10, P14, DOI 10.1016/j.tics.2005.11.006
   Hausen M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00566
   Herrmann CS, 2001, NEUROSCI BIOBEHAV R, V25, P465, DOI 10.1016/S0149-7634(01)00027-6
   Hillyard SA, 1998, P NATL ACAD SCI USA, V95, P781, DOI 10.1073/pnas.95.3.781
   Jackendoff R, 2009, MUSIC PERCEPT, V26, P195, DOI 10.1525/MP.2009.26.3.195
   Jacques C, 2006, PSYCHOL SCI, V17, P485, DOI 10.1111/j.1467-9280.2006.01733.x
   Jeffries KJ, 2003, NEUROREPORT, V14, P749, DOI 10.1097/00001756-200304150-00018
   Koelsch S, 2002, NEUROIMAGE, V17, P956, DOI 10.1016/S1053-8119(02)91154-7
   Kuriki S, 2006, J NEUROSCI, V26, P4046, DOI 10.1523/JNEUROSCI.3907-05.2006
   Kuriki S, 2007, CEREB CORTEX, V17, P2725, DOI 10.1093/cercor/bhl182
   Lanting CP, 2013, J NEUROPHYSIOL, V110, P973, DOI 10.1152/jn.00547.2012
   Lartillot O, 2008, ST CLASS DAT ANAL, P261, DOI 10.1007/978-3-540-78246-9_31
   Leung AWS, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068892
   Lima CF, 2013, BEHAV RES METHODS, V45, P1234, DOI 10.3758/s13428-013-0324-3
   Lopez-Calderon J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00213
   LUCK SJ, 1990, ELECTROEN CLIN NEURO, V75, P528, DOI 10.1016/0013-4694(90)90139-B
   Marozeau J, 2003, J ACOUST SOC AM, V114, P2946, DOI 10.1121/1.1618239
   May PJC, 2010, PSYCHOPHYSIOLOGY, V47, P66, DOI 10.1111/j.1469-8986.2009.00856.x
   Merrill J, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00076
   Murray MM, 2006, J NEUROSCI, V26, P1293, DOI 10.1523/JNEUROSCI.4511-05.2006
   NAATANEN R, 1988, ELECTROEN CLIN NEURO, V69, P523, DOI 10.1016/0013-4694(88)90164-2
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Norman-Haignere S, 2015, NEURON, V88, P1281, DOI 10.1016/j.neuron.2015.11.035
   Özdemir E, 2006, NEUROIMAGE, V33, P628, DOI 10.1016/j.neuroimage.2006.07.013
   Patel AD, 1998, BRAIN LANG, V61, P123, DOI 10.1006/brln.1997.1862
   Pell MD, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027256
   Pell MD, 2009, J PHONETICS, V37, P417, DOI 10.1016/j.wocn.2009.07.005
   Peltola MS, 2012, BRAIN LANG, V121, P261, DOI 10.1016/j.bandl.2012.03.007
   Peretz I, 2004, MUSIC PERCEPT, V21, P373, DOI 10.1525/mp.2004.21.3.373
   PERETZ I, 1994, BRAIN, V117, P1283, DOI 10.1093/brain/117.6.1283
   Peretz I, 2015, PHILOS T R SOC B, V370, P68, DOI 10.1098/rstb.2014.0090
   Pérez-González D, 2014, FRONT INTEGR NEUROSC, V8, DOI 10.3389/fnint.2014.00019
   Rigoulot S, 2015, NEUROSCIENCE, V290, P175, DOI 10.1016/j.neuroscience.2015.01.033
   Rigoulot S, 2014, SPEECH COMMUN, V65, P36, DOI 10.1016/j.specom.2014.05.006
   Rigoulot S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00367
   Rogalsky C, 2011, J NEUROSCI, V31, P3843, DOI 10.1523/JNEUROSCI.4515-10.2011
   Rosburg T, 2006, PSYCHOPHYSIOLOGY, V43, P137, DOI 10.1111/j.1469-8986.2006.00391.x
   Rosburg T, 2004, CLIN NEUROPHYSIOL, V115, P898, DOI 10.1016/j.clinph.2003.11.011
   Schön D, 2010, NEUROIMAGE, V51, P450, DOI 10.1016/j.neuroimage.2010.02.023
   Schweinberger SR, 2008, CURR BIOL, V18, P684, DOI 10.1016/j.cub.2008.04.015
   Seidner W., 1978, DIE SANGERSTIMME
   Tierney A, 2013, CEREB CORTEX, V23, P249, DOI 10.1093/cercor/bhs003
   Todorovic A, 2011, J NEUROSCI, V31, P9118, DOI 10.1523/JNEUROSCI.1425-11.2011
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   Zäske R, 2009, EUR J NEUROSCI, V30, P527, DOI 10.1111/j.1460-9568.2009.06839.x
   Zhang F, 2009, J AM ACAD AUDIOL, V20, P239, DOI 10.3766/jaaa.20.4.4
NR 68
TC 3
Z9 3
U1 0
U2 23
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0953-816X
EI 1460-9568
J9 EUR J NEUROSCI
JI Eur. J. Neurosci.
PD NOV
PY 2016
VL 44
IS 10
BP 2786
EP 2794
DI 10.1111/ejn.13391
PG 9
WC Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Neurosciences & Neurology
GA EC9YJ
UT WOS:000388499900006
PM 27600697
DA 2024-01-09
ER

PT J
AU Frühholz, S
   Trost, W
   Kotz, SA
AF Fruhholz, Sascha
   Trost, Wiebke
   Kotz, Sonja A.
TI The sound of emotions-Towards a unifying neural network perspective of
   affective sound processing
SO NEUROSCIENCE AND BIOBEHAVIORAL REVIEWS
LA English
DT Review
DE Affect; Sound; Voice; Music; Limbic system; Auditory cortex; Basal
   ganglia; Cerebellum
ID HUMAN ORBITOFRONTAL CORTEX; AUDITORY-CORTEX; AMYGDALA SUBREGIONS;
   PREFRONTAL CORTEX; VOCAL EXPRESSIONS; AFFECTIVE PROSODY; FUNCTIONAL MRI;
   BASAL GANGLIA; QUANTITATIVE METAANALYSIS; ACOUSTIC PARAMETERS
AB Affective sounds are an integral part of the natural and social environment that shape and influence behavior across a multitude of species. In human primates, these affective sounds span a repertoire of environmental and human sounds when we vocalize or produce music. In terms of neural processing, cortical and subcortical brain areas constitute a distributed network that supports our listening experience to these affective sounds. Taking an exhaustive cross-domain view, we accordingly suggest a common neural network that facilitates the decoding of the emotional meaning from a wide source of sounds rather than a traditional view that postulates distinct neural systems for specific affective sound types. This new integrative neural network view unifies the decoding of affective valence in sounds, and ascribes differential as well as complementary functional roles to specific nodes within a common neural network. It also highlights the importance of an extended brain network beyond the central limbic and auditory brain systems engaged in the processing of affective sounds. (C) 2016 Elsevier Ltd. All rights reserved.
C1 [Fruhholz, Sascha] Univ Zurich, Dept Psychol, Binzmuhlestr 14,Box 18, CH-8050 Zurich, Switzerland.
   [Fruhholz, Sascha] Univ Zurich, Neurosci Ctr Zurich, Zurich, Switzerland.
   [Fruhholz, Sascha] ETH, Zurich, Switzerland.
   [Fruhholz, Sascha] Univ Zurich, Ctr Integrat Human Physiol ZIHP, CH-8006 Zurich, Switzerland.
   [Trost, Wiebke] Univ Geneva, Swiss Ctr Affect Sci, Geneva, Switzerland.
   [Kotz, Sonja A.] Maastricht Univ, Dept Neuropsychol & Psychopharmacol, Fac Psychol & Neurosci, Maastricht, Netherlands.
   [Kotz, Sonja A.] Max Planck Inst Human Cognit & Brain Sci, Dept Neuropsychol, Leipzig, Germany.
C3 University of Zurich; University of Zurich; Swiss Federal Institutes of
   Technology Domain; ETH Zurich; University of Zurich; Zurich Center
   Integrative Human Physiology (ZIHP); University of Geneva; Maastricht
   University; Max Planck Society
RP Frühholz, S (corresponding author), Univ Zurich, Dept Psychol, Binzmuhlestr 14,Box 18, CH-8050 Zurich, Switzerland.
EM sascha.fruehholz@uzh.ch
RI Frühholz, Sascha/E-9194-2013
OI Fruhholz, Sascha/0000-0002-6485-3817
FU Swiss National Science Foundation [SNSF PP00P1_157409/1]
FX S.F. was supported by a grant from the Swiss National Science Foundation
   (SNSF PP00P1_157409/1). We thank Cristina Soriano for helpful comments
   on the manuscript.
CR Adamaszek M, 2014, CEREBELLUM, V13, P338, DOI 10.1007/s12311-013-0537-0
   Adolphs R, 2002, CURR OPIN NEUROBIOL, V12, P169, DOI 10.1016/S0959-4388(02)00301-X
   Alba-Ferrara L, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0028701
   Amodio DM, 2006, NAT REV NEUROSCI, V7, P268, DOI 10.1038/nrn1884
   [Anonymous], 2009, Int. J. Speech Lang. Pathol
   [Anonymous], 1985, Contributions to the Doctrine of Signs
   Armony JL, 1997, ANN NY ACAD SCI, V821, P259, DOI 10.1111/j.1749-6632.1997.tb48285.x
   Awano H, 2011, LECT NOTES COMPUT SC, V7064, P323, DOI 10.1007/978-3-642-24965-5_36
   Bach DR, 2008, NEUROIMAGE, V42, P919, DOI 10.1016/j.neuroimage.2008.05.034
   Bach DR, 2008, CEREB CORTEX, V18, P145, DOI 10.1093/cercor/bhm040
   Bachorowski JA, 2001, PSYCHOL SCI, V12, P252, DOI 10.1111/1467-9280.00346
   Ball T, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000307
   Bamiou DE, 2003, BRAIN RES REV, V42, P143, DOI 10.1016/S0165-0173(03)00172-3
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Baumgartner T, 2006, BRAIN RES, V1075, P151, DOI 10.1016/j.brainres.2005.12.065
   Beaucousin V, 2007, CEREB CORTEX, V17, P339, DOI 10.1093/cercor/bhj151
   Beaucousin V, 2011, BRAIN RES, V1390, P108, DOI 10.1016/j.brainres.2011.03.043
   Bestelmeyer PEG, 2014, J NEUROSCI, V34, P8098, DOI 10.1523/JNEUROSCI.4820-13.2014
   Blackford JU, 2010, NEUROIMAGE, V50, P1188, DOI 10.1016/j.neuroimage.2009.12.083
   Blood AJ, 1999, NAT NEUROSCI, V2, P382, DOI 10.1038/7299
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Boemio A, 2005, NAT NEUROSCI, V8, P389, DOI 10.1038/nn1409
   Brattico E, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00308
   Brown S, 2004, NEUROREPORT, V15, P2033, DOI 10.1097/00001756-200409150-00008
   Buchanan TW, 2000, COGNITIVE BRAIN RES, V9, P227, DOI 10.1016/S0926-6410(99)00060-9
   Büchel C, 1999, J NEUROSCI, V19, P10869
   Calder AJ, 2000, NAT NEUROSCI, V3, P1077, DOI 10.1038/80586
   Cappe C, 2009, CEREB CORTEX, V19, P2025, DOI 10.1093/cercor/bhn228
   Caria A, 2011, CEREB CORTEX, V21, P2838, DOI 10.1093/cercor/bhr084
   Chanda ML, 2013, TRENDS COGN SCI, V17, P179, DOI 10.1016/j.tics.2013.02.007
   Chapin H, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0013812
   Dalgleish T, 2004, NAT REV NEUROSCI, V5, P583, DOI 10.1038/nrn1432
   Dietrich S, 2007, NEUROREPORT, V18, P1891, DOI 10.1097/WNR.0b013e3282f290df
   Dietrich S, 2008, NEUROREPORT, V19, P1751, DOI 10.1097/WNR.0b013e3283193e9e
   Duchaine B, 2015, ANNU REV VIS SCI, V1, P393, DOI 10.1146/annurev-vision-082114-035518
   Eldar E, 2007, CEREB CORTEX, V17, P2828, DOI 10.1093/cercor/bhm011
   Escoffier N, 2013, HUM BRAIN MAPP, V34, P1796, DOI 10.1002/hbm.22029
   Ethofer T, 2006, NEUROIMAGE, V30, P580, DOI 10.1016/j.neuroimage.2005.09.059
   Ethofer T, 2006, NEUROREPORT, V17, P249, DOI 10.1097/01.wnr.0000199466.32036.5d
   Ethofer T, 2007, SOC COGN AFFECT NEUR, V2, P334, DOI 10.1093/scan/nsm028
   Ethofer T, 2012, CEREB CORTEX, V22, P191, DOI 10.1093/cercor/bhr113
   Ethofer T, 2009, J COGNITIVE NEUROSCI, V21, P1255, DOI 10.1162/jocn.2009.21099
   Etkin A, 2011, TRENDS COGN SCI, V15, P85, DOI 10.1016/j.tics.2010.11.004
   Euston DR, 2012, NEURON, V76, P1057, DOI 10.1016/j.neuron.2012.12.002
   Fecteau S, 2005, J NEUROPHYSIOL, V94, P2251, DOI 10.1152/jn.00329.2005
   Fecteau S, 2007, NEUROIMAGE, V36, P480, DOI 10.1016/j.neuroimage.2007.02.043
   Ferrucci R, 2012, COGNITION EMOTION, V26, P786, DOI 10.1080/02699931.2011.619520
   Friederici AD, 2012, TRENDS COGN SCI, V16, P262, DOI 10.1016/j.tics.2012.04.001
   Frühholz S, 2015, NEUROIMAGE, V109, P27, DOI 10.1016/j.neuroimage.2015.01.016
   Frühholz S, 2015, P NATL ACAD SCI USA, V112, P1583, DOI 10.1073/pnas.1411315112
   Frühholz S, 2014, PROG NEUROBIOL, V123, P1, DOI 10.1016/j.pneurobio.2014.09.003
   Frühholz S, 2013, CORTEX, V49, P1394, DOI 10.1016/j.cortex.2012.08.003
   Frühholz S, 2013, NEUROSCI BIOBEHAV R, V37, P24, DOI 10.1016/j.neubiorev.2012.11.002
   Frühholz S, 2012, NEUROIMAGE, V62, P1658, DOI 10.1016/j.neuroimage.2012.06.015
   Frühholz S, 2012, CEREB CORTEX, V22, P1107, DOI 10.1093/cercor/bhr184
   Frühholz S, 2010, NEUROSCI LETT, V469, P260, DOI 10.1016/j.neulet.2009.12.010
   Fruhholz S., 2013, NEUROSCI BIOBEHAV R, V37, P2847
   Fruhholz S., 2016, BEHAV BRAIN SCI, V37, P554
   Fusar-Poli P, 2009, J PSYCHIATR NEUROSCI, V34, P418
   Garcia R, 1999, NATURE, V402, P294, DOI 10.1038/46286
   George MS, 1996, ARCH NEUROL-CHICAGO, V53, P665, DOI 10.1001/archneur.1996.00550070103017
   Gifford GW, 2005, J COGNITIVE NEUROSCI, V17, P1471, DOI 10.1162/0898929054985464
   Glasser MF, 2008, CEREB CORTEX, V18, P2471, DOI 10.1093/cercor/bhn011
   Grahn JA, 2007, J COGNITIVE NEUROSCI, V19, P893, DOI 10.1162/jocn.2007.19.5.893
   Grandjean D, 2005, NAT NEUROSCI, V8, P145, DOI 10.1038/nn1392
   Green AC, 2008, NEUROREPORT, V19, P711, DOI 10.1097/WNR.0b013e3282fd0dd8
   Gripon V, 2011, IEEE T NEURAL NETWOR, V22, P1087, DOI 10.1109/TNN.2011.2146789
   Hass J, 2012, NEURAL COMPUT, V24, P1519, DOI 10.1162/NECO_a_00280
   Haxby JV, 2000, TRENDS COGN SCI, V4, P223, DOI 10.1016/S1364-6613(00)01482-0
   Hoekert M, 2010, BMC NEUROSCI, V11, DOI 10.1186/1471-2202-11-93
   Hoekert M, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0002244
   JACOBSON L, 1991, ENDOCR REV, V12, P118, DOI 10.1210/edrv-12-2-118
   Janata P, 2012, J EXP PSYCHOL GEN, V141, P54, DOI 10.1037/a0024208
   Janata P, 2009, CEREB CORTEX, V19, P2579, DOI 10.1093/cercor/bhp008
   Johnstone T, 2006, SOC COGN AFFECT NEUR, V1, P242, DOI 10.1093/scan/nsl027
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Khalfa S, 2005, NEUROREPORT, V16, P1981, DOI 10.1097/00001756-200512190-00002
   Knight DC, 2005, NEUROIMAGE, V26, P1193, DOI 10.1016/j.neuroimage.2005.03.020
   Koelsch S, 2006, HUM BRAIN MAPP, V27, P239, DOI 10.1002/hbm.20180
   Koelsch S, 2014, NAT REV NEUROSCI, V15, P170, DOI 10.1038/nrn3666
   Koelsch S, 2013, NEUROIMAGE, V81, P49, DOI 10.1016/j.neuroimage.2013.05.008
   Koelsch S, 2010, TRENDS COGN SCI, V14, P131, DOI 10.1016/j.tics.2010.01.002
   Koelsch S, 2008, NEUROREPORT, V19, P1815, DOI 10.1097/WNR.0b013e32831a8722
   Kotz SA, 2003, BRAIN LANG, V86, P366, DOI 10.1016/S0093-934X(02)00532-1
   Kotz SA, 2013, HUM BRAIN MAPP, V34, P1971, DOI 10.1002/hbm.22041
   Kotz SA, 2010, TRENDS COGN SCI, V14, P392, DOI 10.1016/j.tics.2010.06.005
   Kotz SA, 2009, CORTEX, V45, P982, DOI 10.1016/j.cortex.2009.02.010
   Kreifelts B, 2010, HUM BRAIN MAPP, V31, P979, DOI 10.1002/hbm.20913
   Kriegeskorte N, 2006, P NATL ACAD SCI USA, V103, P3863, DOI 10.1073/pnas.0600244103
   Kringelbach ML, 2005, NAT REV NEUROSCI, V6, P691, DOI 10.1038/nrn1747
   Kringelbach ML, 2004, PROG NEUROBIOL, V72, P341, DOI 10.1016/j.pneurobio.2004.03.006
   Kumar S, 2012, J NEUROSCI, V32, P14184, DOI 10.1523/JNEUROSCI.1759-12.2012
   Laird AR, 2005, NEUROINFORMATICS, V3, P65, DOI 10.1385/NI:3:1:065
   Laricchiuta D, 2015, BRAIN STRUCT FUNCT, V220, P2275, DOI 10.1007/s00429-014-0790-0
   LEDOUX JE, 1990, J NEUROSCI, V10, P1062
   LeDoux J, 2012, NEURON, V73, P653, DOI 10.1016/j.neuron.2012.02.004
   Lee YS, 2011, NEUROIMAGE, V57, P293, DOI 10.1016/j.neuroimage.2011.02.006
   Lehne M, 2014, SOC COGN AFFECT NEUR, V9, P1515, DOI 10.1093/scan/nst141
   Leitman DI, 2011, FRONT HUM NEUROSCI, V5, DOI [10.3389/fnhum.2011.00096, 10.3389/fnhum.2010.00019]
   Mas-Herrero E, 2014, CURR BIOL, V24, P699, DOI 10.1016/j.cub.2014.01.068
   Menon V, 2005, NEUROIMAGE, V28, P175, DOI 10.1016/j.neuroimage.2005.05.053
   Menon V, 2010, BRAIN STRUCT FUNCT, V214, P655, DOI 10.1007/s00429-010-0262-0
   Meyer M, 2005, COGNITIVE BRAIN RES, V24, P291, DOI 10.1016/j.cogbrainres.2005.02.008
   Milesi V, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00275
   Mirz F, 2000, NEUROREPORT, V11, P633, DOI 10.1097/00001756-200002280-00039
   Mitchell RLC, 2007, NEUROIMAGE, V36, P1015, DOI 10.1016/j.neuroimage.2007.03.016
   Mitchell RLC, 2006, EUR J NEUROSCI, V24, P3611, DOI 10.1111/j.1460-9568.2006.05231.x
   Mitchell RLC, 2003, NEUROPSYCHOLOGIA, V41, P1410, DOI 10.1016/S0028-3932(03)00017-4
   Mitterschiffthaler MT, 2007, HUM BRAIN MAPP, V28, P1150, DOI 10.1002/hbm.20337
   Mizuno T, 2007, NEUROREPORT, V18, P1651, DOI 10.1097/WNR.0b013e3282f0b787
   Morris JS, 2001, NEUROIMAGE, V13, P1044, DOI 10.1006/nimg.2000.0721
   Morris JS, 1999, NEUROPSYCHOLOGIA, V37, P1155, DOI 10.1016/S0028-3932(99)00015-9
   Mothes-Lasch M, 2011, J NEUROSCI, V31, P9594, DOI 10.1523/JNEUROSCI.6665-10.2011
   Mueller K, 2011, NEUROIMAGE, V54, P337, DOI 10.1016/j.neuroimage.2010.08.029
   Müller VI, 2011, NEUROIMAGE, V54, P2257, DOI 10.1016/j.neuroimage.2010.10.047
   MURRAY IR, 1993, J ACOUST SOC AM, V93, P1097, DOI 10.1121/1.405558
   Panksepp J, 2002, BEHAV PROCESS, V60, P133, DOI 10.1016/S0376-6357(02)00080-3
   Panksepp J, 1995, MUSIC PERCEPT, V13, P171
   Pannese A, 2015, HEARING RES, V328, P67, DOI 10.1016/j.heares.2015.07.003
   Paradiso S, 2013, PSYCHIAT RES-NEUROIM, V211, P148, DOI 10.1016/j.pscychresns.2012.05.008
   Patel S, 2011, BIOL PSYCHOL, V87, P93, DOI 10.1016/j.biopsycho.2011.02.010
   Paulmann S, 2005, BRAIN LANG, V95, P143, DOI 10.1016/j.bandl.2005.07.079
   Paulmann S, 2008, BRAIN RES, V1217, P171, DOI 10.1016/j.brainres.2008.04.032
   Pell MD, 2003, COGN AFFECT BEHAV NE, V3, P275, DOI 10.3758/CABN.3.4.275
   Pell MD, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027256
   Pell MD, 2006, BRAIN LANG, V96, P221, DOI 10.1016/j.bandl.2005.04.007
   Péron J, 2011, PROG NEURO-PSYCHOPH, V35, P987, DOI 10.1016/j.pnpbp.2011.01.019
   Pessoa L, 2011, NAT REV NEUROSCI, V12, P425, DOI 10.1038/nrn2920-c2
   Pessoa L, 2010, NAT REV NEUROSCI, V11, P773, DOI 10.1038/nrn2920
   Phillips ML, 1998, P ROY SOC B-BIOL SCI, V265, P1809, DOI 10.1098/rspb.1998.0506
   Pichon S, 2013, J NEUROSCI, V33, P1640, DOI 10.1523/JNEUROSCI.3530-12.2013
   Popescu AT, 2009, NAT NEUROSCI, V12, P801, DOI 10.1038/nn.2305
   Quadflieg S, 2008, BIOL PSYCHOL, V78, P129, DOI 10.1016/j.biopsycho.2008.01.014
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Romanski LM, 2005, J NEUROPHYSIOL, V93, P734, DOI 10.1152/jn.00675.2004
   Ross ED, 2008, BRAIN LANG, V104, P51, DOI 10.1016/j.bandl.2007.04.007
   Rota G, 2008, EXP BRAIN RES, V186, P401, DOI 10.1007/s00221-007-1242-3
   Salimpoor VN, 2013, SCIENCE, V340, P216, DOI 10.1126/science.1231059
   Salimpoor VN, 2011, NAT NEUROSCI, V14, P257, DOI 10.1038/nn.2726
   Sander D, 2005, NEUROIMAGE, V28, P848, DOI 10.1016/j.neuroimage.2005.06.023
   Sander K, 2005, J COGNITIVE NEUROSCI, V17, P1519, DOI 10.1162/089892905774597227
   Sander K, 2003, BRAIN RES PROTOC, V11, P81, DOI 10.1016/S1385-299X(03)00018-7
   Sander K, 2007, HUM BRAIN MAPP, V28, P1007, DOI 10.1002/hbm.20333
   Saur D, 2008, P NATL ACAD SCI USA, V105, P18035, DOI 10.1073/pnas.0805234105
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   Schirmer A, 2004, NEUROIMAGE, V21, P1114, DOI 10.1016/j.neuroimage.2003.10.048
   Schirmer A, 2008, NEUROIMAGE, V40, P1402, DOI 10.1016/j.neuroimage.2008.01.018
   Schmahmann JD, 1998, BRAIN, V121, P561, DOI 10.1093/brain/121.4.561
   Schönwiesner M, 2005, EUR J NEUROSCI, V22, P1521, DOI 10.1111/j.1460-9568.2005.04315.x
   Schubotz RI, 2003, NEUROIMAGE, V20, P173, DOI 10.1016/S1053-8119(03)00218-0
   Schutter DJLG, 2009, J PSYCHIATR NEUROSCI, V34, P60
   Schwartze M, 2013, NEUROSCI BIOBEHAV R, V37, P2587, DOI 10.1016/j.neubiorev.2013.08.005
   Sergerie K, 2008, NEUROSCI BIOBEHAV R, V32, P811, DOI 10.1016/j.neubiorev.2007.12.002
   Sescousse G, 2013, NEUROSCI BIOBEHAV R, V37, P681, DOI 10.1016/j.neubiorev.2013.02.002
   Sescousse G, 2010, J NEUROSCI, V30, P13095, DOI 10.1523/JNEUROSCI.3501-10.2010
   Shabel SJ, 2009, P NATL ACAD SCI USA, V106, P15031, DOI 10.1073/pnas.0905580106
   Strata P, 2011, PHYSIOL RES, V60, pS39, DOI 10.33549/physiolres.932169
   Sundberg J, 2011, IEEE T AFFECT COMPUT, V2, P162, DOI 10.1109/T-AFFC.2011.14
   Suzuki M, 2008, COGN AFFECT BEHAV NE, V8, P126, DOI 10.3758/CABN.8.2.126
   Syka J, 1997, ACOUSTICAL SIGNAL PROCESSING IN THE CENTRAL AUDITORY SYSTEM, P431, DOI 10.1007/978-1-4419-8712-9_39
   Szameitat DP, 2010, NEUROIMAGE, V53, P1264, DOI 10.1016/j.neuroimage.2010.06.028
   Taylor KS, 2009, HUM BRAIN MAPP, V30, P2731, DOI 10.1002/hbm.20705
   Tölgyesi B, 2014, J NEUROL SCI, V343, P76, DOI 10.1016/j.jns.2014.05.036
   Tomlinson SP, 2013, NEUROSCI BIOBEHAV R, V37, P766, DOI 10.1016/j.neubiorev.2013.03.001
   Trost W, 2015, SOC COGN AFFECT NEUR, V10, P1705, DOI 10.1093/scan/nsv060
   Trost W, 2014, NEUROIMAGE, V103, P55, DOI 10.1016/j.neuroimage.2014.09.009
   Trost W, 2012, CEREB CORTEX, V22, P2769, DOI 10.1093/cercor/bhr353
   Viinikainen M, 2012, HUM BRAIN MAPP, V33, P2295, DOI 10.1002/hbm.21362
   Villanueva R, 2012, PSYCHIAT RES, V198, P527, DOI 10.1016/j.psychres.2012.02.023
   Vuilleumier P, 2005, TRENDS COGN SCI, V9, P585, DOI 10.1016/j.tics.2005.10.011
   Vuilleumier P, 2004, NAT NEUROSCI, V7, P1271, DOI 10.1038/nn1341
   Warren JE, 2006, J NEUROSCI, V26, P13067, DOI 10.1523/JNEUROSCI.3907-06.2006
   Weninger F, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00292
   Wenstrup JJ, 1999, J NEUROPHYSIOL, V82, P2528, DOI 10.1152/jn.1999.82.5.2528
   Wiethoff S, 2008, NEUROIMAGE, V39, P885, DOI 10.1016/j.neuroimage.2007.09.028
   Wildgruber D, 2005, NEUROIMAGE, V24, P1233, DOI 10.1016/j.neuroimage.2004.10.034
   Wildgruber D, 2004, CEREB CORTEX, V14, P1384, DOI 10.1093/cercor/bhh099
   Wildgruber D, 2002, NEUROIMAGE, V15, P856, DOI 10.1006/nimg.2001.0998
   Wittfoth M, 2010, CEREB CORTEX, V20, P383, DOI 10.1093/cercor/bhp106
   Zald DH, 2002, NEUROIMAGE, V16, P746, DOI 10.1006/nimg.2002.1115
   Zatorre RJ, 2001, CEREB CORTEX, V11, P946, DOI 10.1093/cercor/11.10.946
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 182
TC 121
Z9 135
U1 3
U2 69
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0149-7634
EI 1873-7528
J9 NEUROSCI BIOBEHAV R
JI Neurosci. Biobehav. Rev.
PD SEP
PY 2016
VL 68
BP 96
EP 110
DI 10.1016/j.neubiorev.2016.05.002
PG 15
WC Behavioral Sciences; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Behavioral Sciences; Neurosciences & Neurology
GA DV9WS
UT WOS:000383293500006
PM 27189782
OA Green Published, Green Submitted, Green Accepted, hybrid
DA 2024-01-09
ER

PT J
AU Ghirardini, C
AF Ghirardini, Cristina
TI The "right and natural call". Poetic improvisation in octave rhyme in
   central Italy Cristina Ghirardini
SO RIVISTA ITALIANA DI FILOSOFIA DEL LINGUAGGIO
LA Italian
DT Article
DE Improvised Poetry; Ottava rima; Poetic Dueling; Voice; Italian
   Traditional Music
AB Improvised poetry in octava rima in central Italy takes the form of public duels between two poets who make use of traditional melodic profiles to sing stanzas of eight hendecasyllables respecting the sequence of rhymes of the octava toscana . During a meeting in honor of a renowned improviser of the past - which took place in Massa Marittima (Grosseto) on 10 February 2019 - one of the poets (Pietro De Acutis) invited one of his colleagues (Marco Betti) to sing, according to what he considers "a fair and natural call". This article tries to shed light on the ethical and political aspects of this practice relying on Monica Ferrando's concept of poetic and musical nomos(Ferrando 2018), on Agamben's writings about the bilinguism inside language which becomes especially evident in poetry (Agamben 2019a, 2019b) and on his concept of museic nexus (Agamben 2016). Luciano Berio's notion of vocal gesture (vocal gesture, Berio 1967) and some reflections on the art of improvising poetry in octava rima expressed by the two poets while singing will be taken into consideration to underline the intricacies of sound, meaning and emotion in this practice of sung poetry.
C1 [Ghirardini, Cristina] Univ Huddersfield, Huddersfield, W Yorkshire, England.
C3 University of Huddersfield
RP Ghirardini, C (corresponding author), Univ Huddersfield, Huddersfield, W Yorkshire, England.
EM cristinaghirardini@tiscali.it
CR Abramov-van Rijk Elena, 2014, SINGING DANTE LIT OR
   Abramov-van Rijk Elena, 2009, PARLARCANTANDO PRACT
   Agamben Giorgio, 2019, NESSUNA LINGUA NESSU, P7
   AGAMBEN Giorgio, 2016, CHE COSE FILOSOFIA, P135
   Agamben Giorgio, 2019, GIARDINO STUDI FILOS, V2
   Agamennone Maurizio., 2002, Sul verso cantato. La poesia orale in una prospettiva etnomusicologica, P163
   Agamennone Maurizio., 2017, Cantar ottave. Per una storia culturale dell'intonazione cantata in ottava rima
   Agamennone Maurizio., 1986, I poeti contadini, P171
   [Anonymous], 2014, LUSO DEI CORPI
   Arcangeli Piero, 2001, SPOSA LAMENTAVA AMAT
   Berio Luciano, 2013, SCRITTI SULLA MUSICA, P58
   Bing Gertrud, 1966, RINASCITA PAGANESIMO, pVII
   Carchia Gianni, 2000, AMORE PENSIERO
   Carpitella Diego., 1977, Musica contadina dell'Aretino
   Da Sommacampagna Gidino., 1870, Trattato dei ritmi volgari. Da un Codice del Sec. XIV
   DEGLINNOCEN11 L., 2016, SUON QUESTA CETRA RI
   DeglInnocenti Luca, 2008, REALI ALTISSIMO CICL
   Di Ricco Alessandra, 1990, INUTILE MARAVIGLIOS
   FERRANDO Monica, 2018, REGNO ERRANTE
   Ghirardini Cristina., 2017, Fonti Musicali Italiane, V22, P55
   Kezich Giovanni., 1986, I poeti contadini
   Kezich Giovanni., 2013, Some Peasant Poets. An Odyssey in the Oral Poetry of Latium
   Lord Albert., 1960, The Singer of Tales
   Luzi Mario, 1995, NATURALEZZA POETA
   Perilli Berardino, 2019, CHE SE POSSA PORTA V
   Pianesi Mauro, 1986, THESIS
   Priore Dante, 2002, OTTAVA RIMA
   Tiezzi G., 2010, THESIS
   Tiezzi Grazia, 2012, NAVE POETI ANCORA VI, P119
   Tiezzi Grazia, 2009, ALBICOCCO RIGAGLIA R, P307
   Tomlinson G, 2004, READING THE EARLY MODERN PASSIONS: ESSAYS IN THE CULTURAL HISTORY OF EMOTION, P192
   Venturi G., 2011, UNO ALTRO ARIOSTO CO, P263
   Vitagliano Adele, 1905, STORIA POESIA ESTEMP
   Viveiros de Castro E., 2015, RELATIVE NATIVE
   Waquet Francoise, 1992, RHETHORIQUE POETIQUE
   Warburg Aby, 1966, RINASCITA PAGANESIMO
   Zanzotto Andrea, 1988, FILO
   Zanzotto Andrea, 2008, VIAGGIO MUSICALE CON
NR 38
TC 1
Z9 1
U1 0
U2 1
PU UNIV STUDI CALABRIA
PI ARCAVACATA DI RENDE
PA CAMPUS ARCAVACATA, VIA PIETRO BUCCI, ARCAVACATA DI RENDE, CS 87036,
   ITALY
SN 2036-6728
J9 RIV ITAL FILOS LINGU
JI Riv. Ital. Filos. Linguaggio
PY 2020
VL 14
IS 1
BP 97
EP 112
DI 10.4396/202012
PG 16
WC Language & Linguistics
WE Emerging Sources Citation Index (ESCI)
SC Linguistics
GA PM1KT
UT WOS:000603568000009
DA 2024-01-09
ER

PT J
AU Pond, N
   Leavens, D
AF Pond, Nathan
   Leavens, David
TI Comparing effects of sad melody versus sad lyrics on mood
SO PSYCHOLOGY OF MUSIC
LA English
DT Article; Early Access
DE music; emotion; music therapy; discrete emotions; lyrics; melody; BMIS
ID MUSIC; EMOTIONS; PERFORMANCE; PERCEPTION; EXPRESSION; INDUCTION;
   RESPONSES; LANGUAGE
AB While researchers have consistently found that music can evoke discrete emotions in people cross-culturally, there is little consensus regarding the mechanisms underpinning this effect. The present study aimed to gain further insight into how music influences emotions, investigating whether the lyrics or the melody of a sad piece of non-classical music had a greater influence on mood. The researchers presented a sample of 251 participants with isolated melody, isolated lyrics, and the original version of a sad pop-ballad in turn, measuring the influence of each on mood using the Brief Mood Introspection Scale (BMIS). A one-way repeated measures ANOVA revealed that all versions of the song significantly reduced mood scores from baseline, with the isolated lyrics and original version of the song reducing mood to a greater magnitude than the melody. The results suggested that both the lyrics and melody of the music influenced mood, though the lyrics appeared to do so to a greater extent. Furthermore, a thematic analysis of open-response questions provided preliminary evidence that the semantic content of lyrics was more influential on mood than the vocal expression of lyrics. Future research should aim to replicate these findings, using both positively and negatively emotionally valenced musical stimuli.
C1 [Pond, Nathan; Leavens, David] Univ Sussex, Sch Psychol, Brighton, England.
   [Leavens, David] Univ Sussex, Sch Psychol, Brighton BN1 9QH, England.
C3 University of Sussex; University of Sussex
RP Leavens, D (corresponding author), Univ Sussex, Sch Psychol, Brighton BN1 9QH, England.
EM davidl@sussex.ac.uk
OI Leavens, David/0000-0001-6538-4891; Pond, Nathan/0000-0002-6064-7637
FU School of Psychology, University of Sussex
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This
   research was funded by the School of Psychology, University of Sussex.
CR Ali SO., 2006, Psychology of Music, V34, P511, DOI DOI 10.1177/0305735606067168
   Bailey L. M., 1984, MUSIC THERAPY, V4, P5, DOI [10.1093/mt/4.1.5, DOI 10.1093/MT/4.1.5]
   Bowles L, 2019, NURS FORUM, V54, P340, DOI 10.1111/nuf.12334
   Brattico E, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00308
   Braun V., 2006, Qual. Res. Psychol, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Coutinho E, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179289
   CUNNINGHAM JG, 1988, MOTIV EMOTION, V12, P399, DOI 10.1007/BF00992362
   Eerola T, 2013, MUSIC PERCEPT, V30, P307, DOI [10.1525/mp.2012.30.3.307, 10.1525/MP.2012.30.1.49]
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Fiveash A, 2016, PSYCHOL MUSIC, V44, P1346, DOI 10.1177/0305735615628057
   Gabrielsson A., 2010, HDB MUSIC EMOTION TH, P367, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0014
   Gardiner MF, 2008, BEHAV BRAIN SCI, V31, P580, DOI 10.1017/S0140525X08005359
   Gerry D, 2012, DEVELOPMENTAL SCI, V15, P398, DOI 10.1111/j.1467-7687.2012.01142.x
   Goerlich KS, 2012, J COGNITIVE NEUROSCI, V24, P1725, DOI 10.1162/jocn_a_00213
   HANSER SB, 1994, J GERONTOL, V49, pP265, DOI 10.1093/geronj/49.6.P265
   Juslin P., 2019, Musical Emotions Explained, DOI DOI 10.1093/OSO
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2013, PHYS LIFE REV, V10, P235, DOI 10.1016/j.plrev.2013.05.008
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   KASTNER MP, 1990, MUSIC PERCEPT, V8, P189
   Koelsch S, 2006, HUM BRAIN MAPP, V27, P239, DOI 10.1002/hbm.20180
   Koelsch S, 2005, TRENDS COGN SCI, V9, P578, DOI 10.1016/j.tics.2005.10.001
   Koelsch S, 2004, NAT NEUROSCI, V7, P302, DOI 10.1038/nn1197
   Koelsch S, 2002, NEUROIMAGE, V17, P956, DOI 10.1016/S1053-8119(02)91154-7
   Laukka P, 2013, EMOTION, V13, P434, DOI 10.1037/a0031388
   Lennie TM, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.822264
   Mayer J. D., 1995, Journal of Mental Imagery, V19, P133
   MAYER JD, 1988, J PERS SOC PSYCHOL, V55, P102, DOI 10.1037/0022-3514.55.1.102
   MEDDIS R, 1972, BRIT J SOC CLIN PSYC, V11, P178, DOI 10.1111/j.2044-8260.1972.tb00799.x
   Mori K, 2014, PSYCHOL MUSIC, V42, P643, DOI 10.1177/0305735613483667
   Nawrot ES., 2003, Psychol. Music, V31, P75, DOI DOI 10.1177/0305735603031001325
   Patel AD, 2010, MUSIC LANGUAGE BRAIN
   Pieschl S, 2016, J MEDIA PSYCHOL-GER, V28, P32, DOI 10.1027/1864-1105/a000144
   Rabinowitch TC, 2013, PSYCHOL MUSIC, V41, P484, DOI 10.1177/0305735612440609
   Raglio A, 2008, ALZ DIS ASSOC DIS, V22, P158, DOI 10.1097/WAD.0b013e3181630b6f
   Ransom P. F., 2015, MESSAGE MUSIC DO LYR
   Saarikallio S, 2019, MUSIC EDUC RES, V21, P596, DOI 10.1080/14613808.2019.1670150
   Siedliecki SL, 2006, J ADV NURS, V54, P553, DOI 10.1111/j.1365-2648.2006.03860.x
   Sousou SD, 1997, PERCEPT MOTOR SKILL, V85, P31, DOI 10.2466/pms.1997.85.1.31
   Stratton V. N., 1994, Empir. Stud. Arts, V12, P173, DOI [10.2190/35T0-U4DT-N09Q-LQHW, DOI 10.2190/35T0-U4DT-N09Q-LQHW]
   Thaut M. H., 2010, HDB MUSIC EMOTION TH, P819
   Västfjäll D, 2001, MUSIC SCI, V5, P173
NR 43
TC 0
Z9 0
U1 10
U2 10
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0305-7356
EI 1741-3087
J9 PSYCHOL MUSIC
JI Psychol. Music
PD 2023 SEP 1
PY 2023
DI 10.1177/03057356231189680
EA SEP 2023
PG 14
WC Psychology, Educational; Psychology, Applied; Music; Psychology,
   Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Psychology; Music
GA Q4WR1
UT WOS:001057544600001
OA Green Published, hybrid
DA 2024-01-09
ER

PT J
AU Battcock, A
   Schutz, M
AF Battcock, Aimee
   Schutz, Michael
TI ACOUSTICALLY EXPRESSING AFFECT
SO MUSIC PERCEPTION
LA English
DT Article
DE emotion; perception; applied music cognition; valence; arousal
ID MAJOR MINOR DISTINCTION; EMOTIONAL RESPONSES; VOCAL EXPRESSION;
   DIMENSIONAL MODELS; MUSIC PERFORMANCE; CLASSICAL-MUSIC; PERCEPTION;
   PITCH; TEMPO; COMMUNICATION
AB COMPOSERS CONVEY EMOTION THROUGH MUSIC BY co-varying structural cues. Although the complex interplay provides a rich listening experience, this creates challenges for understanding the contributions of individual cues. Here we investigate how three specific cues (attack rate, mode, and pitch height) work together to convey emotion in Bach's Well Tempered-Clavier (WTC). In three experiments, we explore responses to (1) eight-measure excerpts and (2) musically "resolved" excerpts, and (3) investigate the role of different standard dimensional scales of emotion. In each experiment, thirty nonmusician participants rated perceived emotion along scales of valence and intensity (Experiments 1 & 2) or valence and arousal (Experiment 3) for 48 pieces in the WTC. Responses indicate listeners used attack rate, Mode, and pitch height to make judgements of valence, but only attack rate for intensity/arousal. Commonality analyses revealed mode predicted the most variance for valence ratings, followed by attack rate, with pitch height contributing minimally. In Experiment 2 mode increased in predictive power compared to Experiment 1. For Experiment 3, using "arousal" instead of "intensity" showed similar results to Experiment 1. We discuss how these results complement and extend previous findings of studies with tightly controlled stimuli, providing additional perspective on complex issues of interpersonal communication.
C1 [Battcock, Aimee; Schutz, Michael] McMaster Univ, Hamilton, ON, Canada.
C3 McMaster University
RP Battcock, A (corresponding author), McMaster Univ, Dept Psychol Neurosci & Behav, Psychol Bldg PC,Room 102,1280 Main St West, Hamilton, ON L8S 4K1, Canada.
EM battcoae@mcmaster.ca
OI Battcock, Aimee/0000-0003-2064-0382
FU Social Sciences and Humanities Research Council of Canada (SSHRC);
   Canadian Foundation for Innovation (CFI)
FX This research is supported in part by grants from Social Sciences and
   Humanities Research Council of Canada (SSHRC and the Canadian Foundation
   for Innovation (CFI).
CR Bach, 1973, BACH WELL TEMPERED C
   BACH J. S., 1965, BACH WELL TEMPERED C
   BACH J. S., 1971, BACH WELL TEMPERED C
   BACH J. S., 1953, BACH WELL TEMPERED C
   Bachorowski JA, 1999, CURR DIR PSYCHOL SCI, V8, P53, DOI 10.1111/1467-8721.00013
   BACHOROWSKI JA, 1995, PSYCHOL SCI, V6, P219, DOI 10.1111/j.1467-9280.1995.tb00596.x
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   BEATON A. E., 1973, COMMONALITY
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Borod J.C., 2000, The Neuropsychology of Emotions
   Breitenstein C, 2001, COGNITION EMOTION, V15, P57, DOI 10.1080/0269993004200114
   Broze Y, 2013, MUSIC PERCEPT, V31, P32, DOI 10.1525/MP.2013.31.1.32
   Capraro R, 2001, MULT LINEAR REGRES V, V27, P16
   Carroll J. M., 1999, Review of General Psychology, V3, P14, DOI DOI 10.1037/1089-2680.3.1.14
   Carvalho Larissa Paggioli de, 2016, Per musi, V0, P97, DOI 10.1590/permusi20163305
   Chordia P., 2010, P 11 INT C MUS PERC, P63
   Cohen J., 2002, Applied Multiple Correlation/Regression Analysis for the Behavioral Sciences, V3rd, DOI [DOI 10.1002/0471264385.WEI0219, 10.1002/0471264385.wei0219, 10.4324/9780203774441]
   Collier WG, 2001, AM J PSYCHOL, V114, P355, DOI 10.2307/1423686
   Corrigall KA, 2014, DEVELOPMENTAL SCI, V17, P142, DOI 10.1111/desc.12100
   Costa M, 2004, MUSIC PERCEPT, V22, P1, DOI 10.1525/mp.2004.22.1.1
   CROWDER RG, 1985, B PSYCHONOMIC SOC, V23, P314
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Dean RT, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018591
   Dibben N, 2004, MUSIC PERCEPT, V22, P79, DOI 10.1525/mp.2004.22.1.79
   Eerola T., 2009, Proceedings of the International Conference on Music Information Retrieval ISMIR, P621
   Eerola T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00487
   Eerola T, 2013, MUSIC PERCEPT, V30, P307, DOI [10.1525/mp.2012.30.3.307, 10.1525/MP.2012.30.1.49]
   Eerola T, 2011, J NEW MUSIC RES, V40, P349, DOI 10.1080/09298215.2011.602195
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   Eitan Z, 2010, COGNITION, V114, P405, DOI 10.1016/j.cognition.2009.10.013
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Fabian D, 2003, MUSIC SCI, P49
   Frederick BN, 1999, ADV SOC SCI, V5, P305
   Friberg A, 2014, J ACOUST SOC AM, V136, P1951, DOI 10.1121/1.4892767
   GABRIELSSON A, 2002, MUSIC SCI, V6, P123, DOI [10.3389/fpsyg.2013.00837, DOI 10.3389/FPSYG.2013.00837]
   Gabrielsson A., 2010, HDB MUSIC EMOTION TH, P367, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0014
   Gagnon L, 2003, COGNITION EMOTION, V17, P25, DOI 10.1080/02699930302279
   Gardner H., 1999, Multiple Intelligence: The Theory in Practice
   GERARDI GM, 1995, MUSIC PERCEPT, V12, P279
   Gomez P, 2004, INT J PSYCHOPHYSIOL, V53, P91, DOI 10.1016/j.ijpsycho.2004.02.002
   Gomez P, 2007, EMOTION, V7, P377, DOI 10.1037/1528-3542.7.2.377
   Gundlach RH, 1935, AM J PSYCHOL, V47, P624, DOI 10.2307/1416007
   Hailstone JC, 2009, Q J EXP PSYCHOL, V62, P2141, DOI 10.1080/17470210902765957
   HATTEN Robert S., 2004, Interpreting Musical Gestures, Topics, and Tropes
   Heinlein CP, 1928, J COMP PSYCHOL, V8, P101, DOI 10.1037/h0070573
   Hevner K, 1936, AM J PSYCHOL, V48, P246, DOI 10.2307/1415746
   Hevner K, 1935, AM J PSYCHOL, V47, P103, DOI 10.2307/1416710
   Hevner K, 1937, AM J PSYCHOL, V49, P621, DOI 10.2307/1416385
   Horn K, 2015, MUSIC THEORY ONLINE, V21
   Hunter PG, 2008, COGNITION EMOTION, V22, P327, DOI 10.1080/02699930701438145
   Hunter PG, 2010, PSYCHOL AESTHET CREA, V4, P47, DOI 10.1037/a0016873
   Husain G, 2002, MUSIC PERCEPT, V20, P151, DOI 10.1525/mp.2002.20.2.151
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Johnstone T., 2000, Handbook of Emotions, V2nd ed., P220
   Juslin PN, 2010, MUSIC ANAL, V29, P334, DOI 10.1111/j.1468-2249.2011.00323.x
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 1999, MUSIC PERCEPT, V17, P197
   Juslin PN, 1997, MUSIC PERCEPT, V14, P383
   KASTNER MP, 1990, MUSIC PERCEPT, V8, P189
   Koelsch S, 2004, NAT NEUROSCI, V7, P302, DOI 10.1038/nn1197
   Korhonen MD, 2006, IEEE T SYST MAN CY B, V36, P588, DOI 10.1109/TSMCB.2005.862491
   Laukka P, 2013, EMOTION, V13, P434, DOI 10.1037/a0031388
   Leman M, 2005, J NEW MUSIC RES, V34, P39, DOI 10.1080/09298210500123978
   Lindström E, 2006, MUSIC SCI, V10, P85, DOI 10.1177/102986490601000105
   Luck G, 2008, PSYCHOL MUSIC, V36, P25, DOI 10.1177/0305735607079714
   Meyer LB., 1956, Emotion and meaning in music
   Mote J, 2011, EMOTION, V11, P618, DOI 10.1037/a0022573
   Pallesen KJ, 2005, ANN NY ACAD SCI, V1060, P450, DOI 10.1196/annals.1360.047
   PALMER W. A., 1994, JS BACH WELL TEMPERE
   Pedhazur E. J., 1997, Multiple Regression in Behavioural Research, V3rd ed
   Peirce J, 2019, BEHAV RES METHODS, V51, P195, DOI 10.3758/s13428-018-01193-y
   POON M., 2015, FRONT PSYCHOL, V6, P1
   Post O, 2009, EMPIR MUSICOL REV, V4, P2, DOI 10.18061/1811/36601
   Quinto L, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00184
   Ray-Mukherjee J, 2014, METHODS ECOL EVOL, V5, P320, DOI 10.1111/2041-210X.12166
   Rigg MG, 1940, J EXP PSYCHOL, V27, P566, DOI 10.1037/h0058652
   Rodà A, 2014, IEEE T AFFECT COMPUT, V5, P364, DOI 10.1109/TAFFC.2014.2343222
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Schellenberg EG, 2000, MUSIC PERCEPT, V18, P155
   Scherer K., 1977, MOTIV EMOTION, V1, P331, DOI [DOI 10.1007/BF00992539, 10.1007/bf00992539]
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Schimmack U, 2000, EUR J PERSONALITY, V14, P325, DOI 10.1002/1099-0984(200007/08)14:4<325::AID-PER380>3.0.CO;2-I
   Schmidt LA, 2001, COGNITION EMOTION, V15, P487, DOI 10.1080/0269993004200187
   Schubert E, 2004, MUSIC PERCEPT, V21, P561, DOI 10.1525/mp.2004.21.4.561
   Schubert E, 1999, AUST J PSYCHOL, V51, P154, DOI 10.1080/00049539908255353
   SCHUTZ M, 2017, CRATSCHLA, P8
   Tan SS, 2010, IEEE CUST INTEGR CIR
   Temperley D, 2013, J NEW MUSIC RES, V42, P187, DOI 10.1080/09298215.2013.788039
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   Vuoskoski JK, 2011, MUSIC SCI, V15, P159, DOI 10.1177/1029864911403367
   WATSON KB, 1942, PSYCHOL MONOGRAPHS, V54
   Webster GD, 2005, MOTIV EMOTION, V29, P19, DOI 10.1007/s11031-005-4414-0
   WEDIN L, 1972, SCAND J PSYCHOL, V13, P241, DOI 10.1111/j.1467-9450.1972.tb00072.x
   WEDIN L., 1972, PSYCHOL LAB, V54, P1
   WEDIN L., 1969, SWEDISH J MUSICOLOGY, V51, P119
   Wiggins GA, 1998, P 1 S MUS COMP CORF, P18
   Yang YH, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168754
NR 99
TC 6
Z9 6
U1 1
U2 5
PU UNIV CALIFORNIA PRESS
PI OAKLAND
PA 155 GRAND AVE, SUITE 400, OAKLAND, CA 94612-3758 USA
SN 0730-7829
J9 MUSIC PERCEPT
JI Music Percept.
PD SEP
PY 2019
VL 37
IS 1
BP 66
EP 91
DI 10.1525/MP.2019.37.1.66
PG 26
WC Music; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music; Psychology
GA NT9QZ
UT WOS:000573277500005
DA 2024-01-09
ER

PT J
AU Chari, DA
   Barrett, KC
   Patel, AD
   Colgrove, TR
   Jiradejvong, P
   Jacobs, LY
   Limb, CJ
AF Chari, Divya A.
   Barrett, Karen C.
   Patel, Aniruddh D.
   Colgrove, Thomas R.
   Jiradejvong, Patpong
   Jacobs, Lauren Y.
   Limb, Charles J.
TI Impact of Auditory-Motor Musical Training on Melodic Pattern Recognition
   in Cochlear Implant Users
SO OTOLOGY & NEUROTOLOGY
LA English
DT Article
DE Auditory-motor training; Cochlear implants; Music; Music training;
   Pitch-based speech prosody; Vocal emotion
ID IN-NOISE PERCEPTION; CONTOUR IDENTIFICATION; SPEECH RECOGNITION;
   HEARING; PROSODY; CHILDREN; BATTERY
AB Objective:Cochlear implant (CI) users struggle with tasks of pitch-based prosody perception. Pitch pattern recognition is vital for both music comprehension and understanding the prosody of speech, which signals emotion and intent. Research in normal-hearing individuals shows that auditory-motor training, in which participants produce the auditory pattern they are learning, is more effective than passive auditory training. We investigated whether auditory-motor training of CI users improves complex sound perception, such as vocal emotion recognition and pitch pattern recognition, compared with purely auditory training.Study Design:Prospective cohort study.Setting:Tertiary academic center.Patients:Fifteen postlingually deafened adults with CIs.Intervention(s):Participants were divided into 3 one-month training groups: auditory-motor (intervention), auditory-only (active control), and no training (control). Auditory-motor training was conducted with the "Contours" software program and auditory-only training was completed with the "AngelSound" software program.Main Outcome Measure:Pre and posttest examinations included tests of speech perception (consonant-nucleus-consonant, hearing-in-noise test sentence recognition), speech prosody perception, pitch discrimination, and melodic contour identification.Results:Participants in the auditory-motor training group performed better than those in the auditory-only and no-training (p<0.05) for the melodic contour identification task. No significant training effect was noted on tasks of speech perception, speech prosody perception, or pitch discrimination.Conclusions:These data suggest that short-term auditory-motor music training of CI users impacts pitch pattern recognition. This study offers approaches for enriching the world of complex sound in the CI user.
C1 [Chari, Divya A.; Barrett, Karen C.; Jiradejvong, Patpong; Jacobs, Lauren Y.; Limb, Charles J.] Univ Calif San Francisco, Dept Otolaryngol Head & Neck Surg, San Francisco, CA USA.
   [Patel, Aniruddh D.] Tufts Univ, Dept Psychol, Medford, MA 02155 USA.
   [Patel, Aniruddh D.] Canadian Inst Adv Res CIFAR, Azrieli Program Brain Mind & Consciousness, Toronto, ON, Canada.
   [Colgrove, Thomas R.] Tufts Univ, Dept Comp Sci, Medford, MA 02155 USA.
C3 University of California System; University of California San Francisco;
   Tufts University; Canadian Institute for Advanced Research (CIFAR);
   Tufts University
RP Limb, CJ (corresponding author), Univ Calif San Francisco, Dept Otolaryngol, 2233 Post St,3rd Floor, San Francisco, CA 94115 USA.
EM Charles.Limb@ucsf.edu
RI Jacobs, Lauren/JFS-4701-2023; Barrett, Karen Chan/AAO-7398-2021
OI Barrett, Karen Chan/0000-0002-8991-4778
FU Hearing Research Institute
FX The authors would like to thank the Hearing Research Institute for
   providing funding for support of this study.
CR Barrett KC, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00713
   Bench J, 1979, Br J Audiol, V13, P108, DOI 10.3109/03005367909078884
   Chatterjee M, 2015, HEARING RES, V322, P151, DOI 10.1016/j.heares.2014.10.003
   Cheng XT, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518759214
   Coffey EBJ, 2017, HEARING RES, V352, P49, DOI 10.1016/j.heares.2017.02.006
   Colgrove TR, 2016, P 14 INT C MUS PERC, P39
   Cooper WB, 2008, EAR HEARING, V29, P618, DOI 10.1097/AUD.0b013e318174e787
   Cullington HE, 2011, EAR HEARING, V32, P16, DOI 10.1097/AUD.0b013e3181edfbd2
   D'Alessandro HD, 2018, EAR HEARING, V39, P679, DOI 10.1097/AUD.0000000000000525
   Deroche MLD, 2012, J ACOUST SOC AM, V131, P2938, DOI 10.1121/1.3692230
   Forgeard Marie, 2008, PLoS One, V3, pe3566, DOI 10.1371/journal.pone.0003566
   François C, 2013, CEREB CORTEX, V23, P2038, DOI 10.1093/cercor/bhs180
   Friesen LM, 2001, J ACOUST SOC AM, V110, P1150, DOI 10.1121/1.1381538
   Fu Qian-Jie, 2007, Trends Amplif, V11, P193, DOI 10.1177/1084713807301379
   Fuller CD, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518765379
   Galvin JJ, 2007, EAR HEARING, V28, P302, DOI 10.1097/01.aud.0000261689.35445.20
   Galvin JJ, 2009, ANN NY ACAD SCI, V1169, P518, DOI 10.1111/j.1749-6632.2009.04551.x
   Gfeller Kate, 2002, J Am Acad Audiol, V13, P132
   Gfeller Kate, 2015, Cochlear Implants Int, V16 Suppl 3, pS22, DOI 10.1179/1467010015Z.000000000269
   Gfeller Kate, 2002, Cochlear Implants Int, V3, P29, DOI 10.1179/cim.2002.3.1.29
   Good A, 2017, EAR HEARING, V38, P455, DOI 10.1097/AUD.0000000000000402
   Hannon EE, 2007, TRENDS COGN SCI, V11, P466, DOI 10.1016/j.tics.2007.08.008
   Hausen M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00566
   Herholz SC, 2012, NEURON, V76, P486, DOI 10.1016/j.neuron.2012.10.011
   Jiam NT, 2019, JARO-J ASSOC RES OTO, V20, P247, DOI 10.1007/s10162-018-00704-0
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Lappe C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021493
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Limb CJ, 2014, HEARING RES, V308, P13, DOI 10.1016/j.heares.2013.04.009
   Limb Charles J, 2006, Curr Opin Otolaryngol Head Neck Surg, V14, P337, DOI 10.1097/01.moo.0000244192.59184.bd
   Lo CY, 2015, BEHAV NEUROL, V2015, DOI 10.1155/2015/352869
   Luxford WM, 2001, OTOLARYNG HEAD NECK, V124, P125, DOI 10.1067/mhn.2001.113035
   McDermott Hugh J, 2004, Trends Amplif, V8, P49, DOI 10.1177/108471380400800203
   McKay CM, 1996, J ACOUST SOC AM, V100, P1081, DOI 10.1121/1.416294
   Novembre G, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00603
   Patel AD, 2014, HEARING RES, V308, P98, DOI 10.1016/j.heares.2013.08.011
   Petersen B., 2012, Psychomusicol Music Mind Brain, V22, P134, DOI DOI 10.1037/A0031140
   Slater J, 2015, BEHAV BRAIN RES, V291, P244, DOI 10.1016/j.bbr.2015.05.026
   Stracke Henning, 2010, Commun Integr Biol, V3, P274
   Swaminathan J, 2015, SCI REP-UK, V5, DOI 10.1038/srep11628
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Veekmans K, 2009, AUDIOL NEURO-OTOL, V14, P315, DOI 10.1159/000212111
   Vongpaisal T, 2016, FRONT PSYCHOL, V7, DOI 10.3359/fpsyg.2016.00835
   Wang WQ, 2011, INT J AUDIOL, V50, P270, DOI 10.3109/14992027.2010.542490
NR 44
TC 12
Z9 12
U1 3
U2 23
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 1531-7129
EI 1537-4505
J9 OTOL NEUROTOL
JI Otol. Neurotol.
PD APR
PY 2020
VL 41
IS 4
BP E422
EP E431
DI 10.1097/MAO.0000000000002525
PG 10
WC Clinical Neurology; Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Neurosciences & Neurology; Otorhinolaryngology
GA MF0FC
UT WOS:000545027400002
PM 32176126
DA 2024-01-09
ER

PT J
AU Fuller, CD
   Galvin, JJ
   Maat, B
   Baskent, D
   Free, RH
AF Fuller, Christina D.
   Galvin, John J., III
   Maat, Bert
   Baskent, Deniz
   Free, Rolien H.
TI Comparison of Two Music Training Approaches on Music and Speech
   Perception in Cochlear Implant Users
SO TRENDS IN HEARING
LA English
DT Article
DE cochlear implants; music therapy; music training; auditory perception
ID MELODIC CONTOUR IDENTIFICATION; QUALITY-OF-LIFE; PITCH PERCEPTION;
   NOISE; RECOGNITION; INSTRUMENT; DISCRIMINATION; ADULTS; APPRECIATION;
   PERFORMANCE
AB In normal-hearing (NH) adults, long-term music training may benefit music and speech perception, even when listening to spectro-temporally degraded signals as experienced by cochlear implant (CI) users. In this study, we compared two different music training approaches in CI users and their effects on speech and music perception, as it remains unclear which approach to music training might be best. The approaches differed in terms of music exercises and social interaction. For the pitch/ timbre group, melodic contour identification (MCI) training was performed using computer software. For the music therapy group, training involved face-to-face group exercises (rhythm perception, musical speech perception, music perception, singing, vocal emotion identification, and music improvisation). For the control group, training involved group nonmusic activities (e. g., writing, cooking, and woodworking). Training consisted of weekly 2-hr sessions over a 6-week period. Speech intelligibility in quiet and noise, vocal emotion identification, MCI, and quality of life (QoL) were measured before and after training. The different training approaches appeared to offer different benefits for music and speech perception. Training effects were observed within-domain (better MCI performance for the pitch/timbre group), with little cross-domain transfer of music training (emotion identification significantly improved for the music therapy group). While training had no significant effect on QoL, the music therapy group reported better perceptual skills across training sessions. These results suggest that more extensive and intensive training approaches that combine pitch training with the social aspects of music therapy may further benefit CI users.
C1 [Fuller, Christina D.; Galvin, John J., III; Maat, Bert; Baskent, Deniz; Free, Rolien H.] Univ Groningen, Univ Med Ctr Groningen, Dept Otorhinolaryngol Head & Neck Surg, BB20 POB 30-001, NL-9700 RB Groningen, Netherlands.
   [Fuller, Christina D.; Galvin, John J., III; Maat, Bert; Baskent, Deniz; Free, Rolien H.] Univ Groningen, Univ Med Ctr Groningen, Grad Sch Med Sci, Groningen, Netherlands.
   [Fuller, Christina D.; Galvin, John J., III; Maat, Bert; Baskent, Deniz; Free, Rolien H.] Univ Groningen, Univ Med Ctr Groningen, Res Sch Behav & Cognit Neurosci, Groningen, Netherlands.
   [Galvin, John J., III] House Ear Res Inst, Los Angeles, CA USA.
   [Galvin, John J., III] Univ Calif Los Angeles, David Geffen Sch Med, Dept Head & Neck Surg, Los Angeles, CA 90095 USA.
C3 University of Groningen; University of Groningen; University of
   Groningen; House Research Institute; University of California System;
   University of California Los Angeles; University of California Los
   Angeles Medical Center; David Geffen School of Medicine at UCLA
RP Fuller, CD (corresponding author), Univ Groningen, Univ Med Ctr Groningen, Dept Otorhinolaryngol Head & Neck Surg, BB20 POB 30-001, NL-9700 RB Groningen, Netherlands.
EM c.d.fuller@umcg.nl
OI Baskent, Deniz/0000-0002-6560-1451
FU Rosalind Franklin Fellowship from the University Medical Center
   Groningen, University of Groningen; VIDI grant from the Netherlands
   Organization for Scientific Research [016.096.397]; Netherlands
   Organization for Health Research and Development; Heinsius-Houbolt
   Foundation; Advanced Bionics
FX The authors disclosed receipt of the following financial support for the
   research, authorship, and/or publication of this article: Deniz Baskent
   is supported by a Rosalind Franklin Fellowship from the University
   Medical Center Groningen, University of Groningen, and the VIDI grant
   016.096.397 from the Netherlands Organization for Scientific Research
   and the Netherlands Organization for Health Research and Development.
   Rolien Free is supported by an otological/neurotological stipendium from
   the Heinsius-Houbolt Foundation. Part of the study is funded by a
   research grant from Advanced Bionics.
CR Amitay S, 2005, PERCEPT PSYCHOPHYS, V67, P691, DOI 10.3758/BF03193525
   ASSMANN PF, 1990, J ACOUST SOC AM, V88, P680, DOI 10.1121/1.399772
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Baskent D., 2016, SCI FDN AUDIOLOGY PE, P285
   Baskent D, 2016, J ACOUST SOC AM, V139, pEL51, DOI 10.1121/1.4942628
   Besson M, 2007, RESTOR NEUROL NEUROS, V25, P399
   Blamey P, 2013, AUDIOL NEURO-OTOL, V18, P36, DOI 10.1159/000343189
   Boebinger D, 2015, J ACOUST SOC AM, V137, P378, DOI 10.1121/1.4904537
   Bosman AJ, 1995, AUDIOLOGY, V34, P260
   Brungart DS, 2001, J ACOUST SOC AM, V109, P1101, DOI 10.1121/1.1345696
   Chartrand JP, 2006, NEUROSCI LETT, V405, P164, DOI 10.1016/j.neulet.2006.06.053
   Chen JL, 2008, CEREB CORTEX, V18, P2844, DOI 10.1093/cercor/bhn042
   Clayton KK, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157638
   Deroche MLD, 2017, J ACOUST SOC AM, V142, P1739, DOI 10.1121/1.5005496
   Dmitrieva E S, 2006, Neurosci Behav Physiol, V36, P53, DOI 10.1007/s11055-005-0162-6
   Donnelly S, 1996, PALLIATIVE MED, V10, P275, DOI 10.1177/026921639601000402
   Drennan WR, 2008, J REHABIL RES DEV, V45, P779, DOI 10.1682/JRRD.2007.08.0118
   Dreschler WA, 2001, AUDIOLOGY, V40, P148
   Driscoll Virginia D., 2012, Seminars in Hearing, V33, P410, DOI 10.1055/s-0032-1329230
   Fu QJ, 2008, HEARING RES, V242, P198, DOI 10.1016/j.heares.2007.11.010
   Fu QJ, 2015, J SPEECH LANG HEAR R, V58, P163, DOI 10.1044/2014_JSLHR-H-14-0127
   Fu Qian-Jie, 2007, Seminars in Hearing, V28, P142, DOI 10.1055/s-2007-973440
   Fuller C, 2013, OTOL NEUROTOL, V34, P1041, DOI 10.1097/MAO.0b013e31828f47dd
   Fuller CD, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00179
   Galvin JJ, 2008, J ACOUST SOC AM, V124, pEL189, DOI 10.1121/1.2961171
   Galvin JJ, 2007, EAR HEARING, V28, P302, DOI 10.1097/01.aud.0000261689.35445.20
   Galvin John J. III, 2012, Seminars in Hearing, V33, P399, DOI 10.1055/s-0032-1329227
   Galvin JJ, 2009, ANN NY ACAD SCI, V1169, P518, DOI 10.1111/j.1749-6632.2009.04551.x
   Galvin JJ, 2009, J ACOUST SOC AM, V125, pEL98, DOI 10.1121/1.3062148
   Gfeller K, 2000, J Am Acad Audiol, V11, P390
   Gfeller K., 2001, Music Therapy Perspect, V19, P88, DOI DOI 10.1093/MTP/19.2.88
   Gfeller K, 2007, EAR HEARING, V28, P412, DOI 10.1097/AUD.0b013e3180479318
   Gfeller Kate, 2002, J Am Acad Audiol, V13, P132
   Gfeller Kate, 2015, Cochlear Implants Int, V16 Suppl 3, pS22, DOI 10.1179/1467010015Z.000000000269
   Gilbers S, 2015, I-PERCEPTION, V6, DOI 10.1177/0301006615599139
   Goudbeek M., 2010, 7 INT C LANG RES EV, P2211
   Herholz SC, 2012, NEURON, V76, P486, DOI 10.1016/j.neuron.2012.10.011
   Hilliard RE, 2003, J MUSIC THER, V40, P113, DOI 10.1093/jmt/40.2.113
   Hinderink JB, 2000, OTOLARYNG HEAD NECK, V123, P756, DOI 10.1067/mhn.2000.108203
   House D., 1994, 3 INT C SPOK LANG PR
   Hubbard DJ, 2013, J ACOUST SOC AM, V133, P2367, DOI 10.1121/1.4792145
   Hutter E, 2015, Cochlear Implants Int, V16 Suppl 3, pS13, DOI 10.1179/1467010015Z.000000000261
   Ingvalson EM, 2013, J SPEECH LANG HEAR R, V56, P81, DOI 10.1044/1092-4388(2012/11-0291)
   Jiam NT, 2017, HEARING RES, V352, P30, DOI 10.1016/j.heares.2017.01.006
   Kong YY, 2004, EAR HEARING, V25, P173, DOI 10.1097/01.AUD.0000120365.97792.2F
   Lassaletta L, 2008, ACTA OTORRINOLAR ESP, V59, P228, DOI 10.1016/S0001-6519(08)73300-4
   Limb CJ, 2014, HEARING RES, V308, P13, DOI 10.1016/j.heares.2013.04.009
   Lo CY, 2015, BEHAV NEUROL, V2015, DOI 10.1155/2015/352869
   Loebach JL, 2008, J ACOUST SOC AM, V123, P1126, DOI 10.1121/1.2823453
   Looi V., 2016, ADV OTOLARYNGOLOGY
   Looi Valerie, 2012, Seminars in Hearing, V33, P307, DOI 10.1055/s-0032-1329222
   Looi V, 2010, INT J AUDIOL, V49, P116, DOI 10.3109/14992020903405987
   Luo X, 2009, HEARING RES, V256, P75, DOI 10.1016/j.heares.2009.07.001
   Madsen SMK, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12937-9
   Marques C, 2007, J COGNITIVE NEUROSCI, V19, P1453, DOI 10.1162/jocn.2007.19.9.1453
   McDermott Hugh J, 2004, Trends Amplif, V8, P49, DOI 10.1177/108471380400800203
   McDermott JH, 2008, CURR OPIN NEUROBIOL, V18, P452, DOI 10.1016/j.conb.2008.09.005
   Mehta AH, 2017, JARO-J ASSOC RES OTO, V18, P789, DOI 10.1007/s10162-017-0632-x
   Migchelbrink F., 2000, PRAKTIJKGERICHT ONDE
   Moore DR, 2005, BRAIN LANG, V94, P72, DOI 10.1016/j.bandl.2004.11.009
   Morse-Fortier C, 2017, TRENDS HEAR, V21, DOI 10.1177/2331216517739427
   Oba SI, 2011, EAR HEARING, V32, P573, DOI 10.1097/AUD.0b013e31820fc821
   Parbery-Clark A, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018082
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Patel AD, 2014, HEARING RES, V308, P98, DOI 10.1016/j.heares.2013.08.011
   Patel AD, 2012, ANN NY ACAD SCI, V1252, P124, DOI 10.1111/j.1749-6632.2011.06426.x
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Pereira C, 2000, Cochlear Implants, P343
   Peretz I, 2005, ANNU REV PSYCHOL, V56, P89, DOI 10.1146/annurev.psych.56.091103.070225
   Petersen B., 2012, Psychomusicol Music Mind Brain, V22, P134, DOI DOI 10.1037/A0031140
   Philips B, 2012, EUR ARCH OTO-RHINO-L, V269, P813, DOI 10.1007/s00405-011-1718-4
   PLOMP R, 1979, J ACOUST SOC AM, V66, P1333, DOI 10.1121/1.383554
   Ruggles DR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086980
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Shannon RV, 2004, ACTA OTO-LARYNGOL, V124, P50, DOI 10.1080/03655230410017562
   Smith ZM, 2002, NATURE, V416, P87, DOI 10.1038/416087a
   Stacey PC, 2008, J SPEECH LANG HEAR R, V51, P526, DOI 10.1044/1092-4388(2008/038)
   Stacey PC, 2007, J ACOUST SOC AM, V121, P2923, DOI 10.1121/1.2713668
   Stacey PC, 2010, INT J AUDIOL, V49, P347, DOI 10.3109/14992020903397838
   Swaminathan J, 2015, SCI REP-UK, V5, DOI 10.1038/srep11628
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Vandali A, 2015, EAR HEARING, V36, pE1, DOI 10.1097/AUD.0000000000000109
   Walworth D, 2008, J MUSIC THER, V45, P349, DOI 10.1093/jmt/45.3.349
   Wright BA, 1997, J NEUROSCI, V17, P3956
   Xin Luo, 2007, Trends Amplif, V11, P301
   Zendel BR, 2012, PSYCHOL AGING, V27, P410, DOI 10.1037/a0024816
   Zuk J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0080546
NR 87
TC 35
Z9 37
U1 2
U2 46
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 2331-2165
J9 TRENDS HEAR
JI Trends Hear.
PD APR 6
PY 2018
VL 22
AR 2331216518765379
DI 10.1177/2331216518765379
PG 22
WC Audiology & Speech-Language Pathology; Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Audiology & Speech-Language Pathology; Otorhinolaryngology
GA GC0EQ
UT WOS:000429450100001
PM 29621947
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Morneau-Sévigny, F
   Pouliot, J
   Presseau, S
   Ratté, MH
   Tremblay, MP
   Macoir, J
   Hudon, C
AF Morneau-Sevigny, Flore
   Pouliot, Joannie
   Presseau, Sophie
   Ratte, Marie-Helene
   Tremblay, Marie-Pier
   Macoir, Joel
   Hudon, Carol
TI Validation of emotional prosodic stimuli in Quebec-French for 50-80
   years
SO CANADIAN JOURNAL ON AGING-REVUE CANADIENNE DU VIEILLISSEMENT
LA French
DT Article
DE Aging; Emotion recognition; Prosody; Validation
ID FACIAL EXPRESSIONS; VOCAL EXPRESSION; RECOGNITION; MUSIC; SPEECH; FACE;
   CUES; AGE
AB Few batteries of prosodic stimuli testing have been validated for Quebec-French people. Such validation is necessary to develop auditory-verbal tasks in this population. The objective of this study was to validate a battery of emotional prosodic stimuli for French-Quebec aging subjects. The battery of 195 stimuli, which was elaborated by Maurage et al. (2007), is composed of 195 prosodic stimuli and was administrated to 50 healthy Quebecers aged 50-to-80 years. The percentages of good responses were calculated for each stimulus. For each emotion, Cronbach's alphas were calculated to evaluate the internal consistency of the stimuli. Results showed that among the 195 stimuli, 40 were correctly recognized by at least 80 per cent of the subjects. Anger was the emotion that was most correctly identified by the participants, while recognition of disgust was the least recognised. Overall, this study provides data that will guide the selection of prosodic stimuli in evaluating French-Quebecois.
C1 [Morneau-Sevigny, Flore; Pouliot, Joannie; Presseau, Sophie; Ratte, Marie-Helene; Tremblay, Marie-Pier; Hudon, Carol] Univ Laval, Ecole Psychol, Quebec City, PQ, Canada.
   [Macoir, Joel; Hudon, Carol] Inst Univ Sante Mentale Qubec, Ctr Rech, Quebec City, PQ, Canada.
   [Macoir, Joel] Univ Laval, Dept Readaptat, Quebec City, PQ, Canada.
C3 Laval University; Laval University
RP Hudon, C (corresponding author), 2325 Rue Bibliotheques,Pavillon Felix Antoine Sav, Quebec City, PQ G1V 0A6, Canada.
EM Carol.Hudon@psy.ulaval.ca
RI Macoir, Joël/AAQ-6061-2021; Macoir, Joel/GYA-0703-2022
OI Macoir, Joël/0000-0002-6661-430X; Macoir, Joel/0000-0002-6661-430X;
   Hudon, Carol/0000-0002-7554-3187
CR Adolphs R, 2002, EMOTION, V2, P23, DOI 10.1037/1528-3542.2.1.23
   Bänziger T, 2009, EMOTION, V9, P691, DOI 10.1037/a0017088
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Biehl M, 1997, J NONVERBAL BEHAV, V21, P3, DOI 10.1023/A:1024902500935
   Bonin P, 2003, BEHAV RES METH INS C, V35, P158, DOI 10.3758/BF03195507
   BOROD JC, 1992, NEUROPSYCHOLOGIA, V30, P827, DOI 10.1016/0028-3932(92)90086-2
   Bradley M. M., 1999, Technical Report
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   EKMAN P, 1992, PSYCHOL REV, V99, P550, DOI 10.1037/0033-295X.99.3.550
   Ekman P., 1999, Handbook of Cognition and Emotion, V98, P45, DOI 10.1002/0470013494.ch3
   Erickson K, 2003, BRAIN COGNITION, V52, P52, DOI 10.1016/S0278-2626(03)00008-3
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Johnstone T., 2000, Handbook of Emotions, V2nd ed., P220
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Lang P., 1997, International affective picture system IAPS: Technical manual and affective ratings, P39, DOI [DOI 10.1027/0269-8803/A000147, 10.1027/0269-8803/a000147]
   Larousse P., 2012, PETIT LAROUSSE ILLUS
   Maurage P, 2007, NEUROPSYCHOL TRENDS, P63, DOI 10.7358/neur-2007-002-maur
   Mitchell RLC, 2011, PSYCHOL AGING, V26, P406, DOI 10.1037/a0021861
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   Rankin KP, 2005, COGN BEHAV NEUROL, V18, P28, DOI 10.1097/01.wnn.0000152225.05377.ab
   Ruffman T, 2008, NEUROSCI BIOBEHAV R, V32, P863, DOI 10.1016/j.neubiorev.2008.01.001
   SCHERER KR, 1991, MOTIV EMOTION, V15, P123, DOI 10.1007/BF00995674
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   Schirmer A, 2005, COGNITIVE BRAIN RES, V24, P442, DOI 10.1016/j.cogbrainres.2005.02.022
   Simon D, 2008, PAIN, V135, P55, DOI 10.1016/j.pain.2007.05.008
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Weathers MD., 2002, Journal of Black Psychology, V28, P66, DOI [DOI 10.1177/0095798402028001005, 10.1177/0095798402028001005]
   YESAVAGE JA, 1983, J PSYCHIATR RES, V17, P37, DOI 10.1016/0022-3956(82)90033-4
NR 29
TC 4
Z9 5
U1 0
U2 3
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 0714-9808
EI 1710-1107
J9 CAN J AGING
JI Can. J. Aging-Rev. Can. Vieil.
PD JUN
PY 2014
VL 33
IS 2
BP 111
EP 122
DI 10.1017/S0714980814000063
PG 12
WC Gerontology
WE Social Science Citation Index (SSCI)
SC Geriatrics & Gerontology
GA AJ5VV
UT WOS:000337759200001
PM 24762821
OA Green Accepted
DA 2024-01-09
ER

PT J
AU Blumstein, DT
   Davitian, R
   Kaye, PD
AF Blumstein, Daniel T.
   Davitian, Richard
   Kaye, Peter D.
TI Do film soundtracks contain nonlinear analogues to influence emotion?
SO BIOLOGY LETTERS
LA English
DT Article
DE film soundtracks; arousal; nonlinear vocalizations; horror; drama;
   emotions
ID VOCAL PRODUCTION; ALARM CALLS; RESPONSIVENESS; ACOUSTICS; SCREAMS
AB A variety of vertebrates produce nonlinear vocalizations when they are under duress. By their very nature, vocalizations containing nonlinearities may sound harsh and are somewhat unpredictable; observations that are consistent with them being particularly evocative to those hearing them. We tested the hypothesis that humans capitalize on this seemingly widespread vertebrate response by creating nonlinear analogues in film soundtracks to evoke particular emotions. We used lists of highly regarded films to generate a set of highly ranked action/adventure, dramatic, horror and war films. We then scored the presence of a variety of nonlinear analogues in these film soundtracks. Dramatic films suppressed noise of all types, contained more abrupt frequency transitions and musical sidebands, and fewer noisy screams than expected. Horror films suppressed abrupt frequency transitions and musical sidebands, but had more non-musical sidebands, and noisy screams than expected. Adventure films had more male screams than expected. Together, our results suggest that film-makers manipulate sounds to create nonlinear analogues in order to manipulate our emotional responses.
C1 [Blumstein, Daniel T.; Davitian, Richard] Univ Calif Los Angeles, Dept Ecol & Evolutionary Biol, Los Angeles, CA 90095 USA.
   [Kaye, Peter D.] Kingston Univ, Sch Mus, Surrey KT2 7LB, England.
C3 University of California System; University of California Los Angeles;
   Kingston University
RP Blumstein, DT (corresponding author), Univ Calif Los Angeles, Dept Ecol & Evolutionary Biol, 621 Young Dr S, Los Angeles, CA 90095 USA.
EM marmots@ucla.edu
RI Blumstein, Daniel T./B-6199-2012
OI Blumstein, Daniel T./0000-0001-5793-9244
CR [Anonymous], 1989, KRZYSZTOF PENDERECKI
   Blumstein DT, 2008, ANIM BEHAV, V76, P1055, DOI 10.1016/j.anbehav.2008.06.002
   Blumstein DT, 2009, ETHOLOGY, V115, P1074, DOI 10.1111/j.1439-0310.2009.01691.x
   Bolivar VJ., 1994, Psychomusicology: A Journal of Research in Music Cognition, V13, P28, DOI [10.1037/h0094102, DOI 10.1037/H0094102]
   BOONE A, 1933, POP SCI MONTHLY, V122, P20
   Facchini A, 2005, PHYS LETT A, V338, P332, DOI 10.1016/j.physleta.2005.02.048
   FITCH WT, 1995, AM J PRIMATOL, V37, P191, DOI 10.1002/ajp.1350370303
   Fitch WT, 2002, ANIM BEHAV, V63, P407, DOI 10.1006/anbe.2001.1912
   GOUZOULES S, 1984, ANIM BEHAV, V32, P182, DOI 10.1016/S0003-3472(84)80336-X
   GREEN JA, 1987, DEV PSYCHOL, V23, P370, DOI 10.1037/0012-1649.23.3.370
   Hegarty Paul, 2007, Noise Music: A History
   Held S, 2006, APPL ANIM BEHAV SCI, V98, P216, DOI 10.1016/j.applanim.2005.09.003
   Herzel H., 1991, EUROSPEECH 91. 2nd European Conference on Speech Communication and Technology Proceedings, P263
   Huron D, 2006, EMPIR MUSICOL REV, V1, P170, DOI 10.18061/1811/24068
   JACKSON B, 2010, MIX, V34, P24
   Manser MB, 2002, TRENDS COGN SCI, V6, P55, DOI 10.1016/S1364-6613(00)01840-4
   Snowdon CT, 2010, BIOL LETTERS, V6, P30, DOI 10.1098/rsbl.2009.0593
   WIERZBICKI J, 2008, MUSIC MOVING IMAGE, V1, P2
   Wilden I., 1998, Bioacoustics, V9, P171
NR 19
TC 31
Z9 37
U1 0
U2 13
PU ROYAL SOC
PI LONDON
PA 6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND
SN 1744-9561
J9 BIOL LETTERS
JI Biol. Lett.
PD DEC 23
PY 2010
VL 6
IS 6
BP 751
EP 754
DI 10.1098/rsbl.2010.0333
PG 4
WC Biology; Ecology; Evolutionary Biology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Life Sciences & Biomedicine - Other Topics; Environmental Sciences &
   Ecology; Evolutionary Biology
GA 678TO
UT WOS:000284104000009
PM 20504815
OA Green Published
DA 2024-01-09
ER

PT J
AU Pehrs, C
   Deserno, L
   Bakels, JH
   Schlochtermeier, LH
   Kappelhoff, H
   Jacobs, AM
   Fritz, TH
   Koelsch, S
   Kuchinke, L
AF Pehrs, Corinna
   Deserno, Lorenz
   Bakels, Jan-Hendrik
   Schlochtermeier, Lorna H.
   Kappelhoff, Hermann
   Jacobs, Arthur M.
   Fritz, Thomas Hans
   Koelsch, Stefan
   Kuchinke, Lars
TI How music alters a kiss: superior temporal gyrus controls
   fusiform-amygdalar effective connectivity
SO SOCIAL COGNITIVE AND AFFECTIVE NEUROSCIENCE
LA English
DT Article
DE fMRI; non-linear DCM; multisensory integration; superior temporal gyrus;
   emotion
ID MULTISENSORY INTEGRATION; PERCEPTION; VOICE; BINDING; MODELS; CORTEX;
   FEAR; FMRI
AB While watching movies, the brain integrates the visual information and the musical soundtrack into a coherent percept. Multisensory integration can lead to emotion elicitation on which soundtrack valences may have a modulatory impact. Here, dynamic kissing scenes from romantic comedies were presented to 22 participants (13 females) during functional magnetic resonance imaging scanning. The kissing scenes were either accompanied by happy music, sad music or no music. Evidence from cross-modal studies motivated a predefined three-region network for multisensory integration of emotion, consisting of fusiform gyrus (FG), amygdala (AMY) and anterior superior temporal gyrus (aSTG). The interactions in this network were investigated using dynamic causal models of effective connectivity. This revealed bilinear modulations by happy and sad music with suppression effects on the connectivity from FG and AMY to aSTG. Non-linear dynamic causal modeling showed a suppressive gating effect of aSTG on fusiform-amygdalar connectivity. In conclusion, fusiform to amygdala coupling strength is modulated via feedback through aSTG as region for multisensory integration of emotional material. This mechanism was emotion-specific and more pronounced for sad music. Therefore, soundtrack valences may modulate emotion elicitation in movies by differentially changing preprocessed visual information to the amygdala.
C1 [Pehrs, Corinna; Bakels, Jan-Hendrik; Schlochtermeier, Lorna H.; Kappelhoff, Hermann; Jacobs, Arthur M.; Koelsch, Stefan; Kuchinke, Lars] Free Univ Berlin, Cluster Excellence Languages Emot, D-14195 Berlin, Germany.
   [Pehrs, Corinna; Schlochtermeier, Lorna H.; Jacobs, Arthur M.; Kuchinke, Lars] Free Univ Berlin, Dept Educ & Psychol, D-14195 Berlin, Germany.
   [Pehrs, Corinna; Schlochtermeier, Lorna H.; Jacobs, Arthur M.; Koelsch, Stefan; Kuchinke, Lars] Free Univ Berlin, Dahlem Inst Neuroimaging Emot, D-14195 Berlin, Germany.
   [Pehrs, Corinna] Stanford Univ, Dept Psychol, Stanford, CA 94305 USA.
   [Deserno, Lorenz] Charite, Dept Psychiat & Psychotherapy, D-10117 Berlin, Germany.
   [Deserno, Lorenz; Koelsch, Stefan] Max Planck Inst Human Cognit & Brain Sci, D-04103 Leipzig, Germany.
   [Bakels, Jan-Hendrik; Kappelhoff, Hermann] Free Univ Berlin, Dept Philosophy & Humanities, D-14195 Berlin, Germany.
   [Schlochtermeier, Lorna H.] Princeton Univ, Dept Psychol, Princeton, NJ 08540 USA.
   [Fritz, Thomas Hans] Univ Leipzig, Dept Nucl Med, D-04103 Leipzig, Germany.
   [Fritz, Thomas Hans] IPEM, B-9000 Ghent, Belgium.
   [Kuchinke, Lars] Ruhr Univ Bochum, Dept Psychol Expt Psychol & Methods, D-44801 Bochum, Germany.
C3 Free University of Berlin; Free University of Berlin; Free University of
   Berlin; Stanford University; Free University of Berlin; Humboldt
   University of Berlin; Charite Universitatsmedizin Berlin; Max Planck
   Society; Free University of Berlin; Princeton University; Leipzig
   University; Ghent University; Ruhr University Bochum
RP Pehrs, C (corresponding author), Free Univ Berlin, Cluster Languages Emot, Habelschwerdter Allee 45, D-14195 Berlin, Germany.
EM corinna.pehrs@fu-berlin.de
RI Deserno, Lorenz/G-8309-2018; Koelsch, Stefan/AAV-1556-2020
OI Deserno, Lorenz/0000-0001-7392-5280; Jacobs, Arthur/0000-0002-7910-3955;
   Koelsch, Stefan/0000-0002-8714-3404; Fritz, Thomas/0000-0003-1855-6026
FU German Research Foundation (DFG, Cluster of Excellence 'Languages of
   Emotion') [EXC302]
FX The authors thank Tila-Tabea Brink, Maria Tsaoussoglou and Hilda Hohl
   for help during data acquisition. They thank Stavros Skouras for help
   with data analysis and Andrea Samson and Valeria Manera for fruitful
   discussions. Furthermore, they thank Ursula Beerman and Dar Meshi for
   comments on a previous version of this manuscript. This work was funded
   by the German Research Foundation (DFG, Cluster of Excellence 'Languages
   of Emotion', EXC302). The study sponsor had no influence on study
   design, on the collection, analysis and interpretation of data, on the
   writing of the report and on the decision to submit the article for
   publication.
CR Adolphs R, 2010, ANN NY ACAD SCI, V1191, P42, DOI 10.1111/j.1749-6632.2010.05445.x
   Ashburner J, 2005, NEUROIMAGE, V26, P839, DOI 10.1016/j.neuroimage.2005.02.018
   Ashburner J, 2007, NEUROIMAGE, V38, P95, DOI 10.1016/j.neuroimage.2007.07.007
   Bernardi L, 2006, HEART, V92, P445, DOI 10.1136/hrt.2005.064600
   Boltz MG, 2004, MEM COGNITION, V32, P1194, DOI 10.3758/BF03196892
   Calvert GA, 2004, J PHYSIOL-PARIS, V98, P191, DOI 10.1016/j.jphysparis.2004.03.018
   Cohen AJ., 2011, MUSIC EMOTION THEORY, P1099, DOI [DOI 10.1093/ACPROF:OSO/9780199230143.003.0031, 10.1093/acprof:oso/9780199230143.003.0031]
   DAMASIO AR, 1989, COGNITION, V33, P25, DOI 10.1016/0010-0277(89)90005-X
   Daunizeau J, 2009, PHYSICA D, V238, P2089, DOI 10.1016/j.physd.2009.08.002
   De Gelder B, 2003, TRENDS COGN SCI, V7, P460, DOI 10.1016/j.tics.2003.08.014
   de Gelder B, 2000, COGNITION EMOTION, V14, P289, DOI 10.1080/026999300378824
   Deserno L, 2012, J NEUROSCI, V32, P12, DOI 10.1523/JNEUROSCI.3405-11.2012
   Dolan RJ, 2001, P NATL ACAD SCI USA, V98, P10006, DOI 10.1073/pnas.171288598
   Eldar E, 2007, CEREB CORTEX, V17, P2828, DOI 10.1093/cercor/bhm011
   Ethofer T, 2006, HUM BRAIN MAPP, V27, P707, DOI 10.1002/hbm.20212
   Friston K.J., 1994, Hum Brain Mapp, V2, P189, DOI [10.1002/hbm.460020402, DOI 10.1002/HBM.460020402]
   Friston KJ, 2000, NEUROIMAGE, V12, P466, DOI 10.1006/nimg.2000.0630
   Friston KJ, 2003, NEUROIMAGE, V19, P1273, DOI 10.1016/S1053-8119(03)00202-7
   GROSS JJ, 1995, COGNITION EMOTION, V9, P87, DOI 10.1080/02699939508408966
   Hocking J, 2008, CEREB CORTEX, V18, P2439, DOI 10.1093/cercor/bhn007
   Jeong JW, 2011, NEUROIMAGE, V54, P2973, DOI 10.1016/j.neuroimage.2010.11.017
   Kappelhoff, 2011, Z MEDIENWISSENSCHAFT, V5, P78
   Koelsch S, 2010, TRENDS COGN SCI, V14, P131, DOI 10.1016/j.tics.2010.01.002
   Kreifelts B, 2007, NEUROIMAGE, V37, P1445, DOI 10.1016/j.neuroimage.2007.06.020
   Kuchinke L., 2013, PSYCHOL MUSIC MULTIM
   Li BJ, 2011, NEUROIMAGE, V58, P442, DOI 10.1016/j.neuroimage.2011.01.085
   Macaluso E, 2000, SCIENCE, V289, P1206, DOI 10.1126/science.289.5482.1206
   Marreiros AC, 2008, NEUROIMAGE, V39, P269, DOI 10.1016/j.neuroimage.2007.08.019
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Mesulam MM, 1998, BRAIN, V121, P1013, DOI 10.1093/brain/121.6.1013
   Müller VI, 2012, NEUROIMAGE, V60, P553, DOI 10.1016/j.neuroimage.2011.12.007
   Müller VI, 2011, NEUROIMAGE, V54, P2257, DOI 10.1016/j.neuroimage.2010.10.047
   Penny WD, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000709
   Pourtois G, 2000, NEUROREPORT, V11, P1329, DOI 10.1097/00001756-200004270-00036
   Pourtois G, 2005, CORTEX, V41, P49, DOI 10.1016/S0010-9452(08)70177-1
   Robins DL, 2009, BRAIN COGNITION, V69, P269, DOI 10.1016/j.bandc.2008.08.007
   Sander D, 2003, REV NEUROSCIENCE, V14, P303, DOI 10.1515/REVNEURO.2003.14.4.303
   Seghier ML, 2011, CEREB CORTEX, V21, P1519, DOI 10.1093/cercor/bhq203
   Stephan KE, 2008, NEUROIMAGE, V42, P649, DOI 10.1016/j.neuroimage.2008.04.262
   Stephan KE, 2007, NEUROIMAGE, V38, P387, DOI 10.1016/j.neuroimage.2007.07.040
   Stephan KE, 2009, NEUROIMAGE, V46, P1004, DOI 10.1016/j.neuroimage.2009.03.025
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Vitouch, 2001, PSYCHOL MUSIC, V29, P70, DOI DOI 10.1177/0305735601291005
   Whalen PJ, 1998, CURR DIR PSYCHOL SCI, V7, P177, DOI 10.1111/1467-8721.ep10836912
NR 44
TC 33
Z9 33
U1 1
U2 34
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 1749-5016
EI 1749-5024
J9 SOC COGN AFFECT NEUR
JI Soc. Cogn. Affect. Neurosci.
PD NOV
PY 2014
VL 9
IS 11
BP 1770
EP 1778
DI 10.1093/scan/nst169
PG 9
WC Neurosciences; Psychology; Psychology, Experimental
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Neurosciences & Neurology; Psychology
GA AU8LA
UT WOS:000345846800016
PM 24298171
OA Green Submitted, Green Published
DA 2024-01-09
ER

PT J
AU Ramirez-Melendez, R
   Matamoros, E
   Hernandez, D
   Mirabel, J
   Sanchez, E
   Escude, N
AF Ramirez-Melendez, Rafael
   Matamoros, Elisabet
   Hernandez, Davinia
   Mirabel, Julia
   Sanchez, Elisabet
   Escude, Nuria
TI Music-Enhanced Emotion Identification of Facial Emotions in Autistic
   Spectrum Disorder Children: A Pilot EEG Study
SO BRAIN SCIENCES
LA English
DT Article
DE autistic spectrum disorder (ASD); emotions; affective facial
   expressions; music; brain activity; EEG
ID AFFECTIVE STYLE; RECOGNITION; FACE; COMMUNICATION; INDIVIDUALS;
   EXPRESSIONS; DEFICITS; BRAIN; VOICE; DISCRIMINATION
AB The Autistic Spectrum Disorder (ASD) is characterized by a difficulty in expressing and interpreting others' emotions. In particular, people with ASD have difficulties when interpreting emotions encoded in facial expressions. In the past, music interventions have been shown to improve autistic individuals' emotional and social skills. The present study describes a pilot study to explore the usefulness of music as a tool for improving autistic children's emotion recognition in facial expressions. Twenty-five children (mean age = 8.8 y, SD = 1.24) with high-functioning ASD and normal hearing participated in the study consisting of four weekly sessions of 15 min each. Twenty-five participants were randomly divided into an experimental group (N = 14) and a control group (N = 11). During each session, participants in the experimental group were exposed to images of facial expressions for four emotions (happy, sad, angry, and fear). Images were shown in three conditions, with the second condition consisting of music of congruent emotion with the shown images. Participants in the control group were shown only images in all three conditions. For six participants in each group, EEG data were acquired during the sessions, and instantaneous emotional responses (arousal and valence values) were extracted from the EEG data. Inter- and intra-session emotion identification improvement was measured in terms of verbal response accuracy, and EEG response differences were analyzed. A comparison of the verbal responses of the experimental group pre- and post-intervention showed a significant (p = 0.001) average improvement in emotion identification accuracy responses of 26% (SD = 3.4). Furthermore, emotional responses of the experimental group at the end of the study showed a higher correlation with the emotional stimuli being presented, compared with their emotional responses at the beginning of the study. No similar verbal responses improvement or EEG-stimuli correlation was found in the control group. These results seem to indicate that music can be used to improve both emotion identification in facial expressions and emotion induction through facial stimuli in children with high-functioning ASD.
C1 [Ramirez-Melendez, Rafael] Univ Pompeu Fabra, Mus & Machine Learning Lab, DTIC, Barcelona 08018, Spain.
   [Matamoros, Elisabet; Hernandez, Davinia] Univ Pompeu Fabra, Dept Informat & Commun Technol, Barcelona 08018, Spain.
   [Mirabel, Julia; Sanchez, Elisabet] Ctr Carrilet, Barcelona 08031, Spain.
   [Escude, Nuria] Inst Catala Musicoterapia, Barcelona 08021, Spain.
C3 Pompeu Fabra University; Pompeu Fabra University
RP Ramirez-Melendez, R (corresponding author), Univ Pompeu Fabra, Mus & Machine Learning Lab, DTIC, Barcelona 08018, Spain.
EM rafael.ramirez@upF.edu; elisabet.mlle@gmail.com;
   davinia.hernandez@upF.edu; juliamiralbell@gmail.com;
   esanchez@carrilet.org; nuriescude@ub.edu
RI Hernández-Leo, Davinia/C-2929-2011
OI Hernández-Leo, Davinia/0000-0003-0548-7455
FU European Union [688269]; Spanish Ministerio de Ciencia, Innovacion y
   Universidades (MCIU); Agencia Estatal de Investigacion (AEI) [Musical
   AI-PID2019-111403GB-I00/AEI/10.13039/501100011033]
FX This work was partly sponsored by the European Union Horizon 2020
   research and innovation program under grant agreement No. 688269 (TELMI
   project) and by the Spanish Ministerio de Ciencia, Innovacion y
   Universidades (MCIU) and the Agencia Estatal de Investigacion (AEI)
   project Musical AI-PID2019-111403GB-I00/AEI/10.13039/501100011033.
CR Allen R, 2013, J AUTISM DEV DISORD, V43, P432, DOI 10.1007/s10803-012-1587-8
   Allen R, 2009, ANN NY ACAD SCI, V1169, P326, DOI 10.1111/j.1749-6632.2009.04772.x
   Allen R, 2009, AUTISM, V13, P21, DOI 10.1177/1362361307098511
   American Psychiatric Association, 2013, Diagnostic and statistical manual of mental disorders, V5th, DOI 10.1176/appi.books.9780890425596.744053
   [Anonymous], 2013, Psychomusicology: Music, Mind, and Brain, DOI [DOI 10.1037/A0033754, 10.1037/a0033754]
   [Anonymous], 1992, MUSIC THERAPY AUTIST
   [Anonymous], 2012, J INDIAN I SCI
   Ashwin C, 2007, NEUROPSYCHOLOGIA, V45, P2, DOI 10.1016/j.neuropsychologia.2006.04.014
   Badcock NA, 2013, PEERJ, V1, DOI 10.7717/peerj.38
   Baron-Cohen S, 2000, NEUROSCI BIOBEHAV R, V24, P355, DOI 10.1016/S0149-7634(00)00011-7
   Black MH, 2017, NEUROSCI BIOBEHAV R, V80, P488, DOI 10.1016/j.neubiorev.2017.06.016
   Bonnel A, 2003, J COGNITIVE NEUROSCI, V15, P226, DOI 10.1162/089892903321208169
   BOUCHER J, 1992, J CHILD PSYCHOL PSYC, V33, P843, DOI 10.1111/j.1469-7610.1992.tb01960.x
   Brown LS, 2017, J MUSIC THER, V54, P55, DOI 10.1093/jmt/thw017
   Caria A, 2011, CEREB CORTEX, V21, P2838, DOI 10.1093/cercor/bhr084
   Celani G, 1999, J AUTISM DEV DISORD, V29, P57, DOI 10.1023/A:1025970600181
   Corbett BA, 2009, PSYCHIAT RES-NEUROIM, V173, P196, DOI 10.1016/j.pscychresns.2008.08.005
   Critchley HD, 2000, BRAIN, V123, P2203, DOI 10.1093/brain/123.11.2203
   Davidson Richard J., 1995, P361
   DAVIDSON RJ, 1992, PSYCHOL SCI, V3, P39, DOI 10.1111/j.1467-9280.1992.tb00254.x
   Davidson RJ, 1998, COGNITION EMOTION, V12, P307, DOI 10.1080/026999398379628
   De Bruyn L., 2011, MUSIC MED, V4, P28, DOI [10.1177/1943862111415116, DOI 10.1177/1943862111415116]
   Debener S, 2012, PSYCHOPHYSIOLOGY, V49, P1617, DOI 10.1111/j.1469-8986.2012.01471.x
   Duffy B, 2000, J APPL RES INTELLECT, V13, P77, DOI 10.1046/j.1468-3148.2000.00011.x
   Eigsti IM, 2012, CHILD NEUROPSYCHOL, V18, P600, DOI 10.1080/09297049.2011.639757
   Eren B, 2016, P 2 INT C AUTISM
   Eyler LT, 2012, BRAIN, V135, P949, DOI 10.1093/brain/awr364
   Finnigan E, 2010, AUTISM, V14, P321, DOI 10.1177/1362361309357747
   Frith U, 2004, J CHILD PSYCHOL PSYC, V45, P672, DOI 10.1111/j.1469-7610.2004.00262.x
   Gassner L, 2022, EUR J PUBLIC HEALTH, V32, P27, DOI 10.1093/eurpub/ckab042
   Gervais H, 2004, NAT NEUROSCI, V7, P801, DOI 10.1038/nn1291
   Golan O, 2007, J AUTISM DEV DISORD, V37, P1096, DOI 10.1007/s10803-006-0252-5
   Gold C, 2006, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD004381.pub2
   Hadjikhani N, 2009, SOC COGN AFFECT NEUR, V4, P70, DOI 10.1093/scan/nsn038
   Heaton P, 2005, J AUTISM DEV DISORD, V35, P787, DOI 10.1007/s10803-005-0024-7
   Heaton P, 2012, PSYCHOL MED, V42, P2453, DOI 10.1017/S0033291712000621
   Heaton P, 1999, NEUROCASE, V5, P503, DOI 10.1093/neucas/5.6.503
   Heaton P, 2003, J CHILD PSYCHOL PSYC, V44, P543, DOI 10.1111/1469-7610.00143
   Heaton P, 2008, BRIT J DEV PSYCHOL, V26, P171, DOI 10.1348/026151007X206776
   HENRIQUES JB, 1991, J ABNORM PSYCHOL, V100, P535, DOI 10.1037/0021-843X.100.4.535
   Hobson R Peter, 2005, HDB AUTISM PERVASIVE, P406
   HOBSON RP, 1986, J CHILD PSYCHOL PSYC, V27, P321, DOI 10.1111/j.1469-7610.1986.tb01836.x
   Hubert B, 2007, J AUTISM DEV DISORD, V37, P1386, DOI 10.1007/s10803-006-0275-y
   IBM Corp, 2010, REL 2010 IBM SPSS ST
   Kanner L, 1943, NERV CHILD, V2, P217
   Kaplan RS, 2005, J MUSIC THER, V42, P2, DOI 10.1093/jmt/42.1.2
   Katagiri J, 2009, J MUSIC THER, V46, P15, DOI 10.1093/jmt/46.1.15
   Lindner JL, 2006, J AUTISM DEV DISORD, V36, P769, DOI 10.1007/s10803-006-0105-2
   Lord C, 2000, J AUTISM DEV DISORD, V30, P205, DOI 10.1023/A:1005592401947
   Mazefsky CA, 2007, J AUTISM DEV DISORD, V37, P1086, DOI 10.1007/s10803-006-0251-6
   Molnar-Szakacs I, 2012, ANN NY ACAD SCI, V1252, P318, DOI 10.1111/j.1749-6632.2012.06465.x
   Philip RCM, 2010, PSYCHOL MED, V40, P1919, DOI 10.1017/S0033291709992364
   Quintin EM, 2011, J AUTISM DEV DISORD, V41, P1240, DOI 10.1007/s10803-010-1146-0
   Ramirez Rafael, 2012, Brain Informatics. International Conference, BI 2012. Proceedings, P175, DOI 10.1007/978-3-642-35139-6_17
   Ramirez R, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00354
   Renard Y, 2010, PRESENCE-VIRTUAL AUG, V19, P35, DOI 10.1162/pres.19.1.35
   Schultz RT, 2000, ARCH GEN PSYCHIAT, V57, P331, DOI 10.1001/archpsyc.57.4.331
   Sharda M, 2015, AUTISM RES, V8, P174, DOI 10.1002/aur.1437
   Stanutz S, 2014, AUTISM, V18, P137, DOI 10.1177/1362361312462905
   Thaut MH, 2015, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01185
   Thayer RE., 1990, The Biopsychology of Mood and Activation
   Thie J, 2012, DOC OPHTHALMOL, V125, P149, DOI 10.1007/s10633-012-9345-y
   Vaiouli P, 2015, AUTISM, V19, P73, DOI 10.1177/1362361313511709
   Wan CY, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025505
   Wan CY, 2010, MUSIC PERCEPT, V27, P287, DOI 10.1525/MP.2010.27.4.287
   Wang AT, 2007, ARCH GEN PSYCHIAT, V64, P698, DOI 10.1001/archpsyc.64.6.698
   Wechsler D., 2006, WECHSLER NONVERBAL S
   Wechsler D., 2008, WECHSLER ADULT INTEL, P1
NR 68
TC 1
Z9 1
U1 11
U2 30
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3425
J9 BRAIN SCI
JI Brain Sci.
PD JUN
PY 2022
VL 12
IS 6
AR 704
DI 10.3390/brainsci12060704
PG 11
WC Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Neurosciences & Neurology
GA 2K4UW
UT WOS:000816333900001
PM 35741590
OA gold, Green Published
DA 2024-01-09
ER

PT J
AU Liu, J
AF Liu, Jie
TI The Auxiliary Role of College Music in Teaching in View of Artificial
   Intelligence
SO MOBILE INFORMATION SYSTEMS
LA English
DT Article
AB Music is a common art and it is a jewel of human civilisation. In the course of music's development, the evaluation of music teaching is an inevitable step in the development of quality music. Universities are important places that abound with musical souls and their contribution to the development of music has been outstanding. But with the development of the times, university music has been hampered in the field of teaching and learning. As an important branch in the field of computer science and information technology, artificial intelligence technology contains many intersecting and comprehensive subject connotations, bringing brand-new elements to music education. It has also had an important impact on the development of music teaching. The article focuses in depth on the traditional process of music development in terms of the characteristics and ways of teaching music. Based on this, the article further explores the integration of artificial intelligence and music and analyses the role of emerging technologies as an aid to music from the perspective of the times. And this article uses emotion recognition as an evaluation index to explore the evaluation role of artificial intelligence technology in college music teaching, and improve the quality and efficiency of music teaching. The experimental results show that the teacher's positive emotion rate based on image data is 57.8%, and the student's positive emotion rate is 44.5%; the teacher's positive emotion rate based on voice data is 53.3%, and the student's positive emotion rate is 51.1%. The classroom emotion is negative at 7-13 minutes, the classroom emotion continues to be low at 28-40 minutes, and the teacher and student emotions are more positive at 13-28 minutes.
C1 [Liu, Jie] Xian Shiyou Univ, Dept Mus, Xian 710065, Shaanxi, Peoples R China.
C3 Xi'an Shiyou University
RP Liu, J (corresponding author), Xian Shiyou Univ, Dept Mus, Xian 710065, Shaanxi, Peoples R China.
EM liujie@xsyu.edu.cn
CR Abboud R, 2020, SOFT COMPUT, V24, P9875, DOI 10.1007/s00500-019-04503-4
   Ahvan Y. R., 2016, ED RES REV, V11, P141, DOI DOI 10.5897/ERR2015.2532
   Al Lily AE, 2017, COGN PROCESS, V18, P529, DOI 10.1007/s10339-017-0816-7
   Allegri RF, 2018, REV NEUROLOGIA, V66, P353, DOI 10.33588/rn.6610.2017293
   Mora-Gutiérrez RA, 2016, ARTIF INTELL REV, V46, P225, DOI 10.1007/s10462-016-9462-1
   Benetos E, 2019, IEEE SIGNAL PROC MAG, V36, P20, DOI 10.1109/MSP.2018.2869928
   Blasiman RN, 2018, EUR J PSYCHOL, V14, P188, DOI 10.5964/ejop.v14i1.1472
   Buckner C, 2017, BIOL PHILOS, V32, P1289, DOI 10.1007/s10539-017-9605-z
   Chang J., 2017, KOREAN J ARTS STUDIE, P29
   Collins T, 2016, AI EDAM, V30, P16, DOI 10.1017/S0890060414000687
   Fostick L, 2019, EUR J AGEING, V16, P481, DOI 10.1007/s10433-019-00512-2
   Frisk H, 2020, ORGAN SOUND, V25, P33, DOI 10.1017/S135577181900044X
   Gardini E, 2021, COGN COMPUT, V13, P570, DOI 10.1007/s12559-021-09823-y
   Hassabis D, 2017, NEURON, V95, P245, DOI 10.1016/j.neuron.2017.06.011
   Li RP, 2017, IEEE WIREL COMMUN, V24, P175, DOI 10.1109/MWC.2017.1600304WC
   Liu CH, 2017, IEEE TETCI, V1, P2, DOI 10.1109/TETCI.2016.2642200
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Pasquier P, 2016, COMPUT ENTERTAIN, V14, DOI 10.1145/2930672
   Prichard S, 2017, J RES MUSIC EDUC, V65, P237, DOI 10.1177/0022429417710387
   Roy S, 2020, J AMB INTEL HUM COMP, V11, P151, DOI 10.1007/s12652-019-01261-x
   Silvia PJ, 2016, PSYCHOL AESTHET CREA, V10, P184, DOI 10.1037/aca0000058
   Singh Yashpal, 2017, Ind Psychiatry J, V26, P71, DOI 10.4103/ipj.ipj_61_16
   Thrall JH, 2018, J AM COLL RADIOL, V15, P504, DOI 10.1016/j.jacr.2017.12.026
   Torppa R, 2020, EAR HEARING, V41, P395, DOI 10.1097/AUD.0000000000000763
   Wong YHP, 2018, AUST J TEACH EDUC, V43
   Xu J., 2020, ARAB WORLD ENGL J, V11, P59, DOI DOI 10.24093/AWEJ/VOL11NO2.5
NR 26
TC 1
Z9 1
U1 3
U2 12
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1574-017X
EI 1875-905X
J9 MOB INF SYST
JI Mob. Inf. Syst.
PD JUN 22
PY 2022
VL 2022
AR 2693199
DI 10.1155/2022/2693199
PG 11
WC Computer Science, Information Systems; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 2S5MX
UT WOS:000821837300013
OA gold
DA 2024-01-09
ER

PT J
AU Laukka, P
   Eerola, T
   Thingujam, NS
   Yamasaki, T
   Beller, G
AF Laukka, Petri
   Eerola, Tuomas
   Thingujam, Nutankumar S.
   Yamasaki, Teruo
   Beller, Gregory
TI Universal and Culture-Specific Factors in the Recognition and
   Performance of Musical Affect Expressions
SO EMOTION
LA English
DT Article
DE cross-cultural; emotion recognition; in-group advantage; music
   performance; music feature extraction
ID FACIAL EXPRESSIONS; EMOTION RECOGNITION; VOCAL EXPRESSION; BASIC
   EMOTIONS; PERCEPTION; COMMUNICATION; LANGUAGES; COGNITION; JAPANESE;
   WESTERN
AB We present a cross-cultural study on the performance and perception of affective expression in music. Professional bowed-string musicians from different musical traditions (Swedish folk music, Hindustani classical music, Japanese traditional music, and Western classical music) were instructed to perform short pieces of music to convey 11 emotions and related states to listeners. All musical stimuli were judged by Swedish, Indian, and Japanese participants in a balanced design, and a variety of acoustic and musical cues were extracted. Results first showed that the musicians' expressive intentions could be recognized with accuracy above chance both within and across musical cultures, but communication was, in general, more accurate for culturally familiar versus unfamiliar music, and for basic emotions versus nonbasic affective states. We further used a lens-model approach to describe the relations between the strategies that musicians use to convey various expressions and listeners' perceptions of the affective content of the music. Many acoustic and musical cues were similarly correlated with both the musicians' expressive intentions and the listeners' affective judgments across musical cultures, but the match between musicians' and listeners' uses of cues was better in within-cultural versus cross-cultural conditions. We conclude that affective expression in music may depend on a combination of universal and culture-specific factors.
C1 [Laukka, Petri] Stockholm Univ, Dept Psychol, S-10691 Stockholm, Sweden.
   [Eerola, Tuomas] Univ Jyvaskyla, Dept Mus, Finnish Ctr Excellence Interdisciplinary Mus Res, Jyvaskyla, Finland.
   [Thingujam, Nutankumar S.] Sikkim Univ, Dept Psychol, Gangtok, India.
   [Yamasaki, Teruo] Osaka Shoin Womens Univ, Fac Psychol, Nara, Japan.
   [Beller, Gregory] IRCAM, Paris, France.
C3 Stockholm University; University of Jyvaskyla; Sikkim University
RP Laukka, P (corresponding author), Stockholm Univ, Dept Psychol, S-10691 Stockholm, Sweden.
EM petri.laukka@psychology.su.se
RI Thingujam, Nutankumar S./AAA-6216-2019; Eerola, Tuomas/K-7596-2019;
   Eerola, Tuomas/I-6190-2013; Thingujam, Nutankumar/AAN-3215-2020; Laukka,
   Petri/B-5259-2008
OI Eerola, Tuomas/0000-0002-2896-929X; Eerola, Tuomas/0000-0002-2896-929X;
   Laukka, Petri/0000-0001-8771-6818
CR Adachi M, 2004, JPN PSYCHOL RES, V46, P322, DOI 10.1111/j.1468-5584.2004.00264.x
   [Anonymous], 1985, MUSIC EMOTIONS
   [Anonymous], 2004, MUSIC N INDIA EXPERI
   Bänziger T, 2012, EMOTION, V12, P1161, DOI 10.1037/a0025827
   Balkwill LL, 2004, JPN PSYCHOL RES, V46, P337, DOI 10.1111/j.1468-5584.2004.00265.x
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Becker J., 2010, HDB MUSIC EMOTION TH, P128
   Benamou M, 2003, WORLD MUSIC, V45, P57
   Bhatara A, 2011, J EXP PSYCHOL HUMAN, V37, P921, DOI 10.1037/a0021922
   Bor Joep, 1987, NATL CTR PERFORMING, V16, P1
   Bowling DL, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0031942
   Brown S, 2013, PSYCHOL MUSIC, V41, P229, DOI 10.1177/0305735611425896
   Brunswik E., 1956, Perception and the representative design of psychological experiments, V2nd
   Burkholder J. Peter, 2009, HIST W MUSIC, VEighth
   Collier G. L., 2002, EMPIRICAL STUDIES AR, V20, P21, DOI [10.2190/XXD1-W9R4-H81L-ADP2, DOI 10.2190/XXD1-W9R4-H81L-ADP2]
   Cross I., 2008, MUSIC SCI, V12, P147, DOI [DOI 10.1177/1029864908012001071, 10.1177/1029864908012001071]
   Dailey MN, 2010, EMOTION, V10, P874, DOI 10.1037/a0020019
   DARROW AA, 1987, J RES MUSIC EDUC, V35, P237, DOI 10.2307/3345076
   Davies S., 2011, AESTHETIC MIND PHILO, P376, DOI [DOI 10.1093/ACPR0F:0S0/9780199691517.003, 10.1093/acprof:oso/9780199691517.003.0023]
   Davies S., 2006, Contemporary debates in aesthetics and the philosophy of art, P179, DOI 10.1093/acprof:oso/9780199608775.003.0002
   Eerola T., 2009, Proceedings of the International Conference on Music Information Retrieval ISMIR, P621
   Eerola T, 2011, J NEW MUSIC RES, V40, P349, DOI 10.1080/09298215.2011.602195
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Elfenbein HA, 2002, PSYCHOL BULL, V128, P203, DOI 10.1037//0033-2909.128.2.203
   Elfenbein HA, 2007, EMOTION, V7, P131, DOI 10.1037/1528-3542.7.1.131
   Elfenbein HA, 2002, EMOTION, V2, P75, DOI 10.1037/1528-3542.2.1.75
   Escoffier N, 2013, HUM BRAIN MAPP, V34, P1796, DOI 10.1002/hbm.22029
   Frank MG, 2001, J PERS SOC PSYCHOL, V80, P75, DOI 10.1037/0022-3514.80.1.75
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Gabrielsson A, 2003, SER AFFECTIVE SCI, P503
   Gabrielsson A., 2010, HDB MUSIC EMOTION TH, P223
   Gedik AC, 2010, SIGNAL PROCESS, V90, P1049, DOI 10.1016/j.sigpro.2009.06.017
   Gendron M, 2012, EMOTION, V12, P314, DOI 10.1037/a0026007
   Gómez E, 2008, EMPIR MUSICOL REV, V3, P140, DOI 10.18061/1811/34105
   Gregory A. H., 1996, PSYCHOL MUSIC, V24, P47, DOI [10.1177/0305735696241005, DOI 10.1177/0305735696241005]
   Hall JA, 2008, J RES PERS, V42, P1476, DOI 10.1016/j.jrp.2008.06.013
   Hertenstein MJ, 2006, EMOTION, V6, P528, DOI 10.1037/1528-3542.6.3.528
   Hevner K, 1936, AM J PSYCHOL, V48, P246, DOI 10.2307/1415746
   Higgins KM, 2012, EMOT REV, V4, P273, DOI 10.1177/1754073912439762
   Higgins KM, 2006, REV INT PHILOS, V60, P487
   Hoshino E., 1996, PSYCHOL MUSIC, V24, P29, DOI [DOI 10.1177/0305735696241004, 10.1177/0305735696241004]
   Hughes D. W., 2001, NEW GROVE DICT MUSIC
   HURON DAVID, 2006, SWEET ANTICIPATION M, P148, DOI DOI 10.7551/MITPRESS/6575.001.0001
   Jersild M., 2001, NEW GROVE DICT MUSIC
   Juslin P., 2010, Handbook of Music and Emotion: Theory, Research, Applications, P453, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0017
   Juslin P. N., 1996, PSYCHOL MUSIC, V24, P68, DOI [10.1177/0305735696241007, DOI 10.1177/0305735696241007]
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   KEIL C, 1966, ETHNOMUSICOLOGY, V10, P153
   KILBRIDE JE, 1983, J NONVERBAL BEHAV, V8, P27, DOI 10.1007/BF00986328
   Kwoun SJ, 2009, J MUSIC THER, V46, P217, DOI 10.1093/jmt/46.3.217
   Lartillot O., 2007, P INT C DIG AUD EFF, DOI DOI 10.1007/978-3-540-78246-9_31
   Laukka P., 2004, Music Education Research, V6, P45, DOI DOI 10.1080/1461380032000182821
   Leitman DI, 2011, FRONT HUM NEUROSCI, V5, DOI [10.3389/fnhum.2011.00096, 10.3389/fnhum.2010.00019]
   Malm W.P., 2000, Traditional Japanese Music and Musical Instruments
   Matsumoto D, 2012, J CROSS CULT PSYCHOL, V43, P91, DOI 10.1177/0022022111420147
   McDermott JH, 2008, CURR OPIN NEUROBIOL, V18, P452, DOI 10.1016/j.conb.2008.09.005
   Merriam Alan P., 1964, The Anthropology of Music
   MESQUITA B, 1992, PSYCHOL BULL, V112, P179, DOI 10.1037/0033-2909.112.2.179
   Morrison SJ, 2009, PROG BRAIN RES, V178, P67, DOI 10.1016/S0079-6123(09)17805-6
   Patel A. D., 2008, Music, Language, and the Brain
   Pell MD, 2009, J PHONETICS, V37, P417, DOI 10.1016/j.wocn.2009.07.005
   RUSSELL JA, 1994, PSYCHOL BULL, V115, P102, DOI 10.1037/0033-2909.115.1.102
   Sauter DA, 2010, P NATL ACAD SCI USA, V107, P2408, DOI 10.1073/pnas.0908239106
   Scherer KR, 2011, INT J PSYCHOL, V46, P401, DOI 10.1080/00207594.2011.626049
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   Simon-Thomas ER, 2009, EMOTION, V9, P838, DOI 10.1037/a0017810
   Stevens CJ, 2012, TOP COGN SCI, V4, P653, DOI 10.1111/j.1756-8765.2012.01215.x
   Thompson W.F., 2010, Handbook of music and emotion: Theory, research, and applications, P755
   Thompson WF, 2006, SEMIOTICA, V158, P407, DOI 10.1515/SEM.2006.017
   Tillmann B, 2000, PSYCHOL REV, V107, P885, DOI 10.1037/0033-295X.107.4.885
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   WAGNER HL, 1993, J NONVERBAL BEHAV, V17, P3, DOI 10.1007/BF00987006
   Walker Robert, 1996, PSYCHOL MUSIC, V24, P103, DOI DOI 10.1177/0305735696242001
   WEDIN L., 1969, SWEDISH J MUSICOLOGY, V51, P119
   Wieczorkowska AA, 2010, STUD COMPUT INTELL, V274, P285
   Wong PCM, 2009, MUSIC PERCEPT, V27, P81, DOI 10.1525/MP.2009.27.2.81
   Zacharopoulou K., 2009, J INTERDISCIP MUSIC, V3, P1
   Zatorre RJ, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001372
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 84
TC 90
Z9 103
U1 1
U2 60
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 1528-3542
EI 1931-1516
J9 EMOTION
JI Emotion
PD JUN
PY 2013
VL 13
IS 3
BP 434
EP 449
DI 10.1037/a0031388
PG 16
WC Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA 159RZ
UT WOS:000320064900010
PM 23398579
DA 2024-01-09
ER

PT S
AU Faudree, P
AF Faudree, Paja
BE Brenneis, D
   Ellison, PT
TI Music, Language, and Texts: Sound and Semiotic Ethnography
SO ANNUAL REVIEW OF ANTHROPOLOGY, VOL 41
SE Annual Review of Anthropology
LA English
DT Article; Book Chapter
DE chronotope; circulation; soundscape; subjectivity; textuality; voice
ID SONG; VOICE; RADIO; ANTHROPOLOGY; IMAGINATION; AESTHETICS; EXPERIENCE;
   COUNTRY
AB This review surveys recent research on language-music: the unified expressive field comprising sounded and textual signs whose segmentation into "language" and "music" is culturally constructed. I argue that approaching language-music semiotically will promote-alongside the discipline's emergent "auditory turn"-greater holism in anthropological practice if coupled to the joint effort of attending to textuality while decentering its primacy. I discuss recent scholarship that demonstrates, if often implicitly, the merit of this approach. I organize this work into three overlapping themes of active research: scholarship on chronotopes and soundscapes exploring processes that reconfigure time and place; work on subject creation focusing on voice, emotion, intersubjectivity, and listening; and scholarship on the social dimensions of object creation, including technological mediation, authentication, and circulation. I conclude by discussing future directions in research on language-music and the promise such work offers of furthering the call to broaden anthropology's holism while loosening adherence to its text-centered practices.
C1 Brown Univ, Dept Anthropol, Providence, RI 02912 USA.
C3 Brown University
RP Faudree, P (corresponding author), Brown Univ, Dept Anthropol, Providence, RI 02912 USA.
EM Paja_Faudree@brown.edu
CR Agha A, 2007, STUD SOC CULT FOUND, V24, P1, DOI 10.2277/ 0521576857
   AHEARN L, 1998, J LINGUIST ANTHROPOL, V8, P60, DOI DOI 10.1525/JLIN.1998.8.1.60
   Alim H.S., 2006, Roc the Mic Right: The Language of Hip Hop Culture, V1st
   Alim H. S., 2008, Global linguistic flows: Hip hop cultures, youth identities, and the politics of language
   [Anonymous], 1997, A Day for the Hunter, a Day for the Prey: Popular Music and Power in Haiti
   [Anonymous], 2005, HEARING CULTURES ESS
   [Anonymous], 2009, ETHICAL SOUNDSCAPE C
   [Anonymous], 2006, HIP HOP JAPAN RAP PA
   [Anonymous], 2008, MODERN NOISE FLUID G
   [Anonymous], 1982, DIALOGIC IMAGINATION
   [Anonymous], 2009, Explorations in Navajo Poetry and Poetics
   [Anonymous], MUSIC TECHNOCULTURE
   [Anonymous], SEMIOSIS HINDUSTANI
   [Anonymous], 2003, Global Pop, Local Language
   Appadurai Arjun, 2006, Fear of Small Numbers: An Essay on the Geography of Anger
   Auslander Philip, 1999, Liveness: Performance in a Mediatized Culture
   Bauman R., 2003, VOICES OF MODERNITY
   Bauman R, 2011, LING C
   Bauman Richard, 2010, TELLING STORIES LANG, P23
   Becker J., 2004, Deep listeners: Music emotions and trancing
   Beeman William O., 2011, ANTHR NEWS, V52, P11
   Benson B. E., 2003, The improvisation of musical dialogue: a phenomenology of music
   Berger Harris M., 2010, STANCE IDEAS EMOTION
   Bergeron K, 2010, MUSIC LESSONS FRENCH
   Bergeron K., 1998, Decadent Enchantments : The Revival of Gregorian Chant at Solesmes
   Bickford T, 2007, ETHNOMUSICOLOGY, V51, P439
   Birth Kevin K., 2008, Bacchanalian Sentiments: Musical Experiences and Political Counterpoints in Trinidad
   Black SP, 2010, THESIS U CALIF LOS A
   Black SP, 2011, ANTHR NEWS, V52, P10
   Born Georgina, 2000, W MUSIC ITS OTHERS D
   Brennan VL, 2010, AM ETHNOL, V37, P354, DOI 10.1111/j.1548-1425.2010.01260.x
   Brusila J, 2003, LOCAL MUSIC NOT HERE, V10
   COMAROFF John, 2009, Ethnicity, Inc
   Cowan GM, 1948, LANGUAGE, V24, P280, DOI 10.2307/410362
   Deacon Terrence W, 1997, SYMBOLIC SPECIES CO
   Dent Alexander., 2009, River of Tears: Country Music, Memory, and Modernity in Brazil
   Diehl Keila, 2002, Echoes from Dharamsala: Music in the Life of a Tibetan Refugee Community
   Dorsey Margaret E., 2006, PACHANGAS BORDERLAND
   Duranti A, 2009, HOMME, V1, P23
   Duranti A, 2010, ANTHROPOL THEOR, V10, P16, DOI 10.1177/1463499610370517
   Duranti A, 2009, J LINGUIST ANTHROPOL, V19, P205, DOI 10.1111/j.1548-1395.2009.01031.x
   Eidsheim N, 2008, THESIS U CALIF SAN D
   Erlmann V, 1996, PUBLIC CULTURE, V8, P467, DOI 10.1215/08992363-8-3-467
   Faudree P, 2011, LING C
   Faudree P, 2009, AM ANTHROPOL, V111, P153, DOI 10.1111/j.1548-1433.2009.01108.x
   Faudree Paja, 2013, Singing for the Dead: The Politics of Indigenous Revival in Mexico
   Feld S, 1999, PUBLIC CULTURE, V12, P145
   Feld S, 2004, AM ETHNOL, V31, P461, DOI 10.1525/ae.2004.31.4.461
   FELD S, 1994, ANNU REV ANTHROPOL, V23, P25, DOI 10.1146/annurev.an.23.100194.000325
   Feld S., 1994, MUSIC GROOVES ESSAYS
   Feld S, 1999, J LINGUIST ANTHROPOL, V9, P159
   Feld S., 2001, BOSAVI RAINFOREST MU
   Feld Steven., 2005, COMPANION LINGUISTIC, P321, DOI DOI 10.1002/9780470996522.CH14
   Fellezs Kevin, 2011, Birds of Fire: Jazz, Rock, Funk, and the Creation of Fusion
   Ferguson JM, 2010, AM ETHNOL, V37, P227, DOI 10.1111/j.1548-1425.2010.01252.x
   Fisher D, 2009, CULT ANTHROPOL, V24, P280, DOI 10.1111/j.1548-1360.2009.01132.x
   Fox AA, 2006, ENCY LANGUAGE LINGUI, V9, P80
   Fox Aaron A., 2004, REAL COUNTRY MUSIC L
   Friedson Steven, 1996, DANCING PROPHETS MUS
   Gautier AMO, 2006, SOC IDENT, V12, P803, DOI 10.1080/13504630601031022
   Gilmer MC, 2007, TRANSFORM ANTHROPOL, V15, P141, DOI 10.1525/tran.2007.15.2.141
   Gitelman Lisa, 2000, SCRIPTS GROOVES WRIT
   Goodman Jane E., 2005, Berber Culture on the World Stage: From Village to Video
   Goodman JE, 2002, AM ETHNOL, V29, P86, DOI 10.1525/ae.2002.29.1.86
   Graham LauraR, 1995, Performing dreams: Discourses of immortality among the Xavante of central Brazil
   Hanks W., 1995, LANGUAGE COMMUNICATI
   Harkness N, 2011, J LINGUIST ANTHROPOL, V21, P99, DOI 10.1111/j.1548-1395.2011.01084.x
   Haugh WA, 2005, SINGING NATION DISCO
   Haviland JB, 2012, MULTIMODALITY HUMAN
   Hellier-Tinoco, 2011, EMBODYING MEXICO TOU
   Inoue Miyako., 2006, Vicarious Language: Gender and Linguistic Modernity in Japan, DOI DOI 10.1525/978052
   Jacobs J, 2008, ULULATION LEVANTINE
   Kapchan D, 2006, AM ETHNOL, V33, P361, DOI 10.1525/ae.2006.33.3.361
   Kapchan D, 2009, WORLD MUSIC, V51, P65
   Kapchan DA, 2008, AM ANTHROPOL, V110, P467, DOI 10.1111/j.1548-1433.2008.00079.x
   Keane W, 2003, LANG COMMUN, V23, P409, DOI 10.1016/S0271-5309(03)00010-7
   Keeler W, 2009, AM ETHNOL, V36, P2, DOI 10.1111/j.1548-1425.2008.01106.x
   Kockelman P, 2005, SEMIOTICA, V157, P233
   Kunreuther L, 2006, CULT ANTHROPOL, V21, P323, DOI 10.1525/can.2006.21.3.323
   Kunreuther L, 2010, J LINGUIST ANTHROPOL, V20, P334, DOI 10.1111/j.1548-1395.2010.01073.x
   Largey Michael, 2006, Vodou Nation: Haitian Art Music and Cultural Nationalism
   Larkin Brian, 2008, Signal and Noise: Media, Infrastructure, and Urban Culture in Nigeria
   Levin T., 1999, TUVA SPIRITS SOUND M
   Luvaas B, 2009, CULT ANTHROPOL, V24, P246, DOI 10.1111/j.1548-1360.2009.01131.x
   Mannheim Bruce, 1998, NATIVE TRADITIONS PO, P383
   Matos C, 2008, PALAVRA CANTADA ENSA
   Meintjes Louise, 2003, Sound of Africa! Making Music Zulu in a South African Studio
   Mendoza-Denton Norma., 2008, Homegirls: Language and Cultural Practice among Latina Youth Gangs
   Mertz E, 2007, ANNU REV ANTHROPOL, V36, P337, DOI 10.1146/annurev.anthro.36.081406.094417
   Miller F., 2007, MORAL RESONANCE ARAB
   Miller K, 2009, J SOC AM MUSIC, V3, P395, DOI 10.1017/S1752196309990666
   Miller Kiri, 2008, TRAVELING HOME SACRE
   Minks A, 2008, LANG COMMUN, V28, P36, DOI 10.1016/j.langcom.2007.02.001
   Mitchell Tony, 2002, Global Noise: Rap and Hip Hop Outside the USA
   Myers F., 2002, EMPIRE THINGS REGIME
   Navarrete Pellicer Sergio, 2005, MAYA ACHI MARIMBA MU
   Ninoshvili L, 2010, THESIS COLUMBIA U
   Ninoshvili L, 2011, J LINGUIST ANTHROPOL, V21, P78, DOI 10.1111/j.1548-1395.2011.01083.x
   Novak D, 2008, POP MUSIC, V27, P15, DOI 10.1017/S0261143008001517
   Novak D, 2011, PUBLIC CULTURE, V23, P603, DOI 10.1215/08992363-1336435
   Nuckolls JB, 1996, SOUNDS LIKE LIFE SOU
   Peirce, 1888, ESSENTIAL PEIRCE SEL, VI, P280
   Perlman Marc., 2004, Unplayed Melodies: Javanese Gamelan and the Genesis of Music Theory
   Porcello T, 1998, ETHNOMUSICOLOGY, V42, P485, DOI 10.2307/852851
   Porcello T, 2002, CITY SOC, V14, P69, DOI DOI 10.1525/CITY.2002.14.1.69
   Porcello T, 2010, ANNU REV ANTHROPOL, V39, P51, DOI 10.1146/annurev.anthro.012809.105042
   Porcello Thomas., 2004, Wired for Sound: Engineering and Technologies in Sonic Cultures, P269
   Preucel R. W., 2006, ARCHEOLOGICAL SEMIOT
   Prouty KE, 2006, POP MUSIC SOC, V29, P317, DOI 10.1080/03007760600670372
   Rice Timothy, 2001, British Journal of Ethnomusicology, V10, P19
   Richard Bauman, 2004, WORLD OTHERS WORDS C
   Roseman M, 1998, AM ANTHROPOL, V100, P106, DOI 10.1525/aa.1998.100.1.106
   Rothenberg J, 2003, MARIA SABINA SELECTI
   Rumsey A. L., 2007, ANTHROPOL LINGUIST, V49, P235
   Samuels DW, 2010, ANNU REV ANTHROPOL, V39, P329, DOI 10.1146/annurev-anthro-022510-132230
   Samuels David William, 2004, Putting a Song on Top of It : Expression and Identity on the San Carlos Apache Reservation
   Sarkar M., 2007, Journal of Language, Identity, and Education, V6, P117, DOI [DOI 10.1080/15348450701341253, https://doi.org/10.1080/15348450701341253]
   Seeger A, 2004, WENNER-GR C, P69
   Shankar S, 2012, ANNU REV ANTHROPOL, V41, P355, DOI 10.1146/annurev-anthro-092611-145811
   Shannon JH, 2003, AM ANTHROPOL, V105, P266, DOI 10.1525/aa.2003.105.2.266
   Shoaps R.A., 2002, J LINGUIST ANTHROPOL, V12, P34, DOI DOI 10.1525/jlin.2002.12.1.34
   Silverstein M., 1996, Natural Histories of Discourse, P1
   Silverstein Michael, 1985, Semiotic mediation: Sociocultural and psychological perspective, P219, DOI DOI 10.1016/B978-0-12-491280-9.50016-9
   Silverstein Michael, 2005, J LINGUIST ANTHROPOL, V15, P6, DOI DOI 10.1525/JLIN.2005.15.1.6
   Small C, 1987, Musicking: The Meanings of Performing and Listening
   Stadler G, 2010, SOC TEXT, V28, P87, DOI 10.1215/01642472-2009-061
   Sterne Jonathan, 2003, The Audible Past
   Stirr A, 2010, ETHNOMUSICOLOGY, V54, P257
   Stokes M, 2004, ANNU REV ANTHROPOL, V33, P47, DOI 10.1146/annurev.anthro.33.070203.143916
   Swinehart KF, 2008, J LINGUIST ANTHROPOL, V18, P290, DOI 10.1111/j.1548-1395.2008.00023.x
   Taylor Timothy, 2007, Beyond Exoticism: Western Music and the World
   Taylor Timothy D., 1997, Global Pop: World Music, World Markets
   Tiezzi G, 2010, ATT TERZ CONV INT CO
   Titon JT, 1995, J AM FOLKLORE, V108, P432, DOI 10.2307/541655
   Tomlinson G, 2007, NEW PERSP MUSIC HIST, P1
   Tomlinson G, 2011, CURR ANTHROPOL, V5, P711
   Tucker J, 2011, ETHNOMUSICOLOGY, V55, P387
   Turino T, 1999, ETHNOMUSICOLOGY, V43, P221, DOI 10.2307/852734
   Turino T, 2010, U MICH ANN ARB
   Turino T., 2008, MUSIC SOCIAL LIFE PO
   Urban Greg, 1996, Natural Histories of Discourse
   Urban Greg., 2001, Metaculture: How Culture Moves Through the World
   Van Leeuwen Theo, 1999, SPEECH SOUND MUSIC
   Waksman S, 2003, POP MUSIC SOC, V26, P251, DOI 10.1080/0300776032000116941
   Waksman Steve, 1999, Instruments of Desire: The Electric Guitar and the Shaping of Musical Experience
   Wasson R. Gordon, 1974, MARIA SABINA HER MAZ
   Weidman A., 2011, ANTHR NEWS, V52, P13
   Weidman A., 2006, SINGING CLASSICAL VO
   Wilce James M., 2009, Crying shame metaculture. Modernity, and the exaggerated death of lament
   Wilf E, 2010, AM ETHNOL, V37, P563, DOI 10.1111/j.1548-1425.2010.01273.x
NR 150
TC 45
Z9 61
U1 3
U2 56
PU ANNUAL REVIEWS
PI PALO ALTO
PA 4139 EL CAMINO WAY, PO BOX 10139, PALO ALTO, CA 94303-0897 USA
SN 0084-6570
EI 1545-4290
BN 978-0-8243-1941-0
J9 ANNU REV ANTHROPOL
JI Annu. Rev. Anthropol.
PY 2012
VL 41
BP 519
EP 536
DI 10.1146/annurev-anthro-092611-145851
PG 18
WC Anthropology
WE Book Citation Index – Social Sciences & Humanities (BKCI-SSH); Social Science Citation Index (SSCI)
SC Anthropology
GA BCK35
UT WOS:000310446400032
DA 2024-01-09
ER

PT J
AU Osawa, SI
   Suzuki, K
   Asano, E
   Ukishiro, K
   Agari, D
   Kakinuma, K
   Kochi, R
   Jin, KZTK
   Nakasato, N
   Tominaga, T
AF Osawa, Shin-ichiro
   Suzuki, Kyoko
   Asano, Eishi
   Ukishiro, Kazushi
   Agari, Dai
   Kakinuma, Kazuo
   Kochi, Ryuzaburo
   Jin, Kazutaka
   Nakasato, Nobukazu
   Tominaga, Teiji
TI Causal involvement of medial inferior frontal gyrus of non-dominant
   hemisphere in higher order auditory perception: A single case study
SO CORTEX
LA English
DT Article
DE Medial inferior frontal gyrus; Subjective auditory perception;
   Non-dominant hemisphere; Condition context; Electrical stimulation
ID INHIBITORY CONTROL; LANGUAGE; CORTEX; PROSODY; INSULA; ATTENTION;
   EMOTIONS; MUSIC; VOICE
AB The medial side of the operculum is invisible from the lateral surface of cerebral cortex, and its functions remain largely unexplored using direct evidence. Non-invasive and invasive studies have proved functions on peri-sylvian area including the inferior frontal gyrus (IFG) and superior temporal gyrus within the language-dominant hemisphere for semantic processing during verbal communication. However, within the non-dominant hemisphere, there was less evidence of its functions except for pitch or prosody process-ing. Here we add direct evidence for the functions of the non-dominant hemisphere, the causal involvement of the medial IFG for subjective auditory perception, which is affected by the context of the condition, regarded as a contribution in higher order auditory perception. The phenomenon was clearly distinguished from absolute and invariant pitch perception which is regarded as lower order auditory perception.Electrical stimulation of the medial surface of pars triangularis of IFG in non-dominant hemisphere via depth electrode in an epilepsy patient rapidly and reproducibly elicited perception of pitch changes of auditory input. Pitches were perceived as either higher or lower than those given without stimulation and there was no selectivity for sound type. The patient perceived sounds as higher when she had greater control over the situation when her eyes were open and there were self-cues, and as lower when her eyes were closed and there were investigator-cues. Time-frequency analysis of electrocorticography signals during auditory naming demonstrated medial IFG activation, characterized by low -gamma band augmentation during her own vocal response. The overall evidence provides a neural substrate for altered perception of other vocal tones according to the condition context.& COPY; 2023 Elsevier Ltd. All rights reserved.
C1 [Osawa, Shin-ichiro; Kochi, Ryuzaburo; Tominaga, Teiji] Tohoku Univ, Grad Sch Med, Dept Neurosurg, Sendai, Miyagi, Japan.
   [Suzuki, Kyoko; Kakinuma, Kazuo] Tohoku Univ, Grad Sch Med, Dept Behav Neurol & Cognit Neurosci, Sendai, Miyagi, Japan.
   [Ukishiro, Kazushi; Agari, Dai; Jin, Kazutaka; Nakasato, Nobukazu] Tohoku Univ, Grad Sch Med, Dept Epileptol, Sendai, Miyagi, Japan.
   [Agari, Dai; Nakasato, Nobukazu] Tohoku Univ, Grad Sch Med, Dept Electromagnet Neurophysiol RICOH, Sendai, Miyagi, Japan.
   [Asano, Eishi] Wayne State Univ, Childrens Hosp Michigan, Dept Pediat & Neurol, Detroit, MI USA.
   [Osawa, Shin-ichiro] Tohoku Univ, Grad Sch Med, Dept Neurosurg, 1-1 Seiryo Machi,Aoba Ku, Sendai, Miyagi 9808574, Japan.
C3 Tohoku University; Tohoku University; Tohoku University; Tohoku
   University; Wayne State University; Children's Hospital of Michigan;
   Tohoku University
RP Osawa, SI (corresponding author), Tohoku Univ, Grad Sch Med, Dept Neurosurg, 1-1 Seiryo Machi,Aoba Ku, Sendai, Miyagi 9808574, Japan.
EM osawa@nsg.med.tohoku.ac.jp; kyon@med.tohoku.ac.jp; easano@med.wayne.edu;
   ukishirokazushi@gmail.com; adai.ekpoo@gmail.com;
   kazuo.kakinuma.c1@tohoku.ac.jp; ryuzaburo0618@hotmail.co.jp;
   jink@med.tohoku.ac.jp; nkst@med.tohoku.ac.jp; tomi@nsg.med.tohoku.ac.jp
RI Kakinuma, Kazuo/JRY-5627-2023; Asano, Eishi/AFR-9282-2022
OI Kakinuma, Kazuo/0000-0002-8284-2628; Asano, Eishi/0000-0001-8391-4067
FU Ministry of Education, Culture, Sports, Science and Technol-ogy, Japan
FX Ministry of Education, Culture, Sports, Science and Technol-ogy, Japan.
CR Belyk M, 2014, SOC COGN AFFECT NEUR, V9, P1395, DOI 10.1093/scan/nst124
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Brown EC, 2008, NEUROIMAGE, V41, P1120, DOI 10.1016/j.neuroimage.2008.03.011
   Cai WD, 2017, CEREB CORTEX, V27, P4073, DOI 10.1093/cercor/bhw219
   Cai WD, 2014, J NEUROSCI, V34, P14652, DOI 10.1523/JNEUROSCI.3048-14.2014
   Cai Y, 2016, J COGNITIVE NEUROSCI, V28, P177, DOI 10.1162/jocn_a_00888
   Casey BJ, 1997, J AM ACAD CHILD PSY, V36, P374, DOI 10.1097/00004583-199703000-00016
   Crone NE, 2011, INT J PSYCHOPHYSIOL, V79, P9, DOI 10.1016/j.ijpsycho.2010.10.013
   Ethofer T, 2012, CEREB CORTEX, V22, P191, DOI 10.1093/cercor/bhr113
   Friederici AD, 2004, BRAIN LANG, V89, P267, DOI 10.1016/S0093-934X(03)00351-1
   Friederici AD, 2002, TRENDS COGN SCI, V6, P78, DOI 10.1016/S1364-6613(00)01839-8
   Frühholz S, 2014, PROG NEUROBIOL, V123, P1, DOI 10.1016/j.pneurobio.2014.09.003
   Frühholz S, 2012, CEREB CORTEX, V22, P1107, DOI 10.1093/cercor/bhr184
   Frühholz S, 2016, NEUROSCI BIOBEHAV R, V68, P96, DOI 10.1016/j.neubiorev.2016.05.002
   Glasser MF, 2008, CEREB CORTEX, V18, P2471, DOI 10.1093/cercor/bhn011
   Hoechstetter K, 2004, BRAIN TOPOGR, V16, P233
   Johnson EL, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aat3702
   Kambara T, 2018, CLIN NEUROPHYSIOL, V129, P145, DOI 10.1016/j.clinph.2017.10.018
   Koelsch S, 2006, HUM BRAIN MAPP, V27, P239, DOI 10.1002/hbm.20180
   Nakai Y, 2017, BRAIN, V140, P1351, DOI 10.1093/brain/awx051
   Papp N, 1977, Biomed Sci Instrum, V13, P135
   Pell MD, 2006, BRAIN LANG, V96, P221, DOI 10.1016/j.bandl.2005.04.007
   Poldrack RA, 1999, NEUROIMAGE, V10, P15, DOI 10.1006/nimg.1999.0441
   Ross ED, 2008, BRAIN LANG, V104, P51, DOI 10.1016/j.bandl.2007.04.007
   Rota G, 2009, HUM BRAIN MAPP, V30, P1605, DOI 10.1002/hbm.20621
   Sander K, 2005, J COGNITIVE NEUROSCI, V17, P1519, DOI 10.1162/089892905774597227
   Sommer IEC, 2008, BRAIN, V131, P3169, DOI 10.1093/brain/awn251
   Thompson-Schill SL, 1997, P NATL ACAD SCI USA, V94, P14792, DOI 10.1073/pnas.94.26.14792
   Tolomeo S, 2021, ADDICT BIOL, V26, DOI 10.1111/adb.12976
   Zatorre RJ, 1999, NEUROIMAGE, V10, P544, DOI 10.1006/nimg.1999.0491
NR 30
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER MASSON, CORP OFF
PI PARIS
PA 65 CAMILLE DESMOULINS CS50083 ISSY-LES-MOULINEAUX, 92442 PARIS, FRANCE
SN 0010-9452
EI 1973-8102
J9 CORTEX
JI Cortex
PD JUN
PY 2023
VL 163
BP 57
EP 65
DI 10.1016/j.cortex.2023.02.007
EA APR 2023
PG 9
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA P9MY4
UT WOS:001053858600001
PM 37060887
DA 2024-01-09
ER

PT J
AU Pandeya, YR
   Bhattarai, B
   Lee, J
AF Pandeya, Yagya Raj
   Bhattarai, Bhuwan
   Lee, Joonwhoan
TI Music video emotion classification using slow-fast audio-video network
   and unsupervised feature representation
SO SCIENTIFIC REPORTS
LA English
DT Article
ID RECOGNITION; HISTOGRAMS
AB Affective computing has suffered by the precise annotation because the emotions are highly subjective and vague. The music video emotion is complex due to the diverse textual, acoustic, and visual information which can take the form of lyrics, singer voice, sounds from the different instruments, and visual representations. This can be one reason why there has been a limited study in this domain and no standard dataset has been produced before now. In this study, we proposed an unsupervised method for music video emotion analysis using music video contents on the Internet. We also produced a labelled dataset and compared the supervised and unsupervised methods for emotion classification. The music and video information are processed through a multimodal architecture with audio-video information exchange and boosting method. The general 2D and 3D convolution networks compared with the slow-fast network with filter and channel separable convolution in multimodal architecture. Several supervised and unsupervised networks were trained in an end-to-end manner and results were evaluated using various evaluation metrics. The proposed method used a large dataset for unsupervised emotion classification and interpreted the results quantitatively and qualitatively in the music video that had never been applied in the past. The result shows a large increment in classification score using unsupervised features and information sharing techniques on audio and video network. Our best classifier attained 77% accuracy, an f1-score of 0.77, and an area under the curve score of 0.94 with minimum computational cost.
C1 [Pandeya, Yagya Raj; Bhattarai, Bhuwan; Lee, Joonwhoan] Jeonbuk Natl Univ, Dept Comp Sci & Engn, Jeonju, South Korea.
C3 Jeonbuk National University
RP Pandeya, YR; Lee, J (corresponding author), Jeonbuk Natl Univ, Dept Comp Sci & Engn, Jeonju, South Korea.
EM yagyapandeya@gmail.com; chlee@jbnu.ac.kr
RI Pandeya, Yagya Raj/ACR-3691-2022
OI Pandeya, Yagya Raj/0000-0002-9842-8704
FU National Research Foundation of Korea (NRF) under the Development of AI
   for Analysis and Synthesis of Korean Pansori Project
   [NRF-2021R1A2C2006895]
FX We would also like to express our gratitude to the editors of the
   Writing Center at Jeonbuk National University for their skilled
   English-language assistance. This work was supported by the National
   Research Foundation of Korea (NRF) under the Development of AI for
   Analysis and Synthesis of Korean Pansori NRF-2021R1A2C2006895 Project.
CR Abavisani M, 2018, IEEE J-STSP, V12, P1601, DOI 10.1109/JSTSP.2018.2875385
   Abolhasani M, 2017, MARKETING THEOR, V17, P473, DOI 10.1177/1470593117692021
   Aljanaki A, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0173392
   Aljanaki A, 2016, INFORM PROCESS MANAG, V52, P115, DOI 10.1016/j.ipm.2015.03.004
   [Anonymous], 2016, Content-BasedMultimedia Indexing (CBMI), 201614th International Workshopon, DOI DOI 10.1109/CBMI.2016.7500246
   Avola D, 2022, IEEE T AFFECT COMPUT, V13, P1366, DOI 10.1109/TAFFC.2020.3003816
   Baveye Y, 2015, IEEE T AFFECT COMPUT, V6, P43, DOI 10.1109/TAFFC.2015.2396531
   Berardinis J., 2020, ISMIR2020
   Bhardwaj S, 2019, PROC CVPR IEEE, P354, DOI 10.1109/CVPR.2019.00044
   Bhattarai B, 2020, IEEE ACCESS, V8, P206016, DOI 10.1109/ACCESS.2020.3037773
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chaki S., 2020, ISMIR2020
   Chen Y., 2020, PROC IEEECVF C COMPU, P12090
   Choi W., 2020, ISMIR2020
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   Ekman P., 1999, HDB COGNITION EMOTIO, P45
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Gomez-Canon J. S., 2020, ISMIR2020
   Hallam S., 2016, OXFORD HDB MUSIC PSY, P3
   Hu J., 2019, ARXIV170901507V4
   Jakubik J, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA), P271, DOI 10.1109/INISTA.2017.8001169
   Jeong D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071936
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kaya H, 2017, IMAGE VISION COMPUT, V65, P66, DOI 10.1016/j.imavis.2017.01.012
   Kim JH, 2019, IEEE ACCESS, V7, P41273, DOI 10.1109/ACCESS.2019.2907327
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kostiuk B, 2019, PROC INT C TOOLS ART, P517, DOI 10.1109/ICTAI.2019.00078
   Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343
   Lee J, 2019, IEEE I CONF COMP VIS, P10142, DOI 10.1109/ICCV.2019.01024
   Li X., 2020, LECT NOTES COMP SCI, DOI [10.1007/978-3-030-46640-4_16, DOI 10.1007/978-3-030-46640-4_16]
   Li XH, 2020, PROC CVPR IEEE, P1089, DOI 10.1109/CVPR42600.2020.00117
   Liu Xin, 2017, ARXIV170405665
   Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391
   Makris D., 2014, ARTIFICIAL INTELLIGE, DOI [10.1007/978-3-662-44722-2_18, DOI 10.1007/978-3-662-44722-2_18]
   Malandrakis N, 2011, INT CONF ACOUST SPEE, P2376
   Mohan K, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3031835
   Montagu J., 2017, Frontiers in Sociology, V2, P2, DOI [DOI 10.3389/FSOC.2017.00008, 10.3389/fsoc.2017.00008, DOI 10.3389/FSOC.2017]
   Moore B. C., 2012, An Introduction to the Psychology of Hearing, DOI DOI 10.1080/00224545.1957.9714298
   Morris JD, 1998, ADV CONSUM RES, V25, P518
   Muszynski M, 2021, IEEE T AFFECT COMPUT, V12, P36, DOI 10.1109/TAFFC.2019.2902091
   Nomiya H, 2013, PROCEDIA COMPUT SCI, V22, P375, DOI 10.1016/j.procs.2013.09.115
   North AC, 2010, AM J PSYCHOL, V123, P199, DOI 10.5406/amerjpsyc.123.2.0199
   Omid S. S., 2007, PROC 6 INTERNAL C IN, P1, DOI 10.1109/ICICS.2007.4449839
   Panda R, 2020, IEEE T AFFECT COMPUT, V11, P614, DOI 10.1109/TAFFC.2018.2820691
   Pandeya YR, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144927
   Pandeya YR, 2020, I C INF COMM TECH CO, P273, DOI 10.1109/ICTC49870.2020.9289545
   Pandeya YR, 2020, IEEE ACCESS, V8, P162625, DOI 10.1109/ACCESS.2020.3022058
   Pandeya YR, 2021, MULTIMED TOOLS APPL, V80, P2887, DOI 10.1007/s11042-020-08836-3
   Pandeya YR, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101949
   Pandeya YR, 2018, INT J FUZZY LOG INTE, V18, P154, DOI 10.5391/IJFIS.2018.18.2.154
   Park J, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01880
   Redondo-Cabrera C, 2019, COMPUT VIS IMAGE UND, V179, P79, DOI 10.1016/j.cviu.2018.08.003
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Salih H, 2017, 2017 INTERNATIONAL CONFERENCE ON I-SMAC (IOT IN SOCIAL, MOBILE, ANALYTICS AND CLOUD) (I-SMAC), P692, DOI 10.1109/I-SMAC.2017.8058267
   Shao X, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P2023
   Srivastava N., 2016, ARXIV150204681V3
   Sun M, 2020, CVPR, P10791
   Takahashi N, 2018, INTERSPEECH, P2713, DOI 10.21437/Interspeech.2018-1773
   Tran D, 2019, IEEE I CONF COMP VIS, P5551, DOI 10.1109/ICCV.2019.00565
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Vaezi Joze Hamid Reza, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13286, DOI 10.1109/CVPR42600.2020.01330
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Welch GF, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01246
   Wulfing J., 2012, ISMIR2012
   Xiao Fanyi, 2020, ARXIV200108740, P2020
   Xu JC, 2018, INT C PATT RECOG, P2833, DOI 10.1109/ICPR.2018.8545441
   Yang YH, 2008, IEEE T AUDIO SPEECH, V16, P448, DOI 10.1109/TASL.2007.911513
   Yazdani A, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-26
   Yin D., 2019, ARXIV191104697
   Zhan XH, 2020, PROC CVPR IEEE, P6687, DOI 10.1109/CVPR42600.2020.00672
   Zhang AR, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3356019
   Zhao N, 2017, IEEE T MULTIMEDIA, V19, P2080, DOI 10.1109/TMM.2017.2722687
   Zhu HD, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10217834
NR 77
TC 6
Z9 6
U1 4
U2 14
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD OCT 6
PY 2021
VL 11
IS 1
AR 19834
DI 10.1038/s41598-021-98856-2
PG 14
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Science & Technology - Other Topics
GA WF5ZA
UT WOS:000706380800034
PM 34615904
OA gold, Green Published
DA 2024-01-09
ER

PT J
AU Sievers, B
   Parkinson, C
   Kohler, PJ
   Hughes, JM
   Fogelson, SV
   Wheatley, T
AF Sievers, Beau
   Parkinson, Carolyn
   Kohler, Peter J.
   Hughes, James M.
   Fogelson, Sergey, V
   Wheatley, Thalia
TI Visual and auditory brain areas share a representational structure that
   supports emotion perception
SO CURRENT BIOLOGY
LA English
DT Article
ID SUPERIOR TEMPORAL SULCUS; FACIAL EXPRESSIONS; INTEGRATION; EXPECTATIONS;
   MUSIC; VOICE; FACE; RECOGNITION; INFORMATION; EXPERIENCES
AB Emotionally expressive music and dance occur together across the world. This may be because features shared across the senses are represented the same way even in different sensory brain areas, putting music and movement in directly comparable terms. These shared representations may arise from a general need to identify environmentally relevant combinations of sensory features, particularly those that communicate emotion. To test the hypothesis that visual and auditory brain areas share a representational structure, we created music and animation stimuli with crossmodally matched features expressing a range of emotions. Participants confirmed that each emotion corresponded to a set of features shared across music and movement. A subset of participants viewed both music and animation during brain scanning, revealing that representations in auditory and visual brain areas were similar to one another. This shared representation captured not only simple stimulus features but also combinations of features associated with emotion judgments. The posterior superior temporal cortex represented both music and movement using this same structure, suggesting supramodal abstraction of sensory content. Further exploratory analysis revealed that early visual cortex used this shared representational structure even when stimuli were presented auditorily. We propose that crossmodally shared representations support mutually reinforcing dynamics across auditory and visual brain areas, facilitating crossmodal comparison. These shared representations may help explain why emotions are so readily perceived and why some dynamic emotional expressions can generalize across cultural contexts.
C1 [Sievers, Beau] Harvard Univ, Dept Psychol, 33 Kirkland St, Cambridge, MA 02138 USA.
   [Parkinson, Carolyn] Univ Calif Los Angeles, Dept Psychol, Los Angeles, CA 90095 USA.
   [Parkinson, Carolyn] Univ Calif Los Angeles, Brain Res Inst, Los Angeles, CA 90095 USA.
   [Kohler, Peter J.] York Univ, Dept Psychol, Toronto, ON, Canada.
   [Kohler, Peter J.] York Univ, Ctr Vis Res, Toronto, ON, Canada.
   [Sievers, Beau; Wheatley, Thalia] Dartmouth Coll, Dept Psychol & Brain Sci, Hanover, NH 03755 USA.
   [Wheatley, Thalia] Santa Fe Inst, Santa Fe, NM 87501 USA.
C3 Harvard University; University of California System; University of
   California Los Angeles; University of California System; University of
   California Los Angeles; York University - Canada; York University -
   Canada; Dartmouth College; The Santa Fe Institute
RP Sievers, B (corresponding author), Harvard Univ, Dept Psychol, 33 Kirkland St, Cambridge, MA 02138 USA.; Sievers, B; Wheatley, T (corresponding author), Dartmouth Coll, Dept Psychol & Brain Sci, Hanover, NH 03755 USA.; Wheatley, T (corresponding author), Santa Fe Inst, Santa Fe, NM 87501 USA.
EM beau@beausievers.com; thalia.p.wheatley@dartmouth.edu
RI Kohler, Peter/H-7725-2019
OI Kohler, Peter/0000-0001-5002-3356; Sievers, Beau/0000-0001-8762-7479;
   Wheatley, Thalia/0000-0001-7252-1188; Parkinson,
   Carolyn/0000-0001-7128-3480
FU Nelson A. Rockefeller Center for Public Policy at Dartmouth; John
   Templeton Foun-dation; Neukom Institute for Computational Science;
   Vision Science to Applications (VISTA) program - Canada First Research
   Excel-lence Fund (CFREF, 2016-2023); Natural Sciences and Engineering
   Research Council of Canada
FX We thank Sam Nasatase, Matteo Visconti di Oleggio Castello, J. Swaroop
   Guntupalli, and Joshua Greene for helpful comments during the writing
   pro-cess and Paulina Calcaterra, Rebecca Drapkin, Caitlyn Lee, Elizabeth
   Rey-nolds, Tshibambe Nathanael Tshimbombu, and Kelsey Wheeler for
   assistance collecting fMRI data. This research was supported in part by
   the Nelson A. Rockefeller Center for Public Policy at Dartmouth, the
   John Templeton Foun-dation, the Neukom Institute for Computational
   Science, the Vision Science to Applications (VISTA) program funded by
   the Canada First Research Excel-lence Fund (CFREF, 2016-2023) , and the
   Natural Sciences and Engineering Research Council of Canada.
CR Abraham A, 2014, FRONT NEUROINFORM, V8, DOI 10.3389/fninf.2014.00014
   ADOLPHS R, 1994, NATURE, V372, P669, DOI 10.1038/372669a0
   [Anonymous], P INT COMP MUS C ANN
   Baily John, 1985, MUSICAL STRUCTURE CO, P237
   Barrett LF, 2007, TRENDS COGN SCI, V11, P327, DOI 10.1016/j.tics.2007.06.003
   Barrett LF, 2011, CURR DIR PSYCHOL SCI, V20, P286, DOI 10.1177/0963721411422522
   Beauchamp MS, 2004, NEURON, V41, P809, DOI 10.1016/S0896-6273(04)00070-4
   Belyk M, 2014, SOC COGN AFFECT NEUR, V9, P1395, DOI 10.1093/scan/nst124
   Bulkin DA, 2006, CURR OPIN NEUROBIOL, V16, P415, DOI 10.1016/j.conb.2006.06.008
   Calder AJ, 2001, NAT REV NEUROSCI, V2, P352, DOI 10.1038/35072584
   Cappe C, 2005, EUR J NEUROSCI, V22, P2886, DOI 10.1111/j.1460-9568.2005.04462.x
   Chemero Anthony, 2006, ADV ISSUES COGNITIVE, P59
   Chikazoe J, 2014, NAT NEUROSCI, V17, P1114, DOI 10.1038/nn.3749
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477
   Cowen AS, 2017, P NATL ACAD SCI USA, V114, pE7900, DOI 10.1073/pnas.1702247114
   de Lange FP, 2018, TRENDS COGN SCI, V22, P764, DOI 10.1016/j.tics.2018.06.002
   Deneux T, 2019, ELIFE, V8, DOI 10.7554/eLife.44006
   Destrieux C, 2010, NEUROIMAGE, V53, P1, DOI 10.1016/j.neuroimage.2010.06.010
   Falchier A, 2002, J NEUROSCI, V22, P5749
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Filippi P, 2017, P ROY SOC B-BIOL SCI, V284, DOI 10.1098/rspb.2017.0990
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Gallagher S, 2008, CONSCIOUS COGN, V17, P535, DOI 10.1016/j.concog.2008.03.003
   Gelstein S, 2011, SCIENCE, V331, P226, DOI 10.1126/science.1198331
   Gendron M, 2014, EMOTION, V14, P251, DOI 10.1037/a0036052
   Ghazanfar AA, 2006, TRENDS COGN SCI, V10, P278, DOI 10.1016/j.tics.2006.04.008
   Gopnik A., 1994, The theory theory, P257, DOI DOI 10.1017/CBO9780511752902.011
   Gordon R. M., 1986, Mind Language, V1, P158, DOI [DOI 10.1111/J.1468-0017.1986.TB00324.X, https://doi.org/10.1111/j.1468-0017.1986.tb00324.x]
   Guo JH, 2017, NEUROPSYCHOLOGIA, V105, P215, DOI 10.1016/j.neuropsychologia.2017.03.008
   Hanke M, 2009, NEUROINFORMATICS, V7, P37, DOI 10.1007/s12021-008-9041-y
   Hebets EA, 2016, P ROY SOC B-BIOL SCI, V283, DOI 10.1098/rspb.2015.2889
   Hoemann K, 2019, DEV PSYCHOL, V55, P1830, DOI 10.1037/dev0000686
   Huron D., 2012, P 12 INT C MUS PERC, P473
   Jack RE, 2016, J EXP PSYCHOL GEN, V145, P708, DOI 10.1037/xge0000162
   Jack RE, 2012, J EXP PSYCHOL GEN, V141, P19, DOI 10.1037/a0023463
   Jackson JC, 2019, SCIENCE, V366, P1517, DOI 10.1126/science.aaw8160
   Jenkinson M, 2012, NEUROIMAGE, V62, P782, DOI 10.1016/j.neuroimage.2011.09.015
   Johnstone RA, 1996, PHILOS T R SOC B, V351, P329, DOI 10.1098/rstb.1996.0026
   Johnstone Rufus A., 1997, P155
   Jones E., 2001, SciPy: Open source scientific tools for Python
   KAEPPLER AL, 1978, ANNU REV ANTHROPOL, V7, P31, DOI 10.1146/annurev.an.07.100178.000335
   Kawakami A, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00311
   Kayser C, 2007, BRAIN STRUCT FUNCT, V212, P121, DOI 10.1007/s00429-007-0154-0
   Kim J, 2017, NEUROIMAGE, V148, P42, DOI 10.1016/j.neuroimage.2017.01.002
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Kok P, 2013, J NEUROSCI, V33, P16275, DOI 10.1523/JNEUROSCI.0742-13.2013
   Kreifelts B, 2007, NEUROIMAGE, V37, P1445, DOI 10.1016/j.neuroimage.2007.06.020
   Kriegeskorte N, 2006, P NATL ACAD SCI USA, V103, P3863, DOI 10.1073/pnas.0600244103
   Kriegeskorte N, 2013, TRENDS COGN SCI, V17, P401, DOI 10.1016/j.tics.2013.06.007
   Kriegeskorte N, 2008, FRONT SYST NEUROSCI, V2, DOI 10.3389/neuro.06.004.2008
   Laland KN, 2000, BEHAV BRAIN SCI, V23, P131, DOI 10.1017/S0140525X00002417
   Lang P. J., 2005, Technical Report A-8, DOI 10.1016/j.epsr.2006.03.016
   Levy DJ, 2012, CURR OPIN NEUROBIOL, V22, P1027, DOI 10.1016/j.conb.2012.06.001
   Lindquist KA, 2012, BEHAV BRAIN SCI, V35, P121, DOI 10.1017/S0140525X11000446
   Margulis EH, 2019, PALGR COMMUN, V5, DOI 10.1057/s41599-019-0363-1
   Margulis EH, 2017, MUSIC PERCEPT, V35, P235, DOI 10.1525/MP.2017.35.2.235
   MEHR SA, 2020, BEHAV BRAIN SCI
   Mehr SA, 2019, SCIENCE, V366, P970, DOI 10.1126/science.aax0868
   Murphy DL., 2020, BIORXIV PREPRINT, DOI [10.1101/2020.07.19.210864, DOI 10.1101/2020.07.19.210864]
   Nichols TE, 2002, HUM BRAIN MAPP, V15, P1, DOI 10.1002/hbm.1058
   Nili H, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003553
   Nishimoto S, 2011, CURR BIOL, V21, P1641, DOI 10.1016/j.cub.2011.08.031
   Norman KA, 2006, TRENDS COGN SCI, V10, P424, DOI 10.1016/j.tics.2006.07.005
   Oliphant T. E., 2006, GUIDE NUMPY TRELGOL
   Parkinson C, 2017, EMOTION, V17, P459, DOI 10.1037/emo0000194
   Peelen MV, 2010, J NEUROSCI, V30, P10127, DOI 10.1523/JNEUROSCI.2161-10.2010
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Peres-Neto PR, 2006, ECOLOGY, V87, P2614, DOI 10.1890/0012-9658(2006)87[2614:VPOSDM]2.0.CO;2
   Phillips ML, 1997, NATURE, V389, P495, DOI 10.1038/39051
   Phillips-Silver J, 2005, SCIENCE, V308, P1430, DOI 10.1126/science.1110922
   Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819
   Robins DL, 2009, BRAIN COGNITION, V69, P269, DOI 10.1016/j.bandc.2008.08.007
   Rockland KS, 2003, INT J PSYCHOPHYSIOL, V50, P19, DOI 10.1016/S0167-8760(03)00121-1
   Roskies AL, 2021, SYNTHESE, V199, P5917, DOI 10.1007/s11229-021-03052-4
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Saad ZS, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 and 2, P1510
   Saarimäki H, 2018, SOC COGN AFFECT NEUR, V13, P471, DOI 10.1093/scan/nsy018
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Savage PE, 2015, P NATL ACAD SCI USA, V112, P8987, DOI 10.1073/pnas.1414495112
   Schirmer A, 2017, TRENDS COGN SCI, V21, P216, DOI 10.1016/j.tics.2017.01.001
   Shuster A, 2018, ENEURO, V5, DOI 10.1523/ENEURO.0346-17.2018
   Sievers B, 2013, P NATL ACAD SCI USA, V110, P70, DOI 10.1073/pnas.1209023110
   Sieyers B, 2019, P ROY SOC B-BIOL SCI, V286, DOI 10.1098/rspb.2019.0513
   Skerry AE, 2015, CURR BIOL, V25, P1945, DOI 10.1016/j.cub.2015.06.009
   Spector F, 2009, DEV PSYCHOL, V45, P175, DOI 10.1037/a0014171
   TREHUB SE, 2015, PHILOS T R SOC LON B, V370
   Tsuchiya N, 2009, NAT NEUROSCI, V12, P1224, DOI 10.1038/nn.2380
   Wager TD, 2015, PLOS COMPUT BIOL, V11, DOI 10.1371/journal.pcbi.1004066
   Wang S, 2014, P NATL ACAD SCI USA, V111, pE3110, DOI 10.1073/pnas.1323342111
   Watson R, 2014, J NEUROSCI, V34, P6813, DOI 10.1523/JNEUROSCI.4478-13.2014
   Werner S, 2010, CEREB CORTEX, V20, P1829, DOI 10.1093/cercor/bhp248
   Wheatley, 2021, RAPID DISSONANT GRUN, DOI [10.31234/osf.io/89d2h, DOI 10.31234/OSF.IO/89D2H]
   Wheatley T, 2021, VISUAL AUDITORY BRAI
   Wheeler ME, 2000, P NATL ACAD SCI USA, V97, P11125, DOI 10.1073/pnas.97.20.11125
   Wright TM, 2003, CEREB CORTEX, V13, P1034, DOI 10.1093/cercor/13.10.1034
   Wyk BCV, 2009, PSYCHOL SCI, V20, P771, DOI 10.1111/j.1467-9280.2009.02359.x
   Yuki M, 2007, J EXP SOC PSYCHOL, V43, P303, DOI 10.1016/j.jesp.2006.02.004
NR 97
TC 5
Z9 5
U1 3
U2 22
PU CELL PRESS
PI CAMBRIDGE
PA 50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA
SN 0960-9822
EI 1879-0445
J9 CURR BIOL
JI Curr. Biol.
PD DEC 6
PY 2021
VL 31
IS 23
BP 5192
EP +
DI 10.1016/j.cub.2021.09.043
EA DEC 2021
PG 17
WC Biochemistry & Molecular Biology; Biology; Cell Biology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Biochemistry & Molecular Biology; Life Sciences & Biomedicine - Other
   Topics; Cell Biology
GA XN0PP
UT WOS:000729217200006
PM 34644547
OA hybrid, Green Submitted
DA 2024-01-09
ER

PT J
AU Calderón-Garrido, D
   Gustems-Carnicer, J
AF Calderon-Garrido, Diego
   Gustems-Carnicer, Josep
TI MUSIC AND SOUND FOR BRAND EMPOWERMENT: THE IKEA'S CASE
SO REVISTA DE COMUNICACION DE LA SEECI
LA Spanish
DT Article
DE Multimodality; Music; Sound; Advertising; IKEA; Social Media Emotion
ID EMOTION
AB This paper aims to assess the music and the sound in the enhancement of brand characteristics, taking as an example an ad from IKEA, broadcast for the Christmas campaign 2018. For this aim, we distinguish the most relevant emotions, the orientation towards consumption, together with a psychosocial characterization of the brand. Through a multimodal analysis, carried out by a sample of 86 students of the degree of cinematography at the Higher School of Cinema and Audiovisual of Catalonia who repeatedly visualized this announcement, a predominance of sadness and nervousness was observed through, not only images, but the use of music already used in other audiovisual products (Claire de Lune de C. Debussy), the use of voices and a strategic use of silences. Thanks to multimodal analysis, the orientation of the ad towards human values is appreciated, as well as a certain preponderance of young people and women in the interest to this brand, through the use of sound.
C1 [Calderon-Garrido, Diego] Univ Barcelona, Fac Educ, Dept Didact Aplicadas, Barcelona, Spain.
   [Gustems-Carnicer, Josep] Univ Barcelona, Barcelona, Spain.
C3 University of Barcelona; University of Barcelona
RP Calderón-Garrido, D (corresponding author), Univ Barcelona, Fac Educ, Dept Didact Aplicadas, Barcelona, Spain.
EM dcalderon@ub.edu; jgustems@ub.edu
RI Calderón-Garrido, Diego/P-9365-2015
OI Calderón-Garrido, Diego/0000-0002-2860-6747
CR Aiello G, 2014, VISUAL COMMUN-US, V13, P303, DOI 10.1177/1470357214530054
   Alcalde J., 2007, Musica y comunicacion
   [Anonymous], 2006, MANAGING SERVICE QUA
   BRUNER GC, 1990, J MARKETING, V54, P94, DOI 10.1177/002224299005400408
   Chion M., 1993, AUDIOVISION INTRO AN
   Cluley R, 2019, MARKETING THEOR, V19, P405, DOI 10.1177/1470593119856645
   Coker KK, 2021, J RES INTERACT MARK, V15, P607, DOI 10.1108/JRIM-05-2020-0115
   Dafonte-Gómez A, 2016, PALABRA CLAVE, V19, P501, DOI 10.5294/pacla.2016.19.2.7
   Diaz-Andreu M., 2013, Music Ritual: Bridging Mater, P227
   DIENER E, 1984, J PERS SOC PSYCHOL, V47, P1105, DOI 10.1037/0022-3514.47.5.1105
   Escribano G., 2006, POLITICAS MARKETING
   Fedrizzi L, 2012, REND LINCEI-SCI FIS, V23, P259, DOI 10.1007/s12210-012-0177-1
   Gonzalez-Abarca A. J., 2018, SALUD JALISCO, V1, P47
   Griffiths NK, 2018, MUSIC PERCEPT, V35, P364, DOI 10.1525/MP.2018.35.3.364
   Gummesson E, 2014, J SERV MANAGE, V25, P228, DOI 10.1108/JOSM-01-2014-0031
   Gustems J., 2005, EUFONIA, V34, P91
   Halliday M.A.K, 1978, Language as Social Semiotic: The Social Interpretation of Language and Meaning
   Hernandez C., 2018, BIENESTAR, P180
   IKEA, 2018, FAM VID
   Isidro A. I., 2018, INT J DEV ED PSYCHOL, V1, P203, DOI DOI 10.17060/IJODAEP.2018.N1.V4.1295
   Juslin P. N., 2011, HDB MUSIC EMOTION TH
   Kang JA, 2020, J CONSUM BEHAV, V19, P47, DOI 10.1002/cb.1793
   KRESS G. R., 2001, Multimodal Discourse: The Modes and Media of Contemporary Communication
   Ledin P., 2018, VISUAL COMMUN, P1, DOI [10.1177/1457, DOI 10.1177/1457]
   Lee，Do-Hee, 2014, [Asia Marketing Journal, 아시아마케팅저널], V15, P103
   Livingstone SR, 2006, MUSIC PERCEPT, V24, P89, DOI 10.1525/mp.2006.24.1.89
   Machin David., 2007, Global Media Discourse: A Critical Introduction
   Melgar J., 2019, ANAL EMOCIONES TRAVE
   Nardone G., 2006, DIALOGO ESTRATEGICO
   North AC., 1995, PSYCHOMUSICOLOGY, V14, P77, DOI [10.1037/h0094090, DOI 10.1037/H0094090]
   Norton MI, 2012, J CONSUM PSYCHOL, V22, P453, DOI 10.1016/j.jcps.2011.08.002
   Nowack K, 2019, PSYCHOL MUSIC, V47, P736, DOI 10.1177/0305735618775200
   O'Halloran KL, 2008, VISUAL COMMUN-US, V7, P443, DOI 10.1177/1470357208096210
   Palencia-Lefler M., 2010, COMUN SOC-NAVARRA, V23, P299
   Portela-Fontan A., 2020, ARTSEDUCA, V25, P85, DOI 10.6035/Artseduca.2020.25.5
   Ribeiro-Cardoso J. P., 2019, REV MEDITERRANEA COM, V10, P203
   Roberts K., 2005, LOVEMARKS FUTURO MAS
   Rodriguez Bravo Angel, 1998, DIMENSION SONORA LEN
   Ruas J., 2018, PERSUASION NEUROCIEN
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Sánchez-Porras MJ, 2013, HIST COMUN SOC, V18, P349, DOI 10.5209/rev_HICS.2013.v18.44333
   Schubert E, 1999, AUST J PSYCHOL, V51, P154, DOI 10.1080/00049539908255353
   Sedeno A., 2011, SINFONIA VIRTUAL, V18
   Strobel H., 1990, CLAUDE DEBUSSY
   Van Leeuwen T., 2017, SOUND AND VISION, V6, P136
   Verlaine P., 1999, 100 ONE POEMS PAUL V
   Yang KCC, 2021, J CREAT COMMUN, V16, P7, DOI 10.1177/0973258620984262
   Yilmaz Hakan, 2015, International Journal of Internet Marketing and Advertising, V9, P3, DOI 10.1504/IJIMA.2015.068356
NR 48
TC 1
Z9 1
U1 1
U2 6
PU UNIV COMPLUTENSE MADRID, FAC CIENCIAS INFORMACION
PI MADRID
PA AVE COMPLUTENSE, S-N, MADRID, 28040, SPAIN
SN 1575-9628
EI 1576-3420
J9 REV COMUN SEECI
JI Rev. Comun. SEECI
PY 2021
IS 54
BP 205
EP 222
DI 10.15198/seeci.2021.54.e722
PG 18
WC Communication
WE Emerging Sources Citation Index (ESCI)
SC Communication
GA YC7AS
UT WOS:000739840500012
OA Green Submitted, Green Published, hybrid
DA 2024-01-09
ER

PT J
AU Zhou, SS
   Gao, X
   Hu, YJ
   Zhu, YM
   Tian, YH
   Wang, K
AF Zhou, Shan-Shan
   Gao, Xin
   Hu, Ya-Juan
   Zhu, Yi-Ming
   Tian, Yang-Hua
   Wang, Kai
TI Selective impairment of musical emotion recognition in patients with
   amnesic mild cognitive impairment and mild to moderate Alzheimer disease
SO CHINESE MEDICAL JOURNAL
LA English
DT Article
DE Mild cognitive impairment; Alzheimer disease; Musical emotion; Melody
   recognition; Brain network
ID DEMENTIA; JUDGMENTS; MEMORY; EXPRESSIONS; ACTIVATION; SYMPTOMS; PROSODY;
   VOICE
AB Background Patients with Alzheimer disease (AD) and amnesic mild cognitive impairment (aMCI) have deficits in emotion recognition. However, it has not yet been determined whether patients with AD and aMCI also experience difficulty in recognizing the emotions conveyed by music. This study was conducted to investigate whether musical emotion recognition is impaired or retained in patients with AD and aMCI. Methods All patients were recruited from the First Affiliated Hospital of Anhui Medical University between March 1, 2015 and January 31, 2017. Using the musical emotion recognition test, patients with AD (n = 16), patients with aMCI (n = 19), and healthy controls (HCs, n = 16) were required to choose one of four emotional labels (happy, sad, peaceful, and fearful) that matched each musical excerpt. Emotion recognition scores in three groups were compared using one-way analysis of variance (ANOVA) test. We also investigated the relationship between the emotion recognition scores and Mini-Mental State Examination (MMSE) using Pearson's correlation analysis test in patients with AD and aMCI. Results Compared to the HC group, both of the patient groups showed deficits in the recognition of fearful musical emotions (HC: 7.88 +/- 1.36; aMCI: 5.05 +/- 2.34; AD: 3.69 +/- 2.02), with results of a one-way ANOVA confirming a significant main effect of group (F-(2,F-50) = 18.70, P < 0.001). No significant differences were present among the three groups for the happy (F-(2,F-50)=2.57, P = 0.09), peaceful (F-(2,F-50) = 0.38, P = 0.09), or sad (F-(2,F-50) = 2.50, P = 0.09) musical emotions. The recognition of fearful musical emotion was positively associated with general cognition, which was evaluated by MMSE in patients with AD and aMCI (r = 0.578, P < 0.001). The correlations between the MMSE scores and recognition of the remaining emotions were not significant (happy, r = 0.228, P = 0.11; peaceful, r = 0.047, P = 0.74; sad, r = 0.207, P = 0.15). Conclusion This study showed that both patients with AD and aMCI had decreased ability to distinguish fearful emotions, which might be correlated with diminished cognitive function.
C1 [Zhou, Shan-Shan; Hu, Ya-Juan; Zhu, Yi-Ming; Tian, Yang-Hua; Wang, Kai] Anhui Med Univ, Dept Neurol, Affiliated Hosp 1, Hefei 230022, Anhui, Peoples R China.
   [Gao, Xin] First Peoples Hosp Jiujiang, Dept Neurol, Jiujiang 332000, Jiangxi, Peoples R China.
   [Wang, Kai] Collaborat Innovat Ctr Neuropsychiat Disorders &, Hefei 230032, Anhui, Peoples R China.
   [Wang, Kai] Anhui Med Univ, Dept Med Psychol, Hefei 230032, Anhui, Peoples R China.
C3 Anhui Medical University; Anhui Medical University
RP Wang, K (corresponding author), Anhui Med Univ, Dept Neurol, Affiliated Hosp 1, Hefei 230022, Anhui, Peoples R China.
EM wangkai1964@126.com
RI Wang, Kai/IWD-8760-2023
OI Wang, Kai/0000-0002-6170-4744; Hu, Yajuan/0000-0002-5378-8685; Tian,
   Yanghua/0000-0001-5038-0599
FU National Natural Science Foundation of China [31571149, 91232717,
   81171273]; Anhui Provincial Natural Science Foundation [1608085MH169]
FX This work was supported by grants from the National Natural Science
   Foundation of China (Nos. 31571149, 91232717, and 81171273) and Anhui
   Provincial Natural Science Foundation (No. 1608085MH169).
CR Adolphs R, 2001, NEUROPSYCHOLOGY, V15, P396, DOI 10.1037//0894-4105.15.3.396
   Bora E, 2016, EPILEPSY BEHAV, V60, P50, DOI 10.1016/j.yebeh.2016.04.024
   Borg C, 2013, NEUROCASE, V19, P592, DOI 10.1080/13554794.2012.713491
   Braak H, 2015, ADV ANAT EMBRYOL CEL, V215, P135, DOI 10.1007/978-3-319-12679-1_11
   Calder AJ, 2003, NEUROPSYCHOLOGIA, V41, P195, DOI 10.1016/S0028-3932(02)00149-5
   Cuddy LL, 2015, ANN NY ACAD SCI, V1337, P223, DOI 10.1111/nyas.12617
   Demenescu LR, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/590216
   Drapeau J, 2009, ANN NY ACAD SCI, V1169, P342, DOI 10.1111/j.1749-6632.2009.04768.x
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Gagnon L, 2009, NEUROPSYCHOLOGY, V23, P90, DOI 10.1037/a0013790
   Gosselin N, 2005, BRAIN, V128, P628, DOI 10.1093/brain/awh420
   Gosselin N, 2011, CORTEX, V47, P1116, DOI 10.1016/j.cortex.2011.05.012
   Hailstone JC, 2011, BRAIN, V134, P2535, DOI 10.1093/brain/awr205
   Hsieh S, 2012, NEUROPSYCHOLOGIA, V50, P1814, DOI 10.1016/j.neuropsychologia.2012.04.006
   Irish M, 2006, DEMENT GERIATR COGN, V22, P108, DOI 10.1159/000093487
   Jahng GH, 2016, BRAIN IMAGING BEHAV, V10, P1015, DOI 10.1007/s11682-015-9469-2
   Kerer M, 2014, GERONTOLOGY, V60, P402, DOI 10.1159/000358010
   Khalfa S, 2008, NEUROPSYCHOLOGIA, V46, P2485, DOI 10.1016/j.neuropsychologia.2008.04.009
   Koelsch S, 2010, TRENDS COGN SCI, V14, P131, DOI 10.1016/j.tics.2010.01.002
   Kumfor F, 2014, BRAIN, V137, P3061, DOI 10.1093/brain/awu246
   Matthews BR, 2009, NEUROCASE, V15, P248, DOI 10.1080/13554790802632934
   MCKHANN G, 1984, NEUROLOGY, V34, P939, DOI 10.1212/WNL.34.7.939
   Omar R, 2011, NEUROIMAGE, V56, P1814, DOI 10.1016/j.neuroimage.2011.03.002
   Omar R, 2010, BRAIN, V133, P1200, DOI 10.1093/brain/awp345
   Peretz I, 1999, NEUROCASE, V5, P21, DOI 10.1093/neucas/5.1.21
   Perlovsky L, 2010, PHYS LIFE REV, V7, P2, DOI 10.1016/j.plrev.2009.11.001
   Petersen RC, 2001, ARCH NEUROL-CHICAGO, V58, P1985, DOI 10.1001/archneur.58.12.1985
   Petersen RC, 2004, J INTERN MED, V256, P183, DOI 10.1111/j.1365-2796.2004.01388.x
   Phan KL, 2002, NEUROIMAGE, V16, P331, DOI 10.1006/nimg.2002.1087
   Richard-Mornas A, 2012, DEMENT GERIATR COGN, V33, P43, DOI 10.1159/000336599
   Rosen HJ, 2002, BRAIN, V125, P2286, DOI 10.1093/brain/awf225
   Samson S, 2009, ANN NY ACAD SCI, V1169, P245, DOI 10.1111/j.1749-6632.2009.04555.x
   Schneider F, 1997, PSYCHIAT RES-NEUROIM, V76, P75, DOI 10.1016/S0925-4927(97)00063-2
   Scott SK, 1997, NATURE, V385, P254, DOI 10.1038/385254a0
   Spoletini I, 2008, AM J GERIAT PSYCHIAT, V16, P389, DOI 10.1097/JGP.0b013e318165dbce
   Takizawa C, 2015, J ALZHEIMERS DIS, V43, P1271, DOI 10.3233/JAD-141134
   Testa JA, 2001, NEUROLOGY, V57, P1474, DOI 10.1212/WNL.57.8.1474
   Ueda T, 2013, AGEING RES REV, V12, P628, DOI 10.1016/j.arr.2013.02.003
   Weiss EM, 2008, AM J GERIAT PSYCHIAT, V16, P974, DOI 10.1097/JGP.0b013e318186bd53
   Xu LL, 2016, J ALZHEIMERS DIS, V51, P1045, DOI 10.3233/JAD-151010
   Zatorre RJ, 2013, P NATL ACAD SCI USA, V110, P10430, DOI 10.1073/pnas.1301228110
   Zhao QF, 2016, J AFFECT DISORDERS, V190, P264, DOI 10.1016/j.jad.2015.09.069
NR 42
TC 2
Z9 2
U1 2
U2 16
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0366-6999
EI 2542-5641
J9 CHINESE MED J-PEKING
JI Chin. Med. J.
PD OCT 5
PY 2019
VL 132
IS 19
BP 2308
EP 2314
DI 10.1097/CM9.0000000000000460
PG 7
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC General & Internal Medicine
GA JX1EK
UT WOS:000503485700006
PM 31567383
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Baltes, FR
   Avram, J
   Miclea, M
   Miu, AC
AF Baltes, Felicia Rodica
   Avram, Julia
   Miclea, Mircea
   Miu, Andrei C.
TI Emotions induced by operatic music: Psychophysiological effects of
   music, plot, and acting A scientist's tribute to Maria Callas
SO BRAIN AND COGNITION
LA English
DT Article
DE Operatic music; Music-induced emotions; Physiological differentiation of
   emotions
ID RESPONSES; EXPRESSION; EXPERIENCE; CHILLS; VOICE
AB Operatic music involves both singing and acting (as well as rich audiovisual background arising from the orchestra and elaborate scenery and costumes) that multiply the mechanisms by which emotions are induced in listeners. The present study investigated the effects of music, plot, and acting performance on emotions induced by opera. There were three experimental conditions: (1) participants listened to a musically complex and dramatically coherent excerpt from Tosca; (2) they read a summary of the plot and listened to the same musical excerpt again; and (3) they re-listened to music while they watched the subtitled film of this acting performance. In addition, a control condition was included, in which an independent sample of participants succesively listened three times to the same musical excerpt. We measured subjective changes using both dimensional, and specific music-induced emotion questionnaires. Cardiovascular, electrodermal, and respiratory responses were also recorded, and the participants kept track of their musical chills. Music listening alone elicited positive emotion and autonomic arousal, seen in faster heart rate, but slower respiration rate and reduced skin conductance. Knowing the (sad) plot while listening to the music a second time reduced positive emotions (peacefulness, joyful activation), and increased negative ones (sadness), while high autonomic arousal was maintained. Watching the acting performance increased emotional arousal and changed its valence again (from less positive/sad to transcendent), in the context of continued high autonomic arousal. The repeated exposure to music did not by itself induce this pattern of modifications. These results indicate that the multiple musical and dramatic means involved in operatic performance specifically contribute to the genesis of music-induced emotions and their physiological correlates. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Baltes, Felicia Rodica; Avram, Julia; Miclea, Mircea; Miu, Andrei C.] Univ Babes Bolyai, Dept Psychol, Emot & Cognit Neurosci Lab, Cluj Napoca 400015, CJ, Romania.
C3 Babes Bolyai University from Cluj
RP Miu, AC (corresponding author), 37 Republ, Cluj Napoca 400015, CJ, Romania.
EM andreimiu@gmail.com
RI Miu, Andrei C./C-5184-2011
OI Miu, Andrei C./0000-0002-6459-5010
FU Society for Education, Music, and Psychology (SEMPRE); National
   University Research Council [411/2010]
FX We are grateful to Dr. Laurel J. Trainor and two anonymous reviewers for
   important suggestions that helped us in improving the present article,
   and Dr. Marcel Zentner for permission to use the Geneva Emotional Music
   Scale (GEMS-45) in the study. We also thank Silviu Matu for help with
   data collection. This research was supported by the 2010 Arnold Bentley
   Award from the Society for Education, Music, and Psychology (SEMPRE) to
   R.F.B. and A.C.M., and grant 411/2010 from the National University
   Research Council to A.C.M.
CR Ali SO., 2006, Psychology of Music, V34, P511, DOI DOI 10.1177/0305735606067168
   Bechara A, 1999, J NEUROSCI, V19, P5473
   Bernardi L, 2009, CIRCULATION, V119, P3171, DOI 10.1161/CIRCULATIONAHA.108.806174
   Bezdek MA, 2008, BEHAV BRAIN SCI, V31, P578, DOI 10.1017/S0140525X08005323
   Bharucha JJ, 2006, COGNITION, V100, P131, DOI 10.1016/j.cognition.2005.11.008
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Bleil ME, 2008, PSYCHOSOM MED, V70, P328, DOI 10.1097/PSY.0b013e31816baefa
   Bradley MM, 2000, PSYCHOPHYSIOLOGY, V37, P204, DOI 10.1111/1469-8986.3720204
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Cacioppo J., 1998, Annual review of gerontology and geriatrics, V17, P27
   Camm AJ, 1996, CIRCULATION, V93, P1043
   CHIASCHI M, 2007, THESIS FLORIDA STATE
   Codispoti M, 2001, PSYCHOPHYSIOLOGY, V38, P474, DOI 10.1017/S004857720198028X
   Cohen J, 1988, STAT POWER ANAL BEHA
   de Gelder B, 1999, NEUROSCI LETT, V260, P133, DOI 10.1016/S0304-3940(98)00963-X
   DeNora T, 1999, POETICS, V27, P31, DOI 10.1016/S0304-422X(99)00017-0
   Diserens CM, 1923, PSYCHOL BULL, V20, P173, DOI 10.1037/h0071546
   Eckberg DL, 1997, CIRCULATION, V96, P3224, DOI 10.1161/01.CIR.96.9.3224
   EKMAN P, 1983, SCIENCE, V221, P1208, DOI 10.1126/science.6612338
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Frazier TW, 2004, PSYCHOPHYSIOLOGY, V41, P75, DOI 10.1046/j.1469-8986.2003.00131.x
   Grewe O, 2007, EMOTION, V7, P774, DOI 10.1037/1528-3542.7.4.774
   Grewe O, 2007, MUSIC PERCEPT, V24, P297, DOI 10.1525/MP.2007.24.3.297
   Guhn M, 2007, MUSIC PERCEPT, V24, P473, DOI 10.1525/MP.2007.24.5.473
   Hietanen JK, 1998, PSYCHOPHYSIOLOGY, V35, P530, DOI 10.1017/S0048577298970445
   HUCK W, 1984, OPERA QUART, V2, P175, DOI 10.1093/oq/2.3.175
   Hyde IH, 1918, AM J PHYSIOL, V46, P35, DOI 10.1152/ajplegacy.1918.46.1.35
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2008, EMOTION, V8, P668, DOI 10.1037/a0013505
   KALLINEN K, 2004, INT C MUS PERC COGN
   Khalfa S, 2002, NEUROSCI LETT, V328, P145, DOI 10.1016/S0304-3940(02)00462-7
   KINGWELL BA, 1994, CIRCULATION, V90, P234, DOI 10.1161/01.CIR.90.1.234
   Kivy P., 1990, Music Alone: Philosophical Reflections on the Purely Musical Experience
   Koelsch S, 2005, ANN NY ACAD SCI, V1060, P412, DOI 10.1196/annals.1360.034
   Kreibig SD, 2007, PSYCHOPHYSIOLOGY, V44, P787, DOI 10.1111/j.1469-8986.2007.00550.x
   Kreutz G, 2008, PSYCHOL MUSIC, V36, P101, DOI 10.1177/0305735607082623
   Krumhansl CL, 1997, CAN J EXP PSYCHOL, V51, P336, DOI 10.1037/1196-1961.51.4.336
   LEVENSON RW, 1992, PSYCHOL SCI, V3, P23, DOI 10.1111/j.1467-9280.1992.tb00251.x
   Lundqvist LO, 2009, PSYCHOL MUSIC, V37, P61, DOI 10.1177/0305735607086048
   LUNDQVIST LO, 1995, J PSYCHOPHYSIOL, V9, P203
   Miu AC, 2008, BIOL PSYCHOL, V77, P353, DOI 10.1016/j.biopsycho.2007.11.010
   Miu AC, 2009, AUTON NEUROSCI-BASIC, V145, P99, DOI 10.1016/j.autneu.2008.11.010
   Nakahara H, 2010, INT J PSYCHOPHYSIOL, V75, P268, DOI 10.1016/j.ijpsycho.2009.12.008
   Nater UM, 2006, INT J PSYCHOPHYSIOL, V62, P300, DOI 10.1016/j.ijpsycho.2006.05.011
   Nyklicek I, 1997, J PSYCHOPHYSIOL, V11, P304
   Panksepp J, 1995, MUSIC PERCEPT, V13, P171
   Peretz I, 2001, BRAIN, V124, P928, DOI 10.1093/brain/124.5.928
   Rickard N. S., 2004, Psychology of Music, V32, P371, DOI [10.1177%2F0305735604046096, DOI 10.1177/0305735604046096, 10.1177/0305735604046096]
   Scherer K. R., 2001, MUSIC EMOTION THEORY, P361, DOI DOI 10.1080/0929821042000317822
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   SLOBODA J, 1992, MUSIC CHILD DEV, P28
   Sloboda J. A., 1991, Psychology of Music, V19, P110, DOI [10.1177/0305735691192002, DOI 10.1177/0305735691192002]
   Sloboda JA., 2001, MUSIC EMOTION THEORY, P71
   Sloboda JA, 2001, MUSIC SCI, V5, P237, DOI 10.1177/10298649020050S109
   Stevens J., 2002, APPL MULTIVARIATE ST
   STRATTON VN, 1994, PSYCHOL MUSIC, V12, P70
   Tan SL, 2007, MUSIC PERCEPT, V25, P135, DOI 10.1525/MP.2007.25.2.135
   VAITL D, 1993, STRUCTURE EMOTION PS, P169
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   Vitouch, 2001, PSYCHOL MUSIC, V29, P70, DOI DOI 10.1177/0305735601291005
   Watson D., 1999, The PANAS-X: Manual for the positive and negative affect schedule-expanded form, DOI [10.17077/48vt-m4t2, DOI 10.17077/48VT-M4T2]
   WATT R, 1998, MUSIC SCI, V2, P33
   Witvliet CVO, 2007, COGNITION EMOTION, V21, P3, DOI 10.1080/02699930601000672
   ZEFFIRELLI F, 2002, MARIA CALLAS COVENT
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 65
TC 40
Z9 49
U1 1
U2 41
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0278-2626
EI 1090-2147
J9 BRAIN COGNITION
JI Brain Cogn.
PD JUN
PY 2011
VL 76
IS 1
BP 146
EP 157
DI 10.1016/j.bandc.2011.01.012
PG 12
WC Neurosciences; Psychology, Experimental
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Neurosciences & Neurology; Psychology
GA 758AL
UT WOS:000290131700019
PM 21477909
DA 2024-01-09
ER

PT J
AU Liang, SR
   Shu, R
AF Liang, Shaoru
   Shu, Ran
TI Extraction of Music Main Melody and Multi-Pitch Estimation Method Based
   on Support Vector Machine in Big Data Environment
SO JOURNAL OF ENVIRONMENTAL AND PUBLIC HEALTH
LA English
DT Article
ID EMOTION RECOGNITION; MODEL
AB Main melody extraction and multi-pitch estimation are two important research topics in the MIR field. In this article, the SVM algorithm is used to analyze and discuss music melody extraction and multi-pitch estimation. In the part of multi-fundamental frequency extraction, this article first filters the song signal with equal loudness and weakens the energy of the high-frequency and low-frequency parts of the song signal. Thereafter, the multi-resolution short-time Fourier transform suitable for processing song signals is introduced. In addition, in order to avoid the sharp jump of the estimated melody pitch in the same note duration range, this article proposes a main melody extraction method combining the SVM algorithm with dynamic programming. In this article, more features are used to distinguish the pitch contour of vocal fundamental frequency from that of the nonvocal fundamental frequency, which does not only depend on energy or a certain feature. The experimental results show that the lowest octave error of this method is 1.46. Meanwhile, the recall rate of the algorithm can reach about 95%. This method not only improves the recall rate of the fundamental frequency of the human voice but also improves the recall rate and pitch accuracy rate of the whole main melody extraction system.
C1 [Liang, Shaoru] North Univ China, Sch Art, Taiyuan 030051, Peoples R China.
   [Shu, Ran] Guizhou Normal Coll, Guiyang 550018, Peoples R China.
C3 North University of China; Guizhou Education University
RP Shu, R (corresponding author), Guizhou Normal Coll, Guiyang 550018, Peoples R China.
EM liangshaoru329@163.com; shuran@gznc.edu.cn
CR Baró A, 2019, PATTERN RECOGN LETT, V123, P1, DOI 10.1016/j.patrec.2019.02.029
   Calvo-Zaragoza J, 2017, EXPERT SYST APPL, V72, P395, DOI 10.1016/j.eswa.2016.10.041
   Chin YH, 2017, IET SIGNAL PROCESS, V11, P884, DOI 10.1049/iet-spr.2016.0021
   Corrêa DC, 2016, EXPERT SYST APPL, V60, P190, DOI 10.1016/j.eswa.2016.04.008
   Daltrozzo J, 2010, J COGNITIVE NEUROSCI, V22, P1754, DOI 10.1162/jocn.2009.21311
   Dong YZ, 2019, IEEE T MULTIMEDIA, V21, P3150, DOI 10.1109/TMM.2019.2918739
   Fukayama S., 2016, J ACOUST SOC AM, V140, P3091, DOI [10.1121/1.4969635, DOI 10.1121/1.4969635]
   Kim HG, 2019, IEEE T CONSUM ELECTR, V65, P349, DOI 10.1109/TCE.2019.2924177
   Kostek Bozena, 2013, Journal of the Acoustical Society of America, V134, DOI 10.1121/1.4830570
   Kroher N, 2018, COMPUT MUSIC J, V41, P64, DOI [10.1162/comj_a_00440, 10.1162/COMJ_a_00440]
   Lee J, 2017, IEEE SIGNAL PROC LET, V24, P1208, DOI 10.1109/LSP.2017.2713830
   Palmer SE, 2016, MULTISENS RES, V29, P157, DOI 10.1163/22134808-00002486
   Panda R, 2015, APPL ARTIF INTELL, V29, P313, DOI 10.1080/08839514.2015.1016389
   Raposo FA, 2019, PATTERN RECOGN LETT, V123, P75, DOI 10.1016/j.patrec.2019.03.014
   Wang JC, 2015, IEEE T AFFECT COMPUT, V6, P261, DOI 10.1109/TAFFC.2015.2415212
   Yao G, 2013, ELEKTRON ELEKTROTECH, V19, P103, DOI 10.5755/j01.eee.19.6.4575
   Yao P, 2022, SCI PROGRAMMING-NETH, V2022, DOI 10.1155/2022/9735392
   Zhang KD, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/9298654
   Zhang WW, 2016, APPL ACOUST, V112, P70, DOI 10.1016/j.apacoust.2016.04.023
   Zheng B, 2020, J INTELL FUZZY SYST, V39, P8927, DOI 10.3233/JIFS-189290
NR 20
TC 0
Z9 0
U1 0
U2 10
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1687-9805
EI 1687-9813
J9 J ENVIRON PUBLIC HEA
JI J. Environ. Public Health
PD AUG 31
PY 2022
VL 2022
AR 1074174
DI 10.1155/2022/1074174
PG 11
WC Public, Environmental & Occupational Health
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Public, Environmental & Occupational Health
GA 5A6BR
UT WOS:000862971200001
PM 36089952
OA gold, Green Published
DA 2024-01-09
ER

PT J
AU Nakata, T
   Trehub, SE
   Kanda, Y
AF Nakata, Takayuki
   Trehub, Sandra E.
   Kanda, Yukihiko
TI Effect of cochlear implants on children's perception and production of
   speech prosody
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID NORMAL-HEARING LISTENERS; SPEAKING CHILDREN; MUSIC PERCEPTION; VOCAL
   EMOTION; RECIPIENTS; VOICE; INTELLIGIBILITY; INDIVIDUALS; INTONATION;
   TONES
AB Japanese 5- to 13-yr-olds who used cochlear implants (CIs) and a comparison group of normally hearing (NH) Japanese children were tested on their perception and production of speech prosody. For the perception task, they were required to judge whether semantically neutral utterances that were normalized for amplitude were spoken in a happy, sad, or angry manner. The performance of NH children was error-free. By contrast, child CI users performed well below ceiling but above chance levels on happy-and sad-sounding utterances but not on angry-sounding utterances. For the production task, children were required to imitate stereotyped Japanese utterances expressing disappointment and surprise as well as culturally typically representations of crow and cat sounds. NH 5- and 6-year-olds produced significantly poorer imitations than older hearing children, but age was unrelated to the imitation quality of child CI users. Overall, child CI user's imitations were significantly poorer than those of NH children, but they did not differ significantly from the imitations of the youngest NH group. Moreover, there was a robust correlation between the performance of child CI users on the perception and production tasks; this implies that difficulties with prosodic perception underlie their difficulties with prosodic imitation. (C) 2012 Acoustical Society of America. [DOI: 10.1121/1.3672697]
C1 [Nakata, Takayuki] Future Univ Hakodate, Dept Complex & Intelligent Syst, Hakodate, Hokkaido 0418655, Japan.
   [Trehub, Sandra E.] Univ Toronto, Dept Psychol, Mississauga, ON L5L 1C6, Canada.
   [Kanda, Yukihiko] Kanda ENT Clin, Nagasaki 8528023, Japan.
   [Kanda, Yukihiko] Nagasaki Bell Hearing Ctr, Nagasaki 8528023, Japan.
C3 Future University Hakodate; University of Toronto; University Toronto
   Mississauga
RP Nakata, T (corresponding author), Future Univ Hakodate, Dept Complex & Intelligent Syst, 116-2 Kamedanakano, Hakodate, Hokkaido 0418655, Japan.
EM nakata@fun.ac.jp
FU Japan Society for the Promotion of Science; Natural Sciences and
   Engineering Research Council of Canada; Grants-in-Aid for Scientific
   Research [21530762] Funding Source: KAKEN
FX This research was supported by grants from the Japan Society for the
   Promotion of Science to T.N. and from the Natural Sciences and
   Engineering Research Council of Canada to S.E.T. We gratefully
   acknowledge the cooperation of many parents and children whose
   participation made this study possible. We also acknowledge the
   insightful advice of Dr. Haruo Takahashi and Hideo Tanaka and assistance
   with data collection from Akiko Ito, Yumiko Kido, Yoko Kakita, Noriko
   Matsunaga, Kyoko Ohba, Kyoko Sasaki, and Naoko Maruo.
CR [Anonymous], PROCESSING COMPLEX S
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Barry JG, 2002, CLIN LINGUIST PHONET, V16, P79, DOI 10.1080/02699200110109802
   Boersma P., 2008, PRAAT
   Breitenstein C, 2001, COGNITION EMOTION, V15, P57, DOI 10.1080/0269993004200114
   Ciocca V, 2002, J ACOUST SOC AM, V111, P2250, DOI 10.1121/1.1471897
   Cooper WB, 2008, EAR HEARING, V29, P618, DOI 10.1097/AUD.0b013e318174e787
   Flipsen P, 2006, J COMMUN DISORD, V39, P93, DOI 10.1016/j.jcomdis.2005.11.001
   Geurts L, 2001, J ACOUST SOC AM, V109, P713, DOI 10.1121/1.1340650
   Green T, 2004, J ACOUST SOC AM, V116, P2298, DOI 10.1121/1.1785611
   Hasada R., 2001, EMOTIONS CROSSLINGUI, P217
   Hopyan-Misakyan TM, 2009, CHILD NEUROPSYCHOL, V15, P136, DOI 10.1080/09297040802403682
   Kang R, 2009, EAR HEARING, V30, P411, DOI 10.1097/AUD.0b013e3181a61bc0
   Klieve S, 2001, Deaf Educ Int, V3, P15
   Ladd D. R., 1996, INTONATIONAL PHONOLO, P6
   Lenden JM, 2007, J COMMUN DISORD, V40, P66, DOI 10.1016/j.jcomdis.2006.04.004
   Meister H, 2009, INT J AUDIOL, V48, P38, DOI 10.1080/14992020802293539
   Most T, 2007, J DEAF STUD DEAF EDU, V12, P350, DOI 10.1093/deafed/enm012
   Most T, 2009, J DEAF STUD DEAF EDU, V14, P449, DOI 10.1093/deafed/enp007
   MURRAY IR, 1993, J ACOUST SOC AM, V93, P1097, DOI 10.1121/1.405558
   Peng SC, 2004, J SPEECH LANG HEAR R, V47, P1227, DOI 10.1044/1092-4388(2004/092)
   Peng SC, 2004, EAR HEARING, V25, P251, DOI 10.1097/01.AUD.0000130797.73809.40
   Peng SC, 2008, EAR HEARING, V29, P336, DOI 10.1097/AUD.0b013e318168d94d
   Peng SC, 2007, J SPEECH LANG HEAR R, V50, P1210, DOI 10.1044/1092-4388(2007/085)
   Pereira C, 2000, Cochlear Implants, P343
   Saarni C., 1999, DEV EMOTIONAL COMPET, P131
   SCHORR EA, 2005, THESIS U MARYLAND CO
   Schorr EA, 2009, J SPEECH LANG HEAR R, V52, P141, DOI 10.1044/1092-4388(2008/07-0213)
   Svirsky M. A., 2007, Audiological Medicine, V5, P293, DOI [DOI 10.1080/16513860701727847, 10.1080/16513860701727847]
   Vongpaisal T, 2006, J SPEECH LANG HEAR R, V49, P1091, DOI 10.1044/1092-4388(2006/078)
   Vongpaisal T, 2010, EAR HEARING, V31, P555, DOI 10.1097/AUD.0b013e3181daae5a
   Wei WI, 2000, ACTA OTO-LARYNGOL, V120, P218
   Xin Luo, 2007, Trends Amplif, V11, P301
   Xu L, 2004, ACTA OTO-LARYNGOL, V124, P363, DOI 10.1080/00016480410016351
NR 34
TC 60
Z9 65
U1 1
U2 31
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD FEB
PY 2012
VL 131
IS 2
BP 1307
EP 1314
DI 10.1121/1.3672697
PN 1
PG 8
WC Acoustics; Audiology & Speech-Language Pathology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Acoustics; Audiology & Speech-Language Pathology
GA 895ID
UT WOS:000300488800049
PM 22352504
DA 2024-01-09
ER

PT J
AU Lehne, M
   Rohrmeier, M
   Gollmann, D
   Koelsch, S
AF Lehne, Moritz
   Rohrmeier, Martin
   Gollmann, Donald
   Koelsch, Stefan
TI THE INFLUENCE OF DIFFERENT STRUCTURAL FEATURES ON FELT MUSICAL TENSION
   IN Two PIANO PIECES BY MOZART AND MENDELSSOHN
SO MUSIC PERCEPTION
LA English
DT Article
DE musical tension; music-evoked emotion; continuous rating; structural
   features; loudness
ID PERCEPTION; EMOTION; MODEL
AB IN TONAL MUSIC, PATTERNS OF TENSION AND resolution form one of the core principles evoking emotions. The experience of musical tension and resolution depends on various features of the music (e.g., dynamics, agogics, melody, and harmony); however, the relative contribution of different features to the experience of tension is less clear. To investigate the influence of different features on subjectively experienced musical tension, we compared continuous ratings of felt musical tension for original and modified versions of two piano pieces by Mendelssohn and Mozart. Modifications included versions without dynamics and without agogics as well as versions in which the music was reduced to its melodic, harmonic, or outer voice components. Additionally, we compared tension ratings with a loudness model. Tension ratings for versions without dynamics, versions without agogics and without dynamics, and outer voice reductions correlated highly with ratings for the original versions for both pieces. Tension rating correlations between melodic or harmonic reductions and original versions, as well as loudness and original ratings, differed between pieces and appeared to depend on the relative importance of the feature in the respective piece. In addition, qualitative analyses suggested that felt tension and resolution depend on phrase structure, local harmonic implications, and global syntactic structures of the pieces. Altogether, results indicate that discarding expressive features such as dynamics and agogics largely preserves tension-resolution patterns of the music, whereas the contributions of harmonic and melodic structure depend on the way in which they are employed in the composition.
C1 [Lehne, Moritz; Rohrmeier, Martin; Gollmann, Donald; Koelsch, Stefan] Free Univ Berlin, D-14195 Berlin, Germany.
C3 Free University of Berlin
RP Lehne, M (corresponding author), Free Univ Berlin, Cluster Excellence Languages Emot, Habelschwerdter Allee 45, D-14195 Berlin, Germany.
EM moritz.lehne@fu-berlin.de
RI Lehne, Moritz/AAE-8752-2020; Koelsch, Stefan/AAV-1556-2020
OI Rohrmeier, Martin Alois/0000-0002-4323-7257
CR [Anonymous], FREIE SATZ NEUE MUSI
   [Anonymous], 1999, PSYCHOACOUSTICS FACT, DOI DOI 10.1007/978-3-662-09562-1
   [Anonymous], 2007, P 4 SOUND MUS COMP C
   [Anonymous], MUSICAE SCI
   Bigand E, 1999, PSYCHOL RES-PSYCH FO, V62, P237, DOI 10.1007/s004260050053
   Bigand E, 1996, PERCEPT PSYCHOPHYS, V58, P125, DOI 10.3758/BF03205482
   Farbood MM, 2012, MUSIC PERCEPT, V29, P387, DOI 10.1525/MP.2012.29.4.387
   Fredrickson WE, 1997, J RES MUSIC EDUC, V45, P626, DOI 10.2307/3345427
   Fredrickson WE, 1999, J RES MUSIC EDUC, V47, P44, DOI 10.2307/3345827
   Fredrickson WE, 2000, J MUSIC THER, V37, P40, DOI 10.1093/jmt/37.1.40
   Gabrielsson A, 2001, MUSIC SCI, V5, P123, DOI 10.1177/10298649020050S105
   Huron D., 2008, Sweet Anticipation: Music and the Psychology of Expectation
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Koelsch S., 2012, Brain and Music
   Koelsch S, 2010, TRENDS COGN SCI, V14, P131, DOI 10.1016/j.tics.2010.01.002
   Koelsch S, 2008, NEUROREPORT, V19, P1815, DOI 10.1097/WNR.0b013e32831a8722
   Krumhansl CL, 1997, CAN J EXP PSYCHOL, V51, P336, DOI 10.1037/1196-1961.51.4.336
   Krumhansl CL, 1996, MUSIC PERCEPT, V13, P401
   Lalitte P, 2009, MUSIC PERCEPT, V26, P223, DOI 10.1525/MP.2009.26.3.223
   Lerdahl F, 1996, MUSIC PERCEPT, V13, P319
   Lerdahl F., 2001, Tonal Pitch Space
   Lerdahl F, 2007, MUSIC PERCEPT, V24, P329, DOI 10.1525/MP.2007.24.4.329
   Lerdahl Fred, 1983, A generative theory of tonal music
   Margulis EH, 2005, MUSIC PERCEPT, V22, P663, DOI 10.1525/mp.2005.22.4.663
   Meyer LB., 1956, Emotion and meaning in music
   Narmour E., 1992, ANAL COGNITION BASIC
   Nielsen F.V., 1983, OPLEVELSE MUSIKALSK
   Pressnitzer D, 2000, PERCEPT PSYCHOPHYS, V62, P66, DOI 10.3758/BF03212061
   ROHRMEIER M., 2009, P 9 INT C COGN MOD I, P372
   Rohrmeier M, 2011, J MATH MUSIC, V5, P35, DOI 10.1080/17459737.2011.573676
   Rohrmeier MA, 2012, INT J PSYCHOPHYSIOL, V83, P164, DOI 10.1016/j.ijpsycho.2011.12.010
   Salimpoor VN, 2011, NAT NEUROSCI, V14, P257, DOI 10.1038/nn.2726
   Schubert E, 2004, MUSIC PERCEPT, V21, P561, DOI 10.1525/mp.2004.21.4.561
   Schubert E., 2010, Handbook of music and emotion: Theory, research, applications, P223, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0009
   Vines BW, 2006, COGNITION, V101, P80, DOI 10.1016/j.cognition.2005.09.003
   Williams LR, 2011, INT J MUSIC EDUC, V29, P72, DOI 10.1177/0255761410372725
NR 36
TC 21
Z9 23
U1 0
U2 16
PU UNIV CALIFORNIA PRESS
PI OAKLAND
PA 155 GRAND AVE, SUITE 400, OAKLAND, CA 94612-3758 USA
SN 0730-7829
J9 MUSIC PERCEPT
JI Music Percept.
PD DEC
PY 2013
VL 31
IS 2
BP 171
EP 185
DI 10.1525/MP.2013.31.2.171
PG 15
WC Music; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music; Psychology
GA 265AV
UT WOS:000327923000005
OA Green Submitted
DA 2024-01-09
ER

PT J
AU ter Laan, N
AF ter Laan, Nina
TI Musical negotiations of a 'moderate' versus a 'radical' Islam in
   Morocco: dissonance and the sonic among vocal performers of
   Islam-inspired music
SO RELIGION
LA English
DT Article
DE Morocco; Islam; music; religious politics; dissonance
AB This article explores how in Morocco, music is used to construct and subvert discourses on a 'moderate' vs. a 'radical' Islam. I focus on experiences and practices of vocal performers of Islam-inspired music, who operate in two different musical domains: state-sponsored stages for Sufi music, and non-state-sponsored stages for anashid - acapella Islamic songs, generally associated with more orthodox interpretations of Islam. Based on extensive ethnographic fieldwork among these artists, I analyze how the Moroccan response to the War on Terror, and concomitant perceptions of 'radical' versus 'moderate' Islam, affect the ways in which they present themselves and their music. I propose the notion of 'dissonance' to demonstrate how the artists' musical practices, as well as their narratives of performance, ethics, and emotions converge with, yet simultaneously also rub against state discourses on a 'moderate' vs. a 'radical' Islam.
C1 [ter Laan, Nina] Univ Utrecht, Dept Philosophy & Religious Studies, Utrecht, Netherlands.
   [ter Laan, Nina] Univ Cologne, Dept Social & Cultural Anthropol, Cologne, Germany.
C3 Utrecht University; University of Cologne
RP ter Laan, N (corresponding author), Univ Utrecht, Dept Philosophy & Religious Studies, Utrecht, Netherlands.; ter Laan, N (corresponding author), Univ Cologne, Dept Social & Cultural Anthropol, Cologne, Germany.
EM nterlaan@uni-koeln.de
OI ter Laan, Nina/0000-0002-1223-2218
FU Netherlands Organization of Scientific Research (NWO); Department of
   Religious Studies at Radboud University; research program Religious
   Matters in an Entangled World
FX This research project was funded by the Netherlands Organization of
   Scientific Research (NWO) for the research program 'Islam and the
   Performing Arts in Europe and the Middle East', led by Professor Karin
   van Nieuwkerk and co-financed by the Department of Religious Studies at
   Radboud University. The research for this article was supported by the
   research program Religious Matters in an Entangled World, led by
   Professor Birgit Meyer at Utrecht University.
CR Al-Jabouri, 2010, ISLAMIC THOUGHT MOHA
   [Anonymous], 1998, DESTINATION CULTURE
   [Anonymous], 2018, COUNTERING ONLINE PR
   [Anonymous], 2014, ETHNOGRAPHIC STATE F
   [Anonymous], 1994, High Lonesome: The American Culture of Country Music
   [Anonymous], 2009, SUFISM TODAY HERITAG
   [Anonymous], 2009, SUFIS W SOC GLOBAL N
   Arieff, 2012, REPORT NO RS21579
   Baylocq C., 2016, AFRIQUE CONT, V257, P113, DOI [https://doi.org/10.3917/afco.257.0113, DOI 10.3917/AFCO.257.0113]
   Belghazi T, 2006, MIDDLE EAST CRIT, V15, P97, DOI 10.1080/10669920500515168
   Bogaert K., 2011, THESIS GHENT U, V24, P129
   Daadaoui Mohamed, 2011, MOROCCAN MONARCHY IS, P41
   Dominguez Diaz Marta, 2010, THESIS U LONDON
   Eickelman Dale, 1976, MOROCCAN ISLAM TRADI
   Geertz C., 1968, Islam Observed; Religious Development in Morocco and Indonesia
   Hammoudi Abdellah, 1997, MASTER DISCIPLE CULT
   Hirschkind Charles, 2006, The Ethical Soundscape: Cassette Sermons and Islamic Counterpublics
   Howe Marvine, 2005, MOROCCO ISLAMIST AWA
   Kapchan DA, 2008, AM ANTHROPOL, V110, P467, DOI 10.1111/j.1548-1433.2008.00079.x
   Laack I, 2015, METH THEORY STUD REL, V27, P220, DOI 10.1163/15700682-12341339
   Lahdelma, 2019, IS PERCEPTION CONSON
   Layachi Azzedine, 1998, STATE SOC DEMOCRACY
   Maghraoui D, 2009, MEDITERR POLIT, V14, P195, DOI 10.1080/13629390902985976
   Mahmood S, 2005, POLITICS OF PIETY: THE ISLAMIC REVIVAL AND THE FEMINIST SUBJECT, P1
   Mahmood S, 2006, PUBLIC CULTURE, V18, P323, DOI 10.1215/08992363-2006-006
   Meyer B, 2009, RELIG CULT CRIT, P1, DOI 10.1057/9780230623248
   MEYER B., 2006, INAUGURAL LECT
   Meyer Birgit, 2020, Entangled Religions, V11, DOI DOI 10.13154/ER.11.2020.8444
   Mouna K., 2018, MEDRESET WORKING PAP, V13
   Muedini F, 2012, ISLAM AFR-US, V3, P201, DOI 10.5192/215409930302201
   Munson Jr H, 1993, RELIG POWER MOROCCO
   Murphy Philip., 2018, 12 S ICTM STUD GROUP
   Parncutt R., 2011, J INTERDISCIPLINARY, V5, P119, DOI 10.4407/jims.2011.11.002
   Rice Timothy, 2001, British Journal of Ethnomusicology, V10, P19
   Said B, 2012, STUD CONFL TERROR, V35, P863, DOI 10.1080/1057610X.2012.720242
   Sakthivel V., 2017, WASH POST
   Sakthivel Vish., 2016, FOREIGN POLICY RES I
   Salois Kendra, 2013, THESIS U CALIFORNIA
   Schielke Samuli., 2007, WELT ISLAMS, V47, P319, DOI [10.1163/157006007783237446, DOI 10.1163/157006007783237446]
   Scott James, 1990, Domination and the Arts of Resistance: Hidden Transcripts
   Scott James, 1985, Weapons of the Weak
   Silverstein PA, 2012, MATER RELIG, V8, P330, DOI 10.2752/175183412X13415044208871
   Stokes M., 1992, ARABESK DEBATE MUSIC
   ter Laan, 2016, THESIS RADBOUND U
   Touma HH, 1996, MUSIC ARABS
   Tozy Mohamed, 1999, MONARCHIE ISLAM POLI
   van Nieuwkerk Karin., 2011, MUSLIM RAP HALAL SOA
   Vermeeren, 2009, MAROC MOHAMMED 6 TRA
   Wainscott A.M., 2017, Bureaucratizing Islam: Morocco and the War on Terror
   WAUGH Earle H., 2005, Memory, Music, and Religion: Morocco's Mystical Changers
   Weintraub Andrew, 2011, ISLAM POPULAR CULTUR, P235, DOI DOI 10.4324/9780203829004
   Zeghal Malika, 2008, Islamism in Morocco: Religion, authoritarianism, and electoral politics
   Zemni Sami, 2006, Mediterranean Politics, V11, P231
NR 53
TC 0
Z9 0
U1 1
U2 1
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 0048-721X
EI 1096-1151
J9 RELIGION
JI Religion
PD APR 3
PY 2021
VL 51
IS 2
SI SI
BP 214
EP 236
DI 10.1080/0048721X.2021.1865602
EA JAN 2021
PG 23
WC Religion
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Religion
GA RI3SG
UT WOS:000611615300001
OA hybrid, Green Published
DA 2024-01-09
ER

PT J
AU Frid, E
   Elblaus, L
   Bresin, R
AF Frid, Emma
   Elblaus, Ludvig
   Bresin, Roberto
TI Interactive sonification of a fluid dance movement: an exploratory study
SO JOURNAL ON MULTIMODAL USER INTERFACES
LA English
DT Article
DE Interactive sonification; Fluid movement; Vocal sketching
ID EMOTIONS
AB In this paper we present three different experiments designed to explore sound properties associated with fluid movement: (1) an experiment in which participants adjusted parameters of a sonification model developed for a fluid dance movement, (2) a vocal sketching experiment in which participants sketched sounds portraying fluid versus nonfluid movements, and (3) a workshop in which participants discussed and selected fluid versus nonfluid sounds. Consistent findings from the three experiments indicated that sounds expressing fluidity generally occupy a lower register and has less high frequency content, as well as a lower bandwidth, than sounds expressing nonfluidity. The ideal sound to express fluidity is continuous, calm, slow, pitched, reminiscent of wind, water or an acoustic musical instrument. The ideal sound to express nonfluidity is harsh, non-continuous, abrupt, dissonant, conceptually associated with metal or wood, unhuman and robotic. Findings presented in this paper can be used as design guidelines for future applications in which the movement property fluidity is to be conveyed through sonification.
C1 [Frid, Emma; Elblaus, Ludvig; Bresin, Roberto] KTH Royal Inst Technol, Lindstedsvagen 3, Stockholm, Sweden.
C3 Royal Institute of Technology
RP Frid, E (corresponding author), KTH Royal Inst Technol, Lindstedsvagen 3, Stockholm, Sweden.
EM emmafrid@kth.se
RI Bresin, Roberto/I-3458-2019
OI Bresin, Roberto/0000-0002-3086-0322
FU European Union's Horizon 2020 research and innovation programme [645553]
FX This work was supported by the European Union's Horizon 2020 research
   and innovation programme under Grant Agreement No. 645553 (DANCE).
CR Bencina Ross, 2008, P 8 INT C NIME, P197
   Boyer Eric O., 2013, INT S COMP MUS MULT, P218
   Bresin R, 2011, CORTEX, V47, P1068, DOI 10.1016/j.cortex.2011.05.009
   Camurri A, 2016, MOCO'16: PROCEEDINGS OF THE 3RD INTERNATIONAL SYMPOSIUM ON MOVEMENT AND COMPUTING, DOI 10.1145/2948910.2948927
   Castellano G, 2007, LECT NOTES COMPUT SC, V4738, P71
   Dahl S, 2007, MUSIC PERCEPT, V24, P433, DOI 10.1525/MP.2007.24.5.433
   Danna J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0128388
   Drioli C, 2012, J MULTIMODAL USER IN, V5, P187, DOI 10.1007/s12193-011-0063-7
   Dubus G, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0082491
   Ekman Inger, 2010, Proceedings of the ACM Conference on Designing Interactive Systems, P123, DOI DOI 10.1145/1858171.1858195
   Frid E, 2016, P 5 INT SON WORKSH I, P11
   Frid E, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00521
   Gabrielsson A., 2010, HDB MUSIC EMOTION TH, P367, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0014
   Giordano BL, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0115587
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kirk J, 2016, INT COMP MUS C 2016, P149
   Lemaitre G, 2011, ECOL PSYCHOL, V23, P267, DOI 10.1080/10407413.2011.617225
   Piana Stefano, 2016, P 2016 CHI C HUM FAC, P1629, DOI [10.1145/2851581.2892478, DOI 10.1145/2851581.2892478]
   Rocchesso D, 2004, SONIC INTERACTION DE, P135
   Stemler S., 2001, RES EVAL, V7, P137
NR 20
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1783-7677
EI 1783-8738
J9 J MULTIMODAL USER IN
JI J. Multimodal User Interfaces
PD SEP
PY 2019
VL 13
IS 3
SI SI
BP 181
EP 189
DI 10.1007/s12193-018-0278-y
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IQ1ZV
UT WOS:000480549700004
OA hybrid
DA 2024-01-09
ER

PT J
AU Murthy, YVS
   Koolagudi, SG
AF Murthy, Y. V. Srinivasa
   Koolagudi, Shashidhar G.
TI Content-Based Music Information Retrieval (CB-MIR) and Its Applications
   toward the Music Industry: A Review
SO ACM COMPUTING SURVEYS
LA English
DT Review
DE Artist identification; indian classical music; instrument
   identification; music annotation; music genre; music mood estimation;
   music recommendation system; music related features; open problems in
   music information retrieval; query-by-humming/singing; segmentation of
   vocal and non-vocal regions; survey of music information retrieval
ID GENRE CLASSIFICATION; AUDIO SIGNALS; QUERY; RECOGNITION; FEATURES;
   IMAGE; SUBSEQUENCE; ANNOTATION; RECORDINGS; FRAMEWORK
AB A huge increase in the number of digital music tracks has created the necessity to develop an automated tool to extract the useful information from these tracks. As this information has to be extracted from the contents of the music, it is known as content-based music information retrieval (CB-MIR). In the past two decades, several research outcomes have been observed in the area of CB-MIR. There is a need to consolidate and critically analyze these research findings to evolve future research directions. In this survey article, various tasks of CB-MIR and their applications are critically reviewed. In particular, the article focuses on eight MIR-related tasks such as vocal/non-vocal segmentation, artist identification, genre classification, raga identification, query-by-humming, emotion recognition, instrument recognition, and music clip annotation. The fundamental concepts of Indian classical music are detailed to attract future research on this topic. The article elaborates on the signal-processing techniques to extract useful features for performing specific tasks mentioned above and discusses their strengths as well as weaknesses. This article also points to some general research issues in CB-MIR and probable approaches toward their solutions so as to improve the efficiency of the existing CB-MIR systems.
C1 [Murthy, Y. V. Srinivasa] NITK, Dept CSE, Mangalore 575025, India.
   [Koolagudi, Shashidhar G.] NITK, Mangalore, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka; National Institute of Technology (NIT System);
   National Institute of Technology Karnataka
RP Murthy, YVS (corresponding author), NITK, Dept CSE, Mangalore 575025, India.
EM urvishnu@gmail.com; koolagudi@nitk.edu.in
RI Yarlagadda, Vishnu/AAA-6794-2019; Murthy, Y V Srinivasa/B-4085-2019
OI Murthy, Y V Srinivasa/0000-0001-6146-5272
CR Adams N.H., 2004, P 5 ISMIR, P303
   Agostini G, 2003, EURASIP J APPL SIG P, V2003, P5, DOI 10.1155/S1110865703210118
   AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Allamanche E., 2001, PROC 2 INT S MUSIC I
   [Anonymous], 2014, INFORM RETRIEVAL, DOI DOI 10.1561/1500000042
   [Anonymous], 2006, P IEEE INT C AC SPEE
   [Anonymous], 2009, P 10 INT SOC MUSIC I
   [Anonymous], ACM COMPUTING SURVEY, V51
   [Anonymous], 2010, P 11 INT SOC MUSIC I
   [Anonymous], 2004, J NEGAT RESULTS SPEE
   [Anonymous], 2013, ARXIV13061461
   [Anonymous], 2002, P 3 INT SOC MUS INF
   [Anonymous], 2007, International Symposium on Music Information Retrieval (ISMIR)
   [Anonymous], 2005, ISMIR 2005 6 INT C M
   [Anonymous], 2005, P INT SOC MUS INF RE
   [Anonymous], 2002, P 10 ACM INT C MULTI, DOI DOI 10.1145/641007.641121
   [Anonymous], 2007, EURASIP J. Appl. Signal Process.
   [Anonymous], 2012, P 13 INT SOC MUS INF
   [Anonymous], ISMIR
   [Anonymous], 2009, P 10 INT C MUSIC INF
   [Anonymous], P INT C MUS COMM SCI
   [Anonymous], P 2 COMPMUSIC WORKSH
   [Anonymous], P 3 INT C MUS INF RE
   [Anonymous], 2005, ISMIR 2005
   [Anonymous], 2005, PROC 6 INT C MUSIC I
   [Anonymous], [No title captured]
   [Anonymous], 2005, P INT C MUS INF RETR
   [Anonymous], 2011, P 12 INT SOC MUSIC I
   Aucouturier JJ, 2003, J NEW MUSIC RES, V32, P83, DOI 10.1076/jnmr.32.1.83.16801
   Bagci U, 2007, IEEE SIGNAL PROC LET, V14, P521, DOI 10.1109/LSP.2006.891320
   Bang SW, 2013, INT J CONTROL AUTOM, V11, P1290, DOI 10.1007/s12555-012-9407-7
   BARRINGTON L, 2008, ISMIR, P614
   Becchetti C., 2008, SPEECH RECOGNITION T
   Belle S., 2009, J ITC SANGEET RES AC, V23, P1
   Bello J.P., 2007, P ISMIR INT SOC MUS, P239
   Benzi K, 2016, ARXIV161201840
   Berenzweig A. L, 2002, P 22 INT C VIRT SYNT
   BERGER KW, 1964, J ACOUST SOC AM, V36, P1888, DOI 10.1121/1.1919287
   Bergstra J, 2006, MACH LEARN, V65, P473, DOI 10.1007/s10994-006-9019-7
   Bertin-Mahieux T., 2011, P 12 INT C MUS INF R
   Bhatkhande Vishnu Narayan, 1990, HINDUSTANI SANGEET P, V1
   Bhatkhande VN, 1934, SHORT HIST SURVEY MU
   Bjorkner Eva, 2006, THESIS
   Bonjyotsna A, 2013, INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, IMAGE PROCESSING AND PATTERN RECOGNITION (ICSIPR 2013), P87, DOI 10.1109/ICSIPR.2013.6497965
   Brown JC, 1999, J ACOUST SOC AM, V105, P1933, DOI 10.1121/1.426728
   Bruce LM, 2002, IEEE T GEOSCI REMOTE, V40, P2331, DOI 10.1109/TGRS.2002.804721
   Cano P., 2006, TECHNICAL REPORT
   Casey MA, 2008, P IEEE, V96, P668, DOI 10.1109/JPROC.2008.916370
   Cazaly D., 2000, RIAO, P1238
   Chen L., 2004, P 30 INT C VERY LARG, V30, P792
   Chen L, 2005, P 2005 ACM SIGMOD IN
   Chen ZS, 2009, IEEE T AUDIO SPEECH, V17, P1547, DOI 10.1109/TASL.2009.2022435
   Cheng HT, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1505, DOI 10.1109/ICME.2008.4607732
   Chin-Chin Liu, 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P438
   Chordia P., 2007, INT SOC MUSIC INFORM, P431
   Chordia Parag, 2006, P INT COMP MUS C ICM, P431
   Chou W, 2001, INT CONF ACOUST SPEE, P865, DOI 10.1109/ICASSP.2001.941052
   Chua Bee Yong, 2008, DISSERTATION
   Clark M., 1964, J AUDIO ENG SOC, V12, P199
   Coviello E, 2011, IEEE T AUDIO SPEECH, V19, P1343, DOI 10.1109/TASL.2010.2090148
   Crawford T., 1998, COMPUTING MUSICOLOGY, V11, P73
   Crochemore M., 2002, Nordic Journal of Computing, V9, P54
   Cummings David, 1997, RANDOM HOUSE ENCY DI
   Dannenberg Roger B., 2004, P 5 ANN INT S MUS IN, P43
   Daubechies I., 1992, 10 LECT WAVELETS, V61
   Deller J.R., 2000, Discrete-Time Processing of Speech Signals, DOI DOI 10.1109/9780470544402.CH11
   Diment A., 2013, 21 EUR SIGN PROC C E, P1
   Dittmar C., 2015, P INT SOC MUS INF RE, P618
   Dubnov Shlomo, 1998, P ICMC, P102
   Ellis D., 2007, P IEEE INT C AC SPEE, V4
   Ellis D. P., 2007, P INT SOC MUS INF RE, V7, P339
   Erickson Robert, 1975, SOUND STRUCTURE MUSI
   Eronen A, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 2, PROCEEDINGS, P133, DOI 10.1109/ISSPA.2003.1224833
   Eronen A, 2001, THESIS
   Essid S, 2006, IEEE T AUDIO SPEECH, V14, P68, DOI 10.1109/TSA.2005.860351
   Essid Slim, 2004, EFFICIENT MUSICAL IN
   Faloutsos C., 1994, SIGMOD Record, V23, P419, DOI 10.1145/191843.191925
   Fazekas G, 2010, J NEW MUSIC RES, V39, P295, DOI 10.1080/09298215.2010.536555
   Feng YZ, 2003, IEEE/WIC INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, PROCEEDINGS, P235
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Fu ZY, 2010, LECT NOTES COMPUT SC, V6218, P453
   Fu ZY, 2011, IEEE T MULTIMEDIA, V13, P303, DOI 10.1109/TMM.2010.2098858
   Fuhrmann F, 2009, PROC ISMIR, P321
   Fujihara H., 2005, P 6 INT C MUS INF RE, P329
   Fujinaga I., 2000, P INT COMP MUS C, P141
   Gemmeke Jort F., 2017, P 42 IEEE INT C AC S
   Ghias Asif, 1995, P 3 ACM INT C MULT, P231, DOI DOI 10.1145/217279.215273
   Giannoulis D, 2013, IEEE T AUDIO SPEECH, V21, P1805, DOI 10.1109/TASL.2013.2248720
   Gomez Emilia, 2004, P 5 INT S MUS INF RE
   Goto M., 2004, Acoustical Science and Technology, V25, P419, DOI 10.1250/ast.25.419
   Goto M., 2003, P 4 INT C MUS INF RE
   GRIMALDI M, 2003, P 5 ACM SIGMM INT WO, P102, DOI [DOI 10.1145/973264.973281, 10.1145/973264.973281]
   Guo ZY, 2013, SIGNAL PROCESS, V93, P2229, DOI 10.1016/j.sigpro.2012.09.006
   Hamel P., 2009, P INT S MUS INF RETR, P399
   Hamel P., 2012, P 13 INT INT SOC MUS, P553
   Han BJ, 2010, MULTIMED TOOLS APPL, V47, P433, DOI 10.1007/s11042-009-0332-6
   Han TS, 2007, LECT NOTES ARTIF INT, V4571, P585
   Härmä A, 2001, IEEE T SPEECH AUDI P, V9, P579, DOI 10.1109/89.928922
   Heittola T., 2009, P INT SOC MUS INF RE, P327
   Helen Marko, 2005, 2005 13th European Signal Processing Conference, P1
   Hevner K, 1936, AM J PSYCHOL, V48, P246, DOI 10.2307/1415746
   Homburg H., 2005, ISMIR, V2005, P528
   Hsu CL, 2010, IEEE T AUDIO SPEECH, V18, P310, DOI 10.1109/TASL.2009.2026503
   HU N, 2002, P INT COMP MUS C
   Hu X., 2008, Proceedings of the International Society for Music Information Retrieval Conference, P462
   Hu X., 2007, ISMIR Proceedings, P67
   Hu Y., 2009, P 10 INT SOC MUS INF, P123
   Huang YF, 2014, DATA KNOWL ENG, V92, P60, DOI 10.1016/j.datak.2014.07.005
   Hyoung-Gook Kim, 2004, 2004 12th European Signal Processing Conference (EUSIPCO), P1047
   Ilyas IF, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1391729.1391730
   Ishwar V, 2012, Carnatic Music: Svara, Gamaka, Motif and Raga Identity
   JAIRAZBHOY NA, 1975, ASIAN MUSIC, V6, P38, DOI 10.2307/833842
   Janakiraman S. R., 2008, ESSENTIALS MUSICOLOG
   Jang, 2001, P INT C MULT EXP, P289
   Jang J.-S. Roger, 2006, P MIREX 2006, P77
   Jang JSR, 2008, IEEE T AUDIO SPEECH, V16, P350, DOI 10.1109/TASL.2007.913035
   Jensen JH, 2009, IEEE T AUDIO SPEECH, V17, P693, DOI 10.1109/TASL.2008.2012314
   Jiang DN, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P113, DOI 10.1109/ICME.2002.1035731
   Joshi S, 2015, 6TH INTERNATIONAL CONFERENCE ON COMPUTER & COMMUNICATION TECHNOLOGY (ICCCT-2015), P110, DOI 10.1145/2818567.2818588
   Kaminskyj Ian, 2001, MIKROPOLYPHONIE, V6, P1
   Kao W.-T., 2013, P IEEE AS PAC SIGN I, P1
   Katte T., 2013, Int J Electr Comput Eng, V4, P82
   KENDALL RA, 1986, MUSIC PERCEPT, V4, P185
   Keogh E, 2005, KNOWL INF SYST, V7, P358, DOI 10.1007/s10115-004-0154-9
   Kim Y. E., 2006, P INT C MUS INF RETR, P393, DOI DOI 10.5281/ZENODO.1415722
   Kitahara T, 2010, STUD COMPUT INTELL, V274, P65
   Klapuri AP, 2003, IEEE T SPEECH AUDI P, V11, P804, DOI 10.1109/TSA.2003.815516
   Koduri Gopala Krishna, 2011, P INT C SOUND MUS CO
   Kolozali S, 2013, IEEE T AUDIO SPEECH, V21, P1, DOI 10.1109/TASL.2013.2263801
   Korhonen MD, 2006, IEEE T SYST MAN CY B, V36, P588, DOI 10.1109/TSMCB.2005.862491
   Kotsifakos A, 2011, PROC VLDB ENDOW, V4, P761
   Krishna AG, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL IV, PROCEEDINGS, P265
   Koduri GK, 2012, J NEW MUSIC RES, V41, P337, DOI 10.1080/09298215.2012.735246
   Kristjansson AH, 2004, PROCEEDINGS OF NORDDESIGN 2004, P63
   Krumhansl C. L., 2001, Cognitive Foundations of Musical Pitch, VVol. 17
   Kumar V, 2014, INT C PATT RECOG, P767, DOI 10.1109/ICPR.2014.142
   Kushima K., 2000, 16th World Computer Congress 2000. Proceedings of Conference on Intelligent Information Processing, P179
   Lee CH, 2009, IEEE T MULTIMEDIA, V11, P670, DOI 10.1109/TMM.2009.2017635
   Lehner B, 2015, EUR SIGNAL PR CONF, P21, DOI 10.1109/EUSIPCO.2015.7362337
   Lemstrom K., 2000, AISB, P53
   LEMSTROM K, 2000, P 1 INT S MUS INF RE
   Leveau P., 2007, P INT S MUS INF RETR, P233
   Li GH, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P885, DOI 10.1109/ICME.2000.871501
   Li T, 2005, INT CONF ACOUST SPEE, P197
   Li T, 2003, P 26 ANN INT ACM SIG, P282
   Li T., 2003, Proceedings of the International Symposium on Music Information Retrieval, P239
   Li T, 2006, IEEE T MULTIMEDIA, V8, P564, DOI 10.1109/TMM.2006.870730
   LIDY T, 2007, P 8 INT C MUS INF RE, P61
   Lidy Thomas, 2005, P 6 ANN INT S MUS IN
   Little D., 2008, P 9 INT S MUS INF RE, P127
   Livshin A., 2004, P 7 INT C DIG AUD EF, P1
   Livshin Arie A., 2004, P INT COMP MUS C
   Logan B., 2000, Mel frequency cepstral coefficients for music modeling
   Lu L, 2006, IEEE T AUDIO SPEECH, V14, P5, DOI 10.1109/TSA.2005.860344
   Macy Laura Williams, 2001, GROVE MUSIC ONLINE
   Maddage NC, 2004, INT C PATT RECOG, P375, DOI 10.1109/ICPR.2004.1334225
   Mandal MK, 1998, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES - PROCEEDINGS, P68, DOI 10.1109/IVL.1998.694498
   Manning Christopher D., 2008, INTRO INFORM RETRIEV, V1, DOI DOI 10.1017/CBO9780511809071
   Marchand Ugo, 2016, LAT BREAK DEM SESS 1
   Marques Janet, 1999, TECHNICAL REPORT SER, V4
   Matias Y., 1998, SIGMOD Record, V27, P448, DOI 10.1145/276305.276344
   Mazzoni D., 2001, 2 ANN INT S MUS INF, P17
   MCADAMS S, 1995, PSYCHOL RES-PSYCH FO, V58, P177, DOI 10.1007/BF00419633
   McKay C., 2006, P INT C MUS INF RETR, P160
   McKinney M., 2003, P ISMIR, P151
   Mellody M., 2000, P INT COMP MUS C ICM, P98
   Meng A, 2005, INT CONF ACOUST SPEE, P497
   Meng A, 2007, IEEE T AUDIO SPEECH, V15, P1654, DOI 10.1109/TASL.2007.899293
   Mesaros A, 2005, ISSCS 2005: International Symposium on Signals, Circuits and Systems, Vols 1 and 2, Proceedings, P307
   Mesaros A., 2005, ISMIR, P610
   Mion L, 2008, IEEE T AUDIO SPEECH, V16, P458, DOI 10.1109/TASL.2007.913743
   Miotto R, 2012, IEEE T AUDIO SPEECH, V20, P1096, DOI 10.1109/TASL.2011.2172423
   MONGEAU M, 1990, COMPUT HUMANITIES, V24, P161, DOI 10.1007/BF00117340
   Mörchen F, 2006, IEEE T AUDIO SPEECH, V14, P81, DOI 10.1109/TSA.2005.860352
   Murthy YVS, 2015, CAN CON EL COMP EN, P1271, DOI 10.1109/CCECE.2015.7129461
   Murty G.R.K., 2014, IUP J ENGL STUD, V9, P54
   Ness S. R., 2009, IMPROVING AUTOMATIC, P705
   Orio N., 2011, INT SOC MUS INF RETR, P603
   Orio Nicola, 2006, MUSIC RETRIEVAL TUTO
   Oxford Music, 2010, AM ART J, V28, P1
   Pampalk E., 2005, ISMIR, V5, P634
   Panagakis I., 2008, ISMIR, P583
   Patil HA, 2012, INT CONF ASIAN LANG, P145, DOI 10.1109/IALP.2012.33
   Peeters G., 2004, CUIDADO 1 PROJ REP
   Peeters Geoffroy, 2003, P AUDIO ENG SOC CONV, V115
   PERROT D, 1999, P SOC MUS PERC COGN
   Plomp Reinier, 1989, J ACOUST SOC AM, V86, pS57
   Popper AN, 2014, SPRINGER HANDB AUDIT, V50, P1, DOI 10.1007/978-1-4614-9102-6
   Powers Harold Stone, 1963, BACKGROUND S INDIAN
   QI YG, 1992, J ACOUST SOC AM, V92, P2569, DOI 10.1121/1.404429
   Rabiner L.R., 1993, Fundamentals of Speech Recognition, VVolume 14
   Ramona M, 2008, INT CONF ACOUST SPEE, P1885, DOI 10.1109/ICASSP.2008.4518002
   Ranjani HG, 2011, 2011 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS (WASPAA), P29, DOI 10.1109/ASPAA.2011.6082295
   Reed J, 2009, INT CONF ACOUST SPEE, P1873, DOI 10.1109/ICASSP.2009.4959973
   Regnier L, 2009, INT CONF ACOUST SPEE, P1685, DOI 10.1109/ICASSP.2009.4959926
   Reynolds DA, 1994, IEEE T SPEECH AUDI P, V2, P639, DOI 10.1109/89.326623
   Roger Jang J.-S., 2000, P INT WORKSH INT SYS, P85
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Salamon Justin, 2012, P 13 INT S MUS INF R
   Sambamoorthy Pichu, 1958, S INDIAN MUSIC, V3
   Scaringella N, 2006, IEEE SIGNAL PROC MAG, V23, P133, DOI 10.1109/MSP.2006.1598089
   Schedl Markus, 2005, INTERACTIVE POSTER U
   Schorkhuber C., 2010, P 7 SOUND MUS COMP C, P3
   Seyerlehner Klaus, 2010, P 13 INT C DIG AUD E, P225
   Sharma H., 2014, P 6 ASE INT C SOC CO, P1, DOI [DOI 10.1109/NCC.2014.6811357, 10.1109/NCC.2014.6811357]
   Sharma R, 2016, ADV INTELL SYST, V381, P157, DOI 10.1007/978-81-322-2526-3_17
   Shen JL, 2006, IEEE T MULTIMEDIA, V8, P1179, DOI 10.1109/TMM.2006.884618
   Shen JL, 2009, ACM T INFORM SYST, V27, DOI 10.1145/1508850.1508856
   Shenoy A., 2005, P VIS COMM IM PROC
   Shetty Surendra, 2009, International Journal of Recent Trends in Engineering, V1, P362
   Silla Jr C. N., 2008, Proceedings of the International Society for Music Information Retrieval Conference, P451
   Simpson AJR, 2015, LECT NOTES COMPUT SC, V9237, P429, DOI 10.1007/978-3-319-22482-4_50
   Slaney M, 2002, INT CONF ACOUST SPEE, P4108
   Smith JR, 1999, COMPUT VIS IMAGE UND, V75, P165, DOI 10.1006/cviu.1999.0771
   Song Y., 2012, P 9 INT S COMP MUS M
   Song YQ, 2008, IEEE T MULTIMEDIA, V10, P145, DOI 10.1109/TMM.2007.911305
   Sridhar Rajeswari, 2009, International Journal of Recent Trends in Engineering, V1, P571
   Sriram P., 1990, CARNATIC MUSIC PRIME
   STRUBE HW, 1980, J ACOUST SOC AM, V68, P1071, DOI 10.1121/1.384992
   Suma SM, 2015, ADV INTELL SYST COMP, V339, P865, DOI 10.1007/978-81-322-2250-7_86
   Sundberg J., 1990, J ACOUST SOC AM, V87, P462, DOI [DOI 10.1121/1.399243, 10.1121/1.399243]
   SWIFT GN, 1990, ASIAN MUSIC, V21, P71, DOI 10.2307/834112
   Tellegen A, 1999, PSYCHOL SCI, V10, P297, DOI 10.1111/1467-9280.00157
   Thayer RE., 1990, The Biopsychology of Mood and Activation
   Tingle D., 2010, P INT C MULT INF RET, P55, DOI DOI 10.1145/1743384.1743400
   Tolonen T, 2000, IEEE T SPEECH AUDI P, V8, P708, DOI 10.1109/89.876309
   Trohidis Konstantinos, 2008, ISMIR, P325
   Tsai W.-H., 2008, P 9 INT S MUS INF RE, P115
   Tsai WH, 2006, IEEE T AUDIO SPEECH, V14, P330, DOI 10.1109/TSA.2005.854091
   Tsai WH, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL IV, PROCEEDINGS, P221
   Tsunoo E, 2009, IEEE INT CON MULTI, P382, DOI 10.1109/ICME.2009.5202514
   Turnbull Douglas, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P439, DOI 10.1145/1277741.1277817
   Turnbull D, 2008, IEEE T AUDIO SPEECH, V16, P467, DOI 10.1109/TASL.2007.913750
   Typke R., 2003, ISMIR, P107
   Tzanetakis G., 2007, INT SOC MUS INF RETR INT SOC MUS INF RETR, P441
   Tzanetakis G, 2010, J AUDIO ENG SOC, V58, P409
   Tzanetakis George, 2002, IEEE T SPEECH AUDIO, V10, P5
   Umapathy K, 2005, IEEE T MULTIMEDIA, V7, P308, DOI 10.1109/TMM.2005.843363
   Unal E, 2008, IEEE T AUDIO SPEECH, V16, P359, DOI 10.1109/TASL.2007.912373
   Veltkamp Remco C., 2001, P DAGST SEM STAT ART, P196
   Viswanathan T., 2004, Music in South India: The Karnatak Concert Tradition and Beyond
   Vyas HM, 2015, INT CONF CONTEMP, P106, DOI 10.1109/IC3.2015.7346662
   Wang Q, 2012, INT C PATT RECOG, P3034
   Wang Shuo-Yang, 2014, Proceedings of IEEE International Conference on Multimedia and Expo ICME
   Wei Cai, 2011, 2011 Seventh International Conference on Natural Computation (ICNC 2011), P1624, DOI 10.1109/ICNC.2011.6022500
   Weihs C, 2007, ADV DATA ANAL CLASSI, V1, P255, DOI 10.1007/s11634-007-0016-x
   West K., 2008, THESIS
   Whitman B, 2001, NEURAL NETWORKS FOR SIGNAL PROCESSING XI, P559, DOI 10.1109/NNSP.2001.943160
   Wolter Kay, 2008, P 6 WORKSH AD MULT R, P40
   Y Li, 2006, ISMIR, P176
   Yan Y, 2006, P 5 INT S CHIN SPOK
   Yang JZ, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2898
   Yang YH, 2008, IEEE T AUDIO SPEECH, V16, P448, DOI 10.1109/TASL.2007.911513
   Yoshitaka A, 1999, IEEE T KNOWL DATA EN, V11, P81, DOI 10.1109/69.755617
   Zentner Alejandro, 2003, TECHNICAL REPORT
   Zhang T, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P33
   Zhang T., 2003, RES DISCLOSURE, P756
   Zhu Y, 2003, P 2003 ACM SIGMOD IN, P181, DOI DOI 10.1145/872757.872780
NR 258
TC 31
Z9 32
U1 3
U2 62
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 0360-0300
EI 1557-7341
J9 ACM COMPUT SURV
JI ACM Comput. Surv.
PD JUL
PY 2018
VL 51
IS 3
AR 45
DI 10.1145/3177849
PG 46
WC Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA GO1OU
UT WOS:000439723400002
DA 2024-01-09
ER

PT J
AU Gorlée, DL
AF Gorlee, Dinda L.
TI Intersemioticity and intertextuality: Picaresque and romance in opera
SO SIGN SYSTEMS STUDIES
LA English
DT Article
DE Jakobson; intersemioticity; intertextuality; Ibsen; Grieg; vocal
   translation; opera; Scandinavian cultures
ID WITTGENSTEIN
AB Jakobson introduced the concept of intersemioticity as transmutation of verbal signs by nonverbal sign systems (1959). Intersemioticity generates the linguistic and-cultural elements of intersemiosis (from without), crystallizing mythology and archetypal symbolism, and intertextuality (from within), analyzing the human emotions in the cultural situation of language-and-music aspects. The operatic example of Ibsen's Peer Gynt (1867) intertextualized the cultural trends of Scandinavia. This literary script was set to music by Grieg to make an operatic expression. After the "picaresque" adventures, Peer Gynt ends in a "romantic" revelation. Grieg's music reworded and rephrased the script in musical verse and rhythm, following the intertextuality of Nordic folk music and Wagner's fashionable operas. Ibsen's Peer Gynt text has since been translated in Jakobson's "translation proper" to other languages. After 150 years, the vocal translation of the operatic text needs the "intersemiotic translation or transmutation" to modernize the translated text and attract present-day audiences.
C1 [Gorlee, Dinda L.] Univ Bergen, Wittgenstein Arch, Sydnesplassen 12, N-5020 Bergen, Norway.
C3 University of Bergen
RP Gorlée, DL (corresponding author), Univ Bergen, Wittgenstein Arch, Sydnesplassen 12, N-5020 Bergen, Norway.
EM gorlee@xs4all.nl
CR Aaraas Hans, 1995, PEER GYNT DROM DROMM
   Aasen Ivar, 1918, NORSK ORDBOG MED DAN
   Abel Sam, 1996, OPERA FLESH SEXUALIT
   Abrams M. H., 1957, GLOSSARY LIT TERMS
   Akerholt May Brit, 1980, LANGUAGES THEATRE PR, P104
   Andersen Hans Christian, 1893, LITTLE MERMAID OTHER
   Anderson Myrdene, 2011, SEMIOTICS 2010, P221
   [Anonymous], WHAT IS POSTMODERNIS
   [Anonymous], 1985, REALISM 19 CENTURY M
   [Anonymous], 1961, BOOKS ABROAD, DOI DOI 10.2307/40115290
   APEL W, 1946, HARVARD DICT MUSIC
   APTER R, 1989, TRANSLATION REV, P27
   Asbjornsen Peter Christen, 1982, NORWEGIAN FOLK TALES
   Barthes R., 1974, S/Z
   Belsheim Johannes, 1889, OVERSIGT KIRKENS SAL
   Blake A, 2010, CONTEMP MUSIC REV, V29, P187, DOI 10.1080/07494467.2010.534929
   Booth W. C., 1974, RHETORIC IRONY
   CHANDLER FW, 1907, LIT ROGUERY
   Clebert Jean-Paul, 1970, GYPSIES
   Danesi Marcel, 2003, DICT MEDIA COMMUNICA
   Darwin C., 1958, The Origin of Species
   Darwin Charle, 1998, BXPRESSION EMOTIONS
   Dasent George Webbe, 1859, POPULAR TALES NORSE
   Dictionary O.E, 1989, Oxford English dictionary
   Donington Robert, 1990, OPERA ITS SYMBOLS UN
   Eco U., 1984, CARNIVAL, P1, DOI DOI 10.1515/9783110848717
   Eco U., 1986, TRAVELS HYPERREALITY, P269
   Forster Beryl, 2011, LITERALLY GRIEG
   Gorlée DL, 2015, SEMIOTICA, V205, P37, DOI 10.1515/sem-2015-0011
   Gorlée DL, 2008, SEMIOTICA, V172, P97, DOI 10.1515/SEMI.2008.091
   Gorlee Dinda L., 2004, MACHT ZEICHEN ZEICHE, P164
   Gorlee Dinda L., 2008, SIGN SYST STUD, V36, P341
   Gorlee Dinda L., 2005, APPROACHES TRANSLATI, V25, P7
   Gorlee Dinda L., 2010, APPL SEMIOTICS, V24, P54
   Gorlee Dinda L., 1987, EPOS REV FILOLOGIA, V3, P181
   Gorlee Dinda L, 2012, SIGN SYST STUD, V40, P340
   Gorlee DL, 2015, TARTU SEMIO LIBR, V15, P1
   Gorlée DL, 2002, SEMIOTICA, V142, P153
   GORLEE DL, 1988, NEOPHILOLOGUS, V72, P56, DOI 10.1007/BF00396067
   GORLEE DL, 1997, TARGET, V9, P235, DOI DOI 10.1075/TARGET.9.2.03G0R
   GORLEE DL, 1994, SEMIOTICS PROBLEM TR
   Grieg Edvard, 2000, COMMUNCATION
   Grieg Edvard, 1987, PEER GYNT S JORSALFA
   Grieg Edvard, 1978, PEER GYNT PREMIER RE
   Grieg Edvard, 1988, PEER GYNT SAMLEDE VE, V18, P1
   Hutchison J. A., 1963, LANGUAGE FAITH STUDI
   Ibsen Henrik, 1978, SAMLEDE VERKER, P313
   Jakobson Roman, 1959, TRANSLATION, P232
   Kaplan M, 2003, SCAND STUD, V75, P491
   Konow Karl, 1898, KUNSTBLADET, V1898, P178
   Kristeva J., 1974, REVOLUTION LANGAGE P
   Kristeva J., 1969, SEMIOTIKE RECHERCHES
   Landstad M. B., 1870, KIRKESALMEBOG ETTER
   Landstad Magnus Bostrup, 1869, KIRKESALMEBOG ETTER
   Landstad Magnus Bostrup, 1862, PSALMEBOGEN REDEGJOR
   Lindeman Ludvig Mathias, 1963, AELDRE NYERE FELDMEL
   Logeman Henri, 1917, COMMENTARY CRITICAL
   Meyer Leonard, 1970, EMOTION MEANING MUSI
   Munro T., 1969, The Arts and Their Interrelations
   Nida E. A., 1969, The theory and practice of translation, VVol. 8
   Pearsall Ronald., 1973, VICTORIAN POPULAR MU
   Poizat M., 1992, The Angel's Cry: Beyond the Pleasure Principle in Opera
   Popovic Anton, 1975, DICT ANAL LIT TRANST
   Scholes Robert, 1969, Novel: A Forum on Fiction, V2, P101
   Schoonhoven W. J., 1988, LING ANTVERP NEW SER, V22, P181
   SEBEOK TA, 1985, POETICS TODAY, V6, P657, DOI 10.2307/1771959
   Silverstein Michael., 2003, Translating Cultures: Perspectives on Translation and Anthropology, P75
   Skaar J. N, 1879, NORSK SALMEHISTORIE
   Stauffer GB, 2016, NEW YORK REV BOOKS, V63, P28
   Taylor John V, 1999, GO BETWEEN GOD HOLY
   Valbuena Prat Angel, 1966, NOVELA PICARESCA ESP
   van Baest Arjan, 2000, SEMIOTICS OPERA
   van den Broeck Raymond, 1986, LING ANTVERP NEW SER, V20, P96
   von Franz Marie-Louise, 1964, MAN HIS SYMBOLS, P158
   WAGNER R, DIE WALKURE
   Wagner R., 1910, MEISTERSINGER NURNBE
   Wagner Richard, RHEINGOLD KLAVIERAUS
   Warner Marina, 2015, NEW YORK REV BOOKS, V62, P65
   Werenskiold Erik, 1898, KUNSTBLADET, V1898, P47
   Wicks Ulrich, 1974, PMLA, V89, P240, DOI DOI 10.2307/461446
NR 80
TC 3
Z9 3
U1 0
U2 6
PU TARTU UNIV PRESS
PI TARTU
PA W STRUVE 1, TARTU, 50091, ESTONIA
SN 1406-4243
EI 1736-7409
J9 SIGN SYST STUD
JI Sign Syst. Stud.
PY 2016
VL 44
IS 4
BP 587
EP 622
DI 10.12697/SSS.2016.44.4.06
PG 36
WC Humanities, Multidisciplinary
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Arts & Humanities - Other Topics
GA EJ3ZH
UT WOS:000393151200006
OA Green Submitted, gold
DA 2024-01-09
ER

PT J
AU Weth, K
   Raab, MH
   Carbon, CC
AF Weth, Karim
   Raab, Marius H.
   Carbon, Claus-Christian
TI Investigating emotional responses to self-selected sad music via
   self-report and automated facial analysis
SO MUSICAE SCIENTIAE
LA English
DT Article
DE affective responses; basic emotion; continuous evaluation procedure
   (CEP); emotions; FaceReader; FACS; facial expressions; mixed emotions;
   nostalgia; sad music; self-report
ID EXPRESSIONS; RECOGNITION; EXPERIENCE; CHILLS; RELIABILITY; NOSTALGIA;
   COGNITION; SOFTWARE; JUDGMENT; VALIDITY
AB People often listen to sad music in spite of its seemingly negative qualities. Sad music, and especially sad music with a personal significance, has been shown to evoke a wide span of emotions with both positive and negative qualities. We compared emotional responses to familiar self-selected sad music (SSSM) with both unfamiliar sad and unfamiliar happy music. Alongside self-reports, a commercial, continuous measure of discrete facial expressions was applied, promising an in-depth assessment of both the quality and strength of experienced affective states at any given point in time. Results of the facial analysis showed that SSSM evoked more mixed affective states than unfamiliar sad music. Also, listeners reacted with consistent facial expressions to distinct musical events, e.g. the introduction of a lead voice. SSSM evoked more self-reported feelings of nostalgia, reminiscence, being moved, and chills and tears than unfamiliar sad and happy music. Furthermore, SSSM resulted in more self-reported happiness and a similar trend with happy facial expressions compared to unfamiliar sad music. These results point to the emotional diversity and the strong involvement of positive affective states elicited by SSSM, even when compared with music of similar quality, such as unfamiliar sad music. Automated facial analysis allows us to observe emotions on a more detailed level in terms of time resolution, onset, intensity and concurrence of discrete affective states. This technique is promising for future research, particularly when investigating mixed emotions and the social aspect of emotions in response to music.
C1 [Weth, Karim] Salzburg Univ, A-5020 Salzburg, Austria.
   [Weth, Karim; Raab, Marius H.; Carbon, Claus-Christian] Univ Bamberg, Bamberg, Germany.
   [Raab, Marius H.; Carbon, Claus-Christian] Forschungsgrp EPAEG, Weinheim, Germany.
C3 Salzburg University; Otto Friedrich University Bamberg
RP Weth, K (corresponding author), Salzburg Univ, Dept Psychol, Hellbrunnerstr 34, A-5020 Salzburg, Austria.
EM karim.weth@gmail.com
RI Carbon, Claus-Christian/A-7494-2008; Campailla, Jasmin/AAK-2420-2021;
   Carbon, Claus-Christian/GLQ-6274-2022
OI Carbon, Claus-Christian/0000-0002-3446-9347; Carbon,
   Claus-Christian/0000-0002-3446-9347; Raab, Marius/0000-0002-1018-745X
CR Ali SO., 2006, Psychology of Music, V34, P511, DOI DOI 10.1177/0305735606067168
   [Anonymous], 1992, Psychology of Emotion
   [Anonymous], 2004, P MUS PERC COGN
   [Anonymous], 2009, P 2 INT C MUS COMM S
   [Anonymous], 2000, TECHNICAL REPORT
   Barrett FS, 2010, EMOTION, V10, P390, DOI 10.1037/a0019006
   Beaupré MG, 2005, J CROSS CULT PSYCHOL, V36, P355, DOI 10.1177/0022022104273656
   Brattico E, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00308
   Brown D., 1991, Human universals
   CACIOPPO JT, 1986, J PERS SOC PSYCHOL, V50, P260, DOI 10.1037/0022-3514.50.2.260
   Chentsova-Dutton YE, 2010, J PERS SOC PSYCHOL, V98, P507, DOI 10.1037/a0018534
   Clore GL, 2007, TRENDS COGN SCI, V11, P393, DOI 10.1016/j.tics.2007.08.005
   Cohen AS, 2013, SCHIZOPHR RES, V148, P111, DOI 10.1016/j.schres.2013.05.003
   D'Arcey J.T., 2013, ASSESSING VALIDITY F
   Danner L, 2014, FOOD QUAL PREFER, V32, P167, DOI 10.1016/j.foodqual.2013.01.004
   Den Uyl M. J., 2005, P MEAS BEH INF TECHN, V30, P589
   Derntl B, 2009, PERCEPTION, V38, P1849, DOI 10.1068/p6448
   Dimberg U, 2000, PSYCHOL SCI, V11, P86, DOI 10.1111/1467-9280.00221
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Ekman P., 2000, HDB COGNITION EMOTIO, DOI DOI 10.1002/0470013494.CH3
   Ekman Paul, 2002, A HUMAN FACE, V2, P3
   Elfenbein HA, 2002, PSYCHOL BULL, V128, P243, DOI 10.1037//0033-2909.128.2.243
   Friesen E., 1978, Facialaction coding system: Manual, V3, P5, DOI DOI 10.1708/1069.11717
   Frith C, 2009, PHILOS T R SOC B, V364, P3453, DOI 10.1098/rstb.2009.0142
   Gabrielsson A, 2001, MUSIC SCI, V5, P123, DOI 10.1177/10298649020050S105
   Goldberg JH, 2014, INT J HUM-COMPUT INT, V30, P518, DOI 10.1080/10447318.2014.906156
   Greenberg J., 2004, Handbook of Experimental Existential Psychology
   Grewe O, 2007, EMOTION, V7, P774, DOI 10.1037/1528-3542.7.4.774
   Grewe O, 2011, PSYCHOL MUSIC, V39, P220, DOI 10.1177/0305735610362950
   Grewe O, 2009, ANN NY ACAD SCI, V1169, P351, DOI 10.1111/j.1749-6632.2009.04783.x
   Hazlett RL, 1999, J ADVERTISING RES, V39, P7
   Hietanen JK, 1998, PSYCHOPHYSIOLOGY, V35, P530, DOI 10.1017/S0048577298970445
   Hunter PG, 2010, PSYCHOL AESTHET CREA, V4, P47, DOI 10.1037/a0016873
   Huron D, 2001, ANN NY ACAD SCI, V930, P43, DOI 10.1111/j.1749-6632.2001.tb05724.x
   Huron D, 2011, MUSIC SCI, V15, P146, DOI 10.1177/1029864911401171
   IZARD CE, 1992, PSYCHOL REV, V99, P561, DOI 10.1037/0033-295X.99.3.561
   Jack RE, 2012, P NATL ACAD SCI USA, V109, P7241, DOI 10.1073/pnas.1200155109
   Johnson-Laird Philip Nicholas, 1989, Cognition and emotion, V3, P81, DOI [DOI 10.1080/02699938908408075, 10.1080/02699938908408075]
   Juslin P. N., 2011, Music and the mind: Essays in honour of John Sloboda, P113
   Juslin P. N., 2008, BEHAV BRAIN SCI, V31, P1
   Juslin PN, 2014, PSYCHOL MUSIC, V42, P599, DOI 10.1177/0305735613484548
   Juslin PN, 2013, PHYS LIFE REV, V10, P235, DOI 10.1016/j.plrev.2013.05.008
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kawakami A, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00311
   Kivy P., 1990, Music Alone: Philosophical Reflections on the Purely Musical Experience
   Konecni V. J., 2008, Psychol. Aesthetics, Creativity, Arts, V2, P115, DOI DOI 10.1037/1931-3896.2.2.115
   Konecni VJ, 2007, AM J PSYCHOL, V120, P619, DOI 10.2307/20445428
   Krumhuber EG, 2011, EMOTION, V11, P825, DOI 10.1037/a0023856
   LANG PJ, 1993, PSYCHOPHYSIOLOGY, V30, P261, DOI 10.1111/j.1469-8986.1993.tb03352.x
   Larsen JT, 2011, J PERS SOC PSYCHOL, V100, P1095, DOI 10.1037/a0021846
   Lench HC, 2011, PSYCHOL BULL, V137, P834, DOI 10.1037/a0024244
   Lundqvist LO, 2009, PSYCHOL MUSIC, V37, P61, DOI 10.1177/0305735607086048
   Marsh AA, 2003, PSYCHOL SCI, V14, P373, DOI 10.1111/1467-9280.24461
   Moriguchi Y, 2005, NEUROREPORT, V16, P133, DOI 10.1097/00001756-200502080-00012
   Muth C, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00365
   Nagel F, 2007, BEHAV RES METHODS, V39, P283, DOI 10.3758/BF03193159
   Nelson NL, 2013, EMOT REV, V5, P8, DOI 10.1177/1754073912457227
   Noldus Information Technology, 2008, FACEREADER REF MAN V
   North AC., 1995, PSYCHOMUSICOLOGY, V14, P77, DOI [10.1037/h0094090, DOI 10.1037/H0094090]
   Panksepp J, 1995, MUSIC PERCEPT, V13, P171
   Pereira CS, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027241
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   RUSSELL JA, 1994, PSYCHOL BULL, V115, P102, DOI 10.1037/0033-2909.115.1.102
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Salimpoor VN, 2011, NAT NEUROSCI, V14, P257, DOI 10.1038/nn.2726
   Salimpoor VN, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0007487
   Scherer K. R., 2013, EMOTIONAL POWER MUSI, P121, DOI [DOI 10.1093/ACPROF:OSO/9780199654888.003.0010, 10.1093/acprof:oso/9780199654888.003.0016, DOI 10.1093/ACPROF:OSO/9780199654888.003.0016]
   SCHNEIDER W, 1977, PSYCHOL REV, V84, P1, DOI 10.1037/0033-295X.84.1.1
   Schubert E, 1999, AUST J PSYCHOL, V51, P154, DOI 10.1080/00049539908255353
   Schubert E., 2010, Handbook of music and emotion: Theory, research, applications, P223, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0009
   Sloboda J. A., 1991, Psychology of Music, V19, P110, DOI [10.1177/0305735691192002, DOI 10.1177/0305735691192002]
   Taruffi L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0110490
   Thompson WF, 2001, PSYCHOL SCI, V12, P248, DOI 10.1111/1467-9280.00345
   Van den Tol AJM, 2015, PSYCHOL MUSIC, V43, P473, DOI 10.1177/0305735613517410
   Van den Tol AJM, 2013, PSYCHOL MUSIC, V41, P440, DOI 10.1177/0305735611430433
   van Kuilenburg H, 2005, LECT NOTES ARTIF INT, V3720, P194, DOI 10.1007/11564096_22
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Vuoskoski JK, 2012, PSYCHOL AESTHET CREA, V6, P204, DOI 10.1037/a0026937
   Weth K., 2013, 3 INT C MUS EM ICME3
   Weth K., 2014, INT C STUD SYST MUS
   Whalen PJ, 1998, J NEUROSCI, V18, P411
   Wildschut T, 2006, J PERS SOC PSYCHOL, V91, P975, DOI 10.1037/0022-3514.91.5.975
   Witvliet C. V., 1996, PSYCHOPHYSIOLOGY S, P91
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 85
TC 29
Z9 31
U1 3
U2 40
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1029-8649
EI 2045-4147
J9 MUSIC SCI
JI Music Sci.
PD DEC
PY 2015
VL 19
IS 4
BP 412
EP 432
DI 10.1177/1029864915606796
PG 21
WC Music; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music; Psychology
GA CY0LD
UT WOS:000366096700006
OA Bronze
DA 2024-01-09
ER

PT J
AU Wang, XN
   Guo, W
   Tong, WW
AF Wang, Xiaoning
   Guo, Wei
   Tong, Weiwei
TI Digital Music Feature Recognition Based on Wireless Sensing Technology
SO JOURNAL OF SENSORS
LA English
DT Article
AB With the rapid development of information technology, digital music is subsequently increasing in large quantities, and how a good integration of vocal input and recognition technology can be transformed into digital music can greatly improve the efficiency of music production while ensuring the quality and effect of music. This paper focuses on the implementation and application of human voice input and recognition technology in digital music creation, enabling users to generate digital music forms by simply humming a melodic fragment of a piece of music into a microphone. The paper begins with an introduction to digital music and speech recognition technology and goes on to describe the respective characteristics of various audio formats, which are selected as data sources for digital music creation based on the advantages of the files in terms of retrieval. Following that, the method of extracting musical information from music is described, and the main melody is successfully extracted from the multitrack file to extract the corresponding musical performance information. The feature extraction of humming input melody is further described in detail. The traditional speech recognition method of using short-time energy and short-time overzero rate features for speech endpoint detection is analyzed. Combining the characteristics of humming music, the method of cutting notes by two-stage cutting mode, i.e., combining energy saliency index, overzero rate, and pitch change, is adopted to cut notes, which leads to a substantial improvement in performance. The algorithm uses the melody extraction algorithm to obtain the melody line, merges the short-time segments of the melody line to reduce the error rate of emotion recognition, uses the melody line to segment the music signal to generate segmented segments, then abstracts the features of the segmented segments through a CNN-based structural model, and inputs the output of the model to the regressor in cascade with the melody contour features of the corresponding segmented segments to finally obtain the emotion V/A value of the segmented segments.
C1 [Wang, Xiaoning] Fujian Normal Univ, Sch Mus, Fuzhou 350108, Fujian, Peoples R China.
   [Guo, Wei] Xiamen Univ, Sch Arts, Xiamen 361005, Fujian, Peoples R China.
   [Tong, Weiwei] Mahasarakham Univ, Sch Educ, Maha Sarakham 44150, Thailand.
C3 Fujian Normal University; Xiamen University; Mahasarakham University
RP Guo, W (corresponding author), Xiamen Univ, Sch Arts, Xiamen 361005, Fujian, Peoples R China.
EM wxn123wxn123wxn123@126.com; wguo@xmu.edu.cn; wxn123wxn123wxn123@163.com
OI Guo, Wei/0009-0003-3647-4515
CR Barnes JH, 2020, OTOLARYNG HEAD NECK, V163, P623, DOI 10.1177/0194599820930662
   Belikovetsky S, 2019, IEEE T INF FOREN SEC, V14, P1127, DOI 10.1109/TIFS.2018.2851584
   Bender M, 2021, EUR J OPER RES, V290, P1083, DOI 10.1016/j.ejor.2020.08.049
   Bhangale Tejas, 2019, Soft Computing and Signal Processing. Proceedings of ICSCSP 2018. Advances in Intelligent Systems and Computing (AISC 900), P583, DOI 10.1007/978-981-13-3600-3_55
   Goyal A, 2019, FORENSIC SCI INT, V298, P332, DOI 10.1016/j.forsciint.2019.02.031
   Hodgson T, 2020, CULT THEORY CRIT, V61, P424, DOI 10.1080/14735784.2021.1894961
   Hua G, 2021, IEEE T INF FOREN SEC, V16, P236, DOI 10.1109/TIFS.2020.3009579
   Ismanto B.R., 2021, INDONESIAN J COMPUTI, V15, P11, DOI [10.22146/ijccs.54646, DOI 10.22146/IJCCS.54646]
   Li SL, 2020, PROD OPER MANAG, V29, P688, DOI 10.1111/poms.13131
   Liu ZH, 2019, IEEE T INF FOREN SEC, V14, P1171, DOI 10.1109/TIFS.2018.2871748
   McPherson A, 2020, ORGAN SOUND, V25, P53, DOI 10.1017/S1355771819000463
   Meier LM, 2019, NEW MEDIA SOC, V21, P543, DOI 10.1177/1461444818800998
   Ritts M, 2021, GEOFORUM, V124, P144, DOI 10.1016/j.geoforum.2021.04.022
   Rodman A, 2020, SEMIN NEPHROL, V40, P279, DOI 10.1016/j.semnephrol.2020.04.006
   Rodríguez-Arauz G, 2019, CULT DIVERS ETHN MIN, V25, P379, DOI 10.1037/cdp0000232
   Roper A, 2020, ALEXANDRIA J NATL IN, V30, P32, DOI [10.1177/0955749020967860, DOI 10.1177/0955749020967860]
   Shen JL, 2019, MULTIMEDIA SYST, V25, P639, DOI 10.1007/s00530-019-00613-z
   Shen TC, 2020, AAAI CONF ARTIF INTE, V34, P206
   Shukla S.K., 2021, INDIAN J SCI TECHNOL, V14, P319, DOI [10.17485/IJST/v14i4.2108, DOI 10.17485/IJST/v14i4.2108]
   Wu JQ, 2020, IEEE T INF FOREN SEC, V15, P2282, DOI 10.1109/TIFS.2019.2963764
   Xie ZZ, 2018, J INF SECUR APPL, V43, P37, DOI 10.1016/j.jisa.2018.10.003
NR 21
TC 0
Z9 0
U1 0
U2 6
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1687-725X
EI 1687-7268
J9 J SENSORS
JI J. Sens.
PD MAR 18
PY 2022
VL 2022
AR 8175834
DI 10.1155/2022/8175834
PG 9
WC Engineering, Electrical & Electronic; Instruments & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Instruments & Instrumentation
GA 0Y5QX
UT WOS:000790446500002
OA gold
DA 2024-01-09
ER

PT J
AU Long, P
   Barber, S
AF Long, Paul
   Barber, Simon
TI Voicing passion: The emotional economy of songwriting
SO EUROPEAN JOURNAL OF CULTURAL STUDIES
LA English
DT Article
DE Affect; creativity; emotional labour; music industries; passion;
   songwriter; songwriting; voicing
ID CREATIVITY; TEAMS; MUSIC
AB This article examines articulations of the role of passion in accounts of the life and work of the songwriter. It draws upon a range of interviews with successful artists captured in the Sodajerker On Songwriting podcast. It is suggested that these interviews capture the voicing' of the conventions of creativity in popular music, exploring a context in which passionate motivation, expression and understanding of the (potentially) affective responses to songs are paramount to the labour of the songwriter. The article explores how the core of this labour deals in emotion, attempting to articulate feelings in recognisable, tradable form. This is a process that is both instrumentally rationalised but often felt to be a deeply authentic process, understood (and believed) to spring from the individual's emotional experience, so conferring identity in a generic field. In light of current debates about the nature of creative work and emotional labour, the accounts drawn upon here can be seen to epitomise many of the qualities of what constitutes good work' through a mode of self-actualisation.
C1 [Long, Paul] Birmingham City Univ, Birmingham Ctr Media & Cultural Res, Media & Cultural Hist, Birmingham B4 7XG, W Midlands, England.
   [Barber, Simon] Birmingham City Univ, Ctr Media & Cultural Res, Birmingham B4 7XG, W Midlands, England.
C3 Birmingham City University; Birmingham City University
RP Long, P (corresponding author), Birmingham City Univ, Birmingham Ctr Media & Cultural Res, Parkside Bldg, Birmingham B4 7XG, W Midlands, England.
EM paul.long@bcu.ac.uk
OI Long, Paul/0000-0001-6410-5803; Barber, Simon/0000-0002-2844-360X
CR Adorno T., 1941, RECORD ROCK POP WRIT, P301
   [Anonymous], 6 STEPS SONGWRITING
   [Anonymous], 2013, ISLE NOISES CONVERSA
   [Anonymous], 2011, HDB MUSIC EMOTION TH
   [Anonymous], DID OUR LOVE GO RISE
   [Anonymous], 2003, SONGWRITERS SONGWRIT
   [Anonymous], EVERYBODY DANCE CHIC
   [Anonymous], 2009, PWL FACTORY FLOOR
   [Anonymous], 2011, CREATIVE LABOUR
   [Anonymous], 2003, Cultural Work: Understanding the Cultural Industries
   [Anonymous], 2003, Cultural Work: Understanding the Cultural Industries
   Bennett J, 2012, SEMPRE STUD PSYCHOL, P139
   Bennett Joe, 2011, J ART RECORD PRODUCT
   Burns G., 1987, Popular Music, V6, P1, DOI [DOI 10.1017/S026114, 10.1017/S0261143000006577, DOI 10.1017/S0261143000006577]
   Cairns D, 2014, SUNDAY TIMES, P22
   Caves RE, 2003, J ECON PERSPECT, V17, P73, DOI 10.1257/089533003765888430
   Couldry N, 2011, CULT SOCIOL, V5, P263, DOI 10.1177/1749975510378191
   Emerson Ken, 2006, ALWAYS MAGIC AIR BOM
   Ewer G, 2005, ESSENTIAL SECRETS SO
   Fitzgerald John., 1995, POP MUSIC SOC, V19, P59, DOI DOI 10.1080/03007769508591581)
   GROCE SB, 1991, POP MUSIC SOC, V15, P33, DOI 10.1080/03007769108591421
   Hass RW, 2010, PSYCHOL MUSIC, V38, P463, DOI 10.1177/0305735609352035
   Hesmondhalgh D, 2013, The Cultural Industries
   Hesmondhalgh D., 2008, The SAGE Handbook of Cultural Analysis, P552
   Hirschhorn Joel, 2001, COMPLETE IDIOTS GUID
   Hochschild A. R., 1983, MANAGED HEART
   Hunter PG, 2010, SPRINGER HANDB AUDIT, V36, P129, DOI 10.1007/978-1-4419-6114-3_5
   Isherwood M., 2014, SOUNDING OUT SONGWRI
   Jasen David A., 2003, TIN PAN ALLEY ENCY G
   Jones M, 2003, CULTURAL WORK UNDERS, P147
   Kawashima D, 2004, MATRIX SONGWRITERS W
   McCormick N, 2009, XENOMANIA WRITE HIT
   McIntyre P, 2008, CREATIVITY RES J, V20, P40, DOI 10.1080/10400410701841898
   McIntyre P, 2011, J MUSIC TECHNOL EDUC, V4, P77, DOI 10.1386/jmte.4.1.77_1
   Mosser K, 2008, POPULAR MUSICOLOGY, V2
   Negus K., 2004, Creativity, Communication and Cultural Value
   PAPSON S, 1986, THEOR CULT SOC, V3, P99
   Pattison P., 2012, SONGWRITING BOUNDARI
   Peterik J, 2010, SONGWRITING DUMMIES, V2nd
   Toynbee J., 2000, Making popular music
   UK Music, 2013, EC CONTR COR UK MUS
   West E, 2010, INT J CULTURAL STUD, V13, P451, DOI 10.1177/1367877910372703
NR 42
TC 3
Z9 8
U1 0
U2 23
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1367-5494
EI 1460-3551
J9 EUR J CULT STUD
JI Eur. J. Cult. Stud.
PD APR
PY 2015
VL 18
IS 2
SI SI
BP 142
EP 157
DI 10.1177/1367549414563298
PG 16
WC Cultural Studies
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Cultural Studies
GA CE3DM
UT WOS:000351705200003
OA Green Accepted
DA 2024-01-09
ER

PT J
AU Thompson, WF
   Marin, MM
   Stewart, L
AF Thompson, William Forde
   Marin, Manuela M.
   Stewart, Lauren
TI Reduced sensitivity to emotional prosody in congenital amusia rekindles
   the musical protolanguage hypothesis
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
LA English
DT Article
DE auditory; pitch; contour; intonation; impairment
ID DECODING SPEECH PROSODY; TONE-DEAFNESS; INTONATION; PITCH; PERCEPTION;
   MEMORY; BRAIN; DISCRIMINATION; LANGUAGE; DEFICITS
AB A number of evolutionary theories assume that music and language have a common origin as an emotional protolanguage that remains evident in overlapping functions and shared neural circuitry. The most basic prediction of this hypothesis is that sensitivity to emotion in speech prosody derives from the capacity to process music. We examined sensitivity to emotion in speech prosody in a sample of individuals with congenital amusia, a neurodevelopmental disorder characterized by deficits in processing acoustic and structural attributes of music. Twelve individuals with congenital amusia and 12 matched control participants judged the emotional expressions of 96 spoken phrases. Phrases were semantically neutral but prosodic cues (tone of voice) communicated each of six emotional states: happy, tender, afraid, irritated, sad, and no emotion. Congenitally amusic individuals were significantly worse than matched controls at decoding emotional prosody, with decoding rates for some emotions up to 20% lower than that of matched controls. They also reported difficulty understanding emotional prosody in their daily lives, suggesting some awareness of this deficit. The findings support speculations that music and language share mechanisms that trigger emotional responses to acoustic attributes, as predicted by theories that propose a common evolutionary link between these domains.
C1 [Thompson, William Forde] Macquarie Univ, ARC Ctr Excellence Cognit & Its Disorders, Sydney, NSW 2109, Australia.
   [Marin, Manuela M.] Univ Vienna, Dept Basic Psychol Res & Res Methods, A-1010 Vienna, Austria.
   [Stewart, Lauren] Univ London, Dept Psychol, London SE14 6NW, England.
C3 Macquarie University; University of Vienna; University of London
RP Thompson, WF (corresponding author), Macquarie Univ, ARC Ctr Excellence Cognit & Its Disorders, Sydney, NSW 2109, Australia.
EM Bill.Thompson@mq.edu.au
RI Marin, Manuela M./Q-4496-2017; Marin, Manuela M/G-8693-2012; Stewart,
   Lauren/HHC-2911-2022
OI Marin, Manuela M./0000-0002-9657-1507; stewart,
   lauren/0000-0002-6221-6064; Thompson, William/0000-0002-4256-1338
FU Australian Research Council [DP0771890]; Economic and Social Research
   Council [RES-061-25-0155]; Economic and Social Research Council
   [ES/F001940/1] Funding Source: researchfish; ESRC [ES/F001940/1] Funding
   Source: UKRI; Australian Research Council [DP0771890] Funding Source:
   Australian Research Council
FX We thank Rachel Bennetts, Alex Chilvers, Catherine Greentree, Hao Tam
   Ho, Felicity Keating, Bojan Neskovic, and Lena Quinto for technical
   assistance. Bruno Gingras, Fang Lui, and Isabelle Peretz provided
   valuable input on the research. This research was supported by the
   Australian Research Council Discovery Grant DP0771890 (to W.F.T.) and
   Economic and Social Research Council Grant RES-061-25-0155 (to L.S.).
CR [Anonymous], 1922, LANGUAGE ITS NATURE
   [Anonymous], 2006, SINGING NEANDERTHALS
   Ayotte J, 2002, BRAIN, V125, P238, DOI 10.1093/brain/awf028
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Beaucousin V, 2007, CEREB CORTEX, V17, P339, DOI 10.1093/cercor/bhj151
   Boersma P., 2014, PRAAT DOING PHONETIC
   Brown S, 2000, ORIGINS OF MUSIC, P271
   Cuddy LL, 2005, ANN NY ACAD SCI, V1060, P311, DOI 10.1196/annals.1360.026
   Darwin G., 1871, P423
   Dissanayake E, 2000, ORIGINS OF MUSIC, P389
   Ethofer T, 2006, NEUROIMAGE, V30, P580, DOI 10.1016/j.neuroimage.2005.09.059
   Fitch WT, 2006, COGNITION, V100, P173, DOI 10.1016/j.cognition.2005.11.009
   Fitch WT, 2010, EVOLUTION OF LANGUAGE, PROCEEDINGS, P137
   Fitzsimons M, 2001, BRAIN LANG, V78, P94, DOI 10.1006/brln.2000.2448
   Foxton JM, 2004, BRAIN, V127, P801, DOI 10.1093/brain/awh105
   Frühholz S, 2012, CEREB CORTEX, V22, P1107, DOI 10.1093/cercor/bhr184
   Gaab N, 2003, NEUROIMAGE, V19, P1417, DOI 10.1016/S1053-8119(03)00224-6
   Gordon E., 1965, MUSICAL APTITUDE PRO
   Gosselin N, 2009, ANN NY ACAD SCI, V1169, P270, DOI 10.1111/j.1749-6632.2009.04762.x
   Grandjean D, 2005, NAT NEUROSCI, V8, P145, DOI 10.1038/nn1392
   Grandjean D, 2006, PROG BRAIN RES, V156, P235, DOI 10.1016/S0079-6123(06)56012-1
   Henry MJ, 2010, MUSIC PERCEPT, V27, P413, DOI 10.1525/mp.2010.27.5.413
   Hutchins S, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00236
   Hyde KL, 2004, PSYCHOL SCI, V15, P356, DOI 10.1111/j.0956-7976.2004.00683.x
   Hyde KL, 2007, J NEUROSCI, V27, P13028, DOI 10.1523/JNEUROSCI.3039-07.2007
   Hyde KL, 2006, BRAIN, V129, P2562, DOI 10.1093/brain/awl204
   Hyde KL, 2011, CEREB CORTEX, V21, P292, DOI 10.1093/cercor/bhq094
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Ilie G, 2011, MUSIC PERCEPT, V28, P247, DOI 10.1525/MP.2011.28.3.247
   Jiang CM, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0041411
   Jiang CM, 2010, NEUROPSYCHOLOGIA, V48, P2630, DOI 10.1016/j.neuropsychologia.2010.05.009
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   KALMUS H, 1980, ANN HUM GENET, V43, P369, DOI 10.1111/j.1469-1809.1980.tb01571.x
   Koelsch S, 2009, HUM BRAIN MAPP, V30, P859, DOI 10.1002/hbm.20550
   Levitin DJ, 2003, NEUROIMAGE, V20, P2142, DOI 10.1016/j.neuroimage.2003.08.016
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Liu F, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030374
   Liu F, 2010, BRAIN, V133, P1682, DOI 10.1093/brain/awq089
   Loui P, 2009, ANN NY ACAD SCI, V1169, P121, DOI 10.1111/j.1749-6632.2009.04781.x
   Loui P, 2009, J NEUROSCI, V29, P10215, DOI 10.1523/JNEUROSCI.1701-09.2009
   Mandell J, 2007, RESTOR NEUROL NEUROS, V25, P323
   Marin MM, 2012, NEUROPSYCHOLOGIA, V50, P367, DOI 10.1016/j.neuropsychologia.2011.12.006
   McDonald C, 2008, MUSIC PERCEPT, V25, P345, DOI 10.1525/MP.2008.25.4.345
   Nan Y, 2010, BRAIN, V133, P2635, DOI 10.1093/brain/awq178
   Nelson Hazel E., 1991, National Adult Reading Test (NART)
   Patel A. D., 2008, Music, Language, and the Brain
   Patel AD, 2005, BRAIN COGNITION, V59, P310, DOI 10.1016/j.bandc.2004.10.003
   Patel AD, 2008, MUSIC PERCEPT, V25, P357, DOI 10.1525/MP.2008.25.4.357
   Peretz I, 2003, ANN NY ACAD SCI, V999, P58, DOI 10.1196/annals.1284.006
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   Peretz I, 2002, NEURON, V33, P185, DOI 10.1016/S0896-6273(01)00580-3
   Peretz I, 2001, BRAIN, V124, P928, DOI 10.1093/brain/124.5.928
   Peretz I, 2007, AM J HUM GENET, V81, P582, DOI 10.1086/521337
   Särkämö T, 2009, NEUROPSYCHOLOGIA, V47, P2642, DOI 10.1016/j.neuropsychologia.2009.05.015
   Stewart L, 2011, Q J EXP PSYCHOL, V64, P625, DOI 10.1080/17470218.2011.552730
   Thompson W.F., 2010, Handbook of music and emotion: Theory, research, and applications, P755
   Thompson WF, 2006, SEMIOTICA, V158, P407, DOI 10.1515/SEM.2006.017
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Tillmann B, 2009, BRAIN COGNITION, V71, P259, DOI 10.1016/j.bandc.2009.08.003
   Trehub SE, 2003, NAT NEUROSCI, V6, P669, DOI 10.1038/nn1084
   VOS PG, 1989, MUSIC PERCEPT, V6, P383
   Wechsler D, 1997, WAIS 3 ADM SCORING M, DOI [10.1177/1073191102009001003, DOI 10.1177/1073191102009001003]
   Wiethoff S, 2008, NEUROIMAGE, V39, P885, DOI 10.1016/j.neuroimage.2007.09.028
   Williamson VJ, 2010, MEMORY, V18, P657, DOI 10.1080/09658211.2010.501339
   ZATORRE RJ, 1994, J NEUROSCI, V14, P1908, DOI 10.1523/jneurosci.14-04-01908.1994
NR 66
TC 101
Z9 113
U1 2
U2 38
PU NATL ACAD SCIENCES
PI WASHINGTON
PA 2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA
SN 0027-8424
EI 1091-6490
J9 P NATL ACAD SCI USA
JI Proc. Natl. Acad. Sci. U. S. A.
PD NOV 13
PY 2012
VL 109
IS 46
BP 19027
EP 19032
DI 10.1073/pnas.1210344109
PG 6
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Science & Technology - Other Topics
GA 043UY
UT WOS:000311576300080
PM 23112175
OA Bronze, Green Published
DA 2024-01-09
ER

PT J
AU Gu, J
   Cao, LJ
   Liu, BL
AF Gu, Jin
   Cao, Linjing
   Liu, Baolin
TI Modality-general representations of valences perceived from visual and
   auditory modalities
SO NEUROIMAGE
LA English
DT Article
DE Valence; Modality-general representation; Left postcentral gyrus; MTG;
   Visual; Auditory
ID EMOTIONS; ACTIVATION; DISCRETE; PITFALLS; STIMULI; SYSTEMS; WORDS; MUSIC
AB Valence is a dimension of emotion and can be either positive, negative, or neutral. Valences can be expressed through the visual and auditory modalities, and the valences of each modality can be conveyed by different types of stimuli (face, body, voice or music). This study focused on the modality-general representations of valences, that is, valence information can be shared across not only visual and auditory modalities but also different types of stimuli within each modality. Functional magnetic resonance imaging (fMRI) data were collected when subjects made affective judgment on silent videos (face and body) and audio clips (voice and music). The searchlight analysis helped to locate four areas that might be sensitive to the representations of modality-general valences, including the bilateral postcentral gyrus, left middle temporal gyrus (MTG) and right middle frontal gyrus (MFG). Further cross-modal classification based on multivoxel pattern analysis (MVPA) was performed as a validation analysis, which suggested that only the left postcentral gyrus could successfully distinguish three valences (positive versus negative and versus neutral: PvsNvs0) across different types of stimuli (face, body, voice or music), and the classification was also successful in left MTG across the stimuli types of face and body. The univariate analysis further found the valence-specific activation differences across stimulus types in MTG. Our study showed that the left postcentral gyrus was informative to valence representations, and extended the research about valence representation that the modality-general representation of valences across not only visual and auditory modalities but also different types of stimuli within each modality.
C1 [Gu, Jin; Cao, Linjing] Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China.
   [Liu, Baolin] Univ Sci & Technol Beijing, Sch Comp & Commun Engn, Beijing 100083, Peoples R China.
C3 Tianjin University; University of Science & Technology Beijing
RP Liu, BL (corresponding author), Univ Sci & Technol Beijing, Sch Comp & Commun Engn, Beijing 100083, Peoples R China.
EM liubaolin@tsinghua.edu.cn
RI Cao, Linjing/IWE-2260-2023
OI Gu, Jin/0000-0003-1147-6170
FU National Key Research and Development Program of China [2018YFB0204304];
   National Natural Science Foundation of China [61571327]
FX This work was supported by the National Key Research and Development
   Program of China (No.2018YFB0204304), National Natural Science
   Foundation of China (No.U1736219 and No.61571327).
CR Adolphs R, 2002, CURR OPIN NEUROBIOL, V12, P169, DOI 10.1016/S0959-4388(02)00301-X
   [Anonymous], 2014, PSYCHOL CONSTRUCTION
   Bänziger T, 2012, EMOTION, V12, P1161, DOI 10.1037/a0025827
   Baucom LB, 2012, NEUROIMAGE, V59, P718, DOI 10.1016/j.neuroimage.2011.07.037
   Cao LJ, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00419
   Cato MA, 2004, J COGNITIVE NEUROSCI, V16, P167, DOI 10.1162/089892904322984481
   Chikazoe J, 2014, NAT NEUROSCI, V17, P1114, DOI 10.1038/nn.3749
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   Etzel JA, 2013, NEUROIMAGE, V78, P261, DOI 10.1016/j.neuroimage.2013.03.041
   Flaisch T, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01861
   Fontaine JRJ, 2007, PSYCHOL SCI, V18, P1050, DOI 10.1111/j.1467-9280.2007.02024.x
   Herbert C, 2009, SOC COGN AFFECT NEUR, V4, P35, DOI 10.1093/scan/nsn027
   Hoffmann M, 2015, HUM BRAIN MAPP, V36, P655, DOI 10.1002/hbm.22654
   Kassam KS, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0066032
   Kensinger EA, 2006, COGN AFFECT BEHAV NE, V6, P110, DOI 10.3758/CABN.6.2.110
   Kim J, 2017, NEUROIMAGE, V148, P42, DOI 10.1016/j.neuroimage.2017.01.002
   Kim J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0161589
   Kim J, 2015, J NEUROSCI, V35, P5655, DOI 10.1523/JNEUROSCI.4059-14.2015
   Klasen M, 2011, J NEUROSCI, V31, P13635, DOI 10.1523/JNEUROSCI.2833-11.2011
   Koelsch S, 2006, HUM BRAIN MAPP, V27, P239, DOI 10.1002/hbm.20180
   Kragel PA, 2016, ENEURO, V3, DOI 10.1523/ENEURO.0090-15.2016
   Kragel PA, 2015, SOC COGN AFFECT NEUR, V10, P1437, DOI 10.1093/scan/nsv032
   Kriegeskorte N, 2006, P NATL ACAD SCI USA, V103, P3863, DOI 10.1073/pnas.0600244103
   Kriegeskorte N, 2009, NAT NEUROSCI, V12, P535, DOI 10.1038/nn.2303
   Liang Y, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00094
   Patel I, 2011, PATIENT-RELAT OUTCOM, V2, P21, DOI 10.2147/PROM.S15747
   Peelen MV, 2010, J NEUROSCI, V30, P10127, DOI 10.1523/JNEUROSCI.2161-10.2010
   Saarimäki H, 2016, CEREB CORTEX, V26, P2563, DOI 10.1093/cercor/bhv086
   Sarkheil P, 2013, SOC COGN AFFECT NEUR, V8, P950, DOI 10.1093/scan/nss092
   Shinkareva SV, 2014, HUM BRAIN MAPP, V35, P3558, DOI 10.1002/hbm.22421
   Subramaniam K, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00211
   van de Riet WAC, 2009, SOC NEUROSCI-UK, V4, P101, DOI 10.1080/17470910701865367
   Watson R, 2014, J NEUROSCI, V34, P6813, DOI 10.1523/JNEUROSCI.4478-13.2014
   Woo CW, 2014, NEUROIMAGE, V91, P412, DOI 10.1016/j.neuroimage.2013.12.058
   Zhang GY, 2017, BRAIN IMAGING BEHAV, V11, P784, DOI 10.1007/s11682-016-9553-2
NR 35
TC 2
Z9 2
U1 1
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD DEC
PY 2019
VL 203
AR 116199
DI 10.1016/j.neuroimage.2019.116199
PG 8
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA JN4WY
UT WOS:000496900900017
PM 31536804
DA 2024-01-09
ER

PT J
AU Jafari, Z
   Esmaili, M
   Delbari, A
   Mehrpour, M
   Mohajerani, MH
AF Jafari, Zahra
   Esmaili, Mahdiye
   Delbari, Ahmad
   Mehrpour, Masoud
   Mohajerani, Majid H.
TI Post-stroke acquired amusia: A comparison between right- and left-brain
   hemispheric damages
SO NEUROREHABILITATION
LA English
DT Article
DE Stroke; acquired amusia; Musical Emotional Bursts; emotion recognition;
   aging
ID STROKE PATIENTS; EMOTION RECOGNITION; CONGENITAL AMUSIA; UNILATERAL
   STROKE; MUSICAL EXPERTISE; FACIAL EMOTION; PERCEPTION; DISORDERS;
   THERAPY; LESION
AB BACKGROUND: Although extensive research has been published about the emotional consequences of stroke, most studies have focused on emotionalwords, speech prosody, voices, or facial expressions. The emotional processing of musical excerpts following stroke has been relatively unexplored.
   OBJECTIVE: The present study was conducted to investigate the effects of chronic stroke on the recognition of basic emotions in music.
   METHODS: Seventy persons, including 25 normal controls (NC), 25 persons with right brain damage (RBD) from stroke, and 20 persons with left brain damage (LBD) from stroke between the ages of 31-71 years were studied. The Musical Emotional Bursts (MEB) test, which consists of a set of short musical pieces expressing basic emotional states (happiness, sadness, and fear) and neutrality, was used to test musical emotional perception.
   RESULTS: Both stroke groups were significantly poorer than normal controls for the MEB total score and its subtests (p < 0.001). The RBD group was significantly less able than the LBD group to recognize sadness (p = 0.047) and neutrality (p = 0.015). Negative correlations were found between age and MEB scores for all groups, particularly the NC and RBD groups.
   CONCLUSION: Our findings indicated that stroke affecting the auditory cerebrum can cause acquired amusia with greater severity in RBD than LBD. These results supported the "valence hypothesis" of right hemisphere dominance in processing negative emotions.
C1 [Jafari, Zahra] Iran Univ Med Sci, Sch Rehabil Sci, Dept Basic Sci Rehabil, POB 15875-4391,Shahnazari St,Mother Sq, Tehran, Iran.
   [Jafari, Zahra; Mohajerani, Majid H.] Univ Lethbridge, CCBN, Dept Neurosci, Lethbridge, AB, Canada.
   [Jafari, Zahra; Esmaili, Mahdiye; Delbari, Ahmad] Univ Social Welf & Rehabil Sci USWR, Iranian Res Ctr Aging, Tehran, Iran.
   [Mehrpour, Masoud] IUMS, Firouzgar Hosp, Dept Neurol, Tehran, Iran.
C3 Iran University of Medical Sciences; University of Lethbridge
RP Jafari, Z (corresponding author), Iran Univ Med Sci, Sch Rehabil Sci, Dept Basic Sci Rehabil, POB 15875-4391,Shahnazari St,Mother Sq, Tehran, Iran.
EM jafari.z@iums.ac.ir
RI Jafari, Zahra/GXF-1615-2022; Delbari, Ahmad/D-8560-2017
OI Mohajerani, Majid H./0000-0003-0964-2977
FU Iran University of Medical Sciences [93-03-32-25037]; University of
   Social Welfare and Rehabilitation Sciences
FX This been approved by Iran University of Medical Sciences (grant number
   93-03-32-25037); and University of Social Welfare and Rehabilitation
   Sciences. Good cooperation of all participants in this study are greatly
   appreciated.
CR Adolphs R, 2003, NAT REV NEUROSCI, V4, P165, DOI 10.1038/nrn1056
   [Anonymous], 2004, AM NAT STAND I S3 6
   Balkwill LL, 2004, JPN PSYCHOL RES, V46, P337, DOI 10.1111/j.1468-5584.2004.00265.x
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   BOROD JC, 1992, J CONSULT CLIN PSYCH, V60, P339, DOI 10.1037/0022-006X.60.3.339
   Borod JC, 1998, NEUROPSYCHOLOGY, V12, P446, DOI 10.1037/0894-4105.12.3.446
   Borod JC, 2000, NEUROPSYCHOLOGY, V14, P112, DOI 10.1037/0894-4105.14.1.112
   BOROD JC, 1992, NEUROPSYCHOLOGIA, V30, P827, DOI 10.1016/0028-3932(92)90086-2
   Braun M, 2005, BRAIN COGNITION, V58, P193, DOI 10.1016/j.bandc.2004.11.003
   Carstensen LL, 2005, CURR DIR PSYCHOL SCI, V14, P117, DOI 10.1111/j.0963-7214.2005.00348.x
   Davidson Richard J., 1995, P361
   Ekman P., 1982, Emotion in the Human Face, V2nd ed.
   Eum Y, 2015, TOHOKU J EXP MED, V235, P17, DOI 10.1620/tjem.235.17
   Flom R, 2008, INFANT BEHAV DEV, V31, P716, DOI 10.1016/j.infbeh.2008.04.004
   Foroughan Mahshid, 2008, J. Adv. Cogn. Sci., V10, P29
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Galinska E, 2015, PSYCHIATR POL, V49, P835, DOI 10.12740/PP/25557
   García-Casares N, 2013, NEUROLOGIA, V28, P179, DOI 10.1016/j.nrl.2011.04.010
   Ghassemzadeh H, 2005, DEPRESS ANXIETY, V21, P185, DOI 10.1002/da.20070
   Gopinath B, 2009, STROKE, V40, P1496, DOI 10.1161/STROKEAHA.108.535682
   Gosselin N, 2005, BRAIN, V128, P628, DOI 10.1093/brain/awh420
   Groussard M, 2010, NEUROIMAGE, V49, P2764, DOI 10.1016/j.neuroimage.2009.10.039
   Heilman KM, 1998, J CLIN NEUROPHYSIOL, V15, P409, DOI 10.1097/00004691-199809000-00005
   Hsieh S, 2012, NEUROPSYCHOLOGIA, V50, P1814, DOI 10.1016/j.neuropsychologia.2012.04.006
   Hyde KL, 2007, J NEUROSCI, V27, P13028, DOI 10.1523/JNEUROSCI.3039-07.2007
   Hyde KL, 2011, CEREB CORTEX, V21, P292, DOI 10.1093/cercor/bhq094
   Khalfa S, 2008, NEUROPSYCHOLOGIA, V46, P2485, DOI 10.1016/j.neuropsychologia.2008.04.009
   Kwoun SJ, 2009, J MUSIC THER, V46, P217, DOI 10.1093/jmt/46.3.217
   Laukka P, 2007, MOTIV EMOTION, V31, P182, DOI 10.1007/s11031-007-9063-z
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Loui P, 2009, ANN NY ACAD SCI, V1169, P121, DOI 10.1111/j.1749-6632.2009.04781.x
   Loui P, 2009, J NEUROSCI, V29, P10215, DOI 10.1523/JNEUROSCI.1701-09.2009
   Mandal MK, 1999, J NERV MENT DIS, V187, P603, DOI 10.1097/00005053-199910000-00003
   Mathersul D, 2009, J CLIN EXP NEUROPSYC, V31, P278, DOI 10.1080/13803390802043619
   Mukherjee D, 2006, TOP STROKE REHABIL, V13, P26, DOI 10.1310/tsr1304-26
   Nakhutina L, 2006, ARCH CLIN NEUROPSYCH, V21, P1, DOI 10.1016/j.acn.2005.06.013
   Nilipour R, 2013, CLIN VERSION PERSIAN
   Ofek E, 2013, CLIN NEUROPHYSIOL, V124, P1771, DOI 10.1016/j.clinph.2013.03.005
   Omar R, 2011, NEUROIMAGE, V56, P1814, DOI 10.1016/j.neuroimage.2011.03.002
   Papp G, 2014, SEIZURE-EUR J EPILEP, V23, P533, DOI 10.1016/j.seizure.2014.03.018
   Paquette S., 2013, FRONT PSYCHOL, V4, P1
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   Rodriguez-Fornells A, 2012, ANN NY ACAD SCI, V1252, P282, DOI 10.1111/j.1749-6632.2011.06425.x
   Rosslau K, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00768
   Salimpoor VN, 2011, NAT NEUROSCI, V14, P257, DOI 10.1038/nn.2726
   Särkämö T, 2013, WIRES COGN SCI, V4, P441, DOI 10.1002/wcs.1237
   Särkämö T, 2012, ANN NY ACAD SCI, V1252, P266, DOI 10.1111/j.1749-6632.2011.06405.x
   SILBERMAN EK, 1986, BRAIN COGNITION, V5, P322, DOI 10.1016/0278-2626(86)90035-7
   Stewart L, 2006, BRAIN, V129, P2533, DOI 10.1093/brain/awl171
   Terwogt M. M., 1991, PSYCHOL MUSIC, V19, P99, DOI DOI 10.1177/0305735691192001
   Thompson WF, 2012, P NATL ACAD SCI USA, V109, P19027, DOI 10.1073/pnas.1210344109
   Tinga AM, 2016, NEUROPSYCHOL REV, V26, P73, DOI 10.1007/s11065-015-9301-1
   Yankner BA, 2008, ANNU REV PATHOL-MECH, V3, P41, DOI 10.1146/annurev.pathmechdis.2.010506.092044
   ZATORRE RJ, 1984, MUSIC PERCEPT, V2, P196
   Zgaljardic Dennis J, 2002, Appl Neuropsychol, V9, P159, DOI 10.1207/S15324826AN0903_4
NR 56
TC 7
Z9 7
U1 0
U2 12
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1053-8135
EI 1878-6448
J9 NEUROREHABILITATION
JI Neurorehabilitation
PY 2017
VL 40
IS 2
BP 233
EP 241
DI 10.3233/NRE-161408
PG 9
WC Clinical Neurology; Rehabilitation
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Neurosciences & Neurology; Rehabilitation
GA ER7FW
UT WOS:000398976700008
PM 28211817
DA 2024-01-09
ER

PT J
AU Goycoolea, M
   Levy, R
   Ramírez, C
AF Goycoolea, Marcos
   Levy, Raquel
   Ramirez, Carlos
TI Central auditory processing. Are the emotional perceptions of those
   listening to classical music inherent in the composition or acquired by
   the listeners?
SO ACTA OTO-LARYNGOLOGICA
LA English
DT Article
DE Emotions and music; physical conduct and music; inherent emotions in
   music; expression of emotions; abstract thinking; reading and
   understanding; education and music; early educational intervention;
   universal language
ID EXPRESSION
AB Conclusions: There is seemingly some inherent component in selected musical compositions that elicits specific emotional perceptions, feelings, and physical conduct. Objectives: The purpose of the study was to determine if the emotional perceptions of those listening to classical music are inherent in the composition or acquired by the listeners. Methods: Fifteen kindergarten students, aged 5 years, from three different sociocultural groups, were evaluated. They were exposed to portions of five purposefully selected classical compositions and asked to describe their emotions when listening to these musical pieces. All were instrumental compositions without human voices or spoken language. In addition, they were played to an audience of an age at which they were capable of describing their perceptions and supposedly had no significant previous experience of classical music. Results: Regardless of their sociocultural background, the children in the three groups consistently identified similar emotions (e.g. fear, happiness, sadness), feelings (e.g. love), and mental images (e.g. giants or dangerous animals walking) when listening to specific compositions. In addition, the musical compositions generated physical conducts that were reflected by the children's corporal expressions. Although the sensations were similar, the way of expressing them differed according to their background.
C1 [Goycoolea, Marcos; Levy, Raquel; Ramirez, Carlos] Clin Las Condes, Dept Otolaryngol, Santiago, Chile.
C3 Clinica Las Condes
RP Goycoolea, M (corresponding author), Clin Las Condes Otorrinolaringol, Lo Fontecilla 441 Las Condes, Santiago 7591046, Chile.
EM mgoycoolea@clinicalascondes.cl
RI Goycoolea, Marcos/AAS-2095-2020
CR [Anonymous], EMPIRICAL STUDIES AR, DOI DOI 10.2190/NBNY-AKDK-GW58-MTEL
   Baumgartner T, 2006, BRAIN RES, V1075, P151, DOI 10.1016/j.brainres.2005.12.065
   Eckman P, 1969, SCIENCE, V4, P86
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Goycoolea M, 2006, ACTA OTO-LARYNGOL, V126, P368, DOI 10.1080/00016480500416942
   Goycoolea MV, 2007, ACTA OTO-LARYNGOL, V127, P711, DOI 10.1080/00016480601053057
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Koelsch S, 2006, HUM BRAIN MAPP, V27, P239, DOI 10.1002/hbm.20180
   Mitterschiffthaler MT, 2007, HUM BRAIN MAPP, V28, P1150, DOI 10.1002/hbm.20337
   Seashore CE, 1967, PSYCHOL MUSIC, P38
NR 11
TC 2
Z9 2
U1 0
U2 17
PU INFORMA HEALTHCARE
PI LONDON
PA TELEPHONE HOUSE, 69-77 PAUL STREET, LONDON EC2A 4LQ, ENGLAND
SN 0001-6489
J9 ACTA OTO-LARYNGOL
JI Acta Oto-Laryngol.
PD APR
PY 2013
VL 133
IS 4
BP 390
EP 393
DI 10.3109/00016489.2012.739732
PG 4
WC Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Otorhinolaryngology
GA 116ZI
UT WOS:000316921500008
PM 23106697
DA 2024-01-09
ER

PT J
AU MacDonald, J
   Wilbiks, JMP
AF MacDonald, Jordan
   Wilbiks, Jonathan M. P.
TI Undergraduate students with musical training report less conflict in
   interpersonal relationships
SO PSYCHOLOGY OF MUSIC
LA English
DT Article
DE training; expertise; non-musical abilities; voice; auditory perception;
   cognition; speech prosody; interpersonal relationships
ID EMOTIONAL INTELLIGENCE; SPEECH PROSODY; RECOGNITION; CHILDREN; QUALITY;
   ADULTS; PERCEPTION; EXPRESSION; DEPRESSION; MUSICIANS
AB Recent research has shown that formal musical training has a wealth of benefits in terms of cognition, mental health, social skills, and even speech perception. Of these benefits, there is strong support for a relationship between formal musical training and an improved ability to recognize emotions in speech prosody. Given this connection, interpersonal relationships stand to benefit from improved communication efficacy, which includes an improved ability to recognize emotions in speech. Interpersonal relationships rely on successful expression and interpretation of emotions in speech. If formal musical training can improve the perception of emotions in speech, it should indirectly benefit interpersonal relationship quality. The current study collected data from 197 undergraduate students about their formal musical training and interpersonal relationship quality through an online survey. The results showed that formal musical training accounted for 8% of the difference in relationship conflict but did not benefit relationship support or depth. While musical expertise does not necessarily improve relationship quality overall, it may help reduce conflict in relationships. Further research is needed, with participants who have greater musical expertise, to clarify the relationship between formal musical training and relationship conflict.
C1 [MacDonald, Jordan; Wilbiks, Jonathan M. P.] Univ New Brunswick, St John, NB E2L 4L5, Canada.
C3 University of New Brunswick
RP MacDonald, J (corresponding author), Univ New Brunswick, St John, NB E2L 4L5, Canada.
EM jmacdo29@unb.ca
OI MacDonald, Jordan/0000-0001-6687-3638
CR Baskent D, 2016, J ACOUST SOC AM, V139, pEL51, DOI 10.1121/1.4942628
   Ciechanowski PS, 2005, J PSYCHOSOM RES, V58, P139, DOI 10.1016/j.jpsychores.2004.07.009
   Cores-Bilbao E, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02238
   Cuddy LL, 2005, ANN NY ACAD SCI, V1060, P311, DOI 10.1196/annals.1360.026
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Good A, 2017, EAR HEARING, V38, P455, DOI 10.1097/AUD.0000000000000402
   Gouzouasis P., 2007, Music Education Research, V9, P81, DOI [DOI 10.1080/14613800601127569, 10.1080/14613800601127569]
   Grossmann I, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0213569
   Hofer A, 2009, EUR PSYCHIAT, V24, P27, DOI 10.1016/j.eurpsy.2008.06.008
   Holt-Lunstad J, 2010, PLOS MED, V7, DOI 10.1371/journal.pmed.1000316
   Hou J., 2017, PSYCHOMUSICOLOGY, V27, P75, DOI [10.1037/pmu0000174, DOI 10.1037/PMU0000174]
   Hyde KL, 2009, J NEUROSCI, V29, P3019, DOI 10.1523/JNEUROSCI.5118-08.2009
   Jiam NT, 2017, HEARING RES, V352, P30, DOI 10.1016/j.heares.2017.01.006
   Juslin PN, 2003, ANN NY ACAD SCI, V1000, P279, DOI 10.1196/annals.1280.025
   Kawase S, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02244
   Kenny R, 2013, J ADOLESCENCE, V36, P351, DOI 10.1016/j.adolescence.2012.12.005
   Kershaw T, 2013, AM J COMMUN PSYCHOL, V52, P288, DOI 10.1007/s10464-013-9594-2
   Kim HS, 2018, PSYCHOL MUSIC, V46, P440, DOI 10.1177/0305735617729028
   Lee KJ, 2020, ARCH PSYCHIAT NURS, V34, P115, DOI 10.1016/j.apnu.2020.02.002
   Lee W., 2006, CHINESE ANN REPORT G, V20, P153
   Lim HA, 2010, J MUSIC THER, V47, P2, DOI 10.1093/jmt/47.1.2
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Mandal M, 2013, J ADOLESCENT HEALTH, V53, P187, DOI 10.1016/j.jadohealth.2013.03.015
   Marques C, 2007, J COGNITIVE NEUROSCI, V19, P1453, DOI 10.1162/jocn.2007.19.9.1453
   Martin AJ, 2009, REV EDUC RES, V79, P327, DOI 10.3102/0034654308325583
   Minzenberg MJ, 2006, COMPR PSYCHIAT, V47, P468, DOI 10.1016/j.comppsych.2006.03.005
   Moeller C, 2015, J SOC PSYCHOL, V155, P314, DOI 10.1080/00224545.2015.1007029
   Moreno S, 2005, ANN NY ACAD SCI, V1060, P93, DOI 10.1196/annals.1360.054
   Müllensiefan D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089642
   Musacchia G, 2007, P NATL ACAD SCI USA, V104, P15894, DOI 10.1073/pnas.0701498104
   Park M, 2015, FRONT HUM NEUROSCI, V8, DOI [10.3389/fnhurn.2014.01049, 10.3389/fnhum.2014.01049]
   Parsons CE, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01440
   Passanisi A, 2015, PROCD SOC BEHV, V191, P2476, DOI 10.1016/j.sbspro.2015.04.308
   Patel AD, 2014, HEARING RES, V308, P98, DOI 10.1016/j.heares.2013.08.011
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Peretz I, 2003, ANN NY ACAD SCI, V999, P58, DOI 10.1196/annals.1284.006
   Peretz I, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00030
   Petrovici A, 2014, PROCD SOC BEHV, V116, P1405, DOI 10.1016/j.sbspro.2014.01.406
   Pierce GR, 1997, J SOC PERS RELAT, V14, P339, DOI 10.1177/0265407597143004
   Rodriguez-Stanley J, 2020, J FAM PSYCHOL, V34, P610, DOI 10.1037/fam0000630
   Schellenberg EG, 2012, EMOTION, V12, P887, DOI 10.1037/a0027971
   Schön D, 2004, PSYCHOPHYSIOLOGY, V41, P341, DOI 10.1111/1469-8986.00172.x
   Schutte NS, 2001, J SOC PSYCHOL, V141, P523, DOI 10.1080/00224540109600569
   Sharda M, 2018, TRANSL PSYCHIAT, V8, DOI 10.1038/s41398-018-0287-3
   Stewart-Brown S, 2005, J PUBLIC MENT HEALTH, V4, P24, DOI 10.1108/17465729200500007
   Stoetzer U, 2009, J OCCUP HEALTH, V51, P144, DOI 10.1539/joh.L8134
   Swaminathan S, 2020, J EXP PSYCHOL LEARN, V46, P2340, DOI 10.1037/xlm0000798
   Szanto K, 2012, AM J GERIAT PSYCHIAT, V20, P257, DOI 10.1097/JGP.0b013e31820eea0c
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Tierney A, 2020, J EXP PSYCHOL LEARN, V46, P968, DOI 10.1037/xlm0000767
   Trimmer CG, 2008, EMOTION, V8, P838, DOI 10.1037/a0014080
   Wang YQ, 2019, CHILD INDIC RES, V12, P1369, DOI 10.1007/s12187-018-9590-z
   Weschler D., 1999, WESCHLER ABBREVIATED
   Zlotnick C, 2000, J AFFECT DISORDERS, V59, P205, DOI 10.1016/S0165-0327(99)00153-6
NR 54
TC 2
Z9 2
U1 4
U2 16
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0305-7356
EI 1741-3087
J9 PSYCHOL MUSIC
JI Psychol. Music
PD JUL
PY 2022
VL 50
IS 4
BP 1091
EP 1106
AR 03057356211030985
DI 10.1177/03057356211030985
EA AUG 2021
PG 16
WC Psychology, Educational; Psychology, Applied; Music; Psychology,
   Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Psychology; Music
GA 2M9JU
UT WOS:000684678800001
OA hybrid
DA 2024-01-09
ER

PT J
AU Almeida, A
   Li, WC
   Schubert, E
   Smith, J
   Wolfe, J
AF Almeida, Andre
   Li, Weicong
   Schubert, Emery
   Smith, John
   Wolfe, Joe
TI Expressive goals for performing musicians: The case of clarinetists
SO MUSICAE SCIENTIAE
LA English
DT Article
DE emotions; performance; musical elements; clarinet; playing parameters
ID BLOWING PRESSURE; EXTINCTION THRESHOLDS; VOCAL-TRACT; LIP FORCE; PITCH;
   COMMUNICATION; OSCILLATION; TRANSIENTS; ROLES; MODEL
AB Music can convey emotions. Even in the performance of written rather than improvised music, the performer can modify the way they play particular elements of the music to convey specific emotions. Considerable research attention has been paid to the ways in which performers convey a small set of so-called basic emotions. In the current work, we investigated how musicians think they can convey a larger set of emotions in their performances by modifying musical elements and varying playing parameters. We presented 12 clarinetists trained in Western classical music with 55 pairs of expressive goals (EGs) derived from a list of 11 (e.g., to make the music sound happy, sad, or expressive), and asked them to provide similarity judgments for each pair representing how well they thought they would be able to distinguish between them when performing four excerpts of music, and how they would do it. The similarity judgments produced dissimilarity scores that were grouped using cluster analysis to form six independent, coherent clusters of EGs. Four clusters consisted of, or included, EGs representing four basic emotions: happy/humorous; sad; angry/mad/ugly; and fearful. The other two clusters consisted of the EGs expressive/overly expressive/beautiful and deadpan. We therefore suggest that this set of six clusters could be used in future research on emotional and musical expression in music. Participants reported that to achieve specific EGs, they would vary the way they played a wider range of musical elements than in previous studies, albeit including many of the same elements. Among the playing parameters they reported, reed-bite force was mentioned most often, with consistent associations between more force and ugly or angry, and between less force and fearful and expressive EGs.
C1 [Almeida, Andre; Schubert, Emery; Smith, John; Wolfe, Joe] UNSW Sydney, Sydney, NSW 2052, Australia.
   [Li, Weicong] Univ Western Sydney, Penrith, NSW, Australia.
C3 University of New South Wales Sydney; Western Sydney University
RP Almeida, A (corresponding author), UNSW Sydney, Sydney, NSW 2052, Australia.
EM a.almeida@unsw.edu.au
RI Almeida, André/JRW-8466-2023
OI Li, Weicong/0000-0002-7423-2846
FU Australian Research Council [DP200100963]; Australian Research Council
   [DP200100963] Funding Source: Australian Research Council
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This work
   was supported by the Australian Research Council, grant DP200100963.
CR Almeida A, 2017, J ACOUST SOC AM, V142, P3376, DOI 10.1121/1.5014036
   Almeida A, 2013, J ACOUST SOC AM, V134, P2247, DOI 10.1121/1.4816538
   Averill J.R., 1982, ANGER AGGRESSION ESS, P185, DOI [10.1007/978-1-4612-5743-1_9, DOI 10.1007/978-1-4612-5743-1_9]
   BAK N, 1987, ACUSTICA, V63, P238
   Chen JM, 2009, J ACOUST SOC AM, V126, P1511, DOI 10.1121/1.3177269
   Dalmont JP, 2007, J ACOUST SOC AM, V122, P1173, DOI 10.1121/1.2747197
   Dalmont JP, 2005, J ACOUST SOC AM, V118, P3294, DOI 10.1121/1.2041207
   Dickens P, 2007, ACOUST AUST, V35, P17
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Gabrielsson A., 2010, HDB MUSIC EMOTION TH, P367, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0014
   Guillemain P, 2007, J ACOUST SOC AM, V121, P2396, DOI 10.1121/1.2642173
   Huron D, 2015, PHILOS T R SOC B, V370, P122, DOI 10.1098/rstb.2014.0098
   Juslin, 1997, PSYCHOMUSICOLOGY, V16, P77, DOI DOI 10.1037/H0094065
   Juslin P. N., 1996, PSYCHOL MUSIC, V24, P68, DOI [10.1177/0305735696241007, DOI 10.1177/0305735696241007]
   Juslin PN, 2001, MUSIC SCI, V5, P63, DOI 10.1177/10298649020050S104
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Juslin PN, 1997, MUSIC SCI, V1, P225, DOI DOI 10.1177/102986499700100205
   Kergomard J., 2000, ACTA ACUST UNITED AC, V86, P665
   Kreutz G, 2008, MUSIC PERCEPT, V26, P57, DOI 10.1525/MP.2008.26.1.57
   Li WC, 2016, J ACOUST SOC AM, V140, P1089, DOI 10.1121/1.4960594
   Li WC, 2016, J ACOUST SOC AM, V139, P825, DOI 10.1121/1.4941660
   Lulich SM, 2017, J ACOUST SOC AM, V141, P1759, DOI 10.1121/1.4978059
   Pàmies-Vilà M, 2020, J NEW MUSIC RES, V49, P126, DOI 10.1080/09298215.2019.1708412
   Pàmies-Vilà M, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00617
   Patel S, 2010, J VOICE, V24, P168, DOI 10.1016/j.jvoice.2008.08.002
   Sauchelli A, 2014, PHILOS PAP, V43, P377, DOI 10.1080/05568641.2014.976441
   Schubert E., 2014, Expressiveness in music performance: Empirical approaches across styles and cultures, P283
   Schubert E., 2022, OXFORD HDB MUSIC PER, V1, P273
   Schubert E, 2016, EMPIR MUSICOL REV, V11, P330
   Schubert E, 2017, J NEW MUSIC RES, V46, P175, DOI 10.1080/09298215.2016.1264976
   scikit-learn, AGGLOMERATIVECLUSTER
   SENJU M, 1987, MUSIC PERCEPT, V4, P311
   Stadthagen-González H, 2018, LINGUIST APPROACH BI, V8, P67, DOI 10.1075/lab.16030.sta
   Tarricone P, 2016, INT J EDUC TECHNOL H, V13, DOI 10.1186/s41239-016-0018-x
   THURSTONE LL, 1987, AM J PSYCHOL, V100, P587, DOI 10.2307/1422696
   Zhang JD, 2019, MUSIC PERCEPT, V36, P457, DOI 10.1525/MP.2019.36.5.457
NR 37
TC 0
Z9 0
U1 1
U2 2
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1029-8649
EI 2045-4147
J9 MUSIC SCI
JI Music Sci.
PD SEP
PY 2023
VL 27
IS 3
BP 655
EP 671
DI 10.1177/10298649221122155
EA SEP 2022
PG 17
WC Music; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music; Psychology
GA X3MB9
UT WOS:000858310200001
DA 2024-01-09
ER

PT J
AU Martel, K
   Caracci, C
   Le Normand, MT
AF Martel, Karine
   Caracci, Chantal
   Le Normand, Marie-Therese
TI Prosody at the interface of music and speech in infants and toddlers
SO ENFANCE
LA French
DT Article
DE PROSODY; MUSIC; SPEECH PERCEPTION; INFANT-DIRECTED SPEECH (IDS);
   INTONOSYNTAX
ID MATERNAL SPEECH; DIRECTED SPEECH; MOTHER-INFANT; LANGUAGE
   DISCRIMINATION; PITCH CHARACTERISTICS; INTONATION CONTOURS; VOCAL
   INTERACTIONS; NATIVE-LANGUAGE; ENGLISH; FRENCH
AB Music and speech signals are complex sounds, based on similar acoustic patterns like duration, intensity and pitch, which follow several levels of organization: morphology, phonology, semantics, syntax and pragmatics for speech; rhythm, melody, and harmony for music. One of the most salient components of music is melody, resulting from a set of variations in pitch - correlate of frequency in perception - as a piece unfolds. Similarly, for speech, one of the most prominent components is melody which, combined with tempo and timbre of the voice, forms a real musical partition. In this literature overview, the main question is to know to what extent these two systems of communication, speech and music, are based on common prosodic phenomena, shared or distinct in infants and toddlers whereas the baby perceives in the uterine environment and during its development. From the third trimester of pregnancy, the fetus is already able to perceive rhythms based on a very regular temporal organization similar to those of music. Next, speech perception in newborn infants is related to music cues like accents, rhythm, speech-rate and pauses. At the same time, infant directed speech helps them not only to develop the prosodic forms of their native babbling, first words and early grammar, but also to refine the pragmatic aspects of language expressing their emotions.
C1 [Martel, Karine] UPL, INSHEA, Grhapes EA Grp Rech Handicap Accessibilite Prat E, 58 Ave Landes, F-92150 Suresnes, France.
   [Caracci, Chantal] CAP Enfants, 1 Allee Barbanniers, F-92230 Gennevilliers, France.
   [Le Normand, Marie-Therese] Univ Paris, INSERM, 71 Ave Edouard Vaillant, F-92774 Boulogne, France.
   [Le Normand, Marie-Therese] Univ Paris, Lab Psychopathol & Proc Sante, 71 Ave Edouard Vaillant, F-92774 Boulogne, France.
C3 Institut National de la Sante et de la Recherche Medicale (Inserm);
   Universite Paris Cite; Universite Paris Cite
RP Le Normand, MT (corresponding author), Univ Paris, INSERM, 71 Ave Edouard Vaillant, F-92774 Boulogne, France.; Le Normand, MT (corresponding author), Univ Paris, Lab Psychopathol & Proc Sante, 71 Ave Edouard Vaillant, F-92774 Boulogne, France.
EM karine.martel@inshea.fr; chcaracci@capenfants.com;
   marie-therese.le-normand@u-paris.fr
RI LE NORMAND, Marie Thérèse/P-2026-2019
OI LE NORMAND, Marie Thérèse/0000-0002-6952-5150
CR Abboub N, 2016, BRAIN LANG, V162, P46, DOI 10.1016/j.bandl.2016.08.002
   [Anonymous], 2003, DEV SCI, DOI [10.1111/1467-7687.00273, DOI 10.1111/1467-7687.00273]
   [Anonymous], 1979, Before Speech: The Beginning of Interpersonal Communication
   [Anonymous], 1985, CHILDRENS LANGUAGE
   [Anonymous], 1977, STUDIES MOTHER INFAN
   [Anonymous], 2008, COMMUNICATIVE MUSICA
   [Anonymous], 2009, OXFORD HDB MUSIC PSY
   BATESON MC, 1975, ANN NY ACAD SCI, V263, P101, DOI 10.1111/j.1749-6632.1975.tb41575.x
   Beebe B, 2000, INFANT MENT HEALTH J, V21, P99, DOI 10.1002/(SICI)1097-0355(200001/04)21:1/2<99::AID-IMHJ11>3.0.CO;2-#
   Bosch L, 1997, COGNITION, V65, P33, DOI 10.1016/S0010-0277(97)00040-1
   BRUNDIN K, 1988, EARLY HUM DEV, V16, P35, DOI 10.1016/0378-3782(88)90085-0
   Burnham D, 2002, SCIENCE, V296, P1435, DOI 10.1126/science.1069587
   Carter A, 2004, J CHILD LANG, V31, P561, DOI 10.1017/S030500090400621X
   Cooper RP, 1997, INFANT BEHAV DEV, V20, P477, DOI 10.1016/S0163-6383(97)90037-0
   Cooper W. E., 1980, Syntax and speech
   Corbeil M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00372
   Crown CL, 2002, J PSYCHOLINGUIST RES, V31, P1, DOI 10.1023/A:1014301303616
   Davis BL, 2000, CHILD DEV, V71, P1258, DOI 10.1111/1467-8624.00227
   De Carvalho A, 2017, COGNITION, V163, P67, DOI 10.1016/j.cognition.2017.02.018
   DECASPER AJ, 1994, INFANT BEHAV DEV, V17, P159, DOI 10.1016/0163-6383(94)90051-5
   Delattre, 1961, P 4 INT C PHON SCI H, P407
   Delavenne A, 2013, INFANT BEHAV DEV, V36, P1, DOI 10.1016/j.infbeh.2012.10.004
   Demuth K., 1996, SIGNAL SYNTAX BOOTST, P313
   Demuth K., 2007, P 2 C GEN APPR LANG, P84
   Demuth K, 2006, LANG SPEECH, V49, P129, DOI 10.1177/00238309060490020101
   Demuth K, 2019, FIRST LANG, V39, P80, DOI 10.1177/0142723717751984
   Devouche, 2020, ENFANCE, V5, P67, DOI [10.3917/enf2.201.0067, DOI 10.3917/ENF2.201.0067]
   Estes KG, 2013, INFANCY, V18, P797, DOI 10.1111/infa.12006
   Fava E, 2014, CHILD NEUROPSYCHOL, V20, P430, DOI 10.1080/09297049.2013.803524
   Feldman R, 2007, J CHILD PSYCHOL PSYC, V48, P329, DOI 10.1111/j.1469-7610.2006.01701.x
   FELDSTEIN S, 1993, INFANT BEHAV DEV, V16, P455, DOI 10.1016/0163-6383(93)80004-R
   FERNALD A, 1987, INFANT BEHAV DEV, V10, P279, DOI 10.1016/0163-6383(87)90017-8
   FERNALD A, 1985, INFANT BEHAV DEV, V8, P181, DOI 10.1016/S0163-6383(85)80005-9
   FERNALD A, 1991, DEV PSYCHOL, V27, P209, DOI 10.1037/0012-1649.27.2.209
   FOGEL A, 1985, CHILD DEV, V56, P1271, DOI 10.1111/j.1467-8624.1985.tb00195.x
   FOGEL A, 1993, DEV RELATIONSHIPS CO
   Fogel A., 1993, NEW PERSPECTIVES EAR, P9, DOI DOI 10.4324/9781315111322-3
   GARNICA O. K., 1977, Talking to Children: Language Input and Acquisition, P63
   Gerry D, 2012, DEVELOPMENTAL SCI, V15, P398, DOI 10.1111/j.1467-7687.2012.01142.x
   Gervain J, 2010, ANNU REV PSYCHOL, V61, P191, DOI 10.1146/annurev.psych.093008.100408
   Gleitman L.R., 1982, Language acquisition: The state of the art, P3
   Granier-Deferre C, 2011, DEVELOPMENTAL SCI, V14, P336, DOI 10.1111/j.1467-7687.2010.00978.x
   Granier-Deferre C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017304
   Gratier M, 2003, COGNITIVE DEV, V18, P533, DOI 10.1016/j.cogdev.2003.09.009
   GRATIER M, 2007, INT J DIALOGICAL SCI, V2, P169
   Gratier M, 2015, FRONT PSYCHOL, V6, DOI [10.3389/fpgyg.2015.01167, 10.3389/fpsyg.2015.01167]
   Gratier M, 2012, ADV CULT PSYCHOL CON, P85
   Gratier M, 2011, DEV PSYCHOL, V47, P67, DOI 10.1037/a0020722
   HALLE PA, 1991, LANG SPEECH, V34, P299, DOI 10.1177/002383099103400401
   Henning A, 2005, INFANT BEHAV DEV, V28, P519, DOI 10.1016/j.infbeh.2005.06.001
   JUSCZYK PW, 1993, J EXP PSYCHOL HUMAN, V19, P627, DOI 10.1037/0096-1523.19.3.627
   KARZON RG, 1989, PERCEPT PSYCHOPHYS, V45, P10, DOI 10.3758/BF03208026
   Keller PE, 2008, EMERG COMMUN-STUD NE, V10, P205
   Kempe V, 2010, J MEM LANG, V62, P204, DOI 10.1016/j.jml.2009.11.006
   KENT RD, 1982, J ACOUST SOC AM, V72, P353, DOI 10.1121/1.388089
   Kinzler KD, 2007, P NATL ACAD SCI USA, V104, P12577, DOI 10.1073/pnas.0705345104
   Kisilevsky BS, 2009, INFANT BEHAV DEV, V32, P59, DOI 10.1016/j.infbeh.2008.10.002
   Kisilevsky BS, 2004, DEVELOPMENTAL SCI, V7, P550, DOI 10.1111/j.1467-7687.2004.00379.x
   Kisilevsky BS, 2003, PSYCHOL SCI, V14, P220, DOI 10.1111/1467-9280.02435
   Kitamura C, 2003, INFANCY, V4, P85, DOI 10.1207/S15327078IN0401_5
   Kitamura C, 2002, INFANT BEHAV DEV, V24, P372
   Konopczynski, 1986, B I PHONETIQUE GRENO, VXV, P157
   Konopczynski, 1990, LANGAGE EMERGENT
   Konopczynski G., 1991, LANGAGE EMERGENT
   Kotilahti K, 2010, HUM BRAIN MAPP, V31, P595, DOI 10.1002/hbm.20890
   Kraus N, 2012, ANN NY ACAD SCI, V1252, P100, DOI 10.1111/j.1749-6632.2012.06463.x
   Lecanuet, 2000, J PEDIAT PUERICULTUR, V13, P349, DOI [10.1016/S0987-7983(00)80071-7, DOI 10.1016/S0987-7983(00)80071-7]
   Lecanuet JP, 2000, DEV PSYCHOBIOL, V36, P29, DOI 10.1002/(SICI)1098-2302(200001)36:1<29::AID-DEV4>3.3.CO;2-A
   LECANUET JP, 1993, NATO ADV SCI INST SE, V69, P237
   Lee GY, 2014, DEV PSYCHOBIOL, V56, P1, DOI 10.1002/dev.21084
   LEVITT AG, 1991, LANG SPEECH, V34, P235, DOI 10.1177/002383099103400302
   LEVITT AG, 1992, J CHILD LANG, V19, P19, DOI 10.1017/S0305000900013611
   Lickliter R, 2017, DEV PSYCHOBIOL, V59, P910, DOI 10.1002/dev.21551
   Liu HM, 2009, J CHILD LANG, V36, P909, DOI 10.1017/S030500090800929X
   MASATAKA N, 1992, J CHILD LANG, V19, P213, DOI 10.1017/S0305000900011399
   May L, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00222
   McMullen E, 2004, MUSIC PERCEPT, V21, P289, DOI 10.1525/mp.2004.21.3.289
   McRoberts GW, 1997, J CHILD LANG, V24, P719, DOI 10.1017/S030500099700322X
   MOON C, 1993, INFANT BEHAV DEV, V16, P495, DOI 10.1016/0163-6383(93)80007-U
   Morgan J.L., 1986, SIMPLE INPUT COMPLEX
   MORGAN JL, 1981, J VERB LEARN VERB BE, V20, P67, DOI 10.1016/S0022-5371(81)90312-1
   Nakata T, 2004, INFANT BEHAV DEV, V27, P455, DOI 10.1016/j.infbeh.2004.03.002
   Nathani S, 2003, J CHILD LANG, V30, P3, DOI 10.1017/S0305000902005433
   Nawrot ES., 2003, Psychol. Music, V31, P75, DOI DOI 10.1177/0305735603031001325
   Nazzi T, 1998, J EXP PSYCHOL HUMAN, V24, P756, DOI 10.1037/0096-1523.24.3.756
   Nazzi T, 2000, J MEM LANG, V43, P1, DOI 10.1006/jmla.2000.2698
   NELSON DGK, 1989, J CHILD LANG, V16, P55, DOI 10.1017/S030500090001343X
   Papousek H, 1977, STUDIES MOTHER INFAN, P63
   PAPOUSEK M, 1991, INFANT BEHAV DEV, V14, P415, DOI 10.1016/0163-6383(91)90031-M
   Partanen E, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0078946
   Partanen E, 2013, P NATL ACAD SCI USA, V110, P15145, DOI 10.1073/pnas.1302159110
   Patel AD, 2010, MUSIC LANGUAGE BRAIN
   Perani D, 2010, P NATL ACAD SCI USA, V107, P4758, DOI 10.1073/pnas.0909074107
   Plantinga J, 2005, COGNITION, V98, P1, DOI 10.1016/j.cognition.2004.09.008
   Ramus F., 2002, Annual Review of Language Acquisition, V2, P85
   Rochat P, 1999, DEV PSYCHOL, V35, P950, DOI 10.1037/0012-1649.35.4.950
   Scola C, 2015, SOCIOAFFECTIVE NEURO, V5, DOI 10.3402/snp.v5.28256
   Self P., 1982, INT C INF STUD AUST
   Shenfield T., 2003, Psychol. Music, V31, P365, DOI DOI 10.1177/03057356030314002
   Shukla M, 2007, COGNITIVE PSYCHOL, V54, P1, DOI 10.1016/j.cogpsych.2006.04.002
   Smith NA, 2008, INFANCY, V13, P410, DOI 10.1080/15250000802188719
   Snow C. E., 1994, Input and interaction in language acquisition, P3, DOI [10.1017/CBO9780511620690.002, DOI 10.1017/CBO9780511620690.002]
   Snow D, 1998, J SPEECH LANG HEAR R, V41, P576, DOI 10.1044/jslhr.4103.576
   Snow D, 2006, CHILD DEV, V77, P281, DOI 10.1111/j.1467-8624.2006.00870.x
   Snow D, 2002, INFANT BEHAV DEV, V24, P393
   Song JY, 2010, J ACOUST SOC AM, V128, P389, DOI 10.1121/1.3419786
   Spinelli M, 2017, DEV REV, V44, P1, DOI 10.1016/j.dr.2016.12.001
   Stern D. N., 1974, The effect of the infant on its caregiver
   STERN DN, 1975, ANN NY ACAD SCI, V263, P89, DOI 10.1111/j.1749-6632.1975.tb41574.x
   STERN DN, 1982, DEV PSYCHOL, V18, P727
   STERN DN, 1983, J CHILD LANG, V10, P1, DOI 10.1017/S0305000900005092
   Trainor LJ, 2002, PSYCHON B REV, V9, P335, DOI 10.3758/BF03196290
   TREHUB S E, 1990, International Journal of Comparative Psychology, V4, P91
   Trehub S. E., 2020, ROUTLEDGE COMPANION, V1, P249, DOI [10.4324/9781315163734-19, DOI 10.4324/9781315163734-19]
   Trehub SE, 2003, NAT NEUROSCI, V6, P669, DOI 10.1038/nn1084
   Trehub SE, 2001, ANN NY ACAD SCI, V930, P1
   TREHUB SE, 1995, J ACOUST SOC AM, V98, P2532, DOI 10.1121/1.414396
   TREHUB SE, 1993, INFANT BEHAV DEV, V16, P193, DOI 10.1016/0163-6383(93)80017-3
   Trevarthen C., 2003, DEV DENT, V15, P309, DOI [10.3917/dev.034.0309, DOI 10.3917/DEV.034.0309]
   Trevarthen C., 1999, Musicae Scientiae, V3, P155, DOI [10.1177/10298649000030S109, DOI 10.1177/10298649000030S109]
   Trevarthen C., 1977, Studiesin mother-infantinteraction, P227
   TRONICK EZ, 1989, AM PSYCHOL, V44, P112, DOI 10.1037/0003-066X.44.2.112
   Tsang CD, 2017, CHILD DEV, V88, P1207, DOI 10.1111/cdev.12647
   Vihman M.M., 1988, EMERGENT LEXICON CHI, P151
   Vihman M. M., 2019, PHONOLOGICAL TEMPLAT, P93, DOI [10.1093/oso/9780198793564.003.0004, DOI 10.1093/OSO/9780198793564.003.0004]
   Vihman M.M., 1996, PHONOLOGICAL DEV ORI
   Vosoughi S, 2012, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON SPEECH PROSODY, VOLS I AND II, P194
   WEINBERG MK, 1994, CHILD DEV, V65, P1503, DOI 10.2307/1131514
   WERKER JF, 1989, CAN J PSYCHOL, V43, P230, DOI 10.1037/h0084224
   Whalen, 2006, LAB PHONOLOGY, P341
   WHALEN DH, 1991, J CHILD LANG, V18, P501, DOI 10.1017/S0305000900011223
   Winkler I, 2009, P NATL ACAD SCI USA, V106, P2468, DOI 10.1073/pnas.0809035106
   Zhao TC, 2016, P NATL ACAD SCI USA, V113, P5212, DOI 10.1073/pnas.1603984113
NR 133
TC 0
Z9 0
U1 2
U2 9
PU PRESSES UNIV FRANCE
PI PARIS CEDEX 14
PA 6 AVENUE REILLE, 75685 PARIS CEDEX 14, FRANCE
SN 0013-7545
EI 1969-6981
J9 ENFANCE
JI Enfance
PY 2020
IS 4
BP 451
EP 473
PG 23
WC Psychology, Developmental
WE Emerging Sources Citation Index (ESCI)
SC Psychology
GA PR9WF
UT WOS:000607580200001
DA 2024-01-09
ER

PT J
AU Liu, XL
   Xu, Y
   Alter, K
   Tuomainen, J
AF Liu, Xiaoluan
   Xu, Yi
   Alter, Kai
   Tuomainen, Jyrki
TI Emotional Connotations of Musical Instrument Timbre in Comparison With
   Emotional Speech Prosody: Evidence From Acoustics and Event-Related
   Potentials
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE musical timbre; emotional speech prosody; emotion; ERP; N400
ID VOCAL EXPRESSION; SOUNDS; PERCEPTION; DYNAMICS; ERP
AB Music and speech both communicate emotional meanings in addition to their domain-specific contents. But it is not clear whether and how the two kinds of emotional meanings are linked. The present study is focused on exploring the emotional connotations of musical timbre of isolated instrument sounds through the perspective of emotional speech prosody. The stimuli were isolated instrument sounds and emotional speech prosody categorized by listeners into anger, happiness and sadness, respectively. We first analyzed the timbral features of the stimuli, which showed that relations between the three emotions were relatively consistent in those features for speech and music. The results further echo the size-code hypothesis in which different sound timbre indicates different body size projections. Then we conducted an ERP experiment using a priming paradigm with isolated instrument sounds as primes and emotional speech prosody as targets. The results showed that emotionally incongruent instrument-speech pairs triggered a larger N400 response than emotionally congruent pairs. Taken together, this is the first study to provide evidence that the timbre of simple and isolated musical instrument sounds can convey emotion in a way similar to emotional speech prosody.
C1 [Liu, Xiaoluan; Xu, Yi; Tuomainen, Jyrki] UCL, Dept Speech Hearing & Phonet Sci, London, England.
   [Alter, Kai] Univ Oxford, Fac Linguist Philol & Phonet, Oxford, England.
   [Alter, Kai] Newcastle Univ, Inst Neurosci, Newcastle Upon Tyne, Tyne & Wear, England.
C3 University of London; University College London; University of Oxford;
   Newcastle University - UK
RP Liu, XL; Xu, Y (corresponding author), UCL, Dept Speech Hearing & Phonet Sci, London, England.
EM LXL0803@outlook.com; yi.xu@ucl.ac.uk
RI Xu, Yi/M-9738-2019; Xu, Yi/C-4013-2008
OI Xu, Yi/0000-0002-8541-2658; Xu, Yi/0000-0002-8541-2658; Alter,
   Kai/0000-0003-4575-9494
CR Alluri V, 2010, MUSIC PERCEPT, V27, P223, DOI 10.1525/mp.2010.27.3.223
   [Anonymous], 2001, MUSIC EMOTION THEORY
   [Anonymous], 1987, CONTEMP MUSIC REV, DOI DOI 10.1080/07494468708567057
   Askenfelt A., 1991, P INT S WENN GREN CT, V59, P243
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Bostanov V, 2004, PSYCHOPHYSIOLOGY, V41, P259, DOI 10.1111/j.1469-8986.2003.00142.x
   Buck R., 1984, COMMUNICATION EMOTIO
   Christmann CA, 2014, NEUROSCI LETT, V581, P115, DOI 10.1016/j.neulet.2014.08.035
   Cummings A, 2006, BRAIN RES, V1115, P92, DOI 10.1016/j.brainres.2006.07.050
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Eerola T, 2013, MUSIC PERCEPT, V30, P307, DOI [10.1525/mp.2012.30.3.307, 10.1525/MP.2012.30.1.49]
   Fitch WT, 2002, ANIM BEHAV, V63, P407, DOI 10.1006/anbe.2001.1912
   Frey A, 2014, BRAIN COGNITION, V84, P141, DOI 10.1016/j.bandc.2013.11.013
   Giordano BL, 2010, MUSIC PERCEPT, V28, P155, DOI 10.1525/mp.2010.28.2.155
   Gobl C, 2003, SPEECH COMMUN, V40, P189, DOI 10.1016/S0167-6393(02)00082-1
   Goerlich KS, 2012, J COGNITIVE NEUROSCI, V24, P1725, DOI 10.1162/jocn_a_00213
   Goudbeek M, 2010, J ACOUST SOC AM, V128, P1322, DOI 10.1121/1.3466853
   Goydke KN, 2004, COGNITIVE BRAIN RES, V21, P351, DOI 10.1016/j.cogbrainres.2004.06.009
   Griffiths TD, 2004, NAT REV NEUROSCI, V5, P887, DOI 10.1038/nrn1538
   Holmes P, 2012, PSYCHOL MUSIC, V40, P301, DOI 10.1177/0305735610388898
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Klauer KC, 2003, PSYCHOLOGY OF EVALUATION, P7
   Koelsch S, 2005, TRENDS COGN SCI, V9, P578, DOI 10.1016/j.tics.2005.10.001
   Krumhansl CL, 2010, MUSIC PERCEPT, V27, P337, DOI 10.1525/mp.2010.27.5.337
   Lartillot O., 2014, MIRTOOLBOX USERS GUI
   Levy DA, 2003, PSYCHOPHYSIOLOGY, V40, P291, DOI 10.1111/1469-8986.00031
   Lopez-Calderon J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00213
   Menon V, 2002, NEUROIMAGE, V17, P1742, DOI 10.1006/nimg.2002.1295
   Meyer M, 2006, NEUROIMAGE, V32, P1510, DOI 10.1016/j.neuroimage.2006.04.193
   MORTON ES, 1977, AM NAT, V111, P855, DOI 10.1086/283219
   OHALA JJ, 1984, PHONETICA, V41, P1, DOI 10.1159/000261706
   Olson H. F., 2003, MUSIC PHYS ENG
   Opolko F., 2006, The McGill University Master Samples Collection on DVD
   Painter JG, 2011, PSYCHOPHYSIOLOGY, V48, P645, DOI 10.1111/j.1469-8986.2010.01134.x
   Panksepp J, 2005, CONSCIOUS COGN, V14, P30, DOI 10.1016/j.concog.2004.10.004
   Paulmann S, 2010, COGN AFFECT BEHAV NE, V10, P230, DOI 10.3758/CABN.10.2.230
   Pell MD, 2005, J NONVERBAL BEHAV, V29, P45, DOI 10.1007/s10919-004-0889-8
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   Scherer K., 1977, MOTIV EMOTION, V1, P331, DOI [DOI 10.1007/BF00992539, 10.1007/bf00992539]
   SCHERER KR, 1979, EMOTIONS PERSONALITY, P495
   Schutz M, 2008, EMPIR MUSICOL REV, V3, P126, DOI 10.18061/1811/34103
   Spreckelmeyer KN, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00656
   Steinbeis N, 2011, J COGNITIVE NEUROSCI, V23, P604, DOI 10.1162/jocn.2009.21383
   Stevens K., 1998, Acoustic phonetics
   TREHUB SE, 1990, J EXP CHILD PSYCHOL, V49, P300, DOI 10.1016/0022-0965(90)90060-L
   Xu Y., 2013, PROSODY ICONICITY, P33, DOI DOI 10.1075/ILL.13.02XU
   Xu YL, 2013, PROCEEDINGS 2013 INTERNATIONAL CONFERENCE ON MECHATRONIC SCIENCES, ELECTRIC ENGINEERING AND COMPUTER (MEC), P10, DOI 10.1109/MEC.2013.6885042
NR 48
TC 6
Z9 7
U1 2
U2 24
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD MAY 15
PY 2018
VL 9
AR 737
DI 10.3389/fpsyg.2018.00737
PG 10
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA GG3FR
UT WOS:000432578200001
PM 29867690
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Hämäläinen, S
   Musial, F
   Salamonsen, A
   Graff, O
   Olsen, TA
AF Hamalainen, Soile
   Musial, Frauke
   Salamonsen, Anita
   Graff, Ola
   Olsen, Torjer A.
TI Sami yoik, Sami history, Sami health: a narrative review
SO INTERNATIONAL JOURNAL OF CIRCUMPOLAR HEALTH
LA English
DT Review
DE Sami; yoik; music & health; indigenous singing; emotion regulation
ID EMOTION REGULATION; RESILIENCE FACTORS; ALLOSTATIC LOAD; NORTHERN
   NORWAY; POPULATIONS; DISEASE; STRESS; MUSIC; MECHANISMS; DISORDERS
AB Music as a possible health-promoting agent has attained increasing academic and scientific interest over the last decades. Nonetheless, possible connections between indigenous singing traditions and health beyond traditional ceremonial healing practices are still under-researched worldwide.
   The Sami, the indigenous people living in Northern Fennoscandia, have a distinct ancient vocal music tradition called "yoik" practiced from immemorial times. The Sami share a history of assimilation with many indigenous people. During this period of nearly 400 years, yoik alongside other cultural markers was under hard pressure and even banned at times.
   Compared to other indigenous people in the Arctic, Sami public health shows few significant unfavourable differences to the majority population. The potential role of yoik as a protective health and resilience factor within the Sami culture is the topic of this review. We suggest a two stage model for the health promoting effects of yoik through i) emotion regulation and stress relief on the level of the individual, and ii) as a socio-cultural resilience factors within the Sami population. This review is to be understood as theory-building review article striving for a scholarly review of the literature.
C1 [Hamalainen, Soile; Musial, Frauke] UiT Arctic Univ Norway, Dept Community Med, Natl Res Ctr Complementary & Alternat Med, Fac Hlth Sci, Tromso, Norway.
   [Salamonsen, Anita] UiT Arctic Univ Norway, RKBU North Reg Ctr Child & Youth Mental Hlth & Ch, Fac Hlth Sci, Tromso, Norway.
   [Graff, Ola] UiT Arctic Univ Norway, Univ Museum Tromso, Dept Cultural Sci, Tromso, Norway.
   [Olsen, Torjer A.] UiT Arctic Univ Norway, Ctr Sami Studies SESAM, Fac Humanities Social Sci & Educ, Tromso, Norway.
C3 UiT The Arctic University of Tromso; UiT The Arctic University of
   Tromso; UiT The Arctic University of Tromso; UiT The Arctic University
   of Tromso
RP Hämäläinen, S (corresponding author), UiT Norges Arktiske Univ, NAFKAM, Postboks 6050 Langnes, N-9037 Tromso, Norway.
EM soile.hamalainen@uit.no
OI Olsen, Torjer/0000-0002-7571-4652
FU UiT Norges arktiske universitet [551011]
FX This work was supported by the UiT Norges arktiske universitet [551011].
CR AMTA, 2018, WHAT IS MUS THER
   Anderson I, 2016, LANCET, V388, P131, DOI 10.1016/S0140-6736(16)00345-7
   [Anonymous], 2010, Handbook of Music and Emotion
   [Anonymous], 2002, SAMENE NORDKALOTTENS
   [Anonymous], END DRUM TIME RELIG
   [Anonymous], 2013, COCHRANE DATABASE SY
   [Anonymous], 2014, PSYCHOL HLTH EFFECTS
   Antonovsky A., 1987, Unraveling the mystery of health: how people manage stress and stay well
   Bad Hand HP, 2002, NATIVE AM HEALING
   Bals M, 2011, INT J CIRCUMPOL HEAL, V70, P37, DOI 10.3402/ijch.v70i1.17790
   Barnish J, 2016, J PARKINSON DIS, V6, P473, DOI 10.3233/JPD-160837
   Bassett Deborah, 2012, Perm J, V16, P19
   Berg S, 1926, FINNEMISJONEN ELLER
   Bjorklund Ivar, 1985, FiordPeoplein Kvaenagen
   Breedlove S. M., 2007, BIOL PSYCHOL INTRO B
   Buljo KA, 1998, TROLLSTILT LAEREBOK, P137
   Choi K, 2011, MIND BODY MED, P70
   Clift SM, 2001, J R SOC PROMO HEALTH, V121, P248, DOI 10.1177/146642400112100409
   Crawford O'Brien S, 2008, RELIG HEALING NATIVE
   Daling G., 2014, SLIK VI SER MUSIKK M, P158
   Edstrom O., 2003, STUD MUSICOL, V44, P269
   Eidheim H, 1977, ASPECTS LAPPISH MINO
   Eliassen BM, 2013, BMC PUBLIC HEALTH, V13, DOI 10.1186/1471-2458-13-522
   Eliassen BM, 2012, BMC PUBLIC HEALTH, V12, DOI 10.1186/1471-2458-12-948
   Eriksen AMA, 2015, SCAND J PUBLIC HEALT, V43, P588, DOI 10.1177/1403494815585936
   Eriksen Knut Einar., 1981, FINSKE FARE SIKKERHE
   Forsdahl A, 2001, ISM SKRIFTSERIE, V58:ISBN : 8290262655
   Fossion P, 2014, J PSYCHOL, V148, P641, DOI 10.1080/00223980.2013.819793
   Gaski H, 1994, NORDNORSK KULTURHIST, P403
   Graff O., 2004, KJAERESTEN MIN VIL J
   Graff O., 2016, JOIKEFORBUDET KAUTOK
   Grenersen G., 2002, VED FORSKNINGENS GRE
   Hämäläinen S, 2017, INT J CIRCUMPOL HEAL, V76, DOI 10.1080/22423982.2016.1271590
   Hansen KL, 2008, INT J CIRCUMPOL HEAL, V67, P97
   Hansen KL, 2015, INT J CIRCUMPOL HEAL, V74, DOI 10.3402/ijch.v74.25125
   Hanssen I., 2011, J INTERCULTURAL COMM, V27
   Hanssen I, 2013, SCAND J CARING SCI, V27, P231, DOI 10.1111/j.1471-6712.2012.01021.x
   Hauser M., 1992, TRADITIONAL GREENLAN
   Henry J P, 1977, Prog Brain Res, V47, P263
   HENRY JP, 1986, J HYPERTENS, V4, P687, DOI 10.1097/00004872-198612000-00002
   HENRY JP, 1986, POSTGRAD MED J, V62, P687, DOI 10.1136/pgmj.62.729.687
   Hilder TR, 2015, SAMI MUSICAL PERFORM
   Hou JC, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00501
   Jones-Bamman RW, 1993, LONG WE CONTINUE JOI
   Kamioka H, 2014, PATIENT PREFER ADHER, V8, P727, DOI 10.2147/PPA.S61340
   Karlamangla AS, 2002, J CLIN EPIDEMIOL, V55, P696, DOI 10.1016/S0895-4356(02)00399-2
   Kvamme TS, 2013, GLIMT GLEDE MUSIKKTE
   Linnemann A, 2015, PSYCHONEUROENDOCRINO, V60, P82, DOI 10.1016/j.psyneuen.2015.06.008
   MacDonald RAR, 2013, INT J QUAL STUD HEAL, V8, DOI 10.3402/qhw.v8i0.20635
   McEwen BS, 2003, BIOL PSYCHIAT, V54, P200, DOI 10.1016/S0006-3223(03)00177-X
   MCEWEN BS, 1993, ARCH INTERN MED, V153, P2093, DOI 10.1001/archinte.1993.00410180039004
   Minde G-T, 2013, INT J CIRCUMPOL HEAL, V72, P1
   Minde H., 2005, ASSIMILATION SAMI IM, V3
   Moore KS, 2013, J MUSIC THER, V50, P198, DOI 10.1093/jmt/50.3.198
   Myrseth, 1956, TIDSSKRIFT NORSKE LA, V76, P867
   Myskja A, 2012, INTEGRATED MUSIC NUR
   Naseribafrouei A, 2016, INT J CIRCUMPOL HEAL, V75, DOI 10.3402/ijch.v75.31697
   Novotney, 2013, AM PSYCHOL ASS, V44, P46, DOI [10.1037/e634362013-021, DOI 10.1037/E634362013-021]
   Nystad K, 2014, TRANSCULT PSYCHIATRY, V51, P651, DOI 10.1177/1363461514532511
   Pedersen P, 2012, Sapmi slar tilbake. Samiske revitalisering- og moderniseringsprosesser i siste generasjon [Sapmi hits back. Sami revitalizing and modernization processes in the last generation]
   Pedersen S, 2001, BEREDSKAPSDEPARTEMEN, V34
   Pettersen T, 2015, ETHNIC RACIAL STUD, V38, P2071, DOI 10.1080/01419870.2015.1031262
   Pettersen T, 2013, INT J CIRCUMPOL HEAL, V72, P1, DOI 10.3402/ijch.v72i0.21813
   REIN K, 1956, Tidsskr Nor Laegeforen, V76, P815
   Saastamoinen I, 2007, SON VUAINN SHE SEES
   Sara BR, 2015, SPEECH TRADITIONAL Y
   Särkämö T, 2014, GERONTOLOGIST, V54, P634, DOI 10.1093/geront/gnt100
   Sjölander P, 2011, GLOBAL HEALTH ACTION, V4, DOI 10.3402/gha.v4i0.8457
   Sjostrom N, 1991, INDIGENOUS PEOPLES I
   Stoor Petter, 2016, KUNSKAPSSAMMANSTALLN
   Szomjas-Schiffert G., 1973, YB INT FOLK MUSIC CO, V5, P51
   Ted Gioia, 2006, HEALING SONGS
   Thoma MV, 2012, COGNITION EMOTION, V26, P550, DOI 10.1080/02699931.2011.595390
   Wan CY, 2010, MUSIC PERCEPT, V27, P287, DOI 10.1525/MP.2010.27.4.287
   Wersland EM, 2006, JOIK GAMLE SAMISKE R
NR 75
TC 6
Z9 6
U1 1
U2 17
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1239-9736
EI 2242-3982
J9 INT J CIRCUMPOL HEAL
JI Int. J. Circumpolar Health
PD MAR 26
PY 2018
VL 77
IS 1
AR 1454784
DI 10.1080/22423982.2018.1454784
PG 8
WC Public, Environmental & Occupational Health
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Public, Environmental & Occupational Health
GA GA9RA
UT WOS:000428677300001
PM 29580190
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Pinheiro, AP
   Vasconcelos, M
   Dias, M
   Arrais, N
   Gonçalves, OF
AF Pinheiro, Ana P.
   Vasconcelos, Margarida
   Dias, Marcelo
   Arrais, Nuno
   Goncalves, Oscar F.
TI The music of language: An ERP investigation of the effects of musical
   training on emotional prosody processing
SO BRAIN AND LANGUAGE
LA English
DT Article
DE Event-related potentials; Emotional prosody; Language; Musical training
ID AUDITORY-CORTEX; SELECTIVE-ATTENTION; VOCAL EXPRESSIONS; NEURAL
   RESPONSES; SPEECH PROSODY; HESCHLS GYRUS; EVOKED FIELDS; BRAIN;
   ACTIVATION; EXPERIENCE
AB Recent studies have demonstrated the positive effects of musical training on the perception of vocally expressed emotion. This study investigated the effects of musical training on event-related potential (ERP) correlates of emotional prosody processing.
   Fourteen musicians and fourteen control subjects listened to 228 sentences with neutral semantic content, differing in prosody (one third with neutral, one third with happy and one third with angry intonation), with intelligible semantic content (semantic content condition - SCC) and unintelligible semantic content (pure prosody condition - PPC).
   Reduced P50 amplitude was found in musicians. A difference between SCC and PPC conditions was found in P50 and N100 amplitude in non-musicians only, and in P200 amplitude in musicians only. Furthermore, musicians were more accurate in recognizing angry prosody in PPC sentences.
   These findings suggest that auditory expertise characterizing extensive musical training may impact different stages of vocal emotional processing. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Pinheiro, Ana P.; Vasconcelos, Margarida; Dias, Marcelo; Goncalves, Oscar F.] Univ Minho, Sch Psychol, CIPsi, Neuropsychophysiol Lab, P-4710057 Braga, Portugal.
   [Pinheiro, Ana P.] Harvard Univ, Sch Med, Dept Psychiat, Cognit Neurosci Lab, Boston, MA 02115 USA.
   [Arrais, Nuno] Univ Minho, Inst Arts & Human Sci, Music Dept, P-4710057 Braga, Portugal.
   [Goncalves, Oscar F.] Harvard Univ, Spaulding Rehabil Hosp, Spaulding Ctr Neuromodulat, Dept Phys Med & Rehabil, Boston, MA 02115 USA.
   [Goncalves, Oscar F.] Harvard Univ, Massachusetts Gen Hosp, Sch Med, Boston, MA 02115 USA.
C3 Universidade do Minho; Harvard University; Harvard Medical School;
   Universidade do Minho; Harvard University; Spaulding Rehabilitation
   Hospital; Harvard University; Harvard Medical School; Massachusetts
   General Hospital
RP Pinheiro, AP (corresponding author), Univ Minho, Sch Psychol, CIPsi, Neuropsychophysiol Lab, Campus Gualtar, P-4710057 Braga, Portugal.
EM ana.pinheiro@psi.uminho.pt
RI Gonçalves, Óscar F./G-5278-2010
OI Gonçalves, Óscar F./0000-0003-2735-9155; Vasconcelos,
   Margarida/0000-0001-5544-4643; Pinheiro, Ana/0000-0002-7981-3682; Dias,
   Marcelo/0000-0003-1844-8631
FU Fundacao para a Ciencia e a Tecnologia (FCT, Portugal) [IF/00334/2012,
   PTDC/PSI-PCL/116626/2010, PTDC/MHN-PCN/3606/2012]; FEDER (Fundo Europeu
   de Desenvolvimento Regional) through the European programs QREN (Quadro
   de Referenda Estrategico Nacional); COMPETE (Programa Operacional
   Factores de Competitividade)
FX This work was supported by Grants IF/00334/2012,
   PTDC/PSI-PCL/116626/2010 and PTDC/MHN-PCN/3606/2012 funded by Fundacao
   para a Ciencia e a Tecnologia (FCT, Portugal) and FEDER (Fundo Europeu
   de Desenvolvimento Regional) through the European programs QREN (Quadro
   de Referenda Estrategico Nacional), and COMPETE (Programa Operacional
   Factores de Competitividade), awarded to A.P.P.
CR American Psychiatric Association, 2013, DIAGNOSTIC STAT MANU, V5th edn., DOI [10.1176/appi.books.9780890425596, DOI 10.1176/APPI.BOOKS.9780890425596]
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Belin P, 2011, BRIT J PSYCHOL, V102, P711, DOI 10.1111/j.2044-8295.2011.02041.x
   Besson M, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00094
   Bestelmeyer PEG, 2014, J NEUROSCI, V34, P8098, DOI 10.1523/JNEUROSCI.4820-13.2014
   Bhatara A, 2011, J EXP PSYCHOL HUMAN, V37, P921, DOI 10.1037/a0021922
   Bidelman GM, 2011, J COGNITIVE NEUROSCI, V23, P425, DOI 10.1162/jocn.2009.21362
   Boersma P., 2006, Praat: doing phonetics by computer
   Boutros NN, 2004, PSYCHIAT RES, V126, P203, DOI 10.1016/j.psychres.2004.01.007
   Brandt A, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00327
   Brochard R, 2004, BRAIN COGNITION, V54, P103, DOI 10.1016/S0278-2626(03)00264-1
   Brück C, 2011, NEUROIMAGE, V58, P259, DOI 10.1016/j.neuroimage.2011.06.005
   Buchanan TW, 2000, COGNITIVE BRAIN RES, V9, P227, DOI 10.1016/S0926-6410(99)00060-9
   Chandrasekaran B, 2009, BRAIN LANG, V108, P1, DOI 10.1016/j.bandl.2008.02.001
   Chen C, 1997, PSYCHIAT CLIN NEUROS, V51, P139, DOI 10.1111/j.1440-1819.1997.tb02376.x
   Coutinho E, 2013, COGNITION EMOTION, V27, P658, DOI 10.1080/02699931.2012.732559
   Davis MH, 2007, HEARING RES, V229, P132, DOI 10.1016/j.heares.2007.01.014
   Dietrich S, 2006, PROG BRAIN RES, V156, P295, DOI 10.1016/S0079-6123(06)56016-9
   Dutoit T, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1393, DOI 10.1109/ICSLP.1996.607874
   Escoffier N, 2013, HUM BRAIN MAPP, V34, P1796, DOI 10.1002/hbm.22029
   Ethofer T, 2006, NEUROIMAGE, V30, P580, DOI 10.1016/j.neuroimage.2005.09.059
   Frühholz S, 2012, CEREB CORTEX, V22, P1107, DOI 10.1093/cercor/bhr184
   Fujioka T, 2006, BRAIN, V129, P2593, DOI 10.1093/brain/awl247
   Gandour J, 2003, HUM BRAIN MAPP, V18, P149, DOI 10.1002/hbm.10088
   Globerson E, 2013, ATTEN PERCEPT PSYCHO, V75, P1799, DOI 10.3758/s13414-013-0518-x
   Godey B, 2001, CLIN NEUROPHYSIOL, V112, P1850, DOI 10.1016/S1388-2457(01)00636-8
   Gordon E., 1989, Advanced measures of music audiation
   Grandjean D, 2005, NAT NEUROSCI, V8, P145, DOI 10.1038/nn1392
   Haenschel C, 2005, J NEUROSCI, V25, P10494, DOI 10.1523/JNEUROSCI.1227-05.2005
   Hart HC, 2003, HEARING RES, V179, P104, DOI 10.1016/S0378-5955(03)00100-X
   Hausen M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00566
   HILLYARD SA, 1973, SCIENCE, V182, P177, DOI 10.1126/science.182.4108.177
   Hoenig K, 2011, NEUROIMAGE, V56, P1714, DOI 10.1016/j.neuroimage.2011.02.065
   Hornak J, 1996, NEUROPSYCHOLOGIA, V34, P247, DOI 10.1016/0028-3932(95)00106-9
   Huron D, 2008, NATURE, V453, P456, DOI 10.1038/453456a
   JERGER K, 1992, BIOL PSYCHIAT, V31, P365, DOI 10.1016/0006-3223(92)90230-W
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Koelsch S, 1999, NEUROREPORT, V10, P1309, DOI 10.1097/00001756-199904260-00029
   Koelsch S, 2002, NEUROIMAGE, V17, P956, DOI 10.1016/S1053-8119(02)91154-7
   Kotz SA, 2003, BRAIN LANG, V86, P366, DOI 10.1016/S0093-934X(02)00532-1
   Kotz SA, 2007, BRAIN RES, V1151, P107, DOI 10.1016/j.brainres.2007.03.015
   Kotz SA, 2006, PROG BRAIN RES, V156, P285, DOI 10.1016/S0079-6123(06)56015-7
   Kotz SA, 2011, LANG LINGUIST COMPAS, V5, P108, DOI 10.1111/j.1749-818x.2010.00267.x
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Kühnis J, 2013, NEUROPSYCHOLOGIA, V51, P1608, DOI 10.1016/j.neuropsychologia.2013.04.007
   Kuhnis J., 2014, J COGNITIVE NEUROSCI
   Lattner S, 2003, HUM BRAIN MAPP, V20, P13, DOI 10.1002/hbm.10118
   Lebib R, 2003, NEUROSCI LETT, V341, P185, DOI 10.1016/S0304-3940(03)00131-9
   Leitman DI, 2011, FRONT HUM NEUROSCI, V5, DOI [10.3389/fnhum.2011.00096, 10.3389/fnhum.2010.00019]
   Leitman DI, 2011, BIOL PSYCHIAT, V70, P611, DOI 10.1016/j.biopsych.2011.05.032
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Liu TS, 2012, NEUROREPORT, V23, P108, DOI 10.1097/WNR.0b013e32834ea757
   Magne C, 2006, J COGNITIVE NEUROSCI, V18, P199, DOI 10.1162/089892906775783660
   Marie C, 2011, J COGNITIVE NEUROSCI, V23, P2701, DOI 10.1162/jocn.2010.21585
   Marinkovic K, 2003, NEURON, V38, P487, DOI 10.1016/S0896-6273(03)00197-1
   Marques C, 2007, J COGNITIVE NEUROSCI, V19, P1453, DOI 10.1162/jocn.2007.19.9.1453
   Mitchell RLC, 2003, NEUROPSYCHOLOGIA, V41, P1410, DOI 10.1016/S0028-3932(03)00017-4
   Moreno S, 2009, CEREB CORTEX, V19, P712, DOI 10.1093/cercor/bhn120
   Morris JS, 1999, NEUROPSYCHOLOGIA, V37, P1155, DOI 10.1016/S0028-3932(99)00015-9
   Münte TF, 2002, NAT REV NEUROSCI, V3, P473, DOI 10.1038/nrn843
   MURRAY IR, 1993, J ACOUST SOC AM, V93, P1097, DOI 10.1121/1.405558
   NAATANEN R, 1978, ACTA PSYCHOL, V42, P313, DOI 10.1016/0001-6918(78)90006-9
   NAATANEN R, 1990, BEHAV BRAIN SCI, V13, P201, DOI 10.1017/S0140525X00078407
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Ninomiya H, 2000, PSYCHIAT CLIN NEUROS, V54, P493, DOI 10.1046/j.1440-1819.2000.00741.x
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Ott CGM, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00195
   Pantev C, 1998, NATURE, V392, P811, DOI 10.1038/33918
   Parbery-Clark A, 2009, J NEUROSCI, V29, P14100, DOI 10.1523/JNEUROSCI.3256-09.2009
   Patel AD, 2007, TRENDS COGN SCI, V11, P369, DOI 10.1016/j.tics.2007.08.003
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Paulmann S, 2008, NEUROREPORT, V19, P209, DOI 10.1097/WNR.0b013e3282f454db
   Paulmann S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00345
   Paulmann S, 2010, SOC NEUROSCI-UK, V5, P59, DOI 10.1080/17470910903135668
   Pell MD, 2009, J NONVERBAL BEHAV, V33, P107, DOI 10.1007/s10919-008-0065-7
   Phillips ML, 1998, P ROY SOC B-BIOL SCI, V265, P1809, DOI 10.1098/rspb.1998.0506
   Pinheiro AP, 2013, PSYCHOL MED, V43, P603, DOI 10.1017/S003329171200133X
   Pinheiro AP, 2014, SCHIZOPHR RES, V152, P235, DOI 10.1016/j.schres.2013.10.042
   Pinheiro AP, 2011, RES DEV DISABIL, V32, P133, DOI 10.1016/j.ridd.2010.09.011
   Ramus F, 1999, J ACOUST SOC AM, V105, P512, DOI 10.1121/1.424522
   Rauschecker JP, 1998, CURR OPIN NEUROBIOL, V8, P516, DOI 10.1016/S0959-4388(98)80040-8
   Rosburg T, 2008, PSYCHIAT RES, V161, P259, DOI 10.1016/j.psychres.2008.03.017
   Sanders LD, 2003, COGNITIVE BRAIN RES, V15, P228, DOI 10.1016/S0926-6410(02)00195-7
   Schellenberg EG, 2005, CURR DIR PSYCHOL SCI, V14, P317, DOI 10.1111/j.0963-7214.2005.00389.x
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   Schirmer A, 2004, NEUROIMAGE, V21, P1114, DOI 10.1016/j.neuroimage.2003.10.048
   Schneider P, 2002, NAT NEUROSCI, V5, P688, DOI 10.1038/nn871
   Schön D, 2004, PSYCHOPHYSIOLOGY, V41, P341, DOI 10.1111/1469-8986.00172.x
   Schwartz R, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0047279
   Sluming V, 2002, NEUROIMAGE, V17, P1613, DOI 10.1006/nimg.2002.1288
   Strait DL, 2012, BRAIN LANG, V123, P191, DOI 10.1016/j.bandl.2012.09.001
   Strait DL, 2009, ANN NY ACAD SCI, V1169, P209, DOI 10.1111/j.1749-6632.2009.04864.x
   Thönnessen H, 2010, NEUROIMAGE, V50, P250, DOI 10.1016/j.neuroimage.2009.11.082
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Trainor LJ, 2003, ANN NY ACAD SCI, V999, P506, DOI 10.1196/annals.1284.061
   Trainor LJ, 1999, AUST J PSYCHOL, V51, P147, DOI 10.1080/00049539908255352
   Trimmer CG, 2008, EMOTION, V8, P838, DOI 10.1037/a0014080
   Vouloumanos A, 2001, J COGNITIVE NEUROSCI, V13, P994, DOI 10.1162/089892901753165890
   White PM, 2006, PSYCHOPHYSIOLOGY, V43, P320, DOI 10.1111/j.1469-8986.2006.00408.x
   Wildgruber D, 2006, PROG BRAIN RES, V156, P249, DOI 10.1016/S0079-6123(06)56013-3
   Wildgruber D, 2005, NEUROIMAGE, V24, P1233, DOI 10.1016/j.neuroimage.2004.10.034
   Wildgruber D, 2004, CEREB CORTEX, V14, P1384, DOI 10.1093/cercor/bhh099
   Wildgruber D, 2002, NEUROIMAGE, V15, P856, DOI 10.1006/nimg.2001.0998
   Witteman J, 2012, NEUROPSYCHOLOGIA, V50, P2752, DOI 10.1016/j.neuropsychologia.2012.07.026
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
NR 106
TC 24
Z9 34
U1 2
U2 52
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0093-934X
EI 1090-2155
J9 BRAIN LANG
JI Brain Lang.
PD JAN
PY 2015
VL 140
BP 24
EP 34
DI 10.1016/j.bandl.2014.10.009
PG 11
WC Audiology & Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Audiology & Speech-Language Pathology; Linguistics; Neurosciences &
   Neurology; Psychology
GA CA0UF
UT WOS:000348631100004
PM 25461917
OA Green Published
DA 2024-01-09
ER

PT J
AU D'Onofrio, KL
   Caldwell, M
   Limb, C
   Smith, S
   Kessler, DM
   Gifford, RH
AF D'Onofrio, Kristen L.
   Caldwell, Meredith
   Limb, Charles
   Smith, Spencer
   Kessler, David M.
   Gifford, Rene H.
TI Musical Emotion Perception in Bimodal Patients: Relative Weighting of
   Musical Mode and Tempo Cues
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE cochlear implant; bimodal; music perception; musical emotion; hearing
   loss; frequency following response; spectral modulation detection;
   psychophysical tuning curve
ID IN-NOISE PERCEPTION; COCHLEAR; SPEECH; HEARING; DISCRIMINATION;
   RECOGNITION; APPRAISAL; CHILDREN; SOUNDS; VOICE
AB Several cues are used to convey musical emotion, the two primary being musical mode and musical tempo. Specifically, major and minor modes tend to be associated with positive and negative valence, respectively, and songs at fast tempi have been associated with more positive valence compared to songs at slow tempi (Balkwill and Thompson, 1999; Webster and Weir, 2005). In Experiment I, we examined the relative weighting of musical tempo and musical mode among adult cochlear implant (CI) users combining electric and contralateral acoustic stimulation, or "bimodal" hearing. Our primary hypothesis was that bimodal listeners would utilize both tempo and mode cues in their musical emotion judgments in a manner similar to normal-hearing listeners. Our secondary hypothesis was that low-frequency (LF) spectral resolution in the non-implanted ear, as quantified via psychophysical tuning curves (PTCs) at 262 and 440 Hz, would be significantly correlated with degree of bimodal benefit for musical emotion perception. In Experiment II, we investigated across-channel spectral resolution using a spectral modulation detection (SMD) task and neural representation of temporal fine structure via the frequency following response (FFR) for a 170-ms /da/ stimulus. Results indicate that CI-alone performance was driven almost exclusively by tempo cues, whereas bimodal listening demonstrated use of both tempo and mode. Additionally, bimodal benefit for musical emotion perception may be correlated with spectral resolution in the non-implanted ear via SMD, as well as neural representation of F0 amplitude via FFR - though further study with a larger sample size is warranted. Thus, contralateral acoustic hearing can offer significant benefit for musical emotion perception, and the degree of benefit may be dependent upon spectral resolution of the non-implanted ear.
C1 [D'Onofrio, Kristen L.; Kessler, David M.; Gifford, Rene H.] Vanderbilt Univ, Cochlear Implant Res Lab, Dept Hearing & Speech Sci, 221 Kirkland Hall, Nashville, TN 37235 USA.
   [Caldwell, Meredith] Vanderbilt Univ, Med Ctr, Nashville, TN USA.
   [Limb, Charles] Univ Calif San Francisco, Dept Otolaryngol Head & Neck Surg, San Francisco, CA 94143 USA.
   [Smith, Spencer] Univ Texas Austin, Dept Commun Sci & Disorders, Austin, TX 78712 USA.
C3 Vanderbilt University; Vanderbilt University; University of California
   System; University of California San Francisco; University of Texas
   System; University of Texas Austin
RP D'Onofrio, KL (corresponding author), Vanderbilt Univ, Cochlear Implant Res Lab, Dept Hearing & Speech Sci, 221 Kirkland Hall, Nashville, TN 37235 USA.
EM kristen.l.donofrio@vanderbilt.edu
OI Gifford, Rene/0000-0001-6662-3436
FU National Institute on Deafness and Other Communication Disorders; NIDCD
   [R01DC009404]
FX This research was supported by the National Institute on Deafness and
   Other Communication Disorders and grant NIDCD R01DC009404 (PI: RG).
CR Anderson S, 2013, J ACOUST SOC AM, V133, P3030, DOI 10.1121/1.4799804
   Anderson S, 2011, EAR HEARING, V32, P750, DOI 10.1097/AUD.0b013e31822229d3
   Anderson S, 2010, J NEUROSCI, V30, P4922, DOI 10.1523/JNEUROSCI.0107-10.2010
   Bachorowski JA, 1999, CURR DIR PSYCHOL SCI, V8, P53, DOI 10.1111/1467-8721.00013
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Bidelman GM, 2014, J ACOUST SOC AM, V136, pEL33, DOI 10.1121/1.4885484
   Caldwell Meredith, 2015, Cochlear Implants Int, V16 Suppl 3, pS114, DOI 10.1179/1467010015Z.000000000265
   Chatterjee M, 2008, HEARING RES, V235, P143, DOI 10.1016/j.heares.2007.11.004
   Cohen J, 1988, STAT POWER ANAL BEHA
   D'Alessandro HD, 2018, EAR HEARING, V39, P679, DOI 10.1097/AUD.0000000000000525
   Dorman MF, 2008, AUDIOL NEURO-OTOL, V13, P105, DOI 10.1159/000111782
   Drennan WR, 2015, INT J AUDIOL, V54, P114, DOI 10.3109/14992027.2014.948219
   Eerola T, 2013, MUSIC PERCEPT, V30, P307, DOI [10.1525/mp.2012.30.3.307, 10.1525/MP.2012.30.1.49]
   El Fata F, 2009, AUDIOL NEURO-OTOL, V14, P14, DOI 10.1159/000206491
   Gfeller K, 1997, EAR HEARING, V18, P252, DOI 10.1097/00003446-199706000-00008
   Gfeller K, 2008, J AM ACAD AUDIOL, V19, P120, DOI 10.3766/jaaa.19.2.3
   Gfeller Kate, 2002, Cochlear Implants Int, V3, P29, DOI 10.1179/cim.2002.3.1.29
   Giannantonio S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0136685
   Gifford RH, 2019, EAR HEARING, V40, P501, DOI 10.1097/AUD.0000000000000657
   Gifford RH, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518771176
   Gifford RH, 2014, INT J AUDIOL, V53, P159, DOI 10.3109/14992027.2013.851800
   Gosselin N, 2005, BRAIN, V128, P628, DOI 10.1093/brain/awh420
   Green T, 2012, INT J AUDIOL, V51, P389, DOI 10.3109/14992027.2011.642010
   Holder JT, 2018, OTOL NEUROTOL, V39, pE972, DOI 10.1097/MAO.0000000000002003
   Hopyan T, 2011, Cochlear Implants Int, V12, P21, DOI 10.1179/146701010X12677899497399
   Hopyan T, 2016, CHILD NEUROPSYCHOL, V22, P366, DOI 10.1080/09297049.2014.992400
   Hsiao Feilin, 2012, Update Univ S C Dep Music, V30, P5
   International Organization for Standardization, 1975, AC STAND T1N FREQ ST
   Jiam NT, 2017, HEARING RES, V352, P30, DOI 10.1016/j.heares.2017.01.006
   Juslin P. N., 1996, PSYCHOL MUSIC, V24, P68, DOI [10.1177/0305735696241007, DOI 10.1177/0305735696241007]
   Kang R, 2009, EAR HEARING, V30, P411, DOI 10.1097/AUD.0b013e3181a61bc0
   Kessler DM, 2020, TRENDS HEAR, V24, DOI 10.1177/2331216520902001
   Kong YY, 2004, EAR HEARING, V25, P173, DOI 10.1097/01.AUD.0000120365.97792.2F
   Lassaletta L, 2007, ACTA OTO-LARYNGOL, V127, P682, DOI 10.1080/00016480601002112
   Li X, 2013, IEEE T NEUR SYS REH, V21, P684, DOI 10.1109/TNSRE.2013.2257853
   Limb CJ, 2014, HEARING RES, V308, P13, DOI 10.1016/j.heares.2013.04.009
   Mirza S, 2003, Cochlear Implants Int, V4, P85, DOI 10.1179/cim.2003.4.2.85
   Moore BCJ, 2000, BRIT J AUDIOL, V34, P205, DOI 10.3109/03005364000000131
   MOORE BCJ, 1978, J ACOUST SOC AM, V63, P524, DOI 10.1121/1.381752
   Moore BCJ, 2003, OTOL NEUROTOL, V24, P243, DOI 10.1097/00129492-200303000-00019
   Ollen J. E., 2006, doctoral dissertation
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   Reynolds SM, 2019, INT J AUDIOL, V58, P363, DOI 10.1080/14992027.2019.1580390
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Sek A, 2005, INT J AUDIOL, V44, P408, DOI 10.1080/14992020500060800
   Sek A, 2011, INT J AUDIOL, V50, P237, DOI 10.3109/14992027.2010.550636
   Shabana M., 2014, ADV ARAB ACAD AUDIO, V1, DOI [10.4103/2314-8667.137559, DOI 10.4103/2314-8667.137559]
   Shirvani S, 2016, ANN OTO RHINOL LARYN, V125, P470, DOI 10.1177/0003489415619943
   Sladen DP, 2018, OTOL NEUROTOL, V39, P576, DOI 10.1097/MAO.0000000000001763
   Smith ZM, 2002, NATURE, V416, P87, DOI 10.1038/416087a
   Song JH, 2011, J COGNITIVE NEUROSCI, V23, P2268, DOI 10.1162/jocn.2010.21556
   Sucher Catherine M, 2009, Cochlear Implants Int, V10 Suppl 1, P96, DOI 10.1179/cim.2009.10.Supplement-1.96
   Thompson EC, 2017, HEARING RES, V344, P148, DOI 10.1016/j.heares.2016.11.007
   Wang WQ, 2011, INT J AUDIOL, V50, P270, DOI 10.3109/14992027.2010.542490
   Webster GD, 2005, MOTIV EMOTION, V29, P19, DOI 10.1007/s11031-005-4414-0
   Xin Luo, 2007, Trends Amplif, V11, P301
NR 56
TC 9
Z9 10
U1 0
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD FEB 26
PY 2020
VL 14
AR 114
DI 10.3389/fnins.2020.00114
PG 15
WC Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Neurosciences & Neurology
GA LC0VQ
UT WOS:000525048700001
PM 32174809
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Sieyers, B
   Lee, C
   Haslett, W
   Wheatley, T
AF Sieyers, Beau
   Lee, Caitlyn
   Haslett, William
   Wheatley, Thalia
TI A multi-sensory code for emotional arousal
SO PROCEEDINGS OF THE ROYAL SOCIETY B-BIOLOGICAL SCIENCES
LA English
DT Article
DE emotion; arousal; cross-modal; spectral centroid; supramodal
ID CROSS-MODAL CORRESPONDENCES; CIRCUMPLEX MODEL; MUSIC; EXPRESSIONS;
   INFORMATION; PERCEPTION
AB People express emotion using their voice, face and movement, as well as through abstract forms as in art, architecture and music. The structure of these expressions often seems intuitively linked to its meaning: romantic poetry is written in flowery curlicues, while the logos of death metal bands use spiky script. Here, we show that these associations are universally understood because they are signalled using a multi-sensory code for emotional arousal. Specifically, variation in the central tendency of the frequency spectrum of a stimulus-its spectral centroid-is used by signal senders to express emotional arousal, and by signal receivers to make emotional arousal judgements. We show that this code is used across sounds, shapes, speech and human body movements, providing a strong multi-sensory signal that can be used to efficiently estimate an agent's level of emotional arousal.
C1 [Sieyers, Beau] Harvard Univ, Dept Psychol, Cambridge, MA 02138 USA.
   [Lee, Caitlyn; Wheatley, Thalia] Dartmouth Coll, Dept Psychol & Brain Sci, Hanover, NH 03755 USA.
   [Haslett, William] Geisel Sch Med Dartmouth, Dept Biomed Data Sci, Hanover, NH 03755 USA.
C3 Harvard University; Dartmouth College; Dartmouth College
RP Wheatley, T (corresponding author), Dartmouth Coll, Dept Psychol & Brain Sci, Hanover, NH 03755 USA.
EM thalia.p.wheatley@dartmouth.edu
OI Sievers, Beau/0000-0001-8762-7479
FU McNulty Grant from the Nelson A. Rockefeller Center; Neukom Institute
   for Computational Science Graduate Fellowship
FX This research was supported in part by a McNulty Grant from the Nelson
   A. Rockefeller Center (T.W.) and a Neukom Institute for Computational
   Science Graduate Fellowship (B.S.).
CR [Anonymous], DEV SCI
   [Anonymous], 2005, 9 EUR C SPEECH COMM
   [Anonymous], LOW LEVEL PERCEPTS P
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Bremner AJ, 2013, COGNITION, V126, P165, DOI 10.1016/j.cognition.2012.09.007
   Damasio A, 2013, NAT REV NEUROSCI, V14, P143, DOI 10.1038/nrn3403
   Faragó T, 2014, BIOL LETTERS, V10, DOI 10.1098/rsbl.2013.0926
   Filippi P, 2017, P ROY SOC B-BIOL SCI, V284, DOI 10.1098/rspb.2017.0990
   Gingras B, 2014, Q J EXP PSYCHOL, V67, P1428, DOI 10.1080/17470218.2013.863954
   Harris C. G., 1988, P 4 ALV VIS C, P10
   HOLLAND MK, 1964, PERCEPT MOTOR SKILL, V19, P111, DOI 10.2466/pms.1964.19.1.111
   Knoeferle KM, 2015, PSYCHOL MARKET, V32, P107, DOI 10.1002/mar.20766
   Kohler W., 1929, Gestalt psychology
   Lim Angelica, 2012, Human Behavior Understanding. Proceedings of the Third International Workshop, HBU 2012, P52, DOI 10.1007/978-3-642-34014-7_5
   Lundholm H, 1921, PSYCHOL REV, V28, P43, DOI 10.1037/h0072647
   Lupyan G, 2015, CURR DIR PSYCHOL SCI, V24, P279, DOI 10.1177/0963721415570732
   Ma YL, 2006, BEHAV RES METHODS, V38, P134, DOI 10.3758/BF03192758
   MARLER P, 1961, J THEOR BIOL, V1, P295, DOI 10.1016/0022-5193(61)90032-7
   Martino G, 1999, PERCEPTION, V28, P903, DOI 10.1068/p2866
   McFee B., 2015, P 14 PYTH SCI C, V8, P18, DOI DOI 10.25080/MAJORA-7B98E3ED-003
   Monaghan P, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0299
   Otte D., 1974, Annual Rev Ecol Syst, V5, P385, DOI 10.1146/annurev.es.05.110174.002125
   Owren MJ, 2010, BIOL PHILOS, V25, P755, DOI 10.1007/s10539-010-9224-4
   Ozturk O, 2013, J EXP CHILD PSYCHOL, V114, P173, DOI 10.1016/j.jecp.2012.05.004
   Palmer SE, 2013, P NATL ACAD SCI USA, V110, P8836, DOI 10.1073/pnas.1212562110
   Poffenberger AT, 1924, J APPL PSYCHOL, V8, P187, DOI 10.1037/h0073513
   Pongrácz P, 2005, J COMP PSYCHOL, V119, P136, DOI 10.1037/0735-7036.119.2.136
   Pongrácz P, 2006, APPL ANIM BEHAV SCI, V100, P228, DOI 10.1016/j.applanim.2005.12.004
   Ramachandran VS, 2003, SCI AM, V288, P52, DOI 10.1038/scientificamerican0503-52
   RUSSELL JA, 1989, J PERS SOC PSYCHOL, V57, P848, DOI 10.1037/0022-3514.57.5.848
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Saffran JR, 2018, ANNU REV PSYCHOL, V69, P181, DOI 10.1146/annurev-psych-122216-011805
   Sauter DA, 2010, Q J EXP PSYCHOL, V63, P2251, DOI 10.1080/17470211003721642
   Sauter DA, 2010, P NATL ACAD SCI USA, V107, P2408, DOI 10.1073/pnas.0908239106
   Schubert E, 2006, ACTA ACUST UNITED AC, V92, P820
   Seyfarth RM, 2017, ANIM BEHAV, V124, P339, DOI 10.1016/j.anbehav.2016.05.020
   Sievers B, 2013, P NATL ACAD SCI USA, V110, P70, DOI 10.1073/pnas.1209023110
   Spector F, 2009, DEV PSYCHOL, V45, P175, DOI 10.1037/a0014171
   Spelke ES, 2007, DEVELOPMENTAL SCI, V10, P89, DOI 10.1111/j.1467-7687.2007.00569.x
   Walker P, 2010, PSYCHOL SCI, V21, P21, DOI 10.1177/0956797609354734
   ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949
NR 41
TC 16
Z9 16
U1 3
U2 17
PU ROYAL SOC
PI LONDON
PA 6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND
SN 0962-8452
EI 1471-2954
J9 P ROY SOC B-BIOL SCI
JI Proc. R. Soc. B-Biol. Sci.
PD JUL 10
PY 2019
VL 286
IS 1906
AR 20190513
DI 10.1098/rspb.2019.0513
PG 10
WC Biology; Ecology; Evolutionary Biology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Life Sciences & Biomedicine - Other Topics; Environmental Sciences &
   Ecology; Evolutionary Biology
GA IJ3IL
UT WOS:000475797600003
PM 31288695
OA Bronze, Green Submitted, Green Published
DA 2024-01-09
ER

PT J
AU Gratier, M
AF Gratier, Maya
TI Musicality as a natural resource for all infants and all parents
SO ENFANCE
LA French
DT Editorial Material
DE MUSICALITY; VOICE; SONG; CREATIVITY
ID MATERNAL SPEECH; PERCEPTION; PREFER; VOICE; NEWBORNS; MELODIES
AB Musicality is defined as a fundamental aptitude, present at birth, enabling infants to not only perceive complex organizations of sounds and gestures but also to participate in the musical propositions of adults. Adults' voices offer perhaps the first natural musical experiences for infants, conveying both social emotion and the kinds of rhythms and melodic motifs that infants easily memorize. The musical abilities of infants, that are expressed and develop in the first months of life, have been well documented by researchers. Adults know how to sing for and with infants much as they know intuitively how to speak for and with infants. A natural musicality thus serves perhaps to enable musical encounters between adults and infants, that are a source of both shared enjoyment and knowledge. It also serves to support a creativity based on sound and gesture in toddlers, appearing as they begin to explore and master the meanings of words. During the second year of life, invented songs are associated with the first verbal productions and reflect, as spoken sentences do, regularities that are learned without instruction.
C1 [Gratier, Maya] Univ Paris Nanterre, Ethol, Cognit, Dev, 200 Ave Republ, F-92100 Nanterre, France.
RP Gratier, M (corresponding author), Univ Paris Nanterre, Ethol, Cognit, Dev, 200 Ave Republ, F-92100 Nanterre, France.
EM mayagratier@parisnanterre.fr
CR [Anonymous], RHYTHMS MUSICAL NARR
   [Anonymous], MUSICAL BEGINNINGS O
   [Anonymous], 1976, MUSICAL EXPERIENCE P
   Barrett M.S., 2019, OXFORD HDB SINGING
   Blasi A, 2011, CURR BIOL, V21, P1220, DOI 10.1016/j.cub.2011.06.009
   BLOOM K, 1987, J CHILD LANG, V14, P211, DOI 10.1017/S0305000900012897
   CHANG HW, 1977, CHILD DEV, V48, P1666, DOI 10.2307/1128532
   Corbeil M, 2016, INFANCY, V21, P373, DOI 10.1111/infa.12114
   Corbeil M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00372
   DECASPER AJ, 1980, SCIENCE, V208, P1174, DOI 10.1126/science.7375928
   Delavenne A, 2013, INFANT BEHAV DEV, V36, P1, DOI 10.1016/j.infbeh.2012.10.004
   DEMANY L, 1982, INFANT BEHAV DEV, V5, P261, DOI 10.1016/S0163-6383(82)80036-2
   Dominguez S, 2016, INFANT CHILD DEV, V25, P240, DOI 10.1002/icd.1976
   Eckerdal P., 2009, Communicative musicality: Exploring the basis of human companionship, P241
   FERNALD A, 1991, DEV PSYCHOL, V27, P209, DOI 10.1037/0012-1649.27.2.209
   Filippa M, 2017, ACTA PAEDIATR, V106, P1220, DOI 10.1111/apa.13832
   Filippa M, 2013, ACTA PAEDIATR, V102, P1017, DOI 10.1111/apa.12356
   Granier-Deferre C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017304
   Gratier M, 2012, INTERMEDIALITES, P45, DOI 10.7202/1012655ar
   Honing H, 2015, PHILOS T R SOC B, V370, P5, DOI 10.1098/rstb.2014.0088
   JUSCZYK PW, 1993, J EXP PSYCHOL HUMAN, V19, P627, DOI 10.1037/0096-1523.19.3.627
   Kisilevsky BS, 2003, PSYCHOL SCI, V14, P220, DOI 10.1111/1467-9280.02435
   KRUMHANSL CL, 1990, PSYCHOL SCI, V1, P70, DOI 10.1111/j.1467-9280.1990.tb00070.x
   Malloch S., 2002, ZERO 3, V23, P10
   Malloch S., 2009, COMMUNICATIVE MUSICA
   Masataka N, 2006, DEVELOPMENTAL SCI, V9, P46, DOI 10.1111/j.1467-7687.2005.00462.x
   MEHLER J, 1988, COGNITION, V29, P143, DOI 10.1016/0010-0277(88)90035-2
   Mehr SA, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12542
   Mehr SA, 2016, PSYCHOL SCI, V27, P486, DOI 10.1177/0956797615626691
   Nakata T, 2004, INFANT BEHAV DEV, V27, P455, DOI 10.1016/j.infbeh.2004.03.002
   Oller D. K., 2000, The emergence of the speech capacity
   Panneton R., 1985, THESIS, P47
   Plantinga J, 2014, J EXP PSYCHOL HUMAN, V40, P40, DOI 10.1037/a0033471
   Shenfield T., 2003, Psychol. Music, V31, P365, DOI DOI 10.1177/03057356030314002
   Smith NA, 2008, INFANCY, V13, P410, DOI 10.1080/15250000802188719
   Soley G, 2010, DEV PSYCHOL, V46, P286, DOI 10.1037/a0017555
   THORPE LA, 1989, DEV PSYCHOL, V25, P122, DOI 10.1037/0012-1649.25.1.122
   Trainor LJ, 1997, INFANT BEHAV DEV, V20, P383, DOI 10.1016/S0163-6383(97)90009-6
   Trehub S., 2015, CHILD MUSICIAN HDB M, V2, P31
   Trehub S.E., 2015, ANN NEW YORK ACAD SC, V1
   Trehub S. E., 1998, Advances in Infancy Research, V12, P43
   TREHUB SE, 1989, CAN J PSYCHOL, V43, P217, DOI 10.1037/h0084223
   TREHUB SE, 1993, ADV CHILD DEV BEHAV, V24, P1, DOI 10.1016/S0065-2407(08)60298-0
   Trehub SE, 2003, NAT NEUROSCI, V6, P669, DOI 10.1038/nn1084
   TREHUB SE, 1984, CHILD DEV, V55, P821, DOI 10.1111/j.1467-8624.1984.tb03819.x
   Trevarthen C., 1999, Musicae Scientiae, V3, P155, DOI [10.1177/10298649000030S109, DOI 10.1177/10298649000030S109]
   Tsang CD, 2017, CHILD DEV, V88, P1207, DOI 10.1111/cdev.12647
   Unyk AM., 1992, Psychol Music, V20, P15, DOI [10.1177/0305735692201002, DOI 10.1177/0305735692201002]
NR 48
TC 0
Z9 0
U1 0
U2 4
PU PRESSES UNIV FRANCE
PI PARIS CEDEX 14
PA 6 AVENUE REILLE, 75685 PARIS CEDEX 14, FRANCE
SN 0013-7545
EI 1969-6981
J9 ENFANCE
JI Enfance
PY 2020
IS 1
BP 5
EP 15
PG 11
WC Psychology, Developmental
WE Emerging Sources Citation Index (ESCI)
SC Psychology
GA LC3YF
UT WOS:000525260600002
DA 2024-01-09
ER

PT J
AU López-Mochales, S
   Jiménez-Pasalodos, R
   Valenzuela, J
   Gutiérrez-Cajaraville, C
   Díaz-Andreu, M
   Escera, C
AF Lopez-Mochales, Samantha
   Jimenez-Pasalodos, Raquel
   Valenzuela, Jose
   Gutierrez-Cajaraville, Carlos
   Diaz-Andreu, Margarita
   Escera, Carles
TI Experimental Enhancement of Feelings of Transcendence, Tenderness, and
   Expressiveness by Music in Christian Liturgical Spaces
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE psychoacoustics; archaeoacoustics; emotion; music; auralization
ID CONCERT-HALLS; PREFERENCE RATINGS; EMOTIONS; SOUND
AB In western cultures, when it comes to places of worship and liturgies, music, acoustics and architecture go hand in hand. In the present study, we aimed to investigate whether the emotions evoked by music are enhanced by the acoustics of the space where the music was composed to be played on. We explored whether the emotional responses of western naive listeners to two vocal pieces from the Renaissance, one liturgical and one secular, convolved with the impulse responses of four Christian temples from the United Kingdom, were modulated by the appropriate piece/space matching. In an alternative forced choice task where participants had to indicate their preference for the original recording of the piece (not convolved with any temple-like acoustics) vs. the convolved one, no significant differences were found. However, in the tasks where participants rated their emotional in response to each piece and acoustic condition, the factorial ANCOVA analyses performed on the results revealed significant effects. We observed that, across pieces and spaces, participants found the temple-like acoustics as more transcendent, compared to the acoustics of the original version of the pieces. In addition, they rated the secular piece as more tender and the liturgical piece as more expressive in its original versions, compared to the convolved ones. We conclude that the acoustic signature of the four Christian temples causes an exaltation of certain emotions on listeners, although this effect is not associated to one or another musical piece.
C1 [Lopez-Mochales, Samantha; Valenzuela, Jose; Escera, Carles] Univ Barcelona, Dept Clin Psychol & Psychobiol, Brainlab Cognit Neurosci Res Grp, Fac Psychol, Barcelona, Spain.
   [Lopez-Mochales, Samantha; Valenzuela, Jose; Escera, Carles] Univ Barcelona, Inst Neurosci, Barcelona, Spain.
   [Jimenez-Pasalodos, Raquel; Diaz-Andreu, Margarita] Univ Barcelona, Dept Hist & Arqueol, Barcelona, Spain.
   [Jimenez-Pasalodos, Raquel; Gutierrez-Cajaraville, Carlos] Univ Valladolid, Secc Dept Hist & Ciencias Mus, Valladolid, Spain.
   [Diaz-Andreu, Margarita; Escera, Carles] ICREA, Barcelona, Spain.
   [Diaz-Andreu, Margarita] Univ Barcelona IAUB, Inst Arqueol, Barcelona, Spain.
   [Escera, Carles] IRSJD, Esplugas de Llobregat, Spain.
C3 University of Barcelona; University of Barcelona; University of
   Barcelona; Universidad de Valladolid; ICREA
RP Escera, C (corresponding author), Univ Barcelona, Dept Clin Psychol & Psychobiol, Brainlab Cognit Neurosci Res Grp, Fac Psychol, Barcelona, Spain.; Escera, C (corresponding author), Univ Barcelona, Inst Neurosci, Barcelona, Spain.; Escera, C (corresponding author), ICREA, Barcelona, Spain.; Escera, C (corresponding author), IRSJD, Esplugas de Llobregat, Spain.
EM cescera@ub.edu
RI Diaz-Andreu, Margarita/B-6146-2014
OI Diaz-Andreu, Margarita/0000-0003-1043-2336; Jimenez Pasalodos,
   Raquel/0000-0001-9422-8302; Lopez, Samantha/0000-0003-1093-6366
FU European Research Council (ERC) under the European Union's Horizon 2020
   research and innovation programme [787842]; Generalitat de Catalunya
   [SGR2017-974]; Ministry of Science, Innovation and Universities
   [2017s0729]; ICREA Academia Distinguished Professorship Award; European
   Research Council (ERC) [787842] Funding Source: European Research
   Council (ERC)
FX This article is part of the ERC Artsoundscapes project (Grant Agreeement
   No. 787842, PI: MDA) that has received funding from the European
   Research Council (ERC) under the European Union's Horizon 2020 research
   and innovation programme. CE was also supported by the Generalitat de
   Catalunya SGR2017-974, Maria de Maeztu Unit of Excellence (Institute of
   Neurosciences, University of Barcelona) MDM 2017s0729, Ministry of
   Science, Innovation and Universities, and the ICREA Academia
   Distinguished Professorship Award.
CR Alvarez-Morales L, 2020, ACOUSTICS-BASEL, V2, P13, DOI 10.3390/acoustics2010003
   Barrett LF, 1998, COGNITION EMOTION, V12, P579, DOI 10.1080/026999398379574
   BARRON M, 1971, J SOUND VIB, V15, P475, DOI 10.1016/0022-460X(71)90406-8
   Baumann D., 2016, SACRED BUILDINGS, P54, DOI [10.1007/978-3-7643-8276-6_4, DOI 10.1007/978-3-7643-8276-6_4]
   Bidule, 2020, PLOG ART TECHN COMP
   Carifio J., 2007, Journal of Social Sciences, V3, P106, DOI DOI 10.3844/JSSP.2007.106.116
   Davies S., 2001, MUSIC EMOTION THEORY, P23, DOI DOI 10.1017/S0140525X08005293
   Farina A., 2007, 19 INT C AC, V2007, P2
   Farina A, 2003, P AES 24 INT C MULT
   Farina A., 2007, 23 NORD SOUND S, P27
   Ferrando J, 2014, RODA FORTUNA REV ELE, V3, P170
   Ferrando J., 2020, COMPRENDRE GESTE MUS
   Gemba K.L., 2014, THESIS U HAWAII
   Genell A., 2008, THESIS CHALMERS U TE
   Ghaffari A., 2014, Armanshahr Architect. Urban Dev, V7, P13
   Hanser WE, 2016, MUSIC SCI, V20, P122, DOI 10.1177/1029864915620264
   Huber S, 2012, RELIGIONS, V3, P710, DOI 10.3390/rel3030710
   Juslin P., 2010, Handbook of Music and Emotion: Theory, Research, Applications, P453, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0017
   Kerman J., 1981, FABER FABER, V288, P939976, DOI [10.2307/939976, DOI 10.2307/939976]
   Kuusinen A, 2014, J ACOUST SOC AM, V135, P239, DOI 10.1121/1.4836335
   Lawrence MA., 2016, EZ EASY ANAL VISUALI, V4, P49
   Lokki T, 2012, J ACOUST SOC AM, V132, P3148, DOI 10.1121/1.4756826
   Manzettia MC, 2016, VIRTUAL ARCHAEOL REV, V7, P36, DOI 10.4995/var.2016.5922
   Mattioli T, 2017, J ARCHAEOL SCI, V83, P12, DOI 10.1016/j.jas.2017.04.008
   Miu AC, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030618
   Norman G, 2010, ADV HEALTH SCI EDUC, V15, P625, DOI 10.1007/s10459-010-9222-y
   OpenAIR, 2020, OP AIR LIB
   Pätynen J, 2016, J ACOUST SOC AM, V139, P1214, DOI 10.1121/1.4944038
   Pearce MT, 2015, PSYCHOL AESTHET CREA, V9, P248, DOI 10.1037/a0039279
   Psychstudio, 2019, PSYCHST VERS 2019
   Rainio R, 2018, J ARCHAEOL METHOD TH, V25, P453, DOI 10.1007/s10816-017-9343-1
   Robinson Jenefer, 2007, POSTGRADUATE J AESTH, V4, P19, DOI DOI 10.4236/PSYCH.2019.108072
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Scarre C., 2006, ARCHAEOACOUSTICS
   SCHROEDER MR, 1974, J ACOUST SOC AM, V56, P1195, DOI 10.1121/1.1903408
   Schubert E., 2014, Expressiveness in music performance: Empirical approaches across styles and cultures, P283
   The King's Singers, 1995, ENGLISH RENAISSANCE
   The King's Singers, 2012, ROYAL RHYM ROUNDS AL
   Västfjäll D, 2002, CYBERPSYCHOL BEHAV, V5, P19, DOI 10.1089/109493102753685854
   Västfjäll D, 2003, CYBERPSYCHOL BEHAV, V6, P181, DOI 10.1089/109493103321640374
   Vastfjall D., 2012, Psychology, V3, P606, DOI DOI 10.4236/PSYCH.2012.38091
   Vorlander M, 2008, AURALIZATION
   Woszczyk W., 2008, J ACOUST SOC AM, V2008, P1041, DOI 10.1121/1.2932919
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 44
TC 1
Z9 1
U1 0
U2 8
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD MAR 10
PY 2022
VL 13
AR 844029
DI 10.3389/fpsyg.2022.844029
PG 10
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA 0G8UY
UT WOS:000778316200001
PM 35360627
OA gold, Green Published
DA 2024-01-09
ER

PT J
AU Liu, XL
   Xu, Y
AF Liu, Xiaoluan
   Xu, Yi
TI Relations between affective music and speech: evidence from dynamics of
   affective piano performance and speech production
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE dynamics; emotion; piano performance; speech production; fingerings;
   articulatory constraints
ID VOCAL EXPRESSION; BASIC EMOTIONS; RULE SYSTEMS; PATTERNS; MOVEMENT;
   COMMUNICATION; KINEMATICS; TONGUE; MICROSTRUCTURE; SUPERFICIALIS
AB This study compares affective piano performance with speech production from the perspective of dynamics: unlike previous research, this study uses finger force and articulatory effort as indexes reflecting the dynamics of affective piano performance and speech production respectively. Moreover, for the first time physical constraints such as piano fingerings and speech articulatory constraints are included due to their potential contribution to different patterns of dynamics. A piano performance experiment and speech production experiment were conducted in four emotions: anger, fear, happiness and sadness. The results show that in both piano performance and speech production, anger and happiness generally have high dynamics while sadness has the lowest dynamics. Fingerings interact with fear in the piano experiment and articulatory constraints interact with anger in the speech experiment, i.e., large physical constraints produce significantly higher dynamics than small physical constraints in piano performance under the condition of fear and in speech production under the condition of anger. Using production experiments, this study firstly supports previous perception studies on relations between affective music and speech. Moreover, this is the first study to show quantitative evidence for the importance of considering motor aspects such as dynamics in comparing music performance and speech production in which motor mechanisms play a crucial role.
C1 [Liu, Xiaoluan; Xu, Yi] UCL, Dept Speech Hearing & Phonet Sci, London WC1N 1PF, England.
C3 University of London; University College London
RP Liu, XL (corresponding author), UCL, Dept Speech Hearing & Phonet Sci, Chandler House,2 Wakefield St, London WC1N 1PF, England.
EM lxl0803@outlook.com
RI Xu, Yi/C-4013-2008; Xu, Yi/M-9738-2019
OI Xu, Yi/0000-0002-8541-2658; Xu, Yi/0000-0002-8541-2658
CR ADAMS SG, 1993, J SPEECH HEAR RES, V36, P41, DOI 10.1044/jshr.3601.41
   [Anonymous], 2003, Psychology of Music, DOI DOI 10.1177/03057356030313002
   [Anonymous], 2000, P ITRW SPEECH EMOTIO
   [Anonymous], 2006, MUSIC MOTOR CONTROL, DOI DOI 10.1093/ACPROF:OSO/9780199298723.003.0003
   [Anonymous], 1980, Gray's Anatomy
   AUSTIN GJ, 1989, J HAND SURG-AM, V14, P262, DOI 10.1016/0363-5023(89)90018-X
   BAKER DS, 1981, J HAND SURG-AM, V6, P374, DOI 10.1016/S0363-5023(81)80047-0
   Bamberger J., 1976, MUSIC FORUM, V4, P237
   Bernays M, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00157
   Boersma P., 2021, Glot International
   BOITEN FA, 1994, INT J PSYCHOPHYSIOL, V17, P103, DOI 10.1016/0167-8760(94)90027-2
   Buck R., 1984, COMMUNICATION EMOTIO
   Burke R. E., 1981, Handbook of physiology, the nervous system, motor control, P345
   Caro Tim, 2005, pXIII
   Cheng C, 2015, LANG SPEECH, V58, P281, DOI 10.1177/0023830914543286
   Cheng CE, 2013, J ACOUST SOC AM, V134, P4481, DOI 10.1121/1.4824930
   Clark J, 1990, INTRO PHONETICS PHON
   Clarke E., 1997, MUSIC SCI, V1, P87, DOI DOI 10.1177/102986499700100106
   Cross I, 2013, STRUNGMANN FORUM REP, P541
   Curtis ME, 2010, EMOTION, V10, P335, DOI 10.1037/a0017928
   Darwin C., 1872, P374
   EDWARDS J, 1991, J ACOUST SOC AM, V89, P369, DOI 10.1121/1.400674
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Erickson D., 2004, INT S TON ASP LANG E, P53
   Fonagy I., 1963, Z PHONETIK, V16, P293, DOI DOI 10.1524/STUF.1963.16.14.293
   GABRIELSSON A, 1995, MUSIC MIND MACHINE, P35
   Gentil M, 1998, ARCH ORAL BIOL, V43, P517, DOI 10.1016/S0003-9969(98)00042-9
   Grillner S, 1982, SPEECH MOTOR CONTROL
   Gunter G. S., 1960, AUST NZ J SURG, V30, P1, DOI DOI 10.1111/J.1445-2197.1960.TB03078.X
   Hertrich I, 1997, J ACOUST SOC AM, V102, P523, DOI 10.1121/1.419725
   Huron D, 2011, MUSIC SCI, V15, P146, DOI 10.1177/1029864911401171
   Huron David., 2006, SWEET ANTICIPATION M, DOI DOI 10.7551/MITPRESS/6575.001.0001
   Ilie G, 2011, MUSIC PERCEPT, V28, P247, DOI 10.1525/MP.2011.28.3.247
   Ito T, 2004, J APPL PHYSIOL, V96, P2318, DOI 10.1152/japplphysiol.01048.2003
   Juslin PN, 2013, PSYCHOLOGY OF MUSIC, THIRD EDITION, P583, DOI 10.1016/B978-0-12-381460-9.00015-8
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Juslin PN, 1999, MUSIC PERCEPT, V17, P197
   Juslin PN., 2001, Music and Emotion, P309, DOI 10.1093/oso/9780192631886.003.0014
   Kaplan Abby, 2010, Ph.D. dissertation
   KELSO JAS, 1985, J ACOUST SOC AM, V77, P266, DOI 10.1121/1.392268
   Kinoshita H, 2007, J ACOUST SOC AM, V121, P2959, DOI 10.1121/1.2717493
   Kirchner R., 1998, THESIS UCLA LOS ANGE
   Kochevitsky G., 1967, The Art of Piano Playing: A Scientific Approach
   Kong YY, 2006, J ACOUST SOC AM, V120, P2830, DOI 10.1121/1.2346009
   Laukka P, 2005, COGNITION EMOTION, V19, P633, DOI 10.1080/02699930441000445
   Lavoie L.M., 2001, CONSONANT STRENGTH P
   LeDoux Joseph, 1996, The Emotional Brain
   Lerdahl F, 2013, STRUNGMANN FORUM REP, P257
   LINDBLOM B, 1963, J ACOUST SOC AM, V35, P1773, DOI 10.1121/1.1918816
   LINDBLOM B, 1990, SPEECH PRODUCTION SP, P413, DOI DOI 10.1007/978-94-009-2037-8
   LINDBLOM BE, 1971, J ACOUST SOC AM, V50, P1166, DOI 10.1121/1.1912750
   Lindblom Bjorn, 1983, PRODUCTION SPEECH, P217, DOI DOI 10.1007/978-1-4613-8202-7_10
   Livingstone SR, 2015, Q J EXP PSYCHOL, V68, P952, DOI 10.1080/17470218.2014.971034
   Loucks TMJ, 2010, J MOTOR BEHAV, V42, P233, DOI 10.1080/00222895.2010.492723
   Madison G, 2000, J NEW MUSIC RES, V29, P335, DOI 10.1080/09298210008565466
   MALECOT A, 1955, STUD LINGUISTICA, V9, P35, DOI DOI 10.1111/J.1467-9582.1955.TB00515.X
   McPherson A., 2013, MUSIC HUMAN COMPUTER, P123, DOI DOI 10.1007/978-1-4471-2990-57
   MCPHERSON Andrew, 2013, P INT C NEW INT MUS, P152
   McPherson AP, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2789
   Minetti AE, 2007, J BIOMECH, V40, P3738, DOI 10.1016/j.jbiomech.2007.06.015
   MORTON ES, 1977, AM NAT, V111, P855, DOI 10.1086/283219
   MUNHALL KG, 1985, J EXP PSYCHOL HUMAN, V11, P457, DOI 10.1037/0096-1523.11.4.457
   NELSON WL, 1983, BIOL CYBERN, V46, P135, DOI 10.1007/BF00339982
   Neuhaus H., 1973, ART PIANO PLAYING
   OSTRY DJ, 1985, J ACOUST SOC AM, V77, P640, DOI 10.1121/1.391882
   OSTRY DJ, 1983, J EXP PSYCHOL HUMAN, V9, P622, DOI 10.1037/0096-1523.9.4.622
   Padgett J, 2009, LINGUIST REV, V26, P431, DOI 10.1515/tlir.2009.016
   Paeschke A., 1999, P INT C PHON SCI, P929
   PALMER C, 2007, P INT C MUS COMM SCI, P119
   Palmer C, 2009, MUSIC PERCEPT, V26, P439, DOI 10.1525/MP.2009.26.5.439
   Panksepp J., 1998, AFFECTIVE NEUROSCIEN
   Panksepp J, 2011, EMOT REV, V3, P387, DOI 10.1177/1754073911410741
   Parncutt R, 1997, MUSIC PERCEPT, V14, P341
   Patel A. D., 2008, Music, Language, and the Brain
   Perkell JS, 2002, J ACOUST SOC AM, V112, P1627, DOI 10.1121/1.1506369
   Rainville P, 2006, INT J PSYCHOPHYSIOL, V61, P5, DOI 10.1016/j.ijpsycho.2005.10.024
   Repp B. H., 1994, PSYCHOL MUSIC, V22, P157, DOI [10.1177/0305735694222005, DOI 10.1177/0305735694222005]
   REPP BH, 1995, J ACOUST SOC AM, V98, P2413, DOI 10.1121/1.413276
   Repp BH, 1996, J ACOUST SOC AM, V100, P641, DOI 10.1121/1.415889
   REPP BH, 1992, J ACOUST SOC AM, V92, P2546, DOI 10.1121/1.404425
   REPP BH, 1994, PSYCHOL RES-PSYCH FO, V56, P269, DOI 10.1007/BF00419657
   REPP BH, 1992, MUSIC PERCEPT, V10, P221
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   S?ndor G., 1981, PIANO PLAYING MOTION
   Scherer K. R., 1979, EMOTIONS PERSONALITY, P493, DOI DOI 10.1007/978-1-4613-2892-6_18
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   SCHWARTZ GE, 1981, PSYCHOSOM MED, V43, P343, DOI 10.1097/00006842-198108000-00007
   Scotto di Carlo N, 2004, SEMIOTICA, V149, P37
   Seifert U, 2013, STRUNGMANN FORUM REP, P203
   STEIN RB, 1982, BEHAV BRAIN SCI, V5, P535, DOI 10.1017/S0140525X00013327
   Steinbeis N, 2008, CEREB CORTEX, V18, P1169, DOI 10.1093/cercor/bhm149
   Sundberg J, 2000, J NEW MUSIC RES, V29, P183, DOI 10.1076/jnmr.29.3.183.3089
   SUNDBERG J, 1982, MUSIC MIND BRAIN NEU, P137
   Tortora G. J., 2002, PRINCIPLES HUMAN ANA
   Uchanski RM., 2008, Handb Speech Percept, P207, DOI DOI 10.1111/B.9780631229278.2004.00012.X
   van Vugt FT, 2014, EXP BRAIN RES, V232, P3555, DOI 10.1007/s00221-014-4036-4
   Ververidis D, 2006, SPEECH COMMUN, V48, P1162, DOI 10.1016/j.specom.2006.04.003
   WESTBURY JR, 1986, J LINGUIST, V22, P145, DOI 10.1017/S0022226700010598
   Widmer G, 2004, J NEW MUSIC RES, V33, P203, DOI 10.1080/0929821042000317804
   Wilson G. D., 1994, Psychology for performing artists: Butterflies and bouquets
   Winges SA, 2013, J NEUROPHYSIOL, V110, P230, DOI 10.1152/jn.00973.2012
   Xu Y., 2013, PROSODY ICONICITY, P33, DOI DOI 10.1075/ILL.13.02XU
   Xu Y., 2014, PROSODYPRO PRAAT
   Xu Y, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0062397
   Xu Y, 2009, J PHONETICS, V37, P502, DOI 10.1016/j.wocn.2009.08.003
   Zachar P., 2012, CATEGORICAL VERSUS D
   Zanon P, 2003, J NEW MUSIC RES, V32, P295, DOI 10.1076/jnmr.32.3.295.16869
   Zanon P, 2003, COMPUT MUSIC J, V27, P29, DOI 10.1162/01489260360613326
NR 110
TC 0
Z9 0
U1 0
U2 15
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD JUL 8
PY 2015
VL 6
AR 886
DI 10.3389/fpsyg.2015.00886
PG 13
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA CM4BN
UT WOS:000357629300001
PM 26217252
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Hämäläinen, S
   Musial, F
   Graff, O
   Olsen, TA
   Salamonsen, A
AF Hamalainen, Soile
   Musial, Frauke
   Graff, Ola
   Olsen, Torjer A.
   Salamonsen, Anita
TI Yoik experiences and possible positive health outcomes: an explorative
   pilot study
SO INTERNATIONAL JOURNAL OF CIRCUMPOLAR HEALTH
LA English
DT Article
DE Culture-sensitive research; emotion management; health and well being;
   indigenous methodology; music and health; Norway; Sami; yoik experience;
   yoik
ID CARE
AB Background: Yoik is an old vocal music tradition of Sami, the indigenous people inhabiting Northern Fennoscandia and Kola peninsula in Russia. Studies of music therapy (MT) and especially singing have documented improvements in social and overall functioning in people with severe mental disorders and positive effect on depressive symptoms and sleep quality. Possible connections between yoik and health are so far underexplored.
   Objectives: The overall aim of this study was to explore whether yoik may have the potential to positively influence people's health and well-being. The research questions were: 1. What are different persons' experiences with yoik? 2. Can yoik experiences be related to health outcomes?
   Methods: Explorative, qualitative interviews with 13 participants were conducted in the Norwegian counties Finnmark, Troms, Nordland, and Trondelag.
   Findings: The findings suggest qualities in yoik that are comparable to positive effects of Music Therapy (MT) in general. Yoik may contribute to emotion management, i.e. processing negative emotions and inducing positive ones in people acknowledging yoik as something positive.
   Conclusion: Yoik may be considered an important marker of social and cultural belonging for many Sami people. Yoik seems to have an underresearched potential as an intervention in culture sensitive healthcare and health promotion work that deserves to be further investigated.
C1 [Hamalainen, Soile; Musial, Frauke; Salamonsen, Anita] UiT Arctic Univ Norway, Nat Res Ctr Complementary & Alternat Med, Fac Hlth Sci, Dept Community Med, Tromso, Norway.
   [Graff, Ola] Univ Museum Tromso, UiT Arctic Univ Norway, Tromso, Norway.
   [Olsen, Torjer A.] UiT Arctic Univ Norway, Ctr Sami Studies, Fac Human Soc Sci & Educ, Tromso, Norway.
   UiT Norges arktiske Univ, NAFKAM, Postboks 6050 Langnes, N-9037 Tromso, Norway.
C3 UiT The Arctic University of Tromso; UiT The Arctic University of
   Tromso; UiT The Arctic University of Tromso; UiT The Arctic University
   of Tromso
RP Salamonsen, A (corresponding author), UiT Norges arktiske Univ, NAFKAM, Postboks 6050 Langnes, N-9037 Tromso, Norway.
EM anita.salamonsen@uit.no
CR American Music Therapy Association, What is Music Therapy?
   [Anonymous], 1989, The Practice of Social Research
   [Anonymous], 2002, SAMENE NORDKALOTTENS
   [Anonymous], 2001, OFF NORW REP DEP JUS
   Antonovsky A., 1988, PEOPLE MANAGE STRESS
   Bassett Deborah, 2012, Perm J, V16, P19
   Battiste Marie., 2008, Handbook of Critical and Indigenous Methodologies, P497, DOI [10.4135/9781483385686, DOI 10.4135/9781483385686]
   Blix BH, 2013, THESIS
   BRADT J, 2014, COCHRANE DB SYST REV, V2014, P1, DOI DOI 10.1002/14651858
   Brantenberg T., 2014, SAMI STORIES ART IDE, P37
   Breedlove MS, 2007, BIOL PSYCHOL INTRO B
   Buljo KA, 1998, TROLLSTILT LAEREBOK, P137
   Chilisa Bagele, 2019, Indigenous research methodologies
   Choi K, 2011, MIND BODY MED, P70
   Clift SM, 2001, J R SOC PROMO HEALTH, V121, P248, DOI 10.1177/146642400112100409
   Crawford O'Brien S, RELIG HEALING NATIVE
   Daling G., 2014, SLIK VI SER MUSIKK M, P158
   Daly Berman AE, 2015, VOICES, V15, P3, DOI 10.15845/voices.v15i3.828
   Dassa A, 2014, J MUSIC THER, V51, P131, DOI 10.1093/jmt/thu007
   Denzin NK, 2003, The landscape of qualitative research, V2nd
   Edstrom O., 2003, STUD MUSICOL, V44, P269
   Eliassen BM, 2012, BMC PUBLIC HEALTH, V12, DOI 10.1186/1471-2458-12-948
   Gobo G., 2008, Doing ethnography
   Graff O., 2004, KJAERESTEN MIN VIL J
   Graff O., 2016, JOIKEFORBUDET KAUTOK
   Grande Sandy, 2008, HDB CRITICAL INDIGEN
   Hansen KL, 2015, INT J CIRCUMPOL HEAL, V74, DOI 10.3402/ijch.v74.25125
   Hansen LI, 2014, SAMENES HIST FRAM 17
   Hanssen I., 2011, J INTERCULTURAL COMM, DOI DOI 10.1111/J.1471-6712.2012.01021.X
   Higginbottom GMA, 2005, QUAL REP, V10, P662
   Hilder TR, 2015, SAMI MUSICAL PERFORM
   Holter Brudal L., 2014, EMPATISK KOMMUNIKASJ
   Hsieh HF, 2005, QUAL HEALTH RES, V15, P1277, DOI 10.1177/1049732305276687
   Jernsletten N., 1978, BY BYGD NORSK FOLKEM, P109
   Jones-Bamman RW, 1993, THESIS
   Juslin P. N., 2010, Handbook of music and emotion: Theory, research, applications, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0022
   Kamioka H, 2014, PATIENT PREFER ADHER, V8, P727, DOI 10.2147/PPA.S61340
   Kvale S., 1996, InterViews: An introduction to qualitative research interviewing
   Kvamme TS, 2014, DEMENS ALDERSPSYKIAT, V18, P10
   Minde H., 2003, Acta Borealia, V20, P121, DOI DOI 10.1080/08003830310002877
   Minichiello V., 1990, IN DEPTH INTERVIEWIN
   Mishler E. G., 1986, Research interviewing: Context and narratives
   Moore KS, 2013, J MUSIC THER, V50, P198, DOI 10.1093/jmt/50.3.198
   Murray SA, 2009, BRIT MED J, V339, DOI 10.1136/bmj.b3702
   Myskja A., 2011, THESIS
   Myskja A., 2004, TIDSSKRIFT NORSKE LE, V24, P3229
   Myskja Audun, 2005, Tidsskr Nor Laegeforen, V125, P1497
   O'Brien RL, 2006, J NATL MED ASSOC, V98, P674
   Omma L, 2013, INT J CIRCUMPOL HEAL, V72, DOI 10.3402/ijch.v72i0.19862
   Pedersen P, 2012, Sapmi slar tilbake. Samiske revitalisering- og moderniseringsprosesser i siste generasjon [Sapmi hits back. Sami revitalizing and modernization processes in the last generation]
   Salamonsen A, 2012, QUAL HEALTH RES, V22, P1497, DOI 10.1177/1049732312457077
   Särkämö T, 2014, GERONTOLOGIST, V54, P634, DOI 10.1093/geront/gnt100
   Sexton R, 2008, INT J CIRCUMPOL HEAL, V67, P135
   Stuckey HL, 2010, AM J PUBLIC HEALTH, V100, P254, DOI 10.2105/AJPH.2008.156497
   Szomjas-Schiffert G., 1973, YB INT FOLK MUSIC CO, V5, P51
   Todres L, 2009, INT J QUAL STUD HEAL, V4, P68, DOI 10.1080/17482620802646204
   Tucker CM, 2011, HEALTH PSYCHOL, V30, P342, DOI 10.1037/a0022967
   Wan CY, 2010, MUSIC PERCEPT, V27, P287, DOI 10.1525/MP.2010.27.4.287
NR 58
TC 7
Z9 8
U1 0
U2 7
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1239-9736
EI 2242-3982
J9 INT J CIRCUMPOL HEAL
JI Int. J. Circumpolar Health
PY 2017
VL 76
AR 1271590
DI 10.1080/22423982.2016.1271590
PG 9
WC Public, Environmental & Occupational Health
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Public, Environmental & Occupational Health
GA EN7BU
UT WOS:000396157900001
PM 28452679
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Yilmazyildiz, S
   Read, R
   Belpeame, T
   Verhelst, W
AF Yilmazyildiz, Selma
   Read, Robin
   Belpeame, Tony
   Verhelst, Werner
TI Review of Semantic-Free Utterances in Social Human-Robot Interaction
SO INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION
LA English
DT Article
ID VOCAL COMMUNICATION; AUDITORY DISPLAYS; AGENTS ATTITUDES; EMOTION;
   EXPRESSION; INFORMATION; PERCEPTION; LANGUAGE; MUSIC; RECOGNITION
AB As a young and emerging field in social human-robot interaction (HRI), semantic-free utterances (SFUs) research has been receiving attention over the last decade. SFUs are an auditory interaction means for machines that allow emotion and intent expression, which are composed of vocalizations and sounds without semantic content or language dependence. Currently, SFUs are most commonly utilized in animation movies (e.g., R2-D2, WALL-E, Despicable Me), cartoons (e.g., "Teletubbies," "Morph," "La Linea"), and computer games (e.g., The Sims) and hold significant potential for applications in HRI. SFUs are categorized under four general types: Gibberish Speech (GS), Non-Linguistic Utterances (NLUs), Musical Utterances (MU), and Paralinguistic Utterances (PU). By introducing the concept of SFUs and bringing multiple sets of studies in social HRI that have never been analyzed jointly before, this article addresses the need for a comprehensive study of the existing literature for SFUs. It outlines the current grand challenges, open questions, and provides guidelines for future researchers considering to utilize SFU in social HRI.
C1 [Yilmazyildiz, Selma; Verhelst, Werner] Vrije Univ Brussel, Dept Elect & Informat, B-1050 Brussels, Belgium.
   [Read, Robin; Belpeame, Tony] Univ Plymouth, Ctr Robot & Neural Syst, Plymouth PL4 8AA, Devon, England.
   [Verhelst, Werner] IMinds, Future Media & Imaging Dept, Ghent, Belgium.
C3 Vrije Universiteit Brussel; University of Plymouth; IMEC
RP Yilmazyildiz, S (corresponding author), Vrije Univ Brussel, Dept Elect & Informat, Pl Laan 2, B-1050 Brussels, Belgium.
EM syilmazy@etro.vub.ac.be
RI YILMAZYILDIZ KAYAARMA, Selma/IWE-0237-2023
OI YILMAZYILDIZ KAYAARMA, Selma/0000-0001-7315-3639
CR Alty James L., 2005, INT C AUD DISPL, P351
   [Anonymous], 15 IEEE INT S ROB HU
   [Anonymous], 2004, LINGUISTIC STEGANOGR
   [Anonymous], 1984, Codes, Ciphers, and Secret Writing
   [Anonymous], 2000, INT TUTORIAL RES WOR
   [Anonymous], ICGST INT J AUT ROB
   [Anonymous], 2013, P 12 INT C AUTONOMOU
   [Anonymous], 2000, SOCIABLE MACHINES EX
   [Anonymous], 2008, J PHYS AGENTS, DOI DOI 10.14198/JoPha.2008.2.2.02
   [Anonymous], TRANSITION LANGUAGE
   Arslan LM, 1998, INT CONF ACOUST SPEE, P289, DOI 10.1109/ICASSP.1998.674424
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Barker J, 1999, SPEECH COMMUN, V27, P159, DOI 10.1016/S0167-6393(98)00081-8
   Bartneck C., 2001, P 2001 ROB
   Beck A, 2013, INT J SOC ROBOT, V5, P325, DOI 10.1007/s12369-013-0193-z
   Becker-Asano C., 2009, INT WORKSH SOC INT D, P287
   Becker-Asano C, 2011, AI SOC, V26, P291, DOI 10.1007/s00146-010-0306-2
   Belpaeme T, 2012, J HUM-ROBOT INTERACT, V1, P33, DOI 10.5898/JHRI.1.2.Belpaeme
   Belpaeme T, 2013, LECT NOTES ARTIF INT, V8239, P452, DOI 10.1007/978-3-319-02675-6_45
   Blattner M. M., 1989, Human-Computer Interaction, V4, P11, DOI 10.1207/s15327051hci0401_1
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Bramas Berenger, 2008, 2008 International Conference on Control, Automation and Systems (ICCAS), P2732, DOI 10.1109/ICCAS.2008.4694222
   Breazeal C. L., 2002, DESIGNING SOCIAL ROB
   Breazeal C, 2013, J HUM-ROBOT INTERACT, V2, P82, DOI 10.5898/JHRI.2.1.Breazeal
   Broekens J, 2013, INT J HUM-COMPUT ST, V71, P641, DOI 10.1016/j.ijhcs.2013.02.003
   Brooks AG, 2007, AUTON ROBOT, V22, P55, DOI 10.1007/s10514-006-9005-8
   Brown S, 2000, ORIGINS OF MUSIC, P271
   Burkhardt F., 2000, ISCA TUT RES WORKSH
   Cahn J. E., 1990, Journal of the American Voice I/O Society, V8, P1
   Chao C, 2013, J HUM-ROBOT INTERACT, V2, P4, DOI 10.5898/JHRI.2.1.Chao
   CHOMSKY N, 1956, IRE T INFORM THEOR, V2, P113
   Connell JH, 2015, ROBOTS THAT TALK AND LISTEN: TECHNOLOGY AND SOCIAL IMPACT, P175
   Cowie R, 2003, SPEECH COMMUN, V40, P5, DOI 10.1016/S0167-6393(02)00071-7
   D'Mello S, 2005, 2005 IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN), P184
   Deits R, 2013, J HUM-ROBOT INTERACT, V2, P58, DOI 10.5898/JHRI.2.2.Deits
   Delaunay F, 2010, ACMIEEE INT CONF HUM, P39, DOI 10.1109/HRI.2010.5453271
   Dingler T., 2008, CVPR
   Dombois F, 2011, SONIFICATION HDB, P301
   Duffy B. R., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P484, DOI 10.1109/ROMAN.2012.6343798
   Duffy BR, 2003, ROBOT AUTON SYST, V42, P177, DOI 10.1016/S0921-8890(02)00374-3
   DUTOIT T, 1993, SPEECH COMMUN, V13, P435, DOI 10.1016/0167-6393(93)90042-J
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Embgen S., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P1019, DOI 10.1109/ROMAN.2012.6343883
   Esnaola U, 2005, 2005 IEEE International Symposium on Computational Intelligence in Robotics and Automation, Proceedings, P67, DOI 10.1109/CIRA.2005.1554256
   Eun-Sook Jee, 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P369, DOI 10.1109/ROMAN.2009.5326258
   Eun-Sook Jee, 2007, 16th IEEE International Conference on Robot and Human Interactive Communication, P637
   Fridin M, 2014, INT J HUM-COMPUT INT, V30, P459, DOI 10.1080/10447318.2014.888500
   Friend M, 2000, DEVELOPMENTAL SCI, V3, P148, DOI 10.1111/1467-7687.00108
   Gabsdil M., 2003, P 2003 AAAI SPRING S, P28
   Gaver W. W., 1986, HUMAN COMPUTER INTER, V2, P167, DOI [DOI 10.1207/S15327051HCI0202_3, 10.1207/s15327051hci0202_3]
   Goodrich Michael A., 2007, Foundations and Trends in Human-Computer Interaction, V1, P203, DOI 10.1561/1100000005
   Gorostiza JF, 2011, ROBOT AUTON SYST, V59, P1102, DOI 10.1016/j.robot.2011.07.009
   Haring M., 2011, 2011 RO-MAN: The 20th IEEE International Symposium on Robot and Human Interactive Communication, P204, DOI 10.1109/ROMAN.2011.6005263
   Hermann, 2011, SONIFICATION HDB
   Holzapfel H, 2004, IEEE-RAS INT C HUMAN, P184
   Imai M, 2003, INT J HUM-COMPUT INT, V16, P367, DOI 10.1207/S15327590IJHC1602_12
   Jee ES, 2010, INTEL SERV ROBOT, V3, P199, DOI 10.1007/s11370-010-0070-7
   Johannsen G, 2004, P IEEE, V92, P742, DOI 10.1109/JPROC.2004.825905
   Johannsen G, 2001, J INTELL ROBOT SYST, V32, P161, DOI 10.1023/A:1013953213049
   JOHANNSEN G, 2002, P 8 INT C AUD DISPL, P98
   JOHNSON WF, 1986, ARCH GEN PSYCHIAT, V43, P280
   Jung HM, 2005, LECT NOTES COMPUT SC, V3513, P337
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Knoll MA, 2009, SPEECH COMMUN, V51, P210, DOI 10.1016/j.specom.2008.08.001
   Kobayashi T, 2013, ACOUST SCI TECHNOL, V34, P64, DOI 10.1250/ast.34.64
   Komatsu T, 2005, LECT NOTES COMPUT SC, V3784, P458
   Komatsu T., 2007, INT C ADV COMP ENT T, P123
   Komatsu T, 2012, P C HUM FACT COMP SY, P1595
   Komatsu T, 2011, INT J HUM-COMPUT INT, V27, P260, DOI 10.1080/10447318.2011.537209
   Komatsu T, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1941
   Komatsu T, 2008, IEEE C EVOL COMPUTAT, P1935, DOI 10.1109/CEC.2008.4631053
   Kozima H, 2009, INT J SOC ROBOT, V1, P3, DOI 10.1007/s12369-008-0009-8
   Krosnick JA, 2002, PUBLIC OPIN QUART, V66, P371
   Laukka P, 2005, EMOTION, V5, P277, DOI 10.1037/1528-3542.5.3.277
   Lee MK, 2010, ACMIEEE INT CONF HUM, P203, DOI 10.1109/HRI.2010.5453195
   Leite I, 2008, 2008 17TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1 AND 2, P77, DOI 10.1109/ROMAN.2008.4600646
   Libin AV, 2004, P IEEE, V92, P1789, DOI 10.1109/JPROC.2004.835366
   Lison P, 2009, LECT NOTES ARTIF INT, V5803, P241, DOI 10.1007/978-3-642-04617-9_31
   Lohse M, 2008, IEEE INT CONF ROBOT, P3481, DOI 10.1109/ROBOT.2008.4543743
   McCartney J, 2002, COMPUT MUSIC J, V26, P61, DOI 10.1162/014892602320991383
   Moore RK, 2014, LECT NOTES COMPUT SC, V8791, P21, DOI 10.1007/978-3-319-11397-5_2
   Mozos O. M., 2007, P IEEE INT C ROB AUT, P33
   Mubin O, 2009, SPOK DIAL HUM ROB IN
   Mubin O, 2010, LECT NOTES ARTIF INT, V6233, P250, DOI 10.1007/978-3-642-14770-8_28
   Mumm J, 2011, ACMIEEE INT CONF HUM, P331, DOI 10.1145/1957656.1957786
   Murray IR, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1816, DOI 10.1109/ICSLP.1996.607983
   MURRAY IR, 1995, SPEECH COMMUN, V16, P369, DOI 10.1016/0167-6393(95)00005-9
   Nemeth G., 2011, ICAD 2011 JUN BUD, P1
   Olaszy G., 2000, International Journal of Speech Technology, V3, P201, DOI 10.1023/A:1026558915015
   Paepcke S, 2010, ACMIEEE INT CONF HUM, P45, DOI 10.1109/HRI.2010.5453268
   Palladino D.K., 2007, P 13 INT C AUD DISPL, P274
   Paulmann S, 2011, MOTIV EMOTION, V35, P192, DOI 10.1007/s11031-011-9206-0
   Pell MD, 2009, J PHONETICS, V37, P417, DOI 10.1016/j.wocn.2009.07.005
   Picard R., 1997, Affective Computing
   Pierre-Yves O, 2003, INT J HUM-COMPUT ST, V59, P157, DOI 10.1016/S1071-5819(03)00141-6
   Prendinger H, 2006, INT J HUM ROBOT, V3, P371, DOI 10.1142/S0219843606000801
   Rae I, 2013, ACMIEEE INT CONF HUM, P1, DOI 10.1109/HRI.2013.6483495
   Rastle K, 2002, Q J EXP PSYCHOL-A, V55, P1339, DOI 10.1080/02724980244000099
   Read R, 2014, ACMIEEE INT CONF HUM, P41, DOI 10.1145/2559636.2559680
   Read R, 2013, ACMIEEE INT CONF HUM, P209, DOI 10.1109/HRI.2013.6483575
   Read R, 2012, ACMIEEE INT CONF HUM, P219
   Read Robin G., 2010, Proceedings: 3rd International Workshop on Affective Interaction in Natural Environments (AFFINE), Firenze, Italy, P65
   REMEZ RE, 1993, J ACOUST SOC AM, V94, P1983, DOI 10.1121/1.407501
   REMEZ RE, 1981, SCIENCE, V212, P947, DOI 10.1126/science.7233191
   Ribeiro T, 2012, ACMIEEE INT CONF HUM, P383
   Robins B, 2004, INTERACT STUD, V5, P161, DOI 10.1075/is.5.2.02rob
   Ros R., 2011, P INT C MULT INT, P335, DOI DOI 10.1145/2070481.2070545
   Saerbeck M, 2010, ACMIEEE INT CONF HUM, P53, DOI 10.1109/HRI.2010.5453269
   Scherer K., 1977, MOTIV EMOTION, V1, P331, DOI [DOI 10.1007/BF00992539, 10.1007/bf00992539]
   SCHERER KR, 1971, J EXP RES PERS, V5, P155
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   SCHERER KR, 1972, J PSYCHOLINGUIST RES, V1, P269, DOI 10.1007/BF01074443
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   SCHERER KR, 1985, ADV STUD BEHAV, V15, P189, DOI 10.1016/S0065-3454(08)60490-8
   SCHERER KR, 1994, EMOTIONS: ESSAYS ON EMOTION THEORY, P161
   SCHERER KR, 1982, HDB METHODS NONVERBA, P136
   Schröber M, 2003, SPEECH COMMUN, V40, P99, DOI 10.1016/S0167-6393(02)00078-X
   Schroder M., 2010, BLUEPRINT AFFECTIVE, P222
   Schroder M., 2001, P 7 EUR C SPEECH COM, P2, DOI [10.1002/hyp.6973, DOI 10.1002/HYP.6973]
   Schroder M., 2003, THESIS
   Schröder M, 2012, IEEE T AFFECT COMPUT, V3, P165, DOI 10.1109/T-AFFC.2011.34
   Schuller B., 2014, COMPUTATIONAL PARALI
   Schwenk M, 2014, IEEE ROMAN, P161, DOI 10.1109/ROMAN.2014.6926247
   Seo SH, 2015, ACMIEEE INT CONF HUM, P125, DOI 10.1145/2696454.2696471
   Shiwa T, 2009, INT J SOC ROBOT, V1, P141, DOI 10.1007/s12369-009-0012-8
   Silva-Pereyra J, 2007, J COGNITIVE NEUROSCI, V19, P1050, DOI 10.1162/jocn.2007.19.6.1050
   Singh A, 2012, ACMIEEE INT CONF HUM, P237
   Snel J, 2013, INT CONF AFFECT, P336, DOI 10.1109/ACII.2013.62
   Steels L, 2003, TRENDS COGN SCI, V7, P308, DOI 10.1016/S1364-6613(03)00129-3
   Takayama L, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P5495, DOI 10.1109/IROS.2009.5354145
   Teshigawara M., 2007, 16 INT C PHON SCI, P2101
   Theobalt C, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P1338, DOI 10.1109/IRDS.2002.1043940
   Tickle A., 2000, ISCA WORKSH SPEECH E, P157
   Trouvain J, 2004, LECT NOTES COMPUT SC, V3068, P229
   Trovato G, 2013, INT J HUM ROBOT, V10, DOI 10.1142/S0219843613500138
   Van Tassel D, 1969, P AFIPS, P367
   Vatsa A., 2012, INT J INFORM NETWORK, V1, P313
   Vázquez M, 2014, ACMIEEE INT CONF HUM, P391, DOI 10.1145/2559636.2559684
   Vickers P, 2002, INTERACT COMPUT, V14, P435, DOI 10.1016/S0953-5438(02)00003-6
   Walker Bruce N, 2006, SPEARCONS SPEECH BAS
   Walters ML, 2008, AUTON ROBOT, V24, P159, DOI 10.1007/s10514-007-9058-3
   Wang W., 2014, 4 WORKSH CHILD COMP
   Ward N, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1728, DOI 10.1109/ICSLP.1996.607961
   Yilmazyildiz S., 2006, THESIS
   Yilmazyildiz S., 2013, P WORKSH AFF SOC SPE
   Yilmazyildiz S, 2006, LECT NOTES COMPUT SC, V4261, P1
   Yilmazyildiz S, 2011, LECT NOTES COMPUT SC, V6975, P163, DOI 10.1007/978-3-642-24571-8_17
   Yilmazyildiz S, 2010, LECT NOTES ARTIF INT, V6231, P584, DOI 10.1007/978-3-642-15760-8_74
NR 149
TC 48
Z9 51
U1 0
U2 24
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 1044-7318
EI 1532-7590
J9 INT J HUM-COMPUT INT
JI Int. J. Hum.-Comput. Interact.
PY 2016
VL 32
IS 1
BP 63
EP 85
DI 10.1080/10447318.2015.1093856
PG 23
WC Computer Science, Cybernetics; Ergonomics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA DA4XH
UT WOS:000367805500006
DA 2024-01-09
ER

PT J
AU Brown, LS
AF Brown, Laura S.
TI The Influence of Music on Facial Emotion Recognition in Children with
   Autism Spectrum Disorder and Neurotypical Children
SO JOURNAL OF MUSIC THERAPY
LA English
DT Article
ID EXPRESSIONS; INDIVIDUALS; ADOLESCENTS; FACES; INTERVENTION; PERFORMANCE;
   PERCEPTION; JUDGMENTS; DEFICITS; VOICE
AB Background: Children with autism spectrum disorder (ASD) often struggle with social skills, including the ability to perceive emotions based on facial expressions. Research evidence suggests that many individuals with ASD can perceive emotion in music. Examining whether music can be used to enhance recognition of facial emotion by children with ASD would inform development of music therapy interventions.
   Objective: The purpose of this study was to investigate the influence of music with a strong emotional valance (happy; sad) on children with ASD's ability to label emotions depicted in facial photographs, and their response time.
   Methods: Thirty neurotypical children and 20 children with high-functioning ASD rated expressions of happy, neutral, and sad in 30 photographs under two music listening conditions (sad music; happy music). During each music listening condition, participants rated the 30 images using a 7-point scale that ranged from very sad to very happy. Response time data were also collected across both conditions.
   Results: A significant two-way interaction revealed that participants' ratings of happy and neutral faces were unaffected by music conditions, but sad faces were perceived to be sadder with sad music than with happy music. Across both conditions, neurotypical children rated the happy faces as happier and the sad faces as sadder than did participants with ASD. Response times of the neurotypical children were consistently shorter than response times of the children with ASD; both groups took longer to rate sad faces than happy faces. Response times of neurotypical children were generally unaffected by the valence of the music condition; however, children with ASD took longer to respond when listening to sad music.
   Conclusions: Music appears to affect perceptions of emotion in children with ASD, and perceptions of sad facial expressions seem to be more affected by emotionally congruent background music than are perceptions of happy or neutral faces.
C1 [Brown, Laura S.] Ohio Univ, Athens, OH 45701 USA.
C3 University System of Ohio; Ohio University
RP Brown, LS (corresponding author), Ohio Univ, Athens, OH 45701 USA.
EM BrownL5@ohio.edu
CR Abboud H., 2012, SUPERLAB
   Allen R, 2013, J AUTISM DEV DISORD, V43, P432, DOI 10.1007/s10803-012-1587-8
   Altenmüller E, 2002, NEUROPSYCHOLOGIA, V40, P2242, DOI 10.1016/S0028-3932(02)00107-0
   [Anonymous], MUSIC MED
   Association A. P., 2013, DIAGN STAT MAN MENT, DOI [10.1176/appi.books.9780890425596, DOI 10.1176/APPI.BOOKS.9780890425596]
   Brown LS, 2012, J MUSIC THER, V49, P335, DOI 10.1093/jmt/49.3.335
   Caria A, 2011, CEREB CORTEX, V21, P2838, DOI 10.1093/cercor/bhr084
   Castelli F, 2005, AUTISM, V9, P428, DOI 10.1177/1362361305056082
   Celani G, 1999, J AUTISM DEV DISORD, V29, P57, DOI 10.1023/A:1025970600181
   Dyck MJ, 2006, J CLIN CHILD ADOLESC, V35, P20, DOI 10.1207/s15374424jccp3501_3
   Ekman P, 1976, Pictures of facial affect
   Elfenbein HA, 2002, PSYCHOL BULL, V128, P203, DOI 10.1037//0033-2909.128.2.203
   Gepner B, 2001, J AUTISM DEV DISORD, V31, P37, DOI 10.1023/A:1005609629218
   Geretsegger M, 2014, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD004381.pub3
   Gross TF, 2004, J ABNORM CHILD PSYCH, V32, P469, DOI 10.1023/B:JACP.0000037777.17698.01
   Hall GBC, 2003, AM J PSYCHIAT, V160, P1439, DOI 10.1176/appi.ajp.160.8.1439
   Harms MB, 2010, NEUROPSYCHOL REV, V20, P290, DOI 10.1007/s11065-010-9138-6
   Heaton P, 1999, PSYCHOL MED, V29, P1405, DOI 10.1017/S0033291799001221
   Heaton P, 2008, BRIT J DEV PSYCHOL, V26, P171, DOI 10.1348/026151007X206776
   Henley SJ, 2014, MMWR-MORBID MORTAL W, V63, P1
   Hubl D, 2003, NEUROLOGY, V61, P1232, DOI 10.1212/01.WNL.0000091862.22033.1A
   Jones CRG, 2011, J CHILD PSYCHOL PSYC, V52, P275, DOI 10.1111/j.1469-7610.2010.02328.x
   Jones W, 2008, ARCH GEN PSYCHIAT, V65, P946, DOI 10.1001/archpsyc.65.8.946
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kahana-Kalman R, 2008, RES AUTISM SPECT DIS, V2, P301, DOI 10.1016/j.rasd.2007.07.004
   KANNER L, 1968, ACTA PAEDOPSYCHIATR, V35, P100
   Katagiri J, 2009, J MUSIC THER, V46, P15, DOI 10.1093/jmt/46.1.15
   Kern P, 2013, J MUSIC THER, V50, P274, DOI 10.1093/jmt/50.4.274
   Klin A, 2002, ARCH GEN PSYCHIAT, V59, P809, DOI 10.1001/archpsyc.59.9.809
   LaGasse AB, 2014, J MUSIC THER, V51, P250, DOI 10.1093/jmt/thu012
   Lindner JL, 2006, J AUTISM DEV DISORD, V36, P769, DOI 10.1007/s10803-006-0105-2
   Logeswaran N, 2009, NEUROSCI LETT, V455, P129, DOI 10.1016/j.neulet.2009.03.044
   Loveland KA, 2008, PERCEPT MOTOR SKILL, V107, P557, DOI 10.2466/PMS.107.2.557-575
   Magnée MJCM, 2008, CLIN NEUROPHYSIOL, V119, P2004, DOI 10.1016/j.clinph.2008.05.005
   Massaro DW, 1996, PSYCHON B REV, V3, P215, DOI 10.3758/BF03212421
   Mitterschiffthaler MT, 2007, HUM BRAIN MAPP, V28, P1150, DOI 10.1002/hbm.20337
   New York Philharmonic, 2004, ROM FAV STRINGS
   Oberman LM, 2008, NEUROPSYCHOLOGIA, V46, P1558, DOI 10.1016/j.neuropsychologia.2008.01.010
   Pelphrey KA, 2002, J AUTISM DEV DISORD, V32, P249, DOI 10.1023/A:1016374617369
   Philip RCM, 2010, PSYCHOL MED, V40, P1919, DOI 10.1017/S0033291709992364
   Pierce K, 2008, BIOL PSYCHIAT, V64, P552, DOI 10.1016/j.biopsych.2008.05.013
   Quintin EM, 2011, J AUTISM DEV DISORD, V41, P1240, DOI 10.1007/s10803-010-1146-0
   Rosset DB, 2008, J AUTISM DEV DISORD, V38, P919, DOI 10.1007/s10803-007-0465-2
   Salzburg Chamber Orchestra, 1991, THEAS LIGHT CLASS
   Schultz RT, 2000, ARCH GEN PSYCHIAT, V57, P331, DOI 10.1001/archpsyc.57.4.331
   Thompson WF, 2005, SEMIOTICA, V156, P203, DOI 10.1515/semi.2005.2005.156.203
   Thompson WF, 2008, COGNITION EMOTION, V22, P1457, DOI 10.1080/02699930701813974
   Tottenham N, 2009, PSYCHIAT RES, V168, P242, DOI 10.1016/j.psychres.2008.05.006
   Whipple J, 2004, J MUSIC THER, V41, P90, DOI 10.1093/jmt/41.2.90
NR 49
TC 12
Z9 16
U1 1
U2 62
PU OXFORD UNIV PRESS INC
PI CARY
PA JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA
SN 0022-2917
EI 2053-7395
J9 J MUSIC THER
JI J. Music Ther.
PD SPR
PY 2017
VL 54
IS 1
BP 55
EP 79
DI 10.1093/jmt/thw017
PG 25
WC Music; Rehabilitation
WE Social Science Citation Index (SSCI)
SC Music; Rehabilitation
GA ES0TR
UT WOS:000399240200003
PM 28040801
DA 2024-01-09
ER

PT J
AU Kaiser, D
   Silberberger, S
   Hilzendegen, C
   Stroebele-Benschop, N
AF Kaiser, Daniela
   Silberberger, Sina
   Hilzendegen, Carolin
   Stroebele-Benschop, Nanette
TI The influence of music type and transmission mode on food intake and
   meal duration: An experimental study
SO PSYCHOLOGY OF MUSIC
LA English
DT Article
DE auditory stimuli; emotional arousal; food intake; meal duration; music
ID ENVIRONMENTAL-FACTORS; BACKGROUND MUSIC; CONSUMPTION; DISTRACTION;
   INCREASES; BEHAVIOR; HEADPHONES; TEMPO; SOUND; TASTE
AB The influence of auditory stimuli and their transmission mode on food intake and meal duration was assessed in healthy adults (73 male, 74 female) under laboratory conditions. The participants (18-30 years old) were randomized to one of five lunch groups. Five conditions were compared: eating in silence (control condition), eating while listening to background music via loudspeakers, eating while listening to background music via headphones, eating while listening to pop songs with English vocals and eating while listening to pop songs with German vocals. Results showed no association between listening to songs with different emotion-arousing potential and the amount of food consumed. Within-group comparisons revealed longer meal durations while listening to English music and unfamiliar background music via headphones than while listening to familiar German pop songs. The difference with the control condition just failed to reach significance. No differences were found for transmission mode. Further studies to examine the influence of music on food intake and eating behaviour, especially under controlled conditions, are needed.
C1 [Kaiser, Daniela; Silberberger, Sina; Hilzendegen, Carolin; Stroebele-Benschop, Nanette] Univ Hohenheim, Stuttgart, Germany.
C3 University Hohenheim
RP Stroebele-Benschop, N (corresponding author), Univ Hohenheim, Dept Nutr Psychol, Fruwirthstr 12, D-70593 Stuttgart, Germany.
EM N.Stroebele@Uni-Hohenheim.de
RI Stroebele-Benschop, Nanette/JAC-0796-2023
OI Stroebele-Benschop, Nanette/0000-0002-5835-6945
CR Avila C, 2012, PSYCHOL MUSIC, V40, P84, DOI 10.1177/0305735611422672
   Bellisle F, 2004, APPETITE, V43, P175, DOI 10.1016/j.appet.2004.04.004
   Bellisle F, 2001, AM J CLIN NUTR, V74, P197
   Berthoud HR, 2012, P NUTR SOC, V71, P478, DOI 10.1017/S0029665112000602
   Brunstrom JM, 2006, BRIT J NUTR, V96, P761, DOI 10.1079//BJN20061880
   Caldwell C, 2002, PSYCHOL MARKET, V19, P895, DOI 10.1002/mar.10043
   Crisinel AS, 2012, FOOD QUAL PREFER, V24, P201, DOI 10.1016/j.foodqual.2011.08.009
   Fairclough SH, 2014, PHYSIOL BEHAV, V129, P173, DOI 10.1016/j.physbeh.2014.02.049
   Fiegel A, 2014, APPETITE, V76, P144, DOI 10.1016/j.appet.2014.01.079
   Guéguen N, 2008, ALCOHOL CLIN EXP RES, V32, P1795, DOI 10.1111/j.1530-0277.2008.00764.x
   Hetherington MM, 2007, P NUTR SOC, V66, P113, DOI 10.1017/S0029665107005344
   Higgs S, 2009, APPETITE, V52, P39, DOI 10.1016/j.appet.2008.07.007
   Juslin P. N., 2011, HDB MUSIC EMOTION TH
   Juslin PN, 2013, PSYCHOLOGY OF MUSIC, THIRD EDITION, P583, DOI 10.1016/B978-0-12-381460-9.00015-8
   Kallinen K, 2007, COMPUT HUM BEHAV, V23, P303, DOI 10.1016/j.chb.2004.10.014
   Kimber K, 2015, J HUM NUTR DIET, V28, P517, DOI 10.1111/jhn.12329
   Kristjánsdóttir O, 2011, SCAND J CARING SCI, V25, P19, DOI 10.1111/j.1471-6712.2010.00784.x
   Lee KC, 2011, INT J NURS STUD, V48, P1180, DOI 10.1016/j.ijnurstu.2011.04.001
   Lenhart A., 2009, Report of the Pew Internet & American Life Project
   Lloyd DM, 2009, PERCEPTION, V38, P617, DOI 10.1068/p6317
   Loui P, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00675
   MCCARRON A, 1989, APPETITE, V13, P155, DOI 10.1016/0195-6663(89)90112-8
   Mekhmoukh A, 2012, APPETITE, V59, P90, DOI 10.1016/j.appet.2012.03.021
   MILLIMAN RE, 1986, J CONSUM RES, V13, P286, DOI 10.1086/209068
   North AC, 2012, BRIT J PSYCHOL, V103, P293, DOI 10.1111/j.2044-8295.2011.02072.x
   Oldham-Cooper RE, 2011, AM J CLIN NUTR, V93, P308, DOI 10.3945/ajcn.110.004580
   Peneau S, 2009, BRIT J NUTR, V102, P1854, DOI 10.1017/S0007114509991280
   Pereira CS, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027241
   Privitera Gregory J, 2014, Glob J Health Sci, V6, P1, DOI 10.5539/gjhs.v6n3p1
   Rickard N. S., 2004, Psychology of Music, V32, P371, DOI [10.1177%2F0305735604046096, DOI 10.1177/0305735604046096, 10.1177/0305735604046096]
   Sloboda J.A., 2010, Handbook of music and emotion: theory, research, applications, P493, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0018
   Spence C, 2013, I-PERCEPTION, V4, P137, DOI 10.1068/i0577ic
   Spence C, 2012, PHYSIOL BEHAV, V107, P505, DOI 10.1016/j.physbeh.2012.04.022
   Stafford LD, 2013, EXP CLIN PSYCHOPHARM, V21, P408, DOI 10.1037/a0034020
   Stroebele N, 2004, NUTRITION, V20, P821, DOI 10.1016/j.nut.2004.05.012
   Stroebele N, 2006, APPETITE, V47, P285, DOI 10.1016/j.appet.2006.04.001
   Thomas DW, 2009, ACT ADAPT AGING, V33, P1, DOI 10.1080/01924780902718566
   van den Bosch I, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00534
   van der Zwaag MD, 2011, MUSIC SCI, V15, P250, DOI 10.1177/1029864911403364
   VANSTRIEN T, 1986, INT J EAT DISORDER, V5, P295, DOI 10.1002/1098-108X(198602)5:2<295::AID-EAT2260050209>3.0.CO;2-T
   Wansink B, 2004, ANNU REV NUTR, V24, P455, DOI 10.1146/annurev.nutr.24.012003.132140
   Weiss MW, 2012, PSYCHOL SCI, V23, P1074, DOI 10.1177/0956797612442552
   Yalch RF, 2000, J BUS RES, V49, P139, DOI 10.1016/S0148-2963(99)00003-X
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 44
TC 11
Z9 11
U1 3
U2 23
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0305-7356
EI 1741-3087
J9 PSYCHOL MUSIC
JI Psychol. Music
PD NOV
PY 2016
VL 44
IS 6
BP 1419
EP 1430
DI 10.1177/0305735616636207
PG 12
WC Psychology, Educational; Psychology, Applied; Music; Psychology,
   Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Psychology; Music
GA EJ4TV
UT WOS:000393210700014
DA 2024-01-09
ER

PT J
AU Gemmill, K
AF Gemmill, Katie
TI Typography and Conversational Threat in Samuel Richardson's
   <i>Clarissa</i>
SO NARRATIVE
LA English
DT Article
DE Samuel Richardson; typography; print; drama; the novel; dialogue;
   musical notation; rape
AB This essay examines how Samuel Richardson turned the technologies of print towards the acoustic to produce loud characters-both aurally and emotionally- in Clarissa. Specifically, it traces his techniques for representing the embodied features of argumentative conversation back to the performative genres of drama and music. Richardson's dual professional status as a printer and a novelist meant that he was familiar with the typographical conventions particular to various genres in print and, likewise, that he was invested in the graphic scaffolding of his own novels. As such, he used print as a creative resource, mining comedies and musical dynamics for models to notate interruptive pause, simultaneous speech, and changing vocal tone and cadence in the novel's heated arguments. He uses these techniques to craft an acoustic page with visual cues to help readers hear characters' words through their eyes, and thus to perceive the emotion motivating them. I argue that Richardson figures the twin specters of bodily violation and rape through the novel's threatening conversations and that his richest resources in doing so are notational techniques adapted from specifically embodied art forms. In delineating the architecture of dramatic and musical intonation that supports novelistic dialogue in Clarissa, this essay helps to revise critical narratives about the rise of the novel, emphasizing the residue of orality in this densely literary form and asserting the continuing presence of the spoken word and performative voice in the midst of a genre we tend to think of as having made characters private, quietly read, and interior.
C1 [Gemmill, Katie] Ithaca Coll, Ithaca, NY 14850 USA.
RP Gemmill, K (corresponding author), Ithaca Coll, Ithaca, NY 14850 USA.
CR [Anonymous], 2001, PAMELA VIRTUE REWARD
   [Anonymous], 1950, S RICHARDSON MASTER
   [Anonymous], 1992, Richardson's Clarissa and the Eighteenth-Century Reader
   [Anonymous], DOUBLE DECEIT CURE J
   [Anonymous], LOVE EXCESS FATAL EN
   Barchas Janine, 2003, Graphic Design, Print Culture, and the Eighteenth-Century Novel
   Behn Aphra, 1688, Oroonoko, or The Royal Slave, a True History
   Bray Joe, 2000, MARKING TEXT PRESENT, P105
   Castle Terry, 1982, Clarissa's Ciphers: Meaning and Disruption in Richardson's Clarissa
   Centlivre Susanna, 1734, GAMESTER COMEDY IT I
   Flint Christopher, 2011, APPEARANCE PRINT 18
   Maslen Keith, 2001, S RICHARDSON LONDON
   Parkes Malcolm, 1993, Pause and Effect: As Introduction to the History ofPunctuation in the West
   Popple William, 1734, LADYS REVENGE ROVER
   Richardson Samuel, 2015, PAMELA VIRTUE REWARD
   Richardson Samuel, 1985, CLARISSA HIST YOUNG
   Sabor Peter, 2016, CORRES BRADSHAIGH EC
   Toner A, 2015, ELLIPSIS IN ENGLISH LITERATURE: SIGNS OF OMISSION, P1
   2016, EIGHTEENTH-CENTURY F, V29, P151, DOI DOI 10.3138/ECF.29.2.151
NR 19
TC 4
Z9 4
U1 0
U2 2
PU OHIO STATE UNIV PRESS
PI COLUMBUS
PA 1050 CARMACK RD, COLUMBUS, OH 43210 USA
SN 1063-3685
EI 1538-974X
J9 NARRATIVE
JI Narrative
PD MAY
PY 2019
VL 27
IS 2
BP 140
EP 159
PG 20
WC Literature
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Literature
GA HU8QW
UT WOS:000465555900002
DA 2024-01-09
ER

PT J
AU Proctor, M
   Bresch, E
   Byrd, D
   Nayak, K
   Narayanan, S
AF Proctor, Michael
   Bresch, Erik
   Byrd, Dani
   Nayak, Krishna
   Narayanan, Shrikanth
TI Paralinguistic mechanisms of production in human "beatboxing": A
   real-time magnetic resonance imaging study
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID CROSS-LANGUAGE; SPEECH; EMOTION; ARTICULATION; CONSONANTS; CLICKS; STOPS
AB Real-time Magnetic Resonance Imaging (rtMRI) was used to examine mechanisms of sound production by an American male beatbox artist. rtMRI was found to be a useful modality with which to study this form of sound production, providing a global dynamic view of the midsagittal vocal tract at frame rates sufficient to observe the movement and coordination of critical articulators. The subject's repertoire included percussion elements generated using a wide range of articulatory and airstream mechanisms. Many of the same mechanisms observed in human speech production were exploited for musical effect, including patterns of articulation that do not occur in the phonologies of the artist's native languages: ejectives and clicks. The data offer insights into the paralinguistic use of phonetic primitives and the ways in which they are coordinated in this style of musical performance. A unified formalism for describing both musical and phonetic dimensions of human vocal percussion performance is proposed. Audio and video data illustrating production and orchestration of beatboxing sound effects are provided in a companion annotated corpus. (C) 2013 Acoustical Society of America. [http://dx.doi.org/10.1121/1.4773865]
C1 [Proctor, Michael; Nayak, Krishna; Narayanan, Shrikanth] Univ So Calif, Viterbi Sch Engn, Los Angeles, CA 90089 USA.
   [Bresch, Erik] Philips Res, NL-5656 AE Eindhoven, Netherlands.
   [Byrd, Dani] Univ So Calif, Dept Linguist, Los Angeles, CA 90089 USA.
C3 University of Southern California; Philips; Philips Research; University
   of Southern California
RP Proctor, M (corresponding author), Univ Western Sydney, MARCS Inst, Locked Bag 1797, Penrith, NSW 2751, Australia.
EM michael.proctor@uws.edu.au
RI Narayanan, Shrikanth S/D-5676-2012; Nayak, Krishna/Q-3849-2019; Bresch,
   Erik/T-3394-2019; Proctor, Michael/AAR-3720-2021
OI Proctor, Michael/0000-0002-3083-6859; Byrd, Dani/0000-0003-3319-5871;
   Nayak, Krishna/0000-0001-5735-3550
FU National Institutes of Health [R01 DC007124-01]
FX This work was supported by National Institutes of Health grant R01
   DC007124-01. Special thanks to our experimental subject for
   demonstrating his musical and linguistic talents in the service of
   science. We are especially grateful to three anonymous reviewers for
   their extensive comments on earlier versions of this manuscript.
CR [Anonymous], 2007, LAB PHONOLOGY
   Atherton M, 2007, P INT C MUSIC COMMUN, P15
   Bone D, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P913
   Bresch E, 2008, IEEE SIGNAL PROC MAG, V25, P123, DOI 10.1109/MSP.2008.918034
   Bresch E, 2006, J ACOUST SOC AM, V120, P1791, DOI 10.1121/1.2335423
   Clements N., 2002, LAB PHONOLOGY, V7, P299
   Eklund R, 2008, J INT PHON ASSOC, V38, P235, DOI 10.1017/S0025100308003563
   Erickson D, 1998, LANG SPEECH, V41, P399, DOI 10.1177/002383099804100408
   Gafos A., 1999, ARTICULATORY BASIS L, P272
   Gobl C, 2003, SPEECH COMMUN, V40, P189, DOI 10.1016/S0167-6393(02)00082-1
   Hess M., 2007, ICONS HIP HOP ENCY M, P640
   HOGAN JT, 1976, PHONETICA, V33, P275, DOI 10.1159/000259776
   Kapur Ajay, 2004, P INT C MUS INF RETR, P170
   Kim YC, 2012, J MAGN RESON IMAGING, V35, P943, DOI 10.1002/jmri.23510
   Kingston J, 2005, AMST STUD THEORY HIS, V269, P149
   LADEFOGED P, 1984, LANGUAGE, V60, P1, DOI 10.2307/414188
   Ladefoged P., 1996, SOUNDS WORLD LANGAUG, P426
   Lederer K, 2005, THESIS LEEDS U UK
   LINDAU M, 1984, J PHONETICS, V12, P147, DOI 10.1016/S0095-4470(19)30861-7
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Maddieson Ian., 2001, ANTHROPOL LINGUIST, V43, P619
   McDonough J, 2008, J PHONETICS, V36, P427, DOI 10.1016/j.wocn.2007.11.001
   McLean A., 2009, P INT C NEW INT MUS, P276
   Miller AL, 2009, J INT PHON ASSOC, V39, P129, DOI 10.1017/S0025100309003867
   Narayanan S, 2004, J ACOUST SOC AM, V115, P1771, DOI 10.1121/1.1652588
   Narayanan S., 2011, INTERSPEECH, P837
   Nordstrand M, 2004, SPEECH COMMUN, V44, P187, DOI 10.1016/j.specom.2004.09.003
   Proctor M.I., 2010, P INTERSINGING 2010, P23
   Proctor MI, 2010, P INT, P1576
   Saltzman EL., 1989, Ecological Psychology, V1, P333, DOI DOI 10.1207/S15326969EC00104_
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Sinyor Elliot, 2005, P INT C MUS INF RETR, P672
   Smith A. G., 2005, THESIS OHIO STATE U
   Splinter M, 2006, STANDARD BEATBOX NOT
   Stone Kurt, 1980, MUSIC NOTATION 20 CE
   Stowell D., 2008, BEATBOX ALPHABET
   Stowell D., 2010, THESIS QUEEN MARY U
   Stowell D, 2010, J NEW MUSIC RES, V39, P203, DOI 10.1080/09298215.2010.512979
   Stowell Dan, 2008, Characteristics of the beatboxing vocal style
   Sundara M, 2005, J ACOUST SOC AM, V118, P1026, DOI 10.1121/1.1953270
   TRAILL ANTHONY, 1985, Phonetic and Phonological Studies of IXoo Bushman
   Tyte G., 2012, BEATBOXING TECHNIQUE
   Weinberg N., 1998, GUIDE STANDARDIZED D, P43
   Wood S., 1982, WORKING PAPERS LINGU, V23, P192
   Wright Richard., 2002, J INT PHON ASSOC, V32, P43, DOI DOI 10.1017/S0025100302000142
NR 45
TC 36
Z9 44
U1 0
U2 19
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD FEB
PY 2013
VL 133
IS 2
BP 1043
EP 1054
DI 10.1121/1.4773865
PG 12
WC Acoustics; Audiology & Speech-Language Pathology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Acoustics; Audiology & Speech-Language Pathology
GA 080TW
UT WOS:000314267200050
PM 23363120
OA Green Published
DA 2024-01-09
ER

PT J
AU Li, Y
   Li, XL
   Lou, Z
   Chen, CF
AF Li, Ya
   Li, Xiulai
   Lou, Zheng
   Chen, Chaofan
TI Long Short-Term Memory-Based Music Analysis System for Music Therapy
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE music therapy; LSTM; autoencoder; music analysis; psychology; emotion
AB Music can express people's thoughts and emotions. Music therapy is to stimulate and hypnotize the human brain by using various forms of music activities, such as listening, singing, playing and rhythm. With the empowerment of artificial intelligence, music therapy technology has made innovative development in the whole process of "diagnosis, treatment and evaluation." It is necessary to make use of the advantages of artificial intelligence technology to innovate music therapy methods, ensure the accuracy of treatment schemes, and provide more paths for the development of the medical field. This paper proposes an long short-term memory (LSTM)-based generation and classification algorithm for multi-voice music data. A Multi-Voice Music Generation system called MVMG based on the algorithm is developed. MVMG contains two main steps. At first, the music data are modeled to the MDPI and text sequence data by using an autoencoder model, including music features extraction and music clip representation. And then an LSTM-based music generation and classification model is developed for generating and analyzing music in specific treatment scenario. MVMG is evaluated based on the datasets collected by us: the single-melody MIDI files and the Chinese classical music dataset. The experiment shows that the highest accuracy of the autoencoder-based feature extractor can achieve 95.3%. And the average F1-score of LSTM is 95.68%, which is much higher than the DNN-based classification model.
C1 [Li, Ya; Lou, Zheng] Hainan Normal Univ, Coll Mus, Haikou, Peoples R China.
   [Li, Xiulai; Chen, Chaofan] Hainan Hairui Zhong Chuang Technol Co Ltd, Haikou, Peoples R China.
C3 Hainan Normal University
RP Li, Y (corresponding author), Hainan Normal Univ, Coll Mus, Haikou, Peoples R China.
EM liya@hainnu.edu.cn
FU Hainan Natural Science Foundation; Hainan Philosophy and Social Science
   Planning Project
FX This work was partially supported by Hainan Natural Science Foundation
   "Research on automatic music composition machine learning system based
   on generative countermeasure network". Hainan Philosophy and Social
   Science Planning Project "The new action of Hainan characteristic chorus
   culture from the perspective of human destiny community - A Study on the
   internal development logic and the realistic path of foreign exchange".
CR de Mantaras RL, 2002, AI MAG, V23, P43
   Frid E, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376514
   Köhler F, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00651
   Kumar L., 2020, ASIAN J CONVERG TECH, V6, P36, DOI [10.33130/AJCT.2020v06i02.007, DOI 10.33130/AJCT.2020V06I02.007]
   Lee D, 2021, J ASSOC INF SCI TECH, V72, P570, DOI 10.1002/asi.24426
   Liu C, 2021, J INTERNET TECHNOL, V22, P187, DOI 10.3966/160792642021012201018
   Louie R, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376739
   Lupker J.A., 2021, DHQ, V15
   Moss H, 2019, NORD J MUSIC THER, V28, P212, DOI 10.1080/08098131.2018.1533573
   Panda R, 2020, IEEE T AFFECT COMPUT, V11, P614, DOI 10.1109/TAFFC.2018.2820691
   Pandian M.D., 2019, J ARTIF INTELL, V1, P54, DOI 10.36548/jaicn.2019.2.001
   Ramirez R, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00254
   Shi ER, 2020, BRAIN LANG, V206, DOI 10.1016/j.bandl.2020.104811
   Verhoef T, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.668300
   Xu Tan, 2021, MM '21: Proceedings of the 29th ACM International Conference on Multimedia, P5678, DOI 10.1145/3474085.3478875
   Yanzhen Qu, 2012, 2012 41st International Conference on Parallel Processing (ICPP 2012), P520, DOI 10.1109/ICPP.2012.3
   Zhang Z., 2022, GUQIN DATASET
NR 17
TC 2
Z9 2
U1 5
U2 28
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD JUN 14
PY 2022
VL 13
AR 928048
DI 10.3389/fpsyg.2022.928048
PG 7
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA 2L6VK
UT WOS:000817156600001
PM 35774954
OA gold, Green Published
DA 2024-01-09
ER

PT J
AU Moore, KS
AF Moore, Kimberly Sena
TI A Systematic Review on the Neural Effects of Music on Emotion
   Regulation: Implications for Music Therapy Practice
SO JOURNAL OF MUSIC THERAPY
LA English
DT Review
DE music; emotion regulation; neuroscience; amygdala
ID VOCAL PITCH REGULATION; SELF-REGULATION; BRAIN-REGIONS; LIMBIC
   STRUCTURES; PERCEPTION; ACTIVATION; MECHANISMS; GENERATION; RESPONSES;
   AREAS
AB Background: Emotion regulation (ER) is an internal process through which a person maintains a comfortable state of arousal by modulating one or more aspects of emotion. The neural correlates underlying ER suggest an interplay between cognitive control areas and areas involved in emotional reactivity. Although some studies have suggested that music may be a useful tool in ER, few studies have examined the links between music perception/production and the neural mechanisms that underlie ER and resulting implications for clinical music therapy treatment. Objectives of this systematic review were to explore and synthesize what is known about how music and music experiences impact neural structures implicated in ER, and to consider clinical implications of these findings for structuring music stimuli to facilitate ER.
   Methods: A comprehensive electronic database search resulted in 50 studies that met predetermined inclusion and exclusion criteria. Pertinent data related to the objective were extracted and study outcomes were analyzed and compared for trends and common findings.
   Results: Results indicated there are certain music characteristics and experiences that produce desired and undesired neural activation patterns implicated in ER. Desired activation patterns occurred when listening to preferred and familiar music, when singing, and an musicians) when improvising; undesired activation patterns arose when introducing complexity, dissonance, and unexpected musical events. Furthermore, the connection between music-influenced changes in attention and its link to ER was explored.
   Conclusions: Implications for music therapy practice are discussed and preliminary guidelines for how to use music to facilitate ER are shared.
C1 Univ Missouri, Kansas City, MO 64119 USA.
C3 University of Missouri System; University of Missouri Kansas City
RP Moore, KS (corresponding author), Univ Missouri, Kansas City, MO 64119 USA.
EM ks9r7@mail.umkc.edu
OI Sena Moore, Kimberly/0000-0001-8665-1493
CR [Anonymous], 2010, Treating traumatic stress in children and adolescents: How to foster resilience through attachment, self-regulation, and competency
   Ball T, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000307
   BANDURA A, 1991, ORGAN BEHAV HUM DEC, V50, P248, DOI 10.1016/0749-5978(91)90022-L
   Baumgartner T, 2006, BRAIN RES, V1075, P151, DOI 10.1016/j.brainres.2005.12.065
   Bengtsson SL, 2007, J COGNITIVE NEUROSCI, V19, P830, DOI 10.1162/jocn.2007.19.5.830
   Berns GS, 2012, J CONSUM PSYCHOL, V22, P154, DOI 10.1016/j.jcps.2011.05.001
   Berns GS, 2010, NEUROIMAGE, V49, P2687, DOI 10.1016/j.neuroimage.2009.10.070
   Blasi A, 2011, CURR BIOL, V21, P1220, DOI 10.1016/j.cub.2011.06.009
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Bodner M, 2001, NEUROL RES, V23, P683, DOI 10.1179/016164101101199108
   Brown S, 2004, NEUROREPORT, V15, P2033, DOI 10.1097/00001756-200409150-00008
   Brown S, 2007, BRAIN COGNITION, V63, P59, DOI 10.1016/j.bandc.2006.08.006
   Brown S, 2006, EUR J NEUROSCI, V23, P2791, DOI 10.1111/j.1460-9568.2006.04785.x
   Callan DE, 2006, NEUROIMAGE, V31, P1327, DOI 10.1016/j.neuroimage.2006.01.036
   Chapin H. L., 2010, DISS ABSTR INT, V71, P832
   Cole PM, 2009, SOC DEV, V18, P324, DOI 10.1111/j.1467-9507.2008.00503.x
   Cooper H.M., 1998, Synthesizing research: A guide for literature reviews, V3rd
   de Manzano Ö, 2012, NEUROIMAGE, V59, P772, DOI 10.1016/j.neuroimage.2011.07.016
   Dehaene-Lambertz G, 2010, BRAIN LANG, V114, P53, DOI 10.1016/j.bandl.2009.09.003
   Diamond LM, 2003, MOTIV EMOTION, V27, P125, DOI 10.1023/A:1024521920068
   Dyck M, 2011, NEUROIMAGE, V54, P2503, DOI 10.1016/j.neuroimage.2010.10.013
   Ehring T, 2010, BEHAV THER, V41, P587, DOI 10.1016/j.beth.2010.04.004
   Eldar E, 2007, CEREB CORTEX, V17, P2828, DOI 10.1093/cercor/bhm011
   Flores-Gutiérrez EO, 2007, INT J PSYCHOPHYSIOL, V65, P69, DOI 10.1016/j.ijpsycho.2007.03.004
   Foss AH, 2007, NEUROREPORT, V18, P1521, DOI 10.1097/WNR.0b013e3282ef6b51
   Fratianne RB, 2001, J BURN CARE REHABIL, V22, P47, DOI 10.1097/00004630-200101000-00010
   Fujisawa TX, 2011, BRAIN IMAGING BEHAV, V5, P109, DOI 10.1007/s11682-011-9116-5
   Geva R, 2008, J CHILD PSYCHOL PSYC, V49, P1031, DOI 10.1111/j.1469-7610.2008.01918.x
   Green AC, 2008, NEUROREPORT, V19, P711, DOI 10.1097/WNR.0b013e3282fd0dd8
   Gyurak A, 2011, COGNITION EMOTION, V25, P400, DOI 10.1080/02699931.2010.544160
   Hanson-Abromeit D., SYSTEMATIC IN PRESS
   Hanson-Abromeit D, 2013, INT DICT MUSIC THERA, P130
   Haslinger B, 2004, HUM BRAIN MAPP, V22, P206, DOI 10.1002/hbm.20028
   Hugdahl K, 1999, NEUROPSYCHOLOGIA, V37, P431, DOI 10.1016/S0028-3932(98)00101-8
   Ito M, 2004, BRAIN DEV-JPN, V26, P429, DOI 10.1016/j.braindev.2003.02.001
   James CE, 2008, NEUROIMAGE, V42, P1597, DOI 10.1016/j.neuroimage.2008.06.025
   Janata P, 2009, CEREB CORTEX, V19, P2579, DOI 10.1093/cercor/bhp008
   Jeffries KJ, 2003, NEUROREPORT, V14, P749, DOI 10.1097/00001756-200304150-00018
   Jerde TA, 2011, NEUROIMAGE, V57, P1572, DOI 10.1016/j.neuroimage.2011.05.061
   Juslin P. N., 2010, HDB MUSIC EMOTION TH, P3
   KAROLY P, 1993, ANNU REV PSYCHOL, V44, P23, DOI 10.1146/annurev.ps.44.020193.000323
   Khan KS, 2011, Systematic Reviews to Support Evidence-Based Medicine, V2
   Kleber B, 2007, NEUROIMAGE, V36, P889, DOI 10.1016/j.neuroimage.2007.02.053
   Kleber B, 2010, CEREB CORTEX, V20, P1144, DOI 10.1093/cercor/bhp177
   Knösche TR, 2005, HUM BRAIN MAPP, V24, P259, DOI 10.1002/hbm.20088
   Koelsch S, 2006, HUM BRAIN MAPP, V27, P239, DOI 10.1002/hbm.20180
   Koelsch S, 2010, TRENDS COGN SCI, V14, P131, DOI 10.1016/j.tics.2010.01.002
   Koelsch S, 2008, NEUROREPORT, V19, P1815, DOI 10.1097/WNR.0b013e32831a8722
   Larsen RJ, 2000, PSYCHOL INQ, V11, P129, DOI 10.1207/S15327965PLI1103_01
   Lee YS, 2011, NEUROIMAGE, V57, P293, DOI 10.1016/j.neuroimage.2011.02.006
   Lerner Y, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0006230
   Liebermann D, 2007, COGNITIVE DEV, V22, P511, DOI 10.1016/j.cogdev.2007.08.005
   Limb CJ, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0001679
   McRae K, 2010, J COGNITIVE NEUROSCI, V22, P248, DOI 10.1162/jocn.2009.21243
   Menon V, 2005, NEUROIMAGE, V28, P175, DOI 10.1016/j.neuroimage.2005.05.053
   Merriam Alan P., 1964, The Anthropology of Music
   Milton J, 2007, NEUROIMAGE, V35, P804, DOI 10.1016/j.neuroimage.2007.01.003
   Mitterschiffthaler MT, 2007, HUM BRAIN MAPP, V28, P1150, DOI 10.1002/hbm.20337
   Mizuno T, 2007, NEUROREPORT, V18, P1651, DOI 10.1097/WNR.0b013e3282f0b787
   Mutschler I, 2010, CEREB CORTEX, V20, P2531, DOI 10.1093/cercor/bhq001
   Nakamura S, 1999, NEUROSCI LETT, V275, P222, DOI 10.1016/S0304-3940(99)00766-1
   Ochsner KN, 2005, TRENDS COGN SCI, V9, P242, DOI 10.1016/j.tics.2005.03.010
   Ohnishi T, 2001, CEREB CORTEX, V11, P754, DOI 10.1093/cercor/11.8.754
   Pallesen KJ, 2005, ANN NY ACAD SCI, V1060, P450, DOI 10.1196/annals.1360.047
   Pallesen KJ, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011120
   Pallesen KJ, 2009, J COGNITIVE NEUROSCI, V21, P1065, DOI 10.1162/jocn.2009.21086
   Perry DW, 1999, NEUROREPORT, V10, P3979, DOI 10.1097/00001756-199912160-00046
   Rempel-Clower NL, 2007, ANN NY ACAD SCI, V1121, P72, DOI 10.1196/annals.1401.026
   Robb SL, 2011, J HEALTH PSYCHOL, V16, P342, DOI 10.1177/1359105310374781
   Ruiz MH, 2009, CEREB CORTEX, V19, P2625, DOI 10.1093/cercor/bhp021
   Satoh M, 2001, COGNITIVE BRAIN RES, V12, P101, DOI 10.1016/S0926-6410(01)00044-1
   Saxena P., 2011, SIS Journal of Projective Psychology Mental Health, V18, P147, DOI DOI 10.1016/J.CPR.2009.11.004
   Schore AN, 2001, INFANT MENT HEALTH J, V22, P7, DOI 10.1002/1097-0355(200101/04)22:1<7::AID-IMHJ2>3.0.CO;2-N
   Schulze K, 2011, HUM BRAIN MAPP, V32, P771, DOI 10.1002/hbm.21060
   Sloboda J.A., 2010, Handbook of music and emotion: Theory, research, applications, P73
   Sluming V, 2002, NEUROIMAGE, V17, P1613, DOI 10.1006/nimg.2002.1288
   Smith-Donald R, 2007, EARLY CHILD RES Q, V22, P173, DOI 10.1016/j.ecresq.2007.01.002
   Suda M, 2008, NEUROL RES, V30, P885, DOI 10.1179/174313208X319143
   Tan XL, 2010, J BURN CARE RES, V31, P590, DOI 10.1097/BCR.0b013e3181e4d71b
   Thaut M. H., 2010, HDB MUSIC EMOTION TH, P819
   Thaut MH, 2009, CORTEX, V45, P44, DOI 10.1016/j.cortex.2007.09.009
   Trainor Laurel J., 2003, COGNITIVE NEUROSCIEN, P310
   Verheugt-Pleiter A. J. E., 2008, DEV PSYCHOANALYSIS, P132
   Vogt S, 2007, NEUROIMAGE, V37, P1371, DOI 10.1016/j.neuroimage.2007.07.005
   Zarate JM, 2008, NEUROIMAGE, V40, P1871, DOI 10.1016/j.neuroimage.2008.01.026
   Zarate JM, 2010, NEUROPSYCHOLOGIA, V48, P607, DOI 10.1016/j.neuropsychologia.2009.10.025
   Zarate JM, 2005, ANN NY ACAD SCI, V1060, P404, DOI 10.1196/annals.1360.058
NR 87
TC 122
Z9 161
U1 9
U2 162
PU OXFORD UNIV PRESS INC
PI CARY
PA JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA
SN 0022-2917
EI 2053-7395
J9 J MUSIC THER
JI J. Music Ther.
PD FAL
PY 2013
VL 50
IS 3
BP 198
EP 242
DI 10.1093/jmt/50.3.198
PG 45
WC Music; Rehabilitation
WE Social Science Citation Index (SSCI)
SC Music; Rehabilitation
GA 228LP
UT WOS:000325188600004
PM 24568004
DA 2024-01-09
ER

PT J
AU Williams, D
AF Williams, Duncan
TI Toward Emotionally-Congruent Dynamic Soundtrack Generation
SO JOURNAL OF THE AUDIO ENGINEERING SOCIETY
LA English
DT Article
ID MUSICAL EMOTIONS; TEMPO; MODE; CUES
AB Emotionally congruent sound effect generation can be particularly useful in interactive audio applications with non-linear narrative requirements (such as video gaming). The study of affect (broadly construed here as recognition of emotional suggestion rather than individual emotional response) increasingly concludes that acoustic features can have an influence on the perceived emotional characteristics of an audio signal, from environmental sounds to musical stimuli. This paper presents an investigative approach to measuring the relative impact of musical voicing, in particular musical timbre, on perceived emotion as reported by a panel of listeners, as part of work towards an automated system designed to manipulate sound effects in real-time according to a particular affective intent. In the future this type of system could combine selective spectro-temporal morphing between source sounds and affective acoustic correlates with musical feature quantification and interpolation in order to manipulate a palette of sound effects or music through an emotional space based on quantified affective correlates.
C1 [Williams, Duncan] Univ Plymouth, Interdisciplinary Ctr Comp Mus Res, Plymouth PL4 8AA, Devon, England.
C3 University of Plymouth
RP Williams, D (corresponding author), Univ Plymouth, Interdisciplinary Ctr Comp Mus Res, Plymouth PL4 8AA, Devon, England.
EM Duncan.williams@plymouth.ac.uk
FU EPSRC [EP/J002135/1] Funding Source: UKRI; Engineering and Physical
   Sciences Research Council [EP/J002135/1] Funding Source: researchfish
CR [Anonymous], PYSCHOL MUSIC, DOI DOI 10.1177/0305735603031001325
   [Anonymous], 1984, PSYCHOMUSICOLOGY, DOI DOI 10.1037/H0094207
   [Anonymous], 2007, ESSAYS SOUND VISION
   Berg J, 2005, P 2005 ACM SIGCHI IN, P164
   BERGER KW, 1964, J ACOUST SOC AM, V36, P1888, DOI 10.1121/1.1919287
   Beveridge S., 2010, 11 INT C MUS PERC CO
   Caetano M., 2010, P 13 INT C DIG AUD E, V21
   Caetano M. F., 2010, P 13 INT C DIG AUD E, P11
   Chau CJ, 2016, J AUDIO ENG SOC, V64, P918, DOI 10.17743/jaes.2016.0049
   Chion M., 2019, Audio-Vision: Sound on Screen
   Collins K, 2008, GAME SOUND: AN INTRODUCTION TO THE HISTORY, THEORY, AND PRACTICE OF VIDEO GAME MUSIC AND SOUND DESIGN, P1
   Coutinho E, 2011, EMOTION, V11, P921, DOI 10.1037/a0024700
   Cowie R., 2009, AFFECTIVE COMPUTING, P1
   Daly I, 2015, BRAIN COGNITION, V101, P1, DOI 10.1016/j.bandc.2015.08.003
   Dean RT, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018591
   Fontaine JRJ, 2007, PSYCHOL SCI, V18, P1050, DOI 10.1111/j.1467-9280.2007.02024.x
   Gabrielsson A, 2001, MUSIC SCI, V5, P123, DOI 10.1177/10298649020050S105
   Gagnon L, 2003, COGNITION EMOTION, V17, P25, DOI 10.1080/02699930302279
   Grimaldi M., 2008, P LANGTECH, P1
   Hannon EE, 2004, J EXP PSYCHOL HUMAN, V30, P956, DOI 10.1037/0096-1523.30.5.956
   Heinlein CP, 1928, J COMP PSYCHOL, V8, P101, DOI 10.1037/h0070573
   Holbrook M.B., 1990, Psychology of Music, V18, P150, DOI [10.1177/0305735690182004, DOI 10.1177/0305735690182004]
   Holmes P, 2012, PSYCHOL MUSIC, V40, P301, DOI 10.1177/0305735610388898
   Husain G, 2002, MUSIC PERCEPT, V20, P151, DOI 10.1525/mp.2002.20.2.151
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Kallinen K, 2006, MUSIC SCI, V10, P191, DOI 10.1177/102986490601000203
   Kamp M., 2013, PHILOS TECHNOL, P1
   Kirke Alexis, 2013, P SOUND MUSIC COMPUT, DOI [10.5281/ZENODO.850216, DOI 10.5281/ZENODO.850216]
   KNOX D, 2008, P 10 INT C MUS PERC, P581
   Lamont A, 2011, MUSIC SCI, V15, P139, DOI 10.1177/1029864911403366
   Le Groux S., 2010, P 7 S COMP MUS MOD D
   Lipscomb Scott D, 2004, J Physiol Anthropol Appl Human Sci, V23, P337, DOI 10.2114/jpa.23.337
   Qin H, 2009, INT J HUM-COMPUT INT, V25, P107, DOI 10.1080/10447310802546732
   RODET X, 1992, P 1992 INT COMP MUS, P410
   Russell JA, 1999, J PERS SOC PSYCHOL, V76, P805, DOI 10.1037/0022-3514.76.5.805
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Scherer K. R., 1972, P E PSYCH ASS M BOS
   Scherer KR, 2004, J NEW MUSIC RES, V33, P239, DOI 10.1080/0929821042000317822
   Schmidt LA, 2001, COGNITION EMOTION, V15, P487, DOI 10.1080/0269993004200187
   Slaney M., 1995, P 1996 IEEE INT C AC, V2, P1001
   Strandh R., 1999, P JOURN INF MUS JIM, P83
   Williams D., 2007, 122 CONV AUD ENG SOC
   Williams D., 2015, AES 56 INT C AUD GAM
   Williams D., 2009, 128 CONV AUD ENG SOC
   Williams D., 2009, 126 CONV AUD ENG SOC
   Williams D, 2015, ACM T APPL PERCEPT, V12, DOI 10.1145/2749466
   Yin Haozhe, 2011, Computer Engineering and Applications, V47, P156, DOI 10.3778/j.issn.1002-8331.2011.01.043
NR 48
TC 2
Z9 2
U1 0
U2 10
PU AUDIO ENGINEERING SOC
PI NEW YORK
PA 60 E 42ND ST, NEW YORK, NY 10165-2520 USA
SN 1549-4950
J9 J AUDIO ENG SOC
JI J. Audio Eng. Soc.
PD SEP
PY 2016
VL 64
IS 9
SI SI
BP 654
EP 663
DI 10.17743/jaes.2016.0038
PG 10
WC Acoustics; Engineering, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Acoustics; Engineering
GA DY9TK
UT WOS:000385477800004
DA 2024-01-09
ER

PT J
AU Saiz-Clar, E
   Serrano, MA
   Reales, JM
AF Saiz-Clar, Elena
   Angel Serrano, Miguel
   Manuel Reales, Jose
TI Predicting emotions in music using the onset curve
SO PSYCHOLOGY OF MUSIC
LA English
DT Article
DE emotion; arousal; psychoacoustics; PCA; prediction; onset curve
ID RECOGNITION; FEATURES; TRACKING; TEMPO; MODEL
AB The relationship between parameters extracted from the musical stimuli and emotional response has been traditionally approached using several physical measures extracted from time or frequency domains. From time-domain measures, the musical onset is defined as the moment in that any musical instrument or human voice issues a musical note. The onsets' sequence in the performance of a specific musical score creates what is known as the onset curve (OC). The influence of the structure of OC on the emotional judgment of people is not known. To this end, we have applied principal component analysis on a complete set of variables extracted from the OC to capture their statistical structure. We have found a trifactorial structure related to activation and valence dimensions of emotional judgment. The structure has been cross-validated using different participants and stimuli. In this way, we propose the factorial scores of the OC as a reliable and relevant piece of information to predict the emotional judgment of music.
C1 [Saiz-Clar, Elena; Manuel Reales, Jose] UNED, Dept Sci Behav & Hlth Methodol, Madrid, Spain.
   [Angel Serrano, Miguel] Univ Valencia, Dept Psychobiol, Valencia, Spain.
C3 Universidad Nacional de Educacion a Distancia (UNED); University of
   Valencia
RP Saiz-Clar, E (corresponding author), UNED, Fac Psicol, Dept Metodol Ciencias Comportamiento & Salud, C Juan Rosal 10, Madrid 28040, Spain.
EM esaiz@bec.uned.es
RI Serrano, Miguel-Angel/AAZ-4393-2020; Serrano, Miguel-Angel/ABE-7279-2021
OI Serrano, Miguel-Angel/0000-0002-6574-4532; Saiz-Clar,
   Elena/0000-0002-8714-2305
FU Ministerio de Economia y Competitividad de Espana [UNED13-4E-1906]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: Part of
   this study was funded by Ministerio de Economia y Competitividad de
   Espana (UNED13-4E-1906).
CR Aljanaki A, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0173392
   [Anonymous], 2007, INT C MUSIC INFORM R
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   BERGER KW, 1964, J ACOUST SOC AM, V36, P1888, DOI 10.1121/1.1919287
   Boltz MG, 2011, MUSIC PERCEPT, V28, P367, DOI 10.1525/MP.2011.28.4.367
   Cameron DJ, 2014, ACOUST AUST, V42, P111
   Coath M, 2009, CONNECT SCI, V21, P193, DOI 10.1080/09540090902733905
   Coutinho E, 2011, EMOTION, V11, P921, DOI 10.1037/a0024700
   Eerola T., 2009, Proceedings of the International Conference on Music Information Retrieval ISMIR, P621
   Gomez P, 2007, EMOTION, V7, P377, DOI 10.1037/1528-3542.7.2.377
   Grekow J, 2020, LECT NOTES COMPUT SC, V12117, P150, DOI 10.1007/978-3-030-59491-6_14
   Hevner K, 1936, AM J PSYCHOL, V48, P246, DOI 10.2307/1415746
   Hevner K, 1935, AM J PSYCHOL, V47, P103, DOI 10.2307/1416710
   Hizlisoy S, 2021, ENG SCI TECHNOL, V24, P760, DOI 10.1016/j.jestch.2020.10.009
   Jover-Fernández M, 2022, PSYCHOL MUSIC, V50, P548, DOI 10.1177/03057356211010217
   Kellecher A., 2004, IR SIGN SYST C ISSC
   Klapuri A, 1999, INT CONF ACOUST SPEE, P3089, DOI 10.1109/ICASSP.1999.757494
   Korhonen MD, 2006, IEEE T SYST MAN CY B, V36, P588, DOI 10.1109/TSMCB.2005.862491
   Lartillot O., 2008, MIRTOOLBOX 1 1 USERS
   Lartillot O, 2008, ST CLASS DAT ANAL, P261, DOI 10.1007/978-3-540-78246-9_31
   Lu L, 2006, IEEE T AUDIO SPEECH, V14, P5, DOI 10.1109/TSA.2005.860344
   Neuhaus JO., 1955, AM PSYCHOL, V10, P418
   Peretz I, 2003, NAT NEUROSCI, V6, P688, DOI 10.1038/nn1083
   Pouyanfar S, 2014, 2014 IRANIAN CONFERENCE ON INTELLIGENT SYSTEMS (ICIS)
   Privosnik M., 2002, P 2002 INT COMP MUS
   Rajesh S, 2020, PROCEDIA COMPUT SCI, V167, P16, DOI 10.1016/j.procs.2020.03.178
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Saiz-Clar E, 2019, REV MEX PSICOL, V36, P30
   Saiz-Clar E, 2018, PSYCHOL MUSIC, V46, P222, DOI 10.1177/0305735617705452
   Scheirer ED, 1998, J ACOUST SOC AM, V103, P588, DOI 10.1121/1.421129
   Schuller B., 2014, MULTIRESOLUTION LINE, DOI [10.1109/ICASSI.2014.6853982, DOI 10.1109/ICASSI.2014.6853982]
   Shao B, 2009, IEEE T AUDIO SPEECH, V17, P1602, DOI 10.1109/TASL.2009.2020893
   Sturm I., 2015, BRAIN, V25, P366, DOI [DOI 10.1037/PMU0000104, 10.1037/pmu0000104]
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   Yang YH, 2008, IEEE T AUDIO SPEECH, V16, P448, DOI 10.1109/TASL.2007.911513
   Yang YH, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168754
NR 37
TC 0
Z9 0
U1 0
U2 6
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0305-7356
EI 1741-3087
J9 PSYCHOL MUSIC
JI Psychol. Music
PD JUL
PY 2022
VL 50
IS 4
BP 1107
EP 1120
DI 10.1177/03057356211031658
EA AUG 2021
PG 14
WC Psychology, Educational; Psychology, Applied; Music; Psychology,
   Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Psychology; Music
GA 2M9JU
UT WOS:000684681100001
DA 2024-01-09
ER

PT J
AU Pedro, J
   Gutiérrez-Martínez, B
AF Pedro, Josep
   Gutierrez-Martinez, Begona
TI Women artists in the Spanish African-American music scene: identities,
   discourses and emotions in the public sphere
SO REVISTA MEDITERRANEA COMUNICACION-JOURNAL OF COMMUNICATION
LA Spanish
DT Article
DE African-American music; African descendant collective; emotion;
   ethnography; music scene; public sphere
AB This paper explores the presence and importance of women artists in the Spanish African-American music scene, specifically in the blues, jazz and soul-funk sub-scenes. It presents an ethnography focused on the increasing prominence of women, and it addresses different musical events, texts and artists associated with a diversity of voices, identities, discourses and emotions in the public sphere. Methodologically, we draw on participant observation, interviews, documentation and discourse analysis from a communicative and sociosemiotic perspective. We study the Spanish soul music scene, where African-descendant singers play a leading role, and we examine in depth the case of Aretha Soul Divas, a supergroup tribute to Aretha Franklin. The discourses analysed refer to the emotional dimension of musical experience, where the encounter between artists and audiences facilitates mutual understanding and emotional liberation. Furthermore, we verify the connection between the demands enunciated within the music scene, and the demands of the African descendant collective in Spain, which denounces racism and lack of visibility. The events, texts and discourses that emerge in these confluence spaces contribute to the passionate construction of a symbolic territory of their own, where the individual is combined with the collective.
C1 [Pedro, Josep] Univ Carlos III Madrid, Madrid, Spain.
   [Gutierrez-Martinez, Begona] Univ Complutense Madrid, Madrid, Spain.
C3 Universidad Carlos III de Madrid; Complutense University of Madrid
RP Pedro, J (corresponding author), Univ Carlos III Madrid, Madrid, Spain.
EM jpedro@hum.uc3m.es; beggutie@ucm.es
OI Gutierrez-Martinez, Begona/0000-0003-0046-9696; Pedro,
   Josep/0000-0003-0881-3447
CR Afrofeminas, 2020, PROP ALC
   Ahmed S, 2014, CULTURAL POLITICS OF EMOTION, 2ND EDITION, P1
   Albornoz L. A., 2017, Diversidad e industria audiovisual. El desafio del siglo XXI
   [Anonymous], 2014, DAY NIGHT       1222
   [Anonymous], 2009, LA CONDICION HUMANA
   [Anonymous], 2019, 15 ANOS VISIBILIDAD
   [Anonymous], 1986, EXPERIENCIA ESTETICA
   [Anonymous], 2017, EL MUNDO
   [Anonymous], 1999, BLACK ATLANTIC MODER
   [Anonymous], 1999, BLUES LEGACIES BLACK
   Baitin M., 1989, TEORIA ESTETICA NOVE
   Baraka A., 2002, BLUES PEOPLE BACK MU
   Bele-Lobede D., 2018, SER MUJER NEGRA ESPA
   Bennett A., 2004, LOCAL TRANSLOCAL VIR
   Berlant L, 1998, CRIT INQUIRY, V24, P281, DOI 10.1086/448875
   Berlant L., 2011, PUBLIC FEELINGS SALO
   Bermudez Ruben H., 2018, Y tu, por que eres negro?
   Casas A., 1970, VANGUARDIA, P9
   Garcia M., 2018, INAPROPIADOS INAPROP
   Geertz Clifford, 2003, La interpretacion de las culturas
   Godes P., 2018, VANITY FAIR
   Guralnick P., 2002, SWEET SOUL MUSIC
   Herbst S., 1994, HIST STUDIES PUBLIC
   Jackson B., 2006, DISFRUTA MISI FE ATR
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Lapuente L., 2018, MUELLE BAHIA HIST SO
   Le Gendre K., 2012, SOUL UNSUNG REFLECTI
   Lotman Y., 1996, SEMIOSFETA SEMIATICA
   Manrique D. A., 2017, PAIS
   MARCUS GE, 1995, ANNU REV ANTHROPOL, V24, P95, DOI 10.1146/annurev.an.24.100195.000523
   MARS Amanda, 2018, PAIS
   Martinez L., 2020, EL DIARIO
   Mbomio Rubio L. A., 2017, AUE SE ATREVIERON
   Mbomio Rubio Lucia Asue, 2019, HIJA CAMINO
   Monson I., 2009, JAZZ IMPROVISATION I
   Mundo Joven, 1970, MUNDO JOVEN, V95
   Pedro J., 2018, CUADERNOS ETNOMUSICO, V12, P64
   Pedro J., 2018, APROPRACION DIALOGO
   Pedro J., 2014, IASPM J, V4, P73
   PENAMARIN C., 2016, DESIGNIS, V24, P35
   Penamarin C., 2017, La mediacion fragmentaria. Mediatizacion y controversia en la nueva esfera publica, P11
   Robertson R., 1994, Journal of International Communication, V1, P33, DOI [DOI 10.1080/13216597.1994.9751780, 10.1080/13216597.1994.9751780]
   Rocu Gomez P, 2019, HIST CUENTAN CUENTAN
   Sabugal N, 2018, CHICA SIN SUERTE
   Echezarreta VS, 2012, CIC-CUAD INF COMUN, V17, P107, DOI 10.5209/rev_CIYC.2012.v17.39260
   Scarpellini H, 2018, EL MUNDO
   Song YD, 2016, MUSIC PERCEPT, V33, P472, DOI 10.1525/MP.2016.33.4.472
   Stanfield P., 2005, JAZZ BLUES AM FILM 1
   Thornham S, 2010, ROUTLEDGE COMPANION, P29
   Turino T., 2008, MUSIC SOCIAL LLFE PO
   Welch C., 2000, CREAM LEGENDARY 60S
NR 51
TC 0
Z9 0
U1 0
U2 3
PU UNIV ALICANTE
PI ALICANTE
PA APARTADO DE CORREOS 99, ALICANTE, 3080, SPAIN
SN 1989-872X
J9 REV MEDITERR COMUN
JI Rev. Mediterr. Comun.
PD JUL-DEC
PY 2020
VL 11
IS 2
SI SI
BP 169
EP 183
DI 10.14198/MEDCOM2020.11.2.20
PG 15
WC Communication
WE Emerging Sources Citation Index (ESCI)
SC Communication
GA PP2PE
UT WOS:000605708700014
OA Green Submitted, gold, Green Published
DA 2024-01-09
ER

PT J
AU Lange, EB
   Fünderich, J
   Grimm, H
AF Lange, Elke B.
   Fuenderich, Jens
   Grimm, Hartmut
TI Multisensory integration of musical emotion perception in singing
SO PSYCHOLOGICAL RESEARCH-PSYCHOLOGISCHE FORSCHUNG
LA English
DT Article
ID FACIAL EXPRESSIONS; AUDIOVISUAL INTEGRATION; VISUAL-PERCEPTION;
   PERFORMANCE; RECOGNITION; EXPERTISE; RESPONSES; SPEECH; VOICE; SOUND
AB We investigated how visual and auditory information contributes to emotion communication during singing. Classically trained singers applied two different facial expressions (expressive/suppressed) to pieces from their song and opera repertoire. Recordings of the singers were evaluated by laypersons or experts, presented to them in three different modes: auditory, visual, and audio-visual. A manipulation check confirmed that the singers succeeded in manipulating the face while keeping the sound highly expressive. Analyses focused on whether the visual difference or the auditory concordance between the two versions determined perception of the audio-visual stimuli. When evaluating expressive intensity or emotional content a clear effect of visual dominance showed. Experts made more use of the visual cues than laypersons. Consistency measures between uni-modal and multimodal presentations did not explain the visual dominance. The evaluation of seriousness was applied as a control. The uni-modal stimuli were rated as expected, but multisensory evaluations converged without visual dominance. Our study demonstrates that long-term knowledge and task context affect multisensory integration. Even though singers' orofacial movements are dominated by sound production, their facial expressions can communicate emotions composed into the music, and observes do not rely on audio information instead. Studies such as ours are important to understand multisensory integration in applied settings.
C1 [Lange, Elke B.; Fuenderich, Jens; Grimm, Hartmut] Max Planck Inst Empir Aesthet MPIEA, Dept Mus, Grtineburgweg 14, D-60322 Frankfurt, Germany.
   [Fuenderich, Jens] Univ Erfurt, Erfurt, Germany.
C3 University of Erfurt
RP Lange, EB (corresponding author), Max Planck Inst Empir Aesthet MPIEA, Dept Mus, Grtineburgweg 14, D-60322 Frankfurt, Germany.
EM Elke.Lange@ae.mpg.de
OI Lange, Elke B./0000-0002-8928-3718
FU Projekt DEAL
FX Open Access funding enabled and organized by Projekt DEAL. This research
   did not receive any grant from funding agencies in the public,
   commercial, or not-for-profit sectors.
CR Akkermans J, 2019, COGNITION EMOTION, V33, P1099, DOI 10.1080/02699931.2018.1541312
   Aviezer H, 2017, CURR OPIN PSYCHOL, V17, P47, DOI 10.1016/j.copsyc.2017.06.006
   Bakeman R, 1996, BEHAV RES METH INSTR, V28, P584, DOI 10.3758/BF03200546
   Battcock A, 2022, PSYCHOL RES-PSYCH FO, V86, P66, DOI 10.1007/s00426-020-01467-1
   Baumgartner T, 2006, BRAIN RES, V1075, P151, DOI 10.1016/j.brainres.2005.12.065
   Besson M, 2007, RESTOR NEUROL NEUROS, V25, P399
   Bhatara A, 2011, J EXP PSYCHOL HUMAN, V37, P921, DOI 10.1037/a0021922
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Blair RJR, 2003, PHILOS T R SOC B, V358, P561, DOI 10.1098/rstb.2002.1220
   Bohlman PV, 2005, J MUSICOL RES, V24, P205, DOI 10.1080/01411890500233924
   Broughton M, 2009, PSYCHOL MUSIC, V37, P137, DOI 10.1177/0305735608094511
   BUCK R, 1994, BIOL PSYCHOL, V38, P95, DOI 10.1016/0301-0511(94)90032-9
   Chen YC, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00445
   Collignon O, 2008, BRAIN RES, V1242, P126, DOI 10.1016/j.brainres.2008.04.023
   Coutinho E, 2017, PSYCHOL MUSIC, V45, P550, DOI 10.1177/0305735616670496
   Cowen AS, 2020, P NATL ACAD SCI USA, V117, P1924, DOI 10.1073/pnas.1910704117
   Dahl S, 2007, MUSIC PERCEPT, V24, P433, DOI 10.1525/MP.2007.24.5.433
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Darwin C., 1872, P374
   Davidson JW, 2012, PSYCHOL MUSIC, V40, P595, DOI 10.1177/0305735612449896
   Davidson JW., 1993, PSYCHOL MUSIC, V21, P103, DOI [10.1177/030573569302100201, DOI 10.1177/030573569302100201]
   De Gelder B, 2003, TRENDS COGN SCI, V7, P460, DOI 10.1016/j.tics.2003.08.014
   de Gelder B, 2000, COGNITION EMOTION, V14, P289, DOI 10.1080/026999300378824
   de Gelder B, 2002, P NATL ACAD SCI USA, V99, P4121, DOI 10.1073/pnas.062018499
   de Gelder B, 2000, BRAIN COGNITION, V44, P425, DOI 10.1006/brcg.1999.1203
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Gamer M., 2019, irr: Various coefficients of interrater reliability and agreement ( R package Version 0.84.1 )
   Hargreaves DJ., 1999, PSYCHOL MUSIC, V27, P71, DOI DOI 10.1177/0305735699271007
   Ho HT, 2015, J COGNITIVE NEUROSCI, V27, P798, DOI 10.1162/jocn_a_00734
   Hunter PG, 2008, COGNITION EMOTION, V22, P327, DOI 10.1080/02699930701438145
   Jankelevitch Vladimir, 2003, Music and the Ineffable
   Juslin P. N., 1996, PSYCHOL MUSIC, V24, P68, DOI [10.1177/0305735696241007, DOI 10.1177/0305735696241007]
   Juslin PN, 2013, PHYS LIFE REV, V10, P235, DOI 10.1016/j.plrev.2013.05.008
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kret ME, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00028
   Lakens D., 2019, J INDEXING METRICS, DOI 10.31234/osf.io/baxsf
   Larsen JT, 2011, EMOTION, V11, P1469, DOI 10.1037/a0024081
   Laukka P, 2013, EMOTION, V13, P434, DOI 10.1037/a0031388
   Livi S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193508
   Livingstone SR, 2015, Q J EXP PSYCHOL, V68, P952, DOI 10.1080/17470218.2014.971034
   Livingstone SR, 2009, MUSIC PERCEPT, V26, P475, DOI 10.1525/MP.2009.26.5.475
   Marin MM, 2012, EMOTION, V12, P618, DOI 10.1037/a0025020
   Massaro DW, 1996, PSYCHON B REV, V3, P215, DOI 10.3758/BF03212421
   Müllensiefan D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089642
   Neuhaus C, 2006, J COGNITIVE NEUROSCI, V18, P472, DOI 10.1162/jocn.2006.18.3.472
   North AC, 2004, MUSIC PERCEPT, V22, P41, DOI 10.1525/mp.2004.22.1.41
   Pan FD, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217040
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Petrini K, 2009, EXP BRAIN RES, V198, P339, DOI 10.1007/s00221-009-1817-2
   POSNER MI, 1976, PSYCHOL REV, V83, P157, DOI 10.1037/0033-295X.83.2.157
   Pourtois G, 2005, CORTEX, V41, P49, DOI 10.1016/S0010-9452(08)70177-1
   R Core Team, 2018, R: A Language and Environment for Statistical Computing
   Scherer KR, 2019, PSYCHOL AESTHET CREA, V13, P244, DOI 10.1037/aca0000163
   Schreuder E, 2016, SAGE OPEN, V6, DOI 10.1177/2158244016630591
   Scotto di Carlo N, 2004, SEMIOTICA, V149, P37
   SHROUT PE, 1979, PSYCHOL BULL, V86, P420, DOI 10.1037/0033-2909.86.2.420
   SIEGWART H, 1995, J VOICE, V9, P249, DOI 10.1016/S0892-1997(05)80232-2
   Spence C, 2007, ACOUST SCI TECHNOL, V28, P61, DOI 10.1250/ast.28.61
   Tcherkassof A, 2021, PSYCHOL RES-PSYCH FO, V85, P2954, DOI 10.1007/s00426-020-01448-4
   Thompson WF, 2005, SEMIOTICA, V156, P203, DOI 10.1515/semi.2005.2005.156.203
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Thompson WF, 2010, PSYCHON B REV, V17, P317, DOI 10.3758/PBR.17.3.317
   Thompson WF, 2008, COGNITION EMOTION, V22, P1457, DOI 10.1080/02699930701813974
   Tsay CJ, 2013, P NATL ACAD SCI USA, V110, P14580, DOI 10.1073/pnas.1221454110
   Van den Stock J, 2009, BRAIN TOPOGR, V21, P216, DOI 10.1007/s10548-009-0099-0
   Vines BW, 2006, COGNITION, V101, P80, DOI 10.1016/j.cognition.2005.09.003
   Vines BW, 2011, COGNITION, V118, P157, DOI 10.1016/j.cognition.2010.11.010
   Vuoskoski JK, 2016, MUSIC PERCEPT, V33, P457, DOI 10.1525/MP.2016.33.4.457
   Vuoskoski JK, 2014, ATTEN PERCEPT PSYCHO, V76, P591, DOI 10.3758/s13414-013-0582-2
   WELCH RB, 1980, PSYCHOL BULL, V88, P638, DOI 10.1037/0033-2909.88.3.638
   Wöllner C, 2010, PSYCHOL RES-PSYCH FO, V74, P579, DOI 10.1007/s00426-010-0280-9
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 74
TC 5
Z9 5
U1 2
U2 11
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 0340-0727
EI 1430-2772
J9 PSYCHOL RES-PSYCH FO
JI Psychol. Res.-Psychol. Forsch.
PD OCT
PY 2022
VL 86
IS 7
BP 2099
EP 2114
DI 10.1007/s00426-021-01637-9
EA JAN 2022
PG 16
WC Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA 4M5DJ
UT WOS:000740604100001
PM 35001181
OA hybrid, Green Published
DA 2024-01-09
ER

PT J
AU Weisser, S
AF Weisser, Stephanie
TI Emotion and music: The Ethiopian <i>Iyre bagana</i>
SO MUSICAE SCIENTIAE
LA English
DT Article
DE emotion; ethnomusicology; music; SEM descriptive system
AB The bagana is a paraliturgical Iyre played by the Christian Amhara of Ethiopia. It is used to perform spiritual music. Bagana is an intimate instrument, accompanied by the singing voice only. it has a special role in Christian Amhara music, as its myth of origin closely connects it to God, the biblical King David and King Menelik I. It is reputed lobe very powerful and its performances arouse intense reactions in both players and listeners. Some of these reactions were observed directly (immediate calming, tears, overwhelmed face;;). Inner reactions to bagana were investigated by means of 108 statements collected from 32 participarts (from virtuoso players to simple listeners) during interviews or discussion. Statements were classified by using the Strong Experiences related to Music (SEM) descriptive system (Gabrielsson & Lindstrom Wik, 2003). Results show that the inner reactions bagana elicits are varied (statements fall into six of the seven categories of the SEM descriptive system) but a majority of the statements can be classified into the Feelings/Emotions (5) and Existential and Transcendental (6) categories. The least commonly admitted reactions fall into the Physical Reactions and Behaviours (2) and the Perception (3) categories. These results are discussed in detail and confronted with the direct observations. The utility and difficulties of the SEM descriptive system in ethnomusicological contexts are also discussed.
C1 Museum Mus Instruments, B-1000 Brussels, Belgium.
RP Weisser, S (corresponding author), Museum Mus Instruments, Rue Villa Hermosa 1, B-1000 Brussels, Belgium.
EM s.weisser@mim.be
CR Aga A., 2000, I ETHIOPIAN STUDIES, V21-22, P5
   [Anonymous], 1992, J RELIG AFR
   [Anonymous], 2001, Music and Emotion: Theory and Research
   Aubert L., 2005, CONNAISSANCE RELIG, V75-76, P203
   Becker J., 2004, Deep listeners: Music emotions and trancing
   BERLINER PF, 1981, SOUL MBIRA MUSIC TRA
   Chaillot C., 2002, ETHIOPIAN ORTHODOX T
   Damasio A. R., 2003, Looking for Spinoza: Joy, sorrow, and the feeling brain
   Fletcher N. H., 1998, PHYS MUSICAL INSTRUM
   Gabrielsson A, 2003, MUSIC SCI, V7, P157, DOI 10.1177/102986490300700201
   Gabrielsson A., 2001, MUSIC EMOTION THEORY, P431
   Leipp Emile, 1989, ACOUSTIQUE MUSIQUE
   Mekouria T. T., 1994, ACT XEM C INT ET ETH, P145
   Merahi K., 2004, MOST VERSATILE ETHIO
   Merriam Alan P., 1964, The Anthropology of Music
   Nattiez J.-J., 1981, YB TRADITIONAL MUSIC, V13, P48
   Nattiez J. J., 2005, MUSIQUES ENCY 21 SIE, V3, P971
   Ortony A, 1988, The cognitive structure of emotions
   POWNE MICHAEL, 1968, ETHIOPIAN MUSIC INTR
   Reminick R. A., 1975, P 1 US C ETH STUD MI, P25
   Rickard N. S., 2004, Psychology of Music, V32, P371, DOI [10.1177%2F0305735604046096, DOI 10.1177/0305735604046096, 10.1177/0305735604046096]
   Rouget Gilbert., 1990, La musique et la transe: esquisse d'une theorie generale des relations de la musique et de la possession
   Scherer K. R., 2001, MUSIC EMOTION THEORY, P361, DOI DOI 10.1080/0929821042000317822
   Scherer KR, 2001, MUSIC SCI, V5, P149, DOI 10.1177/10298649020050S106
   Sloboda JA., 2001, MUSIC EMOTION THEORY, P71
   Weisser S., 2005, THESIS U LIBRE BRUXE
   Weisser S., 2006, MUSURGIA, VXIII, P51
   Weisser S, 2006, P 9 INT C MUS PERC C, P376
   Weisser Stephanie, 2007, ANN ETHIOPIE, V23, P61
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 30
TC 1
Z9 1
U1 1
U2 4
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1029-8649
EI 2045-4147
J9 MUSIC SCI
JI Music Sci.
PD SPR
PY 2012
VL 16
IS 1
BP 3
EP 18
DI 10.1177/1029864911416493
PG 16
WC Music; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music; Psychology
GA 927GB
UT WOS:000302894100001
OA Green Published
DA 2024-01-09
ER

PT J
AU Wang, DJ
   Trehub, SE
   Volkova, A
   van Lieshout, P
AF Wang, David J.
   Trehub, Sandra E.
   Volkova, Anna
   van Lieshout, Pascal
TI Child implant users' imitation of happy- and sad-sounding speech
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE prosody; emotion; production; cochlear implants; children
ID COCHLEAR IMPLANT; MUSIC PERCEPTION; DEAF-CHILDREN; LANGUAGE; EMOTION;
   INTELLIGIBILITY; INTONATION; RECIPIENTS; PITCH
AB Cochlear implants have enabled many congenitally or prelingually deaf children to acquire their native language and communicate successfully on the basis of electrical rather than acoustic input. Nevertheless, degraded spectral input provided by the device reduces the ability to perceive emotion in speech. We compared the vocal imitations of 5- to 7-year-old deaf children who were highly successful bilateral implant users with those of a control sample of children who had normal hearing. First, the children imitated several happy and sad sentences produced by a child model. When adults in Experiment 1 rated the similarity of imitated to model utterances, ratings were significantly higher for the hearing children. Both hearing and deaf children produced poorer imitations of happy than sad utterances because of difficulty matching the greater pitch modulation of the happy versions. When adults in Experiment 2 rated electronically filtered versions of the utterances, which obscured the verbal content, ratings of happy and sad utterances were significantly differentiated for deaf as well as hearing children. The ratings of deaf children, however, were significantly less differentiated. Although deaf children's utterances exhibited culturally typical pitch modulation, their pitch modulation was reduced relative to that of hearing children. One practical implication is that therapeutic interventions for deaf children could expand their focus on suprasegmental aspects of speech perception and production, especially intonation patterns.
C1 [Wang, David J.] Univ Toronto, Mississauga Acad Med, Mississauga, ON L5L 1C6, Canada.
   [Trehub, Sandra E.; Volkova, Anna; van Lieshout, Pascal] Univ Toronto, Dept Psychol, Toronto, ON M5S 1A1, Canada.
   [van Lieshout, Pascal] Univ Toronto, Dept Speech Language Pathol, Toronto, ON, Canada.
C3 University of Toronto; University Toronto Mississauga; University of
   Toronto; University of Toronto
RP Trehub, SE (corresponding author), Univ Toronto, Dept Psychol, 3359 Mississauga Rd North, Mississauga, ON L5L 1C6, Canada.
EM sandra.trehub@utoronto.ca
RI van Lieshout, Pascal HHM/A-1371-2008
OI van Lieshout, Pascal HHM/0000-0001-8139-8900
CR [Anonymous], 2010, PERSPECTIVES INDIVID
   [Anonymous], PROCESSING COMPLEX S
   [Anonymous], PRAAT U AMSTERDAM
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Barry JG, 2002, CLIN LINGUIST PHONET, V16, P79, DOI 10.1080/02699200110109802
   Ben-David BM, 2013, BRAIN INJURY, V27, P248, DOI 10.3109/02699052.2012.740648
   Blamey PJ, 2001, J SPEECH LANG HEAR R, V44, P73, DOI 10.1044/1092-4388(2001/007)
   Carter AK, 2002, CLIN LINGUIST PHONET, V16, P619, DOI 10.1080/02699200021000034958
   Chen JKC, 2010, PEDIATRICS, V125, pE793, DOI 10.1542/peds.2008-3620
   Cooper WB, 2008, EAR HEARING, V29, P618, DOI 10.1097/AUD.0b013e318174e787
   Cousineau M, 2010, HEARING RES, V269, P34, DOI 10.1016/j.heares.2010.07.007
   CRUTTENDEN A, 1985, J CHILD LANG, V12, P643, DOI 10.1017/S030500090000670X
   Flipsen P, 2006, J COMMUN DISORD, V39, P93, DOI 10.1016/j.jcomdis.2005.11.001
   Geurts L, 2001, J ACOUST SOC AM, V109, P713, DOI 10.1121/1.1340650
   Green T, 2004, J ACOUST SOC AM, V116, P2298, DOI 10.1121/1.1785611
   Hopyan-Misakyan TM, 2009, CHILD NEUROPSYCHOL, V15, P136, DOI 10.1080/09297040802403682
   Kang R, 2009, EAR HEARING, V30, P411, DOI 10.1097/AUD.0b013e3181a61bc0
   Ladd D. Robert, 1996, Intonational Phonology
   Lenden JM, 2007, J COMMUN DISORD, V40, P66, DOI 10.1016/j.jcomdis.2006.04.004
   Moreno S, 2009, CEREB CORTEX, V19, P712, DOI 10.1093/cercor/bhn120
   Morton JB, 2001, CHILD DEV, V72, P834, DOI 10.1111/1467-8624.00318
   Most T, 2007, J DEAF STUD DEAF EDU, V12, P350, DOI 10.1093/deafed/enm012
   Nakata T, 2012, J ACOUST SOC AM, V131, P1307, DOI 10.1121/1.3672697
   Pals C, 2013, J SPEECH LANG HEAR R, V56, P1075, DOI 10.1044/1092-4388(2012/12-0074)
   Patel R, 2006, SPEECH COMMUN, V48, P1308, DOI 10.1016/j.specom.2006.06.007
   Peng SC, 2004, J SPEECH LANG HEAR R, V47, P1227, DOI 10.1044/1092-4388(2004/092)
   Peng SC, 2004, EAR HEARING, V25, P251, DOI 10.1097/01.AUD.0000130797.73809.40
   Peng SC, 2008, EAR HEARING, V29, P336, DOI 10.1097/AUD.0b013e318168d94d
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   Spencer LJ, 1998, EAR HEARING, V19, P310, DOI 10.1097/00003446-199808000-00006
   Svirsky MA, 2000, PSYCHOL SCI, V11, P153, DOI 10.1111/1467-9280.00231
   Tomblin JB, 2005, J SPEECH LANG HEAR R, V48, P853, DOI 10.1044/1092-4388(2005/059)
   Volkova Anna, 2013, Cochlear Implants Int, V14, P80, DOI 10.1179/1754762812Y.0000000004
   Vongpaisal T, 2006, J SPEECH LANG HEAR R, V49, P1091, DOI 10.1044/1092-4388(2006/078)
   Wei WI, 2000, ACTA OTO-LARYNGOL, V120, P218
   Xin Luo, 2007, Trends Amplif, V11, P301
NR 36
TC 24
Z9 27
U1 0
U2 16
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD JUN 21
PY 2013
VL 4
AR 351
DI 10.3389/fpsyg.2013.00351
PG 8
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA AA4DU
UT WOS:000331046000001
PM 23801976
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Rothenberg, D
   Roeske, TC
   Voss, HU
   Naguib, M
   Tchernichovski, O
AF Rothenberg, David
   Roeske, Tina C.
   Voss, Henning U.
   Naguib, Marc
   Tchernichovski, Ofer
TI Investigation of musicality in birdsong
SO HEARING RESEARCH
LA English
DT Review
ID EXTRA-PAIR PATERNITY; AUDITORY RESPONSES; FUNCTIONAL MRI; VOCAL CONTROL;
   HEMISPHERIC-DIFFERENCES; NEURAL LATERALIZATION; DOPAMINERGIC SYSTEM;
   ANTERIOR FOREBRAIN; LUSCINIA-LUSCINIA; CONSPECIFIC SONG
AB Songbirds spend much of their time learning, producing, and listening to complex vocal sequences we call songs. Songs are learned via cultural transmission, and singing, usually by males, has a strong impact on the behavioral state of the listeners, often promoting affiliation, pair bonding, or aggression. What is it in the acoustic structure of birdsong that makes it such a potent stimulus? We suggest that birdsong potency might be driven by principles similar to those that make music so effective in inducing emotional responses in humans: a combination of rhythms and pitches and the transitions between acoustic states affecting emotions through creating expectations, anticipations, tension, tension release, or surprise. Here we propose a framework for investigating how birdsong, like human music, employs the above "musical" features to affect the emotions of avian listeners. First we analyze songs of thrush nightingales (Luscinia luscinia) by examining their trajectories in terms of transitions in rhythm and pitch. These transitions show gradual escalations and graceful modifications, which are comparable to some aspects of human musicality. We then explore the feasibility of stripping such putative musical features from the songs and testing how this might affect patterns of auditory responses, focusing on fMRI data in songbirds that demonstrate the feasibility of such approaches. Finally, we explore ideas for investigating whether musical features of birdsong activate avian brains and affect avian behavior in manners comparable to music's effects on humans. In conclusion, we suggest that birdsong research would benefit from current advances in music theory by attempting to identify structures that are designed to elicit listeners' emotions and then testing for such effects experimentally. Birdsong research that takes into account the striking complexity of song structure in light of its more immediate function to affect behavioral state in listeners could provide a useful animal model for studying basic principles of music neuroscience in a system that is very accessible for investigation, and where developmental auditory and social experience can be tightly controlled.
   This article is part of a Special Issue entitled <Music: A window into the hearing brain>. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Rothenberg, David] New Jersey Inst Technol, Dept Humanities, Newark, NJ 07102 USA.
   [Roeske, Tina C.; Tchernichovski, Ofer] CUNY Hunter Coll, Dept Psychol, New York, NY 10065 USA.
   [Voss, Henning U.] Weill Cornell Med Coll, Dept Radiol, Citigrp Biomed Imaging Ctr, New York, NY 10021 USA.
   [Naguib, Marc] Wageningen Univ, Dept Anim Sci, Behav Ecol Grp, NL-6700 AP Wageningen, Netherlands.
C3 New Jersey Institute of Technology; City University of New York (CUNY)
   System; Hunter College (CUNY); Cornell University; Weill Cornell
   Medicine; Wageningen University & Research
RP Tchernichovski, O (corresponding author), CUNY Hunter Coll, Dept Psychol, New York, NY 10065 USA.
EM tchernichovski@gmail.com
RI Naguib, Marc/C-2650-2009; Voss, Henning/C-2194-2009; Tchernichovski,
   Ofer/AAC-5678-2019
OI Voss, Henning/0000-0003-2811-2074; Tchernichovski,
   Ofer/0000-0001-6788-614X; Naguib, Marc/0000-0003-0494-4888
FU NSF [1261872]; NIH [PHS DC04722]; Direct For Biological Sciences;
   Division Of Integrative Organismal Systems [0956306, 1261872] Funding
   Source: National Science Foundation
FX We thank E. Janney for comments and suggestions. Supported by NSF award
   1261872 to OT & HV and by NIH award PHS DC04722 to OT.
CR Abe K, 2011, NAT NEUROSCI, V14, P1067, DOI 10.1038/nn.2869
   ADRET P, 1993, ANIM BEHAV, V46, P149, DOI 10.1006/anbe.1993.1170
   Amrhein V, 2004, P ROY SOC B-BIOL SCI, V271, pS167, DOI 10.1098/rsbl.2003.0133
   Amrhein V, 2002, ANIM BEHAV, V64, P939, DOI 10.1006/anbe.2002.1974
   [Anonymous], 2011, ORIGINS GRAMMAR
   [Anonymous], 1943, SONG WOOD PEWEE MYIO
   [Anonymous], FRONTIERS EVOLUTIONA
   [Anonymous], 2010, HDB MUSIC EMOTION
   Araya-Salas M, 2012, ANIM BEHAV, V84, P309, DOI 10.1016/j.anbehav.2012.04.038
   Ballentine B, 2004, BEHAV ECOL, V15, P163, DOI 10.1093/beheco/arg090
   Baptista LF, 2005, PERSPECT BIOL MED, V48, P426, DOI 10.1353/pbm.2005.0066
   Benitez-Bribiesca L, 2001, SCIENCE, V292, P2432
   Berwick Robert C, 2012, Front Evol Neurosci, V4, P5, DOI 10.3389/fnevo.2012.00005
   Berwick RC, 2011, TRENDS COGN SCI, V15, P113, DOI 10.1016/j.tics.2011.01.002
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Bloomfield TC, 2011, NAT NEUROSCI, V14, P947, DOI 10.1038/nn.2884
   Bolhuis JJ, 2010, NAT REV NEUROSCI, V11, P747, DOI 10.1038/nrn2931
   Boumans T., 2005, J CEREB BLOOD FLOW M, V25, pS388
   Boumans T, 2008, J NEUROPHYSIOL, V99, P931, DOI 10.1152/jn.00483.2007
   Boumans T, 2007, EUR J NEUROSCI, V26, P2613, DOI 10.1111/j.1460-9568.2007.05865.x
   Boumans T, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003184
   Brenowitz EA, 2005, TRENDS NEUROSCI, V28, P127, DOI 10.1016/j.tins.2005.01.004
   Brumm H, 2012, J POP MUSIC STUD, V24, P25, DOI 10.1111/j.1533-1598.2012.01314.x
   Callan DE, 2006, NEUROIMAGE, V31, P1327, DOI 10.1016/j.neuroimage.2006.01.036
   Cardin JA, 2003, J NEUROPHYSIOL, V90, P2884, DOI 10.1152/jn.00391.2003
   Catchpole CK, 2008, BIRD SONG: BIOLOGICAL THEMES AND VARIATIONS, 2ND EDITION, P1, DOI 10.1017/CBO9780511754791
   CATCHPOLE CK, 1983, ANIM BEHAV, V31, P1217, DOI 10.1016/S0003-3472(83)80028-1
   CATCHPOLE CK, 1980, BEHAVIOUR, V74, P149, DOI 10.1163/156853980X00366
   Chapin H, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0013812
   CHEW SJ, 1995, P NATL ACAD SCI USA, V92, P3406, DOI 10.1073/pnas.92.8.3406
   CYNX J, 1992, P NATL ACAD SCI USA, V89, P1372, DOI 10.1073/pnas.89.4.1372
   DEUTSCH D, 1980, PERCEPT PSYCHOPHYS, V28, P381, DOI 10.3758/BF03204881
   DOBSON CW, 1977, J ACOUST SOC AM, V61, P888, DOI 10.1121/1.381345
   Doupe AJ, 2005, TRENDS NEUROSCI, V28, P353, DOI 10.1016/j.tins.2005.05.005
   Doupe AJ, 1997, J NEUROSCI, V17, P1147
   Doupe AJ, 1999, ANNU REV NEUROSCI, V22, P567, DOI 10.1146/annurev.neuro.22.1.567
   DOWSETT-LEMAIRE F, 1979, Gerfaut, V69, P475
   DOWSETTLEMAIRE F, 1979, IBIS, V121, P453, DOI 10.1111/j.1474-919X.1979.tb06685.x
   Dunn AM, 1997, BEHAVIOUR, V134, P127, DOI 10.1163/156853997X00313
   Egermann H., 2013, COGN AFFECT BEHAV NE, P1
   ERIKSSON D, 1986, BEHAV ECOL SOCIOBIOL, V19, P297, DOI 10.1007/BF00300645
   Espino GG, 2003, NEUROSCIENCE, V122, P521, DOI 10.1016/S0306-4522(03)00549-9
   Fehér O, 2009, NATURE, V459, P564, DOI 10.1038/nature07994
   Fitch WT, 2006, COGNITION, V100, P173, DOI 10.1016/j.cognition.2005.11.009
   Fitch W Tecumseh, 2011, Front Evol Neurosci, V3, P9, DOI 10.3389/fnevo.2011.00009
   Floody OR, 1997, HORM BEHAV, V31, P25, DOI 10.1006/hbeh.1997.1368
   Forstmeier W, 2002, P ROY SOC B-BIOL SCI, V269, P1479, DOI 10.1098/rspb.2002.2039
   Gentner TQ, 2010, P NATL ACAD SCI USA, V107, pE65, DOI 10.1073/pnas.1000501107
   Gentner TQ, 2006, NATURE, V440, P1204, DOI 10.1038/nature04675
   Gentner TQ, 2000, ANIM BEHAV, V59, P443, DOI 10.1006/anbe.1999.1313
   George I, 2005, J COMP NEUROL, V488, P48, DOI 10.1002/cne.20584
   Gray PM, 2001, SCIENCE, V291, P52, DOI 10.1126/SCIENCE.1056960
   Griessmann B, 2002, ETHOLOGY, V108, P377, DOI 10.1046/j.1439-0310.2002.00781.x
   HALL M. F., 1962, SYMPOSIA ZOOL SOC LONDON, V8, P37
   Halle F, 2003, J NEUROBIOL, V56, P303, DOI 10.1002/neu.10230
   Hara E, 2007, EUR J NEUROSCI, V25, P3406, DOI 10.1111/j.1460-9568.2007.05600.x
   HARTLEY RS, 1990, J NEUROBIOL, V21, P1236, DOI 10.1002/neu.480210808
   Hartshorne C., 1973, Born to Sing: An Interpretation and World Survey ofBird Song
   HARTSHORNE CHARLES, 1958, IBIS, V100, P421, DOI 10.1111/j.1474-919X.1958.tb00406.x
   Hasselquist D, 1996, NATURE, V381, P229, DOI 10.1038/381229a0
   Haueisen J, 2001, J COGNITIVE NEUROSCI, V13, P786, DOI 10.1162/08989290152541449
   Henry KS, 2008, ANIM BEHAV, V76, P1659, DOI 10.1016/j.anbehav.2008.08.003
   Hickok G, 2003, J COGNITIVE NEUROSCI, V15, P673, DOI 10.1162/089892903322307393
   Holveck MJ, 2010, P ROY SOC B-BIOL SCI, V277, P153, DOI 10.1098/rspb.2009.1222
   Hughes M, 2002, ETHOLOGY, V108, P97, DOI 10.1046/j.1439-0310.2002.00720.x
   HULTSCH H, 1981, BEHAV ECOL SOCIOBIOL, V8, P183, DOI 10.1007/BF00299828
   Huron D, 2003, MUSIC PERCEPT, V21, P267, DOI 10.1525/mp.2003.21.2.267
   HURON DAVID, 2006, SWEET ANTICIPATION M, P148, DOI DOI 10.7551/MITPRESS/6575.001.0001
   Jarvis ED, 1998, NEURON, V21, P775, DOI 10.1016/S0896-6273(00)80594-2
   Jarvis ED, 2005, NAT REV NEUROSCI, V6, P151, DOI 10.1038/nrn1606
   Jarvis ED, 2007, J ORNITHOL, V148, pS35, DOI 10.1007/s10336-007-0243-0
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Kao MH, 2008, J NEUROSCI, V28, P13232, DOI 10.1523/JNEUROSCI.2250-08.2008
   Kipper S, 2006, ANIM BEHAV, V71, P211, DOI 10.1016/j.anbehav.2005.04.011
   Kipper S, 2010, ADV STUD BEHAV, V41, P77, DOI 10.1016/S0065-3454(10)41003-7
   Kneutgen J., 1969, J ORNITHOL, V110, P246
   Koelsch S, 2006, HUM BRAIN MAPP, V27, P239, DOI 10.1002/hbm.20180
   Kubikova L, 2010, J CHEM NEUROANAT, V39, P112, DOI 10.1016/j.jchemneu.2009.10.004
   Kunc HP, 2005, BEHAVIOUR, V142, P1077, DOI 10.1163/156853905774405317
   Lipkind D, 2013, NATURE, V498, P104, DOI 10.1038/nature12173
   MARGOLIASH D, 1985, P NATL ACAD SCI USA, V82, P5997, DOI 10.1073/pnas.82.17.5997
   Margoliash D, 2009, TRENDS COGN SCI, V13, P505, DOI 10.1016/j.tics.2009.10.003
   Marler P, 2000, ORIGINS OF MUSIC, P31
   Marler P., 2004, BIRD CALLS CORNUCOPI, P132
   Mathews F.S., 2001, FIELD BOOK WILD BIRD
   Maul KK, 2010, DEV NEUROBIOL, V70, P28, DOI 10.1002/dneu.20751
   McGregor Peter K., 1996, P409
   Meyer LB., 1956, Emotion and meaning in music
   Mitterschiffthaler MT, 2007, HUM BRAIN MAPP, V28, P1150, DOI 10.1002/hbm.20337
   Montag C, 2011, BEHAV BRAIN RES, V225, P511, DOI 10.1016/j.bbr.2011.08.012
   Mooney R, 1997, CURR BIOL, V7, pR289, DOI 10.1016/S0960-9822(06)00139-4
   Mooney R, 2002, J COMP PHYSIOL A, V188, P879, DOI 10.1007/s00359-002-0353-3
   Moorman S, 2012, P NATL ACAD SCI USA, V109, P12782, DOI 10.1073/pnas.1207207109
   MORRIS D, 1954, BEHAVIOUR, V6, P271, DOI 10.1163/156853954X00130
   MORRIS D, 1954, BEHAVIOUR, V7, P1, DOI 10.1163/156853955X00012
   NAGUIB M, 1992, J ORNITHOL, V133, P133, DOI 10.1007/BF01639906
   Naguib M, 2002, BEHAV ECOL SOCIOBIOL, V52, P216, DOI 10.1007/s00265-002-0511-1
   Naguib M, 1998, J AVIAN BIOL, V29, P155, DOI 10.2307/3677193
   Naguib M, 2011, ADV STUD BEHAV, V43, P239, DOI 10.1016/B978-0-12-380896-7.00005-8
   Ng Y.S., 2003, ANN M SOC MUS PERC C
   NOTTEBOHM F, 1971, J EXP ZOOL, V177, P229, DOI 10.1002/jez.1401770210
   NOTTEBOHM F, 1972, J EXP ZOOL, V179, P35, DOI 10.1002/jez.1401790104
   Pa J, 2008, NEUROPSYCHOLOGIA, V46, P362, DOI 10.1016/j.neuropsychologia.2007.06.024
   Peeters RR, 2001, MAGN RESON IMAGING, V19, P821, DOI 10.1016/S0730-725X(01)00391-5
   Pereira CS, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027241
   Phan ML, 2010, P NATL ACAD SCI USA, V107, P2301, DOI 10.1073/pnas.0900091107
   Podos J, 1996, ANIM BEHAV, V51, P1061, DOI 10.1006/anbe.1996.0107
   Podos J, 2009, ADV STUD BEHAV, V40, P159, DOI 10.1016/S0065-3454(09)40005-6
   Poirier C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020131
   Poirier C, 2010, NMR BIOMED, V23, P1027, DOI 10.1002/nbm.1525
   Poirier C, 2009, J NEUROSCI, V29, P2252, DOI 10.1523/JNEUROSCI.4650-08.2009
   Prather JF, 2008, NATURE, V451, P305, DOI 10.1038/nature06492
   Remage-Healey L, 2010, P NATL ACAD SCI USA, V107, P3852, DOI 10.1073/pnas.0906572107
   Riebel K, 2000, P ROY SOC B-BIOL SCI, V267, P2553, DOI 10.1098/rspb.2000.1320
   Riebel K, 2009, ANIM BEHAV, V78, P1397, DOI 10.1016/j.anbehav.2009.09.011
   Riters LV, 2011, NEUROSCI BIOBEHAV R, V35, P1837, DOI 10.1016/j.neubiorev.2010.12.017
   ROBINSON FN, 1991, EMU, V91, P61, DOI 10.1071/MU9910061
   Roth T, 2009, P ROY SOC B-BIOL SCI, V276, P2045, DOI 10.1098/rspb.2008.1726
   Rothenberg David, 2005, Why Birds Sing: A Journey Into the Mystery of Bird Song
   Sakata JT, 2008, J NEUROPHYSIOL, V99, P1700, DOI 10.1152/jn.01296.2007
   Salimpoor VN, 2013, SCIENCE, V340, P216, DOI 10.1126/science.1231059
   Salimpoor VN, 2011, NAT NEUROSCI, V14, P257, DOI 10.1038/nn.2726
   Sasaki A, 2006, J NEUROSCI, V26, P9010, DOI 10.1523/JNEUROSCI.1335-06.2006
   Simonyan K, 2012, BRAIN LANG, V122, P142, DOI 10.1016/j.bandl.2011.12.009
   Slater P., 2001, ORIGINS MUSIC, P49
   Sloboda John A., 2005, Exploring the Musical Mind Cognition, Emotion, Ability, Function
   Soha JA, 2000, ANIM BEHAV, V60, P297, DOI 10.1006/anbe.2000.1499
   Solis MM, 1997, J NEUROSCI, V17, P6447
   SORJONEN J, 1977, Ornis Fennica, V54, P101
   Sotavalta O., 1956, ANN FINNISH ZOOL SOC, V17
   Stepanek L, 2010, J NEUROPHYSIOL, V104, P2474, DOI 10.1152/jn.00977.2009
   Taylor H, 2013, SOC SCI INFORM, V52, P287, DOI 10.1177/0539018413477520
   Tchernichovski O, 2000, ANIM BEHAV, V59, P1167, DOI 10.1006/anbe.1999.1416
   Theunissen FE, 1998, J NEUROSCI, V18, P3786
   Thorpe W.H., 1972, BEHAVIOUR S18, V18
   Tierney AT, 2011, P NATL ACAD SCI USA, V108, P15510, DOI 10.1073/pnas.1103882108
   Van der Linden A, 2009, TRENDS NEUROSCI, V32, P257, DOI 10.1016/j.tins.2009.01.005
   van Heijningen CAA, 2009, P NATL ACAD SCI USA, V106, P20538, DOI 10.1073/pnas.0908113106
   Van Meir V, 2005, NEUROIMAGE, V25, P1242, DOI 10.1016/j.neuroimage.2004.12.058
   Van Meir V., 2003, SOC NEUROSCI, P1298
   VICARIO DS, 1993, J NEUROBIOL, V24, P488, DOI 10.1002/neu.480240407
   Voss H.U., 2007, IBRO WORLD C NEUR ME
   Voss HU, 2007, P NATL ACAD SCI USA, V104, P10667, DOI 10.1073/pnas.0611515104
   Voss HU, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0014415
   West M.J., 1985, P245
   White SA, 2010, BRAIN LANG, V115, P21, DOI 10.1016/j.bandl.2009.10.002
   WILLIAMS H, 1992, J NEUROBIOL, V23, P1006, DOI 10.1002/neu.480230807
   Woolley SMN, 2006, J NEUROSCI, V26, P2499, DOI 10.1523/JNEUROSCI.3731-05.2006
   Woolley SMN, 2005, NAT NEUROSCI, V8, P1371, DOI 10.1038/nn1536
   Zollinger SA, 2004, P ROY SOC B-BIOL SCI, V271, P483, DOI 10.1098/rspb.2003.2598
NR 150
TC 40
Z9 44
U1 2
U2 83
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0378-5955
EI 1878-5891
J9 HEARING RES
JI Hear. Res.
PD FEB
PY 2014
VL 308
SI SI
BP 71
EP 83
DI 10.1016/j.heares.2013.08.016
PG 13
WC Audiology & Speech-Language Pathology; Neurosciences;
   Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Audiology & Speech-Language Pathology; Neurosciences & Neurology;
   Otorhinolaryngology
GA AA9QO
UT WOS:000331428200008
PM 24036130
OA Green Accepted
DA 2024-01-09
ER

PT J
AU Parsons, CE
   Young, KS
   Jegindo, EME
   Vuust, P
   Stein, A
   Kringelbach, ML
AF Parsons, Christine E.
   Young, Katherine S.
   Jegindo, Else-Marie E.
   Vuust, Peter
   Stein, Alan
   Kringelbach, Morten L.
TI Music training and empathy positively impact adults' sensitivity to
   infant distress
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE parenting; crying; vocalization; music; empathy; emotion perception;
   parent-infant; vocal emotion perception
ID CAREGIVING RESPONSES; SOCIOECONOMIC-STATUS; DEPRESSIVE SYMPTOMS;
   MATERNAL DEPRESSION; ACOUSTIC FEATURES; PAIN CRIES; VAGAL TONE;
   OXYTOCIN; SPEECH; PITCH
AB Crying is the most powerful auditory signal of infant need. Adults' ability to perceive and respond to crying is important for infant survival and in the provision of care. This study investigated a number of listener variables that might impact on adults' perception of infant cry distress, namely parental status, musical training, and empathy. Sensitivity to infant distress was tested using a previously validated task, which experimentally manipulated distress by varying the pitch of infant cries. This task required that participants discriminate between pitch differences and interpret these as differences in infant distress. Parents with musical training showed a significant advantage on this task when compared with parents without. The extent of the advantage was correlated with the amount of self-reported musical training. For non-parents, individual differences in empathy were associated with task performance, with higher empathy scores corresponding to greater sensitivity to infant distress. We suggest that sensitivity to infant distress can be impacted by a number of listener variables, and may be amenable to training.
C1 [Parsons, Christine E.; Young, Katherine S.; Stein, Alan; Kringelbach, Morten L.] Univ Oxford, Dept Psychiat, Oxford OX3 7JX, England.
   [Parsons, Christine E.; Young, Katherine S.; Jegindo, Else-Marie E.; Vuust, Peter; Kringelbach, Morten L.] Aarhus Univ, Ctr Funct Integrat Neurosci, Aarhus, Denmark.
   [Young, Katherine S.] Univ Calif Los Angeles, Dept Psychol, Los Angeles, CA 90024 USA.
   [Vuust, Peter] Royal Acad Mus, Aarhus, Denmark.
C3 University of Oxford; Aarhus University; University of California
   System; University of California Los Angeles
RP Kringelbach, ML (corresponding author), Univ Oxford, Warneford Hosp, Dept Psychiat, Oxford OX3 7JX, England.
EM morten.kringelbach@psych.ox.ac.uk
RI Kringelbach, Morten/AAW-5847-2021; Young, Katherine/O-9198-2017; Stein,
   Airton T/AAD-8391-2020; Campailla, Jasmin/AAK-2420-2021; Parsons,
   Christine/V-3571-2019; Kringelbach, Morten L/AAF-5508-2020; Parsons,
   Christine E/G-9286-2016
OI Kringelbach, Morten/0000-0002-3908-6898; Young,
   Katherine/0000-0002-1378-6415; Stein, Airton T/0000-0002-8756-8699;
   Parsons, Christine/0000-0003-2856-6308; Parsons, Christine
   E/0000-0003-2856-6308; Stein, Alan/0000-0001-8207-2822
CR Adams S, 2013, TRIALS, V14, DOI 10.1186/1745-6215-14-161
   Amitay S, 2006, J ACOUST SOC AM, V119, P1616, DOI 10.1121/1.2164988
   Amitay S, 2006, NAT NEUROSCI, V9, P1446, DOI 10.1038/nn1787
   Bakermans-Kranenburg MJ, 2008, SOC COGN AFFECT NEUR, V3, P128, DOI 10.1093/scan/nsn004
   Bakermans-Kranenburg MJ, 2008, DEV PSYCHOL, V44, P293, DOI 10.1037/0012-1649.44.1.293
   Baron-Cohen S, 2004, J AUTISM DEV DISORD, V34, P163, DOI 10.1023/B:JADD.0000022607.19833.00
   Bate S, 2010, PERS INDIV DIFFER, V48, P239, DOI 10.1016/j.paid.2009.10.005
   Beck AT, 1996, Manual for the BDI-II, V2nd
   BETTES BA, 1988, CHILD DEV, V59, P1089, DOI 10.2307/1130275
   Bhandari R, 2014, SOC NEUROSCI-UK, V9, P536, DOI 10.1080/17470919.2014.932307
   Bhandari R, 2014, PHYSIOL BEHAV, V131, P123, DOI 10.1016/j.physbeh.2014.04.028
   BOUKYDIS CFZ, 1982, CHILD DEV, V53, P1291, DOI 10.2307/1129019
   Davis M. H., 1980, JSAS Catalog of Selected Documents in Psychology, V10, P85
   De Pisapia N, 2013, NEUROREPORT, V24, P142, DOI 10.1097/WNR.0b013e32835df4fa
   Decety J, 2014, TRENDS COGN SCI, V18, P337, DOI 10.1016/j.tics.2014.04.008
   Del Vecchio T, 2009, INFANT BEHAV DEV, V32, P117, DOI 10.1016/j.infbeh.2008.10.005
   Dessureau BK, 1998, INFANT BEHAV DEV, V21, P367, DOI 10.1016/S0163-6383(98)90013-3
   Dohn A, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0037961
   Donovan WL, 1998, INFANT BEHAV DEV, V21, P505, DOI 10.1016/S0163-6383(98)90023-6
   Feldman R, 2013, NEUROPSYCHOPHARMACOL, V38, P1154, DOI 10.1038/npp.2013.22
   Giardino J, 2008, HORM BEHAV, V53, P149, DOI 10.1016/j.yhbeh.2007.09.010
   Gordon I, 2010, BIOL PSYCHIAT, V68, P377, DOI 10.1016/j.biopsych.2010.02.005
   Green J., 2000, CRYING SIGN SYMPTOM, V152, P137
   GRUNAU RVE, 1990, PAIN, V42, P295, DOI 10.1016/0304-3959(90)91142-6
   Hall A. E, 1989, 3 STRESS TENSION CON, DOI [10.1007/978-1-4615-7915-1_24, DOI 10.1007/978-1-4615-7915-1_24]
   Hurlemann R, 2010, J NEUROSCI, V30, P4999, DOI 10.1523/JNEUROSCI.5538-09.2010
   Irwin JR, 2003, INFANCY, V4, P503, DOI 10.1207/S15327078IN0404_06
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   LaGasse LL, 2005, MENT RETARD DEV D R, V11, P83, DOI 10.1002/mrdd.20050
   Lawrence EJ, 2004, PSYCHOL MED, V34, P911, DOI 10.1017/S0033291703001624
   Lawrence PJ, 2013, CLIN CHILD PSYCHOL P, V18, P61, DOI 10.1177/1359104512437210
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Lin HC, 2012, INFANT BEHAV DEV, V35, P887, DOI 10.1016/j.infbeh.2012.08.001
   Lockwood P, 2013, J INDIVID DIFFER, V34, P41, DOI 10.1027/1614-0001/a000098
   Magne C, 2006, J COGNITIVE NEUROSCI, V18, P199, DOI 10.1162/089892906775783660
   Marques C, 2007, J COGNITIVE NEUROSCI, V19, P1453, DOI 10.1162/jocn.2007.19.9.1453
   Mascaro JS, 2014, PSYCHONEUROENDOCRINO, V46, P153, DOI 10.1016/j.psyneuen.2014.04.014
   MILLER AR, 1993, PEDIATRICS, V92, P551
   Muncer SJ, 2006, PERS INDIV DIFFER, V40, P1111, DOI 10.1016/j.paid.2005.09.020
   MURRAY L, 1993, J CHILD PSYCHOL PSYC, V34, P1083, DOI 10.1111/j.1469-7610.1993.tb01775.x
   Musacchia G, 2007, P NATL ACAD SCI USA, V104, P15894, DOI 10.1073/pnas.0701498104
   Nair D., 2002, P 7 INT C MUS PERC C, V627, P627
   Nakata T, 2004, INFANT BEHAV DEV, V27, P455, DOI 10.1016/j.infbeh.2004.03.002
   Out D, 2010, CHILD ABUSE NEGLECT, V34, P863, DOI 10.1016/j.chiabu.2010.05.003
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Parsons CE, 2010, PROG NEUROBIOL, V91, P220, DOI 10.1016/j.pneurobio.2010.03.001
   Parsons CE, 2014, SOC COGN AFFECT NEUR, V9, P977, DOI 10.1093/scan/nst076
   Parsons CE, 2014, DEVELOPMENTAL SCI, V17, P257, DOI 10.1111/desc.12112
   Parsons CE, 2013, SOC NEUROSCI-UK, V8, P268, DOI 10.1080/17470919.2013.795189
   Parsons CE, 2012, ACTA PAEDIATR, V101, pE189, DOI 10.1111/j.1651-2227.2011.02554.x
   Parsons CE, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00562
   Penton-Voak IS, 2007, PERS INDIV DIFFER, V43, P2229, DOI 10.1016/j.paid.2007.07.004
   Penton-Voak IS, 2012, BRIT J PSYCHIAT, V201, P71, DOI 10.1192/bjp.bp.111.107086
   Porges SW, 1997, ANN NY ACAD SCI, V807, P62, DOI 10.1111/j.1749-6632.1997.tb51913.x
   PORGES SW, 1995, NEUROSCI BIOBEHAV R, V19, P225, DOI 10.1016/0149-7634(94)00066-A
   PORTER FL, 1986, CHILD DEV, V57, P790, DOI 10.2307/1130355
   PORTER FL, 1988, CHILD DEV, V59, P495, DOI 10.1111/j.1467-8624.1988.tb01483.x
   Protopapas A, 1997, J ACOUST SOC AM, V102, P3723, DOI 10.1121/1.420403
   Raviv T, 2004, EARLY CHILD RES Q, V19, P528, DOI 10.1016/j.ecresq.2004.10.007
   Rilling JK, 2014, SCIENCE, V345, P771, DOI 10.1126/science.1252723
   Rodrigues SM, 2009, P NATL ACAD SCI USA, V106, P21437, DOI 10.1073/pnas.0909579106
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Schön D, 2004, PSYCHOPHYSIOLOGY, V41, P341, DOI 10.1111/1469-8986.00172.x
   Schuetze P, 2003, INFANCY, V4, P65, DOI 10.1207/S15327078IN0401_4
   Schuetze P, 2001, INFANCY, V2, P483, DOI 10.1207/S15327078IN0204_06
   Seifritz E, 2003, BIOL PSYCHIAT, V54, P1367, DOI 10.1016/S0006-3223(03)00697-8
   Soderstrom M, 2007, DEV REV, V27, P501, DOI 10.1016/j.dr.2007.06.002
   Sohr-Preston SL, 2006, CLIN CHILD FAM PSYCH, V9, P65, DOI 10.1007/s10567-006-0004-2
   Soltis J, 2004, BEHAV BRAIN SCI, V27, P443, DOI 10.1017/S0140525X0400010X
   Stallings J, 2001, PARENT-SCI PRACT, V1, P71, DOI 10.1207/S15327922PAR011&2_5
   Stein A, 2008, CHILD CARE HLTH DEV, V34, P603, DOI 10.1111/j.1365-2214.2008.00837.x
   Stein A, 2006, AM J PSYCHIAT, V163, P899, DOI 10.1176/appi.ajp.163.5.899
   Stifter CA, 2003, J REPROD INFANT PSYC, V21, P309, DOI 10.1080/02646830310001622123
   Strait DL, 2009, ANN NY ACAD SCI, V1169, P209, DOI 10.1111/j.1749-6632.2009.04864.x
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Trehub SE, 2001, ANN NY ACAD SCI, V930, P1
   Trimmer CG, 2008, EMOTION, V8, P838, DOI 10.1037/a0014080
   Voorthuis A, 2014, BRAIN RES, V1580, P151, DOI 10.1016/j.brainres.2013.10.051
   Vuust P, 2012, NEUROPSYCHOLOGIA, V50, P1432, DOI 10.1016/j.neuropsychologia.2012.02.028
   Wakabayashi A, 2006, PERS INDIV DIFFER, V41, P929, DOI 10.1016/j.paid.2006.03.017
   Wallentin M, 2010, LEARN INDIVID DIFFER, V20, P188, DOI 10.1016/j.lindif.2010.02.004
   Wang YP, 2013, REV BRAS PSIQUIATR, V35, P416, DOI 10.1590/1516-4446-2012-1048
   Weisman O, 2014, PROG NEURO-PSYCHOPH, V49, P47, DOI 10.1016/j.pnpbp.2013.11.006
   Wood RM, 2001, CHILD DEV, V72, P1287, DOI 10.1111/1467-8624.00348
   Wright BA, 2007, EXP BRAIN RES, V180, P727, DOI 10.1007/s00221-007-0898-z
   Young KS, 2012, EMOTION, V12, P1200, DOI 10.1037/a0028705
   Zeskind P. S., 1995, BIENN M SOC RES CHID
   ZESKIND PS, 1988, CHILD DEV, V59, P193
   ZESKIND PS, 1978, CHILD DEV, V49, P580, DOI 10.1111/j.1467-8624.1978.tb02357.x
   ZESKIND PS, 1987, INFANT BEHAV DEV, V10, P501, DOI 10.1016/0163-6383(87)90046-4
NR 90
TC 11
Z9 15
U1 0
U2 26
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD DEC 19
PY 2014
VL 5
AR 1440
DI 10.3389/fpsyg.2014.01440
PG 8
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA AY4UF
UT WOS:000347572700001
PM 25566122
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Van Puyvelde, M
   Loots, G
   Vanfleteren, P
   Meys, J
   Simcock, D
   Pattyn, N
AF Van Puyvelde, Martine
   Loots, Gerrit
   Vanfleteren, Pol
   Meys, Joris
   Simcock, David
   Pattyn, Nathalie
TI Do You Hear the Same? Cardiorespiratory Responses between Mothers and
   Infants during Tonal and Atonal Music
SO PLOS ONE
LA English
DT Article
ID RESPIRATORY SINUS ARRHYTHMIA; CARDIAC VAGAL TONE; NEUROVISCERAL
   INTEGRATION; RATE-VARIABILITY; PRETERM INFANTS; CARE-UNIT; EMOTION
   REGULATION; UNPLEASANT MUSIC; FUNCTIONAL MRI; HUMAN BRAIN
AB This study examined the effects of tonal and atonal music on respiratory sinus arrhythmia (RSA) in 40 mothers and their 3-month-old infants. The tonal music fragment was composed using the structure of a harmonic series that corresponds with the pitch ratio characteristics of mother-infant vocal dialogues. The atonal fragment did not correspond with a tonal structure. Mother-infant ECG and respiration were registered along with simultaneous video recordings. RR-interval, respiration rate, and RSA were calculated. RSA was corrected for any confounding respiratory and motor activities. The results showed that the infants' and the mothers' RSA-responses to the tonal and atonal music differed. The infants showed significantly higher RSA-levels during the tonal fragment than during the atonal fragment and baseline, suggesting increased vagal activity during tonal music. The mothers showed RSA-responses that were equal to their infants only when the infants were lying close to their bodies and when they heard the difference between the two fragments, preferring the tonal above the atonal fragment. The results are discussed with regard to music-related topics, psychophysiological integration and mother-infant vocal interaction processes.
C1 [Van Puyvelde, Martine; Loots, Gerrit; Vanfleteren, Pol] Vrije Univ Brussel, Fac Psychol & Educ Sci, Discurs & Narrat Studies IDNS, Res Grp Interpersonal, Brussels, Belgium.
   [Van Puyvelde, Martine; Pattyn, Nathalie] Royal Mil Acad, VIPER Res Unit, Brussels, Belgium.
   [Loots, Gerrit] Univ Catolica Boliviana San Pablo, La Paz, Bolivia.
   [Meys, Joris] Univ Ghent, Dept Math Modeling Stat & Bioinformat, Fac Biosci Engn, B-9000 Ghent, Belgium.
   [Simcock, David] Massey Univ, Inst Food Nutr & Human Hlth, Palmerston North, New Zealand.
   [Simcock, David] James Cook Univ, Fac Med & Biosci, Townsville City, Qld, Australia.
   [Pattyn, Nathalie] Vrije Univ Brussel, Dept Expt & Appl Psychol, Brussels, Belgium.
C3 Vrije Universiteit Brussel; Ghent University; Massey University; James
   Cook University; Vrije Universiteit Brussel
RP Van Puyvelde, M (corresponding author), Vrije Univ Brussel, Fac Psychol & Educ Sci, Discurs & Narrat Studies IDNS, Res Grp Interpersonal, Brussels, Belgium.
EM mvpuyvel@vub.ac.be
RI Simcock, David C/J-9676-2014; Van Puyvelde, Martine/AAG-7610-2020;
   Ghiami, Zeinab/G-5492-2016
OI Simcock, David C/0000-0001-8959-9889; Pattyn,
   Nathalie/0000-0002-2690-5479; Loots, VUB/0000-0001-5015-9202; Van
   Puyvelde, Martine/0000-0002-6595-7597
FU OZR-Vrije Universiteit Brussel; Royal Military Academy of Brussels
FX This research was granted by OZR-Vrije Universiteit Brussel and the
   Royal Military Academy of Brussels. The funders had no role in study
   design, data collection and analysis, decision to publish or preparation
   of the manuscript.
CR [Anonymous], 2013, Phia: post-hoc interaction analysis. R package version 0.1-3
   [Anonymous], 2001, MUSIC EMOTION THEORY
   [Anonymous], 2013, R PACKAGE VERSION
   [Anonymous], 1981, CARDIOVASCULAR PSYCH
   Arnon S, 2006, BIRTH-ISS PERINAT C, V33, P131, DOI 10.1111/j.0730-7659.2006.00090.x
   Ball T, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000307
   Bazhenova OV, 2001, CHILD DEV, V72, P1314, DOI 10.1111/1467-8624.00350
   Berntson GG, 2007, BIOL PSYCHOL, V74, P295, DOI 10.1016/j.biopsycho.2006.08.006
   Berntson GG, 1997, PSYCHOPHYSIOLOGY, V34, P623, DOI 10.1111/j.1469-8986.1997.tb02140.x
   Bidelman GM, 2009, J NEUROSCI, V29, P13165, DOI 10.1523/JNEUROSCI.3900-09.2009
   Blood AJ, 1999, NAT NEUROSCI, V2, P382, DOI 10.1038/7299
   BOIK RJ, 1979, PSYCHOL BULL, V86, P1084, DOI 10.1037/0033-2909.86.5.1084
   BROWN TE, 1993, J APPL PHYSIOL, V75, P2310, DOI 10.1152/jappl.1993.75.5.2310
   BUSH LK, 1993, PSYCHOL BULL, V113, P566, DOI 10.1037/0033-2909.113.3.566
   Calkins SD, 1997, DEV PSYCHOBIOL, V31, P125, DOI 10.1002/(SICI)1098-2302(199709)31:2<125::AID-DEV5>3.0.CO;2-M
   DAVIS WB, 1989, J MUSIC THER, V26, P168, DOI 10.1093/jmt/26.4.168
   DoussardRoosevelt JA, 1997, CHILD DEV, V68, P173, DOI 10.1111/j.1467-8624.1997.tb01934.x
   Eckberg DL, 2003, J PHYSIOL-LONDON, V548, P339, DOI 10.1113/jphysiol.2002.037192
   Einthoven W, 1913, PFLUG ARCH GES PHYS, V150, P275, DOI 10.1007/BF01697566
   Feldman R, 2006, DEV PSYCHOL, V42, P175, DOI 10.1037/0012-1649.42.1.175
   Feldman R, 2011, INFANT BEHAV DEV, V34, P569, DOI 10.1016/j.infbeh.2011.06.008
   Feldman R, 2010, DEVELOPMENTAL SCI, V13, P271, DOI 10.1111/j.1467-7687.2009.00890.x
   Filippa M, 2013, ACTA PAEDIATR, V102, P1017, DOI 10.1111/apa.12356
   FINLEY JP, 1983, CAN J PHYSIOL PHARM, V61, P329, DOI 10.1139/y83-050
   Friedman BH, 2007, BIOL PSYCHOL, V74, P185, DOI 10.1016/j.biopsycho.2005.08.009
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   GIDDENS DP, 1985, J THEOR BIOL, V113, P759, DOI 10.1016/S0022-5193(85)80192-2
   Grossman P, 2004, AM J PHYSIOL-HEART C, V287, pH728, DOI 10.1152/ajpheart.00825.2003
   GROSSMAN P, 1990, PSYCHOPHYSIOLOGY, V27, P702, DOI 10.1111/j.1469-8986.1990.tb03198.x
   GROSSMAN P, 1991, PSYCHOPHYSIOLOGY, V28, P201, DOI 10.1111/j.1469-8986.1991.tb00412.x
   Grossman P, 2007, BIOL PSYCHOL, V74, P263, DOI 10.1016/j.biopsycho.2005.11.014
   GUZZETTA CE, 1989, HEART LUNG, V18, P609
   Ham J, 2006, ANN NY ACAD SCI, V1094, P297, DOI 10.1196/annals.1376.038
   Haslbeck FB, 2012, NORD J MUSIC THER, V21, P203, DOI 10.1080/08098131.2011.648653
   HIRSCH JA, 1981, AM J PHYSIOL, V241, pH620, DOI 10.1152/ajpheart.1981.241.4.H620
   Hofer MA, 1995, ATTACHMENT THEORY, P203
   HOLM S, 1979, SCAND J STAT, V6, P65
   Iwanaga M, 2005, BIOL PSYCHOL, V70, P61, DOI 10.1016/j.biopsycho.2004.11.015
   Iwanaga M, 1997, PERCEPT MOTOR SKILL, V85, P287, DOI 10.2466/pms.1997.85.1.287
   Knight AJ, 2011, REHABIL NURS, V36, P200
   Koelsch S, 2006, HUM BRAIN MAPP, V27, P239, DOI 10.1002/hbm.20180
   Koelsch S, 2010, TRENDS COGN SCI, V14, P131, DOI 10.1016/j.tics.2010.01.002
   Koelsch S, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0002631
   Krumhansl CL, 1997, CAN J EXP PSYCHOL, V51, P336, DOI 10.1037/1196-1961.51.4.336
   Lai HL, 2011, J ADV NURS, V67, P2414, DOI 10.1111/j.1365-2648.2011.05670.x
   Masataka N, 2006, DEVELOPMENTAL SCI, V9, P46, DOI 10.1111/j.1467-7687.2005.00462.x
   McDermott JH, 2010, CURR BIOL, V20, P1035, DOI 10.1016/j.cub.2010.04.019
   Mitterschiffthaler MT, 2007, HUM BRAIN MAPP, V28, P1150, DOI 10.1002/hbm.20337
   Moore GA, 2009, CHILD DEV, V80, P209, DOI 10.1111/j.1467-8624.2008.01255.x
   Morinville A, 2013, PSYCHOL AESTHET CREA, V7, P384, DOI 10.1037/a0034495
   Obrist PA, 1982, MEASURING EMOTIONS I, P299
   Pallesen KJ, 2005, ANN NY ACAD SCI, V1060, P450, DOI 10.1196/annals.1360.047
   Peretz I, 2003, ANN NY ACAD SCI, V999, P58, DOI 10.1196/annals.1284.006
   Plantinga J, 2014, J EXP PSYCHOL HUMAN, V40, P40, DOI 10.1037/a0033471
   PORGES SW, 1994, DEV PSYCHOBIOL, V27, P289, DOI 10.1002/dev.420270504
   Rickard N. S., 2004, Psychology of Music, V32, P371, DOI [10.1177%2F0305735604046096, DOI 10.1177/0305735604046096, 10.1177/0305735604046096]
   Ritz T, 2002, PSYCHOPHYSIOLOGY, V39, P546, DOI 10.1017/S0048577202010715
   Ritz T, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0052729
   ROTHER M, 1989, EARLY HUM DEV, V20, P1, DOI 10.1016/0378-3782(89)90068-6
   Sammler D, 2007, PSYCHOPHYSIOLOGY, V44, P293, DOI 10.1111/j.1469-8986.2007.00497.x
   Schäfer T, 2010, PSYCHOL AESTHET CREA, V4, P223, DOI 10.1037/a0018374
   Schlez A, 2011, ISR MED ASSOC J, V13, P354
   Schmidt LA, 2003, BRAIN COGNITION, V52, P27, DOI 10.1016/S0278-2626(03)00006-X
   Shenfield T., 2003, Psychol. Music, V31, P365, DOI DOI 10.1177/03057356030314002
   Sloboda J. A., 1991, Psychology of Music, V19, P110, DOI [10.1177/0305735691192002, DOI 10.1177/0305735691192002]
   Standley J, 2012, NEONATAL NETW, V31, P311, DOI 10.1891/0730-0832.31.5.311
   Stifter CA, 1999, CHILD DEV, V70, P21, DOI 10.1111/1467-8624.00003
   Thaut MH, 2003, ANN NY ACAD SCI, V999, P364, DOI 10.1196/annals.1284.044
   Thayer JF, 2000, J AFFECT DISORDERS, V61, P201, DOI 10.1016/S0165-0327(00)00338-4
   Thayer JF, 2009, NEUROSCI BIOBEHAV R, V33, P81, DOI 10.1016/j.neubiorev.2008.08.004
   Tininenko JR, 2012, BIOL PSYCHOL, V89, P562, DOI 10.1016/j.biopsycho.2011.12.022
   Trainor LJ, 1998, INFANT BEHAV DEV, V21, P77, DOI 10.1016/S0163-6383(98)90055-8
   Trainor LJ, 2002, MUSIC PERCEPT, V20, P187, DOI 10.1525/mp.2002.20.2.187
   Trehub SE, 2003, NAT NEUROSCI, V6, P669, DOI 10.1038/nn1084
   Trevarthen C, 2001, INFANT MENT HEALTH J, V22, P95, DOI 10.1002/1097-0355(200101/04)22:1<95::AID-IMHJ4>3.0.CO;2-6
   Tyrell J, 2001, NEW GROVE DICT MUSIC
   Van Puyvelde M, 2010, INFANT BEHAV DEV, V33, P387, DOI 10.1016/j.infbeh.2010.04.003
   Van Puyvelde M, 2013, INFANCY, V18, P849, DOI 10.1111/infa.12007
   White J M, 1999, Am J Crit Care, V8, P220
   WITTE H, 1992, BASIC RES CARDIOL, V87, P193, DOI 10.1007/BF00801966
   Zentner MR, 1998, INFANT BEHAV DEV, V21, P483, DOI 10.1016/S0163-6383(98)90021-2
NR 81
TC 9
Z9 10
U1 0
U2 24
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD SEP 10
PY 2014
VL 9
IS 9
AR e106920
DI 10.1371/journal.pone.0106920
PG 13
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Science & Technology - Other Topics
GA AP4EP
UT WOS:000342030300048
PM 25207803
OA Green Submitted, Green Published, gold, Green Accepted
DA 2024-01-09
ER

PT J
AU Nizamie, SH
   Tikka, SK
AF Nizamie, Shamsul Haque
   Tikka, Sai Krishna
TI Psychiatry and music
SO INDIAN JOURNAL OF PSYCHIATRY
LA English
DT Review
DE Major psychiatric disorders; music; music therapy; psychiatry
ID RANDOMIZED CONTROLLED-TRIAL; THERAPY; HALLUCINATIONS; DEPRESSION;
   CHILDREN; BRAIN; PREVALENCE; SYMPTOMS; INTERVENTION; ADOLESCENTS
AB Vocal and/or instrumental sounds combined in such a way as to produce beauty of form, harmony and expression of emotion is music. Brain, mind and music are remarkably related to each other and music has got a strong impact on psychiatry. With the advent of music therapy, as an efficient form of alternative therapy in treating major psychiatric conditions, this impact has been further strengthened. In this review, we deliberate upon the historical aspects of the relationship between psychiatry and music, neural processing underlying music, music's relation to classical psychology and psychopathology and scientific evidence base for music therapy in major psychiatric disorders. We highlight the role of Indian forms of music and Indian contribution to music therapy.
C1 [Nizamie, Shamsul Haque; Tikka, Sai Krishna] Cent Inst Psychiat, Dept Psychiat, Ranchi 834006, Jharkhand, India.
C3 Central Institute of Psychiatry
RP Tikka, SK (corresponding author), Cent Inst Psychiat, Dept Psychiat, Ranchi 834006, Jharkhand, India.
EM cricsai@gmail.com
RI Tikka, Sai Krishna/AAE-4604-2019; Tikka, Sai Krishna/AHH-0562-2022
OI Tikka, Sai Krishna/0000-0001-9032-1227
CR Altenmuller E. O., 2003, COGNITIVE NEUROSCIEN, P346, DOI DOI 10.1093/ACPR0F:0S0/9780198525202.003.0022
   [Anonymous], 2005, PSYCHOL MUSIC, DOI DOI 10.1177/0305735605056144
   [Anonymous], J MUSIC THERAPY
   [Anonymous], COCHRANE DATABASE SY, DOI DOI 10.1002/14651858.CD004381.PUB2
   [Anonymous], 1999, PSYCHOACOUSTICS FACT, DOI DOI 10.1007/978-3-662-09562-1
   [Anonymous], 1994, Journal of Research in Reading, DOI [10.1111/j.14679817.1994.tb00057.x, DOI 10.1111/J.14679817.1994.TB00057.X]
   [Anonymous], 2003, Cochrane Database of Systematic Reviews, DOI DOI 10.1002/14651858.CD003477.PUB2
   [Anonymous], ACOUSTICAL PERSPECTI
   [Anonymous], 1998, Hong Kong J Psychiatry
   [Anonymous], 2004, COCHRANE DB SYST REV, DOI DOI 10.1002/14651858.CD003012.PUB2
   Argstatter H, 2009, MUSIC AS THERAPY
   Ball CM., 2004, MUSIC THERAPY CHILDR
   Banerjee M, 2003, THESIS RANCHI U
   Bernardi L, 2006, HEART, V92, P445, DOI 10.1136/hrt.2005.064600
   BERRIOS GE, 1990, BRIT J PSYCHIAT, V156, P188, DOI 10.1192/bjp.156.2.188
   Blood AJ, 1999, NAT NEUROSCI, V2, P382, DOI 10.1038/7299
   Boso M, 2006, FUNCT NEUROL, V21, P187
   Bruscia KE, 1998, Defining music therapy, V2nd
   Chakrabarty S, 2003, THESIS RANCHI U
   Chalmers J, 1993, DIVISION TETRACORD
   Chan AS, 1998, NATURE, V396, P128, DOI 10.1038/24075
   Chan MF, 2007, HEART LUNG, V36, P431, DOI 10.1016/j.hrtlng.2007.05.003
   Choi AN, 2008, J ALTERN COMPLEM MED, V14, P567, DOI 10.1089/acm.2008.0006
   Choudhary S, 2013, THESIS RANCHI U
   Cole MG, 2002, INT J GERIATR PSYCH, V17, P444, DOI 10.1002/gps.618
   Cooke, 1959, LANGUAGE MUSIC
   Coriat IH, 1945, PSYCHOANAL REV, V32, P408
   Davies AN, 2005, J PAIN SYMPTOM MANAG, V29, P327, DOI 10.1016/j.jpainsymman.2005.02.003
   de l'Etoile SK, 2002, ART PSYCHOTHER, V29, P69, DOI 10.1016/S0197-4556(02)00139-9
   Degmecic D, 2005, INT REV AESTHET SOC, V36, P287
   Deshmukh AD, 2009, NORD J MUSIC THER, V18, P70, DOI 10.1080/08098130802697269
   Dingle GA, 2008, DRUG ALCOHOL REV, V27, P190, DOI 10.1080/09595230701829371
   Erkkilä J, 2011, BRIT J PSYCHIAT, V199, P132, DOI 10.1192/bjp.bp.110.085431
   Erkkilä J, 2008, BMC PSYCHIATRY, V8, DOI 10.1186/1471-244X-8-50
   Evers S, 2004, J NEUROL SCI, V227, P55, DOI 10.1016/j.jns.2004.08.004
   Faber M D, 1996, Psychoanal Rev, V83, P419
   Flores-Gutiérrez EO, 2009, INT J PSYCHOPHYSIOL, V71, P43, DOI 10.1016/j.ijpsycho.2008.07.007
   Fukunishi I, 1998, PSYCHOSOMATICS, V39, P175, DOI 10.1016/S0033-3182(98)71368-4
   Geretsegger M, 2012, BMC PEDIATR, V12, DOI 10.1186/1471-2431-12-2
   Gerra G, 1998, INT J PSYCHOPHYSIOL, V28, P99, DOI 10.1016/S0167-8760(97)00071-8
   Gold C, 2005, BMC PSYCHIATRY, V5, DOI 10.1186/1471-244X-5-39
   Gold C, 2007, EVID-BASED MENT HEAL, V10, P77, DOI 10.1136/ebmh.10.3.77
   Gold C, 2009, CLIN PSYCHOL REV, V29, P193, DOI 10.1016/j.cpr.2009.01.001
   Goodman KD., 1981, American Handbook of Psychiatry, V2nd, P564
   GORDON AG, 1994, NEUROLOGY, V44, P986, DOI 10.1212/WNL.44.5.986
   Hayashi N, 2002, PSYCHIAT CLIN NEUROS, V56, P187, DOI 10.1046/j.1440-1819.2002.00953.x
   Hayashi N, 1999, ACTA PSYCHIAT SCAND, V96, P35
   Hermesh H, 2004, J CLIN PSYCHIAT, V65, P191
   Hsu WC, 2004, ARCH PSYCHIAT NURS, V18, P193, DOI 10.1016/j.apnu.2004.07.007
   HUSTIG HH, 1990, BEHAV PSYCHOTHER, V18, P273, DOI 10.1017/S0141347300010375
   Jin Z, 1994, BR J PSYCHIAT S, V24, P52
   Jones NA, 1999, ADOLESCENCE, V34, P529
   Kauffman W, 1968, RAGAS N INDIA
   Kemper KJ, 2005, SOUTH MED J, V98, P282, DOI 10.1097/01.SMJ.0000154773.11986.39
   KESHAVAN MS, 1992, NEUROPSY NEUROPSY BE, V5, P211
   Koelsch S, 2006, HUM BRAIN MAPP, V27, P239, DOI 10.1002/hbm.20180
   Koelsch S, 2005, TRENDS COGN SCI, V9, P578, DOI 10.1016/j.tics.2005.10.001
   Koordeman R, 2012, ALCOHOL ALCOHOLISM, V47, P612, DOI 10.1093/alcalc/ags073
   Kornreich C, 2013, ADDICTION, V108, P80, DOI 10.1111/j.1360-0443.2012.03995.x
   LANGER SK, 1967, MIND
   Lanovaz MJ, 2011, J APPL BEHAV ANAL, V44, P647, DOI 10.1901/jaba.2011.44-647
   LEHTONEN K, 1994, NORD J MUSIC THER, V3, P3
   Leung C. M., 1998, SMJ, V39, P166
   Levitin Daniel., 2008, The World in Six Songs: How the Musical Brain Created Human Nature
   Levitin DJ, 2009, ANN NY ACAD SCI, V1156, P211, DOI 10.1111/j.1749-6632.2009.04417.x
   Levitin DJ, 2003, NEUROIMAGE, V20, P2142, DOI 10.1016/j.neuroimage.2003.08.016
   Lim CJ, 2006, ANAT REC PART A, V288A, P435, DOI 10.1002/ar.a.20316
   Lin LC, 2011, EPILEPSY BEHAV, V21, P420, DOI 10.1016/j.yebeh.2011.05.015
   Lin ST, 2011, HARVARD REV PSYCHIAT, V19, P34, DOI 10.3109/10673229.2011.549769
   Maratos AS, 2008, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD004517.pub2
   Maratos A, 2011, BRIT J PSYCHIAT, V199, P92, DOI 10.1192/bjp.bp.110.087494
   MARGO A, 1981, BRIT J PSYCHIAT, V139, P122, DOI 10.1192/bjp.139.2.122
   Menon V, 2005, NEUROIMAGE, V28, P175, DOI 10.1016/j.neuroimage.2005.05.053
   MORTON LL, 1990, J MUSIC THER, V27, P195, DOI 10.1093/jmt/27.4.195
   Mössler K, 2011, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD004025.pub3
   Mula M, 2009, CLIN MED, V9, P83, DOI 10.7861/clinmedicine.9-1-83
   Nizamie S Haque, 2008, Indian J Psychiatry, V50, P144, DOI 10.4103/0019-5545.42405
   PAVLICEVIC M, 1994, J MUSIC THER, V31, P86, DOI 10.1093/jmt/31.2.86
   Pelham WE, 2011, J ABNORM CHILD PSYCH, V39, P1085, DOI 10.1007/s10802-011-9529-z
   Peng SM, 2010, ARCH PSYCHIAT NURS, V24, P429, DOI 10.1016/j.apnu.2010.04.001
   Peretz I., 2001, Music and emotion: Theory and research, P105
   Pfeiffer H, 1987, Rehabilitation (Stuttg), V26, P184
   PIERCE CM, 1964, DIS NERV SYST, V25, P29
   Praharaj SK, 2009, PSYCHIAT CLIN NEUROS, V63, P230, DOI 10.1111/j.1440-1819.2009.01926.x
   Prommer E, 2005, J PAIN SYMPTOM MANAG, V30, P305, DOI 10.1016/j.jpainsymman.2005.08.003
   RAUSCHER FH, 1995, NEUROSCI LETT, V185, P44, DOI 10.1016/0304-3940(94)11221-4
   Register D, 2007, J MUSIC THER, V44, P23, DOI 10.1093/jmt/44.1.23
   REKER T, 1991, PSYCHIAT PRAX, V18, P216
   Rickard Nikki S, 2005, Behav Cogn Neurosci Rev, V4, P235, DOI 10.1177/1534582305285869
   Rickson DJ, 2006, J MUSIC THER, V43, P39, DOI 10.1093/jmt/43.1.39
   Rideout BE, 1996, PERCEPT MOTOR SKILL, V82, P427, DOI 10.2466/pms.1996.82.2.427
   Rose JP, 2009, MUSIC AS THERAPY, V70, P5
   Rumball K, 2010, VOICES WORLD FORUM M, P10
   Sairam T.V., 2006, MUSIC THERAPY TODAY, V7, P876
   Sairam TV, 2006, MUSIC THERAPY SACRED, P74
   Sarnthein J, 1997, NEUROL RES, V19, P107
   Schellenberg EG, 2001, ANN NY ACAD SCI, V930, P355, DOI 10.1111/j.1749-6632.2001.tb05744.x
   SERAFINE Mary Louise, 1988, Music as cognition: The development of thought in sound
   Silverman MJ, 2003, J MUSIC THER, V40, P27, DOI 10.1093/jmt/40.1.27
   Simpson K, 2011, J AUTISM DEV DISORD, V41, P1507, DOI 10.1007/s10803-010-1172-y
   Singh A, 2003, THESIS RANCHI U
   Sitaram S, 2012, THESIS RANCHI U
   Solli HP, 2008, NORD J MUSIC THER, V17, P67, DOI 10.1080/08098130809478197
   Sousa, 2010, J PAKISTAN PSYCHIAT, V7, P13
   Stewart L, 2006, BRAIN, V129, P2533, DOI 10.1093/brain/awl171
   Storr A., 1992, MUSIC AND MIND
   Sundar S., 2006, VOICES WORLD FORUM M, P6
   Sundar S., 2007, MUSIC THERAPY TODAY, V8
   Sundar S, 2006, MUSIC THER TODAY, V7, P106
   Sundar S., 2006, MUSIC THERAPY SACRED, P91
   Sundar S., 2005, MUSIC THER TODAY, V6, P113
   TANG WH, 1994, BRIT J PSYCHIAT, V165, P38, DOI 10.1192/S0007125000292969
   TERAO T, 1995, BIOL PSYCHIAT, V38, P192, DOI 10.1016/0006-3223(95)00058-O
   Teunisse RJ, 2005, J CLIN PSYCHIAT, V66, P136
   Thaut M. H., 2009, Karger Gazette: Music and Medicine, V70, P2
   Trainor Laurel J., 2003, COGNITIVE NEUROSCIEN, P310
   Ulrich G, 2007, ACTA PSYCHIAT SCAND, V116, P362, DOI 10.1111/j.1600-0447.2007.01073.x
   Whipple J, 2004, J MUSIC THER, V41, P90, DOI 10.1093/jmt/41.2.90
   Winnicott DW., 1985, ART AND PSYCHE, P22
   Yasuhara A, 2001, BRAIN DEV-JPN, V23, pS82, DOI 10.1016/S0387-7604(01)00336-9
   You Zhi-yong, 2002, Zhongguo Yi Xue Ke Xue Yuan Xue Bao, V24, P564
   Zungu-Dirwayi N, 1999, J NEUROPSYCH CLIN N, V11, P398, DOI 10.1176/jnp.11.3.398
NR 122
TC 16
Z9 21
U1 5
U2 51
PU WOLTERS KLUWER MEDKNOW PUBLICATIONS
PI MUMBAI
PA WOLTERS KLUWER INDIA PVT LTD , A-202, 2ND FLR, QUBE, C T S  NO 1498A-2
   VILLAGE MAROL, ANDHERI EAST, MUMBAI, 400059, INDIA
SN 0019-5545
EI 1998-3794
J9 INDIAN J PSYCHIAT
JI Indian J. Psychiatry
PD APR-JUN
PY 2014
VL 56
IS 2
BP 128
EP 140
DI 10.4103/0019-5545.130482
PG 13
WC Psychiatry
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Psychiatry
GA V44AV
UT WOS:000209722800007
PM 24891698
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Joseph, D
   Belford, N
   Lahiri-Roy, R
AF Joseph, Dawn
   Belford, Nish
   Lahiri-Roy, Reshmi
TI Transnational daughters in Australia: Caring remotely for ageing parents
   during COVID 19
SO EMOTION SPACE AND SOCIETY
LA English
DT Article
DE Collaborative autoethnography; Emotional reflexivity; Migration; Remote
   caring; Aging parents; Transnational daughters
ID OLDER-PEOPLE; ELDER CARE; EMOTIONS; FAMILIES; IDENTITY; DISTANCE;
   INDIVIDUALIZATION; MIGRATION; STORIES; GENDER
AB Migration does not diminish the concern migrants have for their kin. Consequently, remote caring is becoming a growing social phenomenon amongst migrants. This paper combines and contextualises three voices of trans -national women of Indian heritage from diverse postcolonial nations. In 2020, long-distance care for aging parents during the global pandemic was extremely challenging. As 'daughters away from home' residing in Melbourne (Australia), we share our story of managing care, emotional stresses, and honouring family values during the pandemic. Our triadic collage of autoethnographical recounts focuses on worry, grief, and loss, interwoven with an emotionally reflexive lens. Drawing on our discipline areas of music, visual art, and literature we hope our microhistories like innumerable other voices globally are heard, and not subsumed in the mega narrative of the pandemic's impact. Our paper contributes to an under-researched area of remote caring for aging parents during this time.
C1 [Joseph, Dawn; Lahiri-Roy, Reshmi] Deakin Univ, Geelong, Vic, Australia.
   [Belford, Nish] Monash Univ, Clayton, Vic, Australia.
C3 Deakin University; Monash University
RP Joseph, D (corresponding author), Fac Arts & Educ, Melbourne, Vic, Australia.
EM djoseph@deakin.edu.au
RI Joseph, Dawn/JUF-6795-2023
OI Joseph, Dawn/0000-0002-6320-900X
CR Abu-Raiya H, 2015, PSYCHOL RELIG SPIRIT, V7, P24, DOI 10.1037/a0037652
   Ahlin T, 2018, MED ANTHROPOL Q, V32, P85, DOI 10.1111/maq.12404
   Anderson H, 2012, FAM PROCESS, V51, P8, DOI 10.1111/j.1545-5300.2012.01385.x
   Andruske CL, 2020, J AGING STUD, V55, DOI 10.1016/j.jaging.2020.100892
   [Anonymous], J FAMILY EC ISSUES
   [Anonymous], 2014, INTERPRETIVE AUTOETH
   [Anonymous], 1983, CHRISTIAN INDIANS NA
   Australian Government, 2020, AUSTR IMM HIST
   Baldassar L, 2007, FAMILIES CARING ACROSS BORDERS: MIGRATION, AGEING AND TRANSNATIONAL CAREGIVING, P1, DOI 10.1057/9780230626263
   Baldassar L., 2008, The Family in question: Immigrant and Ethnic Minorities in Multicultural Europe, P269, DOI [10.1515/9789048501533-014, DOI 10.1515/9789048501533-014]
   Baldassar L., 2007, Family caregiving for older disabled people: Relational and institutional issues, P201
   Baldassar L, 2016, GLOBAL NETW, V16, P133, DOI 10.1111/glob.12108
   Baldassar L, 2015, EMOT SPACE SOC, V16, P81, DOI 10.1016/j.emospa.2014.09.003
   Baldassar L, 2011, J MEDITERR STUD, V20, P255
   Barnes D, 1957, LETT EDWIN MUIR
   Barnett AE, 2020, J FAM ECON ISS, V41, P691, DOI 10.1007/s10834-020-09680-1
   Belford N, 2012, MEMORY LANE 5 MAHA S
   Belford N., ASIAN WOMEN IDENTITY, Vfirst
   Belford N, 2019, EMOT SPACE SOC, V31, P63, DOI 10.1016/j.emospa.2018.11.004
   Belford N, 2018, WOMEN STUD INT FORUM, V70, P24, DOI 10.1016/j.wsif.2018.07.012
   Berg-Weger M, 2001, FAM SOC-J CONTEMP H, V82, P263, DOI 10.1606/1044-3894.191
   Berger L., 2001, QUALITATIVE INQUIRY, V7, P504, DOI DOI 10.1177/107780040100700407
   Bevan JL, 2011, PATIENT EDUC COUNS, V85, P26, DOI 10.1016/j.pec.2010.08.003
   Bilecen B, 2019, COMP MIGR STUD, V7, DOI 10.1186/s40878-019-0161-3
   Boccagni P, 2015, EMOT SPACE SOC, V16, P73, DOI 10.1016/j.emospa.2015.06.009
   Bochner Arthur P., 2001, Qualitative Inquiry, V7, P131, DOI [10.1177/107780040100700201, DOI 10.1177/107780040100700201]
   Bonifacio GlendaTibe., 2010, GENDER RELIG MIGRATI
   Bourdieu Pierre, 2005, Children of Global Migration: Transnational Families and Gendered Woes, DOI DOI 10.1515/9781503624627
   Brannen J, 2005, SOCIOL REV, V53, P412, DOI 10.1111/j.1467-954X.2005.00559.x
   Cadet T, 2021, J FAM ECON ISS, V42, P561, DOI 10.1007/s10834-020-09719-3
   Celestina E.C, 2019, AWKA J RES MUSIC ART, V10, P65
   Chacko E, 2015, J CULT GEOGR, V32, P115, DOI 10.1080/08873631.2015.1004853
   Chang H., 2012, Collaborative autoethnography
   Chawla D., 2019, MIGRATIONS DEPART CR, V1, P1, DOI [10.1525/dcqr.2019.8.1.1, DOI 10.1525/DCQR.2019.8.1.1]
   Clough P, 2008, AFFECTIVE TURN THEOR
   Creech A, 2013, RES STUD MUSIC EDUC, V35, P87, DOI 10.1177/1321103X13478862
   Ellis C., 1992, Investigating subjectivity: Research on lived experience pp
   Ellis C, 2007, QUAL INQ, V13, P3, DOI 10.1177/1077800406294947
   Funk LM, 2009, CAN REV SOCIOL, V46, P235, DOI 10.1111/j.1755-618X.2009.01213.x
   Gardner K., 2002, GLOBAL NETW, V2, P179, DOI [DOI 10.1111/1471-0374.00035, 10.1111/1471-0374.00035]
   Gilmartin M, 2015, J CULT GEOGR, V32, P83, DOI 10.1080/08873631.2014.1000576
   Giuliani C., 2017, Social Sciences, V6, P142, DOI [DOI 10.3390/SOCSCI6040142, 10.3390/socsci6040142]
   Goodman, 2020, FAITH TIME CRISIS, DOI [10.1037/e503942020-001, DOI 10.1037/E503942020-001]
   Gui T, 2016, J CROSS-CULT GERONTO, V31, P255, DOI 10.1007/s10823-016-9295-z
   Hays T, 2005, AGEING SOC, V25, P261, DOI 10.1017/S0144686X04002946
   Heimtun B, 2019, ANN TOURISM RES, V76, P129, DOI 10.1016/j.annals.2019.03.014
   Hequembourg A, 2005, J AGING STUD, V19, P53, DOI 10.1016/j.jaging.2003.12.001
   Hernandez K. A. C., 2017, Auto/Biography Studies, V32, P251
   Hochschild AR, 2012, MANAGED HEART: COMMERCIALIZATION OF HUMAN FEELING, P1
   Holmes M, 2004, SOCIOL REV, V52, P180, DOI 10.1111/j.1467-954X.2004.00464.x
   Holmes M, 2015, EMOT REV, V7, P61, DOI 10.1177/1754073914544478
   Holmes M, 2010, SOCIOLOGY, V44, P139, DOI 10.1177/0038038509351616
   Joseph D., 2015, MUSIEKLEIER, V35, P56
   Joseph D., 2021, TRANSNATIONAL WOMEN
   Joseph D., 2018, RE ENCHANTING ED SPI, P189
   Joseph D. Y., 2015, INT J SOCIAL POLITIC, V10, P29, DOI [https://doi.org/10.18848/2326-9960/CGP/v10i02/29-42, DOI 10.18848/2326-9960/CGP/V10I02/29-42]
   Keller S, 2006, PHILOS QUART, V56, P254, DOI 10.1111/j.1467-9213.2006.00441.x
   Lahiri-Roy R., 2021, IMMIGRANT CONUNDRUMS
   Lahiri-Roy R, 2021, J INTERCULT STUD, V42, P235, DOI 10.1080/07256868.2021.1889487
   Lamb S., 2000, White saris and Sweet mangoes aging, gender, and body in North India
   Leifsen E, 2012, J ETHN MIGR STUD, V38, P219, DOI 10.1080/1369183X.2012.646419
   Mahler SJ, 2006, INT MIGR REV, V40, P27, DOI 10.1111/j.1747-7379.2006.00002.x
   Mazzucato V, 2011, J MARRIAGE FAM, V73, P704, DOI 10.1111/j.1741-3737.2011.00840.x
   Merla L, 2015, INT MIGR, V53, P153, DOI 10.1111/imig.12024
   Morawska E, 2011, ETHNIC RACIAL STUD, V34, P1029, DOI 10.1080/01419870.2010.533783
   Naidoo L., 2005, INDIAN DIASPORA THE, P53
   Nair S, 2012, MOVING TIMES GENDER
   Nganga C. W., 2017, URBAN REV, V49, P551, DOI https://doi.org/10.1007/s11256-017-0408-y
   Ngunjiri FW, 2010, J RES PRACT, V6
   Nnning V., 2017, WRITING EMOTIONS THE
   Paoletti I, 2002, DISCOURSE SOC, V13, P805, DOI 10.1177/0957926502013006758
   Percot M., 2015, S ASIAN MIGRATION GU, P247
   Piper N, 2013, NEW PERSPECTIVES GEN, V1
   Rajan Gita, 2006, NEW COSMOPOLITANISMS
   Ramdas K, 2015, GENDER PLACE CULT, V22, P255, DOI 10.1080/0966369X.2013.879098
   Roy R, 2020, QUAL RES J, V20, P383, DOI 10.1108/QRJ-06-2020-0054
   Seligman M, 2018, J POSIT PSYCHOL, V13, P333, DOI 10.1080/17439760.2018.1437466
   Skrbis Z, 2008, J INTERCULT STUD, V29, P231, DOI 10.1080/07256860802169188
   Stokowski PA, 2002, J LEISURE RES, V34, P368, DOI 10.1080/00222216.2002.11949977
   Sun KC, 2012, J FAM ISSUES, V33, P1240, DOI 10.1177/0192513X12445564
   Taylor Julie., 2012, DJUNA BARNES AFFECTI
   Wall SS, 2016, INT J QUAL METH, V15, DOI 10.1177/1609406916674966
   Zattler J., 2020, NEVER LET CRISIS GO
NR 83
TC 3
Z9 3
U1 1
U2 3
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1755-4586
EI 1878-0040
J9 EMOT SPACE SOC
JI Emot. Space Soc.
PD FEB
PY 2022
VL 42
AR 100864
DI 10.1016/j.emospa.2021.100864
PG 8
WC Geography; Social Sciences, Interdisciplinary
WE Social Science Citation Index (SSCI)
SC Geography; Social Sciences - Other Topics
GA 1D4CY
UT WOS:000793751200005
DA 2024-01-09
ER

PT J
AU Dromey, C
   Holmes, SO
   Hopkin, JA
   Tanner, K
AF Dromey, Christopher
   Holmes, Sharee O.
   Hopkin, J. Arden
   Tanner, Kristine
TI The Effects of Emotional Expression on Vibrato
SO JOURNAL OF VOICE
LA English
DT Article
DE Vibrato; Singing; Emotion; Vibrato extent; Vibrato rate; Modulation
ID VOICE; FREQUENCY; EXTENT; MUSIC; MODULATION; SPEECH
AB Objectives/Hypothesis. The purpose of this study was to investigate the effect of emotional expression on several acoustic measures of vibrato, including its rate, extent, and steadiness. We hypothesized that singing a passage with emotional content would influence these variables.
   Study Design. This study used a within-subjects, repeated-measures design. Singer performance under different conditions was analyzed.
   Methods. Ten graduate student singers (eight women, two men) completed a series of tasks including sustained sung vowels at several pitch and loudness levels, an assigned song that was judged to have relatively neutral emotion, and a personal selection that included passages of intense emotion. Vowel tokens were extracted from the recordings and averaged for each task. Dependent measures included the mean fundamental frequency (F-0), mean intensity, frequency modulation (FM) rate, FM extent, and measures of FM rate and extent variability.
   Results. The FM rate and extent were higher and the modulation variability was lower for the more emotional song than for the sustained vowels. Mean F-0 and intensity were higher for the emotional song than for the neutral song.
   Conclusions. Singing an emotional passage influences acoustic features of vibrato when compared with isolated, sustained vowels. The wider dynamic and pitch ranges for emotional passages only partly explain vibrato differences between emotional and neutral singing.
C1 [Dromey, Christopher; Holmes, Sharee O.; Tanner, Kristine] Brigham Young Univ, Dept Commun Disorders, Provo, UT 84602 USA.
   [Hopkin, J. Arden] Brigham Young Univ, Sch Mus, Provo, UT 84602 USA.
C3 Brigham Young University; Brigham Young University
RP Dromey, C (corresponding author), Brigham Young Univ, Dept Commun Disorders, 133 John Taylor Bldg, Provo, UT 84602 USA.
EM dromey@byu.edu
RI Tanner, Kristine M/AFR-4781-2022
OI Tanner, Kristine M/0000-0001-6973-8490
FU David O. McKay School of Education at Brigham Young University
FX We express our appreciation to the singers and accompanists who
   participated in this study. We are also grateful for the financial
   support provided by the David O. McKay School of Education at Brigham
   Young University. This manuscript is based on the master's thesis
   research of the second author.
CR Baltes FR, 2011, BRAIN COGNITION, V76, P146, DOI 10.1016/j.bandc.2011.01.012
   Cookman S, 1999, J VOICE, V13, P11, DOI 10.1016/S0892-1997(99)80057-5
   Corso JF, 1950, J APPL PSYCHOL, V34, P206, DOI 10.1037/h0058006
   Diaz JA, 2003, J VOICE, V17, P179, DOI 10.1016/S0892-1997(03)00002-X
   Dromey C, 2003, J SPEECH LANG HEAR R, V46, P1234, DOI 10.1044/1092-4388(2003/096)
   Dromey C, 2003, J VOICE, V17, P168, DOI 10.1016/S0892-1997(03)00039-0
   Dromey C, 2010, SPEECH MOTOR CONTROL, P283, DOI DOI 10.1093/ACPROF:OSO/9780199235797.001
   Dromey C, 2008, J SPEECH LANG HEAR R, V51, P196, DOI 10.1044/1092-4388(2008/015)
   Dromey C, 2009, J VOICE, V23, P156, DOI 10.1016/j.jvoice.2007.05.002
   Ekholm E, 1998, J VOICE, V12, P182, DOI 10.1016/S0892-1997(98)80038-6
   Ferrante I, 2011, J ACOUST SOC AM, V130, P1683, DOI 10.1121/1.3621017
   Foulds-Elliott S D, 2000, Logoped Phoniatr Vocol, V25, P151, DOI 10.1080/140154300750067539
   Guzman MA, 2012, J VOICE, V26, DOI 10.1016/j.jvoice.2012.02.006
   Helou LB, 2013, LARYNGOSCOPE, V123, P2756, DOI 10.1002/lary.24109
   HORII Y, 1989, Journal of Voice, V3, P36, DOI 10.1016/S0892-1997(89)80120-1
   HORII Y, 1989, J SPEECH HEAR RES, V32, P829, DOI 10.1044/jshr.3204.829
   HORII Y, 1988, FOLIA PHONIATR, V40, P303, DOI 10.1159/000265924
   Howes P, 2004, J VOICE, V18, P216, DOI 10.1016/j.jvoice.2003.09.003
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Kreibig SD, 2010, BIOL PSYCHOL, V84, P394, DOI 10.1016/j.biopsycho.2010.03.010
   Lang PJ, 2010, BIOL PSYCHOL, V84, P437, DOI 10.1016/j.biopsycho.2009.10.007
   Larrouy-Maestri P, 2014, J VOICE, V28, P52, DOI 10.1016/j.jvoice.2013.07.008
   Mendes AP, 2003, J VOICE, V17, P529, DOI 10.1067/S0892-1997(03)00083-3
   Merritt L, 2001, J VOICE, V15, P257, DOI 10.1016/S0892-1997(01)00026-1
   Mitchell HF, 2010, J VOICE, V24, P427, DOI 10.1016/j.jvoice.2008.12.003
   Molnar-Szakacs I, 2006, SOC COGN AFFECT NEUR, V1, P235, DOI 10.1093/scan/nsl029
   O'Keefe DJ, 2003, HUM COMMUN RES, V29, P464, DOI 10.1111/j.1468-2958.2003.tb00849.x
   PRAME E, 1994, J ACOUST SOC AM, V96, P1979, DOI 10.1121/1.410141
   Prame E, 1997, J ACOUST SOC AM, V102, P616, DOI 10.1121/1.419735
   ROBISON CW, 1994, NATS J, V51, P19
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Seashore CE, 1931, P NATL ACAD SCI USA, V17, P623, DOI 10.1073/pnas.17.12.623
   Solomon NP, 2007, J VOICE, V21, P541, DOI 10.1016/j.jvoice.2006.04.002
   Sundberg J, 1994, VOCAL FOLD PHYSL VOI, V35, P81
   Sundberg J., 1994, STL QPSR, V35, P45
   Sundberg J., 1998, LOGOP PHONIATR VOCO, V23, P169
   Titze IR, 2002, J ACOUST SOC AM, V111, P2272, DOI 10.1121/1.1434945
NR 37
TC 11
Z9 16
U1 0
U2 7
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0892-1997
EI 1873-4588
J9 J VOICE
JI J. Voice
PD MAR
PY 2015
VL 29
IS 2
BP 170
EP 181
DI 10.1016/j.jvoice.2014.06.007
PG 12
WC Audiology & Speech-Language Pathology; Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Audiology & Speech-Language Pathology; Otorhinolaryngology
GA CD4RK
UT WOS:000351071000006
PM 25499525
DA 2024-01-09
ER

PT J
AU Cramer, A
AF Cramer, A.
TI I can hear you, but I don't understand you. Why is it so important to
   perceive high frequencies?
SO HNO
LA German
DT Article
DE High frequency hearing loss; Reticular formation; Communication; Motor
   neurons, gamma; Personality
ID COMPLEX TONES; MUSIC; BRAIN; PITCH; LANGUAGE; VOICE
AB The word personality is derived from the Latin word "persona" (mask, person); "per sona" means "by the sound or through the sound". In order to look through speech, to hear "behind the mask of a person", we have to be able to hear properly. Especially the frequencies between 2 kHz and 5 kHz and the overtones (the higher we can perceive them, the better) play a central role for decoding vowels, consonants and effects of emotions in voice and speech; beyond that they provide the perfect enjoyment of music and sound. Obviously they are also a vital physical necessity. High frequencies stimulate, they provoke attentiveness and concentration. The activity level of the reticular formation is affected by the influent of the sensory organs with a crucial role by the hearing sense. Hearing in high frequencies leads to higher metabolism, to better motility, to an activation of the gamma nervous system and to a better transfer of information.
RP Cramer, A (corresponding author), Hubertusstr 22, D-80639 Munich, Germany.
EM annettecramer@t-online.de
CR Annunciato NF, 2000, NEUROPHYSIOLOGISCHE
   Birbaumer N, 2010, Biologische Psychologie, V7th
   Bregman A.S., 1990, AUDITORY SCENE ANAL, DOI DOI 10.7551/MITPRESS/1486.001.0001
   Cramer A, 2005, MUSIC THERAPY TODAY, VVI, P826
   Cramer A, 1998, BUCH STIMME
   David E, 1990, S PHAN HOR FEST HOR
   Eckert H., 1994, MENSCHEN IHRE STIMME
   Friederici AD, 2003, GEIST HIRN, V2, P43
   Grube AW, 1884, BIOGRAPHISCHE MINIAT, P243
   Herzog H, 1933, Z PSYCHOL PHYSIOL SI, V130, P300
   Kapteina H, 2001, BEITRAGE MEDIEN ASTH, P16
   Koelsch S, 2003, J COGNITIVE NEUROSCI, V15, P683, DOI 10.1162/089892903322307401
   Koelsch S, 2007, MUSIKALISCHER SINN B, P251
   Leont'ev AA, 1975, PSYCHOLINGUISTISCHE, P181
   LEVITT P, 1979, J COMP NEUROL, V186, P505, DOI 10.1002/cne.901860402
   Lusseyran J, 1983, WIEDERGEFUNDENE LICH, P75
   Mathelitsch H, 1995, STIMME, P36
   Moore BCJ, 2001, INTRO PSYCHOL HEARIN, P218
   Moses PJ, 1956, STIMME NEUROSE, P127
   Muller-Limroth W, 1977, RHYTHMUS GESUNDHEIT, P31
   Patel AD, 2003, NAT NEUROSCI, V6, P674, DOI 10.1038/nn1082
   Petsche H, 1989, MUSIK GEHIRN SPIEL, P111
   PREISLER A, 1993, PERCEPT PSYCHOPHYS, V54, P589, DOI 10.3758/BF03211783
   Rohmert G, 1994, DOKUMENTATION ARBEIT, V28
   ROLAND PE, 1982, J NEUROPHYSIOL, V48, P1059, DOI 10.1152/jn.1982.48.5.1059
   Rossing T. D, 2002, ECHOES, V12
   Scherer TM, 2000, THESIS FRANKFURT MAI, P129
   Schön D, 2004, PSYCHOPHYSIOLOGY, V41, P341, DOI 10.1111/1469-8986.00172.x
   Siebenhaar B, 2009, PHONETIK PHONOLOGIE, P7
   SINGH PG, 1992, J ACOUST SOC AM, V92, P2650, DOI 10.1121/1.404381
   Sokolov EN, 1963, PERCEPTION CONDITION, P154
   SUNDBERG J, 1977, SCI AM, V236, P82, DOI 10.1038/scientificamerican0377-82
   Tesarek L, 1997, KLEINE KULTURGESCHIC, P23
   van Uden A, 1955, NEURE BLATTER TAUBST, V9, P5
   Wohl A, 1977, BEWEGUNG SPRACHE, P59
NR 35
TC 1
Z9 1
U1 0
U2 14
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0017-6192
J9 HNO
JI HNO
PD JUN
PY 2012
VL 60
IS 6
BP 532
EP 539
DI 10.1007/s00106-011-2399-4
PG 8
WC Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Otorhinolaryngology
GA 953NV
UT WOS:000304876600012
PM 22358777
DA 2024-01-09
ER

PT J
AU Lin, CY
   Cheng, LC
   Tseng, CK
   Gu, HY
   Chung, KL
   Fahn, CS
   Lu, KJ
   Chang, CC
AF Lin, Chyi-Yeu
   Cheng, Li-Chieh
   Tseng, Chang-Kuo
   Gu, Hung-Yan
   Chung, Kuo-Liang
   Fahn, Chin-Shyurng
   Lu, Kai-Jay
   Chang, Chih-Cheng
TI A face robot for autonomous simplified musical notation reading and
   singing
SO ROBOTICS AND AUTONOMOUS SYSTEMS
LA English
DT Article
DE Face robot; Facial expression; Musical note interpretation; Voice
   synthesis
AB This research is aimed to devise an anthropomorphic robotic head with a human-like face and a sheet of artificial skin that can read a randomly composed simplified musical notation and sing the corresponding content of the song once. The face robot is composed of an artificial facial skin that can express a number of facial expressions via motions driven by internal servo motors. Two cameras, each of them installed inside each eyeball of the face, provide vision capability for reading simplified musical notations. Computer vision techniques are subsequently used to interpret simplified musical notations and lyrics of their corresponding songs. Voice synthesis techniques are implemented to enable the face robot to sing songs by enunciating synthesized sounds. Mouth patterns of the face robot will be automatically changed to match the emotions corresponding to the lyrics of the songs. The experiments show that the face robot can successfully read and then accurately sing a song which is assigned discriminately. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Lin, Chyi-Yeu; Cheng, Li-Chieh; Tseng, Chang-Kuo] Natl Taiwan Univ Sci & Technol, Dept Mech Engn, Taipei 10607, Taiwan.
   [Gu, Hung-Yan; Chung, Kuo-Liang; Fahn, Chin-Shyurng; Lu, Kai-Jay] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 10607, Taiwan.
   [Chang, Chih-Cheng] Natl Taiwan Univ Sci & Technol, Inst Automat & Control, Taipei 10607, Taiwan.
C3 National Taiwan University of Science & Technology; National Taiwan
   University of Science & Technology; National Taiwan University of
   Science & Technology
RP Lin, CY (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Mech Engn, Taipei 10607, Taiwan.
EM jerrylin@mail.ntust.edu.tw
RI Chung, Kuo-Liang/H-6207-2011
FU National Science Council of the Republic of China (Taiwan) [NSC
   94-2212-E-011-032, NSC 94-2218-E-011-012, NSC 95-2218-E-011-009]
FX This research was financially funded by the National Science Council of
   the Republic of China (Taiwan) under grant numbers NSC
   94-2212-E-011-032, NSC 94-2218-E-011-012, and NSC 95-2218-E-011-009.
   Their support made this research and the outcome possible.
CR [Anonymous], 1997, Computer Music: Synthesis, Composition, and Performance
   Breazeal C., 1999, Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289), P858, DOI 10.1109/IROS.1999.812787
   Breazeal C, 2000, ADAPT BEHAV, V8, P49, DOI 10.1177/105971230000800104
   Faires J, 1998, Numerical methods, VSecond
   Gonzales R. C., 2002, Digital Image Processing
   Hara F, 1996, IROS 96 - PROCEEDINGS OF THE 1996 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - ROBOTIC INTELLIGENCE INTERACTING WITH DYNAMIC WORLDS, VOLS 1-3, P1600, DOI 10.1109/IROS.1996.569026
   Hashimoto M, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P1855, DOI 10.1109/IROS.2006.282307
   HASHIMOTO T, 2004, P SICE ANN C, P1563
   Hashimoto T, 2006, IEEE ICMA 2006: PROCEEDING OF THE 2006 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS 1-3, PROCEEDINGS, P25, DOI 10.1109/ICMA.2006.257429
   Hirth J, 2007, IEEE INT CONF ROBOT, P2150, DOI 10.1109/ROBOT.2007.363639
   Kato I., 1987, Robotics, V3, P143, DOI 10.1016/0167-8493(87)90002-7
   LI ZC, 1989, COMPUTER TRANSFORMAT
   MIWA H, 2004, P 2004 IEEE RSJ INT, P2203
   Moore F. R., 1990, Elements of Computer Music
   Nakano T., 2009, P SOUND MUS COMP C, P343
   OSTU N, 1979, IEEE T SYST MAN CYB, V1, P62
   Otsuka T, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P2289, DOI 10.1109/IROS.2009.5354637
   Stylianou Y, 2005, LECT NOTES ARTIF INT, V3445, P244
   Stylianou Y., 1996, THESIS ECOLE NATL SU
   Takanishi A, 1995, RO-MAN'95 TOKYO: 4TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN COMMUNICATION, PROCEEDINGS, P77, DOI 10.1109/ROMAN.1995.531938
   Tiddeman B, 2002, COMP ANIM CONF PROC, P248, DOI 10.1109/CA.2002.1017545
   Waters Keith, 1987, ACM SIGGRAPH Computer Graphics, V21, P17, DOI [10.1145/37402.37405, DOI 10.1145/37402.37405]
NR 22
TC 11
Z9 11
U1 3
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0921-8890
EI 1872-793X
J9 ROBOT AUTON SYST
JI Robot. Auton. Syst.
PD NOV
PY 2011
VL 59
IS 11
BP 943
EP 953
DI 10.1016/j.robot.2011.07.001
PG 11
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Robotics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science; Robotics
GA 833VD
UT WOS:000295912100008
DA 2024-01-09
ER

PT J
AU Soto-Sanfiel, MT
   Freeman, BC
   Angulo-Brunet, A
AF Soto-Sanfiel, Maria T.
   Freeman, Bradley C.
   Angulo-Brunet, Ariadna
TI Understanding radio art reception
SO PROFESIONAL DE LA INFORMACION
LA English
DT Article
DE Radio art; Sound art; Artistic sound; Art reception; Involvement;
   Emotions; Radiophonic language; Radio aesthetics; Creative radio;
   Creative sound; Emotions; Path analysis; Media psychology
ID PERCEPTUAL FLUENCY; PROCESSING FLUENCY; FIT INDEXES; INVOLVEMENT;
   ATTENTION; AROUSAL; COMPLEXITY; VALENCE; PERSUASION; JUDGMENTS
AB Radio art is understood as radio made by artists. The term is typically applied to sound-based artifacts produced and broadcast by means of the creative use of radio media affordances, infrastructure, and technologies. Radio art is known as any sound work conceived to expand the creative and aesthetic possibilities of the medium through the use of the elements of radiophonic language (voice, words, music, sound effects, and silence) with the intention to produce aesthetic messages and to move radio listeners. This study introduces radio art reception as a subject of scientific scrutiny. It proposes a model of radio art processing that includes involvement, art reception, and positive emotions as predictors of the willingness to listen to such works. After listening to each of two pieces of radio art, 126 Singaporean undergraduate communication students (M-Age = 22.7, SD = 1.7) completed a questionnaire measuring involvement, art reception, perceived emotions, and willingness to listen to another radio art feature. The main results confirm our model of radio art reception: involvement predicts the audience's cognitive stimulation generated by radio art, their artistic evaluation, and the positive attraction experienced by audiences towards them. The positive emotions experienced during consumption have a direct effect on the attraction towards radio art. Moreover, the specific radio art content affects the audiences' responses. These results allow us to understand psychological responses to sound art. The hope is to attract the attention of communication and art researchers and invite them to deepen the existing knowledge about artistic sound through empirical studies, since debates about radio art and sound works are almost lacking from scientific literature.
C1 [Soto-Sanfiel, Maria T.] Natl Univ Singapore, Dept Commun & New Media, Ctr Trusted Internet & Community, Singapore, Singapore.
   [Freeman, Bradley C.] Sunway Univ, Dept Commun, Subang Jaya, Malaysia.
   [Angulo-Brunet, Ariadna] Univ Oberta Catalunya, Estudis Psicol & Ciencies Educ, Barcelona, Spain.
C3 National University of Singapore; Sunway University; UOC Universitat
   Oberta de Catalunya
RP Soto-Sanfiel, MT (corresponding author), Natl Univ Singapore, Dept Commun & New Media, Ctr Trusted Internet & Community, Singapore, Singapore.
EM cnmmtss@nus.edu.sg; bfreeman@sunway.edu.my; aangulob@uoc.edu
RI Angulo-Brunet, Ariadna/K-5152-2017; Soto-Sanfiel, María T./L-9833-2014
OI Angulo-Brunet, Ariadna/0000-0002-0583-1618; Soto-Sanfiel, María
   T./0000-0002-1364-8821; Freeman, Bradley/0000-0002-5088-4989
FU Asian Communication Resource Centre (ACRC) at Nanyang Technological
   University
FX This research has been supported by the Asian Communication Resource
   Centre (ACRC) at Nanyang Technological University.
CR Al-Karaki Ghazi N., ENVIRON HEALTH PERSP, V25, P873, DOI [10.1081/PLN-120002966, DOI 10.1289/EHP3424]
   [Anonymous], 2020, 60 2 RADIO
   [Anonymous], 2013, DEV PSYCHOL, DOI DOI 10.1037/A0029397
   Augustin MD, 2012, I-PERCEPTION, V3, P455, DOI [10.1068/i0541ed, 10.1068/i0541aap]
   Ball LJ, 2018, METAPHOR SYMBOL, V33, P235, DOI 10.1080/10926488.2018.1481255
   Bar M, 2006, PSYCHOL SCI, V17, P645, DOI 10.1111/j.1467-9280.2006.01759.x
   Barber John F., 2017, APPAREIL, V18, DOI [10.4000/appareil.2388, DOI 10.4000/APPAREIL.2388]
   Barber John F., 2017, HYPERRHIZ, P41, DOI [10.20415/hyp/017.e04, DOI 10.20415/HYP/017.E04]
   Bertamini M, 2013, I-PERCEPTION, V4, P317, DOI 10.1068/i0601JW
   Black C, 2010, ORGAN SOUND, V15, P198, DOI 10.1017/S1355771810000257
   Bolls PD, 2001, COMMUN RES, V28, P627, DOI 10.1177/009365001028005003
   Bolls PD, 2003, J MARK COMMUN, V9, P17
   BORNSTEIN RF, 1994, SOC COGNITION, V12, P103, DOI 10.1521/soco.1994.12.2.103
   BORNSTEIN RF, 1989, PSYCHOL BULL, V106, P265, DOI 10.1037/0033-2909.106.2.265
   Braverman J, 2005, PERS SOC PSYCHOL B, V31, P1487, DOI 10.1177/0146167205276152
   Breitsameter Sabine, 1998, RESONANCE FM RSL
   Camacho Lidia, 2007, RADIO ARTE GENERO SI
   Carpentier FRD, 2010, J RADIO AUDIO MEDIA, V17, P63, DOI 10.1080/19376521003719375
   CELSI RL, 1988, J CONSUM RES, V15, P210, DOI 10.1086/209158
   Chandra Sourov, 2014, ANALYST, V6, P3647, DOI [10.1039/C3NR06079A, DOI 10.1039/AN9830801067, 10.1126/science.aay9097]
   Das Ananya, 2011, FAM CONSUM SCI RES J, V101, P1342, DOI [10.1111/j.1572-0241.2006.00580.x, DOI 10.1111/J.1552-3934.2011.02091.X]
   De-Quevedo-Orozco Lourdes, 2001, EMANCIPACION ARTISTI
   Delacre M, 2017, INT REV SOC PSYCHOL, V30, P92, DOI 10.5334/irsp.82
   DeLys Sherre, 2006, CONVERGENCE-US, V12, P129, DOI DOI 10.1177/1354856506066112
   Donovan Kate, 2018, THESIS U POTSDAM
   Engel J.F., 1982, Consumer Behavior, V4th ed.
   Fredrickson BL, 2003, J PERS SOC PSYCHOL, V84, P365, DOI 10.1037/0022-3514.84.2.365
   Givens Clark R., The Journal of Social Psychology, V40, P471, DOI [10.1080/09500349314550471, DOI 10.1080/00224540009600467, 10.1080/03014223.1987.10422690, DOI https://doi.org/10.1080/07391102.2020.1776639]
   Glandien Kersten, 2000, MUSIC ELECT MEDIA CU, P167
   Gomez Jorge, 2008, PARLANTE 23 ARTE SON
   GOTLIEB JB, 1991, J ADVERTISING, V20, P38, DOI 10.1080/00913367.1991.10673205
   Grabe ME, 2000, COMMUN RES, V27, P3, DOI 10.1177/009365000027001001
   Green SB, 2009, PSYCHOMETRIKA, V74, P155, DOI 10.1007/s11336-008-9099-3
   Green Samuel B., 2008, PSYCHOMETRIKA, V74, P155, DOI [10.1007/s11336-008-9099-3, DOI 10.1007/S11336-008-9099-3]
   Güçlütürk Y, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21636-y
   Hager M, 2012, PSYCHOL AESTHET CREA, V6, P320, DOI 10.1037/a0028776
   Hall Margaret A., 2015, THESIS U ARTS LONDON
   Hu LT, 1999, STRUCT EQU MODELING, V6, P1, DOI 10.1080/10705519909540118
   Iges Jose, 2009, RADIOARTE REFLEXIONE
   Iges Jose, 2004, REV TELOS CUADERNOS, V60
   Kolb Richard, 1933, RUNDFUNK FILM DIENST, p238f
   Kruglanski AW, 2006, J COMMUN, V56, pS105, DOI 10.1111/j.1460-2466.2006.00285.x
   KRUGMAN HE, 1965, PUBLIC OPIN QUART, V29, P349, DOI 10.1086/267335
   Lang A, 2000, J COMMUN, V50, P46, DOI 10.1093/joc/50.1.46
   LANG A, 1995, J BROADCAST ELECTRON, V39, P313, DOI 10.1080/08838159509364309
   Lang A, 2007, J HEALTH COMMUN, V12, P581, DOI 10.1080/10810730701508708
   Li Jing, 2020, REV AQUACULT, V24, P13356, DOI [10.1111/jcmm.15959, DOI 10.1111/RAQ.12464]
   Marsh HW, 2004, STRUCT EQU MODELING, V11, P320, DOI 10.1207/s15328007sem1103_2
   Mase, 2020, MASE
   McLuhan Marshall, 1994, Understanding media: The extensions of man
   Mende Doreen, 2008, RE INVENTING RADIO A, P149
   Moffat Robert., 1842, Missionary Labours and Scenes in Southern Africa, DOI [10.1017/s0031182099005466, DOI 10.1017/S0373463300039801]
   Mullin C., 2017, ELECT IMAGING HUMAN, V2017, P248, DOI [10. 2352/ISSN. 2470-1173. 2017. 14. HVEI-152, DOI 10.2352/ISSN.2470-1173.2017.14.HVEI-152, 10.2352/ISSN.2470-1173.2017.14.HVEI-152]
   Oppenheimer DM, 2008, COGNITION, V106, P1178, DOI 10.1016/j.cognition.2007.05.010
   Oppenheimer Daniel M., COGNITION, V106, P1178, DOI [10.1016/j.cognition.2007.05.010, DOI 10.1016/J.COGNITION.2007.05.010]
   PETTY RE, 1979, J PERS SOC PSYCHOL, V37, P1915, DOI 10.1037/0022-3514.37.10.1915
   Postman N., 1993, Technopoly: The Surrender of Culture to Technology
   POTTER RF, 2000, J RADIO STUDIES, V7, P29, DOI DOI 10.1207/S15506843JRS0701_5
   Potter RF, 2006, MEDIA PSYCHOL, V8, P395, DOI 10.1207/s1532785xmep0804_4
   R Core Team, 2018, R: A Language and Environment for Statistical Computing
   Reber R, 1998, PSYCHOL SCI, V9, P45, DOI 10.1111/1467-9280.00008
   Reber R, 2004, PERS SOC PSYCHOL REV, V8, P364, DOI 10.1207/s15327957pspr0804_3
   Reber Rolf, 2016, PERS SOC PSYCHOL REV, V8, P364, DOI [10.1207/s15327957pspr0804_3, DOI 10.1207/S15327957PSPR0804_3]
   Rodero E, 2012, J RADIO AUDIO MEDIA, V19, P45, DOI 10.1080/19376529.2012.667022
   Rosseel Y, 2012, J STAT SOFTW, V48, P1, DOI 10.18637/jss.v048.i02
   Schaeffer Pierre, 1966, Traite des Objets Musicaux
   Schoning Klaus, 1997, KLANGREISE STUDIO AK, P12
   Segal Jonathan P., 2019, ENVIRON BEHAV, V12, p175628481983662, DOI [10.1177/1756284819836620, DOI 10.1177/0013916517733782]
   Soto-Sanfiel M., 2021, INT J LISTENING, P1, DOI [10.1080/10904018.2021.1987239, DOI 10.1080/10904018.2021.1987239]
   Suckfüll M, 2009, COMMUNICATIONS-GER, V34, P361, DOI 10.1515/COMM.2009.023
   Todorov A., 2002, The persuasion handbook: Developments in theory and practice, P195
   Topolinski S, 2009, COGNITION EMOTION, V23, P1465, DOI 10.1080/02699930802420745
   Torchiano M., 2020, effsize: Efficient Effect Size Computation. R package version 0.7.1, VVolume 1
   Tormala ZL, 2004, RESISTANCE AND PERSUASION, P65
   Valero Gisbert Maria Joaquina, 2021, J PLANT NUTR, V53, P170, DOI [10.1080/10572317.2021.1909256, DOI 10.1080/01904167.2021.1918156, 10.1080/01904167.2021.1918156]
   Viladrich C, 2017, AN PSICOL-SPAIN, V33, P755
   Vorderer P, 2004, COMMUN THEOR, V14, P388, DOI 10.1111/j.1468-2885.2004.tb00321.x
   Wang K., 2018, SCI REP-UK, V8, DOI [10.1038/s41598-018-29086-2, DOI 10.1038/S41598-018-19502-Y, 10.1038/S41598-018]
   WASSERTHEIL S, 1970, BIOMETRICS, V26, P588, DOI 10.2307/2529115
   Windsor L. W., 2000, Music, electronic media and culture, P7
   Winkle Roger A., ANIM BEHAV, V13, P2119, DOI [DOI 10.1016/J.ANBEHAV.2014.11.002, 10.1371/journal.pmed.1002841]
   Wurtz P, 2008, CONSCIOUS COGN, V17, P171, DOI 10.1016/j.concog.2007.07.001
   Yoon K., 1999, MEDIA PSYCHOL, V1, P331
   ZAICHKOWSKY JL, 1985, J CONSUM RES, V12, P341, DOI 10.1086/208520
   Zurbrugg Nicholas, 1989, CONTINUUM AUSTR J ME, V2, P26, DOI [10.1080/10304318909359363, DOI 10.1080/10304318909359363]
NR 85
TC 0
Z9 0
U1 2
U2 5
PU  EDICIONES PROFESIONALES INFORMACION SL-EPI
PI BARCELONA
PA MISTRAL, 36, BARCELONA, ALBOLOTE, SPAIN
SN 1386-6710
EI 1699-2407
J9 PROF INFORM
JI Prof. Inf.
PY 2022
VL 31
IS 4
AR e310416
DI 10.3145/epi.2022.jul.16
PG 13
WC Communication; Information Science & Library Science
WE Social Science Citation Index (SSCI)
SC Communication; Information Science & Library Science
GA 5V7PP
UT WOS:000877418400009
OA hybrid, Green Submitted
DA 2024-01-09
ER

PT J
AU Kamiyama, KS
   Abla, D
   Iwanaga, K
   Okanoya, K
AF Kamiyama, Keiko S.
   Abla, Dilshat
   Iwanaga, Koichi
   Okanoya, Kazuo
TI Interaction between musical emotion and facial expression as measured by
   event-related potentials
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE Music; Facial expression; Emotion; Electroencephalogram (EEG); N400
ID COMBINED PERCEPTION; BRAIN POTENTIALS; TIME-COURSE; LANGUAGE; PICTURES;
   CONTEXT; SOUNDS; CHORDS; VOICE; MODE
AB We examined the integrative process between emotional facial expressions and musical excerpts by using an affective priming paradigm. Happy or sad musical stimuli were presented after happy or sad facial images during electroencephalography (EEG) recordings. We asked participants to judge the affective congruency of the presented face-music pairs. The congruency of emotionally congruent pairs was judged more rapidly than that of incongruent pairs. In addition, the EEG data showed that incongruent musical targets elicited a larger N400 component than congruent pairs. Furthermore, these effects occurred in nonmusicians as well as musicians. In sum, emotional integrative processing of face-music pairs was facilitated in congruent music targets and inhibited in incongruent music targets; this process was not significantly modulated by individual musical experience. This is the first study on musical stimuli primed by facial expressions to demonstrate that the N400 component reflects the affective priming effect. (c) 2012 Elsevier Ltd. All rights reserved.
C1 [Kamiyama, Keiko S.; Okanoya, Kazuo] Univ Tokyo, Grad Sch Arts & Sci, Dept Life Sci, Meguro Ku, Tokyo 1538902, Japan.
   [Kamiyama, Keiko S.] Japan Soc Promot Sci, Tokyo, Japan.
   [Kamiyama, Keiko S.; Okanoya, Kazuo] Emot Informat Joint Res Lab, Wako, Saitama 3510198, Japan.
   [Abla, Dilshat] RIKEN, Brain Sci Inst, BSI Toyota Collaborat Ctr, Noninvas BMI Unit, Wako, Saitama 3510198, Japan.
   [Iwanaga, Koichi] Chiba Univ, Dept Design, Grad Sch Engn, Chiba, Japan.
   [Okanoya, Kazuo] Japan Sci & Technol Agcy, ERATO, Okanoya Emot Informat Project, Wako, Saitama 3510198, Japan.
C3 University of Tokyo; Japan Society for the Promotion of Science; RIKEN;
   Toyota Motor Corporation; Chiba University; Japan Science & Technology
   Agency (JST)
RP Okanoya, K (corresponding author), Univ Tokyo, Grad Sch Arts & Sci, Dept Life Sci, Meguro Ku, 3-8-1 Komaba, Tokyo 1538902, Japan.
EM kkamiyama@brain.riken.jp; dilshata@gmail.com;
   iwanaga@faculty.chiba-u.jp; kazuookanoya@gmail.com
FU [20300096];  [235634]; Grants-in-Aid for Scientific Research [23240033]
   Funding Source: KAKEN
FX This research was conducted at the Laboratory for Biolinguistics, RIKEN
   Brain Science Institute, and at the University of Tokyo. This work was
   supported by a Grant-in-Aid for Scientific Research (B) (No. 20300096)
   and a Grant-in-Aid for JSPS Fellows Grant Number 235634. We would like
   to thank all the participants who took part in our experiments.
CR [Anonymous], 2001, Music and Emotion, DOI DOI 10.1525/MP.2004.21.4.561
   Baumgartner T, 2006, INT J PSYCHOPHYSIOL, V60, P34, DOI 10.1016/j.ijpsycho.2005.04.007
   Baumgartner T, 2006, BRAIN RES, V1075, P151, DOI 10.1016/j.brainres.2005.12.065
   BENTIN S, 1985, ELECTROEN CLIN NEURO, V60, P343, DOI 10.1016/0013-4694(85)90008-2
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Blair KS, 2006, BIOL PSYCHOL, V73, P114, DOI 10.1016/j.biopsycho.2005.12.006
   Daltrozzo J, 2009, J COGNITIVE NEUROSCI, V21, P1882, DOI 10.1162/jocn.2009.21113
   de Gelder B, 2000, COGNITION EMOTION, V14, P289, DOI 10.1080/026999300378824
   de Gelder B, 1999, NEUROSCI LETT, V260, P133, DOI 10.1016/S0304-3940(98)00963-X
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Gagnon L, 2003, COGNITION EMOTION, V17, P25, DOI 10.1080/02699930302279
   Goerlich KS, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019501
   Grossmann T, 2006, DEVELOPMENTAL SCI, V9, P309, DOI 10.1111/j.1467-7687.2006.00494.x
   Jolj J., 2011, PHYS LIFE REV, V6
   Koelsch S, 2004, NAT NEUROSCI, V7, P302, DOI 10.1038/nn1197
   Krumhansl CL, 2010, MUSIC PERCEPT, V27, P337, DOI 10.1525/mp.2010.27.5.337
   KUTAS M, 1980, SCIENCE, V207, P203, DOI 10.1126/science.7350657
   KUTAS M, 1984, NATURE, V307, P161, DOI 10.1038/307161a0
   Leaver AM, 2004, MUSIC PERCEPT, V22, P117, DOI 10.1525/mp.2004.22.1.117
   Logeswaran N, 2009, NEUROSCI LETT, V455, P129, DOI 10.1016/j.neulet.2009.03.044
   Painter JG, 2011, PSYCHOPHYSIOLOGY, V48, P645, DOI 10.1111/j.1469-8986.2010.01134.x
   Pallesen KJ, 2005, ANN NY ACAD SCI, V1060, P450, DOI 10.1196/annals.1360.047
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   Pourtois G, 2000, NEUROREPORT, V11, P1329, DOI 10.1097/00001756-200004270-00036
   Pourtois G, 2002, COGNITIVE BRAIN RES, V14, P99, DOI 10.1016/S0926-6410(02)00064-2
   Sollberger B, 2003, MUSIC PERCEPT, V20, P263, DOI 10.1525/mp.2003.20.3.263
   Spreckelmeyer KN, 2006, BRAIN RES, V1070, P160, DOI 10.1016/j.brainres.2005.11.075
   Steinbeis N, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0002226
   Steinbeis N, 2011, J COGNITIVE NEUROSCI, V23, P604, DOI 10.1162/jocn.2009.21383
   Tan SL, 2007, MUSIC PERCEPT, V25, P135, DOI 10.1525/MP.2007.25.2.135
   Trainor LJ, 2010, SPRINGER HANDB AUDIT, V36, P89, DOI 10.1007/978-1-4419-6114-3_4
NR 31
TC 20
Z9 29
U1 2
U2 59
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD FEB
PY 2013
VL 51
IS 3
BP 500
EP 505
DI 10.1016/j.neuropsychologia.2012.11.031
PG 6
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA 106PU
UT WOS:000316158000015
PM 23220447
DA 2024-01-09
ER

PT J
AU Puligadda, S
   VanBergen, N
AF Puligadda, Sanjay
   VanBergen, Noah
TI The influence of sound logo instruments on brand personality
   perceptions: An investigation of brand ruggedness and sophistication
SO JOURNAL OF BUSINESS RESEARCH
LA English
DT Article
DE Sound logos; Brand personality; Timbre
ID BACKGROUND MUSIC; BEHAVIOR; DIMENSIONS; GENDER; IMPACT; CONGRUENCY;
   CONSUMERS; EMOTIONS; SCENT; TRAIT
AB Marketing relies heavily on auditory information-from background music in commercials to jingles and sound logos. One attribute of auditory information is timbre, which describes the identity of a sound source (an instrument, voices, etc.). Extensive literature investigating effects of timbre outside of marketing contexts shows that different instruments convey different emotions, personalities, and identities, yet marketing literature is silent on consumers' responses to different instruments in marketing communications. We close this gap by studying the effect of a sound logo's instrumentation on perceptions of brand personality. Through four studies and three pretests we show that a) the instrument used in a brand's sound logo influences the brand's personality perceptions (specifically perceived sophistication and ruggedness); b) these influences are due to visceral and conceptual effects of instrumentation; and c) a sound logo's instrument is just as influential as a visual logo's design on brand personality perceptions.
C1 [Puligadda, Sanjay] Miami Univ, Farmer Sch Business 3039, Oxford, OH 45056 USA.
   [VanBergen, Noah] Univ Cincinnati, 2376 Lindner Hall, 2906 Woodside Dr, Cincinnati, OH 45221 USA.
C3 University System of Ohio; Miami University; University System of Ohio;
   University of Cincinnati
RP Puligadda, S (corresponding author), Miami Univ, Farmer Sch Business 3039, Oxford, OH 45056 USA.
EM puligsan@miamioh.edu; vanbernh@ucmail.uc.edu
CR Aaker JL, 1997, J MARKETING RES, V34, P347, DOI 10.2307/3151897
   Abeles H, 2009, J RES MUSIC EDUC, V57, P127, DOI 10.1177/0022429409335878
   Adeli M, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00352
   Albert N, 2008, J BUS RES, V61, P1062, DOI 10.1016/j.jbusres.2007.09.014
   Alpert MI, 2005, J BUS RES, V58, P369, DOI 10.1016/S0148-2963(03)00101-2
   ANDERSON JR, 1983, J VERB LEARN VERB BE, V22, P261, DOI 10.1016/S0022-5371(83)90201-3
   [Anonymous], 1989, MUSICAL GROWTH DEV B
   Ballouli K, 2015, SPORT MANAG REV, V18, P321, DOI 10.1016/j.smr.2014.03.001
   BELK RW, 1988, J CONSUM RES, V15, P139, DOI 10.1086/209154
   Beverland M, 2006, J BUS RES, V59, P982, DOI 10.1016/j.jbusres.2006.07.001
   Biel A.L, 1993, Brand Equity and Advertising : Advertising's Role in Building Strong Brands
   Bowman C, 2017, COGNITION EMOTION, V31, P1610, DOI 10.1080/02699931.2016.1255588
   BRUNER GC, 1990, J MARKETING, V54, P94, DOI 10.1177/002224299005400408
   Caclin A, 2005, J ACOUST SOC AM, V118, P471, DOI 10.1121/1.1929229
   Chebat JC, 2001, J BUS RES, V54, P115, DOI 10.1016/S0148-2963(99)00089-2
   Cian L, 2014, J MARKETING RES, V51, P184, DOI 10.1509/jmr.13.0023
   Dhar R, 2000, J MARKETING RES, V37, P60, DOI 10.1509/jmkr.37.1.60.18718
   Fournier S, 1998, J CONSUM RES, V24, P343, DOI 10.1086/209515
   Garlin FV, 2006, J BUS RES, V59, P755, DOI 10.1016/j.jbusres.2006.01.013
   Geuens M, 2009, INT J RES MARK, V26, P97, DOI 10.1016/j.ijresmar.2008.12.002
   Grohmann B, 2009, J MARKETING RES, V46, P105, DOI 10.1509/jmkr.46.1.105
   Hagtvedt H, 2011, J MARKETING, V75, P86, DOI 10.1509/jmkg.75.4.86
   Haigood T.L., 2001, AMA EDUCATORS P, V12, P327
   Hailstone JC, 2009, Q J EXP PSYCHOL, V62, P2141, DOI 10.1080/17470210902765957
   Harrison S. D., 2007, British Journal of Music Education, V24, P267
   Heinlein CP, 1928, J COMP PSYCHOL, V8, P101, DOI 10.1037/h0070573
   Henderson PW, 1998, J MARKETING, V62, P14, DOI 10.2307/1252158
   Holbrook M.B., 1990, Psychology of Music, V18, P150, DOI [10.1177/0305735690182004, DOI 10.1177/0305735690182004]
   Jerónimo R, 2018, J BUS RES, V88, P54, DOI 10.1016/j.jbusres.2018.02.029
   Jiang YW, 2016, J CONSUM RES, V42, P709, DOI 10.1093/jcr/ucv049
   Johar GV, 2005, J MARKETING RES, V42, P458, DOI 10.1509/jmkr.2005.42.4.458
   Juslin P. N., 1996, PSYCHOL MUSIC, V24, P68, DOI [10.1177/0305735696241007, DOI 10.1177/0305735696241007]
   KELLARIS JJ, 1993, J MARKETING, V57, P114, DOI 10.2307/1252223
   Kellaris JJ., 1994, J CONSUM PSYCHOL, V2, P381, DOI DOI 10.1016/S1057-7408(08)80068-X
   KELLER KL, 1993, J MARKETING, V57, P1, DOI 10.2307/1252054
   Kleine III R. E., 1993, Journal of Consumer Psychology, V2, P209, DOI [10.1016/S1057-7408(08)80015-0, DOI 10.1016/S1057-7408(08)80015-0]
   Klink RR, 2003, MARKET LETT, V14, P143, DOI 10.1023/A:1027476132607
   Kotler P., 2000, Marketing Management
   Krishna A, 2012, J CONSUM PSYCHOL, V22, P332, DOI 10.1016/j.jcps.2011.08.003
   Krishnan V, 2012, J PROD BRAND MANAG, V21, P275, DOI 10.1108/10610421211246685
   Lavack AM, 2008, INT J ADVERT, V27, P549, DOI 10.2501/S0265048708080141
   Levitin, 2006, THIS IS YOUR BRAIN M
   Lowe ML, 2017, J MARKETING RES, V54, P331, DOI 10.1509/jmr.14.0300
   Lowrey TM, 2007, J CONSUM RES, V34, P406, DOI 10.1086/518530
   Luffarelli J, 2019, J MARKETING RES, V56, P89, DOI 10.1177/0022243718820548
   Lusensky J., 2010, SOUNDS BRANDING
   Mattila AS, 2001, J RETAILING, V77, P273, DOI 10.1016/S0022-4359(01)00042-2
   Menon V, 2005, NEUROIMAGE, V28, P175, DOI 10.1016/j.neuroimage.2005.05.053
   Micu AC, 2010, J ADVERTISING RES, V50, P137, DOI 10.2501/S0021849910091300
   MILLIMAN RE, 1986, J CONSUM RES, V13, P286, DOI 10.1086/209068
   MILLIMAN RE, 1982, J MARKETING, V46, P86, DOI 10.2307/1251706
   Neuhoff J, 1999, The Sonification Report: Status of the Field and Research Agenda. Report prepared for the National Science Foundation by members of the International Community for Auditory Display
   Oakes S, 2006, APPL COGNITIVE PSYCH, V20, P505, DOI 10.1002/acp.1199
   Ogilvy D., 2013, OGILVY ADVERTISING
   Patel A. D., 2008, Music, Language, and the Brain
   Payne PD, 2014, J BAND RES, V50, P40
   Petty R.E., 1986, The Elaboration Likelihood Model of Persuasion, P1, DOI DOI 10.1007/978-1-4612-4964-1_1
   Plummer JT, 2000, J ADVERTISING RES, V40, P79, DOI 10.2501/JAR-40-6-79-83
   RESCORLA RA, 1988, ANNU REV NEUROSCI, V11, P329, DOI 10.1146/annurev.ne.11.030188.001553
   Spangenberg ER, 2005, J BUS RES, V58, P1583, DOI 10.1016/j.jbusres.2004.09.005
   Spence C, 2011, ATTEN PERCEPT PSYCHO, V73, P971, DOI 10.3758/s13414-010-0073-7
   Spence C, 2013, CONSCIOUS COGN, V22, P245, DOI 10.1016/j.concog.2012.12.006
   Turley LW, 2000, J BUS RES, V49, P193, DOI 10.1016/S0148-2963(99)00010-7
   Vurma A, 2011, PSYCHOL MUSIC, V39, P291, DOI 10.1177/0305735610373602
   Wang XH, 2018, J BUS RES, V84, P89, DOI 10.1016/j.jbusres.2017.11.011
   Weiss B, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2014
   Yoo B, 2001, J BUS RES, V52, P1, DOI 10.1016/S0148-2963(99)00098-3
   Yorkston E, 2004, J CONSUM RES, V31, P43, DOI 10.1086/383422
   Zhu R, 2005, J MARKETING RES, V42, P333, DOI 10.1509/jmkr.2005.42.3.333
   Ziv N., 2013, WORLD J PEDIATR, V23, P168
NR 70
TC 2
Z9 2
U1 17
U2 27
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0148-2963
EI 1873-7978
J9 J BUS RES
JI J. Bus. Res.
PD FEB
PY 2023
VL 156
AR 113531
DI 10.1016/j.jbusres.2022.113531
EA DEC 2022
PG 13
WC Business
WE Social Science Citation Index (SSCI)
SC Business & Economics
GA 8X9DO
UT WOS:000932307500003
DA 2024-01-09
ER

PT J
AU Fuller, CD
   Galvin, JJ
   Maat, B
   Free, RH
   Baskent, D
AF Fuller, Christina D.
   Galvin, John J., III
   Maat, Bert
   Free, Rolien H.
   Baskent, Deniz
TI The musician effect: does it persist under degraded pitch conditions of
   cochlear implant simulations?
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE musician effect; music training; cochlear implant; speech perception;
   emotion identification; music perception; pitch processing
AB Cochlear implants (Cis) are auditory prostheses that restore hearing via electrical stimulation of the auditory nerve. Compared to normal acoustic hearing, sounds transmitted through the CI are spectro-temporally degraded, causing difficulties in challenging listening tasks such as speech intelligibility in noise and perception of music. In normal hearing (NH), musicians have been shown to better perform than non-musicians in auditory processing and perception, especially for challenging listening tasks. This "musician effect" was attributed to better processing of pitch cues, as well as better overall auditory cognitive functioning in musicians. Does the musician effect persist when pitch cues are degraded, as it would be in signals transmitted through a CI? To answer this question, NH musicians and non-musicians were tested while listening to unprocessed signals or to signals processed by an acoustic CI simulation. The task increasingly depended on pitch perception: (1) speech intelligibility (words and sentences) in quiet or in noise, (2) vocal emotion identification, and (3) melodic contour identification (MCI). For speech perception, there was no musician effect with the unprocessed stimuli, and a small musician effect only for word identification in one noise condition, in the CI simulation. For emotion identification, there was a small musician effect for both. For MCI, there was a large musician effect for both. Overall, the effect was stronger as the importance of pitch in the listening task increased. This suggests that the musician effect may be more rooted in pitch perception, rather than in a global advantage in cognitive processing (in which musicians would have performed better in all tasks). The results further suggest that musical training before (and possibly after) implantation might offer some advantage in pitch processing that could partially benefit speech perception, and more strongly emotion and music perception.
C1 [Fuller, Christina D.; Galvin, John J., III; Maat, Bert; Free, Rolien H.; Baskent, Deniz] Univ Groningen, Univ Med Ctr Groningen, Dept Otorhinolaryngol Head & Neck Surg, POB 30-001,Hanzepl 1, NL-9700 RB Groningen, Netherlands.
   [Fuller, Christina D.; Galvin, John J., III; Maat, Bert; Free, Rolien H.; Baskent, Deniz] Univ Groningen, Grad Sch Med Sci, Res Sch Behav & Cognit Neurosci, Groningen, Netherlands.
   [Galvin, John J., III] House Res Inst, Div Commun & Auditory Neurosci, Los Angeles, CA USA.
   [Galvin, John J., III] Univ Calif Los Angeles, David Geffen Sch Med, Dept Head & Neck Surg, Los Angeles, CA 90095 USA.
C3 University of Groningen; University of Groningen; University of
   California System; University of California Los Angeles; University of
   California Los Angeles Medical Center; David Geffen School of Medicine
   at UCLA
RP Baskent, D (corresponding author), Univ Groningen, Univ Med Ctr Groningen, Dept Otorhinolaryngol Head & Neck Surg, POB 30-001,Hanzepl 1, NL-9700 RB Groningen, Netherlands.
EM d.baskent@umcg.nl
OI Baskent, Deniz/0000-0002-6560-1451
FU NIH [R01-DC004792]; Heinsius-Houbolt Foundation; Rosalind Franklin
   Fellowship from the University Medical Center Groningen, University of
   Groningen; VIDI grant from the Netherlands Organization for Scientific
   Research (NWO) [016.096.397]; Netherlands Organization for Health
   Research and Development (ZonMw)
FX We would like to thank Joeri Smit and Karin van der Velde for their help
   with collecting the data, Mirjam Broersma and Martijn Goudbeek for
   providing the emotion stimuli, Steven Gilbers for help with the emotion
   data and Qian Jie Fu and the Emily Shannon Fu Foundation for the help
   and support with the testing software. The second author is supported by
   NIH R01-DC004792. The fourth author is supported by an
   otological/neurotological stipendium from the Heinsius-Houbolt
   Foundation. The last author is supported by a Rosalind Franklin
   Fellowship from the University Medical Center Groningen, University of
   Groningen, and the VIDI grant 016.096.397 from the Netherlands
   Organization for Scientific Research (NWO) and the Netherlands
   Organization for Health Research and Development (ZonMw). The study is
   part of the research program of our department: Healthy Aging and
   Communication.
CR [Anonymous], 2000, J ACAD REHABIL AUDIO
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Barrett KC, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00713
   Baskent D, 2006, J ACOUST SOC AM, V119, P1156, DOI 10.1121/1.2151825
   Baskent D, 2007, EAR HEARING, V28, P277
   Baskent D, 2014, J ACOUST SOC AM, V135, pEL147, DOI 10.1121/1.4865261
   Benard MR, 2014, J ACOUST SOC AM, V135, pEL88, DOI 10.1121/1.4862879
   Besson M, 2007, RESTOR NEUROL NEUROS, V25, P399
   Besson M, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00094
   Bhargava P, 2014, HEARING RES, V309, P113, DOI 10.1016/j.heares.2013.12.003
   Bialystok E, 2009, J EXP PSYCHOL HUMAN, V35, P565, DOI 10.1037/a0012735
   Bierer JA, 2010, TRENDS AMPLIF, V14, P84, DOI 10.1177/1084713810375249
   Blamey P, 2013, AUDIOL NEURO-OTOL, V18, P36, DOI 10.1159/000343189
   Bosman AJ, 1995, AUDIOLOGY, V34, P260
   Chartrand JP, 2006, NEUROSCI LETT, V405, P164, DOI 10.1016/j.neulet.2006.06.053
   Crew JD, 2012, J ACOUST SOC AM, V132, pEL429, DOI 10.1121/1.4758770
   Deguchi C, 2012, BRAIN RES, V1455, P75, DOI 10.1016/j.brainres.2012.03.034
   Dreschler WA, 2001, AUDIOLOGY, V40, P148
   Driscoll VD, 2009, J AM ACAD AUDIOL, V20, P71, DOI 10.3766/jaaa.20.1.7
   Friesen LM, 2001, J ACOUST SOC AM, V110, P1150, DOI 10.1121/1.1381538
   Fu QJ, 2005, JARO-J ASSOC RES OTO, V6, P19, DOI 10.1007/s10162-004-5024-3
   Fu QJ, 2004, JARO-J ASSOC RES OTO, V5, P253, DOI 10.1007/s10162-004-4046-1
   Fuller C, 2012, J ACOUST SOC AM, V132, P1009, DOI 10.1121/1.4730910
   Fuller CD, 2014, J ACOUST SOC AM, V135, pEL159, DOI 10.1121/1.4865263
   Galvin JJ, 2008, J ACOUST SOC AM, V124, pEL189, DOI 10.1121/1.2961171
   Galvin JJ, 2007, EAR HEARING, V28, P302, DOI 10.1097/01.aud.0000261689.35445.20
   Galvin John J. III, 2012, Seminars in Hearing, V33, P399, DOI 10.1055/s-0032-1329227
   Galvin JJ, 2009, ANN NY ACAD SCI, V1169, P518, DOI 10.1111/j.1749-6632.2009.04551.x
   Gfeller K, 2007, EAR HEARING, V28, P412, DOI 10.1097/AUD.0b013e3180479318
   Gfeller Kate, 2002, J Am Acad Audiol, V13, P132
   Gfeller Kate, 2002, Cochlear Implants Int, V3, P29, DOI 10.1179/cim.2002.3.1.29
   Globerson E, 2013, ATTEN PERCEPT PSYCHO, V75, P1799, DOI 10.3758/s13414-013-0518-x
   Goudbeek M, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2026
   GREENWOOD DD, 1990, J ACOUST SOC AM, V87, P2592, DOI 10.1121/1.399052
   Heng J, 2011, HEARING RES, V280, P192, DOI 10.1016/j.heares.2011.05.017
   Holden LK, 2013, EAR HEARING, V34, P342, DOI 10.1097/AUD.0b013e3182741aa7
   Hubbard DJ, 2013, J ACOUST SOC AM, V133, P2367, DOI 10.1121/1.4792145
   Hyde KL, 2009, ANN NY ACAD SCI, V1169, P182, DOI 10.1111/j.1749-6632.2009.04852.x
   Kong YY, 2004, EAR HEARING, V25, P173, DOI 10.1097/01.AUD.0000120365.97792.2F
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Lazard DS, 2014, HEARING RES, V307, P136, DOI 10.1016/j.heares.2013.08.006
   Lazard DS, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048739
   Limb CJ, 2014, HEARING RES, V308, P13, DOI 10.1016/j.heares.2013.04.009
   Looi Valerie, 2012, Seminars in Hearing, V33, P307, DOI 10.1055/s-0032-1329222
   McDermott Hugh J, 2004, Trends Amplif, V8, P49, DOI 10.1177/108471380400800203
   Micheyl C, 2006, HEARING RES, V219, P36, DOI 10.1016/j.heares.2006.05.004
   MILLER GA, 1950, J ACOUST SOC AM, V22, P167, DOI 10.1121/1.1906584
   Moreno S, 2011, PSYCHOL SCI, V22, P1425, DOI 10.1177/0956797611416999
   Moreno S, 2009, CEREB CORTEX, V19, P712, DOI 10.1093/cercor/bhn120
   Musacchia G, 2008, HEARING RES, V241, P34, DOI 10.1016/j.heares.2008.04.013
   Nelson PB, 2003, J ACOUST SOC AM, V113, P961, DOI 10.1121/1.1531983
   Oxenham Andrew J, 2008, Trends Amplif, V12, P316, DOI 10.1177/1084713808325881
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   PLOMP R, 1979, J ACOUST SOC AM, V66, P1333, DOI 10.1121/1.383554
   Ruggles DR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086980
   Schön D, 2004, PSYCHOPHYSIOLOGY, V41, P341, DOI 10.1111/1469-8986.00172.x
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Stickney GS, 2004, J ACOUST SOC AM, V116, P1081, DOI 10.1121/1.1772399
   Strait DL, 2009, EUR J NEUROSCI, V29, P661, DOI 10.1111/j.1460-9568.2009.06617.x
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Torppa R, 2014, INT J AUDIOL, V53, P182, DOI 10.3109/14992027.2013.872302
   Versfeld NJ, 2000, J ACOUST SOC AM, V107, P1671, DOI 10.1121/1.428451
   Weenink D., 2012, PRAAT DOING PHONETIC
   Wennerstrom Ann, 2001, MUSIC EVERYDAY SPEEC
   Won JH, 2010, EAR HEARING, V31, P796, DOI 10.1097/AUD.0b013e3181e8b7bd
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   Xin Luo, 2007, Trends Amplif, V11, P301
   Yucel E, 2009, INT J PEDIATR OTORHI, V73, P1043, DOI 10.1016/j.ijporl.2009.04.009
   Zuk J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0080546
NR 69
TC 62
Z9 69
U1 0
U2 19
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA PO BOX 110, EPFL INNOVATION PARK, BUILDING I, LAUSANNE, 1015,
   SWITZERLAND
SN 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD JUN 30
PY 2014
VL 8
AR 179
DI 10.3389/fnins.2014.00179
PG 16
WC Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Neurosciences & Neurology
GA V44TM
UT WOS:000209771300001
PM 25071428
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Yang, CY
   Lin, CP
AF Yang, Chia-Yen
   Lin, Ching-Po
TI Coherent activity between auditory and visual modalities during the
   induction of peacefulness
SO COGNITIVE NEURODYNAMICS
LA English
DT Article
DE Dominance; Audiovisual modality; Magnetoencephalography; Coherence
ID FACIAL EXPRESSIONS; PERCEPTION; EMOTION; VOICE; FACE; INTEGRATION;
   MUSIC; BRAIN; MEG
AB Multisensory integration involves combining information from different senses to create a perception. The diverse characteristics of different sensory systems make it interesting to determine how cooperation and competition contribute to emotional experiences. Therefore, the aim of this study were to estimate the bias from the match attributes of the auditory and visual modalities and to depict specific brain activity frequency (theta, alpha, beta, and gamma) patterns related to a peaceful mood by using magnetoencephalography. The present study provides evidence of auditory domination in perceptual bias during multimodality processing of peaceful consciousness. Coherence analysis suggested that the theta oscillations are a transmitter of emotion signals, with the left and right brains being active in peaceful and fearful moods, respectively. Notably, hemispheric lateralization was also apparent in the alpha and beta oscillations, which might govern simple or pure information (e.g. from single modality) in the right brain but complex or mixed information (e.g. from multiple modalities) in the left brain.
C1 [Yang, Chia-Yen] Ming Chuan Univ, Dept Biomed Engn, Tao Yuan, Taiwan.
   [Lin, Ching-Po] Natl Yang Ming Univ, Inst Neurosci, Taipei 112, Taiwan.
C3 Ming Chuan University; National Yang Ming Chiao Tung University
RP Lin, CP (corresponding author), Natl Yang Ming Univ, Inst Neurosci, 155 Sect 2 Li Nong St, Taipei 112, Taiwan.
EM cyyang@mcu.edu.tw; chingpolin@gmail.com
OI Lin, Ching-Po/0000-0001-6848-8776
FU National Science Council [NSC-99-2410-H-130-018-,
   NSC-100-2628-E-010-002-MY3]; Academia Sinica, Taiwan [AS-99-TP-AC1]
FX This study was supported in part by research grants from National
   Science Council (NSC-99-2410-H-130-018-, NSC-100-2628-E-010-002-MY3) and
   Academia Sinica (AS-99-TP-AC1), Taiwan.
CR Adachi Y, 2001, IEEE T APPL SUPERCON, V11, P669, DOI 10.1109/77.919433
   [Anonymous], 1999, P INT WORKSH IND COM
   Baumgartner T, 2006, INT J PSYCHOPHYSIOL, V60, P34, DOI 10.1016/j.ijpsycho.2005.04.007
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Campanella S, 2007, TRENDS COGN SCI, V11, P535, DOI 10.1016/j.tics.2007.10.001
   Chen YH, 2010, EUR J NEUROSCI, V31, P1818, DOI 10.1111/j.1460-9568.2010.07203.x
   Collignon O, 2008, BRAIN RES, V1242, P126, DOI 10.1016/j.brainres.2008.04.023
   Doehrmann O, 2010, J NEUROSCI, V30, P3370, DOI 10.1523/JNEUROSCI.5074-09.2010
   Dolan RJ, 2001, P NATL ACAD SCI USA, V98, P10006, DOI 10.1073/pnas.171288598
   Esposito A, 2009, COGN COMPUT, V1, P268, DOI 10.1007/s12559-009-9017-8
   Fenko A, 2010, APPL ERGON, V41, P34, DOI 10.1016/j.apergo.2009.03.007
   Fort A, 2002, CEREB CORTEX, V12, P1031, DOI 10.1093/cercor/12.10.1031
   Koelewijn T, 2010, ACTA PSYCHOL, V134, P372, DOI 10.1016/j.actpsy.2010.03.010
   Latinus M, 2010, BMC NEUROSCI, V11, DOI 10.1186/1471-2202-11-36
   Logeswaran N, 2009, NEUROSCI LETT, V455, P129, DOI 10.1016/j.neulet.2009.03.044
   Luo H, 2010, PLOS BIOL, V8, DOI 10.1371/journal.pbio.1000445
   Massaro DW, 1996, PSYCHON B REV, V3, P215, DOI 10.3758/BF03212421
   Mishra J, 2007, J NEUROSCI, V27, P4120, DOI 10.1523/JNEUROSCI.4912-06.2007
   Most T, 2012, J SPEECH LANG HEAR R, V55, P1148, DOI 10.1044/1092-4388(2011/11-0060)
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   Pourtois G, 2005, CORTEX, V41, P49, DOI 10.1016/S0010-9452(08)70177-1
   Pourtois G, 2002, COGNITIVE BRAIN RES, V14, P99, DOI 10.1016/S0926-6410(02)00064-2
   Schifferstein Hendrik N. J., 2010, Journal of Design Research, V8, P119, DOI 10.1504/JDR.2010.032074
   Senkowski D, 2009, EXP BRAIN RES, V198, P363, DOI 10.1007/s00221-009-1835-0
   Stekelenburg JJ, 2009, EXP BRAIN RES, V198, P383, DOI 10.1007/s00221-009-1763-z
   Tanaka E, 2009, NEUROIMAGE, V48, P464, DOI 10.1016/j.neuroimage.2009.06.037
   Wu L, 2010, NEUROIMAGE, V52, P1252, DOI 10.1016/j.neuroimage.2010.05.053
   Yang CY, 2008, VISUAL NEUROSCI, V25, P179, DOI 10.1017/S0952523808080413
   Yang CY, 2011, J NEUROIMAGING, DOI [10.1111/j.1552-6569(2011.00623.x), DOI 10.1111/J.1552-6569(2011.00623.X)]
   Zhao HX, 2009, J PAIN, V10, P953, DOI 10.1016/j.jpain.2009.03.006
NR 30
TC 7
Z9 7
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1871-4080
J9 COGN NEURODYNAMICS
JI Cogn. Neurodynamics
PD AUG
PY 2013
VL 7
IS 4
BP 301
EP 309
DI 10.1007/s11571-012-9234-9
PG 9
WC Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Neurosciences & Neurology
GA 184RM
UT WOS:000321911000002
PM 24427206
OA Green Published
DA 2024-01-09
ER

PT J
AU Okada, BM
   Lachs, L
   Boone, B
AF Okada, Brooke M.
   Lachs, Lorin
   Boone, Benjamin
TI Interpreting tone of voice: Musical pitch relationships convey agreement
   in dyadic conversation
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID PHONETIC CONVERGENCE; ACCOMMODATION; PERCEPTIONS; SPEECH
AB Previous research has found that the musical intervals found in speech are associated with various emotions. Intervals can be classified by their level of consonance or dissonance-how pleasant or unpleasant the combined tones sound to the ear. Exploratory investigations have indicated that in an agreeable conversation, the pitches of the last word in an utterance and the first word of a conversation partner's utterance are consonantly related; in a disagreeable conversation, the two pitches are dissonantly related. The present results showed that the intervals between the tonics of the utterances in a conversation corresponded to the agreement between interlocutors. (C) 2012 Acoustical Society of America
C1 [Okada, Brooke M.; Lachs, Lorin] Calif State Univ Fresno, Dept Psychol, Fresno, CA 93740 USA.
   [Boone, Benjamin] Calif State Univ Fresno, Dept Mus, Fresno, CA 93740 USA.
C3 California State University System; California State University Fresno;
   California State University System; California State University Fresno
RP Okada, BM (corresponding author), Calif State Univ Fresno, Dept Psychol, 2576 E San Ramon ST11, Fresno, CA 93740 USA.
EM brookeokada@gmail.com; llachs@csufresno.edu; bboone@csufresno.edu
OI Lachs, Lorin/0009-0002-4506-9602
CR Aitken H., 1997, PIECE WHOLE STUDIES
   [Anonymous], 2008, SIBELIUS VERS 5 2
   Boersma P., 2010, PRAAT DOING PHONETIC
   Boone B., 2003, 2003 HAW INT C ARTS
   Boone B., 2007, 28 ANN CENTR CAL RES
   Cross Ian, 2003, The Cognitive Neuroscience of Music, P42, DOI DOI 10.1093/ACPROF:OSO/9780198525202.003.0004
   Curtis ME, 2010, EMOTION, V10, P335, DOI 10.1037/a0017928
   DEUTSCH D, 2010, SCI AM MIND, V21, P36
   Dias JW, 2011, PERCEPTION, V40, P1457, DOI 10.1068/p7071
   Gregory SW, 1997, J NONVERBAL BEHAV, V21, P23
   Gregory SW, 1996, J PERS SOC PSYCHOL, V70, P1231, DOI 10.1037/0022-3514.70.6.1231
   Hallam S., 2006, MUSIC PSYCHOL ED
   Heisterman M., 2007, TRISTAN ISOLDE
   Pardo JS, 2012, J PHONETICS, V40, P190, DOI 10.1016/j.wocn.2011.10.001
   Pardo JS, 2006, J ACOUST SOC AM, V119, P2382, DOI 10.1121/1.2178720
   Pytlyk C., 2008, 2008 ANN C CAN LING
   Schmidt-Jones C., 2010, CONSONANCE DISSONANC
   Schreuder M., 2005, THESIS U GRONINGEN G
   Thayer R.E., 1996, ORIGIN EVERYDAY MOOD
   Worrall D., 2008, PHYS PSYCHOPHYSICS S
NR 20
TC 6
Z9 7
U1 0
U2 9
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD SEP
PY 2012
VL 132
IS 3
BP EL208
EP EL214
DI 10.1121/1.4742316
PN 1
PG 7
WC Acoustics; Audiology & Speech-Language Pathology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Acoustics; Audiology & Speech-Language Pathology
GA 011HF
UT WOS:000309155000007
PM 22979834
OA Bronze
DA 2024-01-09
ER

PT J
AU Weeks, K
AF Weeks, Kaja
TI Vowels-Sonic Gems of Emotion for Social Communication: Practical Singing
   Strategies for Non-musician Teachers with Developmentally Diverse Young
   Children
SO EARLY CHILDHOOD EDUCATION JOURNAL
LA English
DT Article
DE Music; Singing; Vowels; Relational; Neurodevelopmental disorders;
   Preschool teachers
ID AUTISM
AB Communicative and social capacities are known to be of primary developmental importance to all children and often present a particular difficulty for children with neurodevelopmental disorders. A recurring challenge for teachers is achieving effective communication with children who span developmental diversity (e.g. inclusive settings or those with a range of special needs) while using practical strategies that feel manageable to the teachers themselves. Music, a powerful affective medium, is appealing to all children and has the inherent flexibility to reach differing individuals. Thus, it is especially valuable for children with autism and other special needs. However, teachers without musical training may miss a great deal of music's potential benefits. The author describes an affective singing technique that, while grounded in vocal practice and music theory, uses an overt focus upon vowels-vowels being known conveyors of emotion in sounded communication. This natural port of entry offers non-musician teachers a simple and accessible way to incorporate live singing into daily activities that opens space for two-way affective communication, a crucial component of social development. Key concepts in this paper are elucidated by childhood instructional and play scenarios and graphics. The discussion is supported by published behavioral and imaging research.
C1 ITS Dev Therapy Serv DTS Inc, 10605 Concord St,Suite 102, Kensington, MD 20895 USA.
RP Weeks, K (corresponding author), ITS Dev Therapy Serv DTS Inc, 10605 Concord St,Suite 102, Kensington, MD 20895 USA.
EM kaja.weeks@gmail.com
CR Adachi M., 2013, OXFORD HDB CHILDRENS, P449
   [Anonymous], CHILDHOOD ED
   [Anonymous], 2012, VISIONS RES MUSIC ED
   [Anonymous], 2005, VOWELS CONSONANTS IN
   [Anonymous], 1998, CHILD SPECIAL NEEDS
   Association A. P., 2013, DIAGN STAT MAN MENT, DOI [10.1176/appi.books.9780890425596, DOI 10.1176/APPI.BOOKS.9780890425596]
   Baranek GT, 2006, J CHILD PSYCHOL PSYC, V47, P591, DOI 10.1111/j.1469-7610.2005.01546.x
   Blacking J., 1973, How Musical is Man
   Chen-Hafteck L., 1997, Early Childhood Development and Care, V130, P85, DOI [DOI 10.1080/0300443971300109, 10.1080/0300443971300109]
   Dansereau D., 2011, LEARNING YOUNG CHILD, P39
   Emberly A., 2013, OXFORD HDB CHILDRENS, P77
   Erdemir A., 2010, THESIS
   Fernald A., 1992, Nonverbal vocal communication: Comparative and developmental approaches, P262
   Flewitt R, 2005, EARLY YEARS-ABINGDON, V25, P207, DOI 10.1080/09575140500251558
   Gillespie CW, 2010, EARLY CHILD DEV CARE, V180, P799, DOI 10.1080/03004430802396530
   Gogate LJ, 2000, CHILD DEV, V71, P878, DOI 10.1111/1467-8624.00197
   Green S. D., 2006, EARLY CHILDHOOD RES, V8
   Greenspan S. I., 2004, FLOORTIME WHAT IT RE
   Hallam S., 1998, British Journal of Special Education, V25, P88, DOI [10.1111/1467-8527.t01-1-00063, DOI 10.1111/1467-8527.T01-1-00063]
   Heaton P, 2009, PHILOS T R SOC B, V364, P1443, DOI 10.1098/rstb.2008.0327
   Huron David., 2006, SWEET ANTICIPATION M, DOI DOI 10.7551/MITPRESS/6575.001.0001
   Jones JA, 2005, CURR BIOL, V15, P1768, DOI 10.1016/j.cub.2005.08.063
   Kim HK, 2011, J EARLY CHILD TEACH, V32, P135, DOI 10.1080/10901027.2011.572228
   Koelsch S, 2013, STRUNGMANN FORUM REP, P141
   Levitin DJ, 2003, NEUROIMAGE, V20, P2142, DOI 10.1016/j.neuroimage.2003.08.016
   Malloch S., 2009, COMMUNICATIVE MUSICA, DOI DOI 10.1111/J.1752-0118.2009.01158_1.X
   Mathews S. E., 2012, DIMENSIONS EARLY CHI, V40, P13
   Molnar-Szakacs I, 2006, SOC COGN AFFECT NEUR, V1, P235, DOI 10.1093/scan/nsl029
   Molnar-Szakacs I, 2012, ANN NY ACAD SCI, V1252, P318, DOI 10.1111/j.1749-6632.2012.06465.x
   Moore T, 2002, YOUNG CHILDREN, V57, P84
   Nardo RL, 2006, J RES MUSIC EDUC, V54, P278, DOI 10.2307/4139751
   Nordoff P., 1983, MUSIC THERAPY SPECIA
   Panksepp J, 2002, BEHAV PROCESS, V60, P133, DOI 10.1016/S0376-6357(02)00080-3
   Porges SW, 2010, HBK BEHAV NEUROSCI, V19, P255, DOI 10.1016/B978-0-12-374593-4.00025-5
   Ringgenberg S, 2003, YOUNG CHILDREN, V58, P76
   Russo N, 2009, J AUTISM DEV DISORD, V39, P1185, DOI 10.1007/s10803-009-0737-0
   Shenfield T., 2003, Psychol. Music, V31, P365, DOI DOI 10.1177/03057356030314002
   Simpson K, 2011, J AUTISM DEV DISORD, V41, P1507, DOI 10.1007/s10803-010-1172-y
   Stern DN, 1985, The interpersonal world of the infant
   Tobin J., 2009, PRESCHOOL 3 CULTURES
   Trehub SE, 2001, MUSIC SCI, V5, P37, DOI 10.1177/10298649020050S103
   Trevarthen C., 2009, COMMUNICATIVE MUSICA, P2
   Trevarthen C., 2009, COMMUNICATIVE MUSICA, P210
   Weeks K., 2009, GROWING MATURING EAR, V15, P22
   Weiss MW, 2012, PSYCHOL SCI, V23, P1074, DOI 10.1177/0956797612442552
   Wiggins DG, 2007, EARLY CHILD EDUC J, V35, P55, DOI 10.1007/s10643-007-0167-6
   Zatorre RJ, 2002, TRENDS COGN SCI, V6, P37, DOI 10.1016/S1364-6613(00)01816-7
NR 47
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1082-3301
EI 1573-1707
J9 EARLY CHILD EDUC J
JI Early Child. Educ. J.
PD NOV
PY 2015
VL 43
IS 6
BP 515
EP 522
DI 10.1007/s10643-014-0681-2
PG 8
WC Education & Educational Research
WE Social Science Citation Index (SSCI)
SC Education & Educational Research
GA CV1GN
UT WOS:000364001800008
DA 2024-01-09
ER

PT J
AU Erdemir, A
   Rieser, JJ
AF Erdemir, Aysu
   Rieser, John J.
TI SINGING WITHOUT HEARING: THE USE OF AUDITORY AND MOTOR INFORMATION WHEN
   SINGERS, INSTRUMENTALISTS, AND NONMUSICIANS SING A FAMILIAR TUNE
SO MUSIC PERCEPTION
LA English
DT Article
DE singing; music training; auditory feedback; kinesthetic feedback; pitch
   and timing accuracy
ID KINESTHETIC FEEDBACK; CONGENITAL AMUSIA; PITCH; EXPRESSION; INTENSITY;
   FREQUENCY; EMOTION; SPEECH; MUSIC
AB SINGING IS A UNIVERSAL FORM OF MUSIC EXPRESSION. However, the extent of skill in carrying a tune and maintaining correct timing varies across people. Differences have been reported between professional singers and non-singers; however, whether singing accuracy depends on specialized vocal training or more general types of music training has not been investigated before. In this study, singers, instrumentalists, and nonmusicians sang Happy Birthday under conditions where they could or could not hear themselves singing. The main purpose of the study was to determine the influence of vocal versus instrumental training on pitch and timing accuracy when singing with and without auditory feedback. The results for pitch and tempo showed that singers depended on auditory feedback less than non musicians and instrumentalists alike, and were better able to use kinesthetic feedback in the absence of auditory feedback. Instrumentalists have had considerable ear and instrumental practice with feedback, but this did not transfer to pitch control when singing without auditory feedback, suggesting the ability to use kinesthesia for singing is enhanced through the kinds of practice/training singers receive. Rhythmic stability across all conditions and groups suggested that rhythmic calculations do not depend on music training or on use of auditory feedback.
C1 [Erdemir, Aysu] Vanderbilt Univ, Nashville, TN 37203 USA.
C3 Vanderbilt University
RP Erdemir, A (corresponding author), Vanderbilt Univ, Dept Psychol & Human Dev, Peabody Coll 512,230 Appleton Pl, Nashville, TN 37203 USA.
EM aysu.erdemir@vanderbilt.edu
CR APPELMAN DR, 1967, SCI VOCAL PEDAGOGY T
   Ayotte J, 2002, BRAIN, V125, P238, DOI 10.1093/brain/awf028
   Bachorowski JA, 2001, J ACOUST SOC AM, V110, P1581, DOI 10.1121/1.1391244
   BACHOROWSKI JA, 1995, PSYCHOL SCI, V6, P219, DOI 10.1111/j.1467-9280.1995.tb00596.x
   Bella SD, 2007, J ACOUST SOC AM, V121, P1182, DOI 10.1121/1.2427111
   Boersma P., 2021, Glot International
   Boersma P, 1993, P I PHONETIC SCI, V17, P97, DOI DOI 10.1371/JOURNAL.PONE.0069107
   Davis C., 2006, P 3 INT C SPEECH PRO, P248
   DICARLO NS, 1994, FOLIA PHONIATR LOGO, V46, P79, DOI 10.1159/000266296
   Elliott L., 1970, INT AUDIOL, VIX, P47
   Howell D. C., 2010, Statistical methods for psychology, V7th ed
   Hutchins S, 2010, J ACOUST SOC AM, V127, P504, DOI 10.1121/1.3270391
   Jeannerod Marc, 2006, Motor Cognition
   Jones JA, 2008, EXP BRAIN RES, V190, P279, DOI 10.1007/s00221-008-1473-y
   Kent R. D., 1992, The acoustic analysis of speech
   Keough D, 2013, BMC NEUROSCI, V14, DOI 10.1186/1471-2202-14-25
   LANE H, 1991, J ACOUST SOC AM, V89, P859, DOI 10.1121/1.1894647
   LANE H, 1971, J SPEECH HEAR RES, V14, P677, DOI 10.1044/jshr.1404.677
   Larson CR, 2008, EXP BRAIN RES, V187, P613, DOI 10.1007/s00221-008-1330-z
   LEDER SB, 1987, ANN OTO RHINOL LARYN, V96, P322, DOI 10.1177/000348948709600316
   LEDER SB, 1987, J ACOUST SOC AM, V82, P843, DOI 10.1121/1.395283
   LEDER SB, 1987, LARYNGOSCOPE, V97, P224
   Martínez-Castilla P, 2008, MUSIC PERCEPT, V25, P449, DOI 10.1525/MP.2008.25.5.449
   Meier U, 2006, PHARM STAT, V5, P253, DOI 10.1002/pst.210
   Monahan C. B., 1993, PSYCHOL MUSIC UNDERS
   Murayama J, 2004, BRAIN COGNITION, V56, P36, DOI 10.1016/j.bandc.2004.05.004
   Mürbe D, 2004, J VOICE, V18, P236, DOI 10.1016/j.jvoice.2003.05.001
   Mürbe D, 2002, J VOICE, V16, P44, DOI 10.1016/S0892-1997(02)00071-1
   Nakata T, 2006, MUSIC PERCEPT, V24, P147, DOI 10.1525/mp.2006.24.2.147
   OLLER DK, 1988, CHILD DEV, V59, P441, DOI 10.1111/j.1467-8624.1988.tb01479.x
   Pfordresher PQ, 2007, MUSIC PERCEPT, V25, P95, DOI 10.1525/MP.2007.25.2.95
   Pfordresher PQ, 2010, J ACOUST SOC AM, V128, P2182, DOI 10.1121/1.3478782
   Plant G, 1984, Br J Audiol, V18, P39, DOI 10.3109/03005368409078927
   Raphael L. J., 2007, SPEECH SCI PRIMER PH
   Repp BH, 1998, J ACOUST SOC AM, V104, P1085, DOI 10.1121/1.423325
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   SCHULTZCOULON HJ, 1978, ACTA OTO-LARYNGOL, V86, P142, DOI 10.3109/00016487809124731
   SERAFINE ML, 1979, GENET PSYCHOL MONOGR, V99, P185
   Tremblay-Champoux A, 2010, COGN NEUROPSYCHOL, V27, P463, DOI 10.1080/02643294.2011.567258
   Ward W. D., 1978, J RES SINGING, V1, P24
   Watson PJ, 2006, J SPEECH LANG HEAR R, V49, P636, DOI 10.1044/1092-4388(2006/040)
   Watts C, 2003, J VOICE, V17, P185, DOI 10.1016/S0892-1997(03)00023-7
   Wise KJ, 2008, MUSIC SCI, V12, P3, DOI 10.1177/102986490801200102
   WYKE BD, 1974, FOLIA PHONIATR, V26, P295, DOI 10.1159/000263791
NR 44
TC 5
Z9 5
U1 0
U2 7
PU UNIV CALIFORNIA PRESS
PI OAKLAND
PA 155 GRAND AVE, SUITE 400, OAKLAND, CA 94612-3758 USA
SN 0730-7829
J9 MUSIC PERCEPT
JI Music Percept.
PD JUN
PY 2016
VL 33
IS 5
BP 546
EP 560
DI 10.1525/MP.2016.33.5.546
PG 15
WC Music; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music; Psychology
GA DP0NI
UT WOS:000378186100002
DA 2024-01-09
ER

PT J
AU Pan, FD
   Zhang, L
   Ou, YH
   Zhang, XN
AF Pan, Fada
   Zhang, Li
   Ou, Yuhong
   Zhang, Xinni
TI The audio-visual integration effect on music emotion: Behavioral and
   physiological evidence
SO PLOS ONE
LA English
DT Article
ID MULTISENSORY INTEGRATION; CROSSMODAL BINDING; SPEECH-PERCEPTION;
   VISUAL-ATTENTION; TIME-COURSE; RESPONSES; VOICE; BRAIN; INFORMATION;
   CONFLICT
AB Previous research has indicated that, compared to audio-only presentation, audio-visual congruent presentation can lead to a more intense emotional response. In the present study, we investigated the audio-visual integration effect on emotions elicited by positive or negative music and the role of visual information presentation durations. The participants were presented with audio-only condition, audio-visual congruent condition, and audiovisual incongruent condition and then required to judge the intensity of emotional experience elicited by the music. Their emotional responses to the music were measured using self-ratings and physiological aspects, including heart rate, skin temperature, EMG root mean square and prefrontal EEG. Relative to the audio-only presentation, the audio-visual congruent presentation led to a more intense emotional response. More importantly, the audiovisual integration occurred both in the positive music and in the negative music. Furthermore, the audio-visual integration effect was larger for positive music than for negative music; meanwhile the audio-visual integration effect was strongest with the visual information presented within 80s for negative music, which indicated that this integration effect was more likely to occur in the negative music. These results suggest that when the music was positive, the effect of audio-visual integration was greater. When the music was negative, the modulation effect of the presentation durations of visual information on the music induced emotion was more significant.
C1 [Pan, Fada; Zhang, Li; Ou, Yuhong; Zhang, Xinni] Nantong Univ, Sch Educ Sci, Nantong, Peoples R China.
C3 Nantong University
RP Pan, FD (corresponding author), Nantong Univ, Sch Educ Sci, Nantong, Peoples R China.
EM psyc_lee2015@126.com
RI zhang, yimeng/JLL-7337-2023; zhang, luyu/JJC-4227-2023; Yuan,
   Fang/JQV-7426-2023; Campailla, Jasmin/AAK-2420-2021
FU Social Sciences Foundation of Jiangsu Province, China [14SHC006];
   Program for Twelfth Five-Year Plan of Educational Science of Jiangsu
   Province, China [C-a/2013/01/003]; Postgraduate Research & Practice
   Innovation Program of Jiangsu Province [KYCX18_2389]
FX Fada Pan was supported by Grant number: 14SHC006, The Social Sciences
   Foundation of Jiangsu Province, China. http://jspopss.jschina.com.cn/;
   and Grant number: C-a/2013/01/003, The Program for Twelfth Five-Year
   Plan of Educational Science of Jiangsu Province, China.
   http://www.jssghb.cn/.Li Zhang was supported by Grant number:
   KYCX18_2389, Postgraduate Research & Practice Innovation Program of
   Jiangsu Province. http://jyt.jiangsu.gov.cn/.The funders had no role in
   study design, data collection and analysis, decision to publish, or
   preparation of the manuscript.
CR Armony JL, 2002, NEUROPSYCHOLOGIA, V40, P817, DOI 10.1016/S0028-3932(01)00178-6
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Bigand E, 2005, ANN NY ACAD SCI, V1060, P429, DOI 10.1196/annals.1360.036
   Brett-Green BA, 2008, BRAIN RES, V1242, P283, DOI 10.1016/j.brainres.2008.03.090
   Calvert GA, 2000, CURR BIOL, V10, P649, DOI 10.1016/S0960-9822(00)00513-3
   Calvert GA, 1997, SCIENCE, V276, P593, DOI 10.1126/science.276.5312.593
   Chapados C, 2008, COGNITION, V108, P639, DOI 10.1016/j.cognition.2008.05.008
   Chen MC, 2013, BRAIN INJURY, V27, P75, DOI 10.3109/02699052.2012.722255
   Chen XH, 2016, INT J PSYCHOPHYSIOL, V106, P14, DOI 10.1016/j.ijpsycho.2016.05.009
   Conrey B, 2006, J ACOUST SOC AM, V119, P4065, DOI 10.1121/1.2195091
   de Gelder B, 2000, COGNITION EMOTION, V14, P289, DOI 10.1080/026999300378824
   Dolan RJ, 2001, P NATL ACAD SCI USA, V98, P10006, DOI 10.1073/pnas.171288598
   Driver J, 2008, NEURON, V57, P11, DOI 10.1016/j.neuron.2007.12.013
   Ethofer T, 2006, HUM BRAIN MAPP, V27, P707, DOI 10.1002/hbm.20212
   Etkin A, 2006, NEURON, V51, P871, DOI 10.1016/j.neuron.2006.07.029
   Eysenck MW, 2007, EMOTION, V7, P336, DOI 10.1037/1528-3542.7.2.336
   Frassinetti F, 2002, EXP BRAIN RES, V147, P332, DOI 10.1007/s00221-002-1262-y
   Gao YL, 2014, NEUROREPORT, V25, P668, DOI 10.1097/WNR.0000000000000155
   [龚栩 Gong Xu], 2011, [中国心理卫生杂志, Chinese Mental Health Journal], V25, P40
   HERSHENSON M, 1962, J EXP PSYCHOL, V63, P289, DOI 10.1037/h0039516
   Jeong JW, 2011, NEUROIMAGE, V54, P2973, DOI 10.1016/j.neuroimage.2010.11.017
   Jessen S, 2011, NEUROIMAGE, V58, P665, DOI 10.1016/j.neuroimage.2011.06.035
   Kreifelts B, 2007, NEUROIMAGE, V37, P1445, DOI 10.1016/j.neuroimage.2007.06.020
   Marin MM, 2012, EMOTION, V12, P618, DOI 10.1037/a0025020
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MEREDITH MA, 1986, BRAIN RES, V365, P350
   Park JY, 2010, CORTEX, V46, P161, DOI 10.1016/j.cortex.2008.06.008
   Paulmann S, 2009, J PSYCHOPHYSIOL, V23, P63, DOI 10.1027/0269-8803.23.2.63
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   Platz F, 2012, MUSIC PERCEPT, V30, P71, DOI 10.1525/MP.2012.30.1.71
   Pourtois G, 2000, NEUROREPORT, V11, P1329, DOI 10.1097/00001756-200004270-00036
   Pourtois G, 2005, CORTEX, V41, P49, DOI 10.1016/S0010-9452(08)70177-1
   Santangelo V, 2010, NEUROIMAGE, V49, P2717, DOI 10.1016/j.neuroimage.2009.10.061
   Senkowski D, 2005, EXP BRAIN RES, V166, P411, DOI 10.1007/s00221-005-2381-z
   Stevenson RA, 2010, NEUROIMAGE, V49, P3308, DOI 10.1016/j.neuroimage.2009.12.001
   Szycik GR, 2008, BRAIN RES, V1220, P142, DOI 10.1016/j.brainres.2007.08.027
   Talsma D, 2007, CEREB CORTEX, V17, P679, DOI 10.1093/cercor/bhk016
   Tang XY, 2016, NEUROSCI BIOBEHAV R, V61, P208, DOI 10.1016/j.neubiorev.2015.11.002
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
   Vines BW, 2011, COGNITION, V118, P157, DOI 10.1016/j.cognition.2010.11.010
   Vuoskoski J. K., 2016, Psychomusicology: Music, mind, and brain, V26, P179, DOI [10.1037/pmu0000142, DOI 10.1037/PMU0000142]
   Vuoskoski JK, 2014, ATTEN PERCEPT PSYCHO, V76, P591, DOI 10.3758/s13414-013-0582-2
   Watson R, 2014, J NEUROSCI, V34, P6813, DOI 10.1523/JNEUROSCI.4478-13.2014
   Weijkamp J, 2017, PSYCHOL MUSIC, V45, P204, DOI 10.1177/0305735616654216
   Werner S, 2010, J NEUROSCI, V30, P2662, DOI 10.1523/JNEUROSCI.5091-09.2010
   Yu HT, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, P1965, DOI 10.1109/ICMA.2016.7558867
   Zimmer U, 2010, NEUROIMAGE, V52, P606, DOI 10.1016/j.neuroimage.2010.04.245
NR 47
TC 19
Z9 20
U1 7
U2 52
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD MAY 30
PY 2019
VL 14
IS 5
AR e0217040
DI 10.1371/journal.pone.0217040
PG 21
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Science & Technology - Other Topics
GA IA2XG
UT WOS:000469425500009
PM 31145745
OA gold, Green Published, Green Submitted
DA 2024-01-09
ER

PT J
AU Küster, M
AF Kuester, Martin
TI Should the End of a Phrase be Emphasized? An Essay in Musical Prosody
SO JOURNAL OF MUSICOLOGICAL RESEARCH
LA English
DT Article
AB For understanding eighteenth-century notions of "singing" on an instrument, modern standards of "classical" performance can be a source of confusion rather than clarification. Rather than simply calling for legato or vibrato, such notions tapped into a pool of ideas concerned with essential commonalities between music and language. Song, as understood in the eighteenth century, is the anthropological origin of music and language, a primitive vocal expression of emotion carried into verbal speech through its musical properties (prosody) and understood as working similarly in musical melody. At the same time, a trove of terms used in music theory-such as "rhythm," "meter," "accent," or "phrase"-is concerned not with language (as is often claimed), but with the same intersection of music and speech, a gray area between these realms. It is in this field that the eighteenth-century theory of text setting operates. It can be said that, from an eighteenth-century perspective, every piece of instrumental music is a "Song without Words," having all the music-prosodic features-accents, lines, phrases, even rhymes-with which the vocal composer would respond to a specific text. Such a perspective can illuminate and perhaps answer some questions that performers (especially historically informed performers) often struggle with and are forced to answer with theories indebted to more recent traditions, such as those associated with Schenker and Riemann.
C1 [Kuester, Martin] Humboldt Univ, Berlin, Germany.
C3 Humboldt University of Berlin
RP Küster, M (corresponding author), Humboldt Univ, Berlin, Germany.
CR [Anonymous], 1903, SYSTEM MUSIKALISCHEN
   Cone E., 1968, MUSICAL FORM MUSICAL
   Haynes Bruce., 2007, The End of Early Music
   Lester J., 1986, RHYTHMS TONAL MUSIC
   Marpurg Friedrich Wilhelm, 1763, KRITISCHE BRIEFE TON, V2, P279
   Mattheson Johann., 1737, KERN MELODISCHER WIS
   Mattheson Johann, 1739, VOLLKOMMENE CAPELLME
   Rothstein W. N., 1989, Phrase Rhythm in Tonal Music
   Scheibe Johann Adolph, 1754, ABHANDLUNG URSPRUNGE, P84
   Weber Gottfried, 1824, VERSUCH GEORDNETEN T, V1, P101
NR 10
TC 0
Z9 0
U1 0
U2 3
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0141-1896
EI 1547-7304
J9 J MUSICOL RES
JI J. Musicol. Res.
PD JUL 2
PY 2020
VL 39
IS 2-3
SI SI
BP 122
EP 133
DI 10.1080/01411896.2020.1773265
EA JUL 2020
PG 12
WC Music
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music
GA OA2EM
UT WOS:000547012900001
DA 2024-01-09
ER

PT J
AU Aubé, W
   Angulo-Perkins, A
   Peretz, I
   Concha, L
   Armony, JL
AF Aube, William
   Angulo-Perkins, Arafat
   Peretz, Isabelle
   Concha, Luis
   Armony, Jorge L.
TI Fear across the senses: brain responses to music, vocalizations and
   facial expressions
SO SOCIAL COGNITIVE AND AFFECTIVE NEUROSCIENCE
LA English
DT Article
DE amygdala; hippocampus; fear; emotional expressions; music; vocalizations
ID EMOTIONAL RESPONSES; NEURAL RESPONSES; HUMAN AMYGDALA; IMPAIRED
   RECOGNITION; AUDITORY-CORTEX; FUNCTIONAL MRI; TEMPORAL-LOBE; MEMORY;
   VOICE; CONNECTIVITY
AB Intrinsic emotional expressions such as those communicated by faces and vocalizations have been shown to engage specific brain regions, such as the amygdala. Although music constitutes another powerful means to express emotions, the neural substrates involved in its processing remain poorly understood. In particular, it is unknown whether brain regions typically associated with processing 'biologically relevant' emotional expressions are also recruited by emotional music. To address this question, we conducted an event-related functional magnetic resonance imaging study in 47 healthy volunteers in which we directly compared responses to basic emotions (fear, sadness and happiness, as well as neutral) expressed through faces, non-linguistic vocalizations and short novel musical excerpts. Our results confirmed the importance of fear in emotional communication, as revealed by significant blood oxygen level-dependent signal increased in a cluster within the posterior amygdala and anterior hippocampus, as well as in the posterior insula across all three domains. Moreover, subject-specific amygdala responses to fearful music and vocalizations were correlated, consistent with the proposal that the brain circuitry involved in the processing of musical emotions might be shared with the one that have evolved for vocalizations. Overall, our results show that processing of fear expressed through music, engages some of the same brain areas known to be crucial for detecting and evaluating threat-related information.
C1 [Aube, William; Peretz, Isabelle; Concha, Luis; Armony, Jorge L.] Int Lab Brain Mus & Sound Res BRAMS, Montreal, PQ H2V 4P3, Canada.
   [Aube, William; Peretz, Isabelle; Armony, Jorge L.] CRBLM, Montreal, PQ H3G 2A8, Canada.
   [Aube, William; Peretz, Isabelle] Univ Montreal, Dept Psychol, Montreal, PQ H2V 2S9, Canada.
   [Angulo-Perkins, Arafat; Concha, Luis] Univ Nacl Autonoma Mexico, Queretaro 76230, Mexico.
   [Armony, Jorge L.] McGill Univ, Dept Psychiat, Montreal, PQ H4H 1R3, Canada.
   [Armony, Jorge L.] McGill Univ, Douglas Mental Hlth Univ Inst, Montreal, PQ H4H 1R3, Canada.
C3 Universite de Montreal; Universite de Montreal; Universidad Nacional
   Autonoma de Mexico; McGill University; McGill University
RP Aubé, W (corresponding author), Univ Montreal, BRAMS, Pavillon 1420,Blvd Mt Royal,CP 6128 Succ Ctr, Montreal, PQ H3C 3J7, Canada.
EM william.aube@umontreal.ca
RI Concha, Luis/M-5720-2019
OI Concha, Luis/0000-0002-7842-3869; Angulo, Alejandra
   Arafat/0000-0001-5635-7509
FU National Science and Engineering Research Council of Canada (NSERC);
   Canadian Institutes of Health Research (CIHR); Consejo Nacional de
   Ciencia y Tecnologia de Mexico (CONACyT); Universidad Nacional Autonoma
   de Mexico (UNAM); NSERC; CONACyT-UNAM
FX This work was partly funded by grants from the National Science and
   Engineering Research Council of Canada (NSERC) and the Canadian
   Institutes of Health Research (CIHR) to J.L.A., and from Consejo
   Nacional de Ciencia y Tecnologia de Mexico (CONACyT) and Universidad
   Nacional Autonoma de Mexico (UNAM) to L.C. We are grateful to Daniel
   Ramirez Pena, Juan Ortiz-Retana, Erick Pasaye and Leopoldo
   Gonzalez-Santos for technical assistance during data acquisition. We
   also thank the authorities of the Music Conservatory 'Jose Guadalupe
   Velazquez', the Queretaro Philharmonic Orchestra, the Queretaro School
   of Violin Making and the Querentaro Fine Arts Institute, for their help
   with the recruitment of musicians. W.A. and A.A.P. were supported by
   scholarships from NSERC and CONACyT-UNAM, respectively.
CR ADOLPHS R, 1995, J NEUROSCI, V15, P5879
   ADOLPHS R, 1994, NATURE, V372, P669, DOI 10.1038/372669a0
   Adolphs R, 2008, CURR OPIN NEUROBIOL, V18, P166, DOI 10.1016/j.conb.2008.06.006
   AMARAL D G, 1992, P1
   [Anonymous], 1997, TALKER VARIABILITY S
   Armony J.L., 2010, OXFORD HDB AUDITORY, P479, DOI DOI 10.1093/OXFORDHB/9780199233281.013.0019
   Armony J.L., 2013, CAMBRIDGE HDB HUMAN, P154
   Armony JL, 2007, PSYCHOL SCI, V18, P1027, DOI 10.1111/j.1467-9280.2007.02019.x
   Armony JL, 2013, EMOT REV, V5, P104, DOI 10.1177/1754073912457208
   Aubé W, 2013, MEMORY, V21, P981, DOI 10.1080/09658211.2013.770871
   Barr R. G., 2000, CRYING SIGN SYMPTOM
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Belin P, 2008, P ROY SOC B-BIOL SCI, V275, P473, DOI 10.1098/rspb.2007.1460
   BERLYNE DE, 1970, PERCEPT PSYCHOPHYS, V8, P279, DOI 10.3758/BF03212593
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Blair RJR, 1999, BRAIN, V122, P883, DOI 10.1093/brain/122.5.883
   Blood AJ, 1999, NAT NEUROSCI, V2, P382, DOI 10.1038/7299
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Boersma P., 2014, PRAAT DOING PHONETIC
   Breiter HC, 1996, NEURON, V17, P875, DOI 10.1016/S0896-6273(00)80219-6
   Brown S, 2004, NEUROREPORT, V15, P2033, DOI 10.1097/00001756-200409150-00008
   Critchley HD, 2002, NEURON, V33, P653, DOI 10.1016/S0896-6273(02)00588-3
   Darwin C., 1872, P374
   de Gelder B, 2006, NAT REV NEUROSCI, V7, P242, DOI 10.1038/nrn1872
   de Gelder B, 2004, P NATL ACAD SCI USA, V101, P16701, DOI 10.1073/pnas.0407042101
   Dehaene S, 2007, NEURON, V56, P384, DOI 10.1016/j.neuron.2007.10.004
   Escoffier N, 2013, HUM BRAIN MAPP, V34, P1796, DOI 10.1002/hbm.22029
   Ethofer T, 2009, J COGNITIVE NEUROSCI, V21, P1255, DOI 10.1162/jocn.2009.21099
   Fecteau S, 2005, APPL NEUROPSYCHOL, V12, P40, DOI 10.1207/s15324826an1201_7
   Fecteau S, 2004, NEUROIMAGE, V23, P840, DOI 10.1016/j.neuroimage.2004.09.019
   Fecteau S, 2007, NEUROIMAGE, V36, P480, DOI 10.1016/j.neuroimage.2007.02.043
   Flores-Gutiérrez EO, 2007, INT J PSYCHOPHYSIOL, V65, P69, DOI 10.1016/j.ijpsycho.2007.03.004
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Fusar-Poli P, 2009, J PSYCHIATR NEUROSCI, V34, P418
   Glasberg BR, 2002, J AUDIO ENG SOC, V50, P331
   Gosselin N, 2005, BRAIN, V128, P628, DOI 10.1093/brain/awh420
   Gosselin N, 2007, NEUROPSYCHOLOGIA, V45, P236, DOI 10.1016/j.neuropsychologia.2006.07.012
   Green AC, 2008, NEUROREPORT, V19, P711, DOI 10.1097/WNR.0b013e3282fd0dd8
   Grèzes J, 2007, NEUROIMAGE, V35, P959, DOI 10.1016/j.neuroimage.2006.11.030
   Grèzes J, 2013, CORTEX, V49, P2210, DOI 10.1016/j.cortex.2012.08.025
   Grossmann T, 2010, RESTOR NEUROL NEUROS, V28, P219, DOI 10.3233/RNN-2010-0499
   Hadjikhani N, 2003, CURR BIOL, V13, P2201, DOI 10.1016/S0960-9822(03)00891-1
   IZARD CE, 1994, PSYCHOL BULL, V115, P288, DOI 10.1037/0033-2909.115.2.288
   Jensen J, 2003, NEURON, V40, P1251, DOI 10.1016/S0896-6273(03)00724-4
   Josephs O, 1997, HUM BRAIN MAPP, V5, P243, DOI 10.1002/(SICI)1097-0193(1997)5:4<243::AID-HBM7>3.0.CO;2-3
   Juslin P. N., 2011, HDB MUSIC EMOTION TH
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00596
   Kanwisher N, 1997, J NEUROSCI, V17, P4302
   Khalfa S, 2008, INT J PSYCHOPHYSIOL, V68, P17, DOI 10.1016/j.ijpsycho.2007.12.001
   Koelsch S, 2006, HUM BRAIN MAPP, V27, P239, DOI 10.1002/hbm.20180
   Koelsch S, 2005, NEUROIMAGE, V25, P1068, DOI 10.1016/j.neuroimage.2004.12.050
   Koelsch S., 2014, HUMAN BRAIN MAPPING
   Koelsch S, 2014, NAT REV NEUROSCI, V15, P170, DOI 10.1038/nrn3666
   Koelsch S, 2013, NEUROIMAGE, V81, P49, DOI 10.1016/j.neuroimage.2013.05.008
   Koelsch S, 2010, TRENDS COGN SCI, V14, P131, DOI 10.1016/j.tics.2010.01.002
   Koelsch Stefan., 2013, The Cambridge Handbook of Human Affective Neuroscience, P286, DOI [10.1017/CBO9780511843716.016, DOI 10.1017/CBO9780511843716.016]
   Lartillot O, 2008, ST CLASS DAT ANAL, P261, DOI 10.1007/978-3-540-78246-9_31
   LeDoux J, 2012, NEURON, V73, P653, DOI 10.1016/j.neuron.2012.02.004
   Lehne M., 2014, SOCIAL COGNITIVE AFF
   Lima CF, 2013, BEHAV RES METHODS, V45, P1234, DOI 10.3758/s13428-013-0324-3
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Maess B, 2001, NAT NEUROSCI, V4, P540, DOI 10.1038/87502
   Marozeau J, 2003, J ACOUST SOC AM, V114, P2946, DOI 10.1121/1.1618239
   Mattavelli G., 2014, SOCIAL COGNITIVE AFF
   Menon V, 2005, NEUROIMAGE, V28, P175, DOI 10.1016/j.neuroimage.2005.05.053
   Mitterschiffthaler MT, 2007, HUM BRAIN MAPP, V28, P1150, DOI 10.1002/hbm.20337
   Mohr C, 2005, PAIN, V114, P347, DOI 10.1016/j.pain.2004.12.036
   Mohr C, 2012, EUR J PAIN, V16, P496, DOI 10.1016/j.ejpain.2011.07.010
   Morris JS, 1999, NEUROPSYCHOLOGIA, V37, P1155, DOI 10.1016/S0028-3932(99)00015-9
   Peelen MV, 2007, SOC COGN AFFECT NEUR, V2, P274, DOI 10.1093/scan/nsm023
   Peretz I., 2013, EVOLUTION EMOTIONAL, P277
   Peretz I, 2006, COGNITION, V100, P1, DOI 10.1016/j.cognition.2005.11.004
   Phillips ML, 1998, P ROY SOC B-BIOL SCI, V265, P1809, DOI 10.1098/rspb.1998.0506
   Puschmann S, 2010, NEUROIMAGE, V49, P1641, DOI 10.1016/j.neuroimage.2009.09.045
   Salimpoor VN, 2011, NAT NEUROSCI, V14, P257, DOI 10.1038/nn.2726
   Sander D, 2003, REV NEUROSCIENCE, V14, P303, DOI 10.1515/REVNEURO.2003.14.4.303
   Sauter DA, 2010, P NATL ACAD SCI USA, V107, P2408, DOI 10.1073/pnas.0908239106
   Schirmer A, 2012, NEUROIMAGE, V63, P137, DOI 10.1016/j.neuroimage.2012.06.025
   Sergerie K, 2008, NEUROSCI BIOBEHAV R, V32, P811, DOI 10.1016/j.neubiorev.2007.12.002
   Sergerie K, 2007, BIOL PSYCHIAT, V62, P1126, DOI 10.1016/j.biopsych.2006.12.024
   Sergerie K, 2006, J COGNITIVE NEUROSCI, V18, P1359, DOI 10.1162/jocn.2006.18.8.1359
   Singer T, 2009, TRENDS COGN SCI, V13, P334, DOI 10.1016/j.tics.2009.05.001
   Slevc LR, 2009, PSYCHON B REV, V16, P374, DOI 10.3758/16.2.374
   Slotnick SD, 2003, COGNITIVE BRAIN RES, V17, P75, DOI 10.1016/S0926-6410(03)00082-X
   Steinbeis N, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0002226
   Steinbeis N, 2006, J COGNITIVE NEUROSCI, V18, P1380, DOI 10.1162/jocn.2006.18.8.1380
   Steiner J E, 1979, Adv Child Dev Behav, V13, P257, DOI 10.1016/S0065-2407(08)60349-3
   Strait DL, 2010, HEARING RES, V261, P22, DOI 10.1016/j.heares.2009.12.021
   Swanson LW, 1998, TRENDS NEUROSCI, V21, P323, DOI 10.1016/S0166-2236(98)01265-X
   Trost W, 2012, CEREB CORTEX, V22, P2769, DOI 10.1093/cercor/bhr353
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   Vuilleumier P, 2005, TRENDS COGN SCI, V9, P585, DOI 10.1016/j.tics.2005.10.011
   Vuilleumier P, 2007, NEUROPSYCHOLOGIA, V45, P174, DOI 10.1016/j.neuropsychologia.2006.06.003
   Whalen PJ, 2001, EMOTION, V1, P70, DOI 10.1037/1528-3542.1.1.70
   Worsley KJ, 2004, NEUROIMAGE, V23, pS189, DOI 10.1016/j.neuroimage.2004.07.026
   Yang TT, 2002, NEUROREPORT, V13, P1737, DOI 10.1097/00001756-200210070-00009
   Young M P, 1994, Rev Neurosci, V5, P227
NR 98
TC 49
Z9 57
U1 2
U2 51
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 1749-5016
EI 1749-5024
J9 SOC COGN AFFECT NEUR
JI Soc. Cogn. Affect. Neurosci.
PD MAR
PY 2015
VL 10
IS 3
BP 399
EP 407
DI 10.1093/scan/nsu067
PG 9
WC Neurosciences; Psychology; Psychology, Experimental
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Neurosciences & Neurology; Psychology
GA CE0VI
UT WOS:000351526400012
PM 24795437
OA hybrid, Green Submitted, Green Published
DA 2024-01-09
ER

PT J
AU Tripathy, M
   Chaudhari, M
AF Tripathy, Manaswini
   Chaudhari, Mithunchandra
TI The impact of rock music on Indian young adults: a qualitative study on
   emotions and moods
SO CARDIOMETRY
LA English
DT Article
DE Music; Moods; Emotions; Positive effects; Rock; Mood-booster;
   Motivation; Anger-management
ID RESPONSES
AB Music has proven to play a vital role in social and emotional development in teenagers and young adults. From contemplation, developing self-identity, understanding interpersonal relationships, and providing possibilities of experience mastery, agency, and self-control with the help of self-directed activities, music helps its audience develop in all aspects of life. In specific, Rock music, since its existence has been more than entertainment, artists expressed themselves and shared their opinions through their musical pieces. Infamous for promoting drugs and alcohol, Rock Music used its platform to enlighten the audience about taboo topics like racism, inequality and other social issues. This research paper uses a qualitative methodology approach to understand Rock Music listeners' points of view. Data was collected through 'in-depth interviews' of 15 participants hailing from different parts of the country. Rock Music has several positive effects on the listeners. Rock can elevate moods, induce emotions, helps the listeners be more productive and creative with their everyday work, and constantly motivate them to do better in every aspect of life. Rock provides a platform to express feelings and vent out all the angst, especially for those who otherwise do not voice their opinions because of their nature in general. Rock Music has been able to shape personalities, characteristics, and thought processes. Moreover, majorly, Rock Music helps people with anger management.
C1 [Tripathy, Manaswini; Chaudhari, Mithunchandra] Symbiosis Int Deemed Univ, Symbiosis Inst Media & Commun, Pune, Maharashtra, India.
C3 Symbiosis International University; Symbiosis Institute of Media &
   Communication (SIMC)
RP Chaudhari, M (corresponding author), Symbiosis Int Deemed Univ, Symbiosis Inst Media & Commun, Pune, Maharashtra, India.
EM mithunchandra.chaudhari@simc.edu
RI Chaudhari, Mithunchandra/HLX-6990-2023
OI Chaudhari, Mithunchandra/0000-0003-1833-3607
CR [Anonymous], 2008, PERSPECTIVE THEORY M
   ARNETT JJ, 1995, J YOUTH ADOLESCENCE, V24, P519, DOI 10.1007/BF01537054
   Azzam F., 2007, MERI NEWS
   Behne K, 1997, DEV MUSICERLEBEN ADO
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Bound C, 2017, HERE IS DIFFERENT MU
   Bowling DL, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0031942
   Chamorro-Premuzic T, 2011, PSYCHOL TODAY
   Dingle LS, 2015, FRONT HUM NEUROSCI
   Egermann H., 2014, EMOTIONAL RESPONSES
   Encyclopedia.com, 2020, MUS ANTHR
   FUNK C, ROCK ROLL YOUTH CULT
   GRACYK TA, 1993, J AESTHET EDUC, V27, P43, DOI 10.2307/3333411
   Grewe O, 2011, PSYCHOL MUSIC, V39, P220, DOI 10.1177/0305735610362950
   Hammarberg K, 2016, HUM REPROD, V31, P498, DOI 10.1093/humrep/dev334
   Hatfield E., 1993, Emotional Contagion
   HowStuffWorks, 2016, YOUR PERS SHAP YOUR
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Laiho S., 2004, NORD J MUSIC THER, V13, P47, DOI DOI 10.1080/08098130409478097
   Lamb B., 2020, HYPODERMIC NEEDLE TH
   Liljeström S, 2013, PSYCHOL MUSIC, V41, P579, DOI 10.1177/0305735612440615
   Mission, 2019, EV ROCK
   Mulligan TP, 2009, RELATIONSHIP MUSIC P
   NoiseyStaff, 2015, SURV SAYS MET LEAST
   Oliver, 1997, DISSERT ABSTR
   Parkinson B., 1996, Changing moods: The psychology of mood and mood regulation
   Pelayo JM, 2013, INFLUENCE ROCK MUSIC
   Rentfrow PJ, 2003, J PERS SOC PSYCHOL, V84, P1236, DOI 10.1037/0022-3514.84.6.1236
   Russo NN., 2013, EXPLORING COGNITIVIS
   Schellenberg EG, 2008, BEHAV BRAIN SCI, V31, P594, DOI 10.1017/S0140525X08005499
   Schellenberg EG, 2015, CURRENT EMOTION RES
   SCHREIBER EH, 1988, PERCEPT MOTOR SKILL, V66, P338, DOI 10.2466/pms.1988.66.1.338
   Schwartz KD, 2003, J YOUTH ADOLESCENCE, V32, P205, DOI 10.1023/A:1022547520656
   Shukla A, 2019, SOCIAL PSYCHOL HEAVY
   Slides.com, EFF ROCK MUS YOUTH A
   Sloboda J. A., 2001, Musicae Scientiae, V5, P9, DOI DOI 10.1177/102986490100500102
   Stalhammar B., 2004, MUSIC THEIR LIVES EX
   Swaminathan S., 2015, CURRENT EMOTION RES
   Tagg Philip Kojak, 1979, 50 Seconds of Television Music: Toward the Analysis of Affect in Popular Music..
   TellTaleWeekly, 2020, TELLTALEWEEKLY
   The Hamilton Spectator, 2016, ROCK ROLL PRES FUT
   Trivedi S., 2003, IMAGINATION PHILOS A, P259
   Vinney C., 2019, WHAT IS USES GRATIFI
   Walworth DD, 2003, J MUSIC THER, V40, P2, DOI 10.1093/jmt/40.1.2
   WELLS A, 1991, JOURNALISM QUART, V68, P445, DOI 10.1177/107769909106800315
NR 45
TC 0
Z9 0
U1 8
U2 22
PU RUSSIAN NEW UNIV
PI MOSCOW
PA UL RADIO, 22, MOSCOW, 105005, RUSSIA
SN 2304-7232
J9 CARDIOMETRY
JI Cardiometry
PD NOV
PY 2021
IS 20
BP 110
EP 118
DI 10.18137/cardiometry.2021.20.110118
PG 9
WC Medical Laboratory Technology
WE Emerging Sources Citation Index (ESCI)
SC Medical Laboratory Technology
GA YP1GR
UT WOS:000748377200014
DA 2024-01-09
ER

PT J
AU Jacobs, R
AF Jacobs, Rachael
TI Affective and emotional experiences in arts-based service-learning
   environments
SO INTERNATIONAL JOURNAL OF EMOTIONAL EDUCATION
LA English
DT Article
DE Keywords; affect; emotion; arts education; education; creativity
ID TEACHER-EDUCATION; EFFICACY
AB Dewey (1938) once wrote that the most effective forms of learning connect intellectual processes with emotion, which is able to inspire curiosity and excite the learner. This paper adds to the body of research that attests to the transformative role of affect in teacher education, which is able to be cultivated through arts-based service-learning experiences. Pre-service teachers at two universities in Sydney, Australia were placed in service-learning settings that were based around participatory experiences in drama and storytelling, music, dance or visual art. The pre-service teachers' reflections on the placement revealed a transformative experience which combined emotional learning with critical analysis of social justice issues as they relate to education. As part of their placement, they experienced arts engagement that utilised affect and emotion as a transformative pedagogy. They broadened their understanding of the role of teachers, both in an institution and in society. These emerging understandings led them to find voice as advocates, investigate arts education and community projects as alternative career paths and re-evaluate their own perceptions of quality teaching. Some participants continued engaging with the community arts projects after the placement had concluded, and others became advocates for the arts in education and society. Finally, they adopted a critical stance on social justice issues, and shed light on the ways that arts learning service-learning placements can become deeper engagements, leading to sustainable benefits for all parties.
C1 [Jacobs, Rachael] Western Sydney Univ, Sydney, Australia.
C3 Western Sydney University
RP Jacobs, R (corresponding author), Western Sydney Univ, Sydney, Australia.
EM r.jacobs@westernsydney.edu.au
CR [Anonymous], New Directions for Adult and Continuing Education, DOI DOI 10.1002/ACE.317
   [Anonymous], 2013, MENTAL HLTH PRACTICE, DOI [DOI 10.7748/MHP2013.05.16.8.36.E855, DOI 10.7748/mhp2013.05.16.8.36.e855]
   Anttila H, 2016, SOC PSYCHOL EDUC, V19, P451, DOI 10.1007/s11218-016-9335-0
   Bakar A.R., 2014, International Education Studies, V7, P155
   BANDURA A, 1977, PSYCHOL REV, V84, P191, DOI 10.1037/0033-295X.84.2.191
   Beard C., 2018, NEW DIRECTIONS ADULT, V2018, P27, DOI [10.1002/ace.20276, DOI 10.1002/ACE.20276]
   Beltman S, 2015, ISS EDUC RES, V25, P225
   Bickford D., 2002, Pedagogy: Critical Approaches to Teaching, Literature, Language, Composition and Culture, V2, P229
   Boggs GL, 2013, ADV SERV LEARN RES, P31
   Boler M., 1999, FEELING POWER
   Chong S, 2009, EDUC RES POLICY PRAC, V8, P59, DOI 10.1007/s10671-008-9056-z
   Daniels H, 2016, ROUTL EDUC CLASS ED, P1
   Day C, 2001, TEACH TEACH EDUC, V17, P403, DOI 10.1016/S0742-051X(01)00003-8
   Dewey J., 1938, Experience and Education
   Eyler J., 1999, Where's the Learning in Service -Learning?
   Furco, 1996, EXPANDING BOUNDARIES, P2
   Heckel C, 2019, J COMPUT ASSIST LEAR, V35, P667, DOI 10.1111/jcal.12367
   Hixon E, 2009, EDUC TECHNOL SOC, V12, P294
   Hoigaard R, 2012, EUR J TEACH EDUC, V35, P347, DOI 10.1080/02619768.2011.633993
   Iyer R, 2018, ASIA-PAC J TEACH EDU, V46, P133, DOI 10.1080/1359866X.2016.1210083
   Jacobs R., 2022, J PEDAGOGY, V13, P29, DOI [10.2478/jped-2022-0007, DOI 10.2478/JPED-2022-0007]
   Jones N, 2012, TEACH COLL REC, V114
   Kaschak J. C., 2015, CLEARING HOUSE J ED, V88, P150, DOI DOI 10.1080/00098655.2015.1059310
   Korthagen FAJ, 2010, TEACH TEACH EDUC, V26, P98, DOI 10.1016/j.tate.2009.05.001
   Lawton MP, 1996, J GERONTOL B-PSYCHOL, V51, pP3, DOI 10.1093/geronb/51B.1.P3
   Linnenbrink-Garcia L., 2016, Policy Insights from the Behavioral and Brain Sciences, V3, P228, DOI [DOI 10.1177/2372732216644450, https://doi.org/10.1177/2372732216644450]
   Martins M, 2015, EUR J TEACH EDUC, V38, P263, DOI 10.1080/02619768.2014.968705
   Nadan Y, 2017, BRIT J SOC WORK, V47, P683, DOI 10.1093/bjsw/bcw023
   NESA (the NSW Education Standards Authority), 2017, PROF EXP IN TEACH ED
   Nicholson Helen, 2015, APPL DRAMA GIFT THEA
   Noddings N., 1996, CAMB J EDUC, V26, P435, DOI [10.1080/0305764960260311, DOI 10.1080/0305764960260311]
   Noddings Nel, 2011, DEMOCRACY ED, V19, P1
   Raphael J. A., 2013, THESIS U MELBOURNE
   Saldana J., 2021, The coding manual for qualitative researchers, V2nd ed.
   Sandaran SC, 2012, PROCD SOC BEHV, V66, P380, DOI 10.1016/j.sbspro.2012.11.281
   Shapiro S, 2010, TEACH TEACH EDUC, V26, P616, DOI 10.1016/j.tate.2009.09.009
   Skinner N, 2010, TEACH DEV, V14, P279, DOI 10.1080/13664530.2010.504007
   Stark K, 2022, TEACH EXCEPT CHILD, DOI 10.1177/00400599221081039
   Stavrou S, 2021, PEDAGOG CULT SOC, V29, P99, DOI 10.1080/14681366.2019.1692058
   Stoeber J, 2008, ANXIETY STRESS COPIN, V21, P37, DOI 10.1080/10615800701742461
   Sutton RE, 2003, EDUC PSYCHOL REV, V15, P327, DOI 10.1023/A:1026131715856
   Sweeny R, 2008, EDUCATING ARTISTS FOR THE FUTURE: LEARNING AT THE INTERSECTIONS OF ART, SCIENCE, TECHNOLOGY AND CULTURE, P85
   Swick K., 2001, The Clearing House, V74, P261, DOI [10.1080/00098650109599204, DOI 10.1080/00098650109599204]
   Teng MF, 2017, AUST J TEACH EDUC, V42, P117
   Terrance T. C., 2018, CULTURALLY ENGAGING, P1, DOI DOI 10.4018/978-1-5225-2900-2.CH001
   Thompson J, 2009, PERFORMANCE AFFECTS: APPLIED THEATRE AND THE END OF EFFECT, P1, DOI 10.1057/9780230242425
   Tinkler AS, 2016, MULTICULT PERSPECT, V18, P192, DOI 10.1080/15210960.2016.1222282
   Tyng CM, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01454
   Vygotsky L. S., 1978, MIND SOC DEV HIGHER, DOI [10.2307/j.ctvjf9vz4, DOI 10.2307/J.CTVJF9VZ4]
   Warren-Gordon K., 2018, CHANGE MAGAZINE HIGH, V50, P20, DOI [DOI 10.1080/00091383.2018, 10.1080/00091383.2018.1540817, DOI 10.1080/00091383.2018.1540817]
   Wasserman KB, 2009, TEACH TEACH EDUC, V25, P1043, DOI 10.1016/j.tate.2009.04.001
   Western Sydney University, 2020, GREAT W SYDN
   Wittmann S, 2011, TEACH TEACH EDUC, V27, P524, DOI 10.1016/j.tate.2010.10.006
NR 53
TC 0
Z9 0
U1 1
U2 1
PU CENTRE RESILIENCE & SOCIO-EMOTIONAL HEALTH
PI MSIDA
PA RM 241 OLD HUMANITIES BUILDING UNIV MALTA, MSIDA, MSD 2080, MALTA
SN 2073-7629
J9 INT J EMOT EDUC
JI Int. J. Emot. Educ.
PD APR
PY 2023
VL 15
IS 1
BP 4
EP 20
DI 10.56300/UANJ1022
PG 17
WC Psychology, Educational
WE Emerging Sources Citation Index (ESCI)
SC Psychology
GA H4RA7
UT WOS:000995840400001
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Cook, KM
AF Cook, Karen M.
TI Medievalism and emotions in video game music
SO POSTMEDIEVAL-A JOURNAL OF MEDIEVAL CULTURAL STUDIES
LA English
DT Article
AB Unlike film, the study of medievalist music within video games remains a nascent field, with recent contributions being made by scholars such as James Cook. To paraphrase Helen Deeming, this article examines what the employment of medieval(ist) music within video games reveals about contemporary notions of the medieval, and what emotional connotations are embedded within such musical choices. I analyze the use of three ubiquitous medievalist musical tropes - the Gothic organ, the church bell, and the wordless voice - to create a set of 'opposite' emotional states: a sense of peace, tranquility, or sanctuary on the one hand, and danger, violence, the supernatural, and death on the other, connecting these emotional and musical stereotypes to those of the medieval era itself.
C1 [Cook, Karen M.] Univ Hartford, Hartt Sch, Mus Hist, Hartford, CT 06117 USA.
C3 University of Hartford
RP Cook, KM (corresponding author), Univ Hartford, Hartt Sch, Mus Hist, Hartford, CT 06117 USA.
EM KACOOK@hartford.edu
OI Cook, Karen/0000-0002-5899-3434
CR Adachi M., 1991, SUPER CASTLEVANIA 4
   [Anonymous], 2014, MUSIC FILMS MIDDLE A
   [Anonymous], 2002, JIMMY NEUTRON VS JIM
   [Anonymous], 2007, Assassin's Creed
   [Anonymous], 1998, HOUSE DEAD 2
   [Anonymous], 1999, Age of Empires 2
   [Anonymous], 2006, SENSELATE MEDIEVAL
   [Anonymous], 1992, GREAT RAGTIME SHOW
   [Anonymous], 1994, CADFAEL
   [Anonymous], 2010, ASSASSINS CREED BROT
   [Anonymous], 1997, OBSIDIAN
   [Anonymous], 1998, AKUMAJO DRACULA X NO
   [Anonymous], MUSIC MOVING IMAGE
   [Anonymous], 2001, Halo
   [Anonymous], 2005, BARDS TALE
   [Anonymous], 2003, The video game theory reader
   Arnold JH, 2012, VIATOR-MEDIEV REN, V43, P99, DOI 10.1484/J.VIATOR.1.102544
   Briggs J. L., 2005, S MEIERS CIVILIZATIO
   Brown Julie, 2010, Music in the Horror Film: Listening to Fear, P1
   Camp J, 1988, PRAISE BELLS FOLKLOR
   Chikuma J., 1987, FAXANADU
   Chion M., 2019, Audio-Vision: Sound on Screen
   Coker G., 2011, ORI BLIND FOREST
   Collins K, 2008, GAME SOUND: AN INTRODUCTION TO THE HISTORY, THEORY, AND PRACTICE OF VIDEO GAME MUSIC AND SOUND DESIGN, P1
   Cook K.M, 2017, GRAVE DIES IRAE VIDE
   Cook KM, 2019, OXFORD HDB MUSIC MED
   Cook KM, 2018, STUDIES MEDIEVALISM, P183
   Djawadi R., 2011, GAME THRONES
   Gee J., 2007, WHAT VIDEO GAMES HAV
   Gee J.P, 2016, STORIES GAMES ARCHIT
   Gibbons W, 2018, ASH SCREEN MUS SER, P139
   Glenville P, 1964, Becket
   Goldstein W., 1988, KINGS QUEST 4 PERILS
   Gorbman Claudia, 1987, Unheard Melodies: Narrative
   Hirano Y., 2004, PAPER MARIO 1000 YEA
   Jumeau-Lafond JD, 1997, REV MUSICOL, V83, P263, DOI 10.2307/946919
   Komozawa M., 1997, MEGA MAN LEGENDS
   Kondo K., 1998, LEGEND ZELDA OCARINA
   Kondo K., 2000, LEGEND ZELDA MAJORAS
   Kondoh R., 2014, BAYONETTA 2
   Kreutziger-Herr A, 2014, GROVE MUSIC ONLINE
   Kubo N., 2017, SUPER MARIO ODYSSEY
   Lerner N., 2010, MUSIC HORROR FILM LI, P55
   Lerner N., 2014, MUSIC VIDEO GAMES ST, P138
   Mann G., 2007, LEGEND SPYRO ETERNAL
   Monger G.P., 2013, MARRIAGE CUSTOMS WOR, V1
   Nishi T., 2007, SUPER SMASH BROS BRA
   Otani K., 2005, SHADOW COLOSSUS
   Parker S., 2014, OCTODAD DADLIEST CAT
   Plank D., 2019, THESIS
   Plank D, 2019, BACH, V50, P32, DOI 10.22513/bach.50.1.0032
   Reynolds RD, 2000, CHORAL J, V41, P19
   Sato T., 2011, DISGAEA 4 PROMISE UN
   Sawa K., 1988, BATTLE OLYMPUS
   Schafer M, 1977, The Tuning of the World
   Schubert L, 1998, FLORILEGIUM, V15, P207
   Senbongi M., 2004, RESIDENT EVIL 4
   Shimomura Y., 1996, SUPER MARIO RPG LEGE
   Sillescu T., 2009, ANNO 1404
   Soule J., 2002, HARRY POTTER PHILOS
   Takehara Y., 1994, BREATH FIRE 2
   Uematsu N., 1994, FINAL FANTASY 6
   Uematsu N., 1991, FINAL FANTASY 4
   van Elferen I., 2012, Gothic Music: The Sounds of the Uncanny
   Van Elferen I, 2012, UNDERSTANDING BACH, V7, P9
   Velasco C., 2015, BLOODBORNE
   Wise D., 1987, WIZARDS WARRIORS
   Yamane M., 2007, CASTLEVANIA ORDER EC
   Yamane M., 1997, CASTLEVANIA SYMPHONY
   Zur I., 2004, CRUSADER KINGS
NR 70
TC 3
Z9 5
U1 2
U2 8
PU PALGRAVE MACMILLAN LTD
PI BASINGSTOKE
PA BRUNEL RD BLDG, HOUNDMILLS, BASINGSTOKE RG21 6XS, HANTS, ENGLAND
SN 2040-5960
EI 2040-5979
J9 POSTMEDIEVAL
JI Postmedieval
PD DEC
PY 2019
VL 10
IS 4
BP 482
EP 497
DI 10.1057/s41280-019-00141-z
PG 16
WC Cultural Studies; Medieval & Renaissance Studies
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Cultural Studies; Arts & Humanities - Other Topics
GA KJ2MR
UT WOS:000511892600007
DA 2024-01-09
ER

PT J
AU Zhu, GJ
   Zhou, Y
   Si, ZY
   Cheng, Y
   Wu, F
   Wang, H
   Pan, YZ
   Xie, J
   Li, CB
   Chen, AY
   Wang, RR
   Sun, J
AF Zhu, Guojian
   Zhou, Yi
   Si, Zeyu
   Cheng, Yin
   Wu, Fei
   Wang, Huan
   Pan, Yaozong
   Xie, Jing
   Li, Chaobo
   Chen, Aiying
   Wang, Ranran
   Sun, Jing
TI A multi-hole resonator enhanced acoustic energy harvester for ultra-high
   electrical output and machine-learning-assisted intelligent voice
   sensing
SO NANO ENERGY
LA English
DT Article
DE Triboelectric nanogenerator; Multi-Hole Acoustic Resonator;
   Acoustic-to-electricity conversion; Sound signal sensing; Machine
   learning
ID TRIBOELECTRIC NANOGENERATOR; NOISE; SENSOR
AB Acoustic energy harvesters are promising platforms for noise-to-electricity conversion in distributed environ-mental power supply and sound sensing in intuitive voice user interface. However, their efficacy in real-world applications is frustrated by the low electric output. We here report a multi-hole acoustic resonator enhanced triboelectric nanogenerator (MHAR-TENG) that couples a perforated plate resonator and a pressure differential acoustic receiver. It generated open-circuit voltage of 347 V, short-circuit current of 95 mu A, and record-high power density of 8.9 W/m2. The numerical simulation confirmed the sound pressure amplification for enhanced output performance. Besides, the high signal-to-noise ratio and precise high-frequency response of electrical signals enabled the high-quality restoration of music and human speech. Assisted by machine learning, the MHAR-TENG realized self-powered voiceprint identification and emotion recognition with a remarkably improved accuracy over 90 %. Our MHAR-TENG holds great potential for efficient acoustic-to-electrical con-version in the fields of noise recycling, biometric authentication, and human-machine interaction.
C1 [Zhu, Guojian; Cheng, Yin; Wu, Fei; Wang, Ranran; Sun, Jing] Chinese Acad Sci, Shanghai Inst Ceram, State Key Lab High Performance Ceram & Superfine M, Shanghai 200050, Peoples R China.
   [Zhu, Guojian; Chen, Aiying] Univ Shanghai Sci & Technol, Sch Mat & Chem, Shanghai 200093, Peoples R China.
   [Zhou, Yi] Natl Univ Singapore, Dept Elect & Comp Engn, 4 Engn Dr 3, Singapore 117583, Singapore.
   [Si, Zeyu; Pan, Yaozong] Chinese Acad Sci, Qingdao Branch, Inst Acoust, Beijing 100190, Peoples R China.
   [Wang, Huan; Xie, Jing; Li, Chaobo] Chinese Acad Sci, Inst Microelect, Beijing 100029, Peoples R China.
   [Wu, Fei; Wang, Huan; Xie, Jing; Li, Chaobo] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Wang, Ranran] Univ Chinese Acad Sci, Hangzhou Inst Adv Study, Sch Chem & Mat Sci, 1 Sub Lane Xiangshan, Hangzhou 310024, Peoples R China.
C3 Chinese Academy of Sciences; Shanghai Institute of Ceramics, CAS;
   University of Shanghai for Science & Technology; National University of
   Singapore; Chinese Academy of Sciences; Chinese Academy of Sciences;
   Institute of Microelectronics, CAS; Chinese Academy of Sciences;
   University of Chinese Academy of Sciences, CAS; Chinese Academy of
   Sciences; University of Chinese Academy of Sciences, CAS
RP Cheng, Y; Wang, RR (corresponding author), Chinese Acad Sci, Shanghai Inst Ceram, State Key Lab High Performance Ceram & Superfine M, Shanghai 200050, Peoples R China.; Wang, RR (corresponding author), Univ Chinese Acad Sci, Hangzhou Inst Adv Study, Sch Chem & Mat Sci, 1 Sub Lane Xiangshan, Hangzhou 310024, Peoples R China.
EM chengyin@mail.sic.ac.cn; wangranran@mail.sic.ac.cn
RI li, chaobo/K-5312-2012
FU National Natural Science Foundation of China [52203365, 61871368,
   62122080]; Austrian Chinese Cooperative Research and Development
   projects [GJHZ2046]; Natural Science Foundation of Shanghai
   [22ZR1481700]; Shanghai Pujiang Program [21PJ1414800]
FX Guojian Zhu and Yi Zhou contributed equally to this work. This work
   received the financial support from the following grants: National
   Natural Science Foundation of China (52203365, 61871368 and 62122080) ;
   the Austrian Chinese Cooperative Research and Development projects
   (GJHZ2046 and POWERTEX) ; Natural Science Foundation of Shanghai
   (22ZR1481700) ; Shanghai Pujiang Program (21PJ1414800) .
CR Cao X, 2018, ADV MATER, V30, DOI 10.1002/adma.201704077
   Carbajo J, 2015, APPL ACOUST, V90, P1, DOI 10.1016/j.apacoust.2014.10.013
   Chen FQ, 2019, NANO ENERGY, V56, P241, DOI 10.1016/j.nanoen.2018.11.041
   Cui NY, 2015, NANO ENERGY, V15, P321, DOI 10.1016/j.nanoen.2015.04.008
   Dong WT, 2018, INT J INTELL ROBOT, V2, P313, DOI 10.1007/s41315-018-0060-z
   Fan FR, 2012, NANO ENERGY, V1, P328, DOI 10.1016/j.nanoen.2012.01.004
   Fan X, 2015, ACS NANO, V9, P4236, DOI 10.1021/acsnano.5b00618
   Ferguson WJG, 2018, SENSOR ACTUAT A-PHYS, V282, P90, DOI 10.1016/j.sna.2018.09.019
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Guo HJ, 2018, ACS NANO, V12, P3461, DOI 10.1021/acsnano.8b00140
   Han JH, 2018, NANO ENERGY, V53, P658, DOI 10.1016/j.nanoen.2018.09.030
   Izhar,, 2018, INT J PRECIS ENG MAN, V19, P143, DOI 10.1007/s12541-018-0017-z
   Lang CH, 2017, NANO ENERGY, V35, P146, DOI 10.1016/j.nanoen.2017.03.038
   Lang CH, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms11108
   Lee KY, 2016, ADV FUNCT MATER, V26, P3067, DOI 10.1002/adfm.201505088
   Li B, 2013, SMART MATER STRUCT, V22, DOI 10.1088/0964-1726/22/5/055013
   Li W, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15310
   Li WB, 2017, ACS APPL MATER INTER, V9, P23716, DOI 10.1021/acsami.7b05051
   Liu F, 2008, J ACOUST SOC AM, V123, P1983, DOI 10.1121/1.2839000
   Liu JM, 2016, NANOSCALE, V8, P4938, DOI 10.1039/c5nr09087c
   Liu YH, 2016, SCI ADV, V2, DOI 10.1126/sciadv.1601185
   Niu SM, 2015, NANO ENERGY, V14, P161, DOI 10.1016/j.nanoen.2014.11.034
   Paradiso JA, 2005, IEEE PERVAS COMPUT, V4, P18, DOI 10.1109/MPRV.2005.9
   Pillai MA, 2014, INT J PRECIS ENG MAN, V15, P949, DOI 10.1007/s12541-014-0422-x
   Qiu WZ, 2020, NANO ENERGY, V70, DOI 10.1016/j.nanoen.2020.104543
   Shao H, 2020, NANO ENERGY, V75, DOI 10.1016/j.nanoen.2020.104956
   Sun KH, 2017, SMART MATER STRUCT, V26, DOI 10.1088/1361-665X/aa724e
   Wang Y, 2018, APPL ENERG, V230, P52, DOI 10.1016/j.apenergy.2018.08.080
   Wang ZX, 2021, ADV FUNCT MATER, V31, DOI 10.1002/adfm.202103081
   Wang ZL, 2019, MATER TODAY, V30, P34, DOI 10.1016/j.mattod.2019.05.016
   Yang J, 2015, ADV MATER, V27, P1316, DOI 10.1002/adma.201404794
   Yang J, 2014, ACS NANO, V8, P2649, DOI 10.1021/nn4063616
   Yu ZH, 2021, ACS APPL MATER INTER, V13, P26981, DOI 10.1021/acsami.1c04489
   Yuan HC, 2021, NANOMATERIALS-BASEL, V11, DOI 10.3390/nano11123431
   Yuan M, 2021, NANO ENERGY, V85, DOI 10.1016/j.nanoen.2021.105962
   Yuan M, 2020, SMART MATER STRUCT, V29, DOI 10.1088/1361-665X/ab6697
   Yuan M, 2018, AIP ADV, V8, DOI 10.1063/1.5042683
   Yuan M, 2012, J INTEL MAT SYST STR, V23, P791, DOI 10.1177/1045389X12439638
   Zhang Q., 2022, NANOMATERIALS-BASEL, V9
   Zhao HF, 2019, ADV ENERGY MATER, V9, DOI 10.1002/aenm.201902824
   Zhao JQ, 2019, NANO ENERGY, V61, P111, DOI 10.1016/j.nanoen.2019.04.047
   Zheng JQ, 2021, ACS NANO, V15, P17499, DOI 10.1021/acsnano.1c04242
NR 42
TC 2
Z9 2
U1 22
U2 57
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2211-2855
EI 2211-3282
J9 NANO ENERGY
JI Nano Energy
PD APR
PY 2023
VL 108
AR 108237
DI 10.1016/j.nanoen.2023.108237
EA FEB 2023
PG 11
WC Chemistry, Physical; Nanoscience & Nanotechnology; Materials Science,
   Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Science & Technology - Other Topics; Materials Science;
   Physics
GA 9C3ZQ
UT WOS:000935360000001
DA 2024-01-09
ER

PT J
AU Müller-Schwarze, N
AF Mueller-Schwarze, Nina
TI "<i>Hay que agacharse</i>": The Embodiment of Culture in the Participant
   Observer Experience and the Return to <i>the West</i>
SO ANTHROPOLOGY OF CONSCIOUSNESS
LA English
DT Article
DE epistemology; embodiment; phenomenology; dance; music
AB Dichotomous categories, such as the West and the rest, primitive and modern, are discussed within a phenomenological theory that suggests humans create structures through which we perceive objects. The perception of culture as an object and its construction through the epistemological practices of fieldwork and interpretation within the metaphor of West and non-Western reveals the structure of sociocultural anthropological inquiry and expresses embodiment of the cosmology of nations. Experiences of, and shared understandings regarding, the body, soul, knowledge, thoughts, emotions, memories, spirits, voice, and speech are compared from descriptions, participant observation, and embodiment as a multi-site ethnographic performance artist expressing new genres of ethnography. Harmony is defined as social location.
C1 [Mueller-Schwarze, Nina] Southern Food & Beverage Museum, New Orleans, LA 70113 USA.
RP Müller-Schwarze, N (corresponding author), Southern Food & Beverage Museum, New Orleans, LA 70113 USA.
EM nina@southernfood.org
CR [Anonymous], 2004, ETHNICITY GROUPS
   [Anonymous], 2009, MIND WORKS
   [Anonymous], 2008, HERO 1000 FACES
   [Anonymous], 2001, PRAYER HAS SPOILT EV
   [Anonymous], 1986, FOLK GROUPS FOLKLORE
   [Anonymous], 2004, Museum Studies: An Anthology of Contexts
   [Anonymous], ED ROLE MUSEUM
   [Anonymous], YOU CAN HEAL YOUR LI
   [Anonymous], 1992, Ethnography and the Historical Imagination
   [Anonymous], 1994, BIRTH CLIN ARCHAEOLO
   [Anonymous], 1998, THEORIES CULTURE POS
   Bainbridge Cohen B., 1993, Sensing, Feeling, and Action: The Experiential Anatomy ofBody- Mind Centering
   Barnard A., 2002, Encyclopedia of Social and Cultural Anthropology
   Bloch Maurice, 2002, ENCY SOCIAL CULTURAL, P108
   Boddy Janice, 1989, Wombs and Alien Spirits
   Bohlman Philip V., 2012, EXCURSIONS WORLD MUS, P238
   Bresciani Jeanne, 2000, THESIS
   Brodkey L., 1987, ANTHR ED Q, V18, P74
   Campanella R, 2006, GEOGRAPHIES NEW ORLE, P193
   CHERNOFF J. M., 1979, African Rhythm and African Sensibility: Aesthetics and SocialAction in African Musical Idioms
   Clark Jack, 2006, WORLD DANC ALL GLOB
   Coombes Annie E, 2007, MUSEUM STUDIES ANTHO, P231
   De Alcantara P., 2013, INDIRECT PROCEDURES
   Duncan Isadora, 1969, THE ART OF DANCE
   Duncan Isadora, 1927, MY LIFE
   Foucault Michel, 2010, The Archaeology of Knowledge
   Freire Ida Mara, 2006, ED COURSE
   Goffman E., 1959, The presentation of self in everyday life
   Goleman D., 2006, SOCIAL INTELLIGENCE
   Halstead N., 2008, Knowing how to know: fieldwork and the ethnographic present
   Hassenstein Bernhard, 1979, MENSCH SEINE SPRACHE, P219
   Hunt Marilyn, 2004, DANCING HEART
   Hyun Yoo Si, 2006, WORLD DANC ALL GLOB
   Johnson D.H., 1995, BONE BREATH BODY PRA
   Johnson S., 1998, WHO MOVED MY CHEESE
   Kaepler Adrienne, 2006, WORLD DANC ALL GLOB
   Kearney Michael, 1996, Reconceptualizing the peasantry: Anthropology in Global Perspective
   Kensinger K., 1995, How Real People Ought to Live: The Cashinahua of Eastern Peru
   Lakoff G., 2003, METAPHORS WE LIVE
   Leone Jay, 1990, ITALIAN WORDS ILLUST
   Levi-Strauss Claude, 1967, STRUCTURAL ANTHR TRA
   Linn M.C., 2010, WORKSH SCOP NAT COMP
   Lorenz Konrad, 1963, GESTALTWAHRNEHMUNG A
   Malkki Liisa H., 1995, PURITY EXILE VIOLENC
   Merleau-Ponty M, 1942, STRUCTURE BEHAV
   Moses Wilson Jeremiah, 1998, AFROTOPIA ROOTS AFRI
   Müller-Schwarze NK, 2006, ECON BOT, V60, P321, DOI 10.1663/0013-0001(2006)60[321:AAHDPK]2.0.CO;2
   Müller-Schwarze NK, 2009, VIS ANTHROPOL, V22, P435, DOI 10.1080/08949460701688965
   Muller-Schwarze Nina K., 2015, BLOOD V LORENZO ETHN
   Muller-Schwarze Nina K., 2005, DIABLOS ROJOS BUSES
   Muller-Schwarze Nina K, 2013, COLLECTIONS J MUSEUM, V9, P353, DOI DOI 10.1177/155019061300900403
   Muller-Schwarze Nina K., 2010, WE ARE LAND SUSTAINA
   Pinkola Estes C., 1996, Women who run with the wolves: Myths and stories of the wild woman archetype
   Queiroz Testa Adriana, 2013, PLACES GO PEOPLE GRO
   Quesada J. Diego, 2007, CHIBCHAN LANGUAGES
   Regis HA, 1999, CULT ANTHROPOL, V14, P472, DOI 10.1525/can.1999.14.4.472
   Rodriguez Floresmiro, 2006, COMMUNICATION
   Spivey T., 1992, USES COMP MYTHOLOGY, P71
   SWIDERSKI RM, 1991, LIVES CULTURES STUDY
   Theophrastus, 1897, THOEPHRASTUSS CHARAK
   Turner Edith, 2006, HEART LIGHTNESS LIFE
   Wikipedia, PHENOMENOLOGY
NR 62
TC 0
Z9 0
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1053-4202
EI 1556-3537
J9 ANTHROPOL CONSCIOUS
JI Anthropol. Conscious.
PD MAR
PY 2019
VL 30
IS 1
BP 7
EP 41
DI 10.1111/anoc.12110
PG 35
WC Anthropology
WE Emerging Sources Citation Index (ESCI)
SC Anthropology
GA HO0KU
UT WOS:000460593100002
DA 2024-01-09
ER

PT J
AU Trevor, C
   Arnal, LH
   Frühholz, S
AF Trevor, Caitlyn
   Arnal, Luc H.
   Fruhholz, Sascha
TI Terrifying film music mimics alarming acoustic feature of human screams
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID COMMUNICATION; SOUND
AB One way music is thought to convey emotion is by mimicking acoustic features of affective human vocalizations [Juslin and Laukka (2003). Psycho]. Bull. 129(5). 770 814]. Regarding fear, it has been informally noted that music for scary scenes in films frequently exhibits a "scream-like" character. Here, this proposition is formally tested. This paper reports acoustic analyses for four categories of audio stimuli: screams, non-screaming vocalizations. scream-like music. and non-scream-like music. Valence and arousal ratings were also collected. Results support the hypothesis that a key feature of human screams (roughness) is imitated by scream-like music and could potentially signal danger through both music and the voice. (C) 2020 Acoustical Society of America
C1 [Trevor, Caitlyn; Fruhholz, Sascha] Univ Zurich, Dept Psychol, Binzmuehlestr 14, CH-8050 Zurich, Switzerland.
   [Arnal, Luc H.] Univ Geneva, Dept Fundamental Neurosci, Biotech Campus, CH-1202 Geneva 7, Switzerland.
   [Fruhholz, Sascha] Univ Oslo, Dept Psychol, Forskningsveien 3A, N-0373 Oslo, Norway.
C3 University of Zurich; University of Geneva; University of Oslo
RP Trevor, C (corresponding author), Univ Zurich, Dept Psychol, Binzmuehlestr 14, CH-8050 Zurich, Switzerland.
EM caitlyn.trevor@psychologie.uzh.ch; luc.arnal@unige.ch;
   sascha.fruehholz@psychologie.uzh.ch
RI Arnal, Luc/AAE-2356-2022
OI Arnal, Luc/0000-0002-2226-6497
FU European Union's Horizon 2020 research and innovation program under the
   Marie Skodowska-Curie Grant [835682]; Swiss National Science Foundation
   [SNSF PP00P1_157409/1, PP00P1_183711/1]; Marie Curie Actions (MSCA)
   [835682] Funding Source: Marie Curie Actions (MSCA)
FX C.T. received funding from the European Union's Horizon 2020 research
   and innovation program under the Marie Skodowska-Curie Grant Agreement
   (No. 835682). S.F. received funding from Swiss National Science
   Foundation (Grants Nos. SNSF PP00P1_157409/1 and PP00P1_183711/1). The
   authors thank Lawrence Feth for guidance regarding the acoustic analyses
   and to David Huron for valuable feedback on the project. Finally, the
   authors thank Arkady Konovalov for helpful input regarding the
   statistical analyses.
CR Anikin A, 2020, BIOACOUSTICS, V29, P226, DOI 10.1080/09524622.2019.1581839
   [Anonymous], 2017, EVOL PSYCHIAT, DOI DOI 10.18637/JSS.V082.I13
   [Anonymous], 2015, BUSINESS ETHICS Q, V25, pv, DOI DOI 10.1016/J.CUB.2015.07.027
   Arnal LH, 2015, CURR BIOL, V25, P2051, DOI 10.1016/j.cub.2015.06.043
   Bates D, 2014, ARXIV14065823
   Blumstein DT, 2012, BIOL LETTERS, V8, P744, DOI 10.1098/rsbl.2012.0374
   Blumstein DT, 2010, BIOL LETTERS, V6, P751, DOI 10.1098/rsbl.2010.0333
   BROWN RS, 1982, CINEMA J, V21, P14, DOI 10.2307/1225034
   Bryant Gregory A, 2013, Front Psychol, V4, P990, DOI 10.3389/fpsyg.2013.00990
   Ehret Guenter, 2006, P85
   Engelberg J. W., 2018, J EXP PSYCHOL, V72, P1889, DOI [10.1177/1747021818816307, DOI 10.1177/1747021818816307]
   Huron D., 2015, SIGNATA ANN SEMIOT, V6, P331, DOI DOI 10.4000/SIGNATA.1115
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Li T, 2018, PHYSIOL BEHAV, V193, P43, DOI 10.1016/j.physbeh.2017.12.033
   Liuni M, 2020, BEHAV PROCESS, V172, DOI 10.1016/j.beproc.2020.104042
   LORENZ K., 1939, ZOOL ANZ SUPPL [VERHANDL DEUTSCH ZOOL GES 41], V12, P69
   Mirka Danuta, 2014, The Oxford Handbook of Topic Theory
   Ohala JJ, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1812, DOI 10.1109/ICSLP.1996.607982
   Ollivier R, 2019, MUSIC PERCEPT, V37, P95, DOI 10.1525/MP.2019.37.2.95
   Parsons N, 2009, TD-J TRANSDISCIPL RE, V5, P1
   Schwartz J. W., 2019, J ACOUST SOC AM, V145, P1776, DOI [10.1121/1.5101500, DOI 10.1121/1.5101500]
   TERHARDT E, 1974, ACUSTICA, V30, P201
   Thompson WF, 2019, PSYCHOL POP MEDIA CU, V8, P218, DOI 10.1037/ppm0000184
   Trevor C., 2017, EMPIRICAL MUSICOLOGY, V11, P261, DOI DOI 10.18061/EMR.V11I2.4968
   Trevor C, 2018, EMPIR MUSICOL REV, V13, P66
   Vassilakis PN, 2010, PROC SPIE, V7527, DOI 10.1117/12.845457
   Warrenburg LA, 2020, PSYCHOMUSICOLOGY, V30, P1, DOI 10.1037/pmu0000247
   2019, FRONT PLANT SCI, V10, P1, DOI DOI 10.1038/S41467-019-11626-7
NR 29
TC 11
Z9 11
U1 6
U2 14
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD JUN
PY 2020
VL 147
IS 6
BP EL540
EP EL545
DI 10.1121/10.0001459
PG 6
WC Acoustics; Audiology & Speech-Language Pathology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Acoustics; Audiology & Speech-Language Pathology
GA MF8ZR
UT WOS:000545627900001
PM 32611175
OA Green Published, Bronze
DA 2024-01-09
ER

PT J
AU Bannister, S
AF Bannister, Scott
TI A survey into the experience of musically induced chills: Emotions,
   situations and music
SO PSYCHOLOGY OF MUSIC
LA English
DT Article
DE chills; emotion; listening; meaning; peak experiences; qualitative
ID AESTHETIC CHILLS; RESPONSES; MIRROR; BRAIN; AWE; ENGAGEMENT; ELICITORS;
   PLEASURE
AB Musically induced chills, an emotional response accompanied by gooseflesh, shivers and tingling sensations, are an intriguing aesthetic phenomenon. Although chills have been linked to musical features, personality traits and listening contexts, there exists no comprehensive study that surveys the general characteristics of chills, such as emotional qualities. Thus, the present research aimed to develop a broad understanding of the musical chills response, in terms of emotional characteristics, types of music and chill-inducing features, and listening contexts. Participants (N = 375) completed a survey collecting qualitative responses regarding a specific experience of musical chills, with accompanying quantitative ratings of music qualia and underlying mechanisms. Participants could also describe two more "chills pieces". Results indicate that chills are often experienced as a mixed and moving emotional state, and commonly occur in isolated listening contexts. Recurring musical features linked to chills include crescendos, the human voice, lyrics, and concepts such as unity and communion in the music. Findings are discussed in terms of theories regarding musical chills, and implications for future empirical testing of the response.
C1 [Bannister, Scott] Univ Durham, Durham, England.
C3 Durham University
RP Bannister, S (corresponding author), Univ Durham, Dept Mus, Palace Green, Durham DH1 3RL, County Durham, England.
EM scott.c.bannister@durham.ac.uk
OI Bannister, Scott/0000-0003-4905-0511
FU Arts and Humanities Research Council UK, Northern Bridge Doctoral
   Scholarship Award [AH/L503927/1]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: The author
   received financial support for the research through the Arts and
   Humanities Research Council UK, Northern Bridge Doctoral Scholarship
   Award (Award No: AH/L503927/1).
CR Algoe SB, 2009, J POSIT PSYCHOL, V4, P105, DOI 10.1080/17439760802650519
   Ali SO., 2006, Psychology of Music, V34, P511, DOI DOI 10.1177/0305735606067168
   Aucouturier JJ, 2017, COGNITION, V161, P94, DOI 10.1016/j.cognition.2017.01.019
   Beerman U., 2015, 4 INT CONTR MUS EM G
   Benedek M, 2011, BIOL PSYCHOL, V86, P320, DOI 10.1016/j.biopsycho.2010.12.012
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Braud W., 2001, Journal of Transpersonal Psychology, V33, P99
   Braun V., 2006, Qual. Res. Psychol, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Clarke E, 2015, PHYS LIFE REV, V15, P61, DOI 10.1016/j.plrev.2015.09.001
   Colver MC, 2016, PSYCHOL MUSIC, V44, P413, DOI 10.1177/0305735615572358
   Craig DG, 2005, MUSIC SCI, V9, P273, DOI 10.1177/102986490500900207
   Cross I, 2014, PSYCHOL MUSIC, V42, P809, DOI 10.1177/0305735614543968
   Davies S., 2011, Empathy: Philosophical and psychological perspectives, P134, DOI [10.1093/acprof:oso/9780199539956.003.0010, DOI 10.1093/ACPROF:OSO/9780199539956.003.0010]
   Egermann H, 2011, MUSIC SCI, V15, P307, DOI 10.1177/1029864911399497
   Fiveash A, 2016, PSYCHOL MUSIC, V44, P1346, DOI 10.1177/0305735615628057
   Gabrielsson A, 2003, MUSIC SCI, V7, P157, DOI 10.1177/102986490300700201
   Gabrielsson A., 2011, Strong Experiences with Music
   Gabrielsson A, 2001, MUSIC SCI, V5, P123, DOI 10.1177/10298649020050S105
   GOLDSTEIN A, 1980, PHYSIOL PSYCHOL, V8, P126
   Greasley AE, 2011, MUSIC SCI, V15, P45, DOI 10.1177/1029864910393417
   Grewe O, 2007, MUSIC PERCEPT, V24, P297, DOI 10.1525/MP.2007.24.3.297
   Guhn M, 2007, MUSIC PERCEPT, V24, P473, DOI 10.1525/MP.2007.24.5.473
   Haidt J, 2003, SER AFFECTIVE SCI, P852
   Hanich J, 2014, PSYCHOL AESTHET CREA, V8, P130, DOI 10.1037/a0035690
   Huron D, 2010, Handbook of music and emotion: theory, research, applications, P575
   HURON DAVID, 2006, SWEET ANTICIPATION M, P148, DOI DOI 10.7551/MITPRESS/6575.001.0001
   Inagaki TK, 2013, PSYCHOL SCI, V24, P2272, DOI 10.1177/0956797613492773
   JAMES W, 1994, PSYCHOL REV, V101, P205, DOI 10.1037/0033-295X.101.2.205
   John O. P., 1993, HDB PERSONALITY THEO, P102
   Juslin PN, 2008, EMOTION, V8, P668, DOI 10.1037/a0013505
   Juslin PN, 2014, PSYCHOL MUSIC, V42, P599, DOI 10.1177/0305735613484548
   Juslin PN, 2013, PHYS LIFE REV, V10, P235, DOI 10.1016/j.plrev.2013.05.008
   Juslin PN, 2011, MUSIC SCI, V15, P174, DOI 10.1177/1029864911401169
   Keltner D, 2003, COGNITION EMOTION, V17, P297, DOI 10.1080/02699930302297
   Khalfa S, 2002, NEUROSCI LETT, V328, P145, DOI 10.1016/S0304-3940(02)00462-7
   Konecni VJ, 2005, B PSYCHOL ARTS, V5, P27, DOI DOI 10.1037/E674862010-005
   Laeng B, 2016, CONSCIOUS COGN, V44, P161, DOI 10.1016/j.concog.2016.07.009
   Lamont A, 2011, MUSIC SCI, V15, P229, DOI 10.1177/1029864911403368
   Lundqvist LO, 2009, PSYCHOL MUSIC, V37, P61, DOI 10.1177/0305735607086048
   Maruskin LA, 2012, J PERS SOC PSYCHOL, V103, P135, DOI 10.1037/a0028117
   Maslow AH., 1964, Religions, values, and peak-experiences
   McCrae RR, 2007, MOTIV EMOTION, V31, P5, DOI 10.1007/s11031-007-9053-1
   Menninghaus W, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0128451
   Meyer LB., 1956, Emotion and meaning in music
   Molnar-Szakacs I, 2006, SOC COGN AFFECT NEUR, V1, P235, DOI 10.1093/scan/nsl029
   Mori K, 2017, SCI REP-UK, V7, DOI 10.1038/srep46063
   Nagel F, 2008, MUSIC SCI, V12, P101, DOI 10.1177/102986490801200106
   North AC, 2004, MUSIC PERCEPT, V22, P41, DOI 10.1525/mp.2004.22.1.41
   Nummenmaa L, 2014, P NATL ACAD SCI USA, V111, P646, DOI 10.1073/pnas.1321664111
   Nusbaum EC, 2014, PSYCHOL AESTHET CREA, V8, P104, DOI 10.1037/a0034867
   Nusbaum EC, 2011, SOC PSYCHOL PERS SCI, V2, P199, DOI 10.1177/1948550610386810
   Panksepp J, 2002, BEHAV PROCESS, V60, P133, DOI 10.1016/S0376-6357(02)00080-3
   Panksepp J, 1995, MUSIC PERCEPT, V13, P171
   Panksepp J., 2004, Affective Neuroscience
   PANZARELLA R, 1980, J HUMANIST PSYCHOL, V20, P69, DOI 10.1177/002216788002000105
   Rickard N. S., 2004, Psychology of Music, V32, P371, DOI [10.1177%2F0305735604046096, DOI 10.1177/0305735604046096, 10.1177/0305735604046096]
   Rizzolatti G, 2016, NAT REV NEUROSCI, V17, P757, DOI 10.1038/nrn.2016.135
   Salimpoor VN, 2011, NAT NEUROSCI, V14, P257, DOI 10.1038/nn.2726
   Salimpoor VN, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0007487
   Schutter DJLG, 2012, MOTIV EMOTION, V36, P46, DOI 10.1007/s11031-011-9237-6
   Seibt B, 2017, EMOTION, V17, P389, DOI 10.1037/emo0000271
   Shiota MN, 2007, COGNITION EMOTION, V21, P944, DOI 10.1080/02699930600923668
   Sloboda J. A., 1991, Psychology of Music, V19, P110, DOI [10.1177/0305735691192002, DOI 10.1177/0305735691192002]
   Steinbeis N, 2006, J COGNITIVE NEUROSCI, V18, P1380, DOI 10.1162/jocn.2006.18.8.1380
   Vuoskoski JK, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00439
   Wassiliwizky E, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00041
   Wassiliwizky E, 2015, PSYCHOL AESTHET CREA, V9, P405, DOI 10.1037/aca0000023
   Zickfeld JH, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00723
NR 68
TC 20
Z9 23
U1 0
U2 27
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0305-7356
EI 1741-3087
J9 PSYCHOL MUSIC
JI Psychol. Music
PD MAR
PY 2020
VL 48
IS 2
BP 297
EP 314
DI 10.1177/0305735618798024
PG 18
WC Psychology, Educational; Psychology, Applied; Music; Psychology,
   Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Psychology; Music
GA LA4FQ
UT WOS:000523904300009
OA Green Accepted
DA 2024-01-09
ER

PT J
AU Huron, D
AF Huron, David
TI Why is sad music pleasurable? A possible role for prolactin
SO MUSICAE SCIENTIAE
LA English
DT Article
DE music; pleasure; prolactin; sadness
ID VOCAL EXPRESSION; SPEECH RATE; EMOTIONS; PERCEPTION; SADNESS;
   RECOGNITION; DEPRESSION; JUDGMENT; EMPATHY; MOOD
AB A hedonic theory of music and sadness is proposed. Some listeners report that nominally sad music genuinely makes them feel sad. It is suggested that, for these listeners, sad affect is evoked through a combination of empathetic responses to sad acoustic features, learned associations, and cognitive rumination. Among those listeners who report sad feelings, some report an accompanying positive affect, whereas others report the experience to be solely negative. Levels of the hormone prolactin increase when sad - producing a consoling psychological effect suggestive of a homeostatic function. it is proposed that variations in prolactin levels might account for the variability in individual hedonic responses. Specifically. it is conjectured that high prolactin concentrations are associated with pleasurable music-induced sadness, whereas low prolactin concentrations are associated with unpleasant music-induced sadness.
C1 Ohio State Univ, Sch Mus, Columbus, OH 43210 USA.
C3 University System of Ohio; Ohio State University
RP Huron, D (corresponding author), Ohio State Univ, Sch Mus, 1866 Coll Rd, Columbus, OH 43210 USA.
EM huron.1@osu.edu
CR Abou-Saleh MT, 1998, PSYCHONEUROENDOCRINO, V23, P465
   ALLOY LB, 1979, J EXP PSYCHOL GEN, V108, P441, DOI 10.1037/0096-3445.108.4.441
   [Anonymous], ASTHETIK PSYCHOL SCH
   [Anonymous], 2010, CONSUMEROLOGY MARKET
   [Anonymous], 1993, MUSIKPSYCHOL JB DTSC
   [Anonymous], 2008, Against happiness: in praise of melancholy
   [Anonymous], 1997, MUSIC MEANING
   [Anonymous], 2008, SADNESS SURVIVED EVO
   Bachorowski JA, 2002, EMO SOC BEH, P11
   Balkwill LL, 2004, JPN PSYCHOL RES, V46, P337, DOI 10.1111/j.1468-5584.2004.00265.x
   Brady S.., 2006, BIOLOGICAL PSYCHOL, V71, P312
   Breitenstein C, 2001, COGNITION EMOTION, V15, P57, DOI 10.1080/0269993004200114
   BROWN JD, 1993, J PERS SOC PSYCHOL, V64, P421, DOI 10.1037/0022-3514.64.3.421
   Carr L, 2003, P NATL ACAD SCI USA, V100, P5497, DOI 10.1073/pnas.0935845100
   Chordia P., 2010, P 11 INT C MUS PERC, P63
   Clore GL, 2007, TRENDS COGN SCI, V11, P393, DOI 10.1016/j.tics.2007.08.005
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Crowder R. G., 1985, PSYCHOMUSICOLOGY, V5, P3, DOI [DOI 10.1037/H0094203, 10.1037/h0094203]
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Davies S., 1997, MUSIC MEANING, P242
   Davis M. H., 1996, Empathy: A social psychological approach
   Ekman Paul., 2003, Emotions Revealed: Recognizing Faces and Feelings to Improve Communication and Emotional Life
   Eugster A., 2001, ADULT CRYING BIOSOCI, P177
   Fairbanks G, 1939, SPEECH MONOGR, V6, P87, DOI 10.1080/03637753909374863
   Feld S., 1990, Sound and Sentiment: Birds, Weeping, Poetics, and Song in Kaluli Expression
   Feld S., 1982, Sound and Sentiment: Birds, Weeping, Poetics, and Song in Kaluli Expression
   Fox Aaron A., 2004, REAL COUNTRY MUSIC L
   Freeman ME, 2000, PHYSIOL REV, V80, P1523, DOI 10.1152/physrev.2000.80.4.1523
   Frey William H., 1985, Crying: The mystery of tears
   Gallese V, 1998, TRENDS COGN SCI, V2, P493, DOI 10.1016/S1364-6613(98)01262-5
   George MS, 1996, BIOL PSYCHIAT, V40, P859, DOI 10.1016/0006-3223(95)00572-2
   Grattan DR, 2008, J NEUROENDOCRINOL, V20, P752, DOI 10.1111/j.1365-2826.2008.01736.x
   Hauser Marc D., 1996, EVOL COMMUN
   Horseman N. D, 2001, PROLACTIN
   Horwitz AV., 2007, LOSS SADNESS PSYCHIA
   Huron D, 2002, P 7 INT C MUS PERC C
   Huron D, 2008, EMPIR MUSICOL REV, V3, P59, DOI 10.18061/1811/31940
   Huron David., 2006, SWEET ANTICIPATION M, DOI DOI 10.7551/MITPRESS/6575.001.0001
   Iacoboni M, 2008, MIRRORING PEOPLE NEW
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   KASTNER MP, 1990, MUSIC PERCEPT, V8, P189
   Kivy P., 1980, CORDED SHELL REFLECT
   Kraepelin E, 1899, MANIC DEPRESSIVE INS
   Ladinig O., SURVEY LISTENE UNPUB
   Laird James D., 2007, Feelings: The Perception of Self
   LANE RD, 1987, J PSYCHOSOM RES, V31, P375, DOI 10.1016/0022-3999(87)90058-4
   Laukka P, 2005, COGNITION EMOTION, V19, P633, DOI 10.1080/02699930441000445
   LeDoux Joseph, 1996, The Emotional Brain
   Lehrer Jonah, 2009, WE DECIDE
   LIEBERMAN P, 1962, J ACOUST SOC AM, V34, P922, DOI 10.1121/1.1918222
   Magowan F., 2007, Melodies of Mourning: Music Emotion in Northern Australia
   Maynard Smith J. M., 2003, Animal signals
   Mazo M, 1994, THEMES VARIATIONS WR, P161
   Mittal VA, 2011, PSYCHIAT RES, V189, P158, DOI 10.1016/j.psychres.2011.06.006
   Nesse R. M., 2010, OXFORD TXB MED, P12
   NESSE RM, 1991, SCIENCES, V31, P30, DOI 10.1002/j.2326-1951.1991.tb02346.x
   Patel A. D., 2007, Music, language, and the brain
   Post O, 2009, EMPIR MUSICOL REV, V4, P2, DOI 10.18061/1811/36601
   Remick J. S., 1991, B PSYCHONOMIC SOC, V29, P187
   Rizzolatti G, 2004, ANNU REV NEUROSCI, V27, P169, DOI 10.1146/annurev.neuro.27.070203.144230
   Ross L., 2011, The Person and the Situation: Perspectives of Social Psychology
   Saarikallio S., 2009, P 7 TRIENN C EUR SOC, P452
   Schellenberg G, 2009, 7 TRIENN C EUR SOC C
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   Schramm H, 2010, POETICS, V38, P319, DOI 10.1016/j.poetic.2010.03.002
   Schubert E., 1996, PSYCHOL MUSIC, V24, P18, DOI DOI 10.1177/0305735696241003
   Schutz M, 2008, EMPIR MUSICOL REV, V3, P126, DOI 10.18061/1811/34103
   Seider B., 2010, SOCIAL COGNITIVE AFF, DOI 10. 109 3/scan/nsq069
   Seremetakis C. Nadia, 1991, The Last Word: Women, Death, and Divination in Inner Mani
   Sheldon KM, 2001, AM PSYCHOL, V56, P216, DOI 10.1037//0003-066X.56.3.216
   Siegal A., 2006, ESSENTIAL NEUROSCIEN
   SIEGMAN AW, 1993, J ABNORM PSYCHOL, V102, P430, DOI 10.1037/0021-843X.102.3.430
   Singer T, 2004, SCIENCE, V303, P1157, DOI 10.1126/science.1093535
   Storbeck J, 2005, PSYCHOL SCI, V16, P785, DOI 10.1111/j.1467-9280.2005.01615.x
   SUSMAN VL, 1988, AM J PSYCHIAT, V145, P498
   TARTTER VC, 1980, PERCEPT PSYCHOPHYS, V27, P24, DOI 10.3758/BF03199901
   Terwogt M. M., 1991, PSYCHOL MUSIC, V19, P99, DOI DOI 10.1177/0305735691192001
   Turner B, 2008, EMPIR MUSICOL REV, V3, P64, DOI 10.18061/1811/31941
   Turner RA, 2002, STRESS, V5, P269, DOI 10.1080/1025389021000037586-1
   Valentine CW, 1913, BRIT J PSYCHOL, V6, P190, DOI 10.1111/j.2044-8295.1913.tb00090.x
   Vingerhoets A., 2000, Gender and Emotion: Social Psychological Perspectives, V2, P143, DOI DOI 10.1017/CBO9780511628191.008
   Vuoskoski J. K., WHO LISTENS SA UNPUB
   Wilce James M., 2009, Crying shame metaculture. Modernity, and the exaggerated death of lament
   Wilde O, 1890, OSCAR WILDE MAJOR WO
   WILSON TD, 1991, J PERS SOC PSYCHOL, V60, P181, DOI 10.1037/0022-3514.60.2.181
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 88
TC 103
Z9 117
U1 0
U2 44
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1029-8649
EI 2045-4147
J9 MUSIC SCI
JI Music Sci.
PD SPR
PY 2011
VL 15
IS 2
SI SI
BP 146
EP 158
DI 10.1177/1029864911401171
PG 13
WC Music; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music; Psychology
GA 799RK
UT WOS:000293303600002
DA 2024-01-09
ER

PT J
AU Anderson-Kunert, T
AF Anderson-Kunert, Todd
TI "Almost there": sonically controlled vibrators, sound, and emotions
SO QUALITATIVE RESEARCH JOURNAL
LA English
DT Article
DE Music; Sound; Contemporary art; Sexual; Erotic; Experimental audio;
   Experimental music; Experimental sound; Soundart
AB Purpose The purpose of this paper is to demonstrate how practice-led research within the sonic practice references what Smith and Dean (2009) describe as the "The Iterative Cyclic Web," and oscillations between different modes of research and practice throughout the methodology. Design/methodology/approach This paper uses this process to document the construction of a sonically based erotic artwork, "Almost there," which used sonically controlled vibrators in order to generate vocal content. Findings The paper found that it was important to oscillate between modes of research and practice in order to create a conceptually concise artwork that functioned as a Gestalt of both practice and research. Originality/value The unique approach to audio collection within this sonic artwork, and the time taken to collect this source material, makes it a unique vehicle for the consideration of "The iterative Cyclic Web."
C1 [Anderson-Kunert, Todd] Swinburne Univ Technol, Melbourne, Vic, Australia.
C3 Swinburne University of Technology
RP Anderson-Kunert, T (corresponding author), Swinburne Univ Technol, Melbourne, Vic, Australia.
EM info@toddanderson-kunert.com
CR Acconci Vito, 1972, SEEDBED
   Attali Jacques., 1985, Noise: The Political Economy of Music
   Doidge N., 2010, BRAIN CHANGES ITSELF, P93
   Knight P., 2008, NEW08
   Kozak R., 2003, NYMPHOMATRIARCH
   Oram D., 2016, INDIVIDUAL NOTE MUSI, P51
   SCHAFER R.M., 1993, The soundscape: Our sonic environment and the tuning of the world
   Smith H, 2009, RES METHOD ART HUM, P1
NR 8
TC 0
Z9 0
U1 0
U2 2
PU EMERALD GROUP PUBLISHING LTD
PI BINGLEY
PA HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND
SN 1443-9883
EI 1448-0980
J9 QUAL RES J
JI Qual. Res. J.
PD FEB 4
PY 2019
VL 19
IS 1
SI SI
BP 72
EP 77
DI 10.1108/QRJ-12-2018-0013
PG 6
WC Social Sciences, Interdisciplinary
WE Emerging Sources Citation Index (ESCI)
SC Social Sciences - Other Topics
GA HP1LL
UT WOS:000461428200008
DA 2024-01-09
ER

PT J
AU Yri, K
AF Yri, Kirsten
TI Black Sabbath <i>Purgatus</i>: Medievalizing heavy metal
SO POSTMEDIEVAL-A JOURNAL OF MEDIEVAL CULTURAL STUDIES
LA English
DT Article
AB This essay explores the medieval ensemble Rondellus's tribute album to Black Sabbath, Sabbatum (Beg the Bug 211200-002, 2002), and the extent to which instrumental timbre, vocality, rhythm, and musical setting help communicate 'authentic' medieval music. Of paramount interest is the way in which these performance practice elements are directed by the emotional expression consistent with the genres. Most of the Black Sabbath songs chosen perform emotions that range from anger and aggression to bitterness and pain. They do so through musico-emotional codes that communicate the body's physicality: snarled or shouted vocals, distorted bass and guitar, pounding drums, and melodies characterized more by rhythm than pitch. Rondellus's adaptation of Black Sabbath's musical codes and emotional register is positioned against Ute Frevert's theorization of emotional display as governed by social etiquette. The body in Rondellus's 'medieval' music thus appears emotionally controlled, suggesting interiority and restraint.
C1 [Yri, Kirsten] Wilfrid Laurier Univ, Fac Mus, Musicol, Waterloo, ON, Canada.
C3 Wilfrid Laurier University
RP Yri, K (corresponding author), Wilfrid Laurier Univ, Fac Mus, Musicol, Waterloo, ON, Canada.
EM kyri@wlu.ca
CR [Anonymous], 1997, Rocking the Classics: English Progressive Rock and the Counterculture
   [Anonymous], BLACK SABBATH
   Carlos C, 2019, OXFORD HDB MUSIC MED
   Cope AL, 2010, ASHG POP FOLK MUSIC, P1
   Cumming Naomi, 2001, The Sonic Self: Musical Subjectivity and Signification
   Deaville J, 2019, OXFORD HDB MUSIC MED
   Fast S, 2000, MITTELALTERSEHNSUCH, P35
   Frevert U, 2014, EMOTIONAL KNOWLEDGE
   FROESE Brian, 2013, BLACK SABBATH PHILOS, P20
   Halliwell Stephen, 1986, ARISTOTLES POETICS
   Hardwick P, 2007, MASS MARKET MEDIEVAL, P28
   Kivy P., 1980, CORDED SHELL REFLECT
   Knapp T, 2002, CULTURAL ARTS MAGAZI, P7
   Kreutziger-Herr A, 2015, GROVE MUSIC ONLINE
   Leech-Wilkinson Daniel, 2002, MODERN INVENTION MED
   Littmann G, 2012, BLACK SABBATH PHILOS, P63
   Marshall Melanie L., 2015, Women Music, V19, P36
   Meyer LB., 1956, Emotion and meaning in music
   Meyer SC, 2019, OXFORD HDB MUSIC MED
   Rondellus, 1995, SECULAR MUSIC FRANCE
   Rondellus, 2002, BEG BUG 211200 002
   Rondellus, 1995, SANCTUM ROSARIUM SAC
   Rondellus, 1998, CARMINA SANCTORUM MU
   Scheer M, 2012, HIST THEORY, V51, P193, DOI 10.1111/j.1468-2303.2012.00621.x
   Taruskin R., 1995, Text&Act: Essays on music and performance
   Trafford S, 2019, OXFORD HDB MUSIC MED
   TREITLER L, 1991, J ROY MUSIC ASSN, V116, P280, DOI 10.1093/jrma/116.2.280
   Walser Robert, 1993, Running with the Devil: Power, Gender, and Madness in Heavy Metal
   Weinstein Deena, 1991, HEAVY METAL CULTURAL
NR 29
TC 0
Z9 0
U1 0
U2 2
PU PALGRAVE MACMILLAN LTD
PI BASINGSTOKE
PA BRUNEL RD BLDG, HOUNDMILLS, BASINGSTOKE RG21 6XS, HANTS, ENGLAND
SN 2040-5960
EI 2040-5979
J9 POSTMEDIEVAL
JI Postmedieval
PD DEC
PY 2019
VL 10
IS 4
BP 466
EP 481
DI 10.1057/s41280-019-00146-8
PG 16
WC Cultural Studies; Medieval & Renaissance Studies
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Cultural Studies; Arts & Humanities - Other Topics
GA KJ2MR
UT WOS:000511892600006
DA 2024-01-09
ER

PT J
AU Jeong, JW
   Diwadkar, VA
   Chugani, CD
   Sinsoongsud, P
   Muzik, O
   Behen, ME
   Chugani, HT
   Chugani, DC
AF Jeong, Jeong-Won
   Diwadkar, Vaibhav A.
   Chugani, Carla D.
   Sinsoongsud, Piti
   Muzik, Otto
   Behen, Michael E.
   Chugani, Harry T.
   Chugani, Diane C.
TI Congruence of happy and sad emotion in music and faces modifies cortical
   audiovisual activation
SO NEUROIMAGE
LA English
DT Article
DE Happy-sad congruence; Music; Face image; Superior temporal gyrus;
   Fusiform gyrus; fMRI
ID MULTISENSORY INTEGRATION; CROSSMODAL BINDING; SPEECH SOUNDS; VOICE;
   PERCEPTION; REPETITION; BRAIN
AB Background: The powerful emotion inducing properties of music are well-known, yet music may convey differing emotional responses depending on environmental factors. We hypothesized that neural mechanisms involved in listening to music may differ when presented together with visual stimuli that conveyed the same emotion as the music when compared to visual stimuli with incongruent emotional content.
   Methods: We designed this study to determine the effect of auditory (happy and sad instrumental music) and visual stimuli (happy and sad faces) congruent or incongruent for emotional content on audiovisual processing using fMRI blood oxygenation level-dependent (BOLD) signal contrast. The experiment was conducted in the context of a conventional block-design experiment. A block consisted of three emotional ON periods, music alone (happy or sad music), face alone (happy or sad faces), and music combined with faces where the music excerpt was played while presenting either congruent emotional faces or incongruent emotional faces.
   Results: We found activity in the superior temporal gyrus (STG) and fusiform gyrus (FG) to be differentially modulated by music and faces depending on the congruence of emotional content. There was a greater BOLD response in STG when the emotion signaled by the music and faces was congruent. Furthermore, the magnitude of these changes differed for happy congruence and sad congruence, i.e., the activation of STG when happy music was presented with happy faces was greater than the activation seen when sad music was presented with sad faces. In contrast, incongruent stimuli diminished the BOLD response in STG and elicited greater signal change in bilateral FG. Behavioral testing supplemented these findings by showing that subject ratings of emotion in faces were influenced by emotion in music. When presented with happy music, happy faces were rated as more happy (p=0.051) and sad faces were rated as less sad (p=0.030). When presented with sad music, happy faces were rated as less happy (p=0.008) and sad faces were rated as sadder (p=0.002).
   Interpretation: Happy sad congruence across modalities may enhance activity in auditory regions while incongruence appears to impact the perception of visual affect, leading to increased activation in face processing regions such as the FG. We suggest that greater understanding of the neural bases of happy sad congruence across modalities can shed light on basic mechanisms of affective perception and experience and may lead to novel insights in the study of emotion regulation and therapeutic use of music. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Jeong, Jeong-Won; Sinsoongsud, Piti; Muzik, Otto; Behen, Michael E.; Chugani, Harry T.; Chugani, Diane C.] Wayne State Univ, Sch Med, Carman & Ann Adams Dept Pediat, Detroit, MI 48201 USA.
   [Jeong, Jeong-Won; Sinsoongsud, Piti; Muzik, Otto; Behen, Michael E.; Chugani, Harry T.] Wayne State Univ, Sch Med, Dept Neurol, Detroit, MI 48201 USA.
   [Diwadkar, Vaibhav A.] Wayne State Univ, Sch Med, Dept Psychiat & Behav Neurosci, Detroit, MI 48201 USA.
   [Muzik, Otto; Chugani, Harry T.; Chugani, Diane C.] Wayne State Univ, Sch Med, Dept Radiol, Detroit, MI 48201 USA.
   [Jeong, Jeong-Won; Sinsoongsud, Piti; Muzik, Otto; Behen, Michael E.; Chugani, Diane C.] Childrens Hosp Michigan, Translat Imaging Lab, Detroit, MI 48201 USA.
   [Chugani, Carla D.] Florida Gulf Coast Univ, Coll Educ, Ft Myers, FL USA.
C3 Wayne State University; Wayne State University; Wayne State University;
   Wayne State University; Children's Hospital of Michigan; State
   University System of Florida; Florida Gulf Coast University
RP Jeong, JW (corresponding author), Wayne State Univ, Childrens Hosp Michigan, Dept Pediat & Neurol, PET Ctr, 3901 Beaubien Blvd, Detroit, MI 48201 USA.
EM jeongwon@pet.wayne.edu
OI Chugani, Carla/0000-0003-3993-3679
CR Adolphs R, 2002, CURR OPIN NEUROBIOL, V12, P169, DOI 10.1016/S0959-4388(02)00301-X
   [Anonymous], 2003, BREDE DATABASE SMALL
   Baumgartner T, 2006, BRAIN RES, V1075, P151, DOI 10.1016/j.brainres.2005.12.065
   Blau V, 2008, EUR J NEUROSCI, V28, P500, DOI 10.1111/j.1460-9568.2008.06350.x
   Calvert GA, 2000, CURR BIOL, V10, P649, DOI 10.1016/S0960-9822(00)00513-3
   Calvert GA, 1999, NEUROREPORT, V10, P2619, DOI 10.1097/00001756-199908200-00033
   Calvert GA, 2001, NEUROIMAGE, V14, P427, DOI 10.1006/nimg.2001.0812
   Campanella S, 2007, TRENDS COGN SCI, V11, P535, DOI 10.1016/j.tics.2007.10.001
   Collignon O, 2008, BRAIN RES, V1242, P126, DOI 10.1016/j.brainres.2008.04.023
   De Gelder B, 2003, TRENDS COGN SCI, V7, P460, DOI 10.1016/j.tics.2003.08.014
   de Gelder B, 2000, COGNITION EMOTION, V14, P321, DOI 10.1080/026999300378842
   de Gelder B, 2005, SCHIZOPHR RES, V72, P195, DOI 10.1016/j.schres.2004.02.013
   Doehrmann O, 2010, J NEUROSCI, V30, P3370, DOI 10.1523/JNEUROSCI.5074-09.2010
   Dolan RJ, 2001, P NATL ACAD SCI USA, V98, P10006, DOI 10.1073/pnas.171288598
   Eldar E, 2007, CEREB CORTEX, V17, P2828, DOI 10.1093/cercor/bhm011
   ERWIN RJ, 1992, PSYCHIAT RES, V42, P231, DOI 10.1016/0165-1781(92)90115-J
   Ethofer T, 2006, HUM BRAIN MAPP, V27, P707, DOI 10.1002/hbm.20212
   GABRIELSSON A, 2002, MUSIC EMOTION THEORY, P432
   Gagnon L, 2003, COGNITION EMOTION, V17, P25, DOI 10.1080/02699930302279
   Grill-Spector K, 2006, TRENDS COGN SCI, V10, P14, DOI 10.1016/j.tics.2005.11.006
   Gur RC, 2002, NEUROIMAGE, V16, P651, DOI 10.1006/nimg.2002.1097
   Haxby JV, 2000, TRENDS COGN SCI, V4, P223, DOI 10.1016/S1364-6613(00)01482-0
   Hertrich I, 2011, J COGNITIVE NEUROSCI, V23, P221, DOI 10.1162/jocn.2010.21421
   Koenigsberg HW, 2009, PSYCHIAT RES-NEUROIM, V172, P192, DOI 10.1016/j.pscychresns.2008.07.010
   Lipscomb SD., 1994, Psychomusicology: A Journal of Research in Music Cognition, V13, P60, DOI DOI 10.1037/H0094101
   Logeswaran N, 2009, NEUROSCI LETT, V455, P129, DOI 10.1016/j.neulet.2009.03.044
   Massaro DW, 1996, PSYCHON B REV, V3, P215, DOI 10.3758/BF03212421
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Mitterschiffthaler MT, 2007, HUM BRAIN MAPP, V28, P1150, DOI 10.1002/hbm.20337
   Peretz I, 1998, MEM COGNITION, V26, P884, DOI 10.3758/BF03201171
   Pourtois G, 2005, CORTEX, V41, P49, DOI 10.1016/S0010-9452(08)70177-1
   Rigg M, 1937, J EXP PSYCHOL, V21, P223, DOI 10.1037/h0056146
   Summerfield C, 2008, NAT NEUROSCI, V11, P1004, DOI 10.1038/nn.2163
   Tournoux P., 1997, Co-Planar Stereotaxis Atlas of the Human Brain
   van Atteveldt N, 2004, NEURON, V43, P271, DOI 10.1016/j.neuron.2004.06.025
   van Atteveldt NM, 2007, NEUROIMAGE, V36, P1345, DOI 10.1016/j.neuroimage.2007.03.065
   van Atteveldt NM, 2010, BMC NEUROSCI, V11, DOI 10.1186/1471-2202-11-11
   Van den Stock J, 2009, BRAIN TOPOGR, V21, P216, DOI 10.1007/s10548-009-0099-0
NR 38
TC 48
Z9 55
U1 3
U2 57
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD FEB 14
PY 2011
VL 54
IS 4
BP 2973
EP 2982
DI 10.1016/j.neuroimage.2010.11.017
PG 10
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA 710FH
UT WOS:000286495800038
PM 21073970
DA 2024-01-09
ER

PT J
AU Lieck, R
   Rohrmeier, M
AF Lieck, Robert
   Rohrmeier, Martin
TI Discretisation and continuity: The emergence of symbols in communication
SO COGNITION
LA English
DT Article
DE Communication games; Reinforcement learning; Language evolution; Symbol
   grounding; Discretisation
ID LANGUAGE-ACQUISITION; SELF-ORGANIZATION; SPEECH; EVOLUTION; MUSIC;
   REPRESENTATION; OPTIMIZATION; CATEGORIES; EMOTIONS; WHALES
AB Vocal signalling systems, as used by humans and various non-human animals, exhibit discrete and continuous properties that can naturally be used to express discrete and continuous information, such as distinct words to denote objects in the world and prosodic features to convey the emotions of the speaker. However, continuous aspects are not always expressed with the continuous properties of an utterance but are frequently categorised into discrete symbols. While the existence of symbols in communication is self-evident, the emergence of discretisation from a continuous space is not well understood. In this paper, we investigate the emergence of discrete symbols in regions with a continuous semantics by simulating the learning process of two agents that acquire a shared signalling system. The task is formalised as a reinforcement learning problem with a continuous form and meaning space. We identify two causes for the emergence of discretisation that do not originate in discrete semantics: 1) premature convergence to sub-optimal signalling conventions and 2) topological mismatch between the continuous form space and the continuous semantic space. The insights presented in this paper shed light on the origins of discrete symbols, whose existence is assumed by a large body of research concerned with the emergence of syntactic structures and meaning in language.
C1 [Lieck, Robert; Rohrmeier, Martin] Ecole Polytech Fed Lausanne, Digital & Cognit Musicol Lab, CH-1015 Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP Lieck, R (corresponding author), Ecole Polytech Fed Lausanne, Digital & Cognit Musicol Lab, CH-1015 Lausanne, Switzerland.
EM research@robert-lieck.com
OI Rohrmeier, Martin Alois/0000-0002-4323-7257
FU European Research Council (ERC) under the European Union [760081 -PMSB]
FX We thank Jacob Feldman, Leona Wall and two anonymous reviewers for their
   very helpful comments on this manuscript. This project has received
   funding from the European Research Council (ERC) under the European
   Union's Horizon 2020 research and innovation programme under grant
   agreement No 760081 -PMSB. This project was conducted at the Latour
   Chair in Digital and Cognitive Musicology, generously funded by Mr.
   Claude Latour.
CR [Anonymous], 2004, CONCEPTUAL SPACES GE
   [Anonymous], 2006, Pattern Recognition and Machine Learning
   [Anonymous], 2016, EVOLUTION GROUNDED S
   [Anonymous], 1990, HDB SEMIOTICS
   Baronchelli A, 2006, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2006/06/P06014
   Bengio Y., 2009, P 26 ANN INT C MACH, P41, DOI DOI 10.1145/1553374.1553380
   Berlin Brent, 1969, Basic Color Terms: Their Universality and Evolution
   Bleys J., 2009, GROUNDED COLOUR NAMI
   Brighton H, 2006, ARTIF LIFE, V12, P229, DOI 10.1162/106454606776073323
   Cangelosi A., 2002, Simulating the evolution of language
   Chandler D., 2017, Semiotics: The basics, V3rd ed.
   Chew E., 2000, THESIS MASSACHUSETTS
   Christiansen MH, 2003, LANGUAGE EVOLUTION
   Cohn R, 1997, J MUSIC THEORY, V41, P1, DOI 10.2307/843761
   Cover T. M., 2005, Elements of information theory, DOI DOI 10.1002/047174882X
   de Boer B, 2000, J PHONETICS, V28, P441, DOI 10.1006/jpho.2000.0125
   de Boer B., 2012, EVOLUTION LANGUAGE, P424
   De Boer B, 2012, ADV COMPLEX SYST, V15, DOI 10.1142/S0219525911500214
   de Jong ED, 1999, LECT NOTES ARTIF INT, V1674, P689
   De Vylder B, 2006, J THEOR BIOL, V242, P818, DOI 10.1016/j.jtbi.2006.05.024
   DEKKERS A, 1991, MATH PROGRAM, V50, P367, DOI 10.1007/BF01594945
   Dimos K., 2015, PERCEPTION LEVELS EM
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   Ellison TM, 2013, LECT NOTES COMPUT SC, V7070, P131, DOI 10.1007/978-3-642-44958-1_10
   Euler L., 1739, Tentamen novae theoriae musicae ex certissismis harmoniae principiis dilucide expositae
   Feldman J, 2012, COGNITION, V123, P61, DOI 10.1016/j.cognition.2011.12.008
   Gibson E, 2017, P NATL ACAD SCI USA, V114, P10785, DOI 10.1073/pnas.1619666114
   Hastie T., 2009, ELEMENTS STAT LEARNI, V1
   HURFORD JR, 1989, LINGUA, V77, P187, DOI 10.1016/0024-3841(89)90015-6
   Janik VM, 2006, P NATL ACAD SCI USA, V103, P8293, DOI 10.1073/pnas.0509918103
   Janik VM, 2009, ADV STUD BEHAV, V40, P123, DOI 10.1016/S0065-3454(09)40004-4
   Janik VM, 1997, ADV STUD BEHAV, V26, P59, DOI 10.1016/S0065-3454(08)60377-0
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   KAY P, 2003, WORLD COLOR SURVEY
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Koelsch S., 2013, Brain and music
   KRUMHANSL CL, 1982, PSYCHOL REV, V89, P334, DOI 10.1037/0033-295X.89.4.334
   Krumhansl CL, 1998, J MUSIC THEORY, V42, P265, DOI 10.2307/843878
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   LADEFOGED P, 1990, J PHONETICS, V18, P93, DOI 10.1016/S0095-4470(19)30396-1
   Lagoudakis MG, 2004, J MACH LEARN RES, V4, P1107, DOI 10.1162/1532443041827907
   Lake BM, 2017, BEHAV BRAIN SCI, V40, DOI 10.1017/S0140525X16001837
   Levy Roger., 2007, Advances in neural information processing systems (NIPS), V19, P849
   Liebenthal E, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00506
   Lieck R., 2018, THESIS U STUTTGART, DOI [10.18419/opus-10068, DOI 10.18419/OPUS-10068]
   Lieck R., 2020, T INT SOC MUSIC INFO, V3, P153, DOI [10.5334/tismir.46, DOI 10.5334/TISMIR.46]
   Little H, 2017, COGNITION, V168, P1, DOI 10.1016/j.cognition.2017.06.011
   MacKay D.J., 2003, INFORM THEORY INFERE
   Marino L, 2007, PLOS BIOL, V5, P966, DOI 10.1371/journal.pbio.0050139
   Meyer LB., 1956, Emotion and meaning in music
   Milne AJ, 2016, J MATH MUSIC, V10, P59, DOI 10.1080/17459737.2016.1152517
   Moulin-Frier C, 2012, J IEEE I C DEVELOP L
   Moulin-Frier C, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01006
   Murakamli M, 2015, 5TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND ON EPIGENETIC ROBOTICS (ICDL-EPIROB), P208, DOI 10.1109/DEVLRN.2015.7346142
   Nolfi S, 2010, EVOLUTION OF COMMUNICATION AND LANGUAGE IN EMBODIED AGENTS, P1, DOI 10.1007/978-3-642-01250-1
   Nowak MA, 1999, P NATL ACAD SCI USA, V96, P8028, DOI 10.1073/pnas.96.14.8028
   Ogden CK., 1923, The meaning of meaning: a study of the influence of language upon thought and of the science of symbolism
   Oliphant M., 1997, CTR RES LANGUAGE NEW, V11, P1
   Ouattara K, 2009, P NATL ACAD SCI USA, V106, P22026, DOI 10.1073/pnas.0908118106
   Oudeyer Pierre-Yves, 2007, Cogn Process, V8, P21, DOI 10.1007/s10339-006-0158-3
   Oudeyer PY, 2005, J THEOR BIOL, V233, P435, DOI 10.1016/j.jtbi.2004.10.025
   Patel AD, 2003, NAT NEUROSCI, V6, P674, DOI 10.1038/nn1082
   Patel AD, 2010, MUSIC LANGUAGE BRAIN
   Pearce M, 2012, TOP COGN SCI, V4, P468, DOI 10.1111/j.1756-8765.2012.01226.x
   Peirce C. S., 1974, COLLECTED PAPERS CS, V2
   Piantadosi ST, 2011, P NATL ACAD SCI USA, V108, P3526, DOI 10.1073/pnas.1012551108
   Pierre-Yves O, 2003, INT J HUM-COMPUT ST, V59, P157, DOI 10.1016/S1071-5819(03)00141-6
   Rendell L, 2001, BEHAV BRAIN SCI, V24, P309, DOI 10.1017/S0140525X0100396X
   Riemann H., 1896, DICT MUSIC
   Roberson D, 2004, J EXP PSYCHOL GEN, V133, P554, DOI 10.1037/0096-3445.133.4.554
   Robert CP, 2004, MONTE CARLO STAT MET, DOI DOI 10.1007/978-1-4757-4145-2
   Robins R. H., 2014, GEN LINGUIST, V4th
   Sandhofer CM, 1999, DEV PSYCHOL, V35, P668, DOI 10.1037/0012-1649.35.3.668
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Schroder M, 2001, P 7 EUR C SPEECH COM, P561, DOI DOI 10.21437/EUROSPEECH.2001-150
   Sethares WA., 2005, Tuning, Timbre, Spectrum, Scale, V2nd ed
   Shannon C. E., 1959, IRE National Convention Record, V7, P325
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   SHEPARD RN, 1964, J ACOUST SOC AM, V36, P2346, DOI 10.1121/1.1919362
   Steels L, 2005, BEHAV BRAIN SCI, V28, P469, DOI 10.1017/S0140525X05000087
   Steels L., 1998, APPROACHES EVOLUTION, P384
   Steels L., 1997, EVOLUTION COMMUNICAT, V1, P1, DOI DOI 10.1075/E0C.1.1.02STE
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Vallabha GK, 2007, P NATL ACAD SCI USA, V104, P13273, DOI 10.1073/pnas.0705369104
   Van Eecke P., 2020, AAAI SPR S CHALL OPP
   Wilbrecht L, 2003, MENT RETARD DEV D R, V9, P135, DOI 10.1002/mrdd.10073
   Wittgenstein Ludwig., 2009, PHILOS INVESTIGATION
   Yurk H, 2002, ANIM BEHAV, V63, P1103, DOI 10.1006/anbe.2002.3012
   Zaslavsky N, 2018, P NATL ACAD SCI USA, V115, P7937, DOI 10.1073/pnas.1800521115
   Zuidema W, 2003, ARTIF LIFE, V9, P387, DOI 10.1162/106454603322694834
NR 91
TC 1
Z9 1
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD OCT
PY 2021
VL 215
AR 104787
DI 10.1016/j.cognition.2021.104787
EA JUL 2021
PG 24
WC Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA TZ2GM
UT WOS:000684293800006
PM 34303183
OA Green Published, hybrid
DA 2024-01-09
ER

PT J
AU He, B
AF He, Bing
TI Video teaching of piano playing and singing based on computer artificial
   intelligence system and virtual image processing
SO JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING
LA English
DT Article; Early Access
DE Artificial intelligence; Image processing; Piano playing and singing;
   Video teaching
ID EMOTIONS
AB As an important part of vocal guidance, piano performance and singing guidance are important ways to cultivate students' interest in piano and improve their improvisational level. With the development of education, especially the rapid popularization and promotion of big data and other information technologies, traditional teacher-led performance and singing teaching models have gradually met the learning needs of students and affected their learning effects. Therefore, it is indispensable to reform and innovate the guiding philosophy and methods of performance and songs. Therefore, how to introduce big data technology into piano performance and singing guidance is worthy of in-depth discussion. Online education has obvious advantages in auditory training. Whether it is impromptu feedback through online classrooms, or completion of homework through audio, it can have the effect of "grinding ears". On the one hand, the clear audio allows students to think aurally in a good auditory environment; on the other hand, through online interactive answering, teachers can accurately understand the development of the auditory perception of the entire class, so as to adjust the training content immediately. The subject studied the problems existing in the teaching of traditional piano playing and singing, and proposed different solutions for the computer artificial intelligence system and virtual image processing technology, so that image classification and video teaching have a better recognition effect, and promote vocal music teaching forward development of.
C1 [He, Bing] Sichuan Normal Univ, Mus Coll, Chengdu 610066, Sichuan, Peoples R China.
C3 Sichuan Normal University
RP He, B (corresponding author), Sichuan Normal Univ, Mus Coll, Chengdu 610066, Sichuan, Peoples R China.
EM hebing82@126.com
CR Ahn H, 2005, LECT NOTES COMPUT SC, V3784, P866
   BURKARD RE, 1982, MATH PROGRAM, V23, P227, DOI 10.1007/BF01583791
   BURKARD RE, 1985, DISCRETE APPL MATH, V12, P21, DOI 10.1016/0166-218X(85)90037-X
   Cabanac M., 1981, STUD ENV SCI, V10, P181, DOI [10.1016/S0166-1116(08)71089-6.C, DOI 10.1016/S0166-1116(08)71089-6.C]
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   Deng J, 2017, IEEE SIGNAL PROC LET, V24, P500, DOI 10.1109/LSP.2017.2672753
   FARMER R, 1986, J PERS ASSESS, V50, P4, DOI 10.1207/s15327752jpa5001_2
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Feng W, 2008, IEEE T IMAGE PROCESS, V17, P2413, DOI 10.1109/TIP.2008.2006435
   Feng W, 2010, IEEE T PATTERN ANAL, V32, P1871, DOI 10.1109/TPAMI.2010.24
   Giatsoglou M, 2017, EXPERT SYST APPL, V69, P214, DOI 10.1016/j.eswa.2016.10.043
   Hall Mark, 2009, SIGKDD Explorations, V11, P10, DOI [10.1145/1656274.1656278, DOI 10.1145/1656274.1656278]
   He XB, 2004, J PARALLEL DISTR COM, V64, P1069, DOI 10.1016/j.jpdc.2004.05.005
   John G. H., 1995, Uncertainty in Artificial Intelligence. Proceedings of the Eleventh Conference (1995), P338
   Kanjo E, 2015, PERS UBIQUIT COMPUT, V19, P1197, DOI 10.1007/s00779-015-0842-3
   Liu JD, 2007, STUD COMPUT INTELL, V50, P121
   Pinchin S, 2013, J ARCHIT CONSERV, V4119, P1
   Power M, 2000, HDB COGNITION EMOTIO, P45
   Qing Guo, 2017, IEEE Trans Image Process, V26, P5692, DOI 10.1109/TIP.2017.2745205
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   Tighe J, 2013, PROC CVPR IEEE, P3001, DOI 10.1109/CVPR.2013.386
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
NR 22
TC 6
Z9 6
U1 0
U2 30
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1868-5137
EI 1868-5145
J9 J AMB INTEL HUM COMP
JI J. Ambient Intell. Humaniz. Comput.
PD 2021 APR 4
PY 2021
DI 10.1007/s12652-021-03099-8
EA APR 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA RI0ZF
UT WOS:000636637400003
DA 2024-01-09
ER

PT J
AU Joseph, D
   Human, R
AF Joseph, Dawn
   Human, Rene
TI "It Is More Than Just about Music": Lifelong Learning, Social
   Interaction and Connection
SO MUZIKI-JOURNAL OF MUSIC RESEARCH IN AFRICA
LA English
DT Article
DE community music; positive emotion; engagement; relationships and
   meaning; and accomplishment; music learning; serious leisure; wellbeing
AB For older people, participating in leisure activities enhances their sense of social, emotional, mental, spiritual and psychological wellbeing. This article reports on a case study that situated itself across two southern hemisphere countries - Australia and South Africa - and with two ensembles, namely: an instrumental ensemble in Melbourne (all musical readers); and a vocal ensemble in Clarens (all non-readers of music). The authors drew on Seligman's elements of positive emotion, engagement, relationships and meaning, and accomplishment (PERMA) to explore the ensemble members' engagement as "serious leisure and the wider community". Using qualitative case study methodology, they employed interpretative phenomenological analysis (IPA) as an organising tool to analyse and code their questionnaires and interview data. The findings are presented under three overarching themes, namely: meeting for serious leisure; music learning; and connecting with the wider community. While music engagement for older adults is an achievement in itself, sharing it with the wider community is considered most significant for the participants. Discussing two ensembles is a limitation in itself, therefore generalisations to other ensembles cannot be made. The article was written in 2020 during the COVID-19 lockdown period in both countries. Further research is planned across both countries to explore any implications the lockdown has had on the two groups once they are permitted to recommence rehearsals.
C1 [Joseph, Dawn] Deakin Univ, Geelong, Vic, Australia.
   [Human, Rene] Univ Pretoria, Pretoria, South Africa.
C3 Deakin University; University of Pretoria
RP Joseph, D (corresponding author), Deakin Univ, Geelong, Vic, Australia.
EM dawn.joseph@deakin.edu.au
RI Joseph, Dawn/JUF-6795-2023
OI Joseph, Dawn/0000-0002-6320-900X; Human, Rene/0000-0002-4497-614X
CR Adams KB, 2011, AGEING SOC, V31, P683, DOI 10.1017/S0144686X10001091
   Amit V, 2002, EURO ASSOC SOCIAL, P1
   [Anonymous], 2006, INT J COMMUNITY MUSI
   [Anonymous], 2011, FLOURISH
   [Anonymous], 2016, P 2016 CHI C HUM FAC
   [Anonymous], 2014, CASE STUDY RES
   [Anonymous], 2003, INT J SOC RES METHOD, DOI DOI 10.1080/1364557021000024749
   Barrett M.J., 2007, VALUE CHORAL SINGING
   Bartleet B. L., 2018, The Oxford handbook of community music, P1, DOI [10.1093/oxfordhb/9780190219505.013.20, DOI 10.1093/OXFORDHB/9780190219505.013.20, 10.1093/oxfordhb/9780190219505.001.0001]
   Bartolome SJ, 2018, RES STUD MUSIC EDUC, V40, P265, DOI 10.1177/1321103X18768101
   Boulton-Lewis GM, 2018, EDUC GERONTOL, V44, P639, DOI 10.1080/03601277.2018.1521902
   Butler J., 2016, International Journal of Wellbeing, V6, P1, DOI [10.5502/ijw.v6i3.526, DOI 10.5502/IJW.V6I3.526]
   Cheng E, 2017, LEISURE STUD, V36, P505, DOI 10.1080/02614367.2016.1188137
   Coffman D. D., 2002, Psychomusicology, V18, P76, DOI DOI 10.1037/H0094050
   Cohen L., 2000, Research methods in education
   Creech A, 2014, PSYCHOL MUSIC, V42, P430, DOI 10.1177/0305735613478313
   Creech A, 2013, RES STUD MUSIC EDUC, V35, P87, DOI 10.1177/1321103X13478862
   Daykin N, 2017, PERSPECT PUBLIC HEAL, V137, P281, DOI 10.1177/1757913916674038
   Delahaye BL, 2008, EDUC GERONTOL, V34, P649, DOI 10.1080/03601270801900875
   Dingle G.A., 2019, MUSIC SCI, V2, P1, DOI DOI 10.1177/2059204319861719
   Dingle GA, 2013, PSYCHOL MUSIC, V41, P405, DOI 10.1177/0305735611430081
   Dufourmantelle Ann, 2000, HOSPITALITY
   Flyvbjerg B, 2006, QUAL INQ, V12, P219, DOI 10.1177/1077800405284363
   Forgeard M. J., 2011, International Journal of Wellbeing, V1, P79, DOI [10.5502/ijw.vlil.15, 10.5502/ijw.v1i1.15, DOI 10.5502/IJW.V1I1.15]
   French M.K., 2017, ONLINE MUSIC ED FUEL
   Gardiner MF, 1996, NATURE, V381, P284, DOI 10.1038/381284a0
   Garofalo R., 2020, HONK STREET BAND REN, DOI [https://doi.org/10.4324/9780429020209, DOI 10.4324/9780429020209]
   Goodman FR., 2017, J POSIT PSYCHOL, V13, P321, DOI DOI 10.1080/17439760.2017.1388434
   Hallam S., 2008, HDB MUSIC PSYCHOL, P471, DOI DOI 10.1093/OXFORDHB/9780199298457.013.0044
   Hallam S, 2016, INT J MUSIC EDUC, V34, P19, DOI 10.1177/0255761415617039
   Hallam S, 2012, J ADULT CONTIN EDUC, V18, P21, DOI 10.7227/JACE.18.2.3
   Harrison H., 2017, FORUM QUALITATIVE SO, V18, P26
   Hays T, 2005, AGEING SOC, V25, P261, DOI 10.1017/S0144686X04002946
   Heath G, 2015, HEALTH PLACE, V31, P46, DOI 10.1016/j.healthplace.2014.10.014
   HIGGINS Lee, 2012, Community Music In Theory and
   Howell Gillian., 2017, OXFORD HDB MUSIC MAK, P601
   Hunt S. J., 2004, Leisure Studies, V23, P387, DOI 10.1080/0261436042000231664
   Iasiello M., 2017, Journal of Positive Psychology and Wellbeing, V1, P53
   Joseph D., 2018, CREATIVE IND J, V11, P158, DOI [https://doi.org/10.1080/17510694.2018.1434360, DOI 10.1080/17510694.2018.1434360]
   Joseph D, 2020, INT J MUSIC EDUC, V38, P177, DOI 10.1177/0255761419880027
   Kelsey-Sugg A., 2020, WERE TURNING MUSIC C
   Kern ML, 2015, J POSIT PSYCHOL, V10, P262, DOI 10.1080/17439760.2014.936962
   Kirkham JA, 2015, HEALTH PSYCHOL, V34, P398, DOI 10.1037/hea0000139
   Kokotsaki D., 2007, Music Education Research, V9, P93, DOI [10.1080/14613800601127577, DOI 10.1080/14613800601127577]
   Lamont A, 2018, PSYCHOL MUSIC, V46, P424, DOI 10.1177/0305735617715514
   Lamont M, 2014, LEISURE SCI, V36, P144, DOI 10.1080/01490400.2013.857623
   Lee J, 2016, INT J COMMUNITY MUSI, V9, P191, DOI 10.1386/ijcm.9.2.191_1
   Lee J, 2017, RES STUD MUSIC EDUC, V39, P73, DOI 10.1177/1321103X17703131
   MacDonald R., 2012, MUSIC HLTH WELLBEING, P3, DOI [DOI 10.1093/ACPROF:O-SO/9780199586974.003.0001, 10.1093/acprof:oso/9780199586974.003, DOI 10.1093/ACPROF:OSO/9780199586974.003]
   MacDonald RAR, 2013, INT J QUAL STUD HEAL, V8, DOI 10.3402/qhw.v8i0.20635
   Mansfield L, 2020, LEISURE STUD, V39, P1, DOI 10.1080/02614367.2020.1713195
   Mariano C., 2001, QUALITATIVE PERSPECT, P359
   McLeod M, 2007, CONTEMP NURSE, V25, P104, DOI 10.5172/conu.2007.25.1-2.104
   Mersham G.M., 2000, MOTS PLURIELS, V13
   Music Australia, 2020, MUSIC COMMUNITY
   North AC, 2004, MUSIC PERCEPT, V22, P41, DOI 10.1525/mp.2004.22.1.41
   Pietkiewicz I., 2014, PSYCHOL J, V20, P7, DOI [DOI 10.14691/CPPJ.20.1.7, 10.14691/CPPJ.20.1.7]
   Poth CN., 2016, QUAL INQ
   Prior D, 2017, J MUSIC TECHNOL EDUC, V10, P197, DOI 10.1386/jmte.10.2-3.197_1
   Rofe M, 2017, J MUSIC TECHNOL EDUC, V10, P147, DOI 10.1386/jmte.10.2-3.147_1
   Schuller Tom., 2009, Learning Through Life: Inquiry into the Future of Lifelong Learning
   Seligman M. E., 2012, Flourishing: A Visionary New Understanding of Happiness and Well-being
   Seligman M, 2018, J POSIT PSYCHOL, V13, P333, DOI 10.1080/17439760.2018.1437466
   Selph C.S, 2014, RES PERSPECTIVES MUS, V16, P32, DOI [https://doi.org/10.1177/8755123314521034, DOI 10.1177/8755123314521034]
   Smith J., 2009, Interpretative phenomenological analysis: Theory, Method and research, DOI DOI 10.1080/14780880903340091
   Smith J., 2004, Qualitative Research in Psychology, V1, P39, DOI [10.1191/1478088704qp004oa, DOI 10.1191/1478088704QP004OA]
   Smith JA, 2017, J POSIT PSYCHOL, V12, P303, DOI 10.1080/17439760.2016.1262622
   Stebbins, 2017, SERIOUS LEISURE PERS, DOI [10.4324/9781315129174, DOI 10.4324/9781315129174]
   Stebbins R., 1992, Amateurs, professionals, and serious leisure, DOI DOI 10.1515/9780773563346
   Stebbins R. A., 1997, Leisure Studies, V16, P17, DOI 10.1080/026143697375485
   Stebbins R.A, 2011, AM SOCIOL, V42, DOI https://doi.org/1007/s12108-011-9126-1
   STEBBINS RA, 1982, PAC SOCIOL REV, V25, P251
   Stebbins RA, 2009, LIBR TRENDS, V57, P618
   Stebbins RobertA., 2015, SERIOUS LEISURE
   Taylor A, 2008, MUSIC EDUC RES, V10, P285, DOI 10.1080/14613800802079148
   Taylor S.E., 2011, OXFORD HDB HLTH PSYC
   Veblen KK, 2007, INT J COMMUNITY MUSI, V1, P5, DOI 10.1386/ijcm.1.1.5_1
   Veblen K.K., 2016, SPECIAL NEEDS COMMUN, V4, P243
   Waldron J, 2009, J MUSIC TECHNOL EDUC, V2, P97, DOI 10.1386/jmte.2.2-3.97_1
   WATSON D, 1985, PSYCHOL BULL, V98, P219, DOI 10.1037/0033-2909.98.2.219
   Williams E, 2019, J APPL SOC PSYCHOL, V49, P15, DOI 10.1111/jasp.12561
   Yair G., 1992, Leisure Studies, V11, P257, DOI 10.1080/02614369200390131
NR 82
TC 4
Z9 4
U1 0
U2 10
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1812-5980
EI 1753-593X
J9 MUZIKI
JI Muziki
PD JAN 2
PY 2020
VL 17
IS 1
BP 72
EP 93
DI 10.1080/18125980.2020.1855082
EA FEB 2021
PG 22
WC Music
WE Emerging Sources Citation Index (ESCI)
SC Music
GA QY7EC
UT WOS:000620571000001
OA Green Submitted
DA 2024-01-09
ER

PT J
AU Hansen, NC
   Huron, D
AF Hansen, Niels Chr.
   Huron, David
TI THE LONE INSTRUMENT: MUSICAL SOLOS AND SADNESS-RELATED FEATURES
SO MUSIC PERCEPTION
LA English
DT Article
DE emotion; music analysis; instrumental music; cognitive musicology;
   corpus
ID VOCAL EXPRESSION; MINOR MODES; SPEECH RATE; PITCH; EMOTIONS; PERCEPTION;
   RHYTHM; DEPRESSION; HAPPINESS; LANGUAGE
AB GIVEN THE EXTENSIVE INSTRUMENTAL RESOURCES afforded by an orchestra, why would a composer elect to feature a single solo instrument? In this study we explore one possible use of solos-that of conveying or enhancing a sad affect. Orchestral passages were identified from an existing collection and categorized as solos or non-solos. Independently, the passages were characterized on seven other features previously linked to sad affect, including mode, tempo, dynamics, articulation, rhythmic smoothness, relative pitch height, and pitch range. Using the first four factors, passages were classified into nine previously defined expressive categories. Passages containing acoustic features associated with the "sad/relaxed'' expressive category were twice as likely to employ solo texture. Moreover, a regression model incorporating all factors significantly predicted solo status. However, only two factors (legato articulation, quiet dynamics) were significant individual predictors. Finally, with the notable exception of string instruments, we found a strong correlation (rho = .88) between the likelihood that a solo is assigned to a given instrument and an independent scale of the capacity of that instrument for expressing sadness. Although solo instrumentation undoubtedly serves many other functions, these results are consistent with a significant though moderate association between sadness-related acoustic features and solo textures.
C1 [Hansen, Niels Chr.; Huron, David] Ohio State Univ, Columbus, OH 43210 USA.
C3 University System of Ohio; Ohio State University
RP Hansen, NC; Huron, D (corresponding author), Ohio State Univ, Sch Mus, 1866 Coll Rd, Columbus, OH 43210 USA.
EM hansen.491@osu.edu; huron.1@osu.edu
RI Hansen, Niels Chr./AAE-8484-2021
OI Hansen, Niels Chr./0000-0003-2142-6484
CR Adachi M., 1998, PSYCHOL MUSIC, V26, P133, DOI [DOI 10.1177/0305735698262003, 10.1177/0305735698262003]
   Adler, 2002, STUDY ORCHESTRATION
   Andrews PW, 2009, PSYCHOL REV, V116, P620, DOI 10.1037/a0016242
   [Anonymous], THESIS
   [Anonymous], 2000, LANG SPEECH
   [Anonymous], 1964, COMMUNICATION EMOTIO
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Barlow Harold, 1948, DICT MUSICAL THEMES
   BERGMANN G, 1988, Z EXP ANGEW PSYCHOL, V35, P167
   BERLIOZ L. H, 2002, BERLIOZS ORCHESTRATI
   Blatter Alfred, 1980, INSTRUMENTATION ORCH
   Breitenstein C, 2001, COGNITION EMOTION, V15, P57, DOI 10.1080/0269993004200114
   CHON S. H, EMPIRICAL MUSICOLOGY
   Chordia P., 2010, P 11 INT C MUS PERC, P63
   CHORDIA P, 2011, SOC MUS PERC C ROCH
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Darwin C., 1872, The Expression of the Emotions in Man and Animals
   de Carvalho JB, 2008, STUD GENERAT GRAMM, V99, P415
   DURICHEN C, 1991, ORCHESTER PROBESPIEL
   ELDRED SH, 1958, PSYCHIATR, V21, P115
   Fairbanks G, 1939, SPEECH MONOGR, V6, P87, DOI 10.1080/03637753909374863
   Forsyth Cecil, 1914, ORCHESTRATION
   Gertheiss J, 2009, INT STAT REV, V77, P345, DOI 10.1111/j.1751-5823.2009.00088.x
   GEVAERT F.-A, 1885, NOUVEAU TRAITED INST
   Hannon EE, 2009, COGNITION, V111, P403, DOI 10.1016/j.cognition.2009.03.003
   Hansen N. C, 2013, HIST NARRATIVES MUSI, P597
   Hansen NC, 2016, MUSIC PERCEPT, V33, P414, DOI 10.1525/MP.2016.33.4.414
   Heinlein CP, 1928, J COMP PSYCHOL, V8, P101, DOI 10.1037/h0070573
   Hevner K, 1935, AM J PSYCHOL, V47, P103, DOI 10.2307/1416710
   Hevner K, 1937, AM J PSYCHOL, V49, P621, DOI 10.2307/1416385
   Hong Y, 2017, J AUDIO ENG SOC, V65, P304, DOI 10.17743/jaes.2017.0001
   Honorof DN, 2005, J ACOUST SOC AM, V117, P2193, DOI 10.1121/1.1841751
   HORN K., 2012, P 12 INT C MUS PERC, P456
   Horn K, 2015, MUSIC THEORY ONLINE, V21
   Huron D, 2003, MUSIC PERCEPT, V21, P267, DOI 10.1525/mp.2003.21.2.267
   Huron D, 2014, EMPIR MUSICOL REV, V9, P29
   Huron D, 2016, EMPIR MUSICOL REV, V11, P261
   Huron D, 2008, EMPIR MUSICOL REV, V3, P59, DOI 10.18061/1811/31940
   Huron David, 2016, VOICE LEADING SCI MU
   Husain G, 2002, MUSIC PERCEPT, V20, P151, DOI 10.1525/mp.2002.20.2.151
   HUTTAR GL, 1968, J SPEECH HEAR RES, V11, P481, DOI 10.1044/jshr.1103.481
   Juslin P. N., 1996, PSYCHOL MUSIC, V24, P68, DOI [10.1177/0305735696241007, DOI 10.1177/0305735696241007]
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   KENNAN K., 1997, TECHNIQUE ORCHESTRAT
   Kienast M., 2000, ISCA TUTORIAL RES WO
   Kienast M., 1999, 6 EUR C SPEECH COMM
   Koechlin C., 1954, TRAITE ORCHESTRATION
   Kraepelin E, 1921, Manic-depressive insanity and paranoia
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   Ladinig O, 2010, EMPIR MUSICOL REV, V5, P51, DOI 10.18061/1811/46762
   London J, 2011, MUSIC PERCEPT, V29, P115, DOI 10.1525/MP.2011.29.1.115
   MARTIN S, 2012, YOU CANT PLAY SAD SO
   MICHELSON M. J, 2014, ACETYLCHOLINE APPROA
   NESSE RM, 1991, SCIENCES, V31, P30, DOI 10.1002/j.2326-1951.1991.tb02346.x
   Patel AD, 2003, MUSIC PERCEPT, V21, P273, DOI 10.1525/mp.2003.21.2.273
   Patel AD, 2003, COGNITION, V87, pB35, DOI 10.1016/S0010-0277(02)00187-7
   PISTON Walter, 1969, Orchestration
   Post O, 2009, EMPIR MUSICOL REV, V4, P2, DOI 10.18061/1811/36601
   Quinto L, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00184
   RASMUSSEN K.-A, 2017, IDIOMATIC ORCHESTRA
   Rigg M, 1937, J EXP PSYCHOL, V21, P223, DOI 10.1037/h0056146
   Rimsky-Korsakov Nicolai, 1964, PRINCIPLES ORCHESTRA
   Romesburg H. C., 2004, Cluster Analysis for Researchers
   Scherer K., 1977, MOTIV EMOTION, V1, P331, DOI [DOI 10.1007/BF00992539, 10.1007/bf00992539]
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   Scherer KR, 2003, SER AFFECTIVE SCI, P433
   Schutz M, 2008, EMPIR MUSICOL REV, V3, P126, DOI 10.18061/1811/34103
   Sevsay E, 2013, CAMBRIDGE GUIDE TO ORCHESTRATION, P1
   Siegel A., 2006, Essential Neuroscience
   SIEGMAN AW, 1993, J ABNORM PSYCHOL, V102, P430, DOI 10.1037/0021-843X.102.3.430
   Skinner ER, 1935, SPEECH MONOGR, V2, P81, DOI 10.1080/03637753509374833
   Sobin C, 1999, J PSYCHOLINGUIST RES, V28, P347, DOI 10.1023/A:1023237014909
   TARTTER VC, 1980, PERCEPT PSYCHOPHYS, V27, P24, DOI 10.3758/BF03199901
   TARTTER VC, 1994, J ACOUST SOC AM, V96, P2101, DOI 10.1121/1.410151
   Tiemann L, 2011, EMPIR MUSICOL REV, V6, P147, DOI 10.18061/1811/52809
   Trainor LJ, 2014, HEARING RES, V308, P60, DOI 10.1016/j.heares.2013.07.014
   Turner B, 2008, EMPIR MUSICOL REV, V3, P64, DOI 10.18061/1811/31941
   WEDIN L, 1972, SCAND J PSYCHOL, V13, P241, DOI 10.1111/j.1467-9450.1972.tb00072.x
   Widor Charles-Marie., 1906, TECHNIQUE MODERN ORC
   WILLIAMS CE, 1972, J ACOUST SOC AM, V52, P1238, DOI 10.1121/1.1913238
   YIM G, 2014, THESIS
NR 83
TC 2
Z9 2
U1 0
U2 2
PU UNIV CALIFORNIA PRESS
PI OAKLAND
PA 155 GRAND AVE, SUITE 400, OAKLAND, CA 94612-3758 USA
SN 0730-7829
J9 MUSIC PERCEPT
JI Music Percept.
PD JUN
PY 2018
VL 35
IS 5
BP 540
EP 560
DI 10.1525/MP.2018.35.5.540
PG 21
WC Music; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music; Psychology
GA HF7SS
UT WOS:000454441300002
DA 2024-01-09
ER

PT J
AU Wali, A
   Alamgir, Z
   Karim, S
   Fawaz, A
   Ali, MB
   Adan, M
   Mujtaba, M
AF Wali, Aamir
   Alamgir, Zareen
   Karim, Saira
   Fawaz, Ather
   Ali, Mubariz Barkat
   Adan, Muhammad
   Mujtaba, Malik
TI Generative adversarial networks for speech processing: A review
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Review
DE GANs; Speech synthesis; Speech enhancement; Data augmentation; Speech
   GANs
ID WAVE-FORM GENERATION; VOICE CONVERSION; VOCODER; ENHANCEMENT
AB Generative adversarial networks (GANs) have seen remarkable progress in recent years. They are used as generative models for all kinds of data such as text, images, audio, music, videos, and animations. This paper presents a comprehensive review of the novel and emerging GANbased speech frameworks and algorithms that have revolutionized speech processing. We have categorized speech GANs based on application areas: speech synthesis, speech enhancement & conversion, and data augmentation in automatic speech recognition and emotion speech recognition systems. This review also includes a summary of the data sets and evaluation metrics commonly used in speech GANs. We also suggest some interesting research directions for future work and highlight the issues faced by current state-of-the-art speech GANs.
C1 [Wali, Aamir; Alamgir, Zareen; Karim, Saira; Fawaz, Ather; Ali, Mubariz Barkat; Adan, Muhammad; Mujtaba, Malik] FAST NUCES, Dept Comp Sci, Lahore, Pakistan.
RP Wali, A (corresponding author), FAST NUCES, Dept Comp Sci, Lahore, Pakistan.
EM aamir.wali@nu.edu.pk
RI Wali, Aamir/AAA-7028-2022
OI Wali, Aamir/0000-0002-5314-6113; Karim, Saira/0000-0002-4285-8991; ,
   Aamir/0009-0001-6571-6611; Alamgir, Zareen/0000-0002-2831-6483; Adan,
   Muhammad/0000-0002-4931-6861; Barkat Ali, Mubariz/0000-0003-1707-9803
CR Abdulatif S, 2019, 2019 INTERNATIONAL RADAR CONFERENCE (RADAR2019), P451, DOI 10.1109/RADAR41533.2019.171396
   Airaksinen M, 2016, INTERSPEECH, P2473, DOI 10.21437/Interspeech.2016-342
   [Anonymous], 2020, ARXIV PREPRINT ARXIV
   [Anonymous], 2019, ARXIV PREPRINT ARXIV
   [Anonymous], 2019, P INTERSPEECH
   [Anonymous], 2014, ARXIV PREPRINT ARXIV
   Asakura T, 2019, SOICT 2019: PROCEEDINGS OF THE TENTH INTERNATIONAL SYMPOSIUM ON INFORMATION AND COMMUNICATION TECHNOLOGY, P9, DOI 10.1145/3368926.3369662
   Atkar G, 2021, NEURAL COMPUT APPL, V33, P9353, DOI 10.1007/s00521-021-05695-3
   Baby D, 2019, INT CONF ACOUST SPEE, P106, DOI [10.1109/icassp.2019.8683799, 10.1109/ICASSP.2019.8683799]
   Berthelot D., 2017, ARXIV170310717
   Binkowski M., 2019, INT C LEARN REPR
   BOLLEPALLI B, 2019, ARXIV190305955
   Cao YX, 2020, INTERSPEECH, P3406, DOI 10.21437/Interspeech.2020-1647
   Chatziagapi A, 2019, INTERSPEECH, P171, DOI 10.21437/Interspeech.2019-2561
   Chen L.-W., 2018, ARXIV181012656
   Chen LW, 2018, INTERSPEECH, P302, DOI 10.21437/Interspeech.2018-1603
   Chen LY, 2020, NEUROCOMPUTING, V418, P211, DOI 10.1016/j.neucom.2020.08.040
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Donahue C, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5024, DOI 10.1109/ICASSP.2018.8462581
   Donahue Chris, 2018, Synthesizing audio with generative adversarial networks
   Enzner G, 2018, IEEE-ACM T AUDIO SPE, V26, P2289, DOI 10.1109/TASLP.2018.2862641
   Ericsson D., 2020, ARXIV PREPRINT ARXIV
   Eskimez SE, 2019, INT CONF ACOUST SPEE, P3717, DOI [10.1109/ICASSP.2019.8682215, 10.1109/icassp.2019.8682215]
   Fawaz A., 2021, IKSP J COMPUT SCI EN, V1
   Fu S.-W., 2019, P INT C MACH LEARN, P2031
   Fu S.-W., 2021, PROC
   Fujimoto M, 2012, INT CONF ACOUST SPEE, P4713, DOI 10.1109/ICASSP.2012.6288971
   Gao Y, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2506, DOI 10.1109/ICASSP.2018.8462018
   Goodfellow I. J., 2015, PROC INT C LEARN REP
   Gulrajani I., 2017, Adv. Neural Inform. Processing Systems, P5767, DOI [10.5555/3295222.3295327, DOI 10.5555/3295222.3295327]
   Hono Y, 2019, INT CONF ACOUST SPEE, P6955, DOI [10.1109/ICASSP.2019.8683154, 10.1109/icassp.2019.8683154]
   Hsu CC, 2017, INTERSPEECH, P3364, DOI 10.21437/Interspeech.2017-63
   Hu H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5044, DOI 10.1109/ICASSP.2018.8462624
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jolicoeur-Martineau A., 2018, INT C LEARN REPR ICL
   Juvela L, 2019, INT CONF ACOUST SPEE, P6915, DOI [10.1109/icassp.2019.8683271, 10.1109/ICASSP.2019.8683271]
   Juvela L, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5679, DOI 10.1109/ICASSP.2018.8461852
   Kameoka H, 2020, IEEE-ACM T AUDIO SPE, V28, P2982, DOI 10.1109/TASLP.2020.3036784
   Kameoka H, 2018, IEEE W SP LANG TECH, P266, DOI 10.1109/SLT.2018.8639535
   Kaneko T, 2018, EUR SIGNAL PR CONF, P2100, DOI 10.23919/EUSIPCO.2018.8553236
   Kaneko T, 2017, INTERSPEECH, P3389, DOI 10.21437/Interspeech.2017-962
   Kaneko T, 2017, INTERSPEECH, P1283, DOI 10.21437/Interspeech.2017-970
   Kaneko T, 2017, INT CONF ACOUST SPEE, P4910, DOI 10.1109/ICASSP.2017.7953090
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T., 2017, arXiv
   Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5
   Kim HY, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11020721
   Kim S., 2017, GAN, V8, P5
   Kim T, 2017, PR MACH LEARN RES, V70
   Larsen ABL, 2016, PR MACH LEARN RES, V48
   Latif S., 2018, ARXIV181111402
   Latif S, 2020, INTERSPEECH, P521, DOI 10.21437/Interspeech.2020-3194
   Lee C., 2018, ARXIV180910636
   Leyuan Sheng, 2019, 2019 International Multi-Conference on Engineering, Computer and Information Sciences (SIBIRCON). Proceedings, P0972, DOI 10.1109/SIBIRCON48586.2019.8957862
   Li S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5029, DOI 10.1109/ICASSP.2018.8462588
   Liang D, 2019, AAAI CONF ARTIF INTE, P8698
   Liu G, 2020, INT CONF ACOUST SPEE, P6624, DOI [10.1109/ICASSP40776.2020.9054060, 10.1109/icassp40776.2020.9054060]
   Liu J.-Y., 2019, ARXIV191211747
   Liu JY, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4718
   Liu JH, 2020, IEEE WCNC, DOI 10.1109/wcnc45663.2020.9120484
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Mariani G., 2018, Bagan: Data augmentation with balancing gan
   Mathur A, 2019, IPSN '19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS, P169, DOI 10.1145/3302506.3310398
   Michelsanti D, 2017, INTERSPEECH, P2008, DOI 10.21437/Interspeech.2017-1620
   Miyato Takeru, 2018, ARXIV180205637
   Morise M, 2016, IEICE T INF SYST, VE99D, P1877, DOI 10.1587/transinf.2015EDP7457
   Mustafa A, 2019, INTERSPEECH, P191, DOI 10.21437/Interspeech.2019-1195
   Oyamada K, 2017, ASIAPAC SIGN INFO PR, P182, DOI 10.1109/APSIPA.2017.8282025
   Palkama K, 2020, INTERSPEECH, P3166, DOI 10.21437/Interspeech.2020-1461
   Pandey A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5414, DOI 10.1109/ICASSP.2018.8462614
   Pascual S., 2019, ARXIV PREPRINT ARXIV
   Pascual S., 2018, PROC IBERSPEECH 2018
   Pascual S, 2019, SPEECH COMMUN, V114, P10, DOI 10.1016/j.specom.2019.09.001
   Pascual S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5019, DOI 10.1109/ICASSP.2018.8462322
   Pascual S, 2017, INTERSPEECH, P3642, DOI 10.21437/Interspeech.2017-1428
   Pasini M., 2019, ARXIV191003713
   Phan H, 2020, IEEE SIGNAL PROC LET, V27, P1700, DOI 10.1109/LSP.2020.3025020
   Qian YM, 2019, SPEECH COMMUN, V114, P1, DOI 10.1016/j.specom.2019.08.006
   Radford A., 2015, ARXIV 151106434
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sahu S, 2018, INTERSPEECH, P3693, DOI 10.21437/Interspeech.2018-1883
   Saito Y, 2019, COMPUT SPEECH LANG, V58, P347, DOI 10.1016/j.csl.2019.05.008
   Saito Y, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5299, DOI 10.1109/ICASSP.2018.8461714
   Saito Y, 2018, IEEE-ACM T AUDIO SPE, V26, P84, DOI 10.1109/TASLP.2017.2761547
   Shah N, 2018, INTERSPEECH, P3157, DOI 10.21437/Interspeech.2018-1565
   Shi YP, 2019, ASIAPAC SIGN INFO PR, P347, DOI [10.1109/apsipaasc47483.2019.9023132, 10.1109/APSIPAASC47483.2019.9023132]
   Sisman B., 2020, PROC SPEAKER LANGUAG, P238
   Sisman B, 2019, ASIAPAC SIGN INFO PR, P112, DOI 10.1109/APSIPAASC47483.2019.9023162
   Soni MH, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5039, DOI 10.1109/ICASSP.2018.8462068
   Sriram A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5639, DOI 10.1109/ICASSP.2018.8462456
   Su JQ, 2020, INTERSPEECH, P4506, DOI 10.21437/Interspeech.2020-2143
   Tamamori A, 2017, INTERSPEECH, P1118, DOI 10.21437/Interspeech.2017-314
   Tanaka K, 2018, IEEE W SP LANG TECH, P632, DOI 10.1109/SLT.2018.8639636
   van den Oord A., 2016, 9 ISCA SPEECH SYNTH
   van den Oord A, 2018, PR MACH LEARN RES, V80, DOI arXiv:1711.10433
   Wang DH, 2020, IEEE ACCESS, V8, P124503, DOI 10.1109/ACCESS.2020.3006130
   Wang K, 2018, INTERSPEECH, P1581, DOI 10.21437/Interspeech.2018-1780
   Wu DY, 2020, INTERSPEECH, P1316, DOI 10.21437/Interspeech.2020-1984
   Xiang Y, 2018, INT WORKSH ACOUSTIC, P46, DOI 10.1109/IWAENC.2018.8521353
   Xu XP, 2021, SAFETY SCI, V141, DOI 10.1016/j.ssci.2021.105319
   Yamamoto R., 2020, ARXIV PREPRINT ARXIV
   Yamamoto R, 2020, INT CONF ACOUST SPEE, P6199, DOI [10.1109/icassp40776.2020.9053795, 10.1109/ICASSP40776.2020.9053795]
   Yang F, 2020, SPEECH COMMUN, V118, P1, DOI 10.1016/j.specom.2020.02.001
   Yang G., 2020, ARXIV200505106
   Yang S, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P685, DOI 10.1109/ASRU.2017.8269003
   Ye SQ, 2020, CONF REC ASILOMAR C, P1405, DOI 10.1109/IEEECONF51394.2020.9443547
   Zen HG, 2013, INT CONF ACOUST SPEE, P7962, DOI 10.1109/ICASSP.2013.6639215
   Zhang Y, 2020, INTERSPEECH, P3945, DOI 10.21437/Interspeech.2020-1454
   Zhang ZZ, 2018, PROC CVPR IEEE, P6199, DOI 10.1109/CVPR.2018.00649
   Zhao H, 2020, IEEE ACCESS, V8, P106889, DOI 10.1109/ACCESS.2020.3000751
   Zhao SK, 2019, INTERSPEECH, P1238, DOI 10.21437/Interspeech.2019-2078
   Zhou K., 2020, ARXIV201014794
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 113
TC 19
Z9 20
U1 15
U2 91
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD MAR
PY 2022
VL 72
AR 101308
DI 10.1016/j.csl.2021.101308
EA OCT 2021
PG 24
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XM4TI
UT WOS:000728821200020
DA 2024-01-09
ER

PT J
AU Mas, L
   Bolls, P
   Rodero, E
   Barreda-Angeles, M
   Churchill, A
AF Mas, Lluis
   Bolls, Paul
   Rodero, Emma
   Barreda-Angeles, Miguel
   Churchill, Ashley
TI The impact of the sonic logo's acoustic features on orienting responses,
   emotions and brand personality transmission
SO JOURNAL OF PRODUCT AND BRAND MANAGEMENT
LA English
DT Article
DE Brand personality; Acoustic features; Gestalt theory; Multisensory
   branding; Orienting response; Sonic logo; Sound branding
ID PSYCHOPHYSIOLOGICAL RESPONSES; SOUND; ATTENTION; MUSIC; TEMPO; MODEL;
   PRODUCT
AB Purpose The purpose of this study is to determine how sonic logo's acoustic features (intensity, pitch and pace) based on melodic tunes with no voice orient the response of consumers, attract attention, elicit levels of pleasantness and calmness and transmit brand personality traits. Design/methodology/approach A within-subject experimental factorial design is applied to measure emotional arousal (indexed as electrodermal activity) and enhancement on perceptual processing (indexed as heart rate), as well as self-reported factors, namely, calmness/excitement, pleasantness and brand personality scales. Findings Results show a significant increase on electrodermal activity associated with fast-paced sonic logos and a decrease in heart rate in slow-paced long sonic logos. Also, fade-up, pitch-ascending fast sonic logos are defined as more exciting and descending-pitch sonic logos as more pleasant. Research limitations/implications The use of sonic logos with no voice does limit its implications. Besides, the use of three variables simultaneously with 18 versions of sonic logos in a laboratory setting may have driven participants to fatigue; hence, findings should be cautiously applied. Practical implications First, sonic logos are best processed in a fade-up form. Second, fast pace is recommended to orient response, whereas slow pace is recommended to transmit calmness. Practitioners may opt for fast-paced sonic logos if the design is new or played in a noisy environment and opt for slow-paced sonic logos in already highly recognized sound designs. Originality/value To the best of authors' knowledge, this study is the first to combine psychophysiological measures and self-reported scales in a laboratory experiment on how sonic logo's acoustic features orient response, transmit emotions and personality traits.
C1 [Mas, Lluis; Rodero, Emma] Pompeu Fabra Univ, Dept Commun, Barcelona, Spain.
   [Bolls, Paul; Churchill, Ashley] Texas Tech Univ, Coll Media & Commun, Lubbock, TX 79409 USA.
   [Barreda-Angeles, Miguel] Univ Amsterdam, Dept Commun Sci, Amsterdam, Netherlands.
C3 Pompeu Fabra University; Texas Tech University System; Texas Tech
   University; University of Amsterdam
RP Mas, L (corresponding author), Pompeu Fabra Univ, Dept Commun, Barcelona, Spain.
EM lluis.mas@upf.edu; pbolls@wsu.edu; emma.rodero@upf.edu;
   m.barredaangeles@vu.nl; ashleyc@biopac.comm
RI Campailla, Jasmin/AAK-2420-2021; Barreda-Ángeles, Miguel/AAX-4359-2020
OI Barreda-Ángeles, Miguel/0000-0002-5056-7633
FU Spanish Government (Jose Castillejo program, Ministerio de Educacion,
   Cultura y Deporte); College of Media & Communication at Texas Tech
   University
FX This research was supported by the Spanish Government (Jose Castillejo
   program, Ministerio de Educacion, Cultura y Deporte). This institution
   funded a research stay in the College of Media & Communication at Texas
   Tech University. The authors thank both the Spanish Government and Texas
   Tech University as a host institution.Declarations of interest: none.
CR ABA. Audio Branding Academy, 2017, AUD LOG DAT
   Alpert MI, 2005, J BUS RES, V58, P369, DOI 10.1016/S0148-2963(03)00101-2
   [Anonymous], 2012, PSYCHOPHYSIOLOGICAL, DOI DOI 10.4324/9780203181027
   [Anonymous], 2001, Music and Emotion, DOI DOI 10.1525/MP.2004.21.4.561
   Babyak MA, 2004, PSYCHOSOM MED, V66, P411, DOI 10.1097/01.psy.0000127692.23278.a9
   Bach DR, 2008, CEREB CORTEX, V18, P145, DOI 10.1093/cercor/bhm040
   Ballouli K, 2015, SPORT MANAG REV, V18, P321, DOI 10.1016/j.smr.2014.03.001
   Bispham JC, 2009, MUSIC SCI, P41
   Biswas D., 2009, J ACAD MARKETING SCI, V47, P37
   Bliese P., 2016, BRIEF INTRO R MULTIL
   Bolls P., 2013, COMMUNICATION RES, V29, P537, DOI DOI 10.1016/J.JBUSRES.2006.08.010
   Bolls PD, 2003, MEDIA PSYCHOL, V5, P33, DOI 10.1207/S1532785XMEP0501_2
   Bonde A., 2013, SoundEffects-An Interdisciplinary Journal of Sound and Sound Experience, V3, P112
   Bradley MM, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P581, DOI 10.1017/CBO9780511546396.025
   Bradley MM, 2009, PSYCHOPHYSIOLOGY, V46, P1, DOI 10.1111/j.1469-8986.2008.00702.x
   Buss D.M., 2015, HDB EVOLUTIONARY PSY
   Carpentier FRD, 2007, MEDIA PSYCHOL, V10, P339, DOI 10.1080/15213260701533045
   Chuen L, 2016, PSYCHOPHYSIOLOGY, V53, P891, DOI 10.1111/psyp.12633
   Davis DF, 2016, J RETAILING, V92, P1, DOI 10.1016/j.jretai.2015.06.002
   Dawson ME, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P159, DOI 10.1017/cbo9780511546396.007
   DUBE L, 1995, PSYCHOL MARKET, V12, P305, DOI 10.1002/mar.4220120407
   Elpidorou A, 2018, PHILOS PSYCHOL, V31, P323, DOI 10.1080/09515089.2017.1346240
   Elpidorou A, 2018, PHENOMENOL COGN SCI, V17, P455, DOI 10.1007/s11097-017-9515-1
   Geuens M, 2009, INT J RES MARK, V26, P97, DOI 10.1016/j.ijresmar.2008.12.002
   Gomez P, 2007, EMOTION, V7, P377, DOI 10.1037/1528-3542.7.2.377
   Graakjær NJ, 2018, EUR J MARKETING, V52, P1505, DOI 10.1108/EJM-09-2017-0609
   Groves J., 2009, AUDIO BRANDING BRAND, P62, DOI DOI 10.1037/0033-295X.114.4.864
   Gustafsson C, 2015, J BRAND MANAG, V22, P20, DOI 10.1057/bm.2015.5
   Jackson D., 2004, SONIC BRANDING
   Kallinen K, 2003, MUSIC SCI, P85
   Kellaris J.J., 1993, Psychol. Mark., V10, P15
   Khalfa S, 2008, INT J PSYCHOPHYSIOL, V68, P17, DOI 10.1016/j.ijpsycho.2007.12.001
   Kim J, 2019, PSYCHOL MUSIC, V47, P392, DOI 10.1177/0305735618754688
   Klink R., 2000, MARKET LETT, V11, P5, DOI [10.1023/A:1008184423824, DOI 10.1023/A:1008184423824]
   Krishnan V, 2012, J PROD BRAND MANAG, V21, P275, DOI 10.1108/10610421211246685
   Kristjansson SD, 2007, PSYCHOPHYSIOLOGY, V44, P728, DOI 10.1111/j.1469-8986.2007.00544.x
   Lang A., SAGE HDB MEDIA PROCE, P193
   Lantos GP, 2012, J CONSUM MARK, V29, P22
   Leder H, 2004, BRIT J PSYCHOL, V95, P489, DOI 10.1348/0007126042369811
   Lehmann M., 2008, AUDIO BRANDING, P83
   Lowe ML, 2019, J CONSUM RES, V46, P159, DOI 10.1093/jcr/ucy068
   Lowe ML, 2017, J MARKETING RES, V54, P331, DOI 10.1509/jmr.14.0300
   Mas Manchon L., 2011, ESTUDIOS FONETICA EX, P71, DOI DOI 10.1111/J.1470-6431.2011.00995.X
   Manchón LM, 2011, ESTUD MENSAJE PERIOD, V17, P95, DOI 10.5209/rev_ESMP.2011.v17.n1.6
   Moosmayer D., 2010, ENHANCING KNOWLEDGE, V28, P1, DOI DOI 10.1016/J.JBUSRES.2007.07.013
   Muller J., 2010, AUDIO BRANDING ACAD, P189, DOI DOI 10.1146/ANNUREV.RESOURCE.012809.103957
   Muller J., 2011, AUDIO BRANDING ACAD, P161
   North AC, 2004, J APPL SOC PSYCHOL, V34, P1675, DOI 10.1111/j.1559-1816.2004.tb02793.x
   Page-Gould E., 2017, HDB PSYCHOPHYSIOLOGY, P628
   Patel A., 2010, EMERGING DISCIPLINES, P91
   Pathak A, 2020, J BRAND MANAG, V27, P339, DOI 10.1057/s41262-019-00183-5
   Potter R. F., 2006, J PROMOTION MANAGEME, V12, P35, DOI [10.1300/J057v12n02_04, DOI 10.1300/J057V12N02_04]
   Potter R. F., 2008, J. Media Psychol., V20, P168, DOI DOI 10.1027/1864-1105.20.4.168
   Potter RF, 2015, COMMUN MONOGR, V82, P359, DOI 10.1080/03637751.2015.1019529
   Reber R, 2004, PERS SOC PSYCHOL REV, V8, P364, DOI 10.1207/s15327957pspr0804_3
   Rodero E., 2020, Innovation in Advertising and Branding Communication, P69, DOI [10.4324/9781003009276, DOI 10.4324/9781003009276-5]
   Rodero E., 2020, REIMAGINING COMMUNIC, P32
   Rodero E., 2015, COMMUNICATION RES, V46, P965
   Rodero E, 2020, J ADVERTISING RES, V60, P337, DOI 10.2501/JAR-2019-038
   Rodero E, 2019, COMMUN RES, V46, P965, DOI 10.1177/0093650215609085
   Rodero E, 2013, SEX ROLES, V68, P349, DOI 10.1007/s11199-012-0247-y
   Schmitt B, 2012, J CONSUM PSYCHOL, V22, P7, DOI 10.1016/j.jcps.2011.09.005
   van der Zwaag MD, 2011, MUSIC SCI, V15, P250, DOI 10.1177/1029864911403364
   Volker B., 2019, WHY SOUND VOICE ARE
   Winkler I, 2009, TRENDS COGN SCI, V13, P532, DOI 10.1016/j.tics.2009.09.003
   Yarkoni T, 2017, PERSPECT PSYCHOL SCI, V12, P1100, DOI 10.1177/1745691617693393
   Zampini M, 2005, FOOD QUAL PREFER, V16, P632, DOI 10.1016/j.foodqual.2004.11.004
   Zander M.F., 2006, PSYCHOL MUSIC, V34, P465, DOI [10.1177/0305735606067158, DOI 10.1177/0305735606067158]
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 69
TC 17
Z9 17
U1 9
U2 51
PU EMERALD GROUP PUBLISHING LTD
PI BINGLEY
PA HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND
SN 1061-0421
EI 2054-1643
J9 J PROD BRAND MANAG
JI J. Prod. Brand Manag.
PD MAY 21
PY 2021
VL 30
IS 5
BP 740
EP 753
DI 10.1108/JPBM-05-2019-2370
EA SEP 2020
PG 14
WC Business; Management
WE Social Science Citation Index (SSCI)
SC Business & Economics
GA SV4NT
UT WOS:000568061700001
OA Green Published, hybrid
DA 2024-01-09
ER

PT J
AU Dell, H
AF Dell, Helen
TI '[A] single, true, certain authenticity': The authenticity wars in
   English twentieth-century folk and medieval music revivals
SO POSTMEDIEVAL-A JOURNAL OF MEDIEVAL CULTURAL STUDIES
LA English
DT Article
AB At intervals throughout the twentieth century, serious disputes about authentic musical values arose amongst performers, collectors, scholars, directors, reviewers, and audiences in the folk and medieval music spheres. Analysis of these controversies offers insights into the deep emotions, fantasies, and desires in arguments around authenticity in medievalism. This essay considers two examples of English musical revivalism, one exemplified by the folk song collector Cecil Sharp, the other by Christopher Page, the medieval literature and music scholar and director of music group Gothic Voices. In the writings of both men, emotional concerns about the purity of English musical traditions reveal the role music is given in the maintenance of English nationalism, and more generally in defending notions of identity and social order against feared sources of contamination.
C1 [Dell, Helen] Univ Melbourne, Sch Culture & Commun, Parkville, Vic, Australia.
C3 University of Melbourne
RP Dell, H (corresponding author), Univ Melbourne, Sch Culture & Commun, Parkville, Vic, Australia.
EM helendell@internode.on.net
CR [Anonymous], 2004, LOGIC SENSE
   [Anonymous], COMPANION MEDIEVAL R
   [Anonymous], AUTHENTICITY EARLY M
   [Anonymous], ZOOPHONE X43167
   [Anonymous], OXFORD HDB MUSIC REV
   [Anonymous], 2012, ETHNOMUSICOLOGY REV
   [Anonymous], INSIDE EARLY MUSIC C
   [Anonymous], MAKING FUTURES EXPLO
   [Anonymous], 1991, Musical Elaborations
   [Anonymous], IDENTITY EVERYDAY LI
   [Anonymous], 1988, ARABIAN NIGHTS ENGLI, DOI DOI 10.1017/CBO9780511551369
   [Anonymous], TEL SAWT 9630 A
   [Anonymous], 1906, ENGLISH FOLK SONGS S
   [Anonymous], BRIGG FAIR
   Boyes Georgina, 2010, IMAGINED VILLAGE CUL
   Burne C., 1914, HDB FOLKLORE
   de Gobineau A., 1915, INEQUALITY HUMAN RAC
   DOUGLAS M, 2003, COLLECTED WORKS, V2
   Haines J, 2001, EARLY MUSIC, V29, P369, DOI 10.1093/em/29.3.369
   Harker Dave, 1985, FAKESONG MANUFACTURE
   Kidson, 1891, TRADITIONAL TUNES CO
   Kristeva Julia, 1982, POWERS HORROR ESSAY
   Livingston TE, 1999, ETHNOMUSICOLOGY, V43, P66, DOI 10.2307/852694
   Marshall Melanie L., 2015, Women Music, V19, P36
   Matthews D, 2018, EXEMPLARIA, V30, P207, DOI 10.1080/10412573.2018.1464812
   PAGE C, 1993, EARLY MUSIC, V21, P453
   Sharp C., 1907, ENGLISH FOLK SONG SO
   Taruskin R., 1988, AUTHENTICITY EARLY M, P137
   Tomlinson Gary., 1988, Authenticity and Early Music, P115
   TREITLER L, 1991, J ROY MUSIC ASSN, V116, P280, DOI 10.1093/jrma/116.2.280
   Turner V., 1974, The Rice University Studies, V60, P53
   Yri K, 2010, EARLY MUSIC, V38, P273, DOI 10.1093/em/caq025
NR 32
TC 1
Z9 1
U1 0
U2 2
PU PALGRAVE MACMILLAN LTD
PI BASINGSTOKE
PA BRUNEL RD BLDG, HOUNDMILLS, BASINGSTOKE RG21 6XS, HANTS, ENGLAND
SN 2040-5960
EI 2040-5979
J9 POSTMEDIEVAL
JI Postmedieval
PD DEC
PY 2019
VL 10
IS 4
BP 439
EP 451
DI 10.1057/s41280-019-00143-x
PG 13
WC Cultural Studies; Medieval & Renaissance Studies
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Cultural Studies; Arts & Humanities - Other Topics
GA KJ2MR
UT WOS:000511892600004
DA 2024-01-09
ER

PT J
AU Bernaerts, L
AF Bernaerts, Lars
TI The Multimodal Evocation of Minds in Audio Drama
SO COUNTERTEXT-A JOURNAL FOR THE STUDY OF THE POST-LITERARY
LA English
DT Article
DE radio play; multimodality; remediation; adaptation; audionarratology;
   fictional minds
AB This article discusses the construction of fictional minds in audio drama. Drawing upon social semiotics, cognitive narratology, and the narratology of audio drama, it starts from the premise that a character's consciousness in radio plays is shaped by the conventions, constraints, and affordances of the medium. This means that the semiotic modes of the radio play are exploited in a particular way to give listeners the impression that they are accessing a character's mind, e.g. through a voice's pitch or the verbal rendering of thoughts. In a dynamics of remediation, audio drama conventionally adopts narrative strategies associated with drama (e.g., soliloquy) as well as novelistic (e.g., thought report by a heterodiegetic narrator) and cinematic procedures (e.g., extradiegetic music as an accompaniment to characters' emotions) to evoke minds. Three adaptations will serve to illustrate this dynamics: Madame Bovary (PBS, 1986), Oeroeg (2009) and The Divine Comedy (BBC, 2014). By taking imported conventions into account alongside the audiophonic deployment of voice, music, sound, silence, and words, the article aims to further our understanding of minds in audio drama-which is relatively unknown territory in narratology-and contribute to the debate on fictional minds in cognitive and transmedial narratology.
C1 [Bernaerts, Lars] Univ Ghent, Dutch Literature & Literary Theory, Ghent, Belgium.
C3 Ghent University
RP Bernaerts, L (corresponding author), Univ Ghent, Dutch Literature & Literary Theory, Ghent, Belgium.
OI Bernaerts, Lars/0000-0001-8211-4551
CR Ammer Andreas, 1993, RADIO INFERNO HORSPI
   Bernaerts L, 2014, STYLE, V48, P294, DOI 10.5325/style.48.3.294
   Bolter Jay, 1999, Remediation: Understanding New Media
   BULLERJAHN C., 1994, Psychomusicology-A Journal of Research in Music Cognition, V13, P99, DOI DOI 10.1037/H0094100
   Caracciolo M, 2014, J NARRATIVE THEORY, V44, P29, DOI 10.1353/jnt.2014.0005
   Chion M., 2019, Audio-Vision: Sound on Screen
   Ciccoricco David, 2015, Refiguring Minds in Narrative Media
   Cohen AJ., 2011, MUSIC EMOTION THEORY, P1099, DOI [DOI 10.1093/ACPROF:OSO/9780199230143.003.0031, 10.1093/acprof:oso/9780199230143.003.0031]
   Cohn Dorrit, 1978, Transparent Minds: Narrative Modes for Presenting Consciousness in Fiction
   Crook Tim, 2012, The Sound Handbook
   Dante, 2014, DIVINE COMEDY
   De Benedictis Angela Ida, 2004, RADIODRAMMA ARTE RAD
   Flaubert G., 1986, MADAME BOVARY
   Flaubert Gustave, 2004, Madame Bovary
   Fludernik Monika, 1993, The Fictions of Language and the Languages of Fiction: The Linguistic Representation of Speech and Consciousness
   Frank Armin P., 1963, HORSPIEL VERGLEICHEN
   Haasse Hella, 2009, OEROEG
   Herman D, 2011, FRONT NARRAT, P1
   Humphrey Robert, 1968, STREAM CONSCIOUSNESS
   Huwiler Elke, 2005, ERZAHL STROME HORSPI
   Kress G., 2010, Multimodality: A Social Semiotic Approach to Contemporary Communication
   Mahne N., 2007, Transmediale Erzahltheorie. Eine Einfuhrung
   McHale B, 2012, NARRATIVE, V20, P115
   Mikkonen K, 2008, PARTIAL ANSW, V6, P301
   Mildorf J, 2017, PARTIAL ANSW, V15, P61, DOI 10.1353/pan.2017.0003
   Mildorf Jarmila, 2016, Audionarratology: Interfaces of Sound and Narrative
   Mildorf Jarmila, 2017, ERZAHLEN INTERDISZIP, P63
   Palmer Alan, 2004, Fictional Minds
   Pfister Manfred, 2001, Das Drama. Theorie und Analyse
   RICHARDSON B, 1988, COMP DRAMA, V22, P193
   Rinke Gunter, 2018, POPHORSPIEL DEFINITI
   Ryan M., 2014, Storyworlds Across Media: Toward a Media-Conscious Narratology, P1
   Schafer R. Murray, 1994, SOUNDSCAPE OUR SONIC
   Schmedes Gotz, 2002, MEDIENTEXT HORSPIEL
   Thon Jan -Noel, 2016, Transmedial Narratology and Contemporary Media Culture
   van Leeuwen T., 1999, Speech, music, sound
   Verma Neil, 2012, Theater of the Mind: Imagination, Aesthetics, and American Radio Drama
   Vielhauer Annette, 1999, WELT STIMMEN ANAL TY
NR 38
TC 2
Z9 2
U1 2
U2 4
PU EDINBURGH UNIV PRESS
PI EDINBURGH
PA THE TUN-HOLYROOD RD, 12 2F JACKSONS ENTRY, EDINBURGH EH8 8PJ, SCOTLAND
SN 2056-4406
EI 2056-4414
J9 COUNTERTEXT
JI CounterText
PD DEC
PY 2019
VL 5
IS 3
BP 312
EP 331
DI 10.3366/count.2019.0168
PG 20
WC Literary Theory & Criticism
WE Emerging Sources Citation Index (ESCI)
SC Literature
GA JX0MY
UT WOS:000503439400005
DA 2024-01-09
ER

PT J
AU Schotanus, YP
AF Schotanus, Yke Paul
TI The Effect of Timing on the Singer's Tone of Voice
SO PSYCHOMUSICOLOGY
LA English
DT Article
DE prosody; syncopation; dynamic attending; music and emotion; music and
   language
ID SPEECH RATE; SYNCOPATION; PERCEPTION; TIME
AB Several studies have shown that music can be used to express and induce specific emotions. Only a few, however, investigate interactive expressions such as dominance, submissiveness, and sincerity. In the current study, it is hypothesized that aligning phrase onsets with strong beats supports perceived sincerity. In 2 online listening experiments, 52 (M = 26.35; SD = 7.25) and 89 (M = 28.39; SD = 11.37) participants, respectively, listened to 27 sung sentences and rated 15 Likert scale items for each stimulus. In Experiment 1, the whole sentence was timed either early, on beat, or late, and in Experiment 2 only the timing of the last stressed syllable was varied. Both experiments show that on-beat phrases are perceived as relatively "right" (a combination of sincerity, naturalness, and convincingness, among other things). Experiment 2 also shows that early phrases support perceived urgency, whereas late phrases support perceived upsetness. These results suggest that a syncopated note can be related to a rest on a strong beat either following or preceding it. In addition, several aspects of melody turned out to affect these factors as well. The results can be related to various theories and indicate that perceived "authenticity" can be modified by using specific musical features.
C1 [Schotanus, Yke Paul] Univ Utrecht, Inst Cultural Inquiry, Muntstr 2a, NL-3512 EV Utrecht, Netherlands.
C3 Utrecht University
RP Schotanus, YP (corresponding author), Univ Utrecht, Inst Cultural Inquiry, Muntstr 2a, NL-3512 EV Utrecht, Netherlands.
EM schotschrift.teksten@planet.nl
OI Schotanus, Yke/0000-0001-9992-4366
FU Netherlands Organization for Scientific Research [023.004.078]
FX This research was supported by the Netherlands Organization for
   Scientific Research: 023.004.078.
CR Aaftink C., 2014, THESIS U ALBERTA
   [Anonymous], 2000, EXPRESSION POP ROCK
   Arthur C, 2018, MUSIC PERCEPT, V35, P295, DOI 10.1525/MP.2018.35.3.295
   Auslander Philip, 1999, Liveness: Performance in a Mediatized Culture
   Bouwer F., 2021, MEASURING MUSICAL SO
   Bouwer FL, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01094
   Brackett David, 1995, Interpreting Popular Music
   Bronzwaer W., 1993, LESSEN LYRIEK NIEUWE
   Cespedes-Guevara J, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00215
   Condit-Schultz N, 2019, EMPIR MUSICOL REV, V14, P81, DOI 10.18061/emr.v14i1-2.7098
   Curtis M.E., 2003, ANN C SOC MUS PERC C
   Eckstein Lars, 2010, READING SONG LYRICS, DOI [10.1163/9789042030367, DOI 10.1163/9789042030367]
   Findeisen F., 2017, HOLISTIC SONGWRITING
   Frijda N., 1986, The emotions: Studies in emotion and social interaction
   Frith S., 2007, TAKING POPULAR MUSIC, P31
   Frith S., 2007, TAKING POPULAR MUSIC, P313, DOI [10.4324/9780203309049_chapter_1, DOI 10.4324/9780203309049_CHAPTER_1]
   Gordon RL, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00352
   Hansen N.C., 2019, MUSIC SCI, V2, P1, DOI [10.1177/2059204318812243, DOI 10.1177/2059204318812243]
   Hansen N.C., 2018, P ICMPC15 ESCOM10, P184
   Huron D, 1996, MUSIC PERCEPT, V13, P489
   Huron D., 2015, SIGNATA ANN SEMIOT, V6, P331, DOI DOI 10.4000/SIGNATA.1115
   Huron D.B., 2016, VOIC LEAD SCI BEH, DOI DOI 10.7551/MITPRESS/9780262034852.001.0001
   Huron D, 2006, EMPIR MUSICOL REV, V1, P170, DOI 10.18061/1811/24068
   JONES MR, 1976, PSYCHOL REV, V83, P323, DOI 10.1037/0033-295x.83.5.323
   Juslin P. N., 1996, PSYCHOL MUSIC, V24, P68, DOI [10.1177/0305735696241007, DOI 10.1177/0305735696241007]
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Koelsch S, 2011, PHYS LIFE REV, V8, P89, DOI 10.1016/j.plrev.2011.04.004
   Koops HendrikVincent, 2015, P 16 INT SOC MUS INF
   Ladinig O, 2009, MUSIC PERCEPT, V26, P377, DOI 10.1525/MP.2009.26.4.377
   Large EW, 1999, PSYCHOL REV, V106, P119, DOI 10.1037/0033-295X.106.1.119
   London Justin, 1993, Music Theory Online, V0
   LONGUETHIGGINS HC, 1984, MUSIC PERCEPT, V1, P424
   Menon V, 2005, NEUROIMAGE, V28, P175, DOI 10.1016/j.neuroimage.2005.05.053
   Müllensiefan D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089642
   OHALA JJ, 1984, PHONETICA, V41, P1, DOI 10.1159/000261706
   Pattison P., 2015, LESSON 46 PHRASING S
   Quené H, 2005, PHONETICA, V62, P1, DOI 10.1159/000087222
   Scherer K.R., 2017, PSYCHOMUSICOL MUSIC, V27, P244, DOI DOI 10.1037/PMU0000193
   Schotanus Y.P., 2015, P 9 TRIENN C EUR SOC
   Schotanus Y.P, 2019, SUPPLEMENTARY MAT PH
   Schotanus Y.P., 2020, THESIS UTRECHT U, DOI [10.33540/249, DOI 10.33540/249]
   Schotanus Y.P., 2018, P ICMPC15 ESCOM10, P401
   Schotanus Y, 2020, EMPIR MUSICOL REV, V15, P18, DOI 10.18061/emr.v15i1-2.6863
   Schubert E, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00837
   Shanahan D., 2014, EMPIR MUSICOL REV, V9, P46, DOI [10.18061/emr.v9i2.4441, DOI 10.18061/EMR.V9I2.4441]
   SIEGMAN AW, 1993, J ABNORM PSYCHOL, V102, P430, DOI 10.1037/0021-843X.102.3.430
   Sun SH, 2017, EMPIR MUSICOL REV, V12, P327
   Tan I, 2019, MUSIC PERCEPT, V36, P353, DOI 10.1525/MP.2019.36.4.353
   TEMPERLEY D., 2001, COGNITION BASIC MUSI
   Temperley D, 2019, EMPIR MUSICOL REV, V14, P66, DOI 10.18061/emr.v14i1-2.6986
   Temperley D, 2009, J NEW MUSIC RES, V38, P3, DOI 10.1080/09298210902928495
   Tusing KJ, 2000, HUM COMMUN RES, V26, P148, DOI 10.1111/j.1468-2958.2000.tb00754.x
   van Heuven VJ, 2005, SPEECH COMMUN, V47, P87, DOI 10.1016/j.specom.2005.05.010
   Warrenburg LA, 2020, PSYCHOMUSICOLOGY, V30, P1, DOI 10.1037/pmu0000247
   Witek MAG, 2014, MUSIC PERCEPT, V32, P201, DOI 10.1525/MP.2014.32.2.201
   Witek MAG, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0094446
NR 56
TC 0
Z9 0
U1 0
U2 0
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0275-3987
EI 2162-1535
J9 PSYCHOMUSICOLOGY
JI Psychomusicology
PD SEP-DEC
PY 2021
VL 31
IS 3-4
BP 107
EP 122
DI 10.1037/pmu0000278
PG 16
WC Music; Psychology, Experimental
WE Emerging Sources Citation Index (ESCI)
SC Music; Psychology
GA YD8XI
UT WOS:000740717900008
DA 2024-01-09
ER

PT J
AU Singh, K
AF Singh, Khenu
TI The Unstruck Sound Archetypes of Rhythm and Emotion in Indian Alchemy
   and Jungian Analysis
SO JUNG JOURNAL-CULTURE & PSYCHE
LA English
DT Article
DE Abhinavagupta; aesthetics; alchemy; archetype; attachment theory;
   Bharat; Wilfred Bion; emotion; India; Indian; individuation; C. G. Jung;
   Lila; Mercury; music; navarasa; Natyashastra; nonverbal; rhythm; rasa;
   Self; Shiva; Shakti; Spanda; symbol; tabla; Tantric; Vasugupta
ID MUSIC
AB Musical and rhythmic dimensions of the alchemical endeavor, and of clinical work, are often in the shadows. Indian philosophy has often been criticized as being otherworldly and even world negating, including by Jung. India has a long history, with many diverse traditions of inquiry. Ideals of renunciation and unification with the Godhead, and perspectives of the world as Maya/illusion-in contrast to some greater Truth-exist, but these only represent an incomplete set of voices. Putting aside verbal traditions, as well as what hasn't been scribed, complex forces shape which texts cross the barriers of language, culture, and history and what sorts of understandings and fantasies emerge as we grapple with the Other. In the Shaivite Tantric traditions, the upward movement into the realm of spirit is only one arc of a larger rhythmic oscillation. The downward earthly embodiment in one's lived life is equally important. In the spirit of Jung, with his emphasis on bringing light into the shadows, we will explore these areas. After a brief review of Jung's interest in medieval European alchemy, we begin our dialogue with lesser-known perspectives from Indian alchemical and Tantric systems. Drawing from Indian philosophy and aesthetics, core archetypes of rhythm (Spanda) and emotion (Rasa) are introduced and developed. Psychological dimensions of Indian classical rhythm and performance are explored. We relate these to perspectives within psychoanalysis and analytical psychology, and then we conclude with clinical considerations, looking at musical and rhythmic dimensions of the analytic exchange.
C1 [Singh, Khenu] CG Jung Inst San Francisco, Analyt Training Program, San Francisco, CA USA.
   [Singh, Khenu] Univ Calif San Francisco, Dept Psychiat, San Francisco, CA USA.
C3 University of California System; University of California San Francisco
RP Singh, K (corresponding author), 322 Clement St, San Francisco, CA 94118 USA.
EM khenusingh@gmail.com
CR [Anonymous], 2003, Archetype, attachment, analysis : Jungian psychology and the emergent mind
   [Anonymous], AION
   [Anonymous], DECTRINE VIBRATION A
   [Anonymous], 1942, CW
   [Anonymous], 1995, MYSTERIUM LECT JOURN
   [Anonymous], NEW LIB PSYCHOANALYS
   [Anonymous], 1995, J CHILD PSYCH, DOI [10.1080/00754179508254905, DOI 10.1080/00754179508254905]
   [Anonymous], 2004, TRANSCENDENT FUNCTIO
   [Anonymous], MYSTICISM SOUND MUSI
   [Anonymous], TANTRIC WAY ART SCI
   [Anonymous], 1980, SPANDA KARIKAS DIVIN
   [Anonymous], COMMUNICATION
   [Anonymous], 1985, JUNG E THOUGHT
   [Anonymous], INTERCULTURAL AESTHE
   [Anonymous], FREUD READER
   [Anonymous], 1997, PSYCHOANAL QUART
   [Anonymous], HDB JUNGIAN PSYCHOL
   [Anonymous], 1952, CW
   [Anonymous], 2002, NEOPLATONISM INDIAN
   [Anonymous], 1996, CLIN THINKING W BION
   [Anonymous], SYNTHESIS YOGA
   [Anonymous], LIFE PROPHECIES PARA
   [Anonymous], 2002, SHAPE ANCIENT THOUGH
   Bion W., 1970, ATTENTION INTERPRETA
   Bisagni F, 2010, J ANAL PSYCHOL, V55, P254, DOI 10.1111/j.1468-5922.2010.01839.x
   Carta S, 2009, J ANAL PSYCHOL, V54, P85, DOI 10.1111/j.1468-5922.2008.01759.x
   Edinger E., 1985, Anatomy of the psyche: Alchemical symbolism in psychotherapy
   Ekman P., 1972, Emotion in the human face: Guidelines for research and an integration of findings
   FORDHAM M, 1976, SELF AUTISM
   GHENT E, 1990, CONTEMP PSYCHOANAL, V26, P108
   HENDERSON J, 2003, TRANSFORMATION PSYCH
   HENDERSON JL, 1967, THRESHOLDS INITIATIO
   Jung C.G., 1921, Psychological types
   Jung C. G., 1989, Memories, Dreams, Reflections
   Jung C.G., 1973, Letters, V1
   JUNG CG, 1916, STRUCTURE DYNAMICS P
   JUNG CG, 1955, CW, V14
   Knoblauch S. H., 2000, The musical edge of therapeutic dialogue
   Otto R., 1923, IDEA HOLY
   Sacks O., 2007, Tales of Music and the Brain
   Schwartz Susan L., 2004, Rasa: Performing the Divine in India
   Schwartz-Salant N., 1995, The interactive field in analysis, V1, P1
   Skar P, 2002, J ANAL PSYCHOL, V47, P629, DOI 10.1111/1465-5922.00351
   White David Gordon, 1996, The Alchemical Body: Siddha Traditions in Medieval India
NR 44
TC 0
Z9 0
U1 0
U2 8
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1934-2039
EI 1934-2047
J9 JUNG J-CULT PSYCHE
JI Jung J.-Cult. Psyche
PD SPR
PY 2013
VL 7
IS 2
BP 35
EP 61
DI 10.1080/19342039.2013.787887
PG 27
WC Humanities, Multidisciplinary
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Arts & Humanities - Other Topics
GA 228BF
UT WOS:000325159200008
DA 2024-01-09
ER

PT J
AU Campesato, C
AF Campesato, Claudio
TI The Natural Power of Music
SO RELIGIONS
LA English
DT Article
DE music; emotions; compunction; liturgy; Middle Ages; Gregorian chant;
   Amalarius; Boethius; philosophy of music
AB Among the early medieval authors, Amalarius of Metz (8th-9th century) is one of those who discussed the impact of religious music and song on the body and soul. In his main work: the Liber Officialis, listening and singing liturgical music are depicted as having a corporeal effect that generates sensations of an intense sensory and emotional character. In Amalarius, living the musical religious phenomenon not only coincides with the idea that music can evoke emotions but there is something that goes further. What Amalarius emphasizes is a particular emotion: a "spiritual state" of the nakedness of the heart, almost a weakness of those who are capable of tears and sensitive to God's voice. During the patristic era, especially in the East, "penthos" (compunction) was used to describe the experience of tears in prayer or meditation; however, Fathers of the Church described liturgical music as an obstacle to compunction. For this reason, an evolution of that compunctory doctrine emerges from the exposition of Amalarius. In this context, it is not a question of crying for one's sins but of exploiting a natural power (vis) of music. By simply listening to music, a person would seem capable of being moved and reaching a particularly "receptive state" to welcome the Word of God and make it bear fruit. What Amalarius describes in religious music seems to be the natural experience that one feels when, just listening to a melody, a tear spontaneously falls. This physical reaction is connected to a spiritual transformation that seems to pass through the flesh (carnalia) of our humanity. The result of this singular experience, strongly connected to musical ethics, is the conversion to good action and the possibility to dispose human beings to attentive, deep, and fruitful listening.
C1 [Campesato, Claudio] Pontifical Anselmian Athenaeum, Pontifical Inst Liturgy PIL, I-00153 Rome, Italy.
RP Campesato, C (corresponding author), Pontifical Anselmian Athenaeum, Pontifical Inst Liturgy PIL, I-00153 Rome, Italy.
EM claudio.campesato@gmail.com
CR Albert Werminghoff., 1906, Monumenta Germaniae Historica. Concilia Aevi Karolini, V2, P421
   Albert Werminghoff., 1906, Monumenta Germaniae Historica. Concilia Aevi Karolini, Vvol. 2,1, P308
   Althoff Gerd., 2000, Emotionalitat. Zur Geschichte der Gefuhle
   Angenendt Arnold., 2005, Lo Sviluppo Organico in Questione
   [Anonymous], 1967, Sacrosanctum Concilium Oecumenicum Vaticanum II Musicam Sacram, Instruction on Music in the Liturgy
   Apel Willi., 1998, Liturgia, Storia, Notazione, Modalita e Tecniche Compositive
   Atkinson Charles Mercer., 2009, The Critical Nexus: Tone-System, Mode, and Notation in Early Medieval Music
   Bacon Roger., 1859, Opera Quadam Hactenus Inedita. Vol. I. Containing I.-Opus Tertium. II.-Opus Minus. III.-Compendium Philosophia, P3
   Barbero Alessandro., 2004, Un Padre dell'Europa
   Baroffio Giacomo., 2012, Rivista Internazionale di Musica Sacra, V33, P265
   Bertram Jerome., 2017, Critical Texts with Translations and Commentary
   Beschi Luigi., 2023, Ε. Studi in Onore di Franco Sartori, P1
   Boethius Severinus., 1990, De Institutione Musica
   Bricout Helene., 2016, Liturgie, Pensee Theologique et Mentalites Religieuses au Haut Moyen Age: Le Temoignage des Sources Liturgique, P101
   Bricout Helene., 2014, La Mistagogia. Attualita di una Antica Risorsa. Atti della XLI Settimana di Studio dell'Associazione Professori di Liturgia, Alghero, P53
   Callahan Annice., 2003, Nuovo Dizionario di Spiritualita, P198
   Campesato Claudio., 2021, L'Interpretazione Allegorica dell'Octoechos Come Ermeneutica Liturgico-Musicale Nella "Summa de Officiis Ecclesiasticis" di Guglielmo di Auxerre
   Campesato Claudio., 2023, Rivista Liturgica, V110, P213
   Canale AngeloValastro., 2014, Etymologiarum Sive Originum Libri XX
   Cardini Franco., 2006, Storia Medievale
   Carruthers Mary, 2013, The Experience of Beauty in the Middle Ages
   Cassian John., 1886, Conlationes IX
   Cassian John, 1985, CONFERENCES
   Catalano Alfio Giuseppe., 2015, Alla Scuola del Canto Gregoriano. Studi in Forma di Manuale, P169
   Cattin Giulio., 1991, La Monodia Nel Medioevo, V2nd ed.
   Cazier Pierre., 1998, Sententiae
   Clement Olivier., 1998, Teologia e Poesia del Corpo
   Comotti Giovanni., 1996, La Musica Nella Cultura Greca e Romana
   Contreni John Joseph., 2016, Surrey: Ashgate, P21
   Cortoni Claudio Ubaldo., 2016, Il Corpo di Cristo Dalla Devozione Alla Sua Umanita al Culto Eucaristico (Sec. VIII-XV)
   Deshusses Jean., 1979, Ses Principales Formes d'Apres les Plus Anciens Manuscripts, V2nd
   Deug-Su I., 1984, Cultura e Ideologia Nella Prima eta Carolingia
   Diosi David., 2006, Eine Quellenkritische Untersuchung der Trierischen Zeugnisse uber Einen Liturgiker der Karolingerzeit
   Donato Antonio., 2021, Un Pensatore Tardodiantico e il suo Mondo
   Durand William., 1995, Rationale Divinorum Officiorum
   Dyer Joseph., 2018, Etudes Gregorienne, V45, P107
   Eco Umberto., 2016, Arte e Bellezza nell'Estetica Medievale
   Ekenberg Anders, 1987, Cur Cantatur? Die Funktionen des Liturgischen Gesanges Nach den Autoren der Karolingerzeit
   Ewig Eugen., 2004, Storia della Chiesa, V4th, P135
   Flores Juan Javier., 2016, Una Vision Liturgica de la Sacramentalidad de la Iglesia
   Gilson Etienne., 2020, Dalle Origini Patristiche Alla Fine del XIV Secolo, V6th ed.
   Girardi Luigi., 2014, Sacrosanctum Concilium. Inter Mirifica, P81
   Gonzalez Villanueva Jose Ignacio., 2010, Estudios Gregorianos, V3, P33
   Gotz Georg Polycarp., 1983, Liber Quare
   Graduale Novum, 2011, Tomus I: De Dominicis Et Festis
   Graduale Romanum, 1974, Sacrosanctae Romanae Ecclesiae de Tempore et de Sanctis
   Grillo Andrea., 2022, Una Introduzione Alla Teologia dell'Azione Rituale
   Hanssens Jean Michel., 1948, Amalarii Episcopi, Opera Liturgica Omnia, Vvol. 1, P58
   Hanssens Jean Michel., 1950, Amalarii Episcopi, Opera Liturgica Omnia, Vvol. 3
   Hanssens JeanMichel., 1950, Amalarii Episcopi, Opera Liturgica Omnia, P9
   Hanssens JeanMichel., 1949, Amalarii Episcopi, Opera Liturgica Omnia, Vvol. 1, P359
   Hanssens JeanMichel., 1950, Amalarii Episcopi, Opera Liturgica Omnia, P5
   Hausherr Irenee., 2013, La Dottrina della Compunzione nell'Oriente Cristiano
   Hayward Paul Antony., 2017, Medieval Cantors and Their Craft: Music, Liturgy and the Shaping of History, 800-1500
   Hiley David, 2009, Gregorian Chant
   Holger Petersen Nils, 2021, Medieval Rituals, the Arts, and the Notion of Medievalism
   Ihnatowicz Janusz Artur., 2016, Amalariusz z Metzu, swiete Obrzedy Kociola, V1, P13
   Ivorra Robla Adolfo V., 2007, Los Sentidos de la Liturgia en Amalario de Metz: Bautismo y Eucaristia
   Jaffe Philipp., 1867, Monumenta Carolina, P426
   Jaschinski Eckhard., 2018, Breve Storia della Musica Sacra, V2nd ed.
   Jeffrey Henderson., 1993, Loeb Classical Library
   Jones Christopher Andrew., 2001, Interpolations in Salisbury, Cathedral Library
   Jungmann Josef Andreas., 1963, Origini, Liturgia, Storia e Teologia della Messa Romana, V2nd
   Knibbs Eric., 2014, On the Liturgy
   Kunzler Michael., 2018, La Liturgia della Chiesa, V3rd ed.
   La Rosa Luigi., 2022, Storia della Catechesi. 2. Dire Dio Nel Medioevo
   Largier Niklaus., 2003, Codierung Von Emotionen Im Mittelalter/Emotions and Sensibilities in the Middle Ages
   Lawson ChristopherM., 1989, De Ecclesiasticis Officiis
   Levy K, 2000, EARLY MUSIC HIST, V19, P81, DOI 10.1017/S0261127900001972
   Levy Kenneth., 1998, Gregorian Chant and the Carolingians
   Lluch-Baixauli Miguel., 1997, La Ragione Teologica
   Marchetti-Salvatori Biagio., 1990, Dizionario Enciclopedico di Spiritualita, Vvol. 1
   Marenbon John., 2009, Fondamenti e Inizi. Secoli IV-IX, V1, P369
   Meβner Reinhard., 1993, Zeitschrift fur katholische Theologie, V115, P415
   Muller Jan-Dirk., 2017, Zur historischen Pragnanz allegorischer und Symbolischer Sinnstiftung, P87
   Neunheuser Burkhard., 1999, Storia della Liturgia Attraverso le Epoche Culturali, V3rd ed.
   Nishiwaki Jun., 2017, Beitrage zur Gregorianik, V64, P99
   Nishiwaki Jun., 2016, Beitrage zur Gregorianik, V62, P71
   Orbetello Luca., 1989, Boezio e Dintorni. Ricerche Sulla Cultura Medievale
   Pecklers Keith., 2013, La Dimensione Storica e Teologica del Culto Cristiano e le Sfide del Domani, V2nd ed.
   Petersen Nils Holger., 2020, Von der Oralitat zum SchiftBild: Visuelle Kultur und Musikalische Notation (9-13 Jahrhundert), P1
   Raffa Vincenzo., 2011, Mistagogia della Messa: Dalla Storia e Dalla Teologia Alla Pastorale Pratica
   Rainoldi Felice., 2000, Appunti Per Una Storia Dei Riti Cantati
   Rampi Fulvio., 2019, Semiologia Gregoriana a Ritroso
   Rankin Susan., 1994, Carolingian Culture: Emulation and Innovation
   Reale Giovanni., 2009, ι
   Riche Pierre., 2019, Nani Sulle Spalle di Giganti: Maestri e Allievi Nel Medioevo, V2nd ed.
   Righetti Mario., 2014, Storia Liturgica, V3rd
   Romano John F., 2020, Liturgy and Society in Early Medieval Rome
   Ruini Cesarino., 2011, Atlante Storico della Musica Nel Medioevo
   Sacrosanctum Concilium, Oecumenicum Vaticanum II Constitution on the Sacred Liturgy Sacrosanctum Concilium, Solemnly Promulgated by His Holiness Pope Paul VI on December 4 1963b
   Simonetti Manlio., 1976, De zelo Et Livore
   Sloboda John., 2012, Handbook of Music and Emotion: Theory, Research, Applications, V3rd ed., P73
   Steck Wolfgang, 2000, Der liturgiker Amalarius: Eine quellenkritische Untersuchung zu Leben und Werk eines Theologen der Karolingerzeit
   Tabacco Giovanni., 2010, Alto Medioevo
   Vagaggini Cipriano., 1999, Il Senso Teologico della Liturgia, V6th ed.
   Vauchez Andre., 2020, La Spiritualita dell'Occidente Medioevale
   Vedris Trpimir., 2018, Imperial Spheres and the Adriatic: Byzantium, the Carolingians and the Treaty of Aachen (812), P288
   Viret Jacques., 2016, Musica Medievale
   Walters Robertson Anne., 2000, The Divine Office in the Latin Middle Ages: Methodology and Source Studies, Regional Developments, Hagiography
   William of Malmesbury, 1980, Recherches de Theologie Ancienne et Medievale, V47, P113
   Wilmart Andre., 1922, Dictionnaire d'Archeologie Chretienne et de Liturgie, Vvol. 5/1, P1014
   Zambon Francesco., 2021, Una Breve Storia dall'Antichita a Dante
NR 103
TC 0
Z9 0
U1 1
U2 1
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2077-1444
J9 RELIGIONS
JI Religions
PD OCT
PY 2023
VL 14
IS 10
AR 1237
DI 10.3390/rel14101237
PG 14
WC Religion
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Religion
GA X0GG1
UT WOS:001095316000001
OA gold
DA 2024-01-09
ER

PT J
AU Cheng, TH
   Tsai, CG
AF Cheng, Tzu-Han
   Tsai, Chen-Gia
TI Female Listeners' Autonomic Responses to Dramatic Shifts Between Loud
   and Soft Music/Sound Passages: A Study of Heavy Metal Songs
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE arousal; heart rate; heavy metal music; relaxation; respiration rate
ID HEART-RATE-VARIABILITY; MUSIC-THERAPY; PHYSIOLOGICAL-RESPONSES;
   PSYCHOPHYSIOLOGICAL RESPONSES; RESPIRATORY RESPONSES; EMOTIONAL INERTIA;
   MENTAL STRESS; ANXIETY; HEALTHY; ANTICIPATION
AB Although music and the emotion it conveys unfold over time, little is known about how listeners respond to shifts in musical emotions. A special technique in heavy metal music utilizes dramatic shifts between loud and soft passages. Loud passages are penetrated by distorted sounds conveying aggression, whereas soft passages are often characterized by a clean, calm singing voice and light accompaniment. The present study used heavy metal songs and soft sea sounds to examine how female listeners' respiration rates and heart rates responded to the arousal changes associated with auditory stimuli. The high-frequency power of heart rate variability (HF-HRV) was used to assess cardiac parasympathetic activity. The results showed that the soft passages of heavy metal songs and soft sea sounds expressed lower arousal and induced significantly higher HF-HRVs than the loud passages of heavy metal songs. Listeners' respiration rate was determined by the arousal level of the present music passage, whereas the heart rate was dependent on both the present and preceding passages. Compared with soft sea sounds, the loud music passage led to greater deceleration of the heart rate at the beginning of the following soft music passage. The sea sounds delayed the heart rate acceleration evoked by the following loud music passage. The data provide evidence that sound-induced parasympathetic activity affects listeners' heart rate in response to the following music passage. These findings have potential implications for future research on the temporal dynamics of musical emotions.
C1 [Cheng, Tzu-Han] Natl Taiwan Univ, Dept Psychol, Taipei 10764, Taiwan.
   [Tsai, Chen-Gia] Natl Taiwan Univ, Grad Inst Musicol, Taipei 10764, Taiwan.
   [Tsai, Chen-Gia] Natl Taiwan Univ, Ctr Neurobiol & Cognit Sci, Taipei 10764, Taiwan.
C3 National Taiwan University; National Taiwan University; National Taiwan
   University
RP Tsai, CG (corresponding author), Natl Taiwan Univ, Grad Inst Musicol, Taipei 10764, Taiwan.; Tsai, CG (corresponding author), Natl Taiwan Univ, Ctr Neurobiol & Cognit Sci, Taipei 10764, Taiwan.
EM tsaichengia@ntu.edu.tw
RI Cheng, Tzu-Han Zoe/IAM-1798-2023
OI Cheng, Tzu-Han Zoe/0000-0003-1687-8304; Tsai,
   Chen-Gia/0000-0001-9398-6080
FU Ministry of Science and Technology of Taiwan [MOST 103-2410-H-002-175]
FX This research was supported by grants from the Ministry of Science and
   Technology of Taiwan (MOST 103-2410-H-002-175).
CR ACOSTA A, 1990, COGNITION EMOTION, V4, P145, DOI 10.1080/02699939008407144
   ARNETT JJ, 1995, J YOUTH ADOLESCENCE, V24, P519, DOI 10.1007/BF01537054
   Bachorik JP, 2009, MUSIC PERCEPT, V26, P355, DOI 10.1525/MP.2009.26.4.355
   Bardo MT, 1996, BEHAV BRAIN RES, V77, P23, DOI 10.1016/0166-4328(95)00203-0
   BERLYNE DE, 1970, PERCEPT PSYCHOPHYS, V8, P279, DOI 10.3758/BF03212593
   Bevins RA, 1999, BEHAV BRAIN RES, V99, P53, DOI 10.1016/S0166-4328(98)00069-2
   Boiten FA, 1998, BIOL PSYCHOL, V49, P29, DOI 10.1016/S0301-0511(98)00025-8
   Camm AJ, 1996, CIRCULATION, V93, P1043
   Chalmers JA, 2014, FRONT PSYCHIATRY, V5, DOI 10.3389/fpsyt.2014.00080
   Chuang CY, 2011, INTEGR CANCER THER, V10, P312, DOI 10.1177/1534735411400311
   Chuang CY, 2010, COMPLEMENT THER MED, V18, P224, DOI 10.1016/j.ctim.2010.08.003
   Coutinho E, 2011, EMOTION, V11, P921, DOI 10.1037/a0024700
   da Silva SAF, 2014, INT CARDIOVASC RES J, V8, P105
   Daniel P, 1997, ACUSTICA, V83, P113
   Dolese M. J., 2005, B PSYCHOL ARTS, V5, P21
   Egermann H, 2009, INT J INTERNET SCI, V4, P4
   Etzel JA, 2006, INT J PSYCHOPHYSIOL, V61, P57, DOI 10.1016/j.ijpsycho.2005.10.025
   FANTZ RL, 1964, SCIENCE, V146, P668, DOI 10.1126/science.146.3644.668
   Geisler FCM, 2010, PERS INDIV DIFFER, V49, P723, DOI 10.1016/j.paid.2010.06.015
   Gomez P, 2004, INT J PSYCHOPHYSIOL, V53, P91, DOI 10.1016/j.ijpsycho.2004.02.002
   Good Marion, 2002, Pain Manag Nurs, V3, P61, DOI 10.1053/jpmn.2002.123846
   Gowensmith WN, 1997, J MUSIC THER, V34, P33, DOI 10.1093/jmt/34.1.33
   Granot RY, 2011, MUSIC PERCEPT, V28, P219, DOI 10.1525/MP.2011.28.3.219
   Grewe O, 2009, MUSIC PERCEPT, V27, P61, DOI 10.1525/MP.2009.27.1.61
   Knight WEJ, 2001, J MUSIC THER, V38, P254, DOI 10.1093/jmt/38.4.254
   Kobayashi H, 2012, J PHYSIOL ANTHROPOL, V31, DOI 10.1186/1880-6805-31-9
   Koelsch S, 2015, EUR HEART J, V36, P3043, DOI 10.1093/eurheartj/ehv430
   Koval P, 2012, COGNITION EMOTION, V26, P1412, DOI 10.1080/02699931.2012.667392
   KRAUS JC, 1991, MUSIC THEOR SPECTRUM, V13, P21, DOI 10.1525/mts.1991.13.1.02a00020
   Krumhansl CL, 1997, CAN J EXP PSYCHOL, V51, P336, DOI 10.1037/1196-1961.51.4.336
   Kuehl LK, 2015, INT J PSYCHOPHYSIOL, V95, P299, DOI 10.1016/j.ijpsycho.2014.12.003
   Kuppens P, 2012, EMOTION, V12, P283, DOI 10.1037/a0025046
   Kuppens P, 2010, PSYCHOL SCI, V21, P984, DOI 10.1177/0956797610372634
   Li CW, 2015, BRAIN RES, V1629, P160, DOI 10.1016/j.brainres.2015.10.024
   Lin MF, 2011, J CLIN NURS, V20, P988, DOI 10.1111/j.1365-2702.2010.03525.x
   Mann SL, 2015, INT J PSYCHOPHYSIOL, V98, P76, DOI 10.1016/j.ijpsycho.2015.07.003
   Masaoka Y, 1997, INT J PSYCHOPHYSIOL, V27, P153, DOI 10.1016/S0167-8760(97)00052-4
   Masaoka Y, 1999, J APPL PHYSIOL, V86, P1329, DOI 10.1152/jappl.1999.86.4.1329
   Masaoka Y, 2001, RESP PHYSIOL, V128, P171, DOI 10.1016/S0034-5687(01)00278-X
   Mazurak N, 2013, EUR J CLIN NUTR, V67, P401, DOI 10.1038/ejcn.2013.32
   Nater UM, 2006, INT J PSYCHOPHYSIOL, V62, P300, DOI 10.1016/j.ijpsycho.2006.05.011
   Nilsson U, 2001, ACTA ANAESTH SCAND, V45, P812, DOI 10.1034/j.1399-6576.2001.045007812.x
   Okada K, 2009, INT HEART J, V50, P95, DOI 10.1536/ihj.50.95
   Olst E. H., 1971, THE ORIENTING REFLEX
   Parducci A., 1995, Happiness, Pleasure, and Judgment: The Contextual Theory and Its Applications
   PARKER S, 2008, PSYCHOL AESTHET CREA, V2, P171, DOI DOI 10.1037/1931-3896.2.3.171
   Peng SM, 2009, J ALTERN COMPLEM MED, V15, P53, DOI 10.1089/acm.2008.0243
   Pumprla J, 2002, INT J CARDIOL, V84, P1, DOI 10.1016/S0167-5273(02)00057-8
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Salimpoor VN, 2011, NAT NEUROSCI, V14, P257, DOI 10.1038/nn.2726
   Salimpoor VN, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0007487
   Schellenberg EG, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00574
   Schubert E, 2004, MUSIC PERCEPT, V21, P561, DOI 10.1525/mp.2004.21.4.561
   Schubert E., 1996, PSYCHOL MUSIC, V24, P18, DOI DOI 10.1177/0305735696241003
   Schwartz KD, 2003, J YOUTH ADOLESCENCE, V32, P205, DOI 10.1023/A:1022547520656
   Selfhout MHW, 2008, YOUTH SOC, V39, P435, DOI 10.1177/0044118X07308069
   Shafron GR, 2013, PSYCHOL POP MEDIA CU, V2, P74, DOI 10.1037/a0031722
   Sharman L, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00272
   STACK S, 1994, SUICIDE LIFE-THREAT, V24, P15
   Trost W, 2012, CEREB CORTEX, V22, P2769, DOI 10.1093/cercor/bhr353
   Tsai CG, 2015, J NEW MUSIC RES, V44, P271, DOI 10.1080/09298215.2015.1043310
   Tsai CG, 2014, MUSIC SCI, V18, P410, DOI 10.1177/1029864914542671
   Tsai CG, 2010, MUSIC PERCEPT, V27, P209, DOI 10.1525/MP.2010.27.3.209
   Van Diest I, 2001, PSYCHOPHYSIOLOGY, V38, P961
   Visnovcova Z, 2015, ADV EXP MED BIOL, V832, P45, DOI 10.1007/5584_2014_10
   Vuoskoski JK, 2011, CORTEX, V47, P1099, DOI 10.1016/j.cortex.2011.04.011
   WITVLIET CV, 1995, PSYCHOPHYSIOLOGY, V32, P436
   Zellner DA, 2003, PSYCHON B REV, V10, P468, DOI 10.3758/BF03196508
   Zellner DA, 2010, ATTEN PERCEPT PSYCHO, V72, P1261, DOI 10.3758/APP.72.5.1261
   Zillmer E., 2008, Principles of Neuropsychology
NR 70
TC 6
Z9 7
U1 2
U2 47
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD FEB 17
PY 2016
VL 7
AR 182
DI 10.3389/fpsyg.2016.00182
PG 11
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA DD9HL
UT WOS:000370236200003
PM 26925009
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Fischer, K
   Niebuhr, O
   Jensen, LC
   Bodenhagen, L
AF Fischer, Kerstin
   Niebuhr, Oliver
   Jensen, Lars C.
   Bodenhagen, Leon
TI Speech Melody Matters-How Robots Profit from Using Charismatic Speech
SO ACM TRANSACTIONS ON HUMAN-ROBOT INTERACTION
LA English
DT Article
DE Human-robot interaction; prosody; social functions of speech; charisma;
   robot personality; persuasion
ID STEVE JOBS; EMOTION; VOICE; CREDIBILITY; PERCEPTION; COMPUTER; SPEAKER
AB In this article, we address to what extent the proverb "the sound makes the music" also applies to humanrobot interaction, and whether robots could profit from using speech characteristics similar to those used by charismatic speakers like Steve Jobs. In three empirical studies, we investigate the effects of using Steve Jobs' and Mark Zuckerberg's speech characteristics during the generation of robot speech on the robot's persuasiveness and its impressionistic evaluation. The three studies address different human-robot interaction situations, which range from online questionnaires to real-time interactions with a large service robot, yet all involve both behavioral measures and users' assessments. The results clearly show that robots can profit from using charismatic speech.
C1 [Fischer, Kerstin] Univ Southern Denmark, Dept Design & Commun, DK-6400 Sonderborg, Denmark.
   [Niebuhr, Oliver] Univ Southern Denmark, Mads Clausens Inst, Sonderborg, Denmark.
   [Jensen, Lars C.] Univ Southern Denmark, Sonderborg, Denmark.
   [Bodenhagen, Leon] Univ Southern Denmark, Maersk McKinney Moller Inst, Sonderborg, Denmark.
C3 University of Southern Denmark; University of Southern Denmark;
   University of Southern Denmark; University of Southern Denmark
RP Fischer, K (corresponding author), Univ Southern Denmark, Dept Design & Commun, DK-6400 Sonderborg, Denmark.
EM kerstin@sdu.dk; olni@sdu.dk; larscj@sdu.dk; lebo@mmmi.sdu.dk
RI Bodenhagen, Leon/Q-9790-2018; Niebuhr, Oliver/O-7639-2018; Niebuhr,
   Oliver/AAB-5675-2020
OI Bodenhagen, Leon/0000-0002-8083-0770; Niebuhr,
   Oliver/0000-0002-8623-1680; Niebuhr, Oliver/0000-0002-8623-1680; Jensen,
   Lars Christian/0000-0003-2830-3719; Fischer, Kerstin/0000-0003-1987-5344
FU Danish Innovation Fund
FX This study was partially funded by the Danish Innovation Fund (projects
   patient@home and Smooth).
CR Andrist S, 2015, ACMIEEE INT CONF HUM, P157, DOI 10.1145/2696454.2696464
   Andrist S, 2013, ACMIEEE INT CONF HUM, P341, DOI 10.1109/HRI.2013.6483608
   [Anonymous], 2001, NATURAL LANG ENG
   [Anonymous], 2005, Proceedings of InterspeechEurospeech, 9th European Conference on Speech Communication and Technology
   [Anonymous], 2013, INTRO PSYCHOL HEARIN
   Bainbridge W. A., 2010, INT J SOC ROBOT, P1
   Berger S., 2017, P 43 M GERM AC SOC D, P1
   Biadsy F., 2007, P 8 C INT SPEECH COM, P2221
   Boersma P., 2021, Glot International
   Campbell N., 2003, P 15 INT C PHON SCI, P2417
   Chidambaram Vijay, 2012, P IEEE ACM INT C HUM
   Clifford Nass, 2015, WIRED SPEECH VOICE A
   Crumpton J, 2016, INT J SOC ROBOT, V8, P271, DOI 10.1007/s12369-015-0329-4
   Dellwo Volker, 2007, Speaker Classification I. Fundamentals, Features, and Methods. (Lecture Notes in Artificial Intelligence vol. 4343), P1, DOI 10.1007/978-3-540-74200-5_1
   Dutoit T., 2013, INTRO TEXT TO SPEECH
   GelinasChebat C, 1996, PERCEPT MOTOR SKILL, V83, P243, DOI 10.2466/pms.1996.83.1.243
   Goetz J, 2003, RO-MAN 2003: 12TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P55
   Graf B, 2009, LECT NOTES COMPUT SC, V5611, P312, DOI [10.1007/978-3-642-02577-8_34, 10.1109/ARSO.2009.5587059]
   Gregory R. L., 1997, EYE BRAIN PSYCHOL SE
   Grigore Elena Corina, 2016, P INT VIRT AG C IVA
   Heracleous L, 2014, GROUP ORGAN MANAGE, V39, P131, DOI 10.1177/1059601114525436
   Jacobs T, 2012, 2012 IEEE WORKSHOP ON ADVANCED ROBOTICS AND ITS SOCIAL IMPACTS (ARSO), P46, DOI 10.1109/ARSO.2012.6213397
   Jiyoung I., 2015, INDIAN J SCI TECHNOL, V8, P48, DOI 10.17485/ijst/2015/v8iS5/61476
   Kanda T, 2008, IEEE T ROBOT, V24, P725, DOI 10.1109/TRO.2008.921566
   Ladd D.Robert., 2014, SIMULTANEOUS STRUCTU
   Lambrecht L, 2014, COGNITION EMOTION, V28, P452, DOI 10.1080/02699931.2013.837378
   Landgraf R., 2014, 4 INT S TON ASP LANG
   Leyzberg D, 2011, ACMIEEE INT CONF HUM, P347, DOI 10.1145/1957656.1957789
   Lorenzo-Trueba J, 2015, COMPUT SPEECH LANG, V34, P292, DOI 10.1016/j.csl.2015.03.008
   Malte Jung, 2017, P IEEE ACM INT C HUM
   Mannell R., 2017, INTRO PROSODY THEORI
   Mutlu B, 2011, AI MAG, V32, P17, DOI 10.1609/aimag.v32i4.2376
   Niebuhr O., 2016, P 8 INT C SPEECH PRO, P1
   Niebuhr O., 2017, J SPEECH SCI, V6, P3, DOI DOI 10.20396/JOSS.V6I1.14983
   Niebuhr O., 2019, HDB PROSODY
   Niebuhr O, 2019, INT J ACOUST VIB, V24, P343
   Niebuhr O, 2017, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-017-0115-3
   Niebuhr O, 2016, COMPUT HUM BEHAV, V64, P366, DOI 10.1016/j.chb.2016.06.059
   Nienhuis M., 2009, P 10 TWENT STUD C TW, P1
   Nishio S., 2012, P IEEE INT S ROB HUM
   Novak-Tot E., 2017, P 18 C INT SPEECH CO, P1
   Pejic A., 2014, NOVEAUX CAHIERS LING, V31, P141
   Powers A., 2006, P HUM ROB INT C HRI
   Read R, 2014, ACMIEEE INT CONF HUM, P41, DOI 10.1145/2559636.2559680
   Read Robin G., 2010, Proceedings: 3rd International Workshop on Affective Interaction in Natural Environments (AFFINE), Firenze, Italy, P65
   Rosenberg A, 2009, SPEECH COMMUN, V51, P640, DOI 10.1016/j.specom.2008.11.001
   Rudzicz Frank, 2015, T ACCESSIBLE COMPUTI, V7, P2
   Schuller B, 2015, COMPUT SPEECH LANG, V29, P100, DOI 10.1016/j.csl.2014.08.003
   SELTING M, 1994, J PRAGMATICS, V22, P375, DOI 10.1016/0378-2166(94)90116-3
   Signorello R, 2013, INTERSPEECH, P987
   Skerry-Ryan RJ, 2018, PR MACH LEARN RES, V80
   Stern SE, 2006, INT J HUM-COMPUT ST, V64, P43, DOI 10.1016/j.ijhcs.2005.07.002
   Stibbard R, 2001, THESIS
   Strait M., 2014, P IEEE ACM INT C HUM
   Taylor Paul, 2009, TEXT TO SPEECH SYNTH
   Tielman M, 2014, ACMIEEE INT CONF HUM, P407, DOI 10.1145/2559636.2559663
   Tylekov├i, 2018, P 9 INT C SPEECH PRO, P359, DOI DOI 10.21437/SPEECHPROSODY.2018-73.
   Viswanath U, 2015, 2015 IEEE 10TH INTERNATIONAL CONFERENCE ON GLOBAL SOFTWARE ENGINEERING WORKSHOPS (ICGSEW 2015), P12, DOI 10.1109/ICGSEW.2015.18
   Walters M. L., 2008, P IEEE INT S ROB HUM
NR 59
TC 16
Z9 16
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
EI 2573-9522
J9 ACM T HUM-ROBOT INTE
JI ACM Trans. Hum.-Robot Interact.
PD JAN
PY 2020
VL 9
IS 1
AR 4
DI 10.1145/3344274
PG 21
WC Robotics
WE Emerging Sources Citation Index (ESCI)
SC Robotics
GA KJ8GI
UT WOS:000512293700004
OA Green Submitted, Bronze
DA 2024-01-09
ER

PT J
AU Luo, CP
AF Luo, Chengping
TI Waveform Feature Extraction of Intelligent Singing Skills under the
   Background of Internet of Things
SO MOBILE INFORMATION SYSTEMS
LA English
DT Article
AB Aiming at the complex and changeable characteristics of intelligent singing skills in the context of Internet of Things, this paper proposes a feature extraction method suitable for intelligent singing skills in this context. Firstly, focusing on vocal features, the time-domain algorithm based on open-loop and closed-loop gene extraction extracts the genetic features of songs with accompaniment; then, the section and its features are extracted by using the windowed moving matching algorithm, and the segments are divided by using the similarity between adjacent segments to obtain the segment features with emotional factors. The segment features are input into the improved BP emotion recognizer for emotion recognition. Finally, the intelligent singing skills of the whole music are determined. The experimental results show that, with the increase in feature extraction time, the accuracy of the extraction results of the existing methods changes little, which is basically maintained at a low level between 15% and 30%. When the proposed method is for feature extraction of intelligent singing skill information, the accuracy shows a continuous growth trend, and with the growth of time, its accuracy is significantly higher than the existing methods, indicating that the proposed method has significant advantages in the accuracy of feature extraction. Because this waveform feature extraction method is applied to the intelligent singing skills under the background of the Internet of Things, it has the advantages of high extraction efficiency, high accuracy, and reliability.
C1 [Luo, Chengping] Jiangxi Normal Univ, Conservatory Mus, Nanchang 330000, Jiangxi, Peoples R China.
C3 Jiangxi Normal University
RP Luo, CP (corresponding author), Jiangxi Normal Univ, Conservatory Mus, Nanchang 330000, Jiangxi, Peoples R China.
EM 003772@jxnu.edu.cn
CR Ahmadi-Asl S., 2021, IEEE ACCESS, V99, P1
   Anshakov G. P., 2021, Journal of Physics: Conference Series, V1791, DOI 10.1088/1742-6596/1791/1/012001
   Asghar MA, 2022, MULTIMEDIA SYST, V28, P1275, DOI 10.1007/s00530-021-00782-w
   Chen L., 2021, IEEE ACCESS, V99, P1
   Chen WL, 2020, IEEE INTERNET THINGS, V7, P1001, DOI 10.1109/JIOT.2019.2947624
   Chu CH, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8814658
   Ding X., 2020, IEEE ACCESS, V99, P1
   Epp V, 2021, HIST Z, V312, P499, DOI 10.1515/hzhz-2021-1109
   Goux N., 2020, IEEE SOLID-ST CIRC L, V99, P1
   Hanifa RM, 2021, COMPUT ELECTR ENG, V90, DOI 10.1016/j.compeleceng.2021.107005
   Hassan M., 2020, IEEE T IND INFORM, V99, P1
   Kaluri R, 2021, INTELL AUTOM SOFT CO, V27, P453, DOI 10.32604/iasc.2021.014369
   Krishnamurthi R, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20216076
   Lin T, 2020, J INTELL FUZZY SYST, V39, P8623, DOI 10.3233/JIFS-189258
   Liu Y, 2021, COMPUT COMMUN, V178, P245, DOI 10.1016/j.comcom.2021.08.002
   Oliva G, 2021, CHEMOSPHERE, V271, DOI 10.1016/j.chemosphere.2021.129768
   Tan C, 2020, NEURAL COMPUT APPL, V32, P16917, DOI 10.1007/s00521-019-04023-0
   Tan JY, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3433539
   Wang YX, 2021, INT J ELEC POWER, V125, DOI 10.1016/j.ijepes.2020.106484
   Xiao ZW, 2021, KNOWL-BASED SYST, V229, DOI 10.1016/j.knosys.2021.107338
   Yang W, 2020, IOP CONF SER-MAT SCI, V853, DOI 10.1088/1757-899X/853/1/012001
   Yaseen A, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8897026
   Yin CY, 2022, IEEE T SYST MAN CY-S, V52, P112, DOI 10.1109/TSMC.2020.2968516
   Zheng TY, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/5567017
NR 24
TC 0
Z9 0
U1 0
U2 3
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1574-017X
EI 1875-905X
J9 MOB INF SYST
JI Mob. Inf. Syst.
PD JUN 28
PY 2022
VL 2022
AR 4638801
DI 10.1155/2022/4638801
PG 11
WC Computer Science, Information Systems; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA 2Z1ET
UT WOS:000826329600015
OA gold
DA 2024-01-09
ER

PT J
AU Mehr, SA
   Singh, M
   York, H
   Glowacki, L
   Krasnow, MM
AF Mehr, Samuel A.
   Singh, Manvir
   York, Hunter
   Glowacki, Luke
   Krasnow, Max M.
TI Form and Function in Human Song
SO CURRENT BIOLOGY
LA English
DT Article
ID MUSIC; EVOLUTION; EMOTION; SOUND; UNIVERSALS
AB Humansuse music for a variety of social functions: we sing to accompany dance, to soothe babies, to heal illness, to communicate love, and so on. Across animal taxa, vocalization forms are shaped by their functions, including in humans. Here, we show that vocal music exhibits recurrent, distinct, and cross-culturally robust form-function relations that are detectable by listeners across the globe. In Experiment 1, internet users (n = 750) in 60 countries listened to brief excerpts of songs, rating each song's function on six dimensions (e.g., "used to soothe a baby''). Excerpts were drawn from a geographically stratified pseudorandom sample of dance songs, lullabies, healing songs, and love songs recorded in 86 mostly small-scale societies, including hunter-gatherers, pastoralists, and subsistence farmers. Experiment 1 and its analysis plan were pre-registered. Despite participants' unfamiliarity with the societies represented, the random sampling of each excerpt, their very short duration (14 s), and the enormous diversity of this music, the ratings demonstrated accurate and cross-culturally reliable inferences about song functions on the basis of song forms alone. In Experiment 2, internet users (n = 1,000) in the United States and India rated three contextual features (e.g., gender of singer) and seven musical features (e.g., melodic complexity) of each excerpt. The songs' contextual features were predictive of Experiment 1 function ratings, but musical features and the songs' actual functions explained unique variance in function ratings. These findings are consistent with the existence of universal links between form and function in vocal music.
C1 [Mehr, Samuel A.; Krasnow, Max M.] Harvard Univ, Dept Psychol, 33 Kirkland St, Cambridge, MA 02138 USA.
   [Mehr, Samuel A.] Harvard Univ, Data Sci Initiat, 1350 Massachusetts Ave, Cambridge, MA 02138 USA.
   [Mehr, Samuel A.] Victoria Univ Wellington, Sch Psychol, Wellington 6012, New Zealand.
   [Singh, Manvir; York, Hunter] Harvard Univ, Dept Human Evolutionary Biol, Peabody Museum, 11 Divin Ave, Cambridge, MA 02138 USA.
   [Glowacki, Luke] Inst Adv Study Toulouse, 21 Allee Brienne, F-31015 Toulouse, France.
   [Glowacki, Luke] Penn State Univ, Dept Anthropol, 410 Carpenter Bldg, University Pk, PA 16802 USA.
C3 Harvard University; Harvard University; Victoria University Wellington;
   Harvard University; Pennsylvania Commonwealth System of Higher Education
   (PCSHE); Pennsylvania State University; Pennsylvania State University -
   University Park
RP Mehr, SA (corresponding author), Harvard Univ, Dept Psychol, 33 Kirkland St, Cambridge, MA 02138 USA.; Mehr, SA (corresponding author), Harvard Univ, Data Sci Initiat, 1350 Massachusetts Ave, Cambridge, MA 02138 USA.; Mehr, SA (corresponding author), Victoria Univ Wellington, Sch Psychol, Wellington 6012, New Zealand.; Mehr, SA; Singh, M (corresponding author), Harvard Univ, Dept Human Evolutionary Biol, Peabody Museum, 11 Divin Ave, Cambridge, MA 02138 USA.
EM sam@wjh.harvard.edu; manvirsingh@fas.harvard.edu
RI Singh, Manvir/K-9698-2019
OI York, Hunter/0000-0001-5084-5966; Mehr, Samuel/0000-0002-9400-7718
FU Harvard University Department of Psychology; National Science Foundation
   Graduate Research Fellowship Program; Harvard College Research Program;
   ANR - Labex IAST; Harvard Data Science Initiative; National Institutes
   of Health Director's Early Independence Award [DP5OD024566]
FX This work was supported by the Harvard University Department of
   Psychology (M.M.K.), the National Science Foundation Graduate Research
   Fellowship Program (M.S.), the Harvard College Research Program (H.Y.),
   ANR - Labex IAST (L.G.), the Harvard Data Science Initiative (S.A.M.),
   and the National Institutes of Health Director's Early Independence
   Award DP5OD024566 (S.A.M.). We thank the participants; J. McDermott and
   K. Woods for sharing their headphone screening task and assisting us
   with it; R. Howard and L. Lopez for research assistance; G. Bryant, D.
   Locke, A. Lomax Wood, A. Martin, J. McDermott, J. Nemirow, T. O'Donnell,
   K. Panchanathan, J. Rekedal, and E. Spelke for comments on the
   manuscript; G. North and four anonymous reviewers for their constructive
   feedback; and S. Pinker and the members of the Evolutionary Psychology
   Laboratory at Harvard University for many productive discussions that
   led to this work.
CR Aarts AA, 2015, SCIENCE, V349, DOI 10.1126/science.aac4716
   [Anonymous], 1968, FOLK SONG STYLE CULT
   Balkwill LL, 2004, JPN PSYCHOL RES, V46, P337, DOI 10.1111/j.1468-5584.2004.00265.x
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Blasi DE, 2016, P NATL ACAD SCI USA, V113, P10818, DOI 10.1073/pnas.1605782113
   Brown D., 1991, Human universals
   Brown S, 2013, PSYCHOL MUSIC, V41, P229, DOI 10.1177/0305735611425896
   Bryant GA, 2007, PSYCHOL SCI, V18, P746, DOI 10.1111/j.1467-9280.2007.01970.x
   Bryant GA, 2016, P NATL ACAD SCI USA, V113, P4682, DOI 10.1073/pnas.1524993113
   Bryant Gregory A, 2013, Front Psychol, V4, P990, DOI 10.3389/fpsyg.2013.00990
   CLUTTONBROCK TH, 1979, BEHAVIOUR, V69, P145, DOI 10.1163/156853979X00449
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   ENDLER JA, 1993, PHILOS T R SOC B, V340, P215, DOI 10.1098/rstb.1993.0060
   Filippi P, 2017, P ROY SOC B-BIOL SCI, V284, DOI 10.1098/rspb.2017.0990
   Fitch WT, 2002, ANIM BEHAV, V63, P407, DOI 10.1006/anbe.2001.1912
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   GRAY JP, 1980, AM J PHYS ANTHROPOL, V53, P441, DOI 10.1002/ajpa.1330530314
   Hagen EH, 2003, HUM NATURE-INT BIOS, V14, P21, DOI 10.1007/s12110-003-1015-z
   Huntington Samuel., 1996, CLASH CIVILIZATIONS
   LADICH F, 1989, J FISH BIOL, V35, P531, DOI 10.1111/j.1095-8649.1989.tb03004.x
   LOMAX A, 1977, WORLD MUSIC, V19, P117
   Mehr SA, 2017, EVOL HUM BEHAV, V38, P674, DOI 10.1016/j.evolhumbehav.2016.12.005
   Meyer RK, 1998, MUSIC PERCEPT, V16, P135
   Miller G. F., 2000, MATING MIND SEXUAL C
   MORTON ES, 1977, AM NAT, V111, P855, DOI 10.1086/283219
   MUELLER HC, 1971, WILSON BULL, V83, P249
   Murdock G. P., 2008, OUTLINE CULTURAL MAT, V6th Edn
   Naroll R., 1967, Behavior Science Notes, V2, P70, DOI [10.1177/106939716700200202, DOI 10.1177/106939716700200202]
   Nettl Bruno, 1983, The study of ethnomusicology: Thirty-three discussions
   Owren MJ, 2001, EVOL ANTHROPOL, V10, P58, DOI 10.1002/evan.1014.abs
   Pinker S., 2002, The blank slate: The modern denial of human nature
   Puts DA, 2012, P ROY SOC B-BIOL SCI, V279, P601, DOI 10.1098/rspb.2011.0829
   Savage PE, 2015, P NATL ACAD SCI USA, V112, P8987, DOI 10.1073/pnas.1414495112
   Sell A, 2010, P ROY SOC B-BIOL SCI, V277, P3509, DOI 10.1098/rspb.2010.0769
   Singh Manvir, 2017, Behav Brain Sci, V41, pe66, DOI 10.1017/S0140525X17001893
   TREHUB SE, 1993, INFANT BEHAV DEV, V16, P193, DOI 10.1016/0163-6383(93)80017-3
   UNDP, 2016, HUM DEV REP 2016 HUM
   Unyk AM., 1992, Psychol Music, V20, P15, DOI [10.1177/0305735692201002, DOI 10.1177/0305735692201002]
   WAGNER WE, 1989, BEHAV ECOL SOCIOBIOL, V25, P429, DOI 10.1007/BF00300189
   Woods KJP, 2017, ATTEN PERCEPT PSYCHO, V79, P2064, DOI 10.3758/s13414-017-1361-2
NR 40
TC 78
Z9 89
U1 2
U2 26
PU CELL PRESS
PI CAMBRIDGE
PA 50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA
SN 0960-9822
EI 1879-0445
J9 CURR BIOL
JI Curr. Biol.
PD FEB 5
PY 2018
VL 28
IS 3
BP 356
EP +
DI 10.1016/j.cub.2017.12.042
PG 18
WC Biochemistry & Molecular Biology; Biology; Cell Biology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Biochemistry & Molecular Biology; Life Sciences & Biomedicine - Other
   Topics; Cell Biology
GA FU8AX
UT WOS:000424075300019
PM 29395919
OA Green Accepted, hybrid
DA 2024-01-09
ER

PT J
AU Alonso, I
   Molina, S
   Porto, MD
AF Alonso, Isabel
   Molina, Silvia
   Dolores Porto, Maria
TI Multimodal digital storytelling Integrating information, emotion and
   social cognition
SO REVIEW OF COGNITIVE LINGUISTICS
LA English
DT Article
DE digital storytelling; multimodality; mental spaces; conceptual
   integration; narrative
AB Digital stories are a very recent multimedia practice by which ordinary people construct short narratives on personal affairs combining voice, images and sometimes music. This paper contributes to the description of this new emergent genre from both a multimodal and a cognitive point of view, by exploring how diverse semiotic channels in digital storytelling provide different kinds of information (factual, emotional, cultural, etc.) which are finally integrated to construct the global meaning of the narrative. For this purpose, we combine Kress and Van Leeuwen's (1996) scholarly work related to multimodal representation, with the use of some notions of the Mental Spaces and Conceptual Integration theory (Dancygier, 2008; Fauconnier & Turner, 2002). The results of this study are of interest to those concerned with the representational and communicational modes of semiotic resources in storytelling.
C1 [Alonso, Isabel] Univ Autonoma Madrid, E-28049 Madrid, Spain.
   [Molina, Silvia] Univ Politecn Madrid, ETSI Navales, E-28040 Madrid, Spain.
   [Dolores Porto, Maria] Univ Alcala de Henares, Alcala De Henares 28801, Spain.
C3 Autonomous University of Madrid; Universidad Politecnica de Madrid;
   Universidad de Alcala
RP Alonso, I (corresponding author), Univ Autonoma Madrid, C Tomas Valiente 3, E-28049 Madrid, Spain.
EM isabel.alonso@uam.es; silvia.molina@upm.es; mdolores.porto@uah.es
RI BELMONTE, ISABEL ALONSO/L-3069-2013; MOLINA, SILVIA/GQH-2897-2022;
   BELMONTE, ISABEL ALONSO/ABC-2900-2020; Porto, M Dolores/ABQ-7224-2022
OI BELMONTE, ISABEL ALONSO/0000-0001-8811-1976; BELMONTE, ISABEL
   ALONSO/0000-0001-8811-1976; Porto, M Dolores/0000-0003-0111-9356
CR [Anonymous], 2004, Narrative Across Media: The Languages of Storytelling
   [Anonymous], 1999, Researching and applying metaphor
   [Anonymous], OXFORD HDB COGNITIVE
   [Anonymous], 2008, MENTAL SPACES DISCOU
   Emmott C., 1997, Narrative Comprehension: A Discourse Perspective
   FAUCONNIER Gilles, 2002, The Way We Think. Conceptual Blending and the Mind's Hidden Complexity
   FAUCONNIER Gilles, 1997, Mappings in Thought and Language
   Halliday Michael A. K., 2004, INTRO FUNCTIONAL GRA, V3rd, DOI DOI 10.4324/9780203783771
   Herman D., 2003, NARRATIVE THEORY COG
   Herman D, 2009, APPL COGN LINGUIST, V10, P79
   Hodge R., 1988, Social semiotics
   Kress GR., 1996, Reading images: the grammar of visual design, DOI DOI 10.4324/9780203619728
   Kress Gunther, 2006, READING IMAGES GRAMM
   Labov W, 1967, ESSAYS VERBAL VISUAL, P12
   Lakoff George, 1989, More than Cool Reason: A Field Guide to Poetic Metaphor
   Meister Jan Christoph, 2005, Narratology beyond Literary Criticism: Mediality, Disciplinarity, P1, DOI DOI 10.1515/9783110201840.1
   O'Halloran KL, 2009, WORLD TOLD AND THE WORLD SHOWN: MULTISEMIOTIC ISSUES, P139
   Oakley T., 2008, Mental Spaces in Discourse and Interaction, P27
   Porto D., 2010, ACT JOURN ET NARR NE
   Semino E, 2009, APPL COGN LINGUIST, V10, P33
   Unsworth L., 2009, ROUTLEDGE HDB MULTIM, P151
NR 21
TC 7
Z9 9
U1 3
U2 41
PU JOHN BENJAMINS PUBLISHING COMPANY
PI AMSTERDAM
PA PO BOX 36224, 1020 ME AMSTERDAM, NETHERLANDS
SN 1877-9751
EI 1877-976X
J9 REV COGN LINGUIST
JI Rev. Cogn. Linguist.
PY 2013
VL 11
IS 2
BP 369
EP 387
DI 10.1075/rcl.11.2.10alo
PG 19
WC Linguistics; Language & Linguistics
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Linguistics
GA 295RC
UT WOS:000330132200010
DA 2024-01-09
ER

PT J
AU Liebowitz, M
   Tucker, MS
   Frontz, M
   Mulholland, S
AF Liebowitz, Marian
   Tucker, Mark Steven
   Frontz, Melanie
   Mulholland, Shaila
TI Participatory choral music as a means of engagement in a veterans'
   mental health and addiction treatment setting
SO ARTS & HEALTH
LA English
DT Article
DE vocal music; mental health; substance abuse; rehabilitation; veterans
ID THERAPY; BEHAVIOR
AB Background: the purpose of this study was to investigate how participation in a music-based performance and instruction program influenced the sense of engagement experienced by participants at a residential setting for at-risk veterans. Methods: semi-structured interviews were conducted with participants in a veterans' choir program conducted at the facility. Results: prominent themes that emerged from the interview included (1) the veterans' personal motivations for participating; (2) emotions associated with participation; and (3) perceptions of intragroup dynamics. Conclusions: primary conclusions drawn include: (1) opportunities to connect with others through shared interests may contribute to sense of engagement; (2) connections forged with other residents of the facility extended beyond relationships established in the choir through increased recognition associated with performances; and (3) the choir represented a diversion from pressing concerns and may have served as a means of facilitating adjustment to change at a measured pace.
C1 [Liebowitz, Marian] San Diego State Univ, Sch Mus & Dance, San Diego, CA 92182 USA.
   [Tucker, Mark Steven; Mulholland, Shaila] San Diego State Univ, Dept Adm Rehabil & Postsecondary Educ, San Diego, CA 92182 USA.
   [Frontz, Melanie] San Diego State Univ, Dept Commun, San Diego, CA 92182 USA.
C3 California State University System; San Diego State University;
   California State University System; San Diego State University;
   California State University System; San Diego State University
RP Tucker, MS (corresponding author), San Diego State Univ, Dept Adm Rehabil & Postsecondary Educ, San Diego, CA 92182 USA.
EM mtucker@interwork.sdsu.edu
CR [Anonymous], 2002, Musical identities
   [Anonymous], 2005, Psychology of Music, DOI DOI 10.1177/0305735605053734
   [Anonymous], 1998, MUSICKING
   Bensimon M, 2008, ART PSYCHOTHER, V35, P34, DOI 10.1016/j.aip.2007.09.002
   Bilmes L., 2013, FACULTY RES WORKING
   Boyce-Tillman June., 2000, Constructing Musical Healing: The Wounds that Sing
   Cohen M.L., 2009, J CORRECTIONAL ED, P52, DOI [10.1177/0032885519861082, DOI 10.1177/0032885519861082]
   CROWE BJ, 2004, MUSIC SOULMAKING NEW
   Dingle GA, 2008, DRUG ALCOHOL REV, V27, P190, DOI 10.1080/09595230701829371
   Dingle GA, 2013, PSYCHOL MUSIC, V41, P405, DOI 10.1177/0305735611430081
   Fischer H., 2013, RS22452
   Frontz M. K., 2013, THESIS SAN DIEGO STA
   Gardstrom SC, 1999, J MUSIC THER, V36, P207, DOI 10.1093/jmt/36.3.207
   Glaser Barney G., 2012, The discovery of grounded theory: Strategies for qualitative research, DOI DOI 10.4324/9780203793206
   Grocke D, 2009, J MUSIC THER, V46, P90, DOI 10.1093/jmt/46.2.90
   Judd M, 2014, PSYCHOL MUSIC, V42, P269, DOI 10.1177/0305735612471237
   Maratos AS, 2008, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD004517.pub2
   *NAT COAL HOM VET, BACKGR STAT
   National Institute on Drug Abuse, 2011, SUBST AB MIL VET THE
   Podolsky E., 1939, DOCTOR PRESCRIBES MU
   Research Triangle Institute, 2009, RTI10940FR
   Silber L., 2005, MUSIC EDUC RES, V7, P251, DOI DOI 10.1080/14613800500169811
   Silverman MJ, 2004, ART PSYCHOTHER, V31, P291, DOI 10.1016/j.aip.2004.06.008
   SOLOMON AL, 1980, J RES MUSIC EDUC, V28, P236, DOI 10.2307/3345033
   Storr A, 1992, MUSIC AND THE MIND
   Strauss A., 1998, Basics of Qualitative research: Grounded theory Procedures and Techniques, V2nd
   TANG WH, 1994, BRIT J PSYCHIAT, V165, P38, DOI 10.1192/S0007125000292969
   United States Department of Veterans Affairs, 2012, SUMM VA TREATM PROGR
   Von Lob G., 2010, INT J MENT HEALTH PR, V12, P45, DOI [DOI 10.1080/14623730.2010.9721818, 10.1080/14623730.2010.9721818]
   Wieser HG, 2003, ANN NY ACAD SCI, V999, P76, DOI 10.1196/annals.1284.007
   Worden MC, 1998, J MUSIC THER, V35, P259, DOI 10.1093/jmt/35.4.259
   Wounded Warrior Project, 2014, WHO WE SERV
NR 32
TC 4
Z9 5
U1 0
U2 7
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1753-3015
EI 1753-3023
J9 ARTS HEALTH
JI Arts Health
PY 2015
VL 7
IS 2
BP 137
EP 150
DI 10.1080/17533015.2014.999246
PG 14
WC Public, Environmental & Occupational Health
WE Social Science Citation Index (SSCI)
SC Public, Environmental & Occupational Health
GA CM4TS
UT WOS:000357678300005
DA 2024-01-09
ER

PT J
AU Wulff, HJ
AF Wulff, Hans J.
TI Of Singing, the Mechanical, and Emotions
SO ARCHIV FUR MUSIKWISSENSCHAFT
LA German
DT Article
DE 1920s avant-garde; dream; popular music; dandy song; gender roles
AB Fernand Leger's The Girl with the Prefabricated Heart from Hans Richter's episode movie Dreams That Money Can Buy (1947) connects the after-war reality to the importance of the mechanical and the dominant role of objects in avant-garde projects of the 1920s and combines them with the disintegration of subject sovereignty as a category and the substitution of the human body through puppets. It is based on a popular dandy song performed by two vocal stars of the 1940s-Libby Holman and Josh White and portrays a romantic love story with a fatal ending, told in animated scenes of mannequin dolls, abstract paintings, and objects from Leger's oeuvre that in the end lead to a collage of discursive differences: the popular vs. avant-garde; the clash between time concepts in music and image; heteronomous concepts of femininity; love and narcissism; and the changing relations between the real and the imaginary, especially in the pretended subjectivity of dreaming.
C1 [Wulff, Hans J.] Christian Albrechts Univ Kiel, Kiel, Germany.
C3 University of Kiel
RP Wulff, HJ (corresponding author), Christian Albrechts Univ Kiel, Kiel, Germany.
EM hwulff@uos.de
CR [Anonymous], 1936, Modern Times
   [Anonymous], 1947, DREAMS MONEY CAN BUY
   [Anonymous], 1948, NY TIMES
   [Anonymous], 1975, DIE SCHWARZE MUHLE
   [Anonymous], 1927, METROPOLIS
   Asper Helmut G., 2004, FILM DIENST, V57, P22
   Bradshaw Jon, 1985, DREAMS MONEY CAN BUY
   Dimitriu Christian, 2006, J FILM PRESERVATION, V72, P37
   Fincher David, 1989, EXPRESS YOURSELF
   Moritz William, 1995, LOVERS CINEMA 1 AM F, P127
   Muller-Thamm Pia, 1999, PUPPEN KORPER AUTOMA
   Mulvey Laura, 1994, WEIBLICHKEIT ALS MAS, P48
   Pollack Howard, 2017, BALLAD J LATOUCHE AM, P239
   Richter Hans, 1947, DREAMS MONEY CAN BUY, P14
   Schmidt-Pirro Julia, 2000, G ANTHEILS BALLET ME
   Spampinato Francesco, 2016, PERFORMING ARTS J, V113, P11
   Wald Elijah, 2000, J WHITE SOC BLUES
   Wulff Hans J., 2012, KULTURPOETIK, V12, P72
NR 18
TC 0
Z9 0
U1 0
U2 0
PU FRANZ STEINER VERLAG GMBH
PI STUTTGART
PA BIRKENWALDSTRABE 44, D-70191 STUTTGART, GERMANY
SN 0003-9292
J9 ARCH MUSIKWISS
JI Arch. Musikwiss.
PY 2018
VL 75
IS 3
BP 179
EP 192
PG 14
WC Music
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music
GA GZ6SN
UT WOS:000449575800002
DA 2024-01-09
ER

PT J
AU Pérez, MC
   González, LJ
   Aedo, JR
AF Perez, Marcy Campos
   Gonzalez, Laura Jordan
   Aedo, Javier Rodriguez
TI Transphonographies of Chilean exile in Europe
SO REVISTA MUSICAL CHILENA
LA English
DT Article
DE Discography; exile; Chile; transphonography; cover
AB Using a transphonographic model, this article examines the Chilean discography created during exile in Europe between 1973 and 1990. Through the study of numerous phonograms, we propose to understand the record as an object key to make visible the aesthetic transformations and to understand, in this sense, some characteristics of the Chilean exile. To show the artistic connections in a broad sense, aspects such as record production, commercial circulation, and intercultural musical receptions were examined. We identify the aspects that interacted in the recording process: the musicians (amateurs and professionals), the graphic imagery of the exiled artists, the experimentation with technologies, and the updating of musical styles. Considering arrangement, performance, and recording as three interconnected dimensions, we analyzed series of cases of musical covers and self-covers that represent different ways of handling emotions through vocal practices and the use of the soundbox. All these elements reveal the potential of music records as a cultural object of exile and demonstrate the richness of the transphonographic model.
C1 [Perez, Marcy Campos] Univ Paris 08, Paris, France.
   [Gonzalez, Laura Jordan; Aedo, Javier Rodriguez] Pontificia Univ Catolica Valparaiso, Valparaiso, Chile.
C3 Universite Paris-VIII; Pontificia Universidad Catolica de Valparaiso
RP Pérez, MC (corresponding author), Univ Paris 08, Paris, France.
EM mmcampos@uc.cl; laura.jordan@pucv.cl; jarodri1@uc.cl
CR ALTEN Michele, 2012, Ilcea, DOI 10.4000/ilcea.1411
   [Anonymous], 1999, MUSIQUES MONDE QUEST
   [Anonymous], OIDO PENSANTE, VX, P5, DOI [10.34096/oidopensante.v10n1.11336, DOI 10.34096/OIDOPENSANTE.V10N1.11336]
   [Anonymous], 2009, EVERYDAY TONALITY TO
   [Anonymous], 2015, MONDE S HIST ESPACES, V8, P141, DOI [10.3917/mond1.152.0141, DOI 10.3917/MOND1.152.0141]
   [Anonymous], 2013, AUDITEURS EXIL CAS C, VX, P147, DOI [10.4000/volume.3770, DOI 10.4000/VOLUME.3770]
   [Anonymous], 2019, RESONANCIAS, VXXIII, P171, DOI [10.7764/res.2019.45.7, DOI 10.7764/RES.2019.45.7]
   [Anonymous], CUADERNOS MUSICA IBE, V32, P137, DOI [10.5209/cmib.65528, DOI 10.5209/CMIB.65528]
   ARBO ALESSANDRO, 2014, MUSIQUE ENREGISTREME, P173
   Archivo de Musica Popular Chilena, FOND QUIL
   Archivo Historico, FOND PAIS
   Becker H.S., 1982, Art worlds
   BESSIERE BERNARD, 1980, NOUVELLE CHANSON CHI
   BIELETTO-BUENO NATALIA, 2020, J INTERDISCIPLINARY, P9, DOI [10.1386/jivs_00013_1, DOI 10.1386/JIVS_00013_1]
   BONNIN JUDITH, 2017, GENRE HUMAIN, VLVIII, P29, DOI [10.3917/lgh.058.0029, DOI 10.3917/LGH.058.0029]
   CAMPOS MARCY, 2016, ACONTECIMIENTOS HIST, P171
   CANALES JORGE, 2017, AMBITO SONORO, VII, P9
   CARRASCO EDUARDO, 1988, QUILAPAYUN REVOLUCIO
   Chappell W, 2020, J VOICE, V34, DOI 10.1016/j.jvoice.2018.06.004
   CIFUENTES LUIS, 1989, FRAGMENTOS SUENO INT
   Donoso Karen, 2019, Cultura y Dictadura: Censuras Proyecto e Institucionalidad Cultural en Chile, 1973-1989
   FIGUEROA GERARDO, 2018, VIENTOS PUEBLO REPRE, P163
   GARCIAPEINAZO D, 2019, ANDUL REV ANDALUZA C, V18, P73, DOI DOI 10.12795/ANDULI.2019.I18.04
   GAVAGNIN STEFANO, 2020, THESIS U ROMA SAPIEN
   GOMES CAIO DE SOUZA, 2015, NUEVO MUNDO MUNDOS N, DOI [10.4000/nuevomundo.68244, DOI 10.4000/NUEVOMUNDO.68244]
   GUERRERO JULIANA, 2019, CUADERNOS MUSICA IBE, V32, P73, DOI [10.5209/cmib.65531, DOI 10.5209/CMIB.65531]
   HENNION ANTOINE, 1983, SOCIOL TRAV, VXXV, P459, DOI [10.3406/sotra.1983.1949, DOI 10.3406/SOTRA.1983.1949]
   HERRERA SILVIA, 2018, VIENTOS PUEBLO REPRE, P133
   INFANTE PATRICIA, 2015, REV ESPANOLA LINGUIS, VXLV, P105
   Jordán L, 2009, REV MUSIC CHIL, V63, P77
   JORDAN Laura, 2014, Resonancias, V18, P15
   KARmY EILEEN, 2013, CANTATA POPULAR SANT, P45
   Karmy Eileen, 2014, PALIMPSESTOS SONOROS, P163
   LACASSE SERGE, 2010, INTRO TRANSPHONOGRAP, VVII, DOI [10.4000/volume.692, DOI 10.4000/VOLUME.692]
   LACASSE Serge, 2018, The Pop Palimpsest: Intertextuality in Recorded Popular Music, P9
   LE6N SILVIA, 1971, RITMO, VVI, P18
   Lemouneau C., 2015, BIFURCACIONES, V20, P1
   MADORY D., 2000, ARTE INVESTIGACION, V4, P90
   Moore AF, 2012, ASHG POP FOLK MUSIC, P1
   Olmedo Carrasco C., 2012, 1912 2012 SIGLO COMU
   PENA QUERALT PILAR, 2014, PALIMPSESTOS SONOROS, P117
   Prismas W, 1962, PRISMAS-ARG
   Rodriguez Aedo J., 2018, MUSICA CONSTRUCCION, P157
   Rodriguez Aedo Javier, 2014, Palimpsestos sonoros. Reflexiones sobre la Nueva Cancion Chilena, P219
   Rodriguez E., 2015, QUE FRACASO DEMOCRAC
   RODRIGUEZ JAVIER, 2020, THESIS U SORBONA
   Rodriguez-Plaza P., 2001, AISTHESIS, V34, P171, DOI [10.4206/aus.2017.n22-03, DOI 10.4206/AUS.2017.N22-03]
   SALINAS HORACIO, 2013, CANCION SOMBRERO HIS
   Schmiedecke N., 2014, PALIMPSESTOS SONOROS, P201
   Szendy P., 2001, Ecoute: une histoire de nos oreilles
   VALDEBENITO MAURICIO, 2014, PALIMPSESTOS SONOROS, P43
   VICO MAURICIO, 2008, CATEDRA ARTES, V5, P23
NR 52
TC 0
Z9 0
U1 0
U2 0
PU UNIV CHILE, FACULTY ARTS
PI SANTIAGO
PA CASILLA 2100, SANTIAGO, 1264, CHILE
SN 0716-2790
EI 0717-6252
J9 REV MUSIC CHIL
JI Rev. Music. Chil.
PD JAN-JUN
PY 2022
VL 76
IS 237
BP 9
EP 43
PG 35
WC Music
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music
GA 3S1XC
UT WOS:000839395000001
DA 2024-01-09
ER

PT J
AU Csehi, A
AF Csehi, Agata
TI THE TRANSFER EFFECT OF MUSICAL ACTIVITIES IN TERMS OF ABILITIES AND
   PERSONALITY DEVELOPMENT - ABOUT THE RESULTS OF A MUSIC-PEDAGOGICAL STUDY
SO AD ALTA-JOURNAL OF INTERDISCIPLINARY RESEARCH
LA English
DT Article
DE music; ability; personality development; transfer; research; study;
   educational
AB Music is an essential condition for both general development and educational work. It evokes emotions, has a therapeutic effect and affects both the individual's intellect and physical-mental-emotional world. As a result, in the last few years or decades, the impact of music and musical activities have become a central topic of more and more research. The requirements of modern education are also met by creative activities that have a broad transfer effect, spread their impact over several areas, a multitude of skills and have a positive effect on the development of the whole personality as well. In the present paper, we demonstrate the results of such study. In our music-pedagogical study, focusing on the elements of production and reproduction, perception and reception, we summarize the ability-developing and personality-developing effects of the use of creative - instrumental and vocal-instrumental - musical activities.
C1 [Csehi, Agata] J Selye Univ, Bratislavska Cesta 3322, Komarno 94501, Slovakia.
C3 J. Selye University
RP Csehi, A (corresponding author), J Selye Univ, Bratislavska Cesta 3322, Komarno 94501, Slovakia.
EM csehiovaa@ujs.sk
CR [Anonymous], 2002, NEW HDB RES MUSIC TE
   BAKOS A., 2014, ZENEPEDAGOG ZENETERO, P13
   Barkoczi Ilona, 1977, KODALY ZENEI NEVELES
   CSEHI A., 2019, PEDAGOGICAL RES CARP, P362
   CSEHI A., 2018, 8 TREF AG SZSF K BUD, P89
   DOBRAY I., 1983, ZENEHALLGATOS FELADA
   DOMBI KEMENY E., 1999, ZENEI KEPESSEGVIZSGO
   Eros, 1993, ZENEI ALAPKEPESSEG
   FALUS A., 2016, ZENE EGESZSEG ZENE E
   FRANEK M., 2007, HUDEBNI PSYCHOL
   Gordon E., 1971, MUSIC EDUCATORS J, V57, P35
   Horváthová K, 2017, J LANG CULT EDUC, V5, P93, DOI 10.1515/jolace-2017-0030
   JANURIK M., 2013, ZENEI KEPESSEGEK FEJ, P75
   KANCZNE NAGY K., 2007, GYERMEK NEVELES PEDA
   Kodaly Zoltan, 1974, VISSZATEKINTES
   Kokas Klara, 1972, KEPESSEGFEJLESZTES Z
   MARTON A., 2016, PEDAGOGIAI FOLYOIRAT, P72
   MATEJOVA Z., 1993, ZAKLADY TEORIE PRAXE
   MICHEL P., 1964, ZENEI KEPESSEG ZENEI
   ORSOVICS Y., 2018, SZEMELYISEGFEJLESZTE
   PAVLOVSKA O., 1980, POSOBENIE HUDBY HAND
   POLEDNAK I., 1984, STRUCNY SLOVNIK HUDE
   Schwarzer G., 1997, PSYCHOL MUSIC, V25, P35, DOI [DOI 10.1177/0305735697251004, 10.1177/0305735697251004]
   SZONYI E., 1988, ZENEI NEVELESIRANYZA
   TEPLOV B. M., 1965, PSYCHOL HUDEBNICH SC
   TICHA L., 2009, SLYSET MYSLET KLAVIR
   TOTH P., 2011, EGYENI KULONBSEGEK S
   TOTH-BAKOS A., 2015, ZBORNIK MEDZINARODNE, P163
   Tóth-Bakos A, 2016, INTED PROC, P1726
   Tóth-Bakos A, 2016, INTED PROC, P1643
   Turmezeyne Heller Erika., 2005, MAGYAR PEDAG GIA, V105, P207
NR 31
TC 1
Z9 1
U1 1
U2 2
PU MAGNANIMITAS
PI HRADEC KRALOVE
PA CESKOSLOVENSKE ARMADY 300, HRADEC KRALOVE, 500 03, CZECH REPUBLIC
SN 1804-7890
J9 AD ALTA-INTERDISCIP
JI AD ALTA-J. Interdiscip. Res.
PY 2020
VL 10
IS 2
BP 46
EP 50
PG 5
WC Multidisciplinary Sciences
WE Emerging Sources Citation Index (ESCI)
SC Science & Technology - Other Topics
GA PQ1RK
UT WOS:000606326200006
DA 2024-01-09
ER

PT J
AU Bartels, J
   Rodenbach, R
   Ciesinski, K
   Gramling, R
   Fiscella, K
   Epstein, R
AF Bartels, Josef
   Rodenbach, Rachel
   Ciesinski, Katherine
   Gramling, Robert
   Fiscella, Kevin
   Epstein, Ronald
TI Eloquent silences: A musical and lexical analysis of conversation
   between oncologists and their patients
SO PATIENT EDUCATION AND COUNSELING
LA English
DT Article
DE Compassion; Empathy; Patient-centered; Silence; Music; Paralinguistic;
   Emotion; End-of-life; Healthcare communication; Engagement; Connection;
   Presence; Interpersonal synchrony; Dialog rhythm; Discourse analysis
ID CENTERED COMMUNICATION; DECISION-MAKING; ADVANCED CANCER; SHARED MIND;
   SPEECH; VOICE
AB Objective: Silences in doctor-patient communication can be "connectional" and communicative, in contrast to silences that indicate awkwardness or distraction. Musical and lexical analyses can identify and characterize connectional silences in consultations between oncologists and patients.
   Methods: Two medical students and a professor of voice screened all 1211 silences over 2 s in length from 124 oncology office visits. We developed a "strength of connection" taxonomy and examined ten connectional silences for lexical and musical features including pitch, volume, and speaker turn-taking rhythm.
   Results: We identified connectional silences with good reliability. Typical dialog rhythms surrounding connectional silences are characterized by relatively equal turn lengths and frequent short vocalizations. We found no pattern of volume and pitch variability around these silences. Connectional silences occurred in a wide variety of lexical contexts.
   Conclusion: Particular patterns of dialog rhythm mark connectional silences. Exploring structures of connectional silence extends our understanding of the audio-linguistic conditions that mark patient-clinician connection.
   Practice implications: Communicating with an awareness of pitch, rhythm, and silence - in addition to lexical content - can facilitate shared understanding and emotional connection. (C) 2016 Elsevier Ireland Ltd. All rights reserved.
C1 [Bartels, Josef; Rodenbach, Rachel] Univ Rochester, Sch Med & Dent, 601 Elmwood Ave, Rochester, NY 14642 USA.
   [Ciesinski, Katherine] Eastman Sch Mus, 26 Gibbs St, Rochester, NY 14604 USA.
   [Gramling, Robert; Fiscella, Kevin; Epstein, Ronald] Univ Rochester, Dept Family Med, Ctr Commun & Dispar Res, 1381 South Ave, Rochester, NY 14620 USA.
C3 University of Rochester; University of Rochester; University of
   Rochester
RP Bartels, J (corresponding author), Univ Rochester, Sch Med & Dent, 601 Elmwood Ave, Rochester, NY 14642 USA.
EM Josef_Bartels@URMC.Rochester.edu; Rachel_Rodenbach@urmc.rochester.edu;
   KCiesinski@esm.rochester.edu; Robert_Gramling@urmc.rochester.edu;
   Kevin_Fiscella@urmc.rochester.edu; Ronald_Epstein@urmc.rochester.edu
RI Fiscella, Kevin Anthony/AFO-3350-2022
OI Fiscella, Kevin Anthony/0000-0003-3613-8012; Rodenbach,
   Rachel/0000-0001-5085-5347
FU University of Rochester CTSA award from the National Center for
   Advancing Translational Sciences of the National Institutes of Health
   [TL1 TR000096]; NCI [R01CA40419]
FX The project described in this publication was supported in part by the
   University of Rochester CTSA award number TL1 TR000096 from the National
   Center for Advancing Translational Sciences of the National Institutes
   of Health and in part by RM Epstein and RL Kravitz with NCI Grant
   R01CA40419.
CR Alexander SC, 2015, PATIENT EDUC COUNS, V98, P1339, DOI 10.1016/j.pec.2015.04.019
   [Anonymous], BIOMETRICS
   [Anonymous], MEASURING ACOUSTIC P
   [Anonymous], CURR ISSUES PSYCHOAN
   [Anonymous], PAUSING INVENT UNPUB
   [Anonymous], 2011, Personal best
   [Anonymous], INT C DEV LEARN
   [Anonymous], HLTH EXPECT
   [Anonymous], CHANCE AGREEMENT SIG
   Back AL, 2009, J PALLIAT MED, V12, P1113, DOI 10.1089/jpm.2009.0175
   Bernacki RE, 2014, JAMA INTERN MED, V174, P1994, DOI 10.1001/jamainternmed.2014.5271
   BLOS P, 1972, PSYCHOANAL QUART, V41, P348, DOI 10.1080/21674086.1972.11926602
   BRUNEAU TJ, 1973, J COMMUN, V23, P17, DOI 10.1111/j.1460-2466.1973.tb00929.x
   Creswell J.W., 2012, QUAL INQ
   Eide H, 2004, SOC SCI MED, V59, P145, DOI 10.1016/j.socscimed.2003.10.011
   Ephratt M, 2008, J PRAGMATICS, V40, P1909, DOI 10.1016/j.pragma.2008.03.009
   Ephratt M, 2011, J PRAGMATICS, V43, P2286, DOI 10.1016/j.pragma.2011.03.006
   Epstein RM, 2015, FAM SYST HEALTH, V33, P280, DOI 10.1037/fsh0000155
   Epstein RM, 2011, ANN FAM MED, V9, P454, DOI 10.1370/afm.1301
   Epstein RM, 2013, PATIENT EDUC COUNS, V90, P200, DOI 10.1016/j.pec.2012.06.035
   Gazzola V, 2006, CURR BIOL, V16, P1824, DOI 10.1016/j.cub.2006.07.072
   Gibbings-Isaac D, 2012, FAM PRACT, V29, P616, DOI 10.1093/fampra/cms001
   Halifax J, 2012, CURR OPIN SUPPORT PA, V6, P228, DOI 10.1097/SPC.0b013e3283530fbe
   HALL JA, 1995, APPL PREV PSYCHOL, V4, P21, DOI 10.1016/S0962-1849(05)80049-6
   Hoerger M, 2013, BMC CANCER, V13, DOI 10.1186/1471-2407-13-188
   Institute of Medicine (US) Committee on Quality of Health Care in America, 2001, Crossing the quality chasm: a new health system for the 21st century
   Jaffe J, 2001, MONOGR SOC RES CHILD, V66, P1, DOI 10.1111/1540-5834.00137
   JENSEN JV, 1973, ET CETERA, V30, P249
   Larson EB, 2005, JAMA-J AM MED ASSOC, V293, P1100, DOI 10.1001/jama.293.9.1100
   Levinson W, 2010, HEALTH AFFAIR, V29, P1310, DOI 10.1377/hlthaff.2009.0450
   Levitt HM, 2001, PSYCHOTHER RES, V11, P295, DOI 10.1080/713663985
   Mack JW, 2009, CANCER-AM CANCER SOC, V115, P3302, DOI 10.1002/cncr.24360
   Makowski SKE, 2012, J PAIN SYMPTOM MANAG, V43, P293, DOI 10.1016/j.jpainsymman.2011.06.014
   Manson JH, 2013, EVOL HUM BEHAV, V34, P419, DOI 10.1016/j.evolhumbehav.2013.08.001
   Margulis EH, 2007, J MUSIC THEORY, V51, P245, DOI 10.1215/00222909-2009-003
   MATTHEWS DA, 1993, ANN INTERN MED, V118, P973, DOI 10.7326/0003-4819-118-12-199306150-00010
   McGarva AR, 2003, J PSYCHOLINGUIST RES, V32, P335, DOI 10.1023/A:1023547703110
   McHenry M, 2012, SUPPORT CARE CANCER, V20, P1073, DOI 10.1007/s00520-011-1187-8
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   Nakane I, 2006, J PRAGMATICS, V38, P1811, DOI 10.1016/j.pragma.2006.01.005
   Ohtaki S, 2003, FAM PRACT, V20, P276, DOI 10.1093/fampra/cmg308
   Pentland A., 2008, Honest signals
   Rizzolatti G, 2009, NAT CLIN PRACT NEURO, V5, P24, DOI 10.1038/ncpneuro0990
   Robson C., 2011, Real world research : a resource for users of social research methods in applied settings
   Sabbadini A., 1991, BRIT J PSYCHOTHER, V7, P406, DOI [DOI 10.1111/J.1752-0118.1991.TB01145.X, DOI 10.1111/j.1752-0118.1991.tb01145.x]
   Sadler P, 2009, J PERS SOC PSYCHOL, V97, P1005, DOI 10.1037/a0016232
   Street RL, 2014, PATIENT EDUC COUNS, V96, P315, DOI 10.1016/j.pec.2014.05.004
   STREET RL, 1982, LANG COMMUN, V2, P13, DOI 10.1016/0271-5309(82)90032-5
   STREET RL, 1987, COMMUN MONOGR, V54, P42, DOI 10.1080/03637758709390215
   SUCHMAN AL, 1988, ANN INTERN MED, V108, P125, DOI 10.7326/0003-4819-108-1-125
   Trainor LJ, 2015, ANN NY ACAD SCI, V1337, P45, DOI 10.1111/nyas.12649
   Ventres WB, 2015, FAM SYST HEALTH, V33, P270, DOI 10.1037/fsh0000123
   Zlatev Jordan, 2008, The shared mind: Perspectives on intersubjectivity
NR 53
TC 23
Z9 27
U1 0
U2 25
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0738-3991
EI 1873-5134
J9 PATIENT EDUC COUNS
JI Patient Educ. Couns.
PD OCT
PY 2016
VL 99
IS 10
BP 1584
EP 1594
DI 10.1016/j.pec.2016.04.009
PG 11
WC Public, Environmental & Occupational Health; Social Sciences,
   Interdisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Public, Environmental & Occupational Health; Social Sciences - Other
   Topics
GA DW0VQ
UT WOS:000383361500007
PM 27156659
OA Green Accepted
DA 2024-01-09
ER

PT J
AU Makaroff, KLS
AF Makaroff, Kara L. Schick
TI The unsayable: a concept analysis
SO JOURNAL OF ADVANCED NURSING
LA English
DT Review
DE communication; document analysis; literature review; nurse-patient
   interactions; nursing; qualitative; unsayable
ID EXPERIENCE; LANGUAGE; UNSAID; PSYCHOTHERAPY; THOUGHTS; THERAPY; EMOTION;
   MUSIC; SPEAK; VOICE
AB Aim To report an analysis of the concept of the unsayable. Background Within nursing, there is recognition that not all experiences of illness can be fully voiced and therefore may be unsayable. However, focus has been on that which is sayable, those experiences that can be communicated through language, leaving the unsayable unexamined. There is little examination of the meaning or relevance of the concept for nursing practice. Data sources The literature search was not limited by date and includes English, peer-reviewed texts in the databases CINAHL, Web of Science, and PsychINFO from 19592011. Design Rodgers' method of evolutionary concept analysis was used. Review methods References were read and analyzed according to surrogate terms, related concepts, attributes, antecedents, and consequences. Results Three surrogate terms, one related concept, four attributes, four antecedents, and two consequences were identified in this concept analysis. Based on this analysis, the unsayable refers to what is not expressed yet alluded to through language and may be conscious or unconscious. The meaning of this concept differs substantially between psychology and nursing. Conclusion Although literature on the unsayable has been developed primarily outside the discipline of nursing, exploration of the concept within nursing may assist nurses to consider situations and experiences that are challenging, elusive, and perhaps impossible for patients to language while living amid illness.
C1 Univ Alberta, Fac Nursing, Edmonton, AB T6G 2M7, Canada.
C3 University of Alberta
RP Makaroff, KLS (corresponding author), Univ Alberta, Fac Nursing, Edmonton, AB T6G 2M7, Canada.
EM kara.schickmakaroff@ualberta.ca
RI Schick-Makaroff, Kara/AFW-1800-2022
OI Schick-Makaroff, Kara/0000-0001-6200-3416
FU Kidney Foundation of Canada [KFOC100031]; Kidney Research Scientist Core
   Education and National Training Program (KRESCENT) [KRES110011R1]
FX This research was supported by a Kidney Foundation of Canada Allied
   Health Doctoral Fellowship (Reference number KFOC100031) on the project
   entitled "Stories of End-stage Renal Disease: Listening for the
   Unsayable." Dr. Schick Makaroff is currently funded by the Kidney
   Research Scientist Core Education and National Training Program
   (KRESCENT - Reference number KRES110011R1) as a Postdoctoral Fellow.
CR Abraham N., 1984, PSYCHOANAL INQ, V4, P221, DOI [10.1080/07351698409533542, DOI 10.1080/07351698409533542]
   Adams M, 2010, THEOR PSYCHOL, V20, P342, DOI 10.1177/0959354310362825
   Allphin C., 2007, J JUNGIAN THEORY PRA, V9, P1
   [Anonymous], INT J PSYCHOANAL SEL
   [Anonymous], 1997, WOUNDED STORYTELLER
   [Anonymous], INT J PSYCHOANAL SEL
   [Anonymous], 1988, Humanistic Nursing
   [Anonymous], 2011, INT J PSYCHOANALYTIC, DOI [10.1080/15551024.2011.552171, DOI 10.1080/15551024.2011.552171]
   [Anonymous], 2011, HUMANIST PSYCHOL
   [Anonymous], 2000, CONCEPT DEV NURSING
   Bergman A., 2011, J INFANT CHILD ADOLE, V10, P207
   BLACHER RS, 1984, GEN HOSP PSYCHIAT, V6, P226, DOI 10.1016/0163-8343(84)90044-6
   Blaustein JP, 1998, B MENNINGER CLIN, V62, P351
   Brockmeier J, 2002, J CONSCIOUSNESS STUD, V9, P79
   Charon R., 2006, Narrative Medicine: Honouring the Stories of Illness
   Clandinin DJ., 2007, HDB NARRATIVE INQUIR, P405, DOI DOI 10.4135/9781452226552.N16
   Cody WK., 2007, INT J HUMAN CARING, V11, P17
   Crowe M, 1996, Aust N Z J Ment Health Nurs, V5, P103
   Cunningham L., 2008, J SANDPLAY THERAPY, V17, P21
   Doenges M. E., 1995, APPL NURSING PROCESS
   Downing David L, 2007, Psychoanal Rev, V94, P991, DOI 10.1521/prev.2007.94.6.991
   Drought T, 2002, NURS ETHICS, V9, P238, DOI 10.1191/0969733002ne505xx
   Ehrensaft E., 2008, J INFANT CHILD ADOLE, V7, P121, DOI [10.1080/15289160802142465, DOI 10.1080/15289160802142465]
   Eifried S, 2003, J NURS EDUC, V42, P59
   Enriquez V., 1979, B HONG KONG PSYCHOL, V3, P7
   Farber BA, 2003, J CLIN PSYCHOL, V59, P589, DOI 10.1002/jclp.10161
   Fawcett J., 2005, CONT NURSING KNOWLED
   Finfgeld-Connett D, 2006, J ADV NURS, V55, P708, DOI 10.1111/j.1365-2648.2006.03961.x
   Flegal KE, 2008, PSYCHON B REV, V15, P927, DOI 10.3758/PBR.15.5.927
   Frank A., 2009, NARRATIVE STORIES HL, P161
   Frank A. W, 2002, WILL BODY REFLECTION
   Frank AW, 2001, QUAL HEALTH RES, V11, P353, DOI 10.1177/104973201129119154
   Frankl V.E., 1946, Man's search for meaning
   Frith C., 2007, BLACKWELL COMPANION, P9
   Gabbard GO, 2001, J AM PSYCHOANAL ASS, V49, P659, DOI 10.1177/00030651010490020601
   Gentile K, 2006, CONTEMP PSYCHOANAL, V42, P297
   Georges JM, 2011, ADV NURS SCI, V34, P130, DOI 10.1097/ANS.0b013e3182186cd8
   Gordon K, 2004, CONTEMP PSYCHOANAL, V40, P5
   Graffigna G, 2009, QUAL HEALTH RES, V19, P790, DOI 10.1177/1049732309335393
   GRIFFITH EEH, 1984, HOSP COMMUNITY PSYCH, V35, P464
   Griffith J. L., 1992, FAMILY SYSTEMS MED, V10, P41
   Griffith James L., 1994, BODY SPEAKS THERAPEU
   Griffith JL, 1998, PSYCHOSOMATICS, V39, P144, DOI 10.1016/S0033-3182(98)71361-1
   Grotstein JS, 1998, J ANAL PSYCHOL, V43, P41, DOI 10.1111/1465-5922.00007
   Harrell Valentina, 2005, J Am Acad Psychoanal Dyn Psychiatry, V33, P149, DOI 10.1521/jaap.33.1.149.65881
   HILL CE, 1993, J COUNS PSYCHOL, V40, P278, DOI 10.1037/0022-0167.40.3.278
   Hill G., 2007, J JUNGIAN THEORY PRA, V9, P11
   HOFFER A, 1980, AM J PSYCHIAT, V137, P1404
   Horner Althea J, 2006, J Am Acad Psychoanal Dyn Psychiatry, V34, P693, DOI 10.1521/jaap.2006.34.4.693
   Howard C, 2000, J LANG SOC PSYCHOL, V19, P295, DOI 10.1177/0261927X00019003002
   Hupcey Judith E, 2005, Res Theory Nurs Pract, V19, P197
   JOHNSONLAIRD PN, 1987, COGNITION, V25, P189, DOI 10.1016/0010-0277(87)90009-6
   Jones AA, 1997, PSYCHOANAL QUART, V66, P683, DOI 10.1080/21674086.1997.11927550
   Jonte-Pace D., 2001, Speaking the unspeakable: Religion, misogyny, and the uncanny mother in Freud's cultural texts
   Klein J., 2003, JACOBS LADDER ESSAYS
   Klein J, 2005, BRIT J PSYCHOTHER, V21, P589, DOI 10.1111/j.1752-0118.2005.tb00248.x
   Kleinman A., 2020, ILLNESS NARRATIVES S
   Koppe H, 2010, AUST FAM PHYSICIAN, V39, P329
   Kruger L.-M., 2005, PSYCHOANAL PSYCHOL, V13, P1
   Levitt H. M., 2002, Counseling Psychology Quarterly, V15, P333
   Lieberman AF, 2009, CHILD ADOL PSYCH CL, V18, P707, DOI 10.1016/j.chc.2009.02.007
   LUDWIG AM, 1966, ARCH GEN PSYCHIAT, V15, P225
   Märtsin M, 2010, THEOR PSYCHOL, V20, P436, DOI 10.1177/0959354310363513
   Makaroff KS, 2010, NURS ETHICS, V17, P566, DOI 10.1177/0969733010373433
   Mangini MC, 2004, COGNITIVE SCI, V28, P209, DOI 10.1016/j.cogsci.2003.11.004
   Mather R, 2008, HIST HUM SCI, V21, P33, DOI 10.1177/0952695107086151
   Miller RB, 1998, CLIN PSYCHOL-SCI PR, V5, P242, DOI 10.1111/j.1468-2850.1998.tb00147.x
   Mills Sara, 2004, DISCOURSE
   Mitchell G. J., 2009, CONT NURSING PROCESS, P99
   Morgan M, 2001, FEM PSYCHOL, V11, P361, DOI 10.1177/0959353501011003007
   Newman M, 2008, Transforming presence: The difference that nursing makes
   Nye Stacey, 2008, Eat Disord, V16, P358, DOI 10.1080/10640260802116041
   OLDNALL AS, 1995, J ADV NURS, V21, P605, DOI 10.1111/j.1365-2648.1995.tb02746.x
   Parkhill KA, 2011, BRIT J SOCIOL, V62, P324, DOI 10.1111/j.1468-4446.2011.01367.x
   Parks TE, 2005, AM J PSYCHOL, V118, P115
   Parse R R, 1992, Nurs Sci Q, V5, P35, DOI 10.1177/089431849200500109
   Livingston LRP, 2006, INT J GROUP PSYCHOTH, V56, P307, DOI 10.1521/ijgp.2006.56.3.307
   Rallison L., 2004, J FAM NURS, V10, P287, DOI DOI 10.1177/1074840704267388
   Ready T, 2010, AM J HOSP PALLIAT ME, V27, P7, DOI 10.1177/1049909109338387
   REGAN AM, 1992, J COUNS PSYCHOL, V39, P168, DOI 10.1037/0022-0167.39.2.168
   Rew L, 2005, J HOLIST NURS, V23, P6, DOI 10.1177/0898010104272296
   Rilke R.M., 1903, Letters to a Young Poet
   Risjord M, 2009, J ADV NURS, V65, P684, DOI 10.1111/j.1365-2648.2008.04903.x
   Rizzuto AM, 2002, INT J PSYCHOANAL, V83, P1325
   Rizzuto AM, 2001, J AM PSYCHOANAL ASS, V49, P535, DOI 10.1177/00030651010490021601
   Rogers A.E., 1999, Making Meaning of Narratives, P77
   Rogers Annie., 2007, The Unsayable: The Hidden Language of Trauma
   Rogers Annie., 2007, HDB NARRATIVE INQUIR, P99
   ROGERS CR, 1985, J HUMANIST PSYCHOL, V25, P7, DOI 10.1177/0022167885254002
   Rominger R, 2010, ART THER, V27, P18, DOI 10.1080/07421656.2010.10129561
   Rubin SE, 2010, J WOMENS HEALTH, V19, P735, DOI 10.1089/jwh.2009.1549
   Rykov MH, 2008, J HEALTH PSYCHOL, V13, P190, DOI 10.1177/1359105307086708
   Schneider S., 2007, BLACKWELL COMPANION, P1, DOI [10.1002/9780470751466.ch1, DOI 10.1002/9780470751466.CH1]
   Schwager E, 2001, Psychoanal Rev, V88, P597, DOI 10.1521/prev.88.5.597.17708
   Schwappach D. L. B., 2008, BIOMED CENTRAL HLTH, V8
   Shoham M, 2009, CONTEMP PSYCHOANAL, V45, P520
   Steinberg S., 1999, PSYCHOANAL REV, V86, P853
   Steinweg DL, 2011, PSYCHOSOMATICS, V52, P255, DOI 10.1016/j.psym.2010.12.022
   Stephens BD, 1999, J ANAL PSYCHOL, V44, P197, DOI 10.1111/1465-5922.00084
   Thomas B., 2002, GROUPWORK, V13, P34
   Todorova I., 2007, Cognitie Creier Comportament, V11, P229
   Tschanz C. L., 2006, THESIS U VICTORIA VI
   TYE M, 2007, BLACKWELL COMPANION, P23, DOI DOI 10.1002/9780470751466.CH3
   van der Riet P, 1998, Nurs Inq, V5, P248
   Villela-Minnerly L., 1991, PSYCHOANAL PSYCHOL, V8, P25
   Vivona JM, 2006, J AM PSYCHOANAL ASS, V54, P877, DOI 10.1177/00030651060540031501
   von Hippel W, 2005, PSYCHOL SCI, V16, P497, DOI 10.1111/j.0956-7976.2005.01563.x
   Walker L. O., Strategies for theory construction in nursing
   WHEELER JL, 1995, J COUNS DEV, V73, P586, DOI 10.1002/j.1556-6676.1995.tb01800.x
   Wurmser Leon, 2003, Am J Psychoanal, V63, P299, DOI 10.1023/B:TAJP.0000004736.10394.00
NR 110
TC 8
Z9 8
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0309-2402
EI 1365-2648
J9 J ADV NURS
JI J. Adv. Nurs.
PD FEB
PY 2013
VL 69
IS 2
BP 481
EP 492
DI 10.1111/j.1365-2648.2012.06083.x
PG 12
WC Nursing
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Nursing
GA 073DC
UT WOS:000313722600023
PM 22765505
DA 2024-01-09
ER

PT J
AU Navarro-Cáceres, M
   Caetano, M
   Bernardes, G
   Sánchez-Barba, M
   Sánchez-Jara, JM
AF Navarro-Caceres, Maria
   Caetano, Marcelo
   Bernardes, Gilberto
   Sanchez-Barba, Mercedes
   Merchan Sanchez-Jara, Javier
TI A Computational Model of Tonal Tension Profile of Chord Progressions in
   the Tonal Interval Space
SO ENTROPY
LA English
DT Article
DE chord progression; hierarchical tension; tonal interval space; melodic
   attraction; dissonance
ID MUSICAL TENSION; CONSONANCE; PERCEPTION; DISSONANCE
AB In tonal music, musical tension is strongly associated with musical expression, particularly with expectations and emotions. Most listeners are able to perceive musical tension subjectively, yet musical tension is difficult to be measured objectively, as it is connected with musical parameters such as rhythm, dynamics, melody, harmony, and timbre. Musical tension specifically associated with melodic and harmonic motion is called tonal tension. In this article, we are interested in perceived changes of tonal tension over time for chord progressions, dubbed tonal tension profiles. We propose an objective measure capable of capturing tension profile according to different tonal music parameters, namely, tonal distance, dissonance, voice leading, and hierarchical tension. We performed two experiments to validate the proposed model of tonal tension profile and compared against Lerdahl's model and MorpheuS across 12 chord progressions. Our results show that the considered four tonal parameters contribute differently to the perception of tonal tension. In our model, their relative importance adopts the following weights, summing to unity: dissonance (0.402), hierarchical tension (0.246), tonal distance (0.202), and voice leading (0.193). The assumption that listeners perceive global changes in tonal tension as prototypical profiles is strongly suggested in our results, which outperform the state-of-the-art models.
C1 [Navarro-Caceres, Maria] Univ Salamanca, Dept Comp Sci, Pza Caidos S-N, Salamanca 37007, Spain.
   [Caetano, Marcelo] McGill Univ, Schulich Sch Mus, 555 Sherbrooke St West, Montreal, PQ H3A 1E3, Canada.
   [Caetano, Marcelo] McGill Univ, CIRMMT, 555 Sherbrooke St West, Montreal, PQ H3A 1E3, Canada.
   [Caetano, Marcelo] Aix Marseille Univ, CNRS, PRISM Percept Representat Image Sound Mus, Marseille, France.
   [Bernardes, Gilberto] Univ Porto, Fac Engn, P-4200465 Porto, Portugal.
   [Bernardes, Gilberto] Univ Porto, INESC TEC, P-4200465 Porto, Portugal.
   [Sanchez-Barba, Mercedes] Univ Salamanca, Dept Stat, Pza Merced S-N, Salamanca 37007, Spain.
   [Merchan Sanchez-Jara, Javier] Univ Salamanca, Dept Didact Mus Plast & Corporal Express, Calle Madrigal de las Altas Torres 3, Avila 05003, Spain.
C3 University of Salamanca; McGill University; McGill University; Centre
   National de la Recherche Scientifique (CNRS); Aix-Marseille Universite;
   Universidade do Porto; Universidade do Porto; INESC TEC; University of
   Salamanca; University of Salamanca
RP Navarro-Cáceres, M (corresponding author), Univ Salamanca, Dept Comp Sci, Pza Caidos S-N, Salamanca 37007, Spain.
EM maria90@usal.es; marcelo.caetano@prism.cnrs.fr; gba@fe.up.pt;
   mersanbar@usal.es; javiermerchan@usal.es
RI Caetano, Marcelo/D-7821-2015; Bernardes, Gilberto/AAV-1847-2020
OI Caetano, Marcelo/0000-0002-5119-8964; Bernardes,
   Gilberto/0000-0003-3884-2687
FU project "Co-POEM:Platform for the Collaborative Generation of European
   Popular Music" under the program Erasmus+:KA201-Strategic Partnership
   [ES01-KA201-064933]; project "Experimentation in music in Portuguese
   culture: History, contexts, and practices in the 20th and 21st
   centuries" [POCI-01-0145-FEDER-031380]; European Union through the
   Operational Program Competitiveness and Internationalization, in its
   ERDF component; European Union's Horizon 2020 research and innovation
   program under the Marie Sklodowska-Curie grant [831852]; Portuguese
   Foundation for Science and Technology; Marie Curie Actions (MSCA)
   [831852] Funding Source: Marie Curie Actions (MSCA)
FX Research partially funded by the project "Co-POEM:Platform for the
   Collaborative Generation of European Popular Music" (ES01-KA201-064933)
   under the program Erasmus+:KA201-Strategic Partnership; by the project
   "Experimentation in music in Portuguese culture: History, contexts, and
   practices in the 20th and 21st centuries" (POCI-01-0145-FEDER-031380)
   co-funded by the European Union through the Operational Program
   Competitiveness and Internationalization, in its ERDF component, and by
   national funds, through the Portuguese Foundation for Science and
   Technology; and by the European Union's Horizon 2020 research and
   innovation program under the Marie Sklodowska-Curie grant agreement No.
   831852 (MORPH).
CR Amiot Emmanuel, 2013, Mathematics and Computation in Music. 4th International Conference, MCM 2013. Proceedings: LNCS 7937, P1, DOI 10.1007/978-3-642-39357-0_1
   Amiot E, 2011, J MATH MUSIC, V5, P149, DOI 10.1080/17459737.2011.640469
   Bernardes G, 2016, COMPUT ENTERTAIN, V14, DOI 10.1145/2991145
   Bernardes G, 2016, J NEW MUSIC RES, V45, P281, DOI 10.1080/09298215.2016.1182192
   Bigand E, 1999, PSYCHOL RES-PSYCH FO, V62, P237, DOI 10.1007/s004260050053
   Bigand E, 1996, PERCEPT PSYCHOPHYS, V58, P125, DOI 10.3758/BF03205482
   BIGAND E, 1993, CONTEMP MUSIC REV, V9, P123, DOI DOI 10.1080/07494469300640391
   Carter Roy E., 1978, THEORY HARMONY
   Chew E., 2002, Music and Artificial Intelligence. Second International Conference, ICMAI 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2445), P18
   Chew E., 2007, COMPUT MUSICOL, V15, P51
   CHOMSKY N., 1965, Aspects of the theory of syntax
   Costa M, 2020, MUSIC PERCEPT, V37, P298, DOI 10.1525/MP.2020.37.4.298
   Farbood M., 2010, P 11 INT C MUS PERC, P119
   Farbood M. M., 2006, THESIS
   Farbood MM, 2017, J ACOUST SOC AM, V141, P419, DOI 10.1121/1.4973568
   Farbood MM, 2012, MUSIC PERCEPT, V29, P387, DOI 10.1525/MP.2012.29.4.387
   Granot RY, 2011, MUSIC PERCEPT, V28, P219, DOI 10.1525/MP.2011.28.3.219
   Guernsey M, 1928, AM J PSYCHOL, V40, P173, DOI 10.2307/1414484
   Harasim D., 2020, P 21 INT SOC MUS INF
   Helmholtz Hermann von, 1912, SENSATIONS TONE PHYS
   Herremans D., 2019, P 41 ANN M COGN SCI, P52
   HURON DAVID, 2006, SWEET ANTICIPATION M, P148, DOI DOI 10.7551/MITPRESS/6575.001.0001
   Juslin PN, 2013, PSYCHOLOGY OF MUSIC, THIRD EDITION, P583, DOI 10.1016/B978-0-12-381460-9.00015-8
   Koelsch S, 2013, P NATL ACAD SCI USA, V110, P15443, DOI 10.1073/pnas.1300272110
   Krumhansl C. L., 2001, Cognitive Foundations of Musical Pitch, VVol. 17
   Krumhansl CL, 1996, MUSIC PERCEPT, V13, P401
   Lerdahl F, 1996, MUSIC PERCEPT, V13, P319
   LERDAHL F, 1988, MUSIC PERCEPT, V5, P315
   Lerdahl F., 2001, Tonal Pitch Space
   Lerdahl F, 2007, MUSIC PERCEPT, V24, P329, DOI 10.1525/MP.2007.24.4.329
   Lerdahl F, 2015, MUSIC PERCEPT, V33, P83, DOI 10.1525/MP.2015.33.1.83
   Lerdahl Fred, 1983, A generative theory of tonal music
   Lewin D, 2001, J MUSIC THEORY, V45, P1, DOI 10.2307/3090647
   McAdams S, 2013, PSYCHOLOGY OF MUSIC, THIRD EDITION, P35, DOI 10.1016/B978-0-12-381460-9.00002-X
   Navarro-Caceres Maria, 2020, Artificial Intelligence in Music, Sound, Art and Design. 9th International Conference, EvoMUSART 2020. Held as Part of EvoStar 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12103), P150, DOI 10.1007/978-3-030-43859-3_11
   Navarro-Caceres M., 2015, LECT NOTES COMPUT SC, P168
   Navarro-Cáceres M, 2019, SWARM EVOL COMPUT, V50, DOI 10.1016/j.swevo.2019.05.012
   Nielsen F., 1987, The semiotic web '86: An international yearbook, P491
   Parncutt, 1989, HARMONY PSYCHOACOUST
   Parncutt R., 2011, J INTERDISCIPLINARY, V5, P119, DOI 10.4407/jims.2011.11.002
   PLOMP R, 1965, J ACOUST SOC AM, V38, P548, DOI 10.1121/1.1909741
   Pressnitzer D, 2000, PERCEPT PSYCHOPHYS, V62, P66, DOI 10.3758/BF03212061
   Quinn I., 2006, PERSPECT NEW MUSIC, V44, P114, DOI [DOI 10.1353/PNM.2006.0010, https://doi.org/10.1353/pnm.2006.0010]
   Quinn I., 2007, PERSPECT NEW MUSIC, V45, P4, DOI DOI 10.1353/PNM.2007.0016
   Riemann H., 1962, HIST MUSIC THEORY
   Rohrmeier M, 2011, J MATH MUSIC, V5, P35, DOI 10.1080/17459737.2011.573676
   Schenker H., 1979, FREE COMPOSITION, VIII
   SCHMUCKLER MA, 1989, MUSIC PERCEPT, V7, P109
   SCHMUCKLER MA, 1994, PERCEPT PSYCHOPHYS, V56, P313, DOI 10.3758/BF03209765
   Teo Y, 2020, EMPIR MUSICOL REV, V15, P61, DOI 10.18061/emr.v15i1-2.6994
   Trulla LL, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00381
   Yust J., 2018, P INT C MATH COMP MU, P207
   Yust J, 2015, J MUSIC THEORY, V59, P121, DOI 10.1215/00222909-2863409
NR 53
TC 3
Z9 3
U1 4
U2 6
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1099-4300
J9 ENTROPY-SWITZ
JI Entropy
PD NOV
PY 2020
VL 22
IS 11
AR 1291
DI 10.3390/e22111291
PG 30
WC Physics, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Physics
GA OW6WA
UT WOS:000593023200001
PM 33287059
OA Green Submitted, gold, Green Published
DA 2024-01-09
ER

PT J
AU Che, YQ
   Jicol, C
   Ashwin, C
   Petrini, K
AF Che, Yuqing
   Jicol, Crescent
   Ashwin, Chris
   Petrini, Karin
TI An RCT study showing few weeks of music lessons enhance audio-visual
   temporal processing
SO SCIENTIFIC REPORTS
LA English
DT Article
ID AUTISM SPECTRUM DISORDER; EMOTIONAL SPEECH PROSODY; PIANO INSTRUCTION;
   BRAIN; RECOGNITION; PERCEPTION; EXPERTISE; CHILDREN; ANXIETY; STRESS
AB Music involves different senses and is emotional in nature, and musicians show enhanced detection of audio-visual temporal discrepancies and emotion recognition compared to non-musicians. However, whether musical training produces these enhanced abilities or if they are innate within musicians remains unclear. Thirty-one adult participants were randomly assigned to a music training, music listening, or control group who all completed a one-hour session per week for 11 weeks. The music training group received piano training, the music listening group listened to the same music, and the control group did their homework. Measures of audio-visual temporal discrepancy, facial expression recognition, autistic traits, depression, anxiety, stress and mood were completed and compared from the beginning to end of training. ANOVA results revealed that only the music training group showed a significant improvement in detection of audio-visual temporal discrepancies compared to the other groups for both stimuli (flash-beep and face-voice). However, music training did not improve emotion recognition from facial expressions compared to the control group, while it did reduce the levels of depression, stress and anxiety compared to baseline. This RCT study provides the first evidence of a causal effect of music training on improved audio-visual perception that goes beyond the music domain.
C1 [Che, Yuqing; Ashwin, Chris; Petrini, Karin] Univ Bath, Dept Psychol, Bath BA2 7AY, Avon, England.
   [Jicol, Crescent] Univ Bath, Dept Comp Sci, Bath BA2 7AY, Avon, England.
   [Ashwin, Chris] Univ Bath, Ctr Appl Autism Res, Dept Psychol, Bath BA2 7AY, Avon, England.
C3 University of Bath; University of Bath; University of Bath
RP Che, YQ (corresponding author), Univ Bath, Dept Psychol, Bath BA2 7AY, Avon, England.
EM yc2210@bath.ac.uk
OI Petrini, Karin/0000-0001-5354-5600; Ashwin, Chris/0000-0003-4606-7318
CR ABRSM, 2017, ABRSM EXAM PIANO GRA
   [Anonymous], 1998, Music Therapy Perspectives, DOI 10.1093/mtp/16.2.75
   [Anonymous], 2014, Psychomusicology: Music, Mind, and Brain, DOI [10.1037/pmu0000036, DOI 10.1037/PMU0000036]
   [Anonymous], PSYCHOL MUSIC, DOI [10.1177/0305735600282007, DOI 10.1177/0305735600282007]
   Baron-Cohen S, 2001, J AUTISM DEV DISORD, V31, P5, DOI 10.1023/A:1005653411471
   Behne DM., 2013, J ACOUST SOC AM, V133, P3570, DOI [10.1121/1.4806538, DOI 10.1121/1.4806538, DOI 10.1121/1.4801060]
   Bianco R, 2018, NEUROIMAGE, V169, P383, DOI 10.1016/j.neuroimage.2017.12.058
   Bidelman GM, 2016, EXP BRAIN RES, V234, P3037, DOI 10.1007/s00221-016-4705-6
   Bigand E, 2006, COGNITION, V100, P100, DOI 10.1016/j.cognition.2005.11.007
   Black SL., 2005, SCI REV MENTAL HLTH, V4, P3
   Bresin R, 2011, CORTEX, V47, P1068, DOI 10.1016/j.cortex.2011.05.009
   Bugos JA, 2007, AGING MENT HEALTH, V11, P464, DOI 10.1080/13607860601086504
   Chan MF, 2011, COMPLEMENT THER MED, V19, P332, DOI 10.1016/j.ctim.2011.08.003
   Clements-Cortes A, 2017, CAN MUSIC ED, V59, P34
   Constantino JN, 2003, ARCH GEN PSYCHIAT, V60, P524, DOI 10.1001/archpsyc.60.5.524
   Correia AI, 2022, EMOTION, V22, P894, DOI 10.1037/emo0000770
   Costa-Giomi E, 1999, J RES MUSIC EDUC, V47, P198, DOI 10.2307/3345779
   Dahl S, 2007, MUSIC PERCEPT, V24, P433, DOI 10.1525/MP.2007.24.5.433
   de Boer-Schellekens L, 2013, FRONT INTEGR NEUROSC, V7, DOI 10.3389/fnint.2013.00008
   Demarin V, 2016, PSYCHIAT DANUB, V28, P343
   Eerola T, 2013, MUSIC PERCEPT, V30, P307, DOI [10.1525/mp.2012.30.3.307, 10.1525/MP.2012.30.1.49]
   Erdem K, 2015, EDUC RES REV-NETH, V10, P2661, DOI DOI 10.5897/ERR2015.2398
   Farmer E, 2020, MUSIC PERCEPT, V37, P323, DOI 10.1525/MP.2020.37.4.323
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Foss-Feig JH, 2010, EXP BRAIN RES, V203, P381, DOI 10.1007/s00221-010-2240-4
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Gagnon L, 2003, COGNITION EMOTION, V17, P25, DOI 10.1080/02699930302279
   Gerson SA, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130960
   Good A, 2017, EAR HEARING, V38, P455, DOI 10.1097/AUD.0000000000000402
   Grandjean D, 2006, PROG BRAIN RES, V156, P235, DOI 10.1016/S0079-6123(06)56012-1
   Hanon C. L, 1986, VIRTUOSO PIANIST 60, V925
   Hodges DA., 2015, MUSIC EDUC J, V101, P41, DOI DOI 10.1177/0027432115575755
   Honing H, 2009, J EXP PSYCHOL HUMAN, V35, P281, DOI 10.1037/a0012732
   Iarocci G, 2006, J AUTISM DEV DISORD, V36, P77, DOI 10.1007/s10803-005-0044-3
   James CE, 2020, BMC GERIATR, V20, DOI 10.1186/s12877-020-01761-y
   Jicol C, 2018, EXP BRAIN RES, V236, P1869, DOI 10.1007/s00221-018-5269-4
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2013, PHYS LIFE REV, V10, P235, DOI 10.1016/j.plrev.2013.05.008
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kamioka H, 2014, PATIENT PREFER ADHER, V8, P727, DOI 10.2147/PPA.S61340
   Kantor-Martynuska J, 2015, PSYCHOL AESTHET CREA, V9, P235, DOI 10.1037/a0039107
   Kaviani H, 2014, COGN PROCESS, V15, P77, DOI 10.1007/s10339-013-0574-0
   Kawakami S, 2020, J AUTISM DEV DISORD, V50, P3944, DOI 10.1007/s10803-020-04452-0
   Kawakami S, 2020, J AUTISM DEV DISORD, V50, P1561, DOI 10.1007/s10803-018-3762-z
   Knight WEJ, 2001, J MUSIC THER, V38, P254, DOI 10.1093/jmt/38.4.254
   Lappe C, 2008, J NEUROSCI, V28, P9632, DOI 10.1523/JNEUROSCI.2254-08.2008
   Lappe C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021493
   Lee H, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00868
   Lee H, 2011, P NATL ACAD SCI USA, V108, pE1441, DOI 10.1073/pnas.1115267108
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Lima CF, 2011, COGNITION EMOTION, V25, P585, DOI 10.1080/02699931.2010.502449
   Lindström R, 2016, NEUROSCI LETT, V628, P47, DOI 10.1016/j.neulet.2016.06.016
   Linnemann A, 2018, INT J BEHAV MED, V25, P223, DOI 10.1007/s12529-017-9697-5
   Liu YH, 2016, WOMEN HEALTH, V56, P296, DOI 10.1080/03630242.2015.1088116
   Love SA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0054798
   Lovibond SH, 1995, Manual for the Depression and Anxiety Stress Scales, DOI DOI 10.1016/0005-7967(94)00075-U
   Lu Y, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090686
   Maratos AS, 2008, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD004517.pub2
   Olszewska AM, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.630829
   Panteleeva Y, 2018, PSYCHOL MUSIC, V46, P473, DOI 10.1177/0305735617712424
   Paraskevopoulos E, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036534
   Park M, 2015, FRONT HUM NEUROSCI, V8, DOI [10.3389/fnhurn.2014.01049, 10.3389/fnhum.2014.01049]
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   Petrini K, 2020, J EXP PSYCHOL HUMAN, V46, P1105, DOI 10.1037/xhp0000827
   Petrini K, 2011, NEUROIMAGE, V56, P1480, DOI 10.1016/j.neuroimage.2011.03.009
   Petrini K, 2010, J VISION, V10, DOI 10.1167/10.5.2
   Petrini K, 2009, EXP BRAIN RES, V198, P339, DOI 10.1007/s00221-009-1817-2
   PiaTube, 2015, PIANO TUTORIAL
   Poljac E, 2013, AUTISM, V17, P668, DOI 10.1177/1362361312455703
   Powers AR, 2009, J NEUROSCI, V29, P12265, DOI 10.1523/JNEUROSCI.3501-09.2009
   Proverbio AM, 2016, MUSIC PERCEPT, V33, P446, DOI 10.1525/MP.2016.33.4.446
   Rochette F, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00488
   Ronald A, 2011, AM J MED GENET B, V156B, P255, DOI 10.1002/ajmg.b.31159
   Ruzich E, 2015, MOL AUTISM, V6, DOI [10.1186/s13229-015-0038-8, 10.1186/2040-2392-6-2]
   Schellenberg EG, 2011, BRIT J PSYCHOL, V102, P283, DOI 10.1111/j.2044-8295.2010.02000.x
   Schellenberg EG, 2004, PSYCHOL SCI, V15, P511, DOI 10.1111/j.0956-7976.2004.00711.x
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   Schlaug G, 2015, PROG BRAIN RES, V217, P37, DOI 10.1016/bs.pbr.2014.11.020
   Seinfeld S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00810
   Sharp A, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01976
   Song YN, 2018, J AUTISM DEV DISORD, V48, P1886, DOI 10.1007/s10803-017-3428-2
   Steele K. M., 2005, SCI REV MENTAL HLTH, V4, P6
   Stevenson RA, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-14632-1
   Stevenson RA, 2016, AUTISM RES, V9, P720, DOI 10.1002/aur.1566
   Stevenson RA, 2014, J AUTISM DEV DISORD, V44, P3161, DOI 10.1007/s10803-014-2179-6
   Ter Bogt TFM, 2017, PSYCHOL MUSIC, V45, P155, DOI 10.1177/0305735616650029
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Van Laarhoven T, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46084-0
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Wesseldijk LW, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-49099-9
   West MJ, 2018, J AUTISM DEV DISORD, V48, P2611, DOI 10.1007/s10803-018-3522-0
   Wingenbach TSH, 2017, RES AUTISM SPECT DIS, V34, P52, DOI 10.1016/j.rasd.2016.11.003
   Wingenbach TSH, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0147112
   Yaguchi A, 2018, MULTISENS RES, V31, P523, DOI 10.1163/22134808-00002612
NR 94
TC 2
Z9 2
U1 4
U2 15
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD NOV 22
PY 2022
VL 12
IS 1
AR 20087
DI 10.1038/s41598-022-23340-4
PG 14
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA 6L1FW
UT WOS:000887936600064
PM 36418441
OA gold, Green Published
DA 2024-01-09
ER

PT J
AU Moysis, L
   Iliadis, LA
   Sotiroudis, SP
   Boursianis, AD
   Papadopoulou, MS
   Kokkinidis, KID
   Volos, C
   Sarigiannidis, P
   Nikolaidis, S
   Goudos, SK
AF Moysis, Lazaros
   Iliadis, Lazaros Alexios
   Sotiroudis, Sotirios P.
   Boursianis, Achilles D.
   Papadopoulou, Maria S.
   Kokkinidis, Konstantinos-Iraklis D.
   Volos, Christos
   Sarigiannidis, Panagiotis
   Nikolaidis, Spiridon
   Goudos, Sotirios K.
TI Music Deep Learning: Deep Learning Methods for Music Signal Processing-A
   Review of the State-of-the-Art
SO IEEE ACCESS
LA English
DT Review
DE Deep learning; Multiple signal classification; Speech recognition;
   Signal processing; Music information retrieval; Instruments; Databases;
   Machine learning; Neural networks; music signal processing; music
   information retrieval; music generation; neural networks; machine
   learning
ID SINGING VOICE DETECTION; GENRE CLASSIFICATION; SEPARATION; RECOGNITION;
   MODEL; GENERATION; EMOTIONS; NETWORK; SYSTEM
AB The discipline of Deep Learning has been recognized for its strong computational tools, which have been extensively used in data and signal processing, with innumerable promising results. Among the many commercial applications of Deep Learning, Music Signal Processing has received an increasing amount of attention over the last decade. This work reviews the most recent developments of Deep Learning in Music signal processing. Two main applications that are discussed are Music Information Retrieval, which spans a plethora of applications, and Music Generation, which can fit a range of musical styles. After a review of both topics, several emerging directions are identified for future research.
C1 [Moysis, Lazaros; Volos, Christos] Aristotle Univ Thessaloniki, Sch Phys, Lab Nonlinear Syst Circuits & Complex, Thessaloniki 54124, Greece.
   [Moysis, Lazaros] Univ Western Macedonia, Dept Mech Engn, Kozani 50100, Greece.
   [Iliadis, Lazaros Alexios; Sotiroudis, Sotirios P.; Boursianis, Achilles D.; Papadopoulou, Maria S.; Nikolaidis, Spiridon; Goudos, Sotirios K.] Aristotle Univ Thessaloniki, Sch Phys, ELEDIA AUTH, Thessaloniki, Greece.
   [Kokkinidis, Konstantinos-Iraklis D.] Univ Macedonia, Dept Appl Informat, Thessaloniki 54636, Greece.
   [Sarigiannidis, Panagiotis] Univ Western Macedonia, Dept Elect & Comp Engn, Kozani 50131, Greece.
   [Papadopoulou, Maria S.] Int Hellen Univ, Dept Informat & Elect Engn, Sindos 57400, Greece.
C3 Aristotle University of Thessaloniki; University of Western Macedonia;
   Aristotle University of Thessaloniki; University of Macedonia;
   University of Western Macedonia
RP Moysis, L (corresponding author), Aristotle Univ Thessaloniki, Sch Phys, Lab Nonlinear Syst Circuits & Complex, Thessaloniki 54124, Greece.; Moysis, L (corresponding author), Univ Western Macedonia, Dept Mech Engn, Kozani 50100, Greece.; Goudos, SK (corresponding author), Aristotle Univ Thessaloniki, Sch Phys, ELEDIA AUTH, Thessaloniki, Greece.
EM lmousis@physics.auth.gr; sgoudo@physics.auth.gr
RI Iliadis, Lazaros Alexios/ITU-7528-2023; Goudos, Sotirios
   K./HJA-6146-2022; Papadopoulou, Maria/AAR-3417-2020; Moysis,
   Lazaros/K-9944-2019; Sarigiannidis, Panagiotis/O-5246-2017
OI Goudos, Sotirios K./0000-0001-5981-5683; Papadopoulou,
   Maria/0000-0002-9651-2144; Moysis, Lazaros/0000-0002-5652-2532;
   Sotiroudis, Sotirios/0000-0003-3557-9211; Boursianis,
   Achilles/0000-0001-5614-9056; Sarigiannidis,
   Panagiotis/0000-0001-6042-0355; Nikolaidis,
   Spyridon/0000-0002-9794-8062; Iliadis, Lazaros
   Alexios/0000-0001-8090-1519
FU European Regional Development Fund [KMP6-0078938]
FX This research was carried out as part of the project "Recognition and
   direct characterization of cultural items for the education and
   promotion of Byzantine Music using artificial intelligence" (Project
   code: KMP6-0078938) under the framework of the Action ``Investment Plans
   of Innovation'' of the Operational Program ``Central Macedonia 2014
   2020'', that is co-funded by the European Regional Development Fund and
   Greece.
CR 8TRACKS, US
   911TABS, US
   Abbott R. B., 2022, DISRUPTING CREATIVIT, DOI [10.2139/ssrn.4185327, DOI 10.2139/SSRN.4185327]
   Adiyansjah, 2019, PROCEDIA COMPUT SCI, V157, P99, DOI 10.1016/j.procs.2019.08.146
   Agarwal S, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P455, DOI 10.1109/SSCI.2018.8628712
   Ali-MacLachlan I., 2018, PROC 8 INT WORKSHOP, P3
   Aljanaki A., 2015, PROC MEDIAEVAL WORKS, P1
   Huang CZA, 2019, Arxiv, DOI arXiv:1907.06637
   Huang CZA, 2018, Arxiv, DOI [arXiv:1809.04281, DOI 10.48550/ARXIV.1809.04281]
   [Anonymous], 2004, ISMIR GENRE DATASET
   [Anonymous], MIDI CLASSIC MUSIC K
   [Anonymous], WIKIFONIA SUBSET DAT
   [Anonymous], 2013, MAGNATAGATUNE DATASE
   [Anonymous], LONDON PHILHARMONIC
   [Anonymous], 2018, SPOTIFY RECSYS CHALL
   [Anonymous], U IOWA MUSICAL INSTR
   [Anonymous], IKALA DATASET
   [Anonymous], JAZZ ML READY MIDI
   [Anonymous], The Session
   [Anonymous], ART MIX
   [Anonymous], JS BACH CHORALES DAT
   [Anonymous], CHORD MELODY DATASET
   [Anonymous], PIANO E COMPETITION
   [Anonymous], 2012, RWC POP MUSIC DATASE
   [Anonymous], 2004, LAKH MIDI DATASET
   [Anonymous], 2012, MUSESCORE
   [Anonymous], MIR 1K DATASET
   [Anonymous], HOOKTHEORY LEAD SHEE
   [Anonymous], CLASSICAL PIANO MIDI
   [Anonymous], EPIDEMIC SOUND
   [Anonymous], CLASSICAL MUSIC MIDI
   [Anonymous], Internet Archives
   [Anonymous], Nottingham dataset
   [Anonymous], MCGILL BILLBOARD CHO
   [Anonymous], SISEC DSD100
   [Anonymous], THRACE MACEDONIA
   Ashraf M, 2020, IEEE ACCESS, V8, P220980, DOI 10.1109/ACCESS.2020.3043142
   Aydingun A., 2020, PROC 28 SIGNAL PROCE, P1
   Aytar Y, 2016, ADV NEUR IN, V29
   Ballam-Cross P, 2021, J POP MUSIC STUD, V33, P70, DOI 10.1525/jpms.2021.33.1.70
   Bassiou N, 2015, INT SYMP IMAGE SIG, P238, DOI 10.1109/ISPA.2015.7306065
   Benetatos C., 2020, PROC INT C NEW INTER, P1
   Berdahl E., 2018, Proceedings of the International Conference on New Interfaces for Musical Expression, Blacksburg, Virginia, USA, P390
   Bertin-Mahieux T., 2011, P 12 INT C MUS INF R
   Bisht Shristi, 2022, 2022 6th International Conference on Intelligent Computing and Control Systems (ICICCS), P1656, DOI 10.1109/ICICCS53718.2022.9788423
   Bittner R.M., 2014, P INT SOC MUSICAL IN, P155
   Blaszke M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22083033
   Bollt E, 2021, CHAOS, V31, DOI 10.1063/5.0024890
   Boom C.D., 2019, JOINT EUROPEAN C MAC
   Briot JP, 2019, Arxiv, DOI arXiv:1709.01620
   Briot JP, 2020, NEURAL COMPUT APPL, V32, P981, DOI 10.1007/s00521-018-3813-6
   Brunner G, 2018, PROC INT C TOOLS ART, P786, DOI 10.1109/ICTAI.2018.00123
   Bulayenko O., 2022, MUSIC OUTPUTS CHALLE
   Cao P., 2021, PROC 2 INT C COMPUT, P1
   Casini L, 2018, 2018 IEEE 29TH ANNUAL INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR AND MOBILE RADIO COMMUNICATIONS (PIMRC), P27, DOI 10.1109/PIMRC.2018.8581038
   Castillo JR, 2021, IEEE ACCESS, V9, P18801, DOI 10.1109/ACCESS.2021.3053864
   Chai J., 2021, Mach. Learn. With Appl., V6, P100134, DOI [DOI 10.1016/J.MLWA.2021.100134, 10.1016/j.mlwa.2021.100134]
   Chauhan N., 2020, INDIARXIV, DOI [10.35543/osf.io/9um2r, DOI 10.35543/OSF.IO/9UM2R]
   Cheddad Z., 2021, ARXIV
   Chen C., 2020, MATH PROBL ENG, P1
   Chen HT, 2020, PROC CVPR IEEE, P1465, DOI 10.1109/CVPR42600.2020.00154
   Chen JM, 2014, INT CONF SIGN PROCES, P2286, DOI 10.1109/ICOSP.2014.7015402
   Chen JM, 2020, IEEE ACCESS, V8, P141860, DOI 10.1109/ACCESS.2020.3013339
   Chen LJ, 2021, INT SYM MED INFORM, P35, DOI 10.1109/ISMICT51748.2021.9434907
   Chen Q, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14052923
   Cheuk KW, 2020, IEEE ACCESS, V8, P161981, DOI 10.1109/ACCESS.2020.3019084
   Child R, 2019, Arxiv, DOI arXiv:1904.10509
   Choi K, 2018, Arxiv, DOI arXiv:1709.04396
   Choi K, 2017, INT CONF ACOUST SPEE, P2392, DOI 10.1109/ICASSP.2017.7952585
   Choi K, 2021, IEEE ACCESS, V9, P42071, DOI 10.1109/ACCESS.2021.3065831
   Chowdhuri S, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P197, DOI 10.1145/3323873.3325039
   Ciborowski T, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10232955
   Civit M., 2022, J MODEL MANAG, V209
   Coca AE, 2013, IEEE IJCNN
   Coca AE, 2010, CHAOS, V20, DOI 10.1063/1.3487516
   Costa YMG, 2017, APPL SOFT COMPUT, V52, P28, DOI 10.1016/j.asoc.2016.12.024
   Cuthbert M. S., 2010, P 11 INT SOC MUS INF, P637, DOI DOI 10.5281/ZENODO.1416114
   Dai J, 2016, 2016 10TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP)
   de Witte M, 2022, HEALTH PSYCHOL REV, V16, P134, DOI 10.1080/17437199.2020.1846580
   Defferrard M, 2017, Arxiv, DOI arXiv:1612.01840
   Dhariwal P, 2020, Arxiv, DOI [arXiv:2005.00341, DOI 10.48550/ARXIV.2005.00341]
   Dieleman S., 2018, P ADV NEUR INF PROC, V31, P1
   Ding Q., 2022, IEEE T CIRC SYST VID, P1
   Dong HW, 2018, AAAI CONF ARTIF INTE, P34
   Downie J. S., 2005, Proceedings of the International Conference on Music Information Retrieval, P320
   Ebrahimi M, 2019, 2019 IEEE 5TH CONFERENCE ON KNOWLEDGE BASED ENGINEERING AND INNOVATION (KBEI 2019), P521, DOI 10.1109/KBEI.2019.8734959
   Engel J., 2017, P INT C MACHINE LEAR, P1068
   Engel J, 2019, Arxiv, DOI arXiv:1902.08710
   ESAC, US
   Fan ZC, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P726, DOI 10.1109/ICASSP.2018.8462091
   Farajzadeh N, 2022, ENTERTAIN COMPUT, V43, DOI 10.1016/j.entcom.2022.100518
   Fatima N, 2022, IEEE ACCESS, V10, P53490, DOI 10.1109/ACCESS.2022.3174108
   Fessahaye F, 2019, I SYMP CONSUM ELECTR, DOI 10.1109/icce.2019.8662028
   Folkdb, US
   Fotiadou E, 2016, EUR SIGNAL PR CONF, P1133, DOI 10.1109/EUSIPCO.2016.7760425
   Gajecki T, 2018, J ACOUST SOC AM, V143, P3602, DOI 10.1121/1.5042056
   Gao H., 2022, MATH PROBLEMS ENG, P1
   Gauer J, 2022, J ACOUST SOC AM, V151, P2975, DOI 10.1121/10.0010371
   Gemmeke JF, 2017, INT CONF ACOUST SPEE, P776, DOI 10.1109/ICASSP.2017.7952261
   Genchel B, 2019, Arxiv, DOI arXiv:1907.05208
   Ghatas Y, 2022, ALEX ENG J, V61, P10183, DOI 10.1016/j.aej.2022.03.060
   Glitsos L, 2018, POP MUSIC, V37, P100, DOI 10.1017/S0261143017000599
   Gong WJ, 2021, IEEE ACCESS, V9, P26290, DOI 10.1109/ACCESS.2021.3057486
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gowrishankar B. S., 2022, PROC IEEE INT C DIST, P1
   Guan FQ, 2019, IEEE IJCNN, DOI [10.1109/ijcnn.2019.8852291, 10.1109/icbdsc.2019.8645580]
   Gupta C, 2022, IEEE-ACM T AUDIO SPE, V30, P2422, DOI 10.1109/TASLP.2022.3190732
   Gupta G, 2021, ARAB J SCI ENG, V46, P3247, DOI 10.1007/s13369-020-05112-2
   Hadjeres G., 2017, PR MACH LEARN RES, P1362
   Hadjeres G, 2017, Arxiv, DOI arXiv:1709.06404
   Hallstrom E., 2019, PROC 16 SOUND MUSIC, P1
   Han DH, 2022, FRONT COMPUT SCI-CHI, V16, DOI 10.1007/s11704-021-0569-4
   Hashim S, 2021, PLASMONICS, V16, P379, DOI 10.1007/s11468-020-01282-9
   Hawthorne C, 2019, Arxiv, DOI arXiv:1810.12247
   Heittola T, 2010, EUR SIGNAL PR CONF, P1272
   Heping Y., 2022, INT J BIFURCAT CHAOS, V119
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Hirvonen T., 2015, P AUD ENG SOC CONV
   Hizlisoy S, 2021, ENG SCI TECHNOL, V24, P760, DOI 10.1016/j.jestch.2020.10.009
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   HOMBURG H, 2005, P INT C MUS INF RETR
   Hong YJ, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12168089
   Hu ZJ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1189, DOI 10.1145/3394171.3414070
   Huang I.-S., 2021, MOB INF SYST, P1
   Huang Y., 2018, COMPUT INF SCI, V11, P50, DOI DOI 10.5539/CIS.VLLN3P50
   Huang YSA, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1180, DOI 10.1145/3394171.3413671
   Huaysrijan A., 2022, PROC 19 INT JOINT C, P1
   Humphrey E., 2018, ISMIR, P438
   Hutchings P., 2017, ARXIV
   Ian G., 2014, P ADV NEUR INF PROC, P1
   Idrobo-Avila E, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103095
   Iliadis L. A., 2022, PROC 11 INT C MODERN, P1
   Islam MM, 2021, IEEE ACCESS, V9, P30551, DOI 10.1109/ACCESS.2021.3058537
   Ji SL, 2020, Arxiv, DOI [arXiv:2011.06801, 10.48550/arXiv.2011.06801]
   Jia X., 2022, COMPUT INTEL NEUROSC
   Jiayi Lin, 2020, 2020 IEEE International Conference on Power, Intelligent Computing and Systems (ICPICS), P420, DOI 10.1109/ICPICS50287.2020.9201993
   Jin C, 2020, NEURAL PROCESS LETT, V52, P1893, DOI 10.1007/s11063-020-10241-8
   John Siji, 2020, 2020 IEEE Recent Advances in Intelligent Computational Systems (RAICS), P110, DOI 10.1109/RAICS51191.2020.9332482
   Johnson DD, 2017, LECT NOTES COMPUT SC, V10198, P128, DOI 10.1007/978-3-319-55750-2_9
   Kaliakatsos-Papakostas M. A., 2013, COMPUT INTEL NEUROSC, V23
   Kang S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10072465
   Karaosmanoglu MK, 2012, Proceedings of the 13th International Society for Music Information Retrieval Conference, Porto, P223
   Karim MR, 2021, BRIEF BIOINFORM, V22, P393, DOI 10.1093/bib/bbz170
   Keerti G, 2022, MULTIMED TOOLS APPL, V81, P5179, DOI 10.1007/s11042-021-11881-1
   Kizrak M. A., 2015, PROC 23 SIGNAL PROCE, P1
   Kizrak MA, 2017, SIMUL-T SOC MOD SIM, V93, P749, DOI 10.1177/0037549717708615
   Klec M., 2021, RECOMMENDER SYSTEMS, P107, DOI DOI 10.1007/978-3-030-66450-3_7
   Kolokolova A, 2020, Arxiv, DOI arXiv:2010.15772
   Koteswararao YV, 2022, DEFENCE SCI J, V72, P417, DOI 10.14429/dsj.72.17640
   Krishna A. S. Lal, 2021, 2021 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC), DOI 10.1109/CLEO/Europe-EQEC52157.2021.9542399
   Kritopoulou P., 2020, P IEEE POW EN SOC GE, P1
   Kruthika G., 2021, Intelligent Data Communication Technologies and Internet of Things. Proceedings of ICICI 2020. Lecture Notes on Data Engineering and Communications Technologies (LNDECT 57), P345, DOI 10.1007/978-981-15-9509-7_30
   Lam HL, 2020, GERIATRICS-BASEL, V5, DOI 10.3390/geriatrics5040062
   Law E, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1197
   Lee J., 2017, arXiv, DOI DOI 10.48550/ARXIV.1703.01789
   Lee J, 2018, KSII T INTERNET INF, V12, P1869, DOI 10.3837/tiis.2018.04.026
   Lee S., 2017, A seqgan for polyphonic music generation
   Li JY, 2023, CURR PSYCHOL, V42, P12814, DOI 10.1007/s12144-021-02671-x
   Li J, 2019, MULTIMED TOOLS APPL, V78, P11563, DOI 10.1007/s11042-018-6637-6
   Li N., 2022, COMPUT INTEL NEUROSC, P1
   Li PT, 2015, Arxiv, DOI arXiv:1511.05520
   Li R., 2022, COGNITIVE COMPUTATIO, V4, P108, DOI DOI 10.1049/CCS2.12047
   Li SY, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9040387
   Li XX, 2016, INT CONF ACOUST SPEE, P544, DOI 10.1109/ICASSP.2016.7471734
   Li Y, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.928048
   Li ZW, 2022, IEEE T NEUR NET LEAR, V33, P6999, DOI 10.1109/TNNLS.2021.3084827
   Liang M., 2022, COMPUT INTEL NEUROSC, P1
   Liao TL, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10030359
   Lim H., 2017, ARXIV
   Lin KWE, 2020, NEURAL COMPUT APPL, V32, P1037, DOI 10.1007/s00521-018-3933-z
   Lin S.-T., 2021, P INT S INT SIGN PRO, P1
   Liu X, 2017, Arxiv, DOI arXiv:1704.05665
   Liusong Y., 2022, MATH PROBLEMS ENG, P1
   Liutkus A, 2017, LECT NOTES COMPUT SC, V10169, P323, DOI 10.1007/978-3-319-53547-0_31
   Liutkus A, 2015, INT CONF ACOUST SPEE, P76, DOI 10.1109/ICASSP.2015.7177935
   Ljung L, 2020, IFAC PAPERSONLINE, V53, P1175, DOI 10.1016/j.ifacol.2020.12.1329
   Lostanlen V., 2016, ARXIV
   Lu M., 2022, WIREL COMMUN MOB COM, P1
   Luo Jing, 2020, P 7 C SOUND MUS TECH, P93
   Lyu Q, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P991, DOI 10.1145/2733373.2806383
   Madhusudhan S. T., 2019, P 20 INT SOC MUSIC I, P533
   Makris D., 2015, PROC 16 INT C ENG AP, P1
   Makris D, 2022, LECT NOTES COMPUT SC, P179, DOI 10.1007/978-3-031-03789-4_12
   Makris D, 2019, NEURAL COMPUT APPL, V31, P1793, DOI 10.1007/s00521-018-3708-6
   Manilow E., 2019, Proc. IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA), P1
   Mao HH, 2018, IEEE INT C SEMANT CO, P377, DOI 10.1109/ICSC.2018.00077
   Marafioti A, 2021, IEEE J-STSP, V15, P120, DOI 10.1109/JSTSP.2020.3037506
   Marchetti Francesco, 2021, Artificial Intelligence in Music, Sound, Art and Design. 10th International Conference, EvoMUSART 2021. Held as Part of EvoStar 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12693), P187, DOI 10.1007/978-3-030-72914-1_13
   Martín-Gutiérrez D, 2020, IEEE ACCESS, V8, P39361, DOI 10.1109/ACCESS.2020.2976033
   McFee B., 2012, The International Society for Music Information Retrieval (ISMIR), V12, P343
   McFee B., 2015, P 14 PYTH SCI C, V8, P18, DOI DOI 10.25080/MAJORA-7B98E3ED-003
   Mehri S, 2017, Arxiv, DOI arXiv:1612.07837
   midas, About us
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Monir R, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24010114
   Mukhedkar D., 2020, SCH ELECT ENG COMPUT
   musicsalesclassical, About us
   Nag S, 2022, PHYSICA A, V597, DOI 10.1016/j.physa.2022.127261
   Nakamura S, 1999, 6 EUR C SPEECH COMM
   Nassif AB, 2019, IEEE ACCESS, V7, P19143, DOI 10.1109/ACCESS.2019.2896880
   Ndou N, 2021, 2021 IEEE INTERNATIONAL IOT, ELECTRONICS AND MECHATRONICS CONFERENCE (IEMTRONICS), P581, DOI 10.1109/IEMTRONICS52119.2021.9422487
   Nistal J, 2022, Arxiv, DOI [arXiv:2008.12073, DOI 10.48550/ARXIV.2008.12073]
   Parascandolo G, 2016, INT CONF ACOUST SPEE, P6440, DOI 10.1109/ICASSP.2016.7472917
   Parlak IH, 2021, TURK J ELECTR ENG CO, V29, P3107, DOI 10.3906/elk-2101-44
   Pati A, 2019, Arxiv, DOI arXiv:1907.01164
   Pendyala V. S., 2022, SYSTEMS SOFT COMPUTI, V4
   Phan H, 2016, Arxiv, DOI arXiv:1604.06338
   Pons Jordi, 2019, THESIS U POMPEU FABR
   Prabhakar SK, 2023, EXPERT SYST APPL, V211, DOI 10.1016/j.eswa.2022.118636
   Purwins H, 2019, IEEE J-STSP, V13, P206, DOI 10.1109/JSTSP.2019.2908700
   Qiu L, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9182274
   Raffel C., 2016, THESIS COLUMBIA U NE, DOI [10.7916/D8N58MHV, DOI 10.7916/D8N58MHV]
   Rafii Zafar, 2017, Zenodo
   Rafii Z, 2018, IEEE-ACM T AUDIO SPE, V26, P1307, DOI 10.1109/TASLP.2018.2825440
   Rajesh S, 2020, PROCEDIA COMPUT SCI, V167, P16, DOI 10.1016/j.procs.2020.03.178
   Ramona M, 2008, INT CONF ACOUST SPEE, P1885, DOI 10.1109/ICASSP.2008.4518002
   Retta EA, 2022, Arxiv, DOI arXiv:2201.08448
   Revathy VR, 2022, LECT NOTE NETW SYST, V417, P484, DOI 10.1007/978-3-030-96302-6_45
   Rhyu S, 2022, IEEE ACCESS, V10, P28261, DOI 10.1109/ACCESS.2022.3155467
   Romero-Arenas R, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12157405
   Royal Museum of Central-Africa (RMCA), US
   Santana IAP, 2020, INT CONF SYST SIGNAL, P399, DOI [10.1109/IWSSIP48289.2020.9145170, 10.1109/iwssip48289.2020.9145170]
   Schedl M, 2019, FRONT APPL MATH STAT, V5, DOI 10.3389/fams.2019.00044
   Senac C, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095733
   Shah Devansh P., 2021, Artificial Intelligence in Music, Sound, Art and Design. 10th International Conference, EvoMUSART 2021. Held as Part of EvoStar 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12693), P248, DOI 10.1007/978-3-030-72914-1_17
   Shahriar S, 2021, IEEE ACCESS, V9, P117271, DOI 10.1109/ACCESS.2021.3098415
   Shaila S., 2022, PROC INT C RECENT TR, P99
   Shaila S., 2022, Computer Vision and Robotics, P35
   Sharma AK, 2021, IEEE ACCESS, V9, P102041, DOI 10.1109/ACCESS.2021.3093911
   Fathollahi MS, 2021, INT J MULTIMED INF R, V10, P43, DOI 10.1007/s13735-021-00206-5
   Shih Yi-Jen, 2023, IEEE Transactions on Multimedia, P3495, DOI 10.1109/TMM.2022.3161851
   Shrestha A, 2019, IEEE ACCESS, V7, P53040, DOI 10.1109/ACCESS.2019.2912200
   Silla Jr C.N., 2008, 9 INT C MUS INF PHIL, P451
   Singh J., 2018, PROC 4 INT C COMPUT, P1
   Skarha M., 2021, PROC NIME, P1
   Skoki A, 2019, PATTERN RECOGN LETT, V128, P340, DOI 10.1016/j.patrec.2019.09.024
   Sobota B., 2019, PROC IEEE 15 INT SCI
   Song GX, 2018, NEUROCOMPUTING, V292, P104, DOI 10.1016/j.neucom.2018.02.076
   Stasiak B, 2016, ACSIS-ANN COMPUT SCI, V8, P147, DOI 10.15439/2016F558
   Stegemann Thomas, 2019, Medicines (Basel), V6, DOI 10.3390/medicines6010025
   Sturm B. L., 2021, HDB ARTIFICIAL INTEL, P423
   Sturm BL, 2016, Arxiv, DOI arXiv:1604.08723
   Su Yuping, 2022, 2022 4th International Conference on Communications, Information System and Computer Engineering (CISCE), P363, DOI 10.1109/CISCE55963.2022.9851120
   Surana R, 2022, ALGO INTELL SY, P1, DOI 10.1007/978-981-16-7389-4_1
   Tahmasebi S, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00434
   Tan H. H., 2019, PROC INT C COMPUTATI, P364
   Tanberk S., 2021, PROC IEEE 19 WORLD S, P181
   Tang TR, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1598, DOI 10.1145/3240508.3240526
   TheFatRat, 2016, ARC
   Theorytab, About us
   Thickstun J, 2017, Arxiv, DOI arXiv:1611.09827
   Thompson N. C., 2020, arXiv, DOI DOI 10.48550/ARXIV.2007.05558
   Van TP, 2019, SOICT 2019: PROCEEDINGS OF THE TENTH INTERNATIONAL SYMPOSIUM ON INFORMATION AND COMMUNICATION TECHNOLOGY, P255, DOI 10.1145/3368926.3369700
   Tony Suman Maria, 2022, High Performance Computing and Networking: Select Proceedings of CHSN 2021. Lecture Notes in Electrical Engineering (853), P109, DOI 10.1007/978-981-16-9885-9_9
   Tsoulou K., 2020, THESIS HELLENIC U TH
   Turnbull Douglas, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P439, DOI 10.1145/1277741.1277817
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Uhlich S, 2017, INT CONF ACOUST SPEE, P261, DOI 10.1109/ICASSP.2017.7952158
   Vall A, 2018, Arxiv, DOI arXiv:1807.04690
   Vall A, 2019, USER MODEL USER-ADAP, V29, P527, DOI 10.1007/s11257-018-9215-8
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3
   Vaswani A., 2017, ADV NEUR INF PROCESS, V30, P1
   Wang HC, 2021, CHIN CONTR CONF, P8679
   Wang S., 2014, PROC IEEE INT C MULT, P1
   Wang ZY, 2020, Arxiv, DOI arXiv:2008.07142
   Wikipedia, LIST CULT REG GEN MU
   Wise A, 2021, EUR SIGNAL PR CONF, P376, DOI 10.23919/EUSIPCO54536.2021.9616348
   Woodford B., 2011, NCS NO COPYTIGHT SOU
   Wu CW, 2018, IEEE-ACM T AUDIO SPE, V26, P1457, DOI 10.1109/TASLP.2018.2830113
   Wyse L., 2017, arXiv
   Xia Gong, 2021, ICBDT '21: 2021 4th International Conference on Big Data Technologies, P184, DOI 10.1145/3490322.3490351
   Xiaojing Liang, 2019, Proceedings of the 6th Conference on Sound and Music Technology (CSMT). Revised Selected Papers: Lecture Notes in Electrical Engineering (LNEE 568), P53, DOI 10.1007/978-981-13-8707-4_5
   Xu K., 2021, CHIN HERB MED, P1
   Xu ZK, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.843427
   Yadav Omprakash, 2021, IETE Journal of Education, V62, P60, DOI 10.1080/09747338.2021.1966843
   Yadav P. S., 2022, PLANT OMICS, P1
   Yang LC, 2017, Arxiv, DOI [arXiv:1703.10847, 10.48550/arXiv.1703.10847]
   Yang R., 2019, Deep music analogy via latent representation disentanglement
   Yang W, 2019, 2019 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE BIG DATA AND INTELLIGENT SYSTEMS (HPBD&IS), P176, DOI [10.1109/hpbdis.2019.8735487, 10.1109/HPBDIS.2019.8735487]
   Yang Y., 2022, SENSORS-BASEL, P1
   Yu LT, 2017, AAAI CONF ARTIF INTE, P2852
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
   Zhang F., 2021, SECUR COMMUN NETW, P1
   Zhang H, 2022, INT CONF ACOUST SPEE, P756, DOI 10.1109/ICASSP43922.2022.9746039
   Zhang N, 2023, IEEE T NEUR NET LEAR, V34, P1754, DOI 10.1109/TNNLS.2020.2990746
   Zhang XL, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9091458
   Zhao W, 2018, PROCEEDINGS OF 2018 IEEE 3RD ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC 2018), P2596, DOI 10.1109/IAEAC.2018.8577272
   Zhau Y., 2022, MATH PROBL ENG, V2022, P1
NR 288
TC 2
Z9 2
U1 34
U2 63
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2023
VL 11
BP 17031
EP 17052
DI 10.1109/ACCESS.2023.3244620
PG 22
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA 9Q4ON
UT WOS:000944945600001
OA gold
DA 2024-01-09
ER

PT J
AU Sarno, R
   Ridoean, JA
   Sunaryono, D
   Wijaya, DR
AF Sarno, Riyanarto
   Ridoean, Johanes Andre
   Sunaryono, Dwi
   Wijaya, Dedy Rahman
TI Classification of Music Mood Using MPEG-7 Audio Features and SVM with
   Confidence Interval
SO INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS
LA English
DT Article
DE Music mood classification; MPEG-7; support vector machine; confidence
   interval
ID EMOTION; EXPRESSION; WAVELET; VOICE
AB Psychologically, music can affect human mood and influence human behavior. In this paper, a novel method for music mood classification is introduced. In the experiment, music mood classification was performed using feature extraction based on MPEG-7 features from the ISO/IEC 15938 standard for describing multimedia content. The result of this feature extraction are 17 low-level descriptors. Here, we used the Audio Power, Audio Harmonicity, and Audio Spectrum Projection features. Moreover, the discrete wavelet transform (DWT) was utilized for audio signal reconstruction. The reconstructed audio signals were classified by the new method, which uses a support vector machine with a confidence interval (SVM-CI). According to the experimental results, the success rate of the proposed method was satisfactory and SVM-CI outperformed the ordinary SVM.
C1 [Sarno, Riyanarto; Ridoean, Johanes Andre; Sunaryono, Dwi; Wijaya, Dedy Rahman] Inst Teknol Sepuluh Nopember, Informat Dept, Surabaya, Indonesia.
   [Wijaya, Dedy Rahman] Telkom Univ, Sch Appl Sci, Bandung, Indonesia.
C3 Institut Teknologi Sepuluh Nopember; Telkom University
RP Wijaya, DR (corresponding author), Inst Teknol Sepuluh Nopember, Informat Dept, Surabaya, Indonesia.; Wijaya, DR (corresponding author), Telkom Univ, Sch Appl Sci, Bandung, Indonesia.
EM riyanarto@if.its.ac.id; johanes.andre13@mhs.if.its.ac.id;
   dwi@if.its.ac.id; dedyrw@tass.telkomuniversity.ac.id
RI Wijaya, Dedy Rahman/P-2905-2015; Sunaryono, Dwi/GMX-1667-2022; Sarno,
   Riyanarto/AAC-2126-2020
OI Wijaya, Dedy Rahman/0000-0003-0351-7331; Sunaryono,
   Dwi/0000-0001-9925-9263; 
CR Ascalon E. I. V., 2015, P DLSU RES C, V3, DOI http://www.dlsu.edu.ph/conferences/dlsu_research_congress/2015/proceedings/HCT/009-HCT_Ascalon_EV.pdf.
   Casey M, 2001, IEEE T CIRC SYST VID, V11, P737, DOI 10.1109/76.927433
   Chen N, 2015, APPL ACOUST, V99, P92, DOI 10.1016/j.apacoust.2015.06.003
   Chen SH, 2010, COMPUT SPEECH LANG, V24, P531, DOI 10.1016/j.csl.2009.06.002
   Didiot E, 2010, COMPUT SPEECH LANG, V24, P341, DOI 10.1016/j.csl.2009.05.003
   Gao RX, 2011, WAVELETS: THEORY AND APPLICATIONS FOR MANUFACTURING, P1, DOI 10.1007/978-1-4419-1545-0
   Hampiholi V., 2012, INT J COMPUTER ELECT, V6, P507, DOI [10.1999/1307-6892/15269., DOI 10.1999/1307-6892/15269]
   Hu X, 2017, IEEE T AFFECT COMPUT, V8, P228, DOI 10.1109/TAFFC.2016.2523503
   Hume D., ORG BEHAV, P258
   *ISO IEC, 2001, 1593842001E ISOIEC F
   Kermanidis KL, 2014, INT J ARTIF INTELL T, V23, DOI 10.1142/S0218213014400077
   Kim H.-G., 2004, 2004 IEEE INT C AC S, V5, P7, DOI [10.1109/ICASSP.2004.1327263, DOI 10.1109/ICASSP.2004.1327263]
   Kim HG, 2005, MPEG-7 AUDIO AND BEYOND: AUDIO CONTENT INDEXING AND RETRIEVAL, P1, DOI 10.1002/0470093366
   Li S., 2010, P 2 INT C INT MULT A, P185, DOI 10.1145/1937728.1937772
   Lin C.-H., CONVERGENCE HYBRID I, P536
   Lin KS, 2013, NEUROCOMPUTING, V119, P111, DOI 10.1016/j.neucom.2012.03.034
   Liu Y., 2009 5 INT JOINT C I, P1485, DOI [10.1109/NCM.2009.311., DOI 10.1109/NCM.2009.311]
   Munawar Muhammad Nadzeri, 2016, Journal of Theoretical and Applied Information Technology, V87, P176
   Nardelli M, 2015, IEEE T AFFECT COMPUT, V6, P385, DOI 10.1109/TAFFC.2015.2432810
   Nishikawa N., P 1 INT ACM WORKSH M, P51, DOI [10.1145/2072529.2072543, DOI 10.1145/2072529.2072543]
   Nugraha Brilian T., 2016, Journal of Theoretical and Applied Information Technology, V86, P347
   Ren JM, 2015, IEEE T AFFECT COMPUT, V6, P236, DOI 10.1109/TAFFC.2015.2427836
   Saari P, 2016, IEEE T AFFECT COMPUT, V7, P122, DOI 10.1109/TAFFC.2015.2462841
   Sarno R., 2016, INT, V11, P214, DOI DOI 10.15866/IRECOS.V11I3.8562
   Scherer KR, 2015, COMPUT SPEECH LANG, V29, P218, DOI 10.1016/j.csl.2013.10.002
   Sharma S., 2014, INT J INNOVATIVE SCI, V1
   Soleymani M., 2015, P ACM INT MULT C EXH, V6, P1
   Soleymani M., EMOTION MUSIC DATABA
   Strachan DL, 2015, MASTERS ARTS ED ACTI, V5
   Ujlambkar A., 2014, INT J ADV COMPUTER R, V4
   Wieczorkowska Alicja A., 2010, ADV MUSIC INFORM RET
   Wiering F., P 4 INT C AD MULT RE, P82, DOI [10.1007/978-3-540-71545-0_7., DOI 10.1007/978-3-540-71545-0_7]
   Wijaya D. R., 2016, International Review on Computers and Software, V11, P659, DOI [DOI 10.15866/IREC0S.V11I8.9425, 10.15866/irecos.v11i8.9425, DOI 10.15866/IRECOS.V11I8.9425]
   Wijaya D. R., 2016, 2016 INT S EL SMART, P337, DOI [10.1109/ISESD.2016.7886744, DOI 10.1109/ISESD.2016.7886744]
   Wijaya DR, 2017, PROCEDIA COMPUT SCI, V124, P728, DOI 10.1016/j.procs.2017.12.211
   Wijaya DR, 2017, CHEMOMETR INTELL LAB, V160, P59, DOI 10.1016/j.chemolab.2016.11.012
   Xing BX, 2015, NEUROCOMPUTING, V148, P619, DOI 10.1016/j.neucom.2014.08.007
   You SD, 2013, SCI WORLD J, DOI 10.1155/2013/752464
   Zhang JL, 2016, NEUROCOMPUTING, V208, P333, DOI 10.1016/j.neucom.2016.01.099
   Zhang KJ, 2013, NEUROCOMPUTING, V105, P100, DOI 10.1016/j.neucom.2012.06.041
NR 40
TC 7
Z9 7
U1 1
U2 13
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-2130
EI 1793-6349
J9 INT J ARTIF INTELL T
JI Int. J. Artif. Intell. Tools
PD AUG
PY 2018
VL 27
IS 5
AR 1850016
DI 10.1142/S0218213018500161
PG 18
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GQ5SE
UT WOS:000441749700002
DA 2024-01-09
ER

PT J
AU Hsu, DY
   Huang, L
   Nordgren, LF
   Rucker, DD
   Galinsky, AD
AF Hsu, Dennis Y.
   Huang, Li
   Nordgren, Loran F.
   Rucker, Derek D.
   Galinsky, Adam D.
TI The Music of Power: Perceptual and Behavioral Consequences of Powerful
   Music
SO SOCIAL PSYCHOLOGICAL AND PERSONALITY SCIENCE
LA English
DT Article
DE music; power; moving first; illusory control; abstract thinking
ID AGGRESSION; DOMINANCE; RESPONSES; EMOTIONS; GENDER; REWARD; VOICE
AB Music has long been suggested to be a way to make people feel powerful. The current research investigated whether music can evoke a sense of power and produce power-related cognition and behavior. Initial pretests identified musical selections that generated subjective feelings of power. Experiment 1 found that music pretested to be powerful implicitly activated the construct of power in listeners. Experiments 2-4 demonstrated that power-inducing music produced three known important downstream consequences of power: abstract thinking, illusory control, and moving first. Experiments 5a and 5b held all features of music constant except for the level of bass and found that music with more bass increased participants' sense of power. This research expands our understanding of music's influence on cognition and behavior and uncovers a novel antecedent of the sense of power.
C1 [Hsu, Dennis Y.; Nordgren, Loran F.; Rucker, Derek D.] Northwestern Univ, Evanston, IL 60208 USA.
   [Huang, Li] INSEAD, F-77305 Fontainebleau, France.
   [Galinsky, Adam D.] Columbia Univ, New York, NY USA.
C3 Northwestern University; INSEAD Business School; Columbia University
RP Hsu, DY (corresponding author), Northwestern Univ, 2001 Sheridan Rd, Evanston, IL 60208 USA.
EM y-hsu@kellogg.northwestern.edu
RI Huang, Li/AAG-8070-2019
OI Huang, Li/0000-0002-2439-7132
CR Anderson C, 2006, EUR J SOC PSYCHOL, V36, P511, DOI 10.1002/ejsp.324
   [Anonymous], 2004, MUSIC POWER POLITICS
   [Anonymous], 1990, SOUND EFFECTS RADIO
   [Anonymous], 2010, Handbook of Music and Emotion
   [Anonymous], EFFECT METAL MUSIC M
   [Anonymous], PYSCHOL MUSIC, DOI DOI 10.1177/0305735603031001325
   [Anonymous], 2010, HDB MUSIC EMOTION TH
   [Anonymous], APA HDB PERSONALITY
   [Anonymous], 2002, Group Processes and Intergroup Relations, DOI DOI 10.1177/1368430202005002541
   [Anonymous], 1990, SOUND LIGHT HIST GOS
   Barsalou LW, 1999, BEHAV BRAIN SCI, V22, P577, DOI 10.1017/S0140525X99532147
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Boal-Palheiros G.M., 2001, BRIT J MUSIC EDUC, V18, P103, DOI DOI 10.1017/S0265051701000213
   Boksem MAS, 2012, SOC COGN AFFECT NEUR, V7, P516, DOI 10.1093/scan/nsp006
   Bordwell D., 2001, MCGRAW HILL FILM VIE
   Carney DR, 2010, PSYCHOL SCI, V21, P1363, DOI 10.1177/0956797610383437
   Carney DR, 2005, J NONVERBAL BEHAV, V29, P105, DOI 10.1007/s10919-005-2743-z
   Chen MJ, 2006, J STUD ALCOHOL, V67, P373, DOI 10.15288/jsa.2006.67.373
   Cole T., 1992, PINDARS FEASTS MUSIC, V69
   Coyne SM, 2012, J AGGRESS CONFL PEAC, V4, P186, DOI 10.1108/17596591211270680
   De Houwer J, 2001, PSYCHOL BULL, V127, P853, DOI 10.1037//0033-2909.127.6.853
   Donald D. H., 2011, LINCOLN
   Fast NJ, 2009, PSYCHOL SCI, V20, P502, DOI 10.1111/j.1467-9280.2009.02311.x
   Fischer P, 2006, PERS SOC PSYCHOL B, V32, P1165, DOI 10.1177/0146167206288670
   GABRIELSSON Alf, 2010, Handbook of Music and Emotion: Theory, Research, Applications, V2, P547, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0020
   Galinsky AD, 2003, J PERS SOC PSYCHOL, V85, P453, DOI 10.1037/0022-3514.85.3.453
   Greitemeyer T, 2011, J EXP SOC PSYCHOL, V47, P28, DOI 10.1016/j.jesp.2010.08.005
   Habe K., 2003, PSIHOLOKA OBZORJA HO, V12, P23
   Hall JA, 2005, PSYCHOL BULL, V131, P898, DOI 10.1037/0033-2909.131.6.898
   Hallam S., 2011, Oxford handbook of music psychology
   Hargreaves DJ., 1999, PSYCHOL MUSIC, V27, P71, DOI DOI 10.1177/0305735699271007
   Huang L, 2011, PSYCHOL SCI, V22, P95, DOI 10.1177/0956797610391912
   Huh H, 2011, PERS INDIV DIFFER, V51, P451, DOI 10.1016/j.paid.2011.04.012
   ISEN AM, 1984, J PERS SOC PSYCHOL, V47, P1206, DOI 10.1037/0022-3514.47.6.1206
   JONES SC, 1992, CRIT STUD MASS COMM, V9, P156, DOI 10.1080/15295039209366822
   Juslin P. N., 2008, OXFORD HDB MUSIC PSY
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Keltner D, 2003, PSYCHOL REV, V110, P265, DOI 10.1037/0033-295X.110.2.265
   LANGER EJ, 1975, J PERS SOC PSYCHOL, V32, P311, DOI 10.1037/0022-3514.32.2.311
   Lesiuk T., 2005, PSYCHOL MUSIC, V33, P173, DOI DOI 10.1177/0305735605050650
   Magee JC, 2007, PERS SOC PSYCHOL B, V33, P200, DOI 10.1177/0146167206294413
   Magee JC, 2008, ACAD MANAG ANN, V2, P351, DOI 10.1080/19416520802211628
   Mannes E., 2011, The power of music: Pioneering discoveries in the new science of song
   Merriam A., 1964, ANTHR MUSIC, V11
   Neumann R, 2000, J PERS SOC PSYCHOL, V79, P211, DOI 10.1037//0022-3514.79.2.211
   Park LE, 2013, J EXP SOC PSYCHOL, V49, P965, DOI 10.1016/j.jesp.2013.06.001
   Puts DA, 2007, EVOL HUM BEHAV, V28, P340, DOI 10.1016/j.evolhumbehav.2007.05.002
   Puts DA, 2006, EVOL HUM BEHAV, V27, P283, DOI 10.1016/j.evolhumbehav.2005.11.003
   Rentfrow PJ, 2003, J PERS SOC PSYCHOL, V84, P1236, DOI 10.1037/0022-3514.84.6.1236
   ROBAZZA C, 1994, PERCEPT MOTOR SKILL, V79, P939, DOI 10.2466/pms.1994.79.2.939
   Rubin AM, 2001, MEDIA PSYCHOL, V3, P25, DOI 10.1207/S1532785XMEP0301_02
   Sacks O, 2006, BRAIN, V129, P2528, DOI 10.1093/brain/awl234
   Salimpoor VN, 2013, SCIENCE, V340, P216, DOI 10.1126/science.1231059
   Scherer K. R., 2001, MUSIC EMOTION THEORY, P361, DOI DOI 10.1080/0929821042000317822
   Schmidt M., 2011, TIME MAGAZINE
   SEIDMAN SA, 1981, ECTJ-EDUC COMMUN TEC, V29, P49
   Siedliecki SL, 2006, J ADV NURS, V54, P553, DOI 10.1111/j.1365-2648.2006.03860.x
   Silverman C, 1996, WORLD MUSIC, V38, P63
   Smith PK, 2008, PSYCHOL SCI, V19, P441, DOI 10.1111/j.1467-9280.2008.02107.x
   Smith PK, 2006, J PERS SOC PSYCHOL, V90, P578, DOI 10.1037/0022-3514.90.4.578
   Stel M, 2012, SOC PSYCHOL PERS SCI, V3, P497, DOI 10.1177/1948550611427610
   Storr A, 1992, MUSIC AND THE MIND
   Vastfjall D., 2010, HDB MUSIC EMOTION TH
   Walser Robert, 1993, Running with the Devil: Power, Gender, and Madness in Heavy Metal
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 65
TC 26
Z9 33
U1 3
U2 73
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1948-5506
EI 1948-5514
J9 SOC PSYCHOL PERS SCI
JI Soc. Psychol. Personal Sci.
PD JAN
PY 2015
VL 6
IS 1
BP 75
EP 83
DI 10.1177/1948550614542345
PG 9
WC Psychology, Social
WE Social Science Citation Index (SSCI)
SC Psychology
GA AX0PX
UT WOS:000346655200009
DA 2024-01-09
ER

PT J
AU Chiu, MC
   Ko, LW
AF Chiu, Ming-Chuan
   Ko, Li-Wei
TI Develop a personalized intelligent music selection system based on heart
   rate variability and machine learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music recommendation; Personalized music system; Machine learning; Heart
   rate variability (HRV); Wearable device
ID EXPRESSION; VOICE
AB Music often plays an important role in people's daily lives. Because it has the power to affect human emotion, music has gained a place in work environments and in sports training as a way to enhance the performance of particular tasks. Studies have shown that office workers perform certain jobs better and joggers run longer distances when listening to music. However, a personalized music system which can automatically recommend songs according to user's physiological response remains absent. Therefore, this study aims to establish an intelligent music selection system for individual users to enhance their learning performance. We first created an emotional music database using data analytics classifications. During testing, innovative wearable sensing devices were used to detect heart rate variability (HRV) in experiments, which subsequently guided music selection. User emotions were then analyzed and appropriate songs were selected by using the proposed application software (App). Machine learning was used to record user preference, ensuring accurate and precise classification. Significant results generated through experimental validation indicate that this system generates high satisfaction levels, does not increase mental workload, and improves users' performance. Under the trend of the Internet of Things (IoT) and the continuing development of wearable devices, the proposed system could stimulate innovative applications for smart factory, home, and health care.
C1 [Chiu, Ming-Chuan; Ko, Li-Wei] Natl Tsing Hua Univ, Dept Ind Engn & Engn Management, 101,Sect 2,Kuang Fu Rd, Hsinchu 30013, Taiwan.
C3 National Tsing Hua University
RP Chiu, MC (corresponding author), Natl Tsing Hua Univ, Dept Ind Engn & Engn Management, 101,Sect 2,Kuang Fu Rd, Hsinchu 30013, Taiwan.
EM mcchiu@ie.nthu.edu.tw
FU Ministry of Science and Technology of the Republic of China, Taiwan
   [MOST 103 -2221-E-007-051-MY3]; Advanced Manufacturing and Service
   Management Research Center (AMSMRC), National Tsing Hua University
FX The authors would like to thank the Ministry of Science and Technology
   of the Republic of China, Taiwan, for partially financially supporting
   this research under contract number MOST 103 -2221-E-007-051-MY3. This
   work was also supported by the Advanced Manufacturing and Service
   Management Research Center (AMSMRC), National Tsing Hua University.
CR [Anonymous], 2001, DATA MINING CONCEPTS
   [Anonymous], 2012, PATTERN CLASSIFICATI
   [Anonymous], P ISMIR C
   [Anonymous], P CHI
   [Anonymous], 2001, Music and Emotion, DOI DOI 10.1525/MP.2004.21.4.561
   BAILEY JE, 1983, MANAGE SCI, V29, P530, DOI 10.1287/mnsc.29.5.530
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Bassellier G, 2004, MIS QUART, V28, P673
   Brooke J., 1996, USABILITY EVALUATION, V189, P4
   Cheng WY, 2014, INT J IND ENG-THEORY, V21, P304
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Davitz JR, 1964, COMMUNICATION EMOTIO, DOI [10.1016/B978-1-4832-3041-2.50008-7, DOI 10.1016/B978-1-4832-3041-2.50008-7]
   Eysenck H., 1985, PERSONALITY INDIVIDU, DOI 13877
   Fairbanks G, 1939, SPEECH MONOGR, V6, P87, DOI 10.1080/03637753909374863
   Fairbanks G, 1941, SPEECH MONOGR, V8, P85, DOI 10.1080/03637754109374888
   Feng Y, 2003, Pro ACM Int. Conf. Information Retrieval, P375, DOI DOI 10.1145/860500.860508
   Fonagy I., 1963, Z PHONETIK, V16, P293, DOI DOI 10.1524/STUF.1963.16.14.293
   FORNELL C, 1981, J MARKETING RES, V18, P382, DOI 10.2307/3150980
   Fu ZY, 2011, IEEE T MULTIMEDIA, V13, P303, DOI 10.1109/TMM.2010.2098858
   Gray E, 2013, PERSPECT PUBLIC HEAL, V133, P14, DOI 10.1177/1757913912468642
   Han BJ, 2010, MULTIMED TOOLS APPL, V47, P433, DOI 10.1007/s11042-009-0332-6
   Hand D.J., 1981, DISCRIMINATION CLASS
   HART S G, 1988, P139
   Hsu Y-W, 2014, P 21 ISPE INC INT C
   IVES B, 1983, COMMUN ACM, V26, P785, DOI 10.1145/358413.358430
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Kenny D, 2004, MUSIC FORUM
   Khalfa S, 2005, NEUROREPORT, V16, P1981, DOI 10.1097/00001756-200512190-00002
   Kim KJ, 2006, INT J IND ENG-THEORY, V13, P177
   Kinoshita Yuichiro, 2009, 2009 IEEE 13th International Symposium on Consumer Electronics (ISCE), P94, DOI 10.1109/ISCE.2009.5157047
   Kohavi R., 1998, Machine Learning, V30, P271
   Levenson RW, 2003, ANN NY ACAD SCI, V1000, P348, DOI 10.1196/annals.1280.016
   Lu L, 2006, IEEE T AUDIO SPEECH, V14, P5, DOI 10.1109/TSA.2005.860344
   Malik M, 2008, DYNAMIC ELECTROCARDI, P13, DOI 10.1002/9780470987483.ch2
   Medicore, 2015, SA 3000P CLIN MAN VE
   Michalski Ryszard Stanislaw, 2013, Machine learning: An artificial intelligence approach
   Mindlab, 2014, DOES PLAYING WORK IN
   Newman K., 2001, International Journal of Bank Marketing, V19, P126
   Nirjon S., 2012, P 10 ACM C EMB NETW, P43, DOI DOI 10.1145/2426656.2426662
   Oliver N, 2006, ISMIR, V2006, P7
   PARASURAMAN A, 1985, J MARKETING, V49, P41, DOI 10.2307/1251430
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Russell S, 1995, ARTIFICIAL INTELLIGE, DOI [10.1016/0925-2312(95)90020-9, DOI 10.1016/0925-2312(95)90020-9]
   Satoh M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0095230
   Schellenberg EG, 2000, MUSIC PERCEPT, V18, P155
   Serrà J, 2008, IEEE T AUDIO SPEECH, V16, P1138, DOI 10.1109/TASL.2008.924595
   Shen JL, 2009, ACM T INFORM SYST, V27, DOI 10.1145/1508850.1508856
   Tseng Y. E., 2010, THESIS
   Wang SF, 2015, MULTIMED TOOLS APPL, V74, P1863, DOI 10.1007/s11042-013-1722-3
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Watson KB, 1942, PSYCHOL MONOGR, V54, P1
   Weiss SM., 1991, Computer Systems That Learn: Classification and Prediction Methods from Statistics, Neural Networks, Machine Learning, and Expert Systems
   Yang YH, 2008, IEEE T AUDIO SPEECH, V16, P448, DOI 10.1109/TASL.2007.911513
   Yeh CH, 2014, MULTIMED TOOLS APPL, V73, P2103, DOI 10.1007/s11042-013-1687-2
   Yi-Hsuan Yang, 2012, ACM T INTEL SYST TEC, V3, P1, DOI DOI 10.1145/2168752.2168754
NR 55
TC 28
Z9 29
U1 7
U2 91
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15607
EP 15639
DI 10.1007/s11042-016-3860-x
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900018
DA 2024-01-09
ER

PT J
AU Filipic, S
   Tillmann, B
   Bigand, E
AF Filipic, Suzanne
   Tillmann, Barbara
   Bigand, Emmanuel
TI Judging familiarity and emotion from very brief musical excerpts
SO PSYCHONOMIC BULLETIN & REVIEW
LA English
DT Article
ID EVENT-RELATED POTENTIALS; SPOKEN WORD RECOGNITION; GATING PARADIGM;
   MELODY RECOGNITION; TIME-COURSE; MEMORY; EXPRESSIONS; DURATION;
   EXPOSURE; DAMAGE
AB In the present study, the gating paradigm was used to measure how much perceptual information that was extracted from musical excerpts needs to be heard to provide judgments of familiarity and of emotionality. Nonmusicians heard segments of increasing duration (250, 500, 1,000 msec, etc.). The stimuli were segments from familiar and unfamiliar musical excerpts in Experiment 1 and from very moving and emotionally neutral musical excerpts in Experiment 2. Participants judged how familiar (Experiment 1) or how moving (Experiment 2) the excerpt was to them. Results show that a feeling of familiarity can be triggered by 500-msec segments, and that the distinction between moving and neutral can be made for 250-msec segments. This finding extends the observation of fast-acting cognitive and emotional processes from face and voice perception to music perception.
C1 [Filipic, Suzanne; Bigand, Emmanuel] Univ Bourgogne, CNRS, UMR 5022, Dijon, France.
   [Tillmann, Barbara] Univ Lyon 1, CNRS, UMR 5020, F-69366 Lyon 07, France.
   [Bigand, Emmanuel] Inst Univ France, Dijon, France.
C3 Universite de Bourgogne; Centre National de la Recherche Scientifique
   (CNRS); CNRS - National Institute for Biology (INSB); Universite Claude
   Bernard Lyon 1; Centre National de la Recherche Scientifique (CNRS);
   Institut Universitaire de France
RP Tillmann, B (corresponding author), Univ Lyon 1, CNRS, UMR Neurosci Comportement Cognit 5020, 50 Av Tony Garnier, F-69366 Lyon 07, France.
EM barbara.tillmann@olfac.univ-lyon1.fr
CR Ashley V, 2004, NEUROREPORT, V15, P211, DOI 10.1097/00001756-200401190-00041
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Bigand E, 2003, J EXP PSYCHOL HUMAN, V29, P159, DOI 10.1037/0096-1523.29.1.159
   COTTON S, 1984, PERCEPT PSYCHOPHYS, V35, P41, DOI 10.3758/BF03205923
   Dalla Bella S, 2003, PERCEPT PSYCHOPHYS, V65, P1019
   Eimer M, 2007, NEUROPSYCHOLOGIA, V45, P15, DOI 10.1016/j.neuropsychologia.2006.04.022
   GROSJEAN F, 1980, PERCEPT PSYCHOPHYS, V28, P267, DOI 10.3758/BF03204386
   HALPERN AR, 1984, J EXP PSYCHOL LEARN, V10, P496, DOI 10.1037/0278-7393.10.3.496
   Koelsch S, 2000, J COGNITIVE NEUROSCI, V12, P520, DOI 10.1162/089892900562183
   LeDoux J. E., 1996, The emotional brain: The mysterious underpinnings of emotional life
   LIEGEOISCHAUVEL C, 2010, UNRAVELING MUSICAL E
   McDermott JH, 2009, CURR DIR PSYCHOL SCI, V18, P164, DOI 10.1111/j.1467-8721.2009.01629.x
   Niedenthal PM, 2007, SCIENCE, V316, P1002, DOI 10.1126/science.1136930
   Peretz I, 1998, MEM COGNITION, V26, P884, DOI 10.3758/BF03201171
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   Peretz I, 2006, COGNITION, V100, P1, DOI 10.1016/j.cognition.2005.11.004
   Plailly J, 2007, CEREB CORTEX, V17, P2650, DOI 10.1093/cercor/bhl173
   Posamentier MT, 2003, NEUROPSYCHOL REV, V13, P113, DOI 10.1023/A:1025519712569
   Rapoport E., 1997, Music, Gestalt, and Computing. Studies in Cognitive and Systematic Musicology, P451, DOI 10.1007/BFb0034133
   Schellenberg EG, 2003, PSYCHOL SCI, V14, P262, DOI 10.1111/1467-9280.03432
   Schellenberg EG, 1999, PSYCHON B REV, V6, P641, DOI 10.3758/BF03212973
   Schulkind MD, 2003, MUSIC PERCEPT, V21, P217, DOI 10.1525/mp.2003.21.2.217
   Schweinberger SR, 1997, J SPEECH LANG HEAR R, V40, P453, DOI 10.1044/jslhr.4002.453
   Steinke WR, 2001, COGN NEUROPSYCHOL, V18, P411, DOI 10.1080/02643290125702
   Szpunar KK, 2004, J EXP PSYCHOL LEARN, V30, P370, DOI 10.1037/0278-7393.30.2.370
   Tekman HG, 1998, J EXP PSYCHOL HUMAN, V24, P252, DOI 10.1037/0096-1523.24.1.252
   WALLEY AC, 1995, PERCEPT PSYCHOPHYS, V57, P343, DOI 10.3758/BF03213059
   Wambacq IJA, 2004, NEUROREPORT, V15, P555, DOI 10.1097/00001756-200403010-00034
NR 28
TC 50
Z9 60
U1 1
U2 8
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1069-9384
EI 1531-5320
J9 PSYCHON B REV
JI Psychon. Bull. Rev.
PD JUN
PY 2010
VL 17
IS 3
BP 335
EP 341
DI 10.3758/PBR.17.3.335
PG 7
WC Psychology, Mathematical; Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA 649YT
UT WOS:000281812700007
PM 20551355
OA Bronze
DA 2024-01-09
ER

PT J
AU Soares, AP
   Pinheiro, AP
   Costa, A
   Frade, CS
   Comesaña, M
   Pureza, R
AF Soares, Ana Paula
   Pinheiro, Ana P.
   Costa, Ana
   Frade, Carla Sofia
   Comesana, Montserrat
   Pureza, Rita
TI Affective auditory stimuli: Adaptation of the International Affective
   Digitized Sounds (IADS-2) for European Portuguese
SO BEHAVIOR RESEARCH METHODS
LA English
DT Article
DE Affective auditory stimuli; IADS; Valence; Arousal; Dominance; European
   Portuguese
ID SEX-DIFFERENCES; EMOTIONAL PROSODY; VOCAL EXPRESSION; ACTIVATION;
   RESPONSES; INSIGHTS; FEMALES; AROUSAL; MUSIC
AB In this study, we present the normative values of the adaptation of the International Affective Digitized Sounds (IADS-2; Bradley & Lang, 2007a) for European Portuguese (EP). The IADS-2 is a standardized database of 167 naturally occurring sounds that is widely used in the study of emotions. The sounds were rated by 300 college students who were native speakers of EP, in the three affective dimensions of valence, arousal, and dominance, by using the Self-Assessment Manikin (SAM). The aims of this adaptation were threefold: (1) to provide researchers with standardized and normatively rated affective sounds to be used with an EP population; (2) to investigate sex and cultural differences in the ratings of affective dimensions of auditory stimuli between EP and the American (Bradley & Lang, 2007a) and Spanish (Fernandez-Abascal et al., Psicothema 20: 104-113 2008; Redondo, Fraga, Padron, & Pineiro, Behavior Research Methods 40: 784790 2008) standardizations; and (3) to promote research on auditory affective processing in Portugal. Our results indicated that the IADS-2 is a valid and useful database of digitized sounds for the study of emotions in a Portuguese context, allowing for comparisons of its results with those of other international studies that have used the same database for stimulus selection. The normative values of the EP adaptation of the IADS-2 database can be downloaded along with the online version of this article.
C1 [Soares, Ana Paula; Costa, Ana; Frade, Carla Sofia; Comesana, Montserrat; Pureza, Rita] Univ Minho, Human Cognit Lab, CIPsi, Sch Psychol, P-4710057 Braga, Portugal.
   [Pinheiro, Ana P.] Univ Minho, Sch Psychol, CIPsi, Neuropsychophysiol Lab, Braga, Portugal.
C3 Universidade do Minho; Universidade do Minho
RP Soares, AP (corresponding author), Univ Minho, Human Cognit Lab, CIPsi, Sch Psychol, Campus Gualtar, P-4710057 Braga, Portugal.
EM asoares@psi.uminho.pt
RI COMESAÑA, MONTSERRAT/H-3785-2011; Soares, Ana Paula/H-3794-2011; Costa,
   Ana Santos/ABB-2614-2021; Frade, Sofia/IWU-8778-2023
OI COMESAÑA, MONTSERRAT/0000-0003-2547-7684; Soares, Ana
   Paula/0000-0002-4047-3799; Frade, Sofia/0000-0001-5239-7335; Pinheiro,
   Ana/0000-0002-7981-3682
FU Fundação para a Ciência e a Tecnologia [PTDC/PSI-PCO/104679/2008]
   Funding Source: FCT
CR Altenmüller E, 2002, NEUROPSYCHOLOGIA, V40, P2242, DOI 10.1016/S0028-3932(02)00107-0
   [Anonymous], 1999, Psychology
   [Anonymous], 2007, Handbook of Emotion Elicitation and Assessment
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Bradley M., 1999, The International affective digitized sounds (IADS): stimuli, instruction manual and affective ratings
   Bradley M.M., 2007, IADS-2): Affective Ratings of Sounds and Instruction Manual (Technical Report B- 3), V2nd
   Bradley MM, 2001, EMOTION, V1, P276, DOI 10.1037//1528-3542.1.3.276
   Bradley MM, 2001, EMOTION, V1, P300, DOI 10.1037//1528-3542.1.3.300
   Bradley MM, 2000, PSYCHOPHYSIOLOGY, V37, P204, DOI 10.1111/1469-8986.3720204
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Briggs KE, 2009, INT J PSYCHOPHYSIOL, V72, P299, DOI 10.1016/j.ijpsycho.2009.01.009
   Brosch T, 2009, J COGNITIVE NEUROSCI, V21, P1670, DOI 10.1162/jocn.2009.21110
   Cacioppo J T, 1997, Pers Soc Psychol Rev, V1, P3, DOI 10.1207/s15327957pspr0101_2
   Ethofer T, 2007, SOC COGN AFFECT NEUR, V2, P334, DOI 10.1093/scan/nsm028
   Fernández-Abascal EG, 2008, PSICOTHEMA, V20, P104
   Gohier B, 2013, EUR PSYCHIAT, V28, P74, DOI 10.1016/j.eurpsy.2011.06.007
   Heilman KM, 1997, J NEUROPSYCH CLIN N, V9, P439, DOI 10.1176/jnp.9.3.439
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Karama S, 2002, HUM BRAIN MAPP, V16, P1, DOI 10.1002/hbm.10014
   Lang P.J., 1999, The center for research in psychophysiology
   Lang P. J., 2008, A8 U FLOR NIMH CTR S
   Lang PJ, 1998, PSYCHOPHYSIOLOGY, V35, P199, DOI 10.1017/S0048577298001991
   LeDoux J. E., 1996, The emotional brain: The mysterious underpinnings of emotional life
   Lewis JW, 2004, CEREB CORTEX, V14, P1008, DOI 10.1093/cercor/bhh061
   Lithari C, 2010, BRAIN TOPOGR, V23, P27, DOI 10.1007/s10548-009-0130-5
   Liu TS, 2012, NEUROREPORT, V23, P108, DOI 10.1097/WNR.0b013e32834ea757
   Lykins AD, 2006, ARCH SEX BEHAV, V35, P569, DOI 10.1007/s10508-006-9065-z
   Mesquita B, 2003, BEHAV RES THER, V41, P777, DOI 10.1016/S0005-7967(02)00189-4
   Most SB, 2007, COGNITION EMOTION, V21, P964, DOI 10.1080/02699930600959340
   Osgood C. E., 1957, Themeasurement ofmeaning
   Partala T, 2003, INT J HUM-COMPUT ST, V59, P185, DOI 10.1016/S1071-5819(03)00017-X
   Pessoa L, 2009, TRENDS COGN SCI, V13, P160, DOI 10.1016/j.tics.2009.01.006
   Phelps EA, 2006, ANNU REV PSYCHOL, V57, P27, DOI 10.1146/annurev.psych.56.091103.070234
   Pinheiro AP, 2013, PSYCHOL MED, V43, P603, DOI 10.1017/S003329171200133X
   Redondo J, 2008, BEHAV RES METHODS, V40, P784, DOI 10.3758/BRM.40.3.784
   Royet JP, 2000, J NEUROSCI, V20, P7752
   Sakaki M, 2012, COGN AFFECT BEHAV NE, V12, P115, DOI 10.3758/s13415-011-0062-x
   Sander K, 2001, COGNITIVE BRAIN RES, V12, P181, DOI 10.1016/S0926-6410(01)00045-3
   Sauter DA, 2010, J COGNITIVE NEUROSCI, V22, P474, DOI 10.1162/jocn.2009.21215
   Scharpf KR, 2010, BEHAV BRAIN RES, V210, P16, DOI 10.1016/j.bbr.2010.01.038
   SCHERER KR, 1984, J ACOUST SOC AM, V76, P1346, DOI 10.1121/1.391450
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   Schirmer A, 2005, NEUROREPORT, V16, P635, DOI 10.1097/00001756-200504250-00024
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   Schirmer A, 2002, COGNITIVE BRAIN RES, V14, P228, DOI 10.1016/S0926-6410(02)00108-8
   Schirmer A, 2003, J COGNITIVE NEUROSCI, V15, P1135, DOI 10.1162/089892903322598102
   Smith NK, 2003, NEUROPSYCHOLOGIA, V41, P171, DOI 10.1016/S0028-3932(02)00147-1
   Soares A. P., 2011, 6 ENC ASS PORT PSIC
   Soares AP, 2012, BEHAV RES METHODS, V44, P256, DOI 10.3758/s13428-011-0131-7
   Stevenson RA, 2008, BEHAV RES METHODS, V40, P315, DOI 10.3758/BRM.40.1.315
   Tressoldi PE, 2011, SAGE OPEN, V1, DOI 10.1177/2158244011420451
   Yu JX, 2012, COGNITION, V124, P251, DOI 10.1016/j.cognition.2012.04.007
NR 52
TC 33
Z9 40
U1 0
U2 17
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1554-351X
EI 1554-3528
J9 BEHAV RES METHODS
JI Behav. Res. Methods
PD DEC
PY 2013
VL 45
IS 4
BP 1168
EP 1181
DI 10.3758/s13428-012-0310-1
PG 14
WC Psychology, Mathematical; Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA 269VZ
UT WOS:000328272100020
PM 23526255
OA Bronze
DA 2024-01-09
ER

PT J
AU Tawdrous, MM
   D'Onofrio, KL
   Gifford, R
   Picou, EM
AF Tawdrous, Marina M.
   D'Onofrio, Kristen L.
   Gifford, Rene
   Picou, Erin M.
TI Emotional Responses to Non-Speech Sounds for Hearing-aid and Bimodal
   Cochlear-Implant Listeners
SO TRENDS IN HEARING
LA English
DT Article
DE emotion; cochlear implant; hearing aid; valence; arousal; hearing loss;
   affect
ID SELF-ASSESSMENT MANNEQUIN; MUSIC PERCEPTION; VOCAL EXPRESSION; ACOUSTIC
   HEARING; ELECTRIC-STIMULATION; POSITIVE EMOTIONS; RECOGNITION; NOISE;
   CUES; BENEFITS
AB The purpose of this project was to evaluate differences between groups and device configurations for emotional responses to non-speech sounds. Three groups of adults participated: 1) listeners with normal hearing with no history of device use, 2) hearing aid candidates with or without hearing aid experience, and 3) bimodal cochlear-implant listeners with at least 6 months of implant use. Participants (n = 18 in each group) rated valence and arousal of pleasant, neutral, and unpleasant non-speech sounds. Listeners with normal hearing rated sounds without hearing devices. Hearing aid candidates rated sounds while using one or two hearing aids. Bimodal cochlear-implant listeners rated sounds while using a hearing aid alone, a cochlear implant alone, or the hearing aid and cochlear implant simultaneously. Analysis revealed significant differences between groups in ratings of pleasant and unpleasant stimuli; ratings from hearing aid candidates and bimodal cochlear-implant listeners were less extreme (less pleasant and less unpleasant) than were ratings from listeners with normal hearing. Hearing aid candidates' ratings were similar with one and two hearing aids. Bimodal cochlear-implant listeners' ratings of valence were higher (more pleasant) in the configuration without a hearing aid (implant only) than in the two configurations with a hearing aid (alone or with an implant). These data support the need for further investigation into hearing device optimization to improve emotional responses to non-speech sounds for adults with hearing loss.
C1 [Tawdrous, Marina M.] Western Univ, Sch Commun Sci & Disorders, 1151 Richmond St, London, ON N6A 3K7, Canada.
   [D'Onofrio, Kristen L.; Gifford, Rene; Picou, Erin M.] Vanderbilt Univ, Grad Sch, Dept Hearing & Speech Sci, 1215 21st Ave South,Room 8310, Nashville, TN 37232 USA.
   [D'Onofrio, Kristen L.; Gifford, Rene; Picou, Erin M.] Vanderbilt Univ, Sch Med, Dept Hearing & Speech Sci, Med Ctr, 1215 21st Ave South,Room 8310, Nashville, TN 37232 USA.
C3 Western University (University of Western Ontario); Vanderbilt
   University; Vanderbilt University
RP Tawdrous, MM (corresponding author), Western Univ, Sch Commun Sci & Disorders, 1151 Richmond St, London, ON N6A 3K7, Canada.
EM marina.m.tawdrous@gmail.com
RI Picou, Erin/J-4563-2019
OI Picou, Erin/0000-0003-3083-0809; Tawdrous, Marina/0000-0001-9026-6803
CR Alcántara JI, 2003, INT J AUDIOL, V42, P34, DOI 10.3109/14992020309056083
   Alvarsson JJ, 2010, INT J ENV RES PUB HE, V7, P1036, DOI 10.3390/ijerph7031036
   Ambert-Dahan E, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00181
   Atias D, 2019, J EXP PSYCHOL GEN, V148, P1842, DOI 10.1037/xge0000535
   Backs RW, 2005, EXP AGING RES, V31, P421, DOI 10.1080/03610730500206808
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Baumeister R. F., 2001, Rev. Gen. Psychol, V5, P323, DOI [DOI 10.1037/1089-2680.5.4.323, 10.1037/1089-2680.5.4.323]
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Boymans M, 2008, EAR HEARING, V29, P930, DOI 10.1097/AUD.0b013e31818713a8
   Bradley M. M., 2007, Technical report B-3
   Bradley MM, 2001, EMOTION, V1, P276, DOI 10.1037//1528-3542.1.3.276
   Bradley MM, 2000, PSYCHOPHYSIOLOGY, V37, P204, DOI 10.1111/1469-8986.3720204
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Buono GH, 2021, HEARING RES, V401, DOI 10.1016/j.heares.2020.108153
   Caldwell Meredith, 2015, Cochlear Implants Int, V16 Suppl 3, pS114, DOI 10.1179/1467010015Z.000000000265
   Chatterjee M, 2008, HEARING RES, V235, P143, DOI 10.1016/j.heares.2007.11.004
   Chatterjee M, 2015, HEARING RES, V322, P151, DOI 10.1016/j.heares.2014.10.003
   Cheng XT, 2018, NEURAL PLAST, V2018, DOI 10.1155/2018/4610592
   Christensen JA, 2019, EAR HEARING, V40, P1069, DOI 10.1097/AUD.0000000000000694
   Crew JD, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0120279
   Cullington HE, 2011, EAR HEARING, V32, P16, DOI 10.1097/AUD.0b013e3181edfbd2
   D'Onofrio KL, 2021, J SPEECH LANG HEAR R, V64, P1341, DOI 10.1044/2020_JSLHR-20-00390
   D'Onofrio KL, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00114
   Dalton DS, 2003, GERONTOLOGIST, V43, P661, DOI 10.1093/geront/43.5.661
   Damm SA, 2019, J SPEECH LANG HEAR R, V62, P3728, DOI 10.1044/2019_JSLHR-S-18-0497
   Davidson LS, 2019, J SPEECH LANG HEAR R, V62, P3620, DOI 10.1044/2019_JSLHR-H-18-0255
   Deroche MLD, 2019, EAR HEARING, V40, P1197, DOI 10.1097/AUD.0000000000000701
   Dorman MF, 2008, AUDIOL NEURO-OTOL, V13, P105, DOI 10.1159/000111782
   Dorman MF, 2010, INT J AUDIOL, V49, P912, DOI 10.3109/14992027.2010.509113
   Dunn CC, 2005, J SPEECH LANG HEAR R, V48, P668, DOI 10.1044/1092-4388(2005/046)
   Dupuis K, 2014, EAR HEARING, V35, P695, DOI 10.1097/AUD.0000000000000082
   Eerola T, 2013, MUSIC PERCEPT, V30, P307, DOI [10.1525/mp.2012.30.3.307, 10.1525/MP.2012.30.1.49]
   El Fata F, 2009, AUDIOL NEURO-OTOL, V14, P14, DOI 10.1159/000206491
   ERDMAN SA, 1981, EAR HEARING, V2, P225, DOI 10.1097/00003446-198109000-00009
   Faith M, 2001, SCAND J PSYCHOL, V42, P121, DOI 10.1111/1467-9450.00221
   Fredrickson BL, 2005, COGNITION EMOTION, V19, P313, DOI 10.1080/02699930441000238
   Fredrickson BL, 2001, AM PSYCHOL, V56, P218, DOI 10.1037/0003-066X.56.3.218
   Freyaldenhoven MC, 2006, J AM ACAD AUDIOL, V17, P659, DOI 10.3766/jaaa.17.9.5
   Fu QJ, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12298-3
   Giannantonio S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0136685
   Gifford RH, 2021, OTOL NEUROTOL, V42, pS19, DOI 10.1097/MAO.0000000000003375
   Gifford RH, 2019, EAR HEARING, V40, P501, DOI 10.1097/AUD.0000000000000657
   Gifford RH, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518771176
   Gosselin N, 2005, BRAIN, V128, P628, DOI 10.1093/brain/awh420
   Goudbeek M, 2010, J ACOUST SOC AM, V128, P1322, DOI 10.1121/1.3466853
   Goy HW, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518801736
   Grühn D, 2008, BEHAV RES METHODS, V40, P512, DOI 10.3758/BRM.40.2.512
   HAWKINS DB, 1984, J SPEECH HEAR DISORD, V49, P278, DOI 10.1044/jshd.4903.278
   Hawthorne G, 2008, SOC PSYCH PSYCH EPID, V43, P140, DOI 10.1007/s00127-007-0279-8
   Holder JT, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518755288
   Hsiao Feilin, 2012, Update Univ S C Dep Music, V30, P5
   HUMES LE, 1990, J SPEECH HEAR RES, V33, P726, DOI 10.1044/jshr.3304.726
   Humes LE, 2002, J SPEECH LANG HEAR R, V45, DOI 10.1044/1092-4388(2002/062)
   Husain FT, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00010
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Jiam NT, 2017, HEARING RES, V352, P30, DOI 10.1016/j.heares.2017.01.006
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Keidser G, 2012, TRENDS AMPLIF, V16, P211, DOI 10.1177/1084713812468511
   Kensinger EA, 2009, EMOT REV, V1, P99, DOI 10.1177/1754073908100432
   Kiss I, 2001, Appl Neuropsychol, V8, P251, DOI 10.1207/09084280152829110
   Köbler S, 2001, SCAND AUDIOL, V30, P223, DOI 10.1080/01050390152704742
   Kong YY, 2007, J ACOUST SOC AM, V121, P3717, DOI 10.1121/1.2717408
   Kong YY, 2012, EAR HEARING, V33, P645, DOI 10.1097/AUD.0b013e318252caae
   Kong YY, 2005, J ACOUST SOC AM, V117, P1351, DOI 10.1121/1.1857526
   Kong YY, 2004, EAR HEARING, V25, P173, DOI 10.1097/01.AUD.0000120365.97792.2F
   Kramer SE, 2002, J AGING HEALTH, V14, P122, DOI 10.1177/089826430201400107
   Laukka P, 2005, COGNITION EMOTION, V19, P633, DOI 10.1080/02699930441000445
   Lenth Russell V, 2023, CRAN
   Lundqvist LO, 2009, PSYCHOL MUSIC, V37, P61, DOI 10.1177/0305735607086048
   Ma C, 2012, BIRTH DEFECTS RES A, V94, P1026, DOI 10.1002/bdra.23053
   Ma WY, 2015, P NATL ACAD SCI USA, V112, P14563, DOI 10.1073/pnas.1515087112
   Mok M, 2006, J SPEECH LANG HEAR R, V49, P338, DOI 10.1044/1092-4388(2006/027)
   Most T, 2012, J DEAF STUD DEAF EDU, V17, P244, DOI 10.1093/deafed/enr046
   Most T, 2011, J SPEECH LANG HEAR R, V54, P668, DOI 10.1044/1092-4388(2010/10-0071)
   Most T, 2009, J DEAF STUD DEAF EDU, V14, P449, DOI 10.1093/deafed/enp007
   Osgood C. E., 1957, Themeasurement ofmeaning
   Paquette S, 2018, HEARING RES, V370, P272, DOI 10.1016/j.heares.2018.08.009
   Paulmann S, 2008, BRAIN LANG, V104, P262, DOI 10.1016/j.bandl.2007.03.002
   Pell MD, 2009, J PHONETICS, V37, P417, DOI 10.1016/j.wocn.2009.07.005
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   Peters RW, 1998, J ACOUST SOC AM, V103, P577, DOI 10.1121/1.421128
   Picou E.M., 2021, SEMIN HEAR
   Picou EM, 2021, TRENDS HEAR, V25, DOI 10.1177/23312165211049938
   Picou EM, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518813243
   Picou EM, 2016, J SPEECH LANG HEAR R, V59, P1233, DOI 10.1044/2016_JSLHR-H-15-0231
   Picou EM, 2013, EAR HEARING, V34, pe52, DOI 10.1097/AUD.0b013e31827f0431
   Plant K, 2016, INT J AUDIOL, V55, pS31, DOI 10.3109/14992027.2016.1150609
   PLOMP R, 1976, ACUSTICA, V34, P201
   Potts LG, 2009, J AM ACAD AUDIOL, V20, P353, DOI 10.3766/jaaa.20.6.4
   R Core Team, 2018, R: A Language and Environment for Statistical Computing
   Ricketts TA, 2019, J SPEECH LANG HEAR R, V62, P3834, DOI 10.1044/2019_JSLHR-H-19-0013
   RIGO TG, 1989, EAR HEARING, V10, P184, DOI 10.1097/00003446-198906000-00008
   Rosslau K, 2012, ACTA OTO-LARYNGOL, V132, P64, DOI 10.3109/00016489.2011.619569
   Sandstrom G. M., 2010, Music and Medicine, V2, P137, DOI DOI 10.1177/1943862110371486
   Schmidt J, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00781
   Schmidt J, 2016, ADV EXP MED BIOL, V894, P47, DOI 10.1007/978-3-319-25474-6_6
   SCHREURS KK, 1985, EAR HEARING, V6, P198, DOI 10.1097/00003446-198507000-00005
   Sheffield SW, 2015, J AM ACAD AUDIOL, V26, P145, DOI 10.3766/jaaa.26.2.5
   Sheffield SW, 2014, AUDIOL NEURO-OTOL, V19, P151, DOI 10.1159/000357588
   Shirvani S, 2016, ANN OTO RHINOL LARYN, V125, P470, DOI 10.1177/0003489415619943
   Shirvani Sareh, 2014, Iran J Otorhinolaryngol, V26, P225
   Singh G, 2019, EAR HEARING, V40, P260, DOI 10.1097/AUD.0000000000000611
   Sladen DP, 2018, OTOL NEUROTOL, V39, P576, DOI 10.1097/MAO.0000000000001763
   Sucher Catherine M, 2009, Cochlear Implants Int, V10 Suppl 1, P96, DOI 10.1179/cim.2009.10.Supplement-1.96
   TAYLOR SE, 1991, PSYCHOL BULL, V110, P67, DOI 10.1037/0033-2909.110.1.67
   VAUGHANJONES RH, 1993, J LARYNGOL OTOL, V107, P329, DOI 10.1017/S0022215100122947
   Weninger F, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00292
   Willis S, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0240752
   Xin Luo, 2007, Trends Amplif, V11, P301
   Yoon Yang-Soo, 2015, Cochlear Implants Int, V16, P159, DOI 10.1179/1754762814Y.0000000101
   ZAJONC RB, 1980, AM PSYCHOL, V35, P151, DOI 10.1037/0003-066X.35.2.151
   ZIGMOND AS, 1983, ACTA PSYCHIAT SCAND, V67, P361, DOI 10.1111/j.1600-0447.1983.tb09716.x
NR 113
TC 3
Z9 4
U1 1
U2 4
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 2331-2165
J9 TRENDS HEAR
JI Trends Hear.
PD APR
PY 2022
VL 26
AR 23312165221083091
DI 10.1177/23312165221083091
PG 17
WC Audiology & Speech-Language Pathology; Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Audiology & Speech-Language Pathology; Otorhinolaryngology
GA 0P1LI
UT WOS:000783983800001
PM 35435773
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Kogan, VV
   Reiterer, SM
AF Kogan, Vita V.
   Reiterer, Susanne M.
TI Eros, Beauty, and Phon-Aesthetic Judgements of Language Sound. We Like
   It Flat and Fast, but Not Melodious. Comparing Phonetic and Acoustic
   Features of 16 European Languages
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE phon-aesthetics; language attitudes and ideologies; speech melody;
   speech rate; language perception; crosslinguistic comparison; rhythm in
   language; prosody and intonation perception
ID SPEECH; MUSIC; RHYTHM; SENSITIVITY; PERCEPTION; EMOTIONS; EXPOSURE;
   ENGLISH; VOICES; RANGE
AB This article concerns sound aesthetic preferences for European foreign languages. We investigated the phonetic-acoustic dimension of the linguistic aesthetic pleasure to describe the "music" found in European languages. The Romance languages, French, Italian, and Spanish, take a lead when people talk about melodious language - the music-like effects in the language (a.k.a., phonetic chill). On the other end of the melodiousness spectrum are German and Arabic that are often considered sounding harsh and un-attractive. Despite the public interest, limited research has been conducted on the topic of phonaesthetics, i.e., the subfield of phonetics that is concerned with the aesthetic properties of speech sounds (Crystal, 2008). Our goal is to fill the existing research gap by identifying the acoustic features that drive the auditory perception of language sound beauty. What is so music-like in the language that makes people say "it is music in my ears"? We had 45 central European participants listening to 16 auditorily presented European languages and rating each language in terms of 22 binary characteristics (e.g., beautiful - ugly and funny - boring) plus indicating their language familiarities, L2 backgrounds, speaker voice liking, demographics, and musicality levels. Findings revealed that all factors in complex interplay explain a certain percentage of variance: familiarity and expertise in foreign languages, speaker voice characteristics, phonetic complexity, musical acoustic properties, and finally musical expertise of the listener. The most important discovery was the trade-off between speech tempo and so-called linguistic melody (pitch variance): the faster the language, the flatter/more atonal it is in terms of the pitch (speech melody), making it highly appealing acoustically (sounding beautiful and sexy), but not so melodious in a "musical" sense.
C1 [Kogan, Vita V.] Univ Kent, Sch European Culture & Languages, Canterbury, Kent, England.
   [Reiterer, Susanne M.] Univ Vienna, Dept Linguist, Vienna, Austria.
   [Reiterer, Susanne M.] Univ Vienna, Teacher Educ Ctr, Vienna, Austria.
C3 University of Kent; University of Vienna; University of Vienna
RP Reiterer, SM (corresponding author), Univ Vienna, Dept Linguist, Vienna, Austria.; Reiterer, SM (corresponding author), Univ Vienna, Teacher Educ Ctr, Vienna, Austria.
EM Susanne.Reiterer@univie.ac.at
OI Kogan, Vita V./0000-0002-8354-020X; Reiterer,
   Susanne/0000-0001-5684-1966
CR Abercombie D., 2013, N WIND SUN 1951 1978
   Albouy P, 2020, SCIENCE, V367, P1043, DOI 10.1126/science.aaz3468
   [Anonymous], 2010, WORST BEST LANGUAGES
   [Anonymous], 2015, WHAT MAK LANG SOUND
   [Anonymous], 2008, DICT LANGUAGE LINGUI
   [Anonymous], 2019, N WIND SUN PHONETICS
   [Anonymous], 2003, Z SPRACHWISSENSCHAFT, DOI DOI 10.1515/ZFSW.2003.22.1.86
   Anwyl-Irvine AL, 2020, BEHAV RES METHODS, V52, P388, DOI 10.3758/s13428-019-01237-x
   Arai T, 1998, INT CONF ACOUST SPEE, P933, DOI 10.1109/ICASSP.1998.675419
   Arvaniti A, 2012, J PHONETICS, V40, P351, DOI 10.1016/j.wocn.2012.02.003
   Arvaniti A, 2009, PHONETICA, V66, P46, DOI 10.1159/000208930
   Assaneo MF, 2019, NAT NEUROSCI, V22, P627, DOI 10.1038/s41593-019-0353-z
   BIRCH LL, 1982, APPETITE, V3, P353, DOI 10.1016/S0195-6663(82)80053-6
   Blevins Juliette., 1995, HDB PHONOLOGICAL THE, P206, DOI DOI 10.1111/B.9780631201267.1996.00008.X
   Boersma P., 2017, PRAAT DOING PHONETIC
   BORNSTEIN RF, 1989, PSYCHOL BULL, V106, P265, DOI 10.1037/0033-2909.106.2.265
   Brattico E, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00206
   Breitenstein C, 2001, COGNITION EMOTION, V15, P57, DOI 10.1080/0269993004200114
   Brück C, 2011, PHYS LIFE REV, V8, P383, DOI 10.1016/j.plrev.2011.10.002
   Brunner B., 2014, The sound of difference: Why we find some languages more beautiful than others
   Burdick DJ, 2014, MOVEMENT DISORD, V29, P1258, DOI 10.1002/mds.25924
   Carbonell J.F., 1992, CATALAN J INT PHONET, V22, P53
   Chahal A., 2017, HEART, V4, P444
   Chow I, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00247
   Christiner M, 2018, INT J MULTILING, V15, P455, DOI 10.1080/14790718.2018.1424171
   Christiner M, 2018, BRAIN SCI, V8, DOI 10.3390/brainsci8090169
   Christiner M, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00482
   Christiner M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00874
   Cordes I., 2000, P 4 INT C MUSIC PERC
   Coupé C, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aaw2594
   Dalle Fratte M., 2018, ITALIAN IS LANGUAGE
   Dellwo V., 2003, P ICPHS LOND
   Dolcos F, 2004, NEUROIMAGE, V23, P64, DOI 10.1016/j.neuroimage.2004.05.015
   Edworthy J, 2003, APPL COGNITIVE PSYCH, V17, P915, DOI 10.1002/acp.927
   Eisentraut J., 2012, ACCESSIBILITY MUSIC
   Elliott TM, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000302
   Falk S, 2014, J EXP PSYCHOL HUMAN, V40, P1491, DOI 10.1037/a0036858
   Fitch WT, 2007, MUSIC PERCEPT, V25, P43, DOI 10.1525/mp.2007.25.1.43
   Fitch WT, 2013, BIRDSONG, SPEECH, AND LANGUAGE: EXPLORING THE EVOLUTION OF MIND AND BRAIN, P489
   Flinker A, 2019, NAT HUM BEHAV, V3, P393, DOI 10.1038/s41562-019-0548-z
   Fonseca-Mora M.C., 2011, ANGLISTIK INT J ENGL, V22, P101
   Fourgeron Celine., 1993, The Journal of the International Phonetic Association, V23, P73, DOI [DOI 10.1017/S0025100300004874, https://doi.org/10.1017/S0025100300004874]
   Giles H., 1998, Language myths, P85
   Gordon E. E., 1982, Intermediate Measures of Music Audiation
   Goswami U, 2013, LAB PHONOL, V4, P67, DOI 10.1515/lp-2013-0004
   GREENBERG JH, 1965, LINGUISTICS, P5
   Grewe O, 2007, MUSIC PERCEPT, V24, P297, DOI 10.1525/MP.2007.24.3.297
   Gronnum Nina., 1998, J INT PHON ASSOC, V28, P99, DOI DOI 10.1017/S0025100300006290
   Guhn M, 2007, MUSIC PERCEPT, V24, P473, DOI 10.1525/MP.2007.24.5.473
   Hualde JI, 2010, J INT PHON ASSOC, V40, P113, DOI 10.1017/S0025100309990260
   Hutchins S, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00236
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Jacobsen T, 2004, PSYCHOL REP, V94, P1253, DOI 10.2466/PR0.94.3.1253-1260
   Janson T., 1986, PHONOL YB, V5, P196
   Jassem, 2003, J. Int. Phon. Assoc, V33, P103, DOI [10.1017/S0025100303001191, DOI 10.1017/S0025100303001191]
   Jekiel M, 2014, P YB POZNAN LINGUIST, DOI [10.1515/yplm-2015-0003, DOI 10.1515/YPLM-2015-0003]
   Jin ZS, 2017, NEUROIMAGE-CLIN, V14, P602, DOI 10.1016/j.nicl.2017.02.024
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Juslin PN, 1997, MUSIC SCI, V1, P225, DOI DOI 10.1177/102986499700100205
   Kerr B., 2017, BBC
   Kirby S., 2011, LANGUAGE MUSIC COGNI, P96, DOI [10.1093/acprof:oso/9780199553426.001.0010, DOI 10.1093/ACPROF:OSO/9780199553426.001.0010]
   Koelsch S, 2006, HUM BRAIN MAPP, V27, P239, DOI 10.1002/hbm.20180
   Kogan V.V., 2017, P INT S MON BIL SPEE
   Krumhansl C.L., 1990, OXFORD PSYCHOL SERIE
   Lau E., 1995, J INT PHONET ASS, V25, P83
   Leder H, 2014, COGNITION EMOTION, V28, P1137, DOI 10.1080/02699931.2013.870132
   Ma WY, 2019, SEMIOTICA, P1, DOI 10.1515/sem-2018-0139
   Ma WY, 2015, P NATL ACAD SCI USA, V112, P14563, DOI 10.1073/pnas.1515087112
   Martinez-Celdran E., 2003, J. Int. Phon. Assoc, V33, P255, DOI [10.1017/S0025100303001373, DOI 10.1017/S0025100303001373]
   Mayer RE, 2019, CAMBRIDGE HANDBOOK OF COGNITION AND EDUCATION, P460
   MCMINN MR, 1993, J PSYCHOL THEOL, V21, P309, DOI 10.1177/009164719302100404
   Mennen I, 2012, J ACOUST SOC AM, V131, P2249, DOI 10.1121/1.3681950
   Mesquita B, 2003, SER AFFECTIVE SCI, P871
   Nardo D, 2009, TRENDS APPL LINGUIST, V1, P213
   Oikkonen J, 2015, MOL PSYCHIATR, V20, P275, DOI 10.1038/mp.2014.8
   Ozernov-Palchik O, 2018, ANN NY ACAD SCI, V1423, P166, DOI 10.1111/nyas.13853
   Patel AD, 2005, BRAIN COGNITION, V59, P310, DOI 10.1016/j.bandc.2004.10.003
   Patel AD, 2010, MUSIC LANGUAGE BRAIN
   Patel AD, 2006, J ACOUST SOC AM, V119, P3034, DOI 10.1121/1.2179657
   Petroni F, 2010, PHYSICA A, V389, P2280, DOI 10.1016/j.physa.2010.02.004
   Pompino-Marschall B, 2017, J INT PHON ASSOC, V47, P349, DOI 10.1017/S0025100316000372
   Quinto L, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00184
   Rathcke T., 2020, P 10 INT C SPEECH PR, DOI [10.21437/SpeechProsody.2020-1, DOI 10.21437/SPEECHPROSODY.2020-1]
   Ravignani A, 2017, NAT HUM BEHAV, V1, DOI 10.1038/s41562-016-0007
   Reber R, 2004, PERS SOC PSYCHOL REV, V8, P364, DOI 10.1207/s15327957pspr0804_3
   Reiterer S, 2008, BRAIN IMAGING BEHAV, V2, P1, DOI 10.1007/s11682-007-9010-3
   Reuter C., 2011, J. Acoust. Soc. Am, V130, DOI [10.1121/1.3655174, DOI 10.1121/1.3655174]
   Roach P., 2004, Journal of the International Phonetic Association: Illustrations of the IPA, V34, P239, DOI DOI 10.1017/S0025100304001768
   Sammler D, 2020, SCIENCE, V367, P974, DOI 10.1126/science.aba7913
   Scherer K.R., 2003, VOCAL EXPRESSION EMO
   Schneider P, 2002, NAT NEUROSCI, V5, P688, DOI 10.1038/nn871
   Science Chat Forum, 2011, SOME LANGUAGES SOUND
   Serva M, 2008, EPL-EUROPHYS LETT, V81, DOI 10.1209/0295-5075/81/68005
   Starcke K, 2019, INT J PSYCHOPHYSIOL, V142, P25, DOI 10.1016/j.ijpsycho.2019.06.001
   Steinbeis N, 2006, J COGNITIVE NEUROSCI, V18, P1380, DOI 10.1162/jocn.2006.18.8.1380
   Szende T., 1994, J INT PHON ASSOC, V24, P91, DOI DOI 10.1017/S0025100300005090
   Thompson WF, 2012, P NATL ACAD SCI USA, V109, P19027, DOI 10.1073/pnas.1210344109
   Tilsen S, 2013, J ACOUST SOC AM, V134, P628, DOI 10.1121/1.4807565
   Torregrosa-Azor J., 2015, 34 ROM MANNH
   Vuust P, 2010, PLEASURES BRAIN, P255
   Whipple TW, 2002, J ADVERTISING, V31, P79, DOI 10.1080/00913367.2002.10673668
   Wilding J, 2000, PERCEPT MOTOR SKILL, V91, P535, DOI 10.2466/PMS.91.6.535-538
   Winkielman P, 2001, J PERS SOC PSYCHOL, V81, P989, DOI 10.1037//0022-3514.81.6.989
   Wrembel M, 2010, INT J MULTILING, V7, P75, DOI 10.1080/14790710902972263
   Yanushevskaya I, 2015, J INT PHON ASSOC, V45, P221, DOI 10.1017/S0025100314000395
   Zaidel DW, 2013, PSYCHOL AESTHET CREA, V7, P100, DOI 10.1037/a0028797
   Zeki S, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00068
NR 108
TC 1
Z9 1
U1 1
U2 9
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD FEB 23
PY 2021
VL 15
AR 578594
DI 10.3389/fnhum.2021.578594
PG 22
WC Neurosciences; Psychology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Neurosciences & Neurology; Psychology
GA QT3BR
UT WOS:000626465600001
PM 33708080
OA gold, Green Accepted, Green Published
DA 2024-01-09
ER

PT J
AU Chen, CF
   Li, Q
AF Chen, Changfeng
   Li, Qiang
TI A Multimodal Music Emotion Classification Method Based on Multifeature
   Combined Network Classifier
SO MATHEMATICAL PROBLEMS IN ENGINEERING
LA English
DT Article
AB Aiming at the shortcomings of single network classification model, this paper applies CNN-LSTM (convolutional neural networks-long short-term memory) combined network in the field of music emotion classification and proposes a multifeature combined network classifier based on CNN-LSTM which combines 2D (two-dimensional) feature input through CNN-LSTM and 1D (single-dimensional) feature input through DNN (deep neural networks) to make up for the deficiencies of original single feature models. The model uses multiple convolution kernels in CNN for 2D feature extraction, BiLSTM (bidirectional LSTM) for serialization processing and is used, respectively, for audio and lyrics single-modal emotion classification output. In the audio feature extraction, music audio is finely divided and the human voice is separated to obtain pure background sound clips; the spectrogram and LLDs (Low Level Descriptors) are extracted there from. In the lyrics feature extraction, the chi-squared test vector and word embedding extracted by Word 2 vec are, respectively, used as the feature representation of the lyrics. Combining the two types of heterogeneous features selected by audio and lyrics through the classification model can improve the classification performance. In order to fuse the emotional information of the two modals of music audio and lyrics, this paper proposes a multimodal ensemble learning method based on stacking, which is different from existing feature-level and decision-level fusion methods, the method avoids information loss caused by direct dimensionality reduction, and the original features are converted into label results for fusion, effectively solving the problem of feature heterogeneity. Experiments on million song dataset show that the audio classification accuracy of the multifeature combined network classifier in this paper reaches 68%, and the lyrics classification accuracy reaches 74%. The average classification accuracy of the multimodal reaches 78%, which is significantly improved compared with the single-modal.
C1 [Chen, Changfeng; Li, Qiang] Hangzhou Danzi Univ, Inst Intelligent & Software Technol, Hangzhou 310018, Peoples R China.
RP Li, Q (corresponding author), Hangzhou Danzi Univ, Inst Intelligent & Software Technol, Hangzhou 310018, Peoples R China.
EM 171050003@hdu.edu.cn; hzlee@hdu.edu.cn
CR An YJ, 2017, 2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS 2017), P635
   Chand N, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATION AND AUTOMATION (ICACCA 2016), P40, DOI 10.1109/ICACCA.2016.7578859
   Chen SH, 2015, ASIAPAC SIGN INFO PR, P495, DOI 10.1109/APSIPA.2015.7415321
   Chen XT, 2018, PROCEEDINGS OF 2018 10TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING (ICMLC 2018), P85, DOI 10.1145/3195106.3195148
   He H., 2009, PAC AS C KNOWL DISC
   Hwang FC, 2013, 1ST INTERNATIONAL CONFERENCE ON ORANGE TECHNOLOGIES (ICOT 2013), P282, DOI 10.1109/ICOT.2013.6521213
   Jokinen E, 2019, COMPUT SPEECH LANG, V53, P1, DOI 10.1016/j.csl.2018.06.002
   Kim JW, 2018, INTERSPEECH, P937, DOI 10.21437/Interspeech.2018-1132
   Lin YC, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2037676.2037683
   Liu G, 2019, NEUROCOMPUTING, V337, P325, DOI 10.1016/j.neucom.2019.01.078
   Mei-Hui Wang, 2018, 2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC). Proceedings, P4254, DOI 10.1109/SMC.2018.00720
   Mihalcea Rada, 2012, P 2012 JOINT C EMPIR, P590
   Panda R., 2013, P INT S COMP MUS MUL, DOI [10.1109/ICASSP.2013.66382982-s2.0-84890486138, DOI 10.1109/ICASSP.2013.66382982-S2.0-84890486138]
   Rachman F.H., 2018, INT J ELECT COMPUTER, V8, P1720, DOI 10.11591/ijece.v8i3.pp1720-1730
   Ramani RG, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.5065
   Reddy G. R. R., 2018, ADDITION CODE MIXED
   Satt A, 2017, INTERSPEECH, P1089, DOI 10.21437/Interspeech.2017-200
   SEO YS, 2019, ELECTRONICS, V0008, DOI DOI 10.3390/ELECTRONICS80201642-S2.0-85063304013
   Shahana PH, 2015, PROCEDIA COMPUT SCI, V46, P1585, DOI 10.1016/j.procs.2015.02.088
   Shi WL, 2018, PROCEEDINGS OF 2018 IEEE 3RD ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC 2018), P1154, DOI 10.1109/IAEAC.2018.8577944
   Su D, 2013, INT CONF ACOUST SPEE, P3447, DOI 10.1109/ICASSP.2013.6638298
   Su F, 2017, LECT NOTES COMPUT SC, V10132, P152, DOI 10.1007/978-3-319-51811-4_13
   Wang CX, 2002, BMC NEUROL, V2, DOI 10.1186/1471-2377-2-2
   Wang J., 2019, DEEP LEARNING BASED
   Wang R., 2019, 2019 IEEE 20th International Workshop on Signal Processing Advances in Wireless Communications, P1
   Yaxin W., 2018, PERSONAL MUSIC EMOTI
   Zhang JL, 2017, MULTIMEDIA SYST, V23, P251, DOI 10.1007/s00530-015-0489-y
   Zhao W, 2018, PROCEEDINGS OF 2018 IEEE 3RD ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC 2018), P2596, DOI 10.1109/IAEAC.2018.8577272
   Zheng J, 2019, IEEE ACCESS, V7, P106673, DOI 10.1109/ACCESS.2019.2932619
NR 29
TC 19
Z9 19
U1 6
U2 18
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1024-123X
EI 1563-5147
J9 MATH PROBL ENG
JI Math. Probl. Eng.
PD AUG 1
PY 2020
VL 2020
AR 4606027
DI 10.1155/2020/4606027
PG 11
WC Engineering, Multidisciplinary; Mathematics, Interdisciplinary
   Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Mathematics
GA NC5GC
UT WOS:000561241900005
OA gold
DA 2024-01-09
ER

PT J
AU Sun, B
AF Sun, Bo
TI Emotional Analysis and Personalized Recommendation Analysis in Music
   Performance
SO SCIENTIFIC PROGRAMMING
LA English
DT Article
AB Music performance belongs to music recreation activities, is through singing, musical instrument performance, and vocal conductor, including a variety of artistic means, to convey music to the audience with real sound effects that can be felt, and can play its social function. Emotional state is a part of the whole attitude, which is consistent with introverted feelings and intentions in attitude, and is a complex and stable physiological evaluation and experience of attitude in physiology. This paper first introduces the concepts of music performance from the perspective of music appreciation and music ability. Then based on the emotional feature learning of matrix factorization constrained nonnegative matrix factorization and model optimization algorithm are used to analyze the emotional aspects of music. Finally, through the experimental comparison of the difficulty of emotion in various artistic creations, a conclusion is drawn. The research involves matrix decomposition, mathematical modeling, model optimization, digital audio technology application, and other fields. In the third part of this paper, the constrained nonnegative matrix factorization, the constrained nonnegative matrix factorization with external information, and the model optimization algorithm are used to study the mathematical modeling.
C1 [Sun, Bo] Bo SunHunan City Univ, Yiyang 413000, Hunan, Peoples R China.
RP Sun, B (corresponding author), Bo SunHunan City Univ, Yiyang 413000, Hunan, Peoples R China.
EM sunbo@hncu.edu.cn
CR Egner T, 2003, NEUROREPORT, V14, P1221, DOI 10.1097/00001756-200307010-00006
   Gu Y., 2018, MULTIMODAL AFFECTIVE, V23, P156, DOI [10.18653/v1/p18-1207, DOI 10.18653/V1/P18-1207]
   Hunt A., 2000, INTERPRETATION SPACE, V12, P34
   Kallipolitis A, 2020, NEURAL COMPUT APPL, V32, P17125, DOI 10.1007/s00521-020-05203-z
   Kim HR, 2008, APPL INTELL, V28, P153, DOI 10.1007/s10489-007-0056-0
   Limb CJ, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0001679
   Lozano R, 2012, LANCET, V380, P2095, DOI 10.1016/S0140-6736(12)61728-0
   Moher D, 2010, INT J SURG, V8, P336, DOI [10.1016/j.ijsu.2010.02.007, DOI 10.1016/J.IJSU.2010.02.007]
   PALMER C, 1989, J EXP PSYCHOL HUMAN, V15, P331, DOI 10.1037/0096-1523.15.2.331
   Pang L, 2015, IEEE T MULTIMEDIA, V17, P2008, DOI 10.1109/TMM.2015.2482228
   Riecken D, 2000, COMMUN ACM, V43, P27
   Roberto B., 2006, ADV COGN PSYCHOL, V2, P145
   Subramanian A, 2005, P NATL ACAD SCI USA, V102, P15545, DOI 10.1073/pnas.0506580102
   Wolf KE, 2019, J MULTIMODAL USER IN, V13, P245, DOI 10.1007/s12193-019-00294-y
   Zeng Chun, 2002, Journal of Software, V13, P1952
NR 15
TC 2
Z9 2
U1 0
U2 4
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1058-9244
EI 1875-919X
J9 SCI PROGRAMMING-NETH
JI Sci. Program.
PD APR 23
PY 2022
VL 2022
AR 9548486
DI 10.1155/2022/9548486
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1C8QP
UT WOS:000793377800002
OA gold
DA 2024-01-09
ER

PT J
AU Hogle, LA
AF Hogle, Lauri A.
TI Fostering singing agency through emotional differentiation in an
   inclusive singing environment
SO RESEARCH STUDIES IN MUSIC EDUCATION
LA English
DT Article
DE agency; choral; differentiated instruction; emotion; inclusion; music
   education; qualitative; shame; singing agency; social constructivism;
   Universal Design for Learning
ID EMBRACING 2 AESTHETICS; TONE-DEAFNESS; SOCIAL ANXIETY; EMBARRASSMENT;
   SINGER; SHAME; MYTH; FEAR
AB The purpose of this phenomenological study was to gain insight into experiences of adults who expressed personal discomfort with singing, either alone or when others might hear them. Singing agency in music learning, one's belief in one's own capacity to sing aloud, served as the guiding lens for the study. Narrative analysis of interview data, from 15 adults who self-identified as non-singers, provided understanding of experiences that they believed undermined their capacity for singing agency. Four initial themes emerged as participants described wounding incidents with resultant perceptions of deficit, disability, and shame; personal strategies to enhance or protect singing agency; perceived obstacles to singing agency; and personal definitions of good singing. Findings describe vocal skill development through emotional differentiation, linking singing agency with principles that underlie a social constructivist approach to music learning and teaching and a Universal Design for Learning.
C1 [Hogle, Lauri A.] Oakland Univ, Mus Educ Fac, Mus Educ, Rochester, MI 48309 USA.
C3 Oakland University
RP Hogle, LA (corresponding author), Oakland Univ, Sch Mus Theatre & Dance, 371 Varner Dr, Rochester, MI 48309 USA.
EM laurihogle@oakland.edu
OI Hogle, Lauri/0000-0001-7895-7206
CR Anderson P. A., 1978, SIGN LANGUAGE STUDIE, V19, P155, DOI [10.1353/sls.1978.0003, DOI 10.1353/SLS.1978.0003]
   [Anonymous], 2003, CHORAL CONDUCTING PH
   [Anonymous], 2007, Music Education Research, DOI DOI 10.1080/14613800601127494
   [Anonymous], 2003, RES STUD MUSIC EDUC, DOI DOI 10.1177/1321103X030200010501
   Baker S., 2012, Youth Studies Australia, V31, P25
   BANDURA A, 1989, AM PSYCHOL, V44, P1175, DOI 10.1037/0003-066X.44.9.1175
   Barefield R., 2012, MUSIC EDUC J, V98, P60, DOI [10. 1177/0027432111434588 ., DOI 10.1177/0027432111434588]
   Brinkmann S., 2015, InterViews: Learning the craft of qualitative research interviewing
   Brouwer AM, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00224
   Brown B, 2006, FAM SOC, V87, P43, DOI 10.1606/1044-3894.3483
   Brown B., 2017, RISING STRONG
   Carver C.S., 1998, On the self-regulation of behavior
   Casals A, 2011, BRIT J MUSIC EDUC, V28, P247, DOI 10.1017/S0265051711000192
   Center for Applied Special Technology, 2018, UN DES LEARN GUID VE
   Chen V, 2008, COGNITION EMOTION, V22, P21, DOI 10.1080/02699930701273815
   Clandinin D. J., 2000, Narrative inquiry: Experience and story in qualitative research
   Crawford R, 2019, INT J MUSIC EDUC, V37, P454, DOI 10.1177/0255761419830151
   Cuddy LL, 2005, ANN NY ACAD SCI, V1060, P311, DOI 10.1196/annals.1360.026
   Demorest SM, 2015, MUSIC PERCEPT, V32, P266, DOI 10.1525/MP.2015.32.3.266
   Denzin N. K., 2000, Handbook of Qualitative Research
   Drew R., 2001, KARAOKE NIGHTS
   Drummond PD, 2012, COGNITION EMOTION, V26, P561, DOI 10.1080/02699931.2011.595775
   Freer P. K., 2018, CHORAL J, V59, P49
   Fuelberth R., 2017, MUSIC EDUC J, V104, P38, DOI DOI 10.1177/0027432117735875
   Giddens S. R., 2006, STUDIES POPULAR CULT, V28, P93
   Gower L, 2012, BRIT J MUSIC EDUC, V29, P91, DOI 10.1017/S0265051711000398
   Harris CR, 2006, AM SCI, V94, P524, DOI 10.1511/2006.62.1009
   Hendricks K.S., 2016, UPDATE APPL RES MUSI, V35, P32, DOI DOI 10.1177/8755123315576535
   Hofmann SG, 2006, INT J PSYCHOPHYSIOL, V61, P134, DOI 10.1016/j.ijpsycho.2005.09.003
   Hogle L. A., 2018, THESIS
   Hogle LA, 2018, B COUN RES MUSIC ED, P7, DOI 10.5406/bulcouresmusedu.218.0007
   Hoover M, 2005, PHILOS MUSIC EDUC RE, V13, P202
   Kgatie M. S., 2019, VERBUM ECCLESIA, V40, DOI 10.4102/ve.v40i1.1910
   Knight S., 1999, PHENOMENON SINGING, P144
   Kvale S., 1996, InterViews: An introduction to qualitative research interviewing
   Leary MR, 1996, J PERS, V64, P619, DOI 10.1111/j.1467-6494.1996.tb00524.x
   Martens W, 2005, J THEOR SOC BEHAV, V35, P399, DOI 10.1111/j.1468-5914.2005.00283.x
   McGregor HA, 2005, PERS SOC PSYCHOL B, V31, P218, DOI 10.1177/0146167204271420
   Mishler E. G., 1986, Research interviewing: Context and narratives
   Mitchell P. A., 1991, PSYCHOL MUSIC, V19, P74
   Mullen J., 2019, ACTION CRITICISM THE, V18, P44, DOI DOI 10.22176/ACT18.1.44
   Nakata T., 2011, EUROPEAN J SOCIAL BE, V21, P45
   Palmer P., 1993, To Know As We Are Known: A Spirituality of Education
   Paney A. S., 2015, Update: Applications of Research in Music Education, V34, P42, DOI DOI 10.1177/8755123314548047
   Pascale LM, 2005, PHILOS MUSIC EDUC RE, V13, P165, DOI 10.2979/PME.2005.13.2.165
   Patton M. Q., 2002, Qualitative Research & Evaluation Methods, V3rd ed.
   Reimer B., 2007, MUSIC ED RES INT, V1, P1
   Rogoff Barbara, 1990, Apprenticeships in thinking: cognitive development in social context
   Ruddock E, 2012, RES STUD MUSIC EDUC, V34, P207, DOI 10.1177/1321103X12461747
   Ruismaki H., 2013, EUR J SOC BEHAV SCI, V7, P1222, DOI DOI 10.15405/EJSBS.102
   Rullo J. M., 2016, USITC PUBL
   Sabini J, 2001, PERS SOC PSYCHOL B, V27, P104, DOI 10.1177/0146167201271009
   Saldana J., 2021, The coding manual for qualitative researchers, V2nd ed.
   Salvador K., 2019, MUSIC EDUC J, V105, P59, DOI DOI 10.1177/0027432119846841
   Salwen N., 2016, FEAR SINGING BREAKTH
   Sandelowski M., 2008, The SAGE encyclopedia of qualitative research methods, DOI [10.4135/9781412963909.n257, DOI 10.4135/9781412963909.N257]
   Seidman I., 2006, Interviewing as Qualitative Research: A Guide for Researchers in Education and the Social Sciences
   Singer E, 2005, J LEARN DISABIL-US, V38, P411, DOI 10.1177/00222194050380050401
   Sloboda JA, 2005, ANN NY ACAD SCI, V1060, P255, DOI 10.1196/annals.1360.018
   Smith JA., 2003, The sage handbook of qualitative research in psychology, P51, DOI [DOI 10.4135/9781848607927, DOI 10.1037/13620-005]
   Sweet B, 2018, J RES MUSIC EDUC, V66, P133, DOI 10.1177/0022429418763790
   Tomlinson C.A., 2010, Leading and Managing a Differentiated Classroom
   Turino T., 2008, MUSIC SOCIAL LIFE PO
   Turoy AKW, 2018, BRIT J MUSIC EDUC, V35, P91, DOI 10.1017/S026505171700016X
   Turton A, 2002, British Journal of Music Education, V19, P31
   van Manen M., 2015, Researching lived experience
   Vygotsky L. S., 1994, The Vygotsky reader, P338
   Wagner M. J., 1993, MUSIC EDUC J, V79, P44
   Welch G. F., 2017, OXFORD HDB MUSICAL I, P543
   West S., 2009, MUSICAL UNDERSTANDIN, P212
   WHIDDEN C., 2008, GEMS GENDER ED MUSIC, V4, P1
   Wiggins J., 2015, Teaching for musical understanding
   Wiggins J., 2016, The child as musician: A handbook of musical development, V2nd, P102
   Wise KJ, 2008, MUSIC SCI, V12, P3, DOI 10.1177/102986490801200102
   Zimmerman B. J., 2006, Adolescence and education, P45
NR 75
TC 6
Z9 9
U1 1
U2 4
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1321-103X
EI 1834-5530
J9 RES STUD MUSIC EDUC
JI Res. Stud. Music Educ.
PD JUL
PY 2021
VL 43
IS 2
BP 179
EP 194
AR 1321103X20930426
DI 10.1177/1321103X20930426
EA AUG 2020
PG 16
WC Music
WE Emerging Sources Citation Index (ESCI)
SC Music
GA TE4FR
UT WOS:000562793600001
DA 2024-01-09
ER

PT J
AU Bullack, A
   Büdenbender, N
   Roden, I
   Kreutz, G
AF Bullack, Antje
   Buedenbender, Niklas
   Roden, Ingo
   Kreutz, Gunter
TI PSYCHOPHYSIOLOGICAL RESPONSES TO "HAPPY'' AND "SAD'' MUSIC: A
   REPLICATION STUDY
SO MUSIC PERCEPTION
LA English
DT Article
DE music listening; psychophysiology; auto-nomic activity; emotions;
   replication study
ID AUTONOMIC NERVOUS-SYSTEM; EMOTIONAL RESPONSES; SEX-DIFFERENCES;
   PHYSIOLOGICAL-RESPONSES; GENDER-DIFFERENCES; FACIAL REACTIONS;
   EXPERIENCE; PERCEPTION; EXPERTISE; EXPOSURE
AB LUNDQVIST, CARLSSON, HILMERSSON, AND JUSLIN (2009) presented evidence of differential autonomic emotional responses to "happy'' and "sad'' music in healthy adult listeners. The present study sought to replicate and extend these findings by employing a similar research design and measurement instruments. Therefore, we used instrumental film music instead of vocal music, and assessed listeners' music expertise. The present results show similarities and differences in patterns of psychological and physiological responses as compared to the previous work. Happy music evoked more happiness, higher skin conductance level, higher respiratory rate, and more zygomatic facial muscle activity than sad music, whereas sad music generated higher corrugator muscle activity than happy music. Influences of music sophistication as well as of sex were negligible. Taken together, these results further support the hypothesis that music induces differential autonomic emotional responses in healthy listeners. They also highlight the importance of replication or multi-site studies to strengthen the empirical basis of fundamental issues in music psychological research.
C1 [Bullack, Antje; Buedenbender, Niklas; Roden, Ingo; Kreutz, Gunter] Carl von Ossietzky Univ Oldenburg, Oldenburg, Germany.
C3 Carl von Ossietzky Universitat Oldenburg
RP Bullack, A (corresponding author), Carl von Ossietzky Univ Oldenburg, Dept Mus, Ammerlander Heerstr 114-118, D-26111 Oldenburg, Germany.; Kreutz, G (corresponding author), Dept Mus, Ammerlander Heerstr 114-118, D-26111 Oldenburg, Germany.
EM antje.bullack@uni-oldenburg.de; gunter.kreutz@uni-oldenburg.de
RI Kreutz, Gunter/J-1451-2019
OI Kreutz, Gunter/0000-0001-9586-241X; Roden, Ingo/0000-0002-5691-793X
CR Aarts AA, 2015, SCIENCE, V349, DOI 10.1126/science.aac4716
   Ali SO., 2006, Psychology of Music, V34, P511, DOI DOI 10.1177/0305735606067168
   Altenmüller E, 2002, NEUROPSYCHOLOGIA, V40, P2242, DOI 10.1016/S0028-3932(02)00107-0
   Anderson CA, 2003, J PERS SOC PSYCHOL, V84, P960, DOI 10.1037/0022-3514.84.5.960
   [Anonymous], 1993, DIFFERENTIELLE AFFEK
   Argstatter H, 2016, PSYCHOL MUSIC, V44, P674, DOI 10.1177/0305735615589214
   Bartlett D. L., 1996, HDB MUSIC PSYCHOL, P343
   Baumgartner T, 2006, INT J PSYCHOPHYSIOL, V60, P34, DOI 10.1016/j.ijpsycho.2005.04.007
   Bernardi L, 2006, HEART, V92, P445, DOI 10.1136/hrt.2005.064600
   Bernardi L, 2009, CIRCULATION, V119, P3171, DOI 10.1161/CIRCULATIONAHA.108.806174
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Bigand E, 2006, COGNITION, V100, P100, DOI 10.1016/j.cognition.2005.11.007
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Bradley MM, 2000, PSYCHOPHYSIOLOGY, V37, P204, DOI 10.1111/1469-8986.3720204
   Cohen AJ., 2011, MUSIC EMOTION THEORY, P1099, DOI [DOI 10.1093/ACPROF:OSO/9780199230143.003.0031, 10.1093/acprof:oso/9780199230143.003.0031]
   Craig DG, 2005, MUSIC SCI, V9, P273, DOI 10.1177/102986490500900207
   Dawson M. E., 2016, Cambridge Handbooks in Psychology, V4th, P217, DOI DOI 10.1017/9781107415782.010
   DIMBERG U, 1990, SCAND J PSYCHOL, V31, P228, DOI 10.1111/j.1467-9450.1990.tb00835.x
   DIMBERG U, 1990, BIOL PSYCHOL, V30, P151, DOI 10.1016/0301-0511(90)90024-Q
   DIMBERG U, 1990, PSYCHOPHYSIOLOGY, V27, P481, DOI 10.1111/j.1469-8986.1990.tb01962.x
   Eerola T, 2011, J NEW MUSIC RES, V40, P349, DOI 10.1080/09298215.2011.602195
   EKMAN P, 1981, PSYCHOPHYSIOLOGY, V18, P101, DOI 10.1111/j.1469-8986.1981.tb02919.x
   EKMAN P, 1983, SCIENCE, V221, P1208, DOI 10.1126/science.6612338
   ELLIS DS, 1952, AM J PSYCHOL, V65, P39, DOI 10.2307/1418826
   Ellis RJ., 2005, Psychomusicology, V19, P15, DOI [DOI 10.1037/H0094042, 10.1037/h0094042]
   Eschrich S, 2008, BMC NEUROSCI, V9, DOI 10.1186/1471-2202-9-48
   Etzel JA, 2006, INT J PSYCHOPHYSIOL, V61, P57, DOI 10.1016/j.ijpsycho.2005.10.025
   Evans P, 2008, MUSIC SCI, V12, P75, DOI 10.1177/102986490801200105
   FRIDLUND AJ, 1986, PSYCHOPHYSIOLOGY, V23, P567, DOI 10.1111/j.1469-8986.1986.tb00676.x
   Garrido S, 2011, MUSIC PERCEPT, V28, P279, DOI 10.1525/MP.2011.28.3.279
   Gomez P, 2004, INT J PSYCHOPHYSIOL, V53, P91, DOI 10.1016/j.ijpsycho.2004.02.002
   Gomez P, 2007, EMOTION, V7, P377, DOI 10.1037/1528-3542.7.2.377
   Grewe O, 2007, EMOTION, V7, P774, DOI 10.1037/1528-3542.7.4.774
   Hunter PG, 2008, COGNITION EMOTION, V22, P327, DOI 10.1080/02699930701438145
   Hunter PG, 2011, EMOTION, V11, P1068, DOI 10.1037/a0023749
   Hunter PG, 2010, PSYCHOL AESTHET CREA, V4, P47, DOI 10.1037/a0016873
   Iwanaga M, 1999, J MUSIC THER, V36, P26, DOI 10.1093/jmt/36.1.26
   Iwanaga M, 1996, J MUSIC THER, V33, P219, DOI 10.1093/jmt/33.3.219
   Izard C. E., 2013, Human emotions
   Juslin P. N., 2010, Handbook of music and emotion: Theory, research, applications, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0022
   Juslin PN, 2008, EMOTION, V8, P668, DOI 10.1037/a0013505
   Juslin PN, 2015, AM J PSYCHOL, V128, P281
   Juslin PN, 2014, PSYCHOL MUSIC, V42, P599, DOI 10.1177/0305735613484548
   Juslin PN, 1997, MUSIC PERCEPT, V14, P383
   Kallinen K., 2005, Psychology of Music, V33, P373, DOI DOI 10.1177/0305735605056147
   Kallinen K, 2006, MUSIC SCI, V10, P191, DOI 10.1177/102986490601000203
   Kamenetsky S.B., 1997, PSYCHOL MUSIC, V25, P149
   Kantor-Martynuska J, 2015, PSYCHOL AESTHET CREA, V9, P235, DOI 10.1037/a0039107
   Khalfa S, 2002, NEUROSCI LETT, V328, P145, DOI 10.1016/S0304-3940(02)00462-7
   Khalfa S, 2008, INT J PSYCHOPHYSIOL, V68, P17, DOI 10.1016/j.ijpsycho.2007.12.001
   Koelsch S, 2015, EUR HEART J, V36, P3043, DOI 10.1093/eurheartj/ehv430
   Kreutz G, 2002, MUSIC SCI, V6, P257, DOI 10.1177/102986490200600207
   Kreutz G, 2008, PSYCHOL MUSIC, V36, P101, DOI 10.1177/0305735607082623
   Kring AM, 1998, J PERS SOC PSYCHOL, V74, P686, DOI 10.1037/0022-3514.74.3.686
   Krumhansl CL, 1997, CAN J EXP PSYCHOL, V51, P336, DOI 10.1037/1196-1961.51.4.336
   Larsen JT, 2003, PSYCHOPHYSIOLOGY, V40, P776, DOI 10.1111/1469-8986.00078
   Levenson RW, 2014, EMOT REV, V6, P100, DOI 10.1177/1754073913512003
   Levenson RW, 2003, SER AFFECTIVE SCI, P212
   Liljeström S, 2013, PSYCHOL MUSIC, V41, P579, DOI 10.1177/0305735612440615
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Lundqvist LO, 2009, PSYCHOL MUSIC, V37, P61, DOI 10.1177/0305735607086048
   MCFARLAND RA, 1991, INT J PSYCHOPHYSIOL, V11, P295, DOI 10.1016/0167-8760(91)90024-R
   Mcrae K, 2008, GROUP PROCESS INTERG, V11, P143, DOI 10.1177/1368430207088035
   Mohn C, 2011, PSYCHOL MUSIC, V39, P503, DOI 10.1177/0305735610378183
   Müllensiefan D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089642
   Nater UM, 2006, INT J PSYCHOPHYSIOL, V62, P300, DOI 10.1016/j.ijpsycho.2006.05.011
   Nyklicek I, 1997, J PSYCHOPHYSIOL, V11, P304
   Rickard N. S., 2004, Psychology of Music, V32, P371, DOI [10.1177%2F0305735604046096, DOI 10.1177/0305735604046096, 10.1177/0305735604046096]
   ROBAZZA C, 1994, PERCEPT MOTOR SKILL, V79, P939, DOI 10.2466/pms.1994.79.2.939
   Schaal NK, 2014, MUSIC SCI, V18, P423, DOI 10.1177/1029864914541851
   Scherer K. R., 2001, MUSIC EMOTION THEORY, P361, DOI DOI 10.1080/0929821042000317822
   Schubert E., 2007, Psychology of Music, V35, P499, DOI [10.1177/0305735607072657, DOI 10.1177/0305735607072657]
   Swaminathan S, 2015, EMOT REV, V7, P189, DOI 10.1177/1754073914558282
   Taruffi L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0110490
   TASSINARY LG, 1989, PSYCHOPHYSIOLOGY, V26, P1, DOI 10.1111/j.1469-8986.1989.tb03125.x
   Thayer JF, 2001, ANN NY ACAD SCI, V930, P452, DOI 10.1111/j.1749-6632.2001.tb05768.x
   Trochidis K, 2013, LECT NOTES COMPUT SC, V7900, P44, DOI 10.1007/978-3-642-41248-6_3
   Verduyn P, 2011, EMOTION, V11, P20, DOI 10.1037/a0021239
   Verduyn P, 2009, EMOTION, V9, P83, DOI 10.1037/a0014610
   Vuoskoski JK, 2011, CORTEX, V47, P1099, DOI 10.1016/j.cortex.2011.04.011
   White EL, 2016, MUSIC SCI, V20, P11, DOI 10.1177/1029864915608911
   WITVLIET C. V. O, 1998, DISS ABSTR INT B, V58, P6832
   Witvliet CVO, 2007, COGNITION EMOTION, V21, P3, DOI 10.1080/02699930601000672
NR 83
TC 10
Z9 12
U1 4
U2 42
PU UNIV CALIFORNIA PRESS
PI OAKLAND
PA 155 GRAND AVE, SUITE 400, OAKLAND, CA 94612-3758 USA
SN 0730-7829
J9 MUSIC PERCEPT
JI Music Percept.
PD APR
PY 2018
VL 35
IS 4
BP 502
EP 517
DI 10.1525/MP.2018.35.4.502
PG 16
WC Music; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music; Psychology
GA GA9DT
UT WOS:000428642200006
DA 2024-01-09
ER

PT J
AU Speranza, L
   Pulcrano, S
   Perrone-Capano, C
   di Porzio, U
   Volpicelli, F
AF Speranza, Luisa
   Pulcrano, Salvatore
   Perrone-Capano, Carla
   di Porzio, Umberto
   Volpicelli, Floriana
TI Music affects functional brain connectivity and is effective in the
   treatment of neurological disorders
SO REVIEWS IN THE NEUROSCIENCES
LA English
DT Article
DE dopamine; mental disorders; music; serotonin; synaptic plasticity
ID MILD COGNITIVE IMPAIRMENT; DANCE-BASED REHABILITATION;
   ALZHEIMERS-DISEASE; NUCLEUS-ACCUMBENS; STRUCTURAL MRI; THERAPY; REWARD;
   STROKE; MEMORY; VOLUME
AB In a million years, under the pressure of natural selection, hominins have acquired the abilities for vocal learning, music, and language. Music is a relevant human activity, highly effective in enhancing sociality, is a universal experience common to all known human cultures, although it varies in rhythmic and melodic complexity. It has been part of human life since the beginning of our history, or almost, and it strengthens the mother-baby relation even within the mother's womb. Music engages multiple cognitive functions, and promotes attention, concentration, imagination, creativity, elicits memories and emotions, and stimulates imagination, and harmony of movement. It changes the chemistry of the brain, by inducing the release of neurotransmitters and hormones (dopamine, serotonin, and oxytocin) and activates the reward and prosocial systems. In addition, music is also used to develop new therapies necessary to alleviate severe illness, especially neurological disorders, and brain injuries.
C1 [Pulcrano, Salvatore; Perrone-Capano, Carla; di Porzio, Umberto] CNR, Inst Genet & Biophys Adriano Buzzati Traverso, Via P Castellino 111, I-80131 Naples, Italy.
   [Pulcrano, Salvatore; Perrone-Capano, Carla; Volpicelli, Floriana] Univ Naples Federico II, Sch Med & Surg, Dept Pharm, I-80131 Naples, Italy.
   [Speranza, Luisa] Albert Einstein Coll Med, Dept Neurosci, New York, NY 10461 USA.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Genetica e
   Biofisica "Adriano Buzzati-Traverso" (IGB-CNR); University of Naples
   Federico II; Yeshiva University
RP Pulcrano, S (corresponding author), CNR, Inst Genet & Biophys Adriano Buzzati Traverso, Via P Castellino 111, I-80131 Naples, Italy.; Pulcrano, S (corresponding author), Univ Naples Federico II, Sch Med & Surg, Dept Pharm, I-80131 Naples, Italy.
EM luisa.speranza@einsteinmed.edu; salvatore.pulcrano@igb.cnr.it;
   perrone@unina.it; diporzio@igb.cnr.it; floriana.volpicelli@unina.it
OI Pulcrano, Salvatore/0000-0002-5324-8689; Volpicelli,
   Floriana/0000-0003-0618-5504
FU POR Campania FESR 2014/2020 from Regione Campania, Italy
   [B61G18000470007];  [000005_2018_ RARE.PLAT.NET
   000005_BUDGET_ECONOMICO_RICERCA_2020]
FX This work was supported by "POR Campania FESR 2014/2020" (Project N.
   B61G18000470007) from Regione Campania, Italy, Progetto 000005_2018_
   RARE.PLAT.NET and 000005_BUDGET_ECONOMICO_RICERCA_2020.
CR Allen JL, 2017, J NEUROPHYSIOL, V118, P363, DOI 10.1152/jn.00813.2016
   Altenmller E., 2017, ENEUROFORUM, V23, P57, DOI DOI 10.1515/NF-2016-A054
   Altenmller E., 2020, MUSIC AGING BRAIN, P407, DOI DOI 10.1016/B978-0-12-817422-7.00016-X
   Amengual JL, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0061883
   Amunts K, 1997, HUM BRAIN MAPP, V5, P206, DOI 10.1002/(SICI)1097-0193(1997)5:3<206::AID-HBM5>3.0.CO;2-7
   [Anonymous], 2018, Neuroplasticity: Insights of Neural Reorganization
   Azam S, 2021, FRONT CELL DEV BIOL, V09, DOI 10.3389/fcell.2021.683459
   Baird A, 2018, J ALZHEIMERS DIS, V61, P827, DOI 10.3233/JAD-170737
   Baker LD, 2010, ARCH NEUROL-CHICAGO, V67, P71, DOI 10.1001/archneurol.2009.307
   Balbag M Alison, 2014, Int J Alzheimers Dis, V2014, P836748, DOI 10.1155/2014/836748
   Bangerter A, 2004, BRIT J SOC PSYCHOL, V43, P605, DOI 10.1348/0144666042565353
   BARRETT FS, 2018, CEREB CORTEX, V28, P3939, DOI [DOI 10.1093/CERCOR/BHX257, 10.1093/cercor/bhx257]
   Batson G, 2016, FRONT NEUROL, V7, DOI 10.3389/fneur.2016.00015
   Benz S, 2016, FRONT PSYCHOL, V6, DOI [10.3389/fpsyg.2015.02023, 10.3389/fpsyg.2075.02023]
   Bishop NA, 2010, NATURE, V464, P529, DOI 10.1038/nature08983
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Bugos JA, 2007, AGING MENT HEALTH, V11, P464, DOI 10.1080/13607860601086504
   Burns A, 2009, BMJ-BRIT MED J, V338, DOI 10.1136/bmj.b158
   Butzlaff R, 2000, J AESTHET EDUC, V34, P167, DOI 10.2307/3333642
   Chanda ML, 2013, TRENDS COGN SCI, V17, P179, DOI 10.1016/j.tics.2013.02.007
   Colucci-D'Amato L, 2020, INT J MOL SCI, V21, DOI 10.3390/ijms21207777
   Cortese MD, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00520
   Crispino M, 2020, INT J MOL SCI, V21, DOI 10.3390/ijms21020505
   Dalla Bella S, 2017, SCI REP-UK, V7, DOI 10.1038/srep42005
   Degé F, 2018, ANN NY ACAD SCI, V1423, P242, DOI 10.1111/nyas.13685
   Eisinger BE, 2018, CELL TISSUE RES, V371, P7, DOI 10.1007/s00441-017-2718-5
   ELBERT T, 1995, SCIENCE, V270, P305, DOI 10.1126/science.270.5234.305
   Evers S, 2000, EUR ARCH PSY CLIN N, V250, P144, DOI 10.1007/s004060070031
   Feduccia AA, 2008, BRAIN RES BULL, V77, P189, DOI 10.1016/j.brainresbull.2008.07.007
   Feigin VL, 2014, LANCET, V383, P245, DOI 10.1016/S0140-6736(13)61953-4
   Ferreri L, 2021, ANN NY ACAD SCI, V1502, P85, DOI 10.1111/nyas.14656
   Ferreri L, 2019, P NATL ACAD SCI USA, V116, P3793, DOI 10.1073/pnas.1811878116
   Fjell AM, 2010, REV NEUROSCIENCE, V21, P187, DOI 10.1515/revneuro.2010.21.3.187
   Forgeard M, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003566
   Frisoni GB, 2007, BRAIN, V130, P720, DOI 10.1093/brain/awl377
   Frisoni GB, 2010, NAT REV NEUROL, V6, P67, DOI 10.1038/nrneurol.2009.215
   García-Casares N, 2018, J AM MED DIR ASSOC, V19, P1054, DOI 10.1016/j.jamda.2018.09.025
   Gaser C, 2003, J NEUROSCI, V23, P9240
   Geretsegger M, 2014, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD004381.pub3
   Gómez-Gallego M, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18158067
   Gordon RL, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01777
   Grau-Sánchez J, 2020, NEUROSCI BIOBEHAV R, V112, P585, DOI 10.1016/j.neubiorev.2020.02.027
   Groussard M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0013225
   Guétin S, 2009, DEMENT GERIATR COGN, V28, P36, DOI 10.1159/000229024
   Guo X, 2021, HUM BRAIN MAPP, V42, P1359, DOI 10.1002/hbm.25298
   Haber SN., 2011, Neuroanatomy of reward: a view from the ventral striatum
   Han EY, 2018, J MOV DISORD, V11, P121, DOI 10.14802/jmd.17078
   Hansen NC, 2021, BEHAV BRAIN SCI, V44, DOI 10.1017/S0140525X20001235
   Harada CN, 2013, CLIN GERIATR MED, V29, P737, DOI 10.1016/j.cger.2013.07.002
   Hardy MW, 2013, FRONT INTEGR NEUROSC, V7, DOI 10.3389/fnint.2013.00019
   Hodges D.A., 2010, Handbook of Music and Emotion: Theory, Research, Applications, P279
   Hou LJ, 2017, FRONT AGING NEUROSCI, V9, DOI 10.3389/fnagi.2017.00358
   Hutchinson S, 2003, CEREB CORTEX, V13, P943, DOI 10.1093/cercor/13.9.943
   Jacobsen JH, 2015, BRAIN, V138, P2438, DOI 10.1093/brain/awv135
   James CE, 2008, NEUROIMAGE, V42, P1597, DOI 10.1016/j.neuroimage.2008.06.025
   James CE, 2020, BMC GERIATR, V20, DOI 10.1186/s12877-020-01761-y
   Jaschke AC, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0207265
   Jasemi M, 2016, INDIAN J PALLIAT CAR, V22, P455, DOI 10.4103/0973-1075.191823
   Katagiri J, 2009, J MUSIC THER, V46, P15, DOI 10.1093/jmt/46.1.15
   Kaup AR, 2011, J NEUROPSYCH CLIN N, V23, P6, DOI 10.1176/appi.neuropsych.23.1.6
   Keenan JP, 2001, NEUROIMAGE, V14, P1402, DOI 10.1006/nimg.2001.0925
   Keller SS, 2009, J ANTHROPOL SCI, V87, P127
   Kennelly J, 2000, J Pediatr Health Care, V14, P56, DOI 10.1016/S0891-5245(00)52709-6
   Köhler F, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00651
   Koelsch S, 2014, NAT REV NEUROSCI, V15, P170, DOI 10.1038/nrn3666
   Lappe C, 2008, J NEUROSCI, V28, P9632, DOI 10.1523/JNEUROSCI.2254-08.2008
   Leggieri M, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00132
   Li YF, 2020, J ADV NURS, V76, P1111, DOI 10.1111/jan.14313
   Lyu JH, 2018, J ALZHEIMERS DIS, V64, P1347, DOI 10.3233/JAD-180183
   Sotomayor MJM, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph182111618
   Maguire EA, 2006, HIPPOCAMPUS, V16, P1091, DOI 10.1002/hipo.20233
   Mallik A, 2017, SCI REP-UK, V7, DOI 10.1038/srep41952
   Martínez-Molina N, 2016, P NATL ACAD SCI USA, V113, pE7337, DOI 10.1073/pnas.1611211113
   Mas-Herrero E, 2018, NAT HUM BEHAV, V2, P27, DOI 10.1038/s41562-017-0241-z
   Mattson MP, 2018, CELL METAB, V27, P1176, DOI 10.1016/j.cmet.2018.05.011
   Mayer-Benarous H, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.643234
   McKay JL, 2016, J NEUROL PHYS THER, V40, P257, DOI 10.1097/NPT.0000000000000150
   Mithen S, 2006, CAMB ARCHAEOL J, V16, P97, DOI 10.1017/S0959774306000060
   Moraes MM, 2018, NEUROSCI LETT, V673, P73, DOI 10.1016/j.neulet.2018.02.058
   Müller KU, 2015, ADDICT BIOL, V20, P534, DOI 10.1111/adb.12136
   Nakafuku M, 2020, WIRES DEV BIOL, V9, DOI 10.1002/wdev.369
   Narme P, 2014, J ALZHEIMERS DIS, V38, P359, DOI 10.3233/JAD-130893
   Nys GMS, 2007, CEREBROVASC DIS, V23, P408, DOI 10.1159/000101464
   Oechslin MS, 2013, HIPPOCAMPUS, V23, P552, DOI 10.1002/hipo.22120
   Pasiali V, 2018, J MUSIC THER, V55, P280, DOI 10.1093/jmt/thy007
   Pereira APS, 2019, J GERIATR PSYCH NEUR, V32, P49, DOI 10.1177/0891988718819858
   Peretz I, 1996, J COGNITIVE NEUROSCI, V8, P481, DOI 10.1162/jocn.1996.8.6.481
   Perrone-Capano C, 2017, REV NEUROSCIENCE, V28, P235, DOI 10.1515/revneuro-2016-0046
   Preller KH, 2018, CURR TOP BEHAV NEURO, V36, P221, DOI 10.1007/7854_2016_459
   Quintin EM, 2019, FRONT NEURAL CIRCUIT, V13, DOI 10.3389/fncir.2019.00049
   Raz N, 2005, CEREB CORTEX, V15, P1676, DOI 10.1093/cercor/bhi044
   Reidy J, 2021, J PALLIAT MED, V24, P1603, DOI 10.1089/jpm.2020.0739
   Ribeiro FS, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.647473
   Ripollés P, 2016, BRAIN IMAGING BEHAV, V10, P1289, DOI 10.1007/s11682-015-9498-x
   Sala G, 2017, EDUC RES REV-NETH, V20, P55, DOI 10.1016/j.edurev.2016.11.005
   Salimpoor VN, 2013, SCIENCE, V340, P216, DOI 10.1126/science.1231059
   Salimpoor VN, 2011, NAT NEUROSCI, V14, P257, DOI 10.1038/nn.2726
   Salthouse TA, 2011, PSYCHOL BULL, V137, P753, DOI 10.1037/a0023262
   Samson S, 2005, ANN NY ACAD SCI, V1060, P419, DOI 10.1196/annals.1360.035
   Särkämö T, 2008, BRAIN, V131, P866, DOI 10.1093/brain/awn013
   Särkämö T, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00245
   Satoh M, 2015, DEMENT GER COGN D EX, V5, P296, DOI 10.1159/000436960
   Schellenberg EG, 2006, J EDUC PSYCHOL, V98, P457, DOI 10.1037/0022-0663.98.2.457
   SCHLAUG G, 1995, SCIENCE, V267, P699, DOI 10.1126/science.7839149
   Schlaug G, 2001, ANN NY ACAD SCI, V930, P281, DOI 10.1111/j.1749-6632.2001.tb05739.x
   Schlaug G, 2010, FUTUR NEUROL, V5, P657, DOI 10.2217/FNL.10.44
   Schneider P, 2005, NAT NEUROSCI, V8, P1241, DOI 10.1038/nn1530
   Seinfeld S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00810
   Sharma SR, 2018, PHARMACOL THERAPEUT, V190, P91, DOI 10.1016/j.pharmthera.2018.05.007
   Sihvonen AJ, 2021, ENEURO, V8, DOI 10.1523/ENEURO.0158-21.2021
   Sihvonen AJ, 2017, LANCET NEUROL, V16, P648, DOI 10.1016/S1474-4422(17)30168-0
   Singh V, 2006, BRAIN, V129, P2885, DOI 10.1093/brain/awl256
   Slavin D, 2018, AM J SPEECH-LANG PAT, V27, P1352, DOI 10.1044/2018_AJSLP-17-0030
   Sluming V, 2002, NEUROIMAGE, V17, P1613, DOI 10.1006/nimg.2002.1288
   Sowell ER, 2003, NAT NEUROSCI, V6, P309, DOI 10.1038/nn1008
   Speranza L, 2021, CELLS-BASEL, V10, DOI 10.3390/cells10040735
   Srinivasan SM, 2015, RES AUTISM SPECT DIS, V18, P51, DOI 10.1016/j.rasd.2015.07.004
   Standley J. M., 2008, Update: Applications of Research in Music Education, V27, P17, DOI [DOI 10.1177/8755123308322270, 10.1177/8755123308322270]
   Sutcliffe R, 2020, NEUROSCI BIOBEHAV R, V113, P479, DOI 10.1016/j.neubiorev.2020.03.026
   Tabei K, 2016, FRONT NEUROL, V7, DOI 10.3389/fneur.2016.00148
   Thompson PM, 2003, J NEUROSCI, V23, P994
   Tomchek SD, 2007, AM J OCCUP THER, V61, P190, DOI 10.5014/ajot.61.2.190
   Van Hoesen GW, 2000, CEREB CORTEX, V10, P243, DOI 10.1093/cercor/10.3.243
   Vanstone AD, 2010, AGING NEUROPSYCHOL C, V17, P108, DOI 10.1080/13825580903042676
   Villain N, 2012, BRAIN, V135, P2126, DOI 10.1093/brain/aws125
   Volpicelli F, 2020, INT J MOL SCI, V21, DOI 10.3390/ijms21113995
   Voss P, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01657
   Wan CY, 2014, BRAIN LANG, V136, P1, DOI 10.1016/j.bandl.2014.03.011
   Wan CY, 2010, NEUROSCIENTIST, V16, P566, DOI 10.1177/1073858410377805
   Whitall J, 2011, NEUROREHAB NEURAL RE, V25, P118, DOI 10.1177/1545968310380685
   Worschech F, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.696240
   Zald D. H., 2011, Music: Neurobiology of sensation and reward, P405
   Zhang YS, 2017, AGEING RES REV, V35, P1, DOI 10.1016/j.arr.2016.12.003
   Zhang YZ, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-17178-4
NR 134
TC 6
Z9 6
U1 8
U2 46
PU WALTER DE GRUYTER GMBH
PI BERLIN
PA GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY
SN 0334-1763
EI 2191-0200
J9 REV NEUROSCIENCE
JI Rev. Neurosci.
PD OCT 26
PY 2022
VL 33
IS 7
BP 789
EP 801
DI 10.1515/revneuro-2021-0135
EA MAR 2022
PG 13
WC Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Neurosciences & Neurology
GA 4W3LO
UT WOS:000772655000001
PM 35325516
DA 2024-01-09
ER

PT J
AU Ma, WY
   Zhou, P
   Thompson, WF
AF Ma, Weiyi
   Zhou, Peng
   Thompson, William Forde
TI Children's Decoding of Emotional Prosody in Four Languages
SO EMOTION
LA English
DT Article
DE prosody; emotional perception; child development; in-group advantage
ID INFANT-DIRECTED SPEECH; FACIAL EXPRESSIONS; VOCAL EXPRESSION;
   NONLINGUISTIC VOCALIZATIONS; CULTURAL-DIFFERENCES; RECOGNITION;
   PERCEPTION; MUSIC; COMMUNICATION; CUES
AB It is well established that adults can interpret emotional speech prosody independent of word meaning comprehension, even for emotional speech prosody in an unfamiliar language. However, the acquisition of this ability remains unclear. This study examined the decoding of four emotions (happy, sad, surprise, angry) conveyed with speech prosody in four languages (English, Chinese, French, Spanish) by American and Chinese children at 3 to 5 years of age-an age range when the ability to decode emotional prosody in one's native language emerges but remains fragile. Chinese and American children could decode the emotional meaning of speech prosody in both familiar and unfamiliar languages as young as 3 years old. Performance did not differ across the four languages used-a finding observed in both American and Chinese children. Thus, the in-group advantage of emotional prosody decoding reported for adults may not be evident by 5 years of age. Furthermore, emotional prosody decoding skills improved with age.
C1 [Ma, Weiyi] Univ Arkansas, Sch Human Environm Sci, Room 118,987 West Maple St, Fayetteville, AR 72701 USA.
   [Zhou, Peng] Tsinghua Univ, Dept Foreign Languages & Literatures, Beijing 100084, Peoples R China.
   [Thompson, William Forde] Macquarie Univ, Dept Psychol, Sydney, NSW, Australia.
C3 University of Arkansas System; University of Arkansas Fayetteville;
   Tsinghua University; Macquarie University
RP Ma, WY (corresponding author), Univ Arkansas, Sch Human Environm Sci, Room 118,987 West Maple St, Fayetteville, AR 72701 USA.
EM Weiyima@uark.edu
RI Zhou, Peng/C-8845-2018; Ma, Weiyi/T-4617-2017
OI Zhou, Peng/0000-0002-0818-2545; Ma, Weiyi/0000-0002-2299-9834; Thompson,
   William/0000-0002-4256-1338
FU University of Arkansas; Provost's Collaborative Research Grant; National
   Natural Science Grant [U20B2062]; National Natural Science Foundation of
   China; Australian Research Council [DP210101247]
FX This research was supported by The University of Arkansas Startup Fund
   and the Provost's Collaborative Research Grant awarded to Weiyi Ma, a
   National Natural Science Grant (U20B2062) awarded to Peng Zhou by
   National Natural Science Foundation of China, and a Discovery Project
   Grant (DP210101247) awarded to William Forde Thompson by the Australian
   Research Council.
CR Aguert M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0083657
   Aguert M, 2010, J SPEECH LANG HEAR R, V53, P1629, DOI 10.1044/1092-4388(2010/08-0078)
   Albin DD, 1996, INFANT BEHAV DEV, V19, P401, DOI 10.1016/S0163-6383(96)90002-8
   Allgood R, 2015, BRIT J DEV PSYCHOL, V33, P398, DOI 10.1111/bjdp.12097
   Amorim M, 2021, EMOTION, V21, P315, DOI 10.1037/emo0000692
   BALTAXE CAM, 1991, PERCEPT MOTOR SKILL, V72, P1187, DOI 10.2466/PMS.72.4.1187-1202
   BEIER EG, 1972, J CONSULT CLIN PSYCH, V39, P166, DOI 10.1037/h0033170
   Ben-David BM, 2011, BRAIN INJURY, V25, P206, DOI 10.3109/02699052.2010.536197
   Bennet-Clark HC, 1998, PHILOS T ROY SOC B, V353, P407, DOI 10.1098/rstb.1998.0219
   Benton M., 2007, P ICPHS, P1269
   Brooks PJ, 2013, RES AUTISM SPECT DIS, V7, P845, DOI 10.1016/j.rasd.2013.03.003
   Cheang HS, 2009, J ACOUST SOC AM, V126, P1394, DOI 10.1121/1.3177275
   Chevallier Coralie, 2012, J Autism Dev Disord, V42, P1504, DOI 10.1007/s10803-011-1364-0
   Chiew J., 2017, CLIN ARCH COMMUNICAT, V2, P128, DOI [10.21849/cacd.2017.00157, DOI 10.21849/CACD.2017.00157]
   Chronaki G, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-26889-1
   Chronaki G, 2015, BRIT J DEV PSYCHOL, V33, P218, DOI 10.1111/bjdp.12075
   COOPER RP, 1990, CHILD DEV, V61, P1584, DOI 10.2307/1130766
   Cordaro DT, 2018, EMOTION, V18, P75, DOI 10.1037/emo0000302
   Creel SC, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12503
   Crivelli C, 2016, P NATL ACAD SCI USA, V113, P12403, DOI 10.1073/pnas.1611622113
   Dahl A, 2016, J EXP CHILD PSYCHOL, V152, P71, DOI 10.1016/j.jecp.2016.07.009
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Darwin C., 1872, P374
   Darwin C., 1889, DESCENT MAN SELECTIO, V1, DOI 10.5962/bhl.title.106468
   Ekman P., 1972, Emotion in the Human Face
   Ekman P, 2016, PERSPECT PSYCHOL SCI, V11, P31, DOI 10.1177/1745691615596992
   Elfenbein HA, 2007, EMOTION, V7, P131, DOI 10.1037/1528-3542.7.1.131
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   FERNALD A, 1993, CHILD DEV, V64, P657, DOI 10.1111/j.1467-8624.1993.tb02934.x
   FERNALD A, 1985, INFANT BEHAV DEV, V8, P181, DOI 10.1016/S0163-6383(85)80005-9
   FERNALD A, 1984, DEV PSYCHOL, V20, P104, DOI 10.1037/0012-1649.20.1.104
   Flom R, 2007, DEV PSYCHOL, V43, P238, DOI 10.1037/0012-1649.43.1.238
   Fridenson-Hayo S, 2016, MOL AUTISM, V7, DOI 10.1186/s13229-016-0113-9
   Friend M, 2000, MERRILL PALMER QUART, V46, P342
   Friend Margaret, 2001, First Lang, V21, P219, DOI 10.1177/014272370102106302
   Friend M, 2000, DEVELOPMENTAL SCI, V3, P148, DOI 10.1111/1467-7687.00108
   Gil S, 2016, DEV PSYCHOL, V52, P1064, DOI 10.1037/dev0000121
   Gil S, 2014, INT J BEHAV DEV, V38, P539, DOI 10.1177/0165025414535123
   Gingras B, 2013, J ZOOL, V289, P143, DOI 10.1111/j.1469-7998.2012.00973.x
   Good A, 2017, EAR HEARING, V38, P455, DOI 10.1097/AUD.0000000000000402
   Grosbras MH, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32868-3
   Grossman RB, 2010, J SPEECH LANG HEAR R, V53, P778, DOI 10.1044/1092-4388(2009/08-0127)
   Grossmann T, 2006, DEVELOPMENTAL SCI, V9, P309, DOI 10.1111/j.1467-7687.2006.00494.x
   Grossmann T, 2010, NEURON, V65, P852, DOI 10.1016/j.neuron.2010.03.001
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   IZARD CE, 1994, PSYCHOL BULL, V115, P288, DOI 10.1037/0033-2909.115.2.288
   Jack RE, 2012, P NATL ACAD SCI USA, V109, P7241, DOI 10.1073/pnas.1200155109
   Javanbakht A, 2015, FRONT BEHAV NEUROSCI, V9, DOI 10.3389/fnbeh.2015.00154
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kahana-Kalman R, 2001, CHILD DEV, V72, P352, DOI 10.1111/1467-8624.00283
   KASTNER MP, 1990, MUSIC PERCEPT, V8, P189
   Kuhl PK, 1997, SCIENCE, V277, P684, DOI 10.1126/science.277.5326.684
   Laukka P, 2021, EMOT REV, V13, P3, DOI 10.1177/1754073919897295
   Laukka P, 2014, EMOTION, V14, P445, DOI 10.1037/a0036048
   Laval V, 2005, J SPEECH LANG HEAR R, V48, P610, DOI 10.1044/1092-4388(2005/042)
   Le Sourn-Bissaoui S, 2013, J COMMUN DISORD, V46, P309, DOI 10.1016/j.jcomdis.2013.03.002
   Lima CF, 2014, EMOTION, V14, P145, DOI 10.1037/a0034287
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Liu H., 2014, ENGLISH LANGUAGE TEA, V7, P1, DOI DOI 10.5539/ELT.V7N6P1
   Ma WY, 2020, Q J EXP PSYCHOL, V73, P1036, DOI 10.1177/1747021819888982
   Ma WY, 2019, COGENT PSYCHOL, V6, DOI 10.1080/23311908.2019.1690816
   Ma WY, 2019, SEMIOTICA, P1, DOI 10.1515/sem-2018-0139
   Ma Weiyi, 2017, [Journal of Electronic Science and Technology, 电子科技学刊(英文版)], V15, P25
   Ma WY, 2017, COGNITION, V159, P139, DOI 10.1016/j.cognition.2016.11.011
   Ma WY, 2015, P NATL ACAD SCI USA, V112, P14563, DOI 10.1073/pnas.1515087112
   Ma WY, 2011, LANG LEARN DEV, V7, P185, DOI 10.1080/15475441.2011.579839
   MACINTYRE PD, 1994, LANG LEARN, V44, P283, DOI 10.1111/j.1467-1770.1994.tb01103.x
   Marques C, 2007, J COGNITIVE NEUROSCI, V19, P1453, DOI 10.1162/jocn.2007.19.9.1453
   MARTEN K, 1977, BEHAV ECOL SOCIOBIOL, V2, P271, DOI 10.1007/BF00299740
   MATSUMOTO D, 1983, INT J INTERCULT REL, V7, P415, DOI 10.1016/0147-1767(83)90047-0
   MCCLUSKEY KW, 1975, DEV PSYCHOL, V11, P551, DOI 10.1037/0012-1649.11.5.551
   MCCLUSKEY KW, 1981, INT J PSYCHOL, V16, P119, DOI 10.1080/00207598108247409
   McRoberts GW, 1997, J CHILD LANG, V24, P719, DOI 10.1017/S030500099700322X
   MEHRABIAN A, 1968, PSYCHOL TODAY, V2, P53
   Merriman W. E., 1989, Monographs of the Society for Research in Child Development, V54, P1, DOI [10.2307/1166130, DOI 10.2307/1166130]
   Montague DPF, 2002, CHILD DEV, V73, P1339, DOI 10.1111/1467-8624.00475
   Morton JB, 2001, CHILD DEV, V72, P834, DOI 10.1111/1467-8624.00318
   Mote J, 2011, EMOTION, V11, P618, DOI 10.1037/a0022573
   Mumme DL, 1996, CHILD DEV, V67, P3219, DOI 10.2307/1131775
   Muscatell KA, 2012, NEUROIMAGE, V60, P1771, DOI 10.1016/j.neuroimage.2012.01.080
   Nagels L, 2020, PEERJ, V8, DOI 10.7717/peerj.8773
   Nawrot ES., 2003, Psychol. Music, V31, P75, DOI DOI 10.1177/0305735603031001325
   Nelson NL, 2011, J EXP CHILD PSYCHOL, V110, P52, DOI 10.1016/j.jecp.2011.03.014
   Palama A, 2022, EMOTION, V22, P725, DOI 10.1037/emo0000758
   Paulmann S, 2014, COGNITION EMOTION, V28, P230, DOI 10.1080/02699931.2013.812033
   Pell MD, 2015, BIOL PSYCHOL, V111, P14, DOI 10.1016/j.biopsycho.2015.08.008
   Pell MD, 2009, J NONVERBAL BEHAV, V33, P107, DOI 10.1007/s10919-008-0065-7
   Peppé S, 2007, J SPEECH LANG HEAR R, V50, P1015, DOI 10.1044/1092-4388(2007/071)
   Pinheiro AP, 2015, BRAIN LANG, V140, P24, DOI 10.1016/j.bandl.2014.10.009
   Quam C, 2012, CHILD DEV, V83, P236, DOI 10.1111/j.1467-8624.2011.01700.x
   Ross P, 2021, J EXP CHILD PSYCHOL, V204, DOI 10.1016/j.jecp.2020.105068
   Russell JA, 2003, ANNU REV PSYCHOL, V54, P329, DOI 10.1146/annurev.psych.54.101601.145102
   Saffran JR, 2018, ANNU REV PSYCHOL, V69, P181, DOI 10.1146/annurev-psych-122216-011805
   Sauter DA, 2013, BRIT J DEV PSYCHOL, V31, P97, DOI 10.1111/j.2044-835X.2012.02081.x
   Sauter DA, 2010, P NATL ACAD SCI USA, V107, P2408, DOI 10.1073/pnas.0908239106
   Scheerer NE, 2020, J ABNORM CHILD PSYCH, V48, P965, DOI 10.1007/s10802-020-00644-5
   Scherer KR, 2015, COMPUT SPEECH LANG, V29, P218, DOI 10.1016/j.csl.2013.10.002
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   Soken NH, 1999, CHILD DEV, V70, P1275, DOI 10.1111/1467-8624.00093
   Song YQ, 2020, J COMMUN DISORD, V88, DOI 10.1016/j.jcomdis.2020.106032
   STIFTER CA, 1986, J NONVERBAL BEHAV, V10, P255, DOI 10.1007/BF00987483
   Thompson WF, 2006, SEMIOTICA, V158, P407, DOI 10.1515/SEM.2006.017
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Thompson WF, 2012, P NATL ACAD SCI USA, V109, P19027, DOI 10.1073/pnas.1210344109
   Trainor LJ, 2000, PSYCHOL SCI, V11, P188, DOI 10.1111/1467-9280.00240
   Vaillant-Molina M, 2013, INFANCY, V18, pE97, DOI 10.1111/infa.12017
   Vaish A, 2004, DEVELOPMENTAL SCI, V7, P261, DOI 10.1111/j.1467-7687.2004.00344.x
   VANBEZOOIJEN R, 1983, J CROSS CULT PSYCHOL, V14, P387, DOI 10.1177/0022002183014004001
   Vidas D., 2018, MUSIC SCI, V1, DOI 10.1177/2059204318762650
   WALKER AS, 1982, J EXP CHILD PSYCHOL, V33, P514, DOI 10.1016/0022-0965(82)90063-7
   Wang JE, 2015, RES DEV DISABIL, V37, P162, DOI 10.1016/j.ridd.2014.11.013
   WERKER JF, 1994, INFANT BEHAV DEV, V17, P323, DOI 10.1016/0163-6383(94)90012-4
   Wierzbicka A., 1999, EMOTIONS LANGUAGES C, DOI [10.1017/CBO9780511521256, DOI 10.1017/CBO9780511521256]
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   Woodard K, 2021, AFFECT SCI, V2, P301, DOI 10.1007/s42761-021-00038-w
   Zhao C, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0212205
NR 116
TC 5
Z9 5
U1 7
U2 36
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 1528-3542
EI 1931-1516
J9 EMOTION
JI Emotion
PD FEB
PY 2022
VL 22
IS 1
BP 198
EP 212
DI 10.1037/emo0001054
EA JAN 2022
PG 15
WC Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA YS9SE
UT WOS:000740010300001
PM 35007119
DA 2024-01-09
ER

PT J
AU Harris, R
   Leenders, KL
   de Jong, BM
AF Harris, Robert
   Leenders, Klaus L.
   de Jong, Bauke M.
TI Speech dysprosody but no music 'dysprosody' in Parkinson's disease
SO BRAIN AND LANGUAGE
LA English
DT Article
DE Parkinson's disease; Gait; Music; Dysprosody; Singing; Improvisation
ID EMOTION RECOGNITION; PROSODIC CUES; GAIT; RHYTHM; DEFICITS; INDIVIDUALS;
   COMMUNICATION; PROGRESSION; PERCEPTION; DYSARTHRIA
AB Parkinson's disease is characterized not only by bradykinesia, rigidity, and tremor, but also by impairments of expressive and receptive linguistic prosody. The facilitating effect of music with a salient beat on patients' gait suggests that it might have a similar effect on vocal behavior, however it is currently unknown whether singing is affected by the disease. In the present study, fifteen Parkinson patients were compared with fifteen healthy controls during the singing of familiar melodies and improvised melodic continuations. While patients' speech could reliably be distinguished from that of healthy controls matched for age and gender, purely on the basis of aural perception, no significant differences in singing were observed, either in pitch, pitch range, pitch variability, and tempo, or in scale tone distribution, interval size or interval variability. The apparent dissociation of speech and singing in Parkinson's disease suggests that music could be used to facilitate expressive linguistic prosody. (C) 2016 The Authors. Published by Elsevier Inc.
C1 [Harris, Robert; Leenders, Klaus L.; de Jong, Bauke M.] Univ Groningen, Univ Med Ctr Groningen, Dept Neurol, POB 30-001, NL-9700 RB Groningen, Netherlands.
   [Harris, Robert] Hanze Univ Appl Sci, Prince Claus Conservatoire, Veemarktstr 76, NL-9724 GA Groningen, Netherlands.
C3 University of Groningen
RP Harris, R (corresponding author), Univ Med Ctr Groningen, Dept Neurol, POB 30-001, NL-9700 RB Groningen, Netherlands.
EM r.i.harris@pl.hanze.nl; b.m.de.jong@umcg.nl
OI de Jong, Bauke M./0000-0002-6568-5739; Leenders, Klaus
   Leonhard/0000-0002-9406-5512
CR Adams RA, 2013, BRAIN STRUCT FUNCT, V218, P611, DOI 10.1007/s00429-012-0475-5
   Adolphs R, 2002, CURR OPIN NEUROBIOL, V12, P169, DOI 10.1016/S0959-4388(02)00301-X
   ALEXANDER GE, 1986, ANNU REV NEUROSCI, V9, P357, DOI 10.1146/annurev.ne.09.030186.002041
   [Anonymous], 2004, P 8 INT C MUS PERC C
   Ariatti A, 2008, NEUROL SCI, V29, P219, DOI 10.1007/s10072-008-0971-9
   Bartels AL, 2009, CORTEX, V45, P915, DOI 10.1016/j.cortex.2008.11.010
   Benke T, 1998, BRAIN COGNITION, V38, P36, DOI 10.1006/brcg.1998.1013
   Benoit CE, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00494
   Bernatzky G, 2004, NEUROSCI LETT, V361, P4, DOI 10.1016/j.neulet.2003.12.022
   Biro D. P., 2014, P 4 INT WORKSH FOLK
   BLONDER LX, 1989, BRAIN LANG, V36, P193, DOI 10.1016/0093-934X(89)90061-8
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Cheang HS, 2007, J NEUROLINGUIST, V20, P221, DOI 10.1016/j.jneuroling.2006.07.001
   CHILDERS DG, 1991, J ACOUST SOC AM, V90, P1841, DOI 10.1121/1.401664
   Connolly BS, 2014, JAMA-J AM MED ASSOC, V311, P1670, DOI 10.1001/jama.2014.3654
   Dalla Bella S, 2015, ANN NY ACAD SCI, V1337, P77, DOI 10.1111/nyas.12651
   Dara C, 2008, BRAIN RES, V1188, P100, DOI 10.1016/j.brainres.2007.10.034
   DARKINS AW, 1988, BRAIN LANG, V34, P315, DOI 10.1016/0093-934X(88)90142-3
   de Bruin N, 2010, PARKINSONS DIS-US, V2010, DOI 10.4061/2010/483530
   FERNALD A, 1984, DEV PSYCHOL, V20, P104, DOI 10.1037/0012-1649.20.1.104
   Ferriero G, 2013, MOVEMENT DISORD, V28, P686, DOI 10.1002/mds.25440
   Fitch W. T., 2012, Language and music as cognitive systems, P73
   Ford MP, 2010, ARCH PHYS MED REHAB, V91, P1255, DOI 10.1016/j.apmr.2010.04.012
   Fox CM, 1997, Am J Speech Lang Pathol, V6, P85, DOI [10.1044/1058-0360.0602.85, DOI 10.1044/1058-0360.0602.85]
   Gamboa J, 1997, J VOICE, V11, P314, DOI 10.1016/S0892-1997(97)80010-0
   Goberman AM, 2005, J COMMUN DISORD, V38, P215, DOI 10.1016/j.jcomdis.2004.10.001
   Goetz CG, 2003, MOVEMENT DISORD, V18, P738, DOI 10.1002/mds.10473
   Grahn JA, 2007, J COGNITIVE NEUROSCI, V19, P893, DOI 10.1162/jocn.2007.19.5.893
   Grahn JA, 2009, CORTEX, V45, P54, DOI 10.1016/j.cortex.2008.01.005
   Gray HA, 2010, NEUROPSYCHOLOGY, V24, P176, DOI 10.1037/a0018104
   Hammer Oyvind, 2001, Palaeontologia Electronica, V4, pUnpaginated
   Hayashi A, 2006, PARKINSONISM RELAT D, V12, pS76, DOI 10.1016/j.parkreldis.2006.05.026
   HOEHN MM, 1967, NEUROLOGY, V17, P427, DOI 10.1212/WNL.17.5.427
   Holmes RJ, 2000, INT J LANG COMM DIS, V35, P407
   Honing H, 2012, ANN NY ACAD SCI, V1252, P85, DOI 10.1111/j.1749-6632.2011.06402.x
   Hove MJ, 2015, ANN NY ACAD SCI, V1337, P111, DOI 10.1111/nyas.12615
   Huber JE, 2012, AM J SPEECH-LANG PAT, V21, P368, DOI 10.1044/1058-0360(2012/11-0059)
   Ito N, 2000, INTEGRATED HUMAN BRA, P435
   Jankovic J, 2008, J NEUROL NEUROSUR PS, V79, P368, DOI 10.1136/jnnp.2007.131045
   Kempler D, 2002, BRAIN LANG, V80, P449, DOI 10.1006/brln.2001.2602
   Kotz SA, 2015, ANN NY ACAD SCI, V1337, P62, DOI 10.1111/nyas.12657
   Krumhansl C. L., 1990, COGNITIVE FDN MUSICA, V17
   Large EW, 2009, ANN NY ACAD SCI, V1169, P46, DOI 10.1111/j.1749-6632.2009.04550.x
   Lim I, 2005, CLIN REHABIL, V19, P695, DOI 10.1191/0269215505cr906oa
   Lima CF, 2013, J CLIN EXP NEUROPSYC, V35, P373, DOI 10.1080/13803395.2013.776518
   Ling LE, 2000, LANG SPEECH, V43, P377, DOI 10.1177/00238309000430040301
   Lloyd AJ, 1999, CORTEX, V35, P389, DOI 10.1016/S0010-9452(08)70807-4
   MacPherson MK, 2011, J SPEECH LANG HEAR R, V54, P19, DOI 10.1044/1092-4388(2010/09-0079)
   Madison G, 2006, MUSIC PERCEPT, V24, P201, DOI 10.1525/mp.2006.24.2.201
   McIntosh GC, 1997, J NEUROL NEUROSUR PS, V62, P22, DOI 10.1136/jnnp.62.1.22
   METTER EJ, 1986, J COMMUN DISORD, V19, P347, DOI 10.1016/0021-9924(86)90026-2
   Midi I, 2008, ACTA NEUROL SCAND, V117, P26, DOI 10.1111/j.1600-0404.2007.00965.x
   Mikos AE, 2009, CLIN NEUROPSYCHOL, V23, P805, DOI 10.1080/13854040802572434
   Monetta L, 2008, J NEUROPSYCHOL, V2, P415, DOI 10.1348/174866407X216675
   Patel AD, 2006, J ACOUST SOC AM, V119, P3034, DOI 10.1121/1.2179657
   Pell ID, 1996, CORTEX, V32, P693, DOI 10.1016/S0010-9452(96)80039-6
   Pell MD, 2003, COGN AFFECT BEHAV NE, V3, P275, DOI 10.3758/CABN.3.4.275
   Pell MD, 2008, LANG LINGUIST COMPAS, V2, P739, DOI 10.1111/j.1749-818x.2008.00074.x
   Pell MD, 2006, BRAIN LANG, V97, P123, DOI 10.1016/j.bandl.2005.08.010
   PITCAIRN TK, 1990, BRIT J DISORD COMMUN, V25, P85
   Rigaldie K., 2006, SPEECH PROSODY 2006
   Rubinstein TC, 2002, MOVEMENT DISORD, V17, P1148, DOI 10.1002/mds.10259
   Sapir S, 2014, J SPEECH LANG HEAR R, V57, P1330, DOI 10.1044/2014_JSLHR-S-13-0039
   Satoh M, 2008, EUR NEUROL, V60, P237, DOI 10.1159/000151699
   Schachner A, 2009, CURR BIOL, V19, P831, DOI 10.1016/j.cub.2009.03.061
   Schröder C, 2006, MOVEMENT DISORD, V21, P1774, DOI 10.1002/mds.21038
   Schröder C, 2010, J NEUROL SCI, V289, P32, DOI 10.1016/j.jns.2009.08.038
   SCOTT S, 1984, J NEUROL NEUROSUR PS, V47, P840, DOI 10.1136/jnnp.47.8.840
   Shute B., 2001, ED PSY CHOL OGY, V21, P493, DOI DOI 10.1080/01443410120090858
   Skodda S, 2008, MOVEMENT DISORD, V23, P985, DOI 10.1002/mds.21996
   Skodda S, 2009, MOVEMENT DISORD, V24, P716, DOI 10.1002/mds.22430
   Steinhauer K, 1999, NAT NEUROSCI, V2, P191, DOI 10.1038/5757
   Tanaka Y, 2011, FOLIA PHONIATR LOGO, V63, P223, DOI 10.1159/000322059
   Thaut MH, 1996, MOVEMENT DISORD, V11, P193, DOI 10.1002/mds.870110213
   van Tricht MJ, 2010, BRAIN COGNITION, V74, P58, DOI 10.1016/j.bandc.2010.06.005
   Ventura MI, 2012, NEUROPSYCHOLOGIA, V50, P1936, DOI 10.1016/j.neuropsychologia.2012.04.018
   Volpe D, 2013, BMC GERIATR, V13, DOI 10.1186/1471-2318-13-54
   Walsh B, 2012, MOVEMENT DISORD, V27, P843, DOI 10.1002/mds.24888
   Wennerstrom Ann, 2001, MUSIC EVERYDAY SPEEC
   YAMADORI A, 1977, J NEUROL NEUROSUR PS, V40, P221, DOI 10.1136/jnnp.40.3.221
   Yip JTH, 2003, MOVEMENT DISORD, V18, P1115, DOI 10.1002/mds.10497
   Zatorre R, 2005, NATURE, V434, P312, DOI 10.1038/434312a
   ZWIRNER P, 1991, J COMMUN DISORD, V24, P287, DOI 10.1016/0021-9924(91)90004-3
NR 83
TC 12
Z9 17
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0093-934X
EI 1090-2155
J9 BRAIN LANG
JI Brain Lang.
PD DEC
PY 2016
VL 163
BP 1
EP 9
DI 10.1016/j.bandl.2016.08.008
PG 9
WC Audiology & Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Audiology & Speech-Language Pathology; Linguistics; Neurosciences &
   Neurology; Psychology
GA EE8IF
UT WOS:000389868200001
PM 27618779
OA Green Published, hybrid
DA 2024-01-09
ER

PT J
AU Seidler, VJ
AF Seidler, Victor Jeleniewski
TI Sounds, sufferings, memories and emotions
SO EMPEDOCLES-EUROPEAN JOURNAL FOR THE PHILOSOPHY OF COMMUNICATION
LA English
DT Article
DE sound ethnography; gender in historiography; popular music; cultural
   memory; affect; transgenerational trauma; Shoah
AB Social researchers have long known that playing music to people can evoke memories of their pasts and bring people into a different relationship with themselves as the sounds move them to make connections with an earlier period in their lives. It has been discovered in patients with dementia that it could revive people to hear songs they have loved, which can help to bring them back from a state of inner withdrawal. Some researchers have given people portable music listening devices so that they can listen to music that evokes memories from particular moments that they might be willing to share as part of an oral history or ethnographic project. This is to invoke processes that we can acknowledge ourselves as we realize the very special relationship we seem to have with music from our teenage years - processes that have helped to shape a generational experience and sensibility. Hearing old tracks from the past can move us to make connections and can invoke emotions and feelings in us that we might not have felt for years. It can restore memories of times past as we feel the presence of the past through the mediation of the sounds. This article explores the significance of sound and voice memory for traumatic suffering in the form of an autoethnographic study of Amy Berg's documentary Janis: Little Girl Blue (2015), transgenerational trauma, sexual trauma, feminism, therapy and the truths of memory.
C1 [Seidler, Victor Jeleniewski] Goldsmiths Univ London New Cross, Dept Sociol, London SE14 6NW, England.
RP Seidler, VJ (corresponding author), Goldsmiths Univ London New Cross, Dept Sociol, London SE14 6NW, England.
EM v.seidler@gold.ac.uk
CR [Anonymous], 1982, Sister Outsider: Essays Speeches
   Berg A. J., 2015, JANICE LITTLE GIRL B
   Grosman T., 2020, NYL C LOND SCH EC MA
   Reddy WM, 1997, CURR ANTHROPOL, V38, P327, DOI 10.1086/204622
   Shone T., 2016, GUARDIAN WEEKEN 0312, P27
NR 5
TC 0
Z9 0
U1 2
U2 6
PU INTELLECT LTD
PI BRISTOL
PA THE MILL, PARNALL RD, BRISTOL, BS16 3JG, ENGLAND
SN 1757-1952
EI 1757-1960
J9 EMPEDOCLES
JI Empedocles
PD SEP 1
PY 2020
VL 11
IS 1
BP 7
EP 24
DI 10.1386/ejpc_00009_1
PG 18
WC Philosophy
WE Emerging Sources Citation Index (ESCI)
SC Philosophy
GA NV6YU
UT WOS:000574465100002
DA 2024-01-09
ER

PT J
AU Jiam, NT
   Limb, C
AF Jiam, Nicole T.
   Limb, Charles
TI Music perception and training for pediatric cochlear implant users
SO EXPERT REVIEW OF MEDICAL DEVICES
LA English
DT Review
DE Auditory system; cochlear implants; melody; music training; music
   perception; pediatric Cochlear implant users; pitch; rehabilitation;
   rhythm; timbre
ID HEARING PRESERVATION; DEAF-CHILDREN; ELECTRICAL-STIMULATION; SPEECH
   RECOGNITION; MELODY RECOGNITION; PITCH PERCEPTION; TONE RECOGNITION;
   NORMALLY HEARING; EMOTIONAL SPEECH; INSERTION DEPTH
AB Introduction
   Cochlear implants (CIs) are biomedical devices that restore sound perception for people with severe-to-profound sensorineural hearing loss. Most postlingually deafened CI users are able to achieve excellent speech recognition in quiet environments. However, current CI sound processors remain limited in their ability to deliver fine spectrotemporal information, making it difficult for CI users to perceive complex sounds. Limited access to complex acoustic cues such as music, environmental sounds, lexical tones, and voice emotion may have significant ramifications on quality of life, social development, and community interactions.
   Areas covered
   The purpose of this review article is to summarize the literature on CIs and music perception, with an emphasis on music training in pediatric CI recipients. The findings have implications on our understanding of noninvasive, accessible methods for improving auditory processing and may help advance our ability to improve sound quality and performance for implantees.
   Expert opinion
   Music training, particularly in the pediatric population, may be able to continue to enhance auditory processing even after performance plateaus. The effects of these training programs appear generalizable to non-trained musical tasks, speech prosody and, emotion perception. Future studies should employ rigorous control groups involving a non-musical acoustic intervention, standardized auditory stimuli, and the provision of feedback.
C1 [Jiam, Nicole T.; Limb, Charles] Univ Calif San Francisco, Sch Med, Dept Otolaryngol Head & Neck Surg, San Francisco, CA USA.
C3 University of California System; University of California San Francisco
RP Limb, C (corresponding author), UCSF, Dept Otolaryngol Head & Neck Surg, San Francisco, CA 94143 USA.
EM charles.limb@ucsf.edu
CR ABRAMSON AS, 1978, LANG SPEECH, V21, P319, DOI 10.1177/002383097802100406
   Adunka O, 2006, OTOLARYNG HEAD NECK, V135, P374, DOI 10.1016/j.otohns.2006.05.002
   Auinger AB, 2017, HEARING RES, V350, P226, DOI 10.1016/j.heares.2017.05.004
   Barrett KC, 2020, EAR HEARING, V41, P1372, DOI 10.1097/AUD.0000000000000862
   Bedoin N, 2018, ANN PHYS REHABIL MED, V61, P365, DOI 10.1016/j.rehab.2017.03.004
   Boothroyd A, 2010, J AM ACAD AUDIOL, V21, P601, DOI 10.3766/jaaa.21.9.6
   Brockmeier S J, 2011, Cochlear Implants Int, V12, P10, DOI 10.1179/146701010X12677899497236
   Bruce Iain A, 2018, Adv Otorhinolaryngol, V81, P66, DOI 10.1159/000485544
   Bruns L, 2016, SCI REP-UK, V6, DOI 10.1038/srep32026
   Caldwell M, 2015, COCHLEAR IMPLANTS IN, V16, pS114
   Castiglione A, 2016, AUDIOL NEUROOTOL S1, V21, pS21, DOI 10.1159/000448350
   Causon A, 2015, OTOL NEUROTOL, V36, P1137, DOI 10.1097/MAO.0000000000000753
   Chakravorti S, 2019, OTOL NEUROTOL, V40, P617, DOI 10.1097/MAO.0000000000002204
   Chang YS, 2019, BRAZ J OTORHINOLAR, V85, P571, DOI 10.1016/j.bjorl.2018.04.009
   Chari DA, 2019, OTOL NEUROTOL, V40, P38, DOI 10.1097/MAO.0000000000002061
   Chatterjee M, 2011, J ACOUST SOC AM, V130, P1567, DOI 10.1121/1.3621445
   Chen JK, 2010, PEDIATRICS, V125, P793
   Cheng XT, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518759214
   Ching TYC, 2013, EAR HEARING, V34, P535, DOI 10.1097/AUD.0b013e3182857718
   Clinkard David, 2015, Cochlear Implants Int, V16, P181, DOI 10.1179/1754762814Y.0000000096
   Coco A, 2007, HEARING RES, V225, P60, DOI 10.1016/j.heares.2006.12.004
   Dalbert A, 2016, OTOL NEUROTOL, V37, P446, DOI 10.1097/MAO.0000000000000998
   Degé F, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00124
   Dennis M, 2013, NEUROSCI BIOBEHAV R, V37, P2760, DOI 10.1016/j.neubiorev.2013.09.010
   Di Nardo W, 2015, ACTA OTORHINOLARYNGO, V35, P249
   Donaldson GS, 2006, EAR HEARING, V27, P658, DOI 10.1097/01.aud.0000240543.31567.54
   Driscoll Virginia, 2015, Cochlear Implants Int, V16, P137, DOI 10.1179/1754762814Y.0000000103
   Durham D, 2000, HEARING RES, V147, P145, DOI 10.1016/S0378-5955(00)00128-3
   FELDMANN H, 1988, LARYNGO RHINO OTOL, V67, P489, DOI 10.1055/s-2007-998547
   Francis HW, 1999, ARCH OTOLARYNGOL, V125, P499, DOI 10.1001/archotol.125.5.499
   Fu Qian-Jie, 2007, Trends Amplif, V11, P193, DOI 10.1177/1084713807301379
   Fu QJ, 2008, HEARING RES, V242, P198, DOI 10.1016/j.heares.2007.11.010
   Fu QJ, 2015, J SPEECH LANG HEAR R, V58, P163, DOI 10.1044/2014_JSLHR-H-14-0127
   Fu QJ, 1998, J ACOUST SOC AM, V104, P505, DOI 10.1121/1.423251
   Fu QJ, 2004, EAR HEARING, V25, P501, DOI 10.1097/01.aud.0000145125.50433.19
   Fuller CD, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518765379
   Galvin JJ, 2007, EAR HEARING, V28, P302, DOI 10.1097/01.aud.0000261689.35445.20
   Geers A. E., 2003, EAR HEAR S, V24, p24S
   GERKEN L, 1994, COGNITION, V51, P237, DOI 10.1016/0010-0277(94)90055-8
   GFELLER K, 1991, J SPEECH HEAR RES, V34, P916, DOI 10.1044/jshr.3404.916
   Gfeller K, 1998, J Am Acad Audiol, V9, P1
   Gfeller K, 1998, VOLTA REV, V100, P213
   Gfeller K, 2000, J Am Acad Audiol, V11, P390
   Gfeller K, 2007, EAR HEARING, V28, P412, DOI 10.1097/AUD.0b013e3180479318
   Gfeller Kate, 2002, J Am Acad Audiol, V13, P132
   Gfeller K, 2011, MUSIC THER PERSPECT, V29, P39, DOI 10.1093/mtp/29.1.39
   Gifford RH, 2008, AUDIOL NEURO-OTOL, V13, P193, DOI 10.1159/000113510
   Glennon E, 2020, CURR OPIN NEUROBIOL, V60, P108, DOI 10.1016/j.conb.2019.11.003
   Good A, 2017, EAR HEARING, V38, P455, DOI 10.1097/AUD.0000000000000402
   GREENWOOD DD, 1990, J ACOUST SOC AM, V87, P2592, DOI 10.1121/1.399052
   GREY JM, 1977, J ACOUST SOC AM, V61, P1270, DOI 10.1121/1.381428
   Guiraud J, 2007, J NEUROSCI, V27, P7838, DOI 10.1523/JNEUROSCI.0154-07.2007
   Han JJ, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-37014-7
   Harris MS, 2017, OTOL NEUROTOL, V38, pE107, DOI 10.1097/MAO.0000000000001425
   Hausen M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00566
   He A, 2016, OTOL NEUROTOL, V37, P324, DOI 10.1097/MAO.0000000000000980
   Hemmingson Carly, 2018, J Am Acad Audiol, V29, P722, DOI 10.3766/jaaa.17011
   Heng J, 2011, HEARING RES, V280, P192, DOI 10.1016/j.heares.2011.05.017
   Hidalgo C, 2020, EAR HEAR
   Hidalgo C, 2017, HEARING RES, V351, P11, DOI 10.1016/j.heares.2017.05.006
   Ho YC, 2003, NEUROPSYCHOLOGY, V17, P439, DOI 10.1037/0894-4105.17.3.439
   Holder JT, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518755288
   Hong RS, 2009, J ACOUST SOC AM, V126, P291, DOI 10.1121/1.3140592
   Hopyan-Misakyan TM, 2009, CHILD NEUROPSYCHOL, V15, P136, DOI 10.1080/09297040802403682
   Hyde KL, 2009, J NEUROSCI, V29, P3019, DOI 10.1523/JNEUROSCI.5118-08.2009
   Isaiah A, 2014, J NEUROSCI, V34, P11119, DOI 10.1523/JNEUROSCI.4767-13.2014
   Jentschke S, 2009, NEUROIMAGE, V47, P735, DOI 10.1016/j.neuroimage.2009.04.090
   Jiam NT, 2017, HEARING RES, V352, P30, DOI 10.1016/j.heares.2017.01.006
   Jiam NTF, 2019, ANN NY ACAD SCI, V1453, P22, DOI 10.1111/nyas.14130
   Jiam NT, 2019, JARO-J ASSOC RES OTO, V20, P247, DOI 10.1007/s10162-018-00704-0
   Jiam Nicole T, 2016, World J Otorhinolaryngol Head Neck Surg, V2, P142, DOI 10.1016/j.wjorl.2016.07.001
   Jiam NT, 2017, OTOL NEUROTOL, V38, pE240, DOI 10.1097/MAO.0000000000001448
   Jiam NT, 2016, OTOL NEUROTOL, V37, P672, DOI 10.1097/MAO.0000000000001060
   Jiam NTL, 2016, LARYNGOSCOPE, V126, P2587, DOI 10.1002/lary.25927
   Jiam NT, 2017, REFERENCE MODULE NEU
   JOHNSON DH, 1980, J ACOUST SOC AM, V68, P1115, DOI 10.1121/1.384982
   Jusczyk PW, 1999, COGNITIVE PSYCHOL, V39, P159, DOI 10.1006/cogp.1999.0716
   Kamakura T, 2018, OTOL NEUROTOL, V39, P284, DOI 10.1097/MAO.0000000000001686
   Ketten DR, 1998, ANN OTO RHINOL LARYN, V107, P1
   Kim I, 2010, TRENDS AMPLIF, V14, P164, DOI 10.1177/1084713810387937
   Kochanski G, 2005, J ACOUST SOC AM, V118, P1038, DOI 10.1121/1.1923349
   Koelsch S, 2004, CLIN NEUROPHYSIOL, V115, P966, DOI 10.1016/j.clinph.2003.11.032
   Kong YY, 2011, J SPEECH LANG HEAR R, V54, P981, DOI 10.1044/1092-4388(2010/10-0196)
   Kong YY, 2004, EAR HEARING, V25, P173, DOI 10.1097/01.AUD.0000120365.97792.2F
   Kraus N, 2017, NEUROSCIENTIST, V23, P287, DOI 10.1177/1073858416653593
   Kraus N, 2009, ANN NY ACAD SCI, V1169, P543, DOI 10.1111/j.1749-6632.2009.04549.x
   Kumpik DP, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01164
   Kuthubutheen J, 2015, HEARING RES, V327, P257, DOI 10.1016/j.heares.2015.06.010
   Laneau J, 2006, AUDIOL NEURO-OTOL, V11, P38, DOI 10.1159/000088853
   Leal MC, 2003, ACTA OTO-LARYNGOL, V123, P826, DOI 10.1080/00016480310000386
   Lee DS, 2001, NATURE, V409, P149, DOI 10.1038/35051653
   Leigh JR, 2016, INT J AUDIOL, V55, pS3, DOI 10.3109/14992027.2016.1146415
   Limb CJ, 2014, HEARING RES, V308, P13, DOI 10.1016/j.heares.2013.04.009
   Limb CJ, 2010, JARO-J ASSOC RES OTO, V11, P133, DOI 10.1007/s10162-009-0184-9
   Limb Charles J, 2006, Curr Opin Otolaryngol Head Neck Surg, V14, P337, DOI 10.1097/01.moo.0000244192.59184.bd
   Lin FR, 2013, JAMA INTERN MED, V173, P293, DOI 10.1001/jamainternmed.2013.1868
   Liu JG, 2012, BIOSYST ENG, V112, P6, DOI 10.1016/j.biosystemseng.2012.01.004
   Lo CY, 2020, J SPEECH LANG HEAR R, V63, P1990, DOI 10.1044/2020_JSLHR-19-00391
   Lo CY, 2015, BEHAV NEUROL, V2015, DOI 10.1155/2015/352869
   Looi V., 2007, EAR HEAR, V28, p59S
   Looi V, 2008, EAR HEARING, V29, P421, DOI 10.1097/AUD.0b013e31816a0d0b
   Looi V, 2019, EAR HEARING, V40, P529, DOI 10.1097/AUD.0000000000000632
   Looi V, 2011, INT J PEDIATR OTORHI, V75, P472, DOI 10.1016/j.ijporl.2010.12.023
   Looi V, 2010, INT J AUDIOL, V49, P116, DOI 10.3109/14992020903405987
   MacDonald RAR, 2013, INT J QUAL STUD HEAL, V8, DOI 10.3402/qhw.v8i0.20635
   Macherey O, 2013, EAR HEARING, V34, P426, DOI 10.1097/AUD.0b013e31827535f8
   Magnusson L, 2011, INT J AUDIOL, V50, P279, DOI 10.3109/14992027.2010.537378
   Maharani A, 2019, AM J GERIAT PSYCHIAT, V27, P1348, DOI 10.1016/j.jagp.2019.07.010
   Martines F, 2013, INT J PEDIATR OTORHI, V77, P707, DOI 10.1016/j.ijporl.2013.01.023
   McDermott Hugh J, 2004, Trends Amplif, V8, P49, DOI 10.1177/108471380400800203
   McKay CM, 2005, J ACOUST SOC AM, V118, P386, DOI 10.1121/1.1937349
   Meister H, 2011, EAR HEARING, V32, P459, DOI 10.1097/AUD.0b013e3182064882
   Mick P, 2014, OTOLARYNG HEAD NECK, V150, P378, DOI 10.1177/0194599813518021
   Mitani C, 2007, EAR HEAR S, V28, p29S
   Moore BCJ, 2003, OTOL NEUROTOL, V24, P243, DOI 10.1097/00129492-200303000-00019
   Moore DR, 2005, BRAIN LANG, V94, P72, DOI 10.1016/j.bandl.2004.11.009
   Moreno S, 2009, CEREB CORTEX, V19, P712, DOI 10.1093/cercor/bhn120
   Murphy J, 2011, INT J PEDIATR OTORHI, V75, P489, DOI 10.1016/j.ijporl.2011.01.002
   Nakata Takayuki, 2005, Journal of Physiological Anthropology and Applied Human Science, V24, P29, DOI 10.2114/jpa.24.29
   Nakata T, 2012, J ACOUST SOC AM, V131, P1307, DOI 10.1121/1.3672697
   Noble JH, 2014, AUDIOL NEURO-OTOL, V19, P400, DOI 10.1159/000365273
   Omar R, 2011, NEUROIMAGE, V56, P1814, DOI 10.1016/j.neuroimage.2011.03.002
   Pantev C, 2006, CEREB CORTEX, V16, P31, DOI 10.1093/cercor/bhi081
   Pantev C, 1998, NATURE, V392, P811, DOI 10.1038/33918
   Patel A. D., 2003, NAT NEUROSCI, V6, P7
   Peng SC, 2004, EAR HEARING, V25, P251, DOI 10.1097/01.AUD.0000130797.73809.40
   Penninger RT, 2013, OTOL NEUROTOL, V34, P1267, DOI 10.1097/MAO.0b013e3182923f04
   Petersen B., 2012, Psychomusicol Music Mind Brain, V22, P134, DOI DOI 10.1037/A0031140
   Rogalsky C, 2011, J NEUROSCI, V31, P3843, DOI 10.1523/JNEUROSCI.4515-10.2011
   Roy AT, 2016, OTOL NEUROTOL, V37, P146, DOI 10.1097/MAO.0000000000000932
   Roy AT, 2012, OTOL NEUROTOL, V33, P319, DOI 10.1097/MAO.0b013e31824296a9
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Schorr EA, 2009, J SPEECH LANG HEAR R, V52, P141, DOI 10.1044/1092-4388(2008/07-0213)
   Selleck AM, 2019, OTOL NEUROTOL, V40, P1148, DOI 10.1097/MAO.0000000000002342
   Shannon RV, 2005, INT REV NEUROBIOL, V70, P121, DOI 10.1016/S0074-7742(05)70004-0
   SHANNON RV, 1983, HEARING RES, V11, P157, DOI 10.1016/0378-5955(83)90077-1
   Shukor NFA, 2020, CLIN EXP OTORHINOLAR
   Singh S, 2009, EAR HEARING, V30, P160, DOI 10.1097/AUD.0b013e31819342b9
   Snel-Bongers J, 2012, EAR HEARING, V33, P367, DOI 10.1097/AUD.0b013e318234efd5
   Snels C, 2019, OTOL NEUROTOL, V40, P145, DOI 10.1097/MAO.0000000000002083
   Sorkin DL, 2016, OTOL NEUROTOL, V37, pE161, DOI 10.1097/MAO.0000000000000946
   SPIVAK LG, 1990, J SPEECH HEAR RES, V33, P511, DOI 10.1044/jshr.3303.511
   Sucher CM, 2007, HEARING RES, V230, P80, DOI 10.1016/j.heares.2007.05.002
   Svirsky MA, 2000, PSYCHOL SCI, V11, P153, DOI 10.1111/1467-9280.00231
   Sweeney AD, 2016, OTOLARYNG HEAD NECK, V154, P907, DOI 10.1177/0194599816630545
   Sweeney AD, 2015, OTOL NEUROTOL, V36, P1480, DOI 10.1097/MAO.0000000000000847
   Tang Q, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/4/046029
   Tao DD, 2015, EAR HEARING, V36, P102, DOI 10.1097/AUD.0000000000000086
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Throckmorton CS, 2006, HEARING RES, V218, P30, DOI 10.1016/j.heares.2006.03.020
   Torppa R, 2020, EAR HEARING, V41, P395, DOI 10.1097/AUD.0000000000000763
   Torppa R, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01389
   Torppa R, 2014, INT J AUDIOL, V53, P182, DOI 10.3109/14992027.2013.872302
   Trehub SE, 2009, ANN NY ACAD SCI, V1169, P534, DOI 10.1111/j.1749-6632.2009.04554.x
   Vainio Martti, 2007, J ACOUSTICAL SOC AM, V121, pEL55
   Vongpaisal T, 2006, J SPEECH LANG HEAR R, V49, P1091, DOI 10.1044/1092-4388(2006/078)
   Wang CC, 2011, J CLIN VIROL, V50, P4, DOI 10.1016/j.jcv.2010.09.009
   Watanabe D, 2007, EXP BRAIN RES, V176, P332, DOI 10.1007/s00221-006-0619-z
   Wei CG, 2004, HEARING RES, V197, P87, DOI 10.1016/j.heares.2004.06.002
   Welch G.F., 2015, COCHLEAR IMPLANTS IN, V16, DOI 10.1179/1467010015Z.000000000276
   Whitehead JC, 2018, HUM BRAIN MAPP, V39, P4913, DOI 10.1002/hbm.24333
   Wiefferink CH, 2012, INT J PEDIATR OTORHI, V76, P883, DOI 10.1016/j.ijporl.2012.02.065
   Wilson BS, 2008, HEARING RES, V242, P3, DOI 10.1016/j.heares.2008.06.005
   Witt S, 2002, ANN OTO RHINOL LARYN, V111, P349, DOI 10.1177/000348940211100412
   Wright BA, 2001, P NATL ACAD SCI USA, V98, P12307, DOI 10.1073/pnas.211220498
   Würfel W, 2014, HEARING RES, V316, P65, DOI 10.1016/j.heares.2014.07.013
   Yucel E, 2009, INT J PEDIATR OTORHI, V73, P1043, DOI 10.1016/j.ijporl.2009.04.009
   Zatorre R, 2005, NATURE, V434, P312, DOI 10.1038/434312a
   Zeng FG, 2002, HEARING RES, V174, P101, DOI 10.1016/S0378-5955(02)00644-5
   Zhao TC, 2016, P NATL ACAD SCI USA, V113, P5212, DOI 10.1073/pnas.1603984113
NR 170
TC 9
Z9 9
U1 2
U2 38
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1743-4440
EI 1745-2422
J9 EXPERT REV MED DEVIC
JI Expert Rev. Med. Devices
PD NOV 1
PY 2020
VL 17
IS 11
BP 1193
EP 1205
DI 10.1080/17434440.2020.1841628
EA OCT 2020
PG 13
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Engineering
GA PM6TQ
UT WOS:000582893300001
PM 33090055
DA 2024-01-09
ER

PT J
AU Parncutt, R
   Chuckrow, R
AF Parncutt, Richard
   Chuckrow, Robert
TI Chuckrow's theory of the prenatal origin of music
SO MUSICAE SCIENTIAE
LA English
DT Article
DE Prenatal; origin; music; voice; heartbeat; footsteps; melody; rhythm;
   harmony; emotion
ID HEART-RATE RESPONSE; DELIBERATE PRACTICE; EVOLUTION; ACQUISITION;
   PERCEPTION; LANGUAGE; MOTHER; ELECTROCARDIOGRAPHY; EXPRESSIONS;
   MAINTENANCE
AB In 1965, the second author, a graduate student in physics at New York University, drafted a paper entitled "Music: A synthesis of prenatal stimuli," in which he proposed that structural elements of music such as rhythm and melody are analogs of fetal stimuli. In the 1980s, the first author independently published a similar theory. Both authors considered fetal perception of internal body sounds, correlations between those sounds and maternal states, the ability of the fetus to hear and remember sound patterns, biological and behavioral correlates of emotions shared by mother and fetus, transfer of hormones across the placenta, and effects of maternal psychopathology on infant behavior. Both argued that consideration of fetal consciousness is unnecessary because unconscious learning can influence later conscious behaviors and experiences. Chuckrow uniquely proposed that meter and polymeter, perceived as combinations of approximately isochronous pulses with one pulse in the foreground, might derive from the combined sound of maternal and fetal heartbeats as perceived by the fetus. We evaluate these theories in the context of more recent approaches to the origin of music. A systematic consideration of prenatal influences can parsimoniously explain communicative, emotional and structural aspects of music. Music may be a by-product of adaptations such as prenatal hearing and motherese that promoted infant survival in ancient hunter-gatherer settings.
C1 [Parncutt, Richard] Karl Franzens Univ Graz, Graz, Austria.
   [Chuckrow, Robert] NYU, New York, NY 10003 USA.
C3 University of Graz; New York University
RP Parncutt, R (corresponding author), Karl Franzens Univ Graz, Ctr Systemat Musicol, Merangasse 70, A-8010 Graz, Austria.
EM parncutt@uni-graz.at
CR Abrams RM, 1998, MUSIC PERCEPT, V15, P307
   Allister L, 2001, DEV NEUROPSYCHOL, V20, P639, DOI 10.1207/875656401753549843
   [Anonymous], FREQUENCY RANG UNPUB
   [Anonymous], THESIS
   [Anonymous], 2013, OXFORD HDB NEW CULTU
   [Anonymous], TAI CHI BOOK
   [Anonymous], 1999, MUSIC SCI, DOI DOI 10.1177/10298649000030S105
   [Anonymous], MUSIC SYNTHESI UNPUB
   [Anonymous], 1911, ORIGINS MUSIC
   [Anonymous], NEUROSCIENCE 21 CENT
   [Anonymous], 1973, Review of child development research
   [Anonymous], KEY PROBLEMS SOCIOLO
   [Anonymous], SCI MUSICAL SOUNDS
   [Anonymous], MUSIC SYNTHESIS PREN
   [Anonymous], NEUR MUS DIJ FRANC 2
   [Anonymous], NATURE LANGUAGE EVOL, DOI 10.1007/978-1-4939-0609-3_2
   [Anonymous], ACTION PERCEPTION RH
   [Anonymous], 2005, CREATIVITY HUMAN EVO
   [Anonymous], PRENATAL PERCEPTION
   [Anonymous], 2006, MUSIC SCI, DOI DOI 10.1177/1029864906010001031
   [Anonymous], 1969, BASIC BOOKS
   [Anonymous], THESIS
   [Anonymous], ETHOLOGICAL STUDIES
   [Anonymous], TAI CHI CHUAN EMBRAC
   [Anonymous], 1996, Philosophy of Natural Science
   [Anonymous], 2006, MUSIC MANIPULATION S
   Arom S., 2004, African polyphony and polyrhythm: Musical structure and methodology
   Baars BJ., 1986, The cognitive revolution in psychology
   Becker J., 2004, Deep listeners: Music emotions and trancing
   Bereczkei T, 1997, ETHOLOGY, V103, P681
   Black RE, 2010, LANCET, V375, P1969, DOI 10.1016/S0140-6736(10)60549-1
   BRETHERTON I, 1982, DEV PSYCHOL, V18, P906, DOI 10.1037/0012-1649.18.6.906
   Brown S, 2000, ORIGINS OF MUSIC, P271
   Bryson B., 2003, SHORT HIST NEARLY EV
   Buunk BP, 2002, PERS RELATIONSHIP, V9, P271, DOI 10.1111/1475-6811.00018
   Caspari R, 2004, P NATL ACAD SCI USA, V101, P10895, DOI 10.1073/pnas.0402857101
   Chen JL, 2006, NEUROIMAGE, V32, P1771, DOI 10.1016/j.neuroimage.2006.04.207
   CHUCKROW R, 1971, J OPT SOC AM, V61, P218, DOI 10.1364/JOSA.61.000218
   Clarke E. F., 1987, ACTION PERCEPTION RH, V55, P19
   COLLINGS C, 1985, AM J OBSTET GYNECOL, V151, P498, DOI 10.1016/0002-9378(85)90277-7
   Cooper NP, 1998, J PHYSIOL-LONDON, V509, P277, DOI 10.1111/j.1469-7793.1998.277bo.x
   COPELAND BL, 1991, J SPORT MED PHYS FIT, V31, P100
   Croxson PL, 2009, J NEUROSCI, V29, P4531, DOI 10.1523/JNEUROSCI.4515-08.2009
   d'Errico F, 2003, J WORLD PREHIST, V17, P1, DOI 10.1023/A:1023980201043
   Darwin C., 1859, ORIGIN SPECIES MEANS, DOI 10.5962/bhl.title.82303
   DAVIDSON I, 1989, CURR ANTHROPOL, V30, P125, DOI 10.1086/203723
   Dissanayake E, 2000, ORIGINS OF MUSIC, P389
   Dollard J., 1950, Personality and psychotherapy; an analysis in terms of learning, thinking, and culture
   DOWLING WJ, 1978, PSYCHOL REV, V85, P341, DOI 10.1037/0033-295X.85.4.341
   Dutton D., 2009, The Art Instinct: Beauty, Pleasure, Human Evolution
   ERICSSON KA, 1993, PSYCHOL REV, V100, P363, DOI 10.1037/0033-295X.100.3.363
   Ericsson KA, 2004, ACAD MED, V79, pS70, DOI 10.1097/00001888-200410001-00022
   Falk D, 2004, BEHAV BRAIN SCI, V27, P491
   Fernald A., 1992, The Adapted Mind: Evolutionary Psychology and the Generation of Culture, P391, DOI DOI 10.1007/BF00852474
   Field T, 2006, INFANT BEHAV DEV, V29, P445, DOI 10.1016/j.infbeh.2006.03.003
   Fitch WT, 2006, COGNITION, V100, P173, DOI 10.1016/j.cognition.2005.11.009
   Flinn MV, 1997, EVOL HUM BEHAV, V18, P23, DOI 10.1016/S1090-5138(96)00046-3
   FORSTER M, 1994, BRIT J PHILOS SCI, V45, P1, DOI 10.1093/bjps/45.1.1
   FOX JG, 1972, APPL ERGON, V3, P202, DOI 10.1016/0003-6870(72)90101-9
   FRIJDA NH, 1989, J PERS SOC PSYCHOL, V57, P212, DOI 10.1037/0022-3514.57.2.212
   Gabrielsson A., 2011, Strong Experiences with Music
   Gibson James J., 1979, 'The Theory of Affordances'. The Ecological Approach to Visual Perception
   Gottlieb G, 2007, DEVELOPMENTAL SCI, V10, P1, DOI 10.1111/j.1467-7687.2007.00556.x
   GOURLAY KA, 1984, WORLD MUSIC, V26, P25
   Hallam S, 2010, INT J MUSIC EDUC, V28, P269, DOI 10.1177/0255761410370658
   Hekmat H. M., 1993, Psychology of Music, V21, P163, DOI DOI 10.1177/030573569302100205
   Hepper PG, 1996, ACTA PAEDIATR, V85, P16, DOI 10.1111/j.1651-2227.1996.tb14272.x
   HEPPER PG, 1994, ARCH DIS CHILD-FETAL, V71, pF81, DOI 10.1136/fn.71.2.F81
   Hill K, 1999, ANNU REV ANTHROPOL, V28, P397, DOI 10.1146/annurev.anthro.28.1.397
   Hill K, 2007, J HUM EVOL, V52, P443, DOI 10.1016/j.jhevol.2006.11.003
   Hrdy S. B., 2011, MOTHERS OTHERS
   HUHEEY JE, 1977, BEHAV GENET, V7, P29
   HURON D, 1992, MUSIC PERCEPT, V10, P83
   JENNINGS B, 1980, Clinical Obstetrics and Gynecology, V23, P1093, DOI 10.1097/00003081-198012000-00013
   JONIDES J, 1988, PERCEPT PSYCHOPHYS, V43, P346, DOI 10.3758/BF03208805
   Kirschner S, 2010, EVOL HUM BEHAV, V31, P354, DOI 10.1016/j.evolhumbehav.2010.04.004
   Kisilevsky BS, 2009, INFANT BEHAV DEV, V32, P59, DOI 10.1016/j.infbeh.2008.10.002
   Kuhn T. S, 1962, The Essential Tension: Selected Studies in Scientific Tradition and Change, P165
   LARKS SD, 1958, AM HEART J, V56, P701, DOI 10.1016/0002-8703(58)90213-8
   Lerdahl Fred, 1983, A generative theory of tonal music
   Lindsey L. L., 2015, Gender roles: A sociological perspective
   Livingstone SR, 2009, MUSIC SCI, P83, DOI 10.1177/1029864909013002061
   LORENZ K., 1935, Journal fur Ornithologie, V83, P137, DOI 10.1007/BF01905355
   Mampe B, 2009, CURR BIOL, V19, P1994, DOI 10.1016/j.cub.2009.09.064
   Mastropieri D, 1999, DEV PSYCHOBIOL, V35, P204, DOI 10.1002/(SICI)1098-2302(199911)35:3<204::AID-DEV5>3.0.CO;2-V
   Mehr SA, 2017, EVOL HUM BEHAV, V38, P674, DOI 10.1016/j.evolhumbehav.2016.12.005
   Mekel-Bobrov N, 2005, SCIENCE, V309, P1720, DOI 10.1126/science.1116815
   Merikle PM, 2001, COGNITION, V79, P115, DOI 10.1016/S0010-0277(00)00126-8
   Miller G, 2000, ORIGINS OF MUSIC, P329
   MILLER J, 1989, PERCEPT PSYCHOPHYS, V45, P567, DOI 10.3758/BF03208064
   Mithen S, 2009, ANN NY ACAD SCI, V1169, P3, DOI 10.1111/j.1749-6632.2009.04590.x
   Moon C M, 2000, J Perinatol, V20, pS37
   Morley I, 2002, CAMB ARCHAEOL J, V12, P195, DOI 10.1017/S0959774302000100
   MURRAY L, 1986, J CHILD LANG, V13, P15, DOI 10.1017/S0305000900000271
   NAGEL T, 1974, PHILOS REV, V83, P435, DOI 10.2307/2183914
   Nazzi T, 1998, J EXP PSYCHOL HUMAN, V24, P756, DOI 10.1037/0096-1523.24.3.756
   Nowak MA, 2006, SCIENCE, V314, P1560, DOI 10.1126/science.1133755
   Palmer C, 1996, MUSIC PERCEPT, V14, P23
   PAPOUSEK M, 1991, INFANT BEHAV DEV, V14, P415, DOI 10.1016/0163-6383(91)90031-M
   PARNCUTT R, 1994, MUSIC PERCEPT, V11, P409
   Parncutt R, 2012, Harmony: A psychoacoustical approach, V19
   Parncutt R., 2016, OXFORD HDB MUSIC PSY, P371, DOI [DOI 10.1093/OXFORDHB/9780198722946.013.55, 10.1093/oxfordhb/9780198722946.013.11]
   Parncutt R, 2009, MUSIC THAT WORKS, P185, DOI 10.1007/978-3-211-75121-3_13
   Parncutt R, 2009, MUSIC SCI, P119, DOI 10.1177/1029864909013002071
   Penel A, 1998, PSYCHOL RES-PSYCH FO, V61, P12, DOI 10.1007/PL00008161
   Peretz I, 2003, NAT NEUROSCI, V6, P688, DOI 10.1038/nn1083
   Phillips-Silver J, 2007, COGNITION, V105, P533, DOI 10.1016/j.cognition.2006.11.006
   Pinker S., 1997, How the mind works
   PLOMP R, 1964, J ACOUST SOC AM, V36, P1628, DOI 10.1121/1.1919256
   Popper K., 1959, The logic ofscientific discovery
   PUJOL R, 1973, ACTA OTO-LARYNGOL, V76, P1, DOI 10.3109/00016487309121476
   Raviv A, 1996, J YOUTH ADOLESCENCE, V25, P631, DOI 10.1007/BF01537358
   Repp BH, 2004, PSYCHOL RES-PSYCH FO, V68, P252, DOI 10.1007/s00426-003-0143-8
   ROEDERER JG, 1984, MUSIC PERCEPT, V1, P350
   Rosenberg K, 2002, BJOG-INT J OBSTET GY, V109, P1199, DOI 10.1046/j.1471-0528.2002.00010.x
   SALK L, 1973, SCI AM, V228, P24, DOI 10.1038/scientificamerican0573-24
   Scheib JE, 2001, PERS RELATIONSHIP, V8, P371, DOI 10.1111/j.1475-6811.2001.tb00046.x
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Schiavio A., 2016, PHENOMENOL COGN SCI, P1
   SMYTH CN, 1958, BMJ-BRIT MED J, V2, P1005, DOI 10.1136/bmj.2.5103.1005
   SOKAL RR, 1990, AM NAT, V135, P157, DOI 10.1086/285037
   SOKOL S, 1978, VISION RES, V18, P33, DOI 10.1016/0042-6989(78)90074-3
   SORCE JF, 1981, DEV PSYCHOL, V17, P737, DOI 10.1037/0012-1649.17.6.737
   Steinbeis N, 2009, CEREB CORTEX, V19, P619, DOI 10.1093/cercor/bhn110
   Stewart GW, 1931, J ACOUST SOC AM, V2, P325, DOI 10.1121/1.1915259
   Teie D, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01158
   TERHARDT E, 1974, J ACOUST SOC AM, V55, P1061, DOI 10.1121/1.1914648
   Trehub SE, 2001, ANN NY ACAD SCI, V930, P1
   TRIVERS RL, 1971, Q REV BIOL, V46, P35, DOI 10.1086/406755
   Ullal-Gupta S, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00048
   Van Leeuwen P, 2009, P NATL ACAD SCI USA, V106, P13661, DOI 10.1073/pnas.0901049106
   Withagen R, 2010, THEOR PSYCHOL, V20, P489, DOI 10.1177/0959354310361405
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 133
TC 7
Z9 7
U1 1
U2 36
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1029-8649
EI 2045-4147
J9 MUSIC SCI
JI Music Sci.
PD DEC
PY 2019
VL 23
IS 4
BP 403
EP 425
DI 10.1177/1029864917738130
PG 23
WC Music; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music; Psychology
GA IS6DL
UT WOS:000482242400002
DA 2024-01-09
ER

PT J
AU Lake, JI
   Labar, KS
   Meck, WH
AF Lake, Jessica I.
   LaBar, Kevin S.
   Meck, Warren H.
TI Hear it playing low and slow: How pitch level differentially influences
   time perception
SO ACTA PSYCHOLOGICA
LA English
DT Article
DE Timing and time perception; Interval-based timing; Attention; Emotion;
   Clock speed; Mode control
ID INTERNAL CLOCK; DURATION DISCRIMINATION; TEMPORAL INTEGRATION; EMOTIONAL
   RESPONSES; PERCEIVED DURATION; MUSIC PERFORMANCE; VOCAL EXPRESSION;
   RHESUS-MONKEYS; INTERVAL; MEMORY
AB Variations in both pitch and time are important in conveying meaning through speech and music, however, research is scant on perceptual interactions between these two domains. Using an ordinal comparison procedure, we explored how different pitch levels of flanker tones influenced the perceived duration of empty interstimulus intervals (ISIs). Participants heard monotonic, isochronous tone sequences (ISIs of 300, 600, or 1200 ms) composed of either one or five standard ISIs flanked by 500 Hz tones, followed by a final interval (FI) flanked by tones of either the same (500 Hz), higher (625 Hz), or lower (400 Hz) pitch. The FI varied in duration around the standard ISI duration. Participants were asked to determine if the FI was longer or shorter in duration than the preceding intervals. We found that an increase in FI flanker tone pitch level led to the underestimation of FI durations while a decrease in FI flanker tone pitch led to the overestimation of El durations. The magnitude of these pitch-level effects decreased as the duration of the standard interval was increased, suggesting that the effect was driven by differences in mode-switch latencies to start/stop timing. Temporal context (One vs. Five Standard ISIS) did not have a consistent effect on performance. We propose that the interaction between pitch and time may have important consequences in understanding the ways in which meaning and emotion are communicated. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Lake, Jessica I.; LaBar, Kevin S.] Duke Univ, Ctr Cognit Neurosci, Durham, NC 27708 USA.
   [Meck, Warren H.] Duke Univ, Ctr Behav Neurosci & Genom, Durham, NC 27708 USA.
   [Lake, Jessica I.; LaBar, Kevin S.; Meck, Warren H.] Duke Univ, Dept Psychol & Neurosci, Durham, NC 27708 USA.
C3 Duke University; Duke University; Duke University
RP Meck, WH (corresponding author), Duke Univ, Dept Psychol & Neurosci, Genome Sci Res Bldg 2,3rd Floor,572 Res Dr, Durham, NC 27708 USA.
EM meck@psych.duke.edu
OI Meck, Warren/0000-0002-6120-4790
CR Agostino PV, 2008, BEHAV BRAIN SCI, V31, P575, DOI 10.1017/S0140525X0800530X
   Allman MJ, 2014, ANNU REV PSYCHOL, V65, P743, DOI 10.1146/annurev-psych-010213-115117
   Allman MJ, 2012, BRAIN, V135, P656, DOI 10.1093/brain/awr210
   Andrade PE, 2003, J ROY SOC MED, V96, P284, DOI 10.1258/jrsm.96.6.284
   Arvaniti A, 2009, PHONETICA, V66, P46, DOI 10.1159/000208930
   Bach DR, 2009, INT J PSYCHOPHYSIOL, V74, P28, DOI 10.1016/j.ijpsycho.2009.06.004
   Bays RB, 2013, ACTA PSYCHOL, V142, P30, DOI 10.1016/j.actpsy.2012.10.004
   Boltz MG, 1998, PERCEPT PSYCHOPHYS, V60, P1357, DOI 10.3758/BF03207998
   Bradshaw CM, 1997, TIME BEHAV PSYCHOL N, P409, DOI DOI 10.1016/S0166-4115(97)80062-3
   BRIGNER WL, 1988, PERCEPT MOTOR SKILL, V67, P301, DOI 10.2466/pms.1988.67.1.301
   Buhusi CV, 2006, J EXP PSYCHOL-ANIM B, V32, P329, DOI 10.1037/0097-7403.32.3.329
   Buhusi CV, 2009, PHILOS T R SOC B, V364, P1875, DOI 10.1098/rstb.2009.0022
   Buhusi CV, 2005, NAT REV NEUROSCI, V6, P755, DOI 10.1038/nrn1764
   Buhusi CV, 2002, J COMP PSYCHOL, V116, P381, DOI 10.1037//0735-7036.116.4.381
   COHEN J, 1954, NATURE, V174, P642, DOI 10.1038/174642a0
   Conway LG, 2004, J EXP SOC PSYCHOL, V40, P113, DOI 10.1016/S0022-1031(03)00089-1
   Cordes S., 2014, J EXPT PSYC IN PRESS
   Coull JT, 2011, NEUROPSYCHOPHARMACOL, V36, P3, DOI 10.1038/npp.2010.113
   Cutler A, 1997, LANG SPEECH, V40, P141, DOI 10.1177/002383099704000203
   Di Pietro M, 2004, NEUROPSYCHOLOGIA, V42, P868, DOI 10.1016/j.neuropsychologia.2003.12.004
   DRAKE C, 1993, PERCEPT PSYCHOPHYS, V54, P277, DOI 10.3758/BF03205262
   Droit-Volet S, 2007, BEHAV PROCESS, V74, P244, DOI 10.1016/j.beproc.2006.09.012
   Fortin C, 2009, ATTEN PERCEPT PSYCHO, V71, P789, DOI 10.3758/APP.71.4.789
   Ghazanfar AA, 2002, P NATL ACAD SCI USA, V99, P15755, DOI 10.1073/pnas.242469699
   Ghazanfar AA, 2009, BEHAV NEUROSCI, V123, P822, DOI 10.1037/a0016391
   GIBBON J, 1984, ANN NY ACAD SCI, V423, P52, DOI 10.1111/j.1749-6632.1984.tb23417.x
   GIBBON J, 1984, ANIMAL COGNITION
   Griffiths TD, 2012, J NEUROSCI, V32, P13333, DOI 10.1523/JNEUROSCI.1661-12.2012
   Grommet EK, 2011, BEHAV PROCESS, V86, P88, DOI 10.1016/j.beproc.2010.10.003
   GRONDIN S, 1993, PERCEPT PSYCHOPHYS, V54, P383, DOI 10.3758/BF03205274
   Grondin S, 1996, PERCEPT PSYCHOPHYS, V58, P424, DOI 10.3758/BF03206818
   Gu B.-M., 2014, NEUROBIOLOG IN PRESS
   Gu BM, 2011, LECT NOTES ARTIF INT, V6789, P67, DOI 10.1007/978-3-642-21478-3_6
   Han SE, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020160
   Hasuo E, 2012, ATTEN PERCEPT PSYCHO, V74, P430, DOI 10.3758/s13414-011-0236-1
   Henry MJ, 2009, J EXP PSYCHOL HUMAN, V35, P551, DOI 10.1037/0096-1523.35.2.551
   Hyde KL, 2004, PSYCHOL SCI, V15, P356, DOI 10.1111/j.0956-7976.2004.00683.x
   Jerde TA, 2011, NEUROIMAGE, V57, P1572, DOI 10.1016/j.neuroimage.2011.05.061
   JUSLIN P, 2005, MUSICAL COMMUNICATIO
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Krumhansl CL, 2000, PSYCHOL BULL, V126, P159, DOI 10.1037/0033-2909.126.1.159
   Kung SJ, 2013, J COGNITIVE NEUROSCI, V25, P401, DOI 10.1162/jocn_a_00325
   Lake JI, 2013, NEUROPSYCHOLOGIA, V51, P284, DOI 10.1016/j.neuropsychologia.2012.09.014
   Lebrun-Guillaud G, 2007, PERCEPT PSYCHOPHYS, V69, P1450, DOI 10.3758/BF03192959
   Lejeune H, 1998, BEHAV PROCESS, V44, P127, DOI 10.1016/S0376-6357(98)00045-X
   Lewis PA, 2012, PSYCHOLOGIST, V25, P594
   Lui MA, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021829
   Lustig C, 2001, PSYCHOL SCI, V12, P478, DOI 10.1111/1467-9280.00389
   Lustig C, 2011, BRAIN COGNITION, V77, P298, DOI 10.1016/j.bandc.2011.07.007
   Matell MS, 2004, COGNITIVE BRAIN RES, V21, P139, DOI 10.1016/j.cogbrainres.2004.06.012
   Matell MS, 2000, BIOESSAYS, V22, P94, DOI 10.1002/(SICI)1521-1878(200001)22:1<94::AID-BIES14>3.0.CO;2-E
   Matthews WJ, 2013, COGNITIVE PSYCHOL, V66, P259, DOI 10.1016/j.cogpsych.2013.01.001
   McAuley JD, 2003, J EXP PSYCHOL HUMAN, V29, P1102, DOI 10.1037/0096-1523.29.6.1102
   McBeath MK, 2002, PSYCHON B REV, V9, P306, DOI 10.3758/BF03196286
   Meck WH, 2008, CURR OPIN NEUROBIOL, V18, P145, DOI 10.1016/j.conb.2008.08.002
   Meck WH, 2006, BRAIN RES, V1108, P157, DOI 10.1016/j.brainres.2006.06.046
   Meck WH, 2012, FRONT INTEGR NEUROSC, V6, DOI 10.3389/fnint.2012.00013
   MECK WH, 1984, ANN NY ACAD SCI, V423, P528, DOI 10.1111/j.1749-6632.1984.tb23457.x
   Meck WH, 2005, BRAIN COGNITION, V58, P1, DOI 10.1016/j.bandc.2004.09.004
   MECK WH, 1983, J EXP PSYCHOL ANIM B, V9, P171, DOI 10.1037/0097-7403.9.2.171
   Meck WH, 1996, COGNITIVE BRAIN RES, V3, P227, DOI 10.1016/0926-6410(96)00009-2
   MECK WH, 1985, J EXP PSYCHOL ANIM B, V11, P591, DOI 10.1037/0097-7403.11.4.591
   MECK WH, 1983, J EXP PSYCHOL ANIM B, V9, P320, DOI 10.1037/0097-7403.9.3.320
   Meck WH, 2002, BRAIN COGNITION, V48, P195, DOI 10.1006/brcg.2001.1313
   MECK WH, 1986, PHARMACOL BIOCHEM BE, V25, P1185, DOI 10.1016/0091-3057(86)90109-7
   Melgire M, 2005, BRAIN COGNITION, V58, P119, DOI 10.1016/j.bandc.2004.09.013
   Merchant H, 2013, ANNU REV NEUROSCI, V36, P313, DOI 10.1146/annurev-neuro-062012-170349
   MURRAY IR, 1993, J ACOUST SOC AM, V93, P1097, DOI 10.1121/1.405558
   Neuhoff JG, 1999, J EXP PSYCHOL HUMAN, V25, P1050, DOI 10.1037/0096-1523.25.4.1050
   Neuhoff JG, 1996, J EXP PSYCHOL HUMAN, V22, P970, DOI 10.1037/0096-1523.22.4.970
   Ono F, 2009, PSYCHON B REV, V16, P182, DOI 10.3758/PBR.16.1.182
   Pashler H, 2001, J EXP PSYCHOL HUMAN, V27, P485, DOI 10.1037/0096-1523.27.2.485
   Patel AD, 2006, J ACOUST SOC AM, V119, P3034, DOI 10.1121/1.2179657
   Penney TB, 1996, EXP CLIN PSYCHOPHARM, V4, P82, DOI 10.1037//1064-1297.4.1.82
   Penney TB, 1998, TIMING OF BEHAVIOR, P165
   Penney TB, 2000, J EXP PSYCHOL HUMAN, V26, P1770, DOI 10.1037//0096-1523.26.6.1770
   Penney TB., 2003, FUNCTIONAL NEURAL ME, P209
   Pfeuty M, 2010, ATTEN PERCEPT PSYCHO, V72, P763, DOI 10.3758/APP.72.3.763
   Rammsayer T, 2011, ACTA PSYCHOL, V137, P127, DOI 10.1016/j.actpsy.2011.03.010
   Samson S, 2002, BRAIN, V125, P511, DOI 10.1093/brain/awf051
   Schellenberg EG, 2000, MUSIC PERCEPT, V18, P155
   Scherer KR, 2003, SER AFFECTIVE SCI, P433
   SCHIFF W, 1962, SCIENCE, V136, P982, DOI 10.1126/science.136.3520.982
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   Schirmer A, 2004, COGNITIVE BRAIN RES, V21, P269, DOI 10.1016/j.cogbrainres.2004.04.003
   Seifritz E, 2002, CURR BIOL, V12, P2147, DOI 10.1016/S0960-9822(02)01356-8
   Stevens SS, 1934, P NATL ACAD SCI USA, V20, P457, DOI 10.1073/pnas.20.7.457
   Tse CY, 2006, PSYCHOPHYSIOLOGY, V43, P172, DOI 10.1111/j.1469-8986.2006.389.x
   Tse PU, 2004, PERCEPT PSYCHOPHYS, V66, P1171, DOI 10.3758/BF03196844
   van Wassenhove V, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0001437
   Webster GD, 2005, MOTIV EMOTION, V29, P19, DOI 10.1007/s11031-005-4414-0
   Zatorre RJ, 2002, TRENDS COGN SCI, V6, P37, DOI 10.1016/S1364-6613(00)01816-7
NR 94
TC 17
Z9 18
U1 1
U2 16
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0001-6918
EI 1873-6297
J9 ACTA PSYCHOL
JI Acta Psychol.
PD JUN
PY 2014
VL 149
SI SI
BP 169
EP 177
DI 10.1016/j.actpsy.2014.03.010
PG 9
WC Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA AI9OR
UT WOS:000337262400021
PM 24746941
DA 2024-01-09
ER

PT J
AU Vrysis, L
   Tsipas, N
   Thoidis, I
   Dimoulas, C
AF Vrysis, Lazaros
   Tsipas, Nikolaos
   Thoidis, Iordanis
   Dimoulas, Charalampos
TI 1D/2D Deep CNNs vs. Temporal Feature Integration for General Audio
   Classification
SO JOURNAL OF THE AUDIO ENGINEERING SOCIETY
LA English
DT Article
AB Semantic audio analysis has become a fundamental task in modern audio applications, making the improvement and optimization of classification algorithms a necessity. Standard frame-based audio classification methods have been optimized and modern approaches introduce engineering methodologies that capture the temporal dependency between successive feature observations, following the process of temporal feature integration. Moreover, the deployment of the convolutional neural networks defined a new era on semantic audio analysis. The current paper attempts a thorough comparison between standard feature-based classification strategies, state-of-the-art temporal feature integration tactics and 1D/2D deep convolutional neural network setups, on typical audio classification tasks. Experiments focus on optimizing a lightweight configuration for convolutional network topologies on a Speech/Music/Other classification scheme that can be deployed on various audio information retrieval tasks, such as voice activity detection, speaker diarization, or speech emotion recognition. The outmost target of this work is to establish an optimized protocol for constructing deep convolutional topologies on general audio detection classification schemes, minimizing complexity and computational needs.
C1 [Vrysis, Lazaros; Tsipas, Nikolaos; Thoidis, Iordanis; Dimoulas, Charalampos] Aristotle Univ Thessaloniki, Thessaloniki, Greece.
C3 Aristotle University of Thessaloniki
RP Vrysis, L (corresponding author), Aristotle Univ Thessaloniki, Thessaloniki, Greece.
EM lvrysis@auth.gr; nitsipas@auth.gr; ithoidis@auth.gr; babis@eng.auth.gr
RI Vrysis, Lazaros/V-2260-2019; Dimoulas, Charalampos/ABU-1098-2022;
   Thoidis, Iordanis/GQY-5907-2022
OI Vrysis, Lazaros/0000-0003-2900-4657; Dimoulas,
   Charalampos/0000-0001-7923-9361; Thoidis, Iordanis/0000-0001-6636-4745
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2013, 134 CONV AUD ENG SOC
   Badshah AM, 2017, 2017 INTERNATIONAL CONFERENCE ON PLATFORM TECHNOLOGY AND SERVICE (PLATCON), P125
   Bountourakis V, 2019, ACOUSTICS-BASEL, V1, P410, DOI 10.3390/acoustics1020023
   CANNAM C., 2006, Proceedings of the International Conference on Music Information Retrieval, P324
   Choi, 2016, ARXIV PREPRINT ARXIV
   Choi K, 2017, INT CONF ACOUST SPEE, P2392, DOI 10.1109/ICASSP.2017.7952585
   Chollet F., 2017, Deep Learning with Python
   Cotton CV, 2011, 2011 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS (WASPAA), P69, DOI 10.1109/ASPAA.2011.6082331
   Dai W, 2017, INT CONF ACOUST SPEE, P421, DOI 10.1109/ICASSP.2017.7952190
   Dieleman Sander, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6964, DOI 10.1109/ICASSP.2014.6854950
   Dimoulas C., 2012, 132 CONV AUD ENG SOC
   Fayek HM, 2017, NEURAL NETWORKS, V92, P60, DOI 10.1016/j.neunet.2017.02.013
   Garcia-Romero D, 2017, INT CONF ACOUST SPEE, P4930, DOI 10.1109/ICASSP.2017.7953094
   Gomez, 2014, ISMIR 2014
   Goyal, 2014, INT J INNOVATIVE RES, P2347
   Hall Mark, 2009, SIGKDD Explorations, V11, P10, DOI [10.1145/1656274.1656278, DOI 10.1145/1656274.1656278]
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Joder C, 2009, IEEE T AUDIO SPEECH, V17, P174, DOI 10.1109/TASL.2008.2007613
   Korvel G, 2018, J AUDIO ENG SOC, V66, P1072, DOI 10.17743/jaes.2018.0066
   KOSTEK B, 1999, STUD FUZZ SOFT COMP, V31, P1
   Kotsakis R, 2012, SPEECH COMMUN, V54, P743, DOI 10.1016/j.specom.2012.01.004
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lee J., 2017, SAMPLE LEVEL DEEP CO
   Lee J, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8010150
   LeNail A., 2019, J. Open Source Softw., V4, P747, DOI [DOI 10.21105/JOSS.00747, 10.21105/joss.00747]
   Lim W, 2016, ASIAPAC SIGN INFO PR, DOI 10.1109/APSIPA.2016.7820699
   Mathieu B., 2010, P INT SOC MUS INF RE, P441
   McKinney M., 2003, P ISMIR, P151
   Meng, 2006, THESIS
   Meng A, 2007, IEEE T AUDIO SPEECH, V15, P1654, DOI 10.1109/TASL.2007.899293
   Mitilineos SA, 2019, J AUDIO ENG SOC, V67, P27, DOI 10.17743/jaes.2018.0071
   Ntalampiras S, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/807162
   Palaz D, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P11
   Papanikolaou, 2017, MULTIMED TOOLS APPL, P1
   Papanikolaou, 2015, P MIREX 2015
   Papanikolaou G., 2013, 134 CONV AUD ENG SOC
   Piczak KJ, 2015, IEEE INT WORKS MACH
   Sainath TN, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1
   Salamon J, 2017, IEEE SIGNAL PROC LET, V24, P279, DOI 10.1109/LSP.2017.2657381
   Salamon J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1041, DOI 10.1145/2647868.2655045
   Salamon J, 2015, INT CONF ACOUST SPEE, P171, DOI 10.1109/ICASSP.2015.7177954
   Scalart P., 2014, 137 CONV AUD ENG SOC
   Schowe, 2011, P 2 RAP MIN COMM M C
   Shum SH, 2013, IEEE T AUDIO SPEECH, V21, P2015, DOI 10.1109/TASL.2013.2264673
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Slaney M, 2002, INT CONF ACOUST SPEE, P4108
   Thoidis I, 2019, 146TH AES CONVENTION
   Tsipas N, 2015, PROCEEDINGS OF THE 10TH AUDIO MOSTLY: A CONFERENCE ON INTERACTION WITH SOUND, AM'15, DOI 10.1145/2814895.2814907
   Vrysis L., 2017, 142 CONV AUD ENG SOC
   Vrysis L, 2019, 146TH AES CONVENTION
   Vrysis L, 2016, J AUDIO ENG SOC, V64, P1042, DOI 10.17743/jaes.2016.0051
   Vrysis L, 2015, PROCEEDINGS OF THE 10TH AUDIO MOSTLY: A CONFERENCE ON INTERACTION WITH SOUND, AM'15, DOI 10.1145/2814895.2814906
   Vryzas N, 2018, J AUDIO ENG SOC, V66, P457, DOI 10.17743/jaes.2018.0036
NR 54
TC 24
Z9 24
U1 1
U2 5
PU AUDIO ENGINEERING SOC
PI NEW YORK
PA 60 E 42ND ST, NEW YORK, NY 10165-2520 USA
SN 1549-4950
J9 J AUDIO ENG SOC
JI J. Audio Eng. Soc.
PD JAN-FEB
PY 2020
VL 68
IS 1-2
BP 66
EP 77
DI 10.17743/jaes.2019.0058
PG 12
WC Acoustics; Engineering, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Acoustics; Engineering
GA PS2WH
UT WOS:000607787600007
DA 2024-01-09
ER

PT J
AU Acquavella-Rauch, S
AF Acquavella-Rauch, Stefanie
TI Sound and Orchestration as a unifying Element of "romantic" Thinking
   between Symphony and Symphonic Poetry
SO MUSIKTHEORIE
LA German
DT Article
AB By investigating the connection between sound and romantic thinking, the text discusses how orchestration was used in various genres in the first half of the 19thcentury. Various compositional approaches were fine-tuned so that romantically-influenced ideas could be implemented through an actor-like nature of sound. This phenomenon can be found in opera, in Lieder, in piano transcriptions and ultimately in symphonic genres (symphony, concert overture, symphonic poem). After a short depiction of well-known factors like instrumental or structural compositional developments, the text describes music's potential in evoking emotions and enabling emotional insight into the innermost part of another human being. Well-planned orchestration in symphonic music is not only based on the use of special instruments, on an amalgamating treatment of wind, brass and string sections, on soloistic structures, or on an increasing use of new registers. Rather, orchestration also functions dramaturgically by giving the orchestra an additional voice.
C1 [Acquavella-Rauch, Stefanie] Johannes Gutenberg Univ Mainz, Mus Wissensch, Mainz, Germany.
   [Acquavella-Rauch, Stefanie] Univ Paderborn, Paderborn, Germany.
   [Acquavella-Rauch, Stefanie] Akad Wissensch, Verbindung, Mainz, Germany.
   [Acquavella-Rauch, Stefanie] Johannes Gutenberg Univ Mainz, Mainz, Germany.
C3 Johannes Gutenberg University of Mainz; University of Paderborn;
   Johannes Gutenberg University of Mainz
RP Acquavella-Rauch, S (corresponding author), Johannes Gutenberg Univ Mainz, Mus Wissensch, Mainz, Germany.; Acquavella-Rauch, S (corresponding author), Univ Paderborn, Paderborn, Germany.; Acquavella-Rauch, S (corresponding author), Akad Wissensch, Verbindung, Mainz, Germany.; Acquavella-Rauch, S (corresponding author), Johannes Gutenberg Univ Mainz, Mainz, Germany.
CR Acquavella-Rauch Stefanie, 2020, NEUE ANSDTZE SKIZZEN, V12, P143
   [Anonymous], 1826, SOMMERNACHTSTRAUM
   [Anonymous], 1833, ALLGEMEINEN MUSIKALI, V35, P59
   [Anonymous], 1841, GISELLE
   [Anonymous], 1809, ALLGEMEINEN MUSIKALI, V11, P267
   [Anonymous], 1832, LA SYLPHIDE
   [Anonymous], 2004, BARENREITER STUDIENB, V13, P17
   Aringer Klaus, 2007, TAGUNGSBERICHT DRESD, V8, P137
   Becker Alexander, 1966, M REGERS ORCHESTERBE, P9
   Becker Alexander, 2012, UNTERSUCHUNGEN INSTR, P5
   Becker Heinz, 1964, MUSIKWERK, V27, P29
   Becker Heinz, 2022, INSTRUMENTATION
   Bertagnolli PA, 2002, NINETEEN CENT MUSIC, V26, P23
   Burkholder J. Peter, 1905, MUSIK, V5, P168
   Burkholder J. Peter, 2019, HIST W MUSIC, P635
   Dahlhaus Carl., 1985, MUSIKFORSCHUNG, V38, P161
   Dahlhaus Carl, 1989, MUSIKTHEORIE 18 19JA
   Dahlhaus Carl, 1989, NEUES HDB MUSIKWISSE, V6, P13
   Döhring S, 2017, OSTERR MUSIKZ, V72, P56
   Dohring Sieghart, 1976, COULEUR LOCALE OPER, V42, P279
   Domokos Zsuzsanna, 1996, STUDIO MUSICOLOGICA, V37, P249
   Ehrle Thomas, 1983, NEUE MUSIKGESCHICHTL, V13, P12
   Erpf Hermann, 1959, LEHRBUCH INSTRUMENTA, P150
   Frangne Pierre -Henry, 2017, VALEUR EMOTION MUSIC
   Haine Malou, 2019, BERLIOZ POETE THEORI, V7, P45
   Hans, 1833, HANS HEILING
   Haraszti Emile, 1952, REV MUSICOL, V34, P81
   Henze-Dohring Sabine, 2007, SCHRIFTENREIHE HOCHS, V4, P83
   Herrmann Joachim, 1956, WESEN EINHEIT MUSIK, P56
   Hoffmanns Z.B, 1809, RITTER GLUCK
   Jost Peter, 2007, MUSIK UNTERRICHT, V86, P48
   Kampf Christian, 2021, NEUE SCHAUDER PHANTA, pXV
   Kapp Reinhard, 1982, MUSIK KONZEPTE SONDE, P232
   Keil Werner, 2012, MUSIKGESCHICHTE UBER, P174
   Kohler Siegfried, 1955, DISSERTATION, P1
   Krones Heinrich, 2005, INTERPRETATIONEN SEI, V2, P128
   Marschners Heinrich, 1828, VOMPYR
   Messwarb Katja, 1997, EUROPAISCHE HOCHSCHU, V171, P4
   Meyerbeer Ahnliches, 1831, ROBERT DIABLE
   Miller Norbert, 1987, PIPERS ENZYKLOPODIE, V2, P1
   Morelli Giovanni, 1986, DRAMMATURGIA MUSICAL, P411
   Rauch Stefanie, 2014, MUSIKTHEATER FOKUS, P329
   Reininghaus Frieder, 1998, MEYERBEER EUROPAISCH, V16, P288
   Solare Carlos Maria, 2009, WORT MUSIK, V70, P123
   Spohrs Louis, 1825, BERGGEIST
   STEINBECK W, 1984, ARCH MUSIKWISS, V41, P208, DOI 10.2307/930806
   Waczkat Andreas, 2012, LANDSCHAFT URN 1800, P227
   Webers, 1826, OBERON ELF KINGS OAT
NR 48
TC 0
Z9 0
U1 0
U2 0
PU LAABER-VERLAG
PI LAABER
PA REGENSBURGER STRASSE 19, W-8411 LAABER, GERMANY
SN 0177-4182
J9 MUSIKTHEORIE
JI Musiktheorie
PY 2022
VL 37
IS 4
BP 364
EP 375
PG 12
WC Music
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music
GA 6V4XR
UT WOS:000895053200007
DA 2024-01-09
ER

PT J
AU Pérez, HA
   Gallardo, FJG
AF Arredondo Perez, Herminia
   Garcia Gallardo, Francisco Jose
TI Seguidillas and Fandangos in the Colas of Alosno (Andalusia): Gender,
   Corporeality and Affect
SO RESONANCIAS
LA Spanish
DT Article
DE musical performance; gender; corporeality; affect; traditional music and
   dance; fandangos and seguidillas
AB This article explores the interaction between gender, corporeality and affect in a musical practice of a locality in Andalusia. As part of a broader research study, we focus on a special and paradigmatic context, a festive manifestation representative of traditional culture that still continues to live with great dynamism in this place. We examine how the celebration of the May Cross in the colas de Alosno (Huelva) puts into action roles, gender relations and ideas about sexuality, femininity and masculinity, together with collective experiences of community and place emotionally contextualized. The musical performance, the interpretation of the music and dance of seguidillas and fandangos in the embodied voice of the alosneros and alosneras, contributes in a privileged way to the articulation of meanings and experiences of identity and personal subjectivity of gender, to the construction of social values and local identity, in a climate of strong circulation of affect, pleasure and emotion.
C1 [Arredondo Perez, Herminia; Garcia Gallardo, Francisco Jose] Univ Huelva, Area Mus, Huelva, Spain.
C3 Universidad de Huelva
RP Pérez, HA (corresponding author), Univ Huelva, Area Mus, Huelva, Spain.
EM herminia@uhu.es; fgarcia@uhu.es
RI PEREZ, HERMINIA ARREDONDO/AAB-6592-2020; GALLARDO, FRANCISCO JOSE
   GARCIA/AAD-2865-2019
OI PEREZ, HERMINIA ARREDONDO/0000-0002-8694-5499; GALLARDO, FRANCISCO JOSE
   GARCIA/0000-0003-3106-1765
CR Alosno Orta Santiago, 1998, NARRIA ESTUDIOS ARTE, V81-84, P85
   [Anonymous], 1979, ESTACION AMOR FIESTA
   [Anonymous], 10 PALABRAS CLAVE MU
   [Anonymous], 1987, WOMEN MUSIC CROSS CU
   [Anonymous], LOS BAROJA
   Bader S, 2014, ETHNOMUSICOL FORUM, V23, P149, DOI 10.1080/17411912.2014.925641
   Bithell Caroline, 2003, Music and Gender: Perspectives from the Mediterranean, P33
   Blacking J., 1973, How Musical is Man
   Butler J., 1999, GENDER TROUBLE FEMIN
   Butler J., 2011, BODIES MATTER DISCUR
   Butler Judith., 1997, Excitable Speech: A Politics of the Performative
   Canterla Juan Francisco, 2012, COPLAS BAILES FANDAN
   Canterla Juan Francisco, 2014, FANDANGO HUELVA 1730
   Caro Baroja Julio, 1957, REV DIALECT TRAD POP, VXIII, P411
   Caro Baroja Julio, 1968, ESTUDIOS VIDA TRADIC
   Caro Baroja Julio, 1993, ETNOLOGIA ANDALUZA
   Cidra R, 2015, ETHNOMUSICOL FORUM, V24, P304, DOI 10.1080/17411912.2015.1070677
   Clayton M, 2012, CULTURAL STUDY OF MUSIC: A CRITICAL INTRODUCTION, 2ND EDITION, P1
   Clayton Martin, 2003, The Cultural Study of Music: A Critical Introduction, P204
   Cook Susan C., 1994, Cecilia Reclaimed: Feminist Perspectives on Gender and Music
   Davis Kathy, 2006, SAGE HDB GENDER WOME
   Del Campo Alberto, 2005, MAYO FESTERO RITUAL
   Diamond Beverley, 2013, PERFORMING GENDER PL, P185
   Dunn Leslie., 1994, EMBODIED VOICES REPR
   Eliade Mircea, 1985, MITO ETERNO RETORNO
   Evans Mary, 1997, INTRODUCCION PENSAMI
   Finnegan Ruth, 2003, The Cultural Study of Music: A Critical Introduction, P181
   Frenk Margit, 1978, ESTUDIOS LIRICA ANTI
   Gabe J., 2013, KEY CONCEPTS MED SOC
   Garcia Maximo, 2004, CRUCES MAYO ESPANA H, P21
   Garrido Palacios Manuel, 1992, ALOSNO PALABRA CANTA
   Garrido Palacios Manuel, 1996, CANCIONERO ALOSNO BA
   Gonzalez Palencia Angel, 1944, MAYA NOTAS ESTUDIO E
   HAKIM Catherine, 2012, CAPITAL EROTICO PODE
   Hanna Judith Lynne, 1988, DANCE SEX GENDER SIG
   Herdorn Marcia, 1990, MUSIC GENDER CULTURE
   de Madariaga CJ, 2011, GAZ ANTROPOL, V27
   Jimenez de Madariaga Celeste, 2015, PH B I ANDALUX PATRI, V88, P82
   Jimenez de Madariaga Celeste, 2004, CRUCES MAYO ESPANA T, P95
   Koskoff E, 2014, NEW PERSP GENDER MUS, P1
   Koskoff Ellen, 1987, WOMEN MUSICIN CROSS
   Lisardo Bowie Manuel, 1955, ARCH HISPALENSE, VXXII, P285
   Magowan F., 2013, PERFORMING GENDER PL
   Magrini Tullia, 2003, Music and Gender: perspectives from the Mediterranean
   McClary Susan, 1991, Feminine Endings: Music, Gender and Sexuality
   Merriam Alan P., 1964, The Anthropology of Music
   Moreno Isidoro, 2012, EXPRESIONES CULTURAL, P167
   Nettl Bruno, 1983, STUDY ETNOMUSICOLOGY
   Oakley Ann, 1972, Sex, gender, and society
   Ortner S. B., 1981, Sexual meanings, the Cultural construction of Gender and Sexuality
   Ortner Sherry B., 1974, Woman, Culture and Society, DOI DOI 10.2307/3177638
   Pelinski Ramon, 2000, INVITACION ETNOMUSIC
   RICE T, 1987, ETHNOMUSICOLOGY, V31, P469, DOI 10.2307/851667
   Rodriguez Becerra Salvador, 1999, ANTROPOLOGIA FIESTA, P45
   Rodriguez Becerra Salvador, 2004, CRUCES MAYO ESPANA T, P57
   Romero Manuel, 2002, ESTE OTRO CANTAR VOC
   Solie Ruth A., 1993, Musicology and Difference
   Sugarman Jane, 2003, MUSIC GENDER PERSPEC, P87
   Taylor D., 2011, Estudios avanzados de performance, P7
   Tolbert E., 1994, EMBODIED VOICES REPR, P179
   Turner Victor, 1988, El proceso ritual
   Velasco Honorio M., 1982, TIEMPO FIESTA ENSAYO, P169
   Wetherell M., 2012, Affect and emotion. A new social science understanding
   Woodward Kathleen, 2015, INTRO GENDER WOMENS, P97
NR 64
TC 0
Z9 0
U1 0
U2 0
PU PONTIFICIA UNIV CATOLICA CHILE
PI SANTIAGO
PA AVENIDA VICUNA MACKENNA 4860, MACUL, SANTIAGO, 00000, CHILE
SN 0717-3474
EI 0719-5702
J9 RESONANCIAS
JI Resonancias
PD JUL-NOV
PY 2018
VL 22
IS 43
BP 83
EP 112
PG 30
WC Music
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music
GA HC5XX
UT WOS:000451876800005
DA 2024-01-09
ER

PT J
AU Frühholz, S
   Staib, M
AF Fruehholz, Sascha
   Staib, Matthias
TI Neurocircuitry of impaired affective sound processing: A clinical
   disorders perspective
SO NEUROSCIENCE AND BIOBEHAVIORAL REVIEWS
LA English
DT Review
DE Affect; Auditory; Psychiatric disorders; Neurological disorders; Neural
   network; Amygdala
ID AUTISM SPECTRUM DISORDERS; SUPERIOR TEMPORAL SULCUS; ANTERIOR CINGULATE
   CORTEX; HIGH-FUNCTIONING AUTISM; PARKINSONS-DISEASE; EMOTIONAL PROSODY;
   CHILDHOOD AUTISM; ACOUSTIC FEATURES; VOCAL EXPRESSIONS; MUSICAL EMOTIONS
AB Decoding affective meaning from sensory information is central to accurate and adaptive behavior in many natural and social contexts. Human vocalizations (speech and non-speech), environmental sounds (e.g. thunder, noise, or animal sounds) and human-produced sounds (e.g. technical sounds or music) can carry a wealth of important aversive, threatening, appealing, or pleasurable affective information that sometimes 'implicitly influences and guides our behavior. A deficit in processing such affective information is detrimental to adaptive environmental behavior, psychological well-being, and social interactive abilities. These deficits can originate from a diversity of psychiatric and neurological disorders, and are associated with neural dysfunctions across largely distributed brain networks. Recent neuroimaging studies in psychiatric and neurological patients outline the cortical and subcortical neurocircuitry of the complimentary and differential functional roles for affective sound processing. This points to and confirms a recently proposed distributed network rather than a single brain region underlying affective sound processing, and highlights the notion of a multi-functional process that can be differentially impaired in clinical disorders.
C1 [Fruehholz, Sascha; Staib, Matthias] Univ Zurich, Dept Psychol, Binzmuhlestr 14,Box 18, Zurich, Switzerland.
   [Fruehholz, Sascha; Staib, Matthias] Univ Zurich, Neurosci Ctr Zurich, Zurich, Switzerland.
   [Fruehholz, Sascha; Staib, Matthias] ETH, Zurich, Switzerland.
   [Fruehholz, Sascha] Univ Zurich, Ctr Integrat Human Physiol ZIHP, Zurich, Switzerland.
C3 University of Zurich; University of Zurich; Swiss Federal Institutes of
   Technology Domain; ETH Zurich; University of Zurich; Zurich Center
   Integrative Human Physiology (ZIHP)
RP Frühholz, S (corresponding author), Univ Zurich, Dept Psychol, Binzmuhlestr 14,Box 18, Zurich, Switzerland.
EM sascha.fruehholz@uzh.ch
RI Frühholz, Sascha/E-9194-2013
OI Staib, Matthias/0000-0001-9688-838X; Fruhholz,
   Sascha/0000-0002-6485-3817
FU Swiss National Science Foundation [SNSF PP00P1_157409/1]
FX S.F. and M.S. were supported by a grant from the Swiss National Science
   Foundation (SNSF PP00P1_157409/1).
CR Abrams DA, 2013, P NATL ACAD SCI USA, V110, P12060, DOI 10.1073/pnas.1302982110
   Adolphs R, 1999, NEUROPSYCHOLOGIA, V37, P1285, DOI 10.1016/S0028-3932(99)00023-8
   Alba-Ferrara L, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00059
   Alba-Ferrara L, 2012, BRAIN STIMUL, V5, P347, DOI 10.1016/j.brs.2011.06.004
   Alpeit Alpeit M.I., 1989, ADV CONSUM RES, V16, P485
   Amodio DM, 2006, NAT REV NEUROSCI, V7, P268, DOI 10.1038/nrn1884
   Anderson AK, 1998, NEUROREPORT, V9, P3607
   Ariatti A, 2008, NEUROL SCI, V29, P219, DOI 10.1007/s10072-008-0971-9
   Aust S, 2013, WORLD J PSYCHIATR, V3, P8, DOI 10.5498/wjp.v3.i2.8
   Bach DR, 2009, PSYCHOL MED, V39, P927, DOI 10.1017/S0033291708004704
   Bach DR, 2013, NEUROPSYCHOLOGIA, V51, P2070, DOI 10.1016/j.neuropsychologia.2013.07.005
   Bach DR, 2011, SCHIZOPHRENIA BULL, V37, P426, DOI 10.1093/schbul/sbp092
   Bach DR, 2009, SCHIZOPHR RES, V110, P180, DOI 10.1016/j.schres.2009.02.011
   Baranek GT, 2007, AM J MENT RETARD, V112, P233, DOI 10.1352/0895-8017(2007)112[233:HSPIYC]2.0.CO;2
   Baron-Cohen S, 2000, NEUROSCI BIOBEHAV R, V24, P355, DOI 10.1016/S0149-7634(00)00011-7
   Bhatara A, 2010, AUTISM RES, V3, P214, DOI 10.1002/aur.147
   Boddaert N, 2004, NEUROIMAGE, V23, P364, DOI 10.1016/j.neuroimage.2004.06.016
   Boddaert N, 2002, PEDIATR RADIOL, V32, P1, DOI 10.1007/s00247-001-0570-x
   Bodner E, 2012, J PSYCHOPATHOL BEHAV, V34, P458, DOI 10.1007/s10862-012-9304-7
   Bottiroli S, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00284
   Bowers D, 2006, BRAIN, V129, P3356, DOI 10.1093/brain/awl301
   Breitenstein C, 2001, BRAIN COGNITION, V45, P277, DOI 10.1006/brcg.2000.1246
   Brierley B, 2004, J NEUROL NEUROSUR PS, V75, P593, DOI 10.1136/jnnp.2002.006403
   Brück C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019140
   Buxton SL, 2013, BEHAV NEUROSCI, V127, P193, DOI 10.1037/a0032013
   Calder AJ, 2004, BRAIN, V127, P1958, DOI 10.1093/brain/awh214
   Calder AJ, 2001, NAT REV NEUROSCI, V2, P352, DOI 10.1038/35072584
   Caria A, 2011, CEREB CORTEX, V21, P2838, DOI 10.1093/cercor/bhr084
   Connolly CG, 2013, BIOL PSYCHIAT, V74, P898, DOI 10.1016/j.biopsych.2013.05.036
   Dara C, 2008, BRAIN RES, V1188, P100, DOI 10.1016/j.brainres.2007.10.034
   de Jong JJ, 2009, SCHIZOPHR RES, V107, P286, DOI 10.1016/j.schres.2008.10.001
   Di Martino A, 2009, BIOL PSYCHIAT, V65, P63, DOI 10.1016/j.biopsych.2008.09.022
   Dimoska A, 2010, J INT NEUROPSYCH SOC, V16, P369, DOI 10.1017/S1355617709991445
   Doyle-Thomas Krissy A R, 2013, Front Psychiatry, V4, P48, DOI 10.3389/fpsyt.2013.00048
   Drevets WC, 2008, CNS SPECTRUMS, V13, P663, DOI 10.1017/S1092852900013754
   Dricu M, 2016, NEUROSCI BIOBEHAV R, V71, P810, DOI 10.1016/j.neubiorev.2016.10.020
   Ethofer T, 2012, CEREB CORTEX, V22, P191, DOI 10.1093/cercor/bhr113
   Fatemi SH, 2012, CEREBELLUM, V11, P777, DOI 10.1007/s12311-012-0355-9
   Freeman TW, 2009, J NEUROPSYCH CLIN N, V21, P52, DOI 10.1176/appi.neuropsych.21.1.52
   Frühholz S, 2015, NEUROIMAGE, V109, P27, DOI 10.1016/j.neuroimage.2015.01.016
   Frühholz S, 2015, P NATL ACAD SCI USA, V112, P1583, DOI 10.1073/pnas.1411315112
   Frühholz S, 2014, PROG NEUROBIOL, V123, P1, DOI 10.1016/j.pneurobio.2014.09.003
   Fruehholz S, 2013, NEUROSCI BIOBEHAV R, V37, P2847, DOI 10.1016/j.neubiorev.2013.10.007
   Frühholz S, 2012, NEUROIMAGE, V62, P1658, DOI 10.1016/j.neuroimage.2012.06.015
   Frühholz S, 2012, CEREB CORTEX, V22, P1107, DOI 10.1093/cercor/bhr184
   Fruhholz S., 2017, BRAIN STRUCT FUNCT
   Frühholz S, 2016, SOC COGN AFFECT NEUR, V11, P1638, DOI 10.1093/scan/nsw066
   Frühholz S, 2016, NEUROSCI BIOBEHAV R, V68, P96, DOI 10.1016/j.neubiorev.2016.05.002
   Furman DJ, 2011, BIOL MOOD ANXIETY DI, V1, DOI 10.1186/2045-5380-1-11
   Gabbay V, 2013, J AM ACAD CHILD PSY, V52, P628, DOI 10.1016/j.jaac.2013.04.003
   Gaigg SB, 2007, NEUROPSYCHOLOGIA, V45, P2125, DOI 10.1016/j.neuropsychologia.2007.01.012
   Garrido-Vásquez P, 2013, SOC COGN AFFECT NEUR, V8, P918, DOI 10.1093/scan/nss094
   Garrido-Vásquez P, 2011, SOC NEUROSCI-UK, V6, P515, DOI 10.1080/17470919.2011.620771
   Gervais H, 2004, NAT NEUROSCI, V7, P801, DOI 10.1038/nn1291
   Golan O, 2006, DEV PSYCHOPATHOL, V18, P591, DOI 10.1017/S0954579406060305
   Golan O, 2007, J AUTISM DEV DISORD, V37, P1096, DOI 10.1007/s10803-006-0252-5
   Gold R, 2012, AM J PSYCHIAT, V169, P424, DOI 10.1176/appi.ajp.2011.11081230
   Gomot M, 2008, BRAIN, V131, P2479, DOI 10.1093/brain/awn172
   Gosselin N, 2011, CORTEX, V47, P1116, DOI 10.1016/j.cortex.2011.05.012
   Grandjean D, 2008, NEUROPSYCHOLOGIA, V46, P487, DOI 10.1016/j.neuropsychologia.2007.08.025
   Green SA, 2013, J AM ACAD CHILD PSY, V52, P1158, DOI 10.1016/j.jaac.2013.08.004
   Groen W, 2008, J AUTISM DEV DISORD, V38, P1819, DOI 10.1007/s10803-008-0572-8
   Hajek T, 2008, J PSYCHIATR NEUROSCI, V33, P91
   Hatada S, 2014, J PSYCHIATR NEUROSCI, V39, P118, DOI 10.1503/jpn.120207
   Hesling I, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011571
   Ho TC, 2014, J AFFECT DISORDERS, V155, P65, DOI 10.1016/j.jad.2013.10.025
   Hsieh S, 2012, NEUROPSYCHOLOGIA, V50, P1814, DOI 10.1016/j.neuropsychologia.2012.04.006
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kanske P, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030086
   Kantrowitz JT, 2013, SCHIZOPHRENIA BULL, V39, P86, DOI 10.1093/schbul/sbr060
   Khalfa S, 2008, NEUROPSYCHOLOGIA, V46, P2485, DOI 10.1016/j.neuropsychologia.2008.04.009
   Kotz SA, 2010, TRENDS COGN SCI, V14, P392, DOI 10.1016/j.tics.2010.06.005
   Kucharska-Pietura K, 2005, BRIT J PSYCHIAT, V187, P523, DOI 10.1192/bjp.187.6.523
   Kumar S, 2012, J NEUROSCI, V32, P14184, DOI 10.1523/JNEUROSCI.1759-12.2012
   LABAR KS, 1995, J NEUROSCI, V15, P6846
   LALANDE S, 1992, BRAIN LANG, V42, P165, DOI 10.1016/0093-934X(92)90123-V
   Leitman DI, 2007, AM J PSYCHIAT, V164, P474, DOI 10.1176/appi.ajp.164.3.474
   Leitman DI, 2011, FRONT HUM NEUROSCI, V5, DOI [10.3389/fnhum.2011.00096, 10.3389/fnhum.2010.00019]
   Leitman DI, 2011, BIOL PSYCHIAT, V70, P611, DOI 10.1016/j.biopsych.2011.05.032
   Leitman DI, 2010, SCHIZOPHRENIA BULL, V36, P545, DOI 10.1093/schbul/sbn115
   Leitman DI, 2005, BIOL PSYCHIAT, V58, P56, DOI 10.1016/j.biopsych.2005.02.034
   Lima CF, 2013, J CLIN EXP NEUROPSYC, V35, P373, DOI 10.1080/13803395.2013.776518
   Loveland KA, 2008, PERCEPT MOTOR SKILL, V107, P557, DOI 10.2466/PMS.107.2.557-575
   Marco EJ, 2011, PEDIATR RES, V69, p48R, DOI [10.1203/PDR.0b013e3182130c54, 10.1109/SPL.2011.5782616]
   Markram K, 2008, NEUROPSYCHOPHARMACOL, V33, P901, DOI 10.1038/sj.npp.1301453
   Milesi V, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00275
   Mitchell RLC, 2004, BRIT J PSYCHIAT, V184, P223, DOI 10.1192/bjp.184.3.223
   Molnar-Szakacs I, 2012, ANN NY ACAD SCI, V1252, P318, DOI 10.1111/j.1749-6632.2012.06465.x
   Mottron L, 2006, J AUTISM DEV DISORD, V36, P27, DOI 10.1007/s10803-005-0040-7
   Müller RA, 1999, J AUTISM DEV DISORD, V29, P19, DOI 10.1023/A:1025914515203
   Naranjo C, 2011, J AFFECT DISORDERS, V128, P243, DOI 10.1016/j.jad.2010.06.039
   Nestler EJ, 2002, NEURON, V34, P13, DOI 10.1016/S0896-6273(02)00653-0
   Nikolova ZT, 2011, EUR J NEUROL, V18, P329, DOI 10.1111/j.1468-1331.2010.03144.x
   Öhman A, 2001, PSYCHOL REV, V108, P483, DOI 10.1037//0033-295X.108.3.483
   Ohnishi T, 2000, BRAIN, V123, P1838, DOI 10.1093/brain/123.9.1838
   Omar R, 2011, NEUROIMAGE, V56, P1814, DOI 10.1016/j.neuroimage.2011.03.002
   Omar R, 2010, BRAIN, V133, P1200, DOI 10.1093/brain/awp345
   Orekhova EV, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0039906
   Osuch EA, 2009, NEUROREPORT, V20, P1204, DOI 10.1097/WNR.0b013e32832f4da3
   Ouimet T, 2012, ANN NY ACAD SCI, V1252, P325, DOI 10.1111/j.1749-6632.2012.06453.x
   Pannese A, 2016, CORTEX, V85, P116, DOI 10.1016/j.cortex.2016.10.013
   Pannese A, 2015, HEARING RES, V328, P67, DOI 10.1016/j.heares.2015.07.003
   Patel S, 2011, BIOL PSYCHOL, V87, P93, DOI 10.1016/j.biopsycho.2011.02.010
   Paulmann S, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017694
   Paulmann S, 2009, BRAIN RES, V1295, P159, DOI 10.1016/j.brainres.2009.07.102
   Péron J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090092
   Péron J, 2012, MOVEMENT DISORD, V27, P186, DOI 10.1002/mds.24025
   Punkanen M, 2011, J AFFECT DISORDERS, V130, P118, DOI 10.1016/j.jad.2010.10.034
   Quadflieg S, 2008, BIOL PSYCHOL, V78, P129, DOI 10.1016/j.biopsycho.2008.01.014
   Ramdoss S, 2012, DEV NEUROREHABIL, V15, P119, DOI 10.3109/17518423.2011.651655
   Redcay E, 2008, NEUROSCI BIOBEHAV R, V32, P123, DOI 10.1016/j.neubiorev.2007.06.004
   Reker P, 2014, J AFFECT DISORDERS, V156, P150, DOI 10.1016/j.jad.2013.12.010
   Rohrer JD, 2012, CORTEX, V48, P308, DOI 10.1016/j.cortex.2010.09.004
   Rosenblau G, 2017, SOC COGN AFFECT NEUR, V12, P224, DOI 10.1093/scan/nsw118
   Ross ED, 2008, BRAIN LANG, V104, P51, DOI 10.1016/j.bandl.2007.04.007
   Ross ED, 2011, NEUROPSYCHOLOGIA, V49, P866, DOI 10.1016/j.neuropsychologia.2010.12.024
   Rushworth MFS, 2007, TRENDS COGN SCI, V11, P168, DOI 10.1016/j.tics.2007.01.004
   Saenz A, 2013, EUR J NEUROL, V20, P571, DOI 10.1111/ene.12040
   Saitovitch A, 2012, REV NEUROL-FRANCE, V168, P762, DOI 10.1016/j.neurol.2012.07.017
   Salimpoor VN, 2013, SCIENCE, V340, P216, DOI 10.1126/science.1231059
   Salimpoor VN, 2011, NAT NEUROSCI, V14, P257, DOI 10.1038/nn.2726
   Savitz J, 2009, NEUROSCI BIOBEHAV R, V33, P699, DOI 10.1016/j.neubiorev.2009.01.004
   Schmahmann JD, 1998, BRAIN, V121, P561, DOI 10.1093/brain/121.4.561
   Schröder C, 2010, J NEUROL SCI, V289, P32, DOI 10.1016/j.jns.2009.08.038
   Scott SK, 1997, NATURE, V385, P254, DOI 10.1038/385254a0
   Seeley WW, 2007, J NEUROSCI, V27, P2349, DOI 10.1523/JNEUROSCI.5587-06.2007
   Sergerie K, 2008, NEUROSCI BIOBEHAV R, V32, P811, DOI 10.1016/j.neubiorev.2007.12.002
   Shih P, 2011, BIOL PSYCHIAT, V70, P270, DOI 10.1016/j.biopsych.2011.03.040
   Spreng RN, 2009, J COGNITIVE NEUROSCI, V21, P489, DOI 10.1162/jocn.2008.21029
   Sprengelmeyer R, 1999, P ROY SOC B-BIOL SCI, V266, P2451, DOI 10.1098/rspb.1999.0945
   Stewart L, 2006, BRAIN, V129, P2533, DOI 10.1093/brain/awl171
   Tesink CMJY, 2009, BRAIN, V132, P1941, DOI 10.1093/brain/awp103
   Trost W, 2015, SOC COGN AFFECT NEUR, V10, P1705, DOI 10.1093/scan/nsv060
   Trost W, 2014, NEUROIMAGE, V103, P55, DOI 10.1016/j.neuroimage.2014.09.009
   van Tricht MJ, 2010, BRAIN COGNITION, V74, P58, DOI 10.1016/j.bandc.2010.06.005
   Ventura MI, 2012, NEUROPSYCHOLOGIA, V50, P1936, DOI 10.1016/j.neuropsychologia.2012.04.018
   Wang AT, 2007, ARCH GEN PSYCHIAT, V64, P698, DOI 10.1001/archpsyc.64.6.698
   Zilbovicius M, 2000, AM J PSYCHIAT, V157, P1988, DOI 10.1176/appi.ajp.157.12.1988
   Zilbovicius M, 2006, TRENDS NEUROSCI, V29, P359, DOI 10.1016/j.tins.2006.06.004
NR 139
TC 10
Z9 11
U1 0
U2 27
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0149-7634
EI 1873-7528
J9 NEUROSCI BIOBEHAV R
JI Neurosci. Biobehav. Rev.
PD DEC
PY 2017
VL 83
BP 516
EP 524
DI 10.1016/j.neubiorev.2017.09.009
PG 9
WC Behavioral Sciences; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Behavioral Sciences; Neurosciences & Neurology
GA FR9UN
UT WOS:000419418700044
PM 28919431
OA hybrid
DA 2024-01-09
ER

PT J
AU Huang, JL
AF Huang, Jingle
TI Analysis of Different Keying Modes and Brain Sound Image Establishment
   Mode in Piano Playing
SO WIRELESS COMMUNICATIONS & MOBILE COMPUTING
LA English
DT Article
ID VOCAL MELODIES; TIMBRE
AB The piano is known as the king of musical instruments for its rich expressiveness. Pianists get rich emotion with tone control. Touch key mode is the primary method of tone control. The purpose of this paper is to conduct research and analysis on different keying modes and brain-sound image establishment modes in piano performance. In this paper, we first propose a fuzzy mathematical proximity comparison method and an audio feature extraction method. Most of the audio features are derived from speech recognition tasks. They can reduce the original waveform sampling signal, thereby accelerating the machine's understanding of the semantic meaning of audio. Using comparative analysis method, fuzzy mathematical proximity comparison method, and audio feature extraction as research methods, a model analysis research model based on different key touch methods in piano playing was established, and the relationship between piano key touch and brain sound image was studied. The experimental results of this paper show that after using the research method in this paper, the error rate of the data is controlled within 5%. Compared with previous research methods, the error rate is lower and has certain practical value.
C1 [Huang, Jingle] Zhengzhou Normal Univ, Coll Mus & Dance, Zhengzhou 475000, Henan, Peoples R China.
C3 Zhengzhou Normal University
RP Huang, JL (corresponding author), Zhengzhou Normal Univ, Coll Mus & Dance, Zhengzhou 475000, Henan, Peoples R China.
EM hjl@zznu.edu.cn
CR Anderson B.E., 2016, J ACOUST SOC AM, V139, P2180, DOI [10.1121/1.4950482, DOI 10.1121/1.4950482]
   Baume C, 2015, J AUDIO ENG SOC, V63, P203
   Carney LH, 2015, ENEURO, V2, DOI 10.1523/ENEURO.0004-15.2015
   Cazau D, 2015, J ACOUST SOC AM, V138, P2561, DOI 10.1121/1.4932584
   Chau CJ, 2015, J AUDIO ENG SOC, V63, P228, DOI 10.17743/jaes.2015.0016
   Chen YT, 2019, MATHEMATICS-BASEL, V7, DOI 10.3390/math7010019
   Giordano N, 2015, J ACOUST SOC AM, V138, P2359, DOI 10.1121/1.4931439
   Haselböck L, 2016, STUD MUSICOL, V57, P61, DOI 10.1556/6.2016.57.1-2.5
   Hsiao CJ, 2016, NEUROREPORT, V27, P923, DOI 10.1097/WNR.0000000000000633
   Judge JA, 2017, TOPOI-INT REV PHILOS, V36, P319, DOI 10.1007/s11245-014-9298-8
   Khalaf OI, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/6297856
   Lahdelma I, 2016, PSYCHOL MUSIC, V44, P37, DOI 10.1177/0305735614552006
   Langlois T., 2015, J VISION, V15, P853, DOI [10.1167/15.12.853, DOI 10.1167/15.12.853]
   Matter SS, 2015, MUSICA HODIE, V15, P31
   Olsen KN, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0167643
   Plaisier MA, 2017, J EXP PSYCHOL HUMAN, V43, P741, DOI 10.1037/xhp0000345
   Prentiss SM, 2015, J AM ACAD AUDIOL, V26, P494, DOI 10.3766/jaaa.14098
   Rowe M., 2015, CEUR WORKSHOP PROC, P121
   Schellenberg EG, 2015, MEM COGNITION, V43, P1021, DOI 10.3758/s13421-015-0519-1
   Siedlecka B, 2015, ACTA BIOENG BIOMECH, V17, P95, DOI 10.5277/ABB-00150-2014-03
   Sun H, 2016, J APPL PHYS, V120, DOI 10.1063/1.4959209
   Suryanarayana G, 2021, IEEE ACCESS, V9, P71406, DOI 10.1109/ACCESS.2021.3077611
   Trevino J, 2015, COMPUT MUSIC J, V39, P92, DOI 10.1162/COMJ_r_00317
   Wang B, 2020, OPTIK, V224, DOI 10.1016/j.ijleo.2020.165476
   Weiss MW, 2015, Q J EXP PSYCHOL, V68, P866, DOI 10.1080/17470218.2015.1020818
   Weiss MW, 2015, DEV PSYCHOL, V51, P370, DOI 10.1037/a0038784
   Williams D., 2017, COMPUT ENTERTAIN, V14
   Williams D, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/3059005
   Xiao GN, 2019, IEEE ACCESS, V7, P116741, DOI 10.1109/ACCESS.2019.2936443
   Zhang Y., 2018, J ACOUST SOC AM, V143, P1962, DOI [10.1121/1.5036450, DOI 10.1121/1.5036450]
NR 30
TC 0
Z9 0
U1 3
U2 5
PU WILEY-HINDAWI
PI LONDON
PA ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND
SN 1530-8669
EI 1530-8677
J9 WIREL COMMUN MOB COM
JI Wirel. Commun. Mob. Comput.
PD APR 11
PY 2022
VL 2022
AR 6713468
DI 10.1155/2022/6713468
PG 8
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA 1W1AR
UT WOS:000806513000007
OA gold
DA 2024-01-09
ER

PT J
AU Zatorre, RJ
   Baum, SR
AF Zatorre, Robert J.
   Baum, Shari R.
TI Musical Melody and Speech Intonation: Singing a Different Tune?
SO PLOS BIOLOGY
LA English
DT Article
ID HUMAN BRAIN-STEM; AUDITORY-CORTEX; FUNCTIONAL-ANATOMY; CONGENITAL
   AMUSIA; PITCH; LANGUAGE; PERCEPTION; COMPONENTS; NETWORK; PROSODY
AB Music and speech are often cited as characteristically human forms of communication. Both share the features of hierarchical structure, complex sound systems, and sensorimotor sequencing demands, and both are used to convey and influence emotions, among other functions [1]. Both music and speech also prominently use acoustical frequency modulations, perceived as variations in pitch, as part of their communicative repertoire. Given these similarities, and the fact that pitch perception and production involve the same peripheral transduction system (cochlea) and the same production mechanism (vocal tract), it might be natural to assume that pitch processing in speech and music would also depend on the same underlying cognitive and neural mechanisms. In this essay we argue that the processing of pitch information differs significantly for speech and music; specifically, we suggest that there are two pitch-related processing systems, one for more coarse-grained, approximate analysis and one for more fine-grained accurate representation, and that the latter is unique to music. More broadly, this dissociation offers clues about the interface between sensory and motor systems, and highlights the idea that multiple processing streams are a ubiquitous feature of neuro-cognitive architectures.
C1 [Zatorre, Robert J.] McGill Univ, Montreal Neurol Inst, Montreal, PQ, Canada.
   [Zatorre, Robert J.; Baum, Shari R.] McGill Univ, Ctr Res Brain Language & Mus, Montreal, PQ, Canada.
   [Baum, Shari R.] McGill Univ, Sch Commun Sci & Disorders, Montreal, PQ, Canada.
C3 McGill University; McGill University; McGill University
RP Zatorre, RJ (corresponding author), McGill Univ, Montreal Neurol Inst, Montreal, PQ, Canada.
EM robert.zatorre@mcgill.ca
FU Canadian Institutes of Health Research; Natural Sciences and Engineering
   Research Council of Canada; Canada Fund for Innovation; Government of
   Quebec via the Fonds de Recherche Nature et Technologies; Societe et
   Culture
FX We thank Andrea Halpern and Marc Bouffard for assistance in construction
   of the figures and sound examples. The authors' research is funded via
   the Canadian Institutes of Health Research, the Natural Sciences and
   Engineering Research Council of Canada, and the Canada Fund for
   Innovation. The Centre is funded by the Government of Quebec via the
   Fonds de Recherche Nature et Technologies and Societe et Culture.
CR Ayotte J, 2002, BRAIN, V125, P238, DOI 10.1093/brain/awf028
   Bidelman GM, 2011, J COGNITIVE NEUROSCI, V23, P425, DOI 10.1162/jocn.2009.21362
   Binns C, 2007, J ACOUST SOC AM, V122, P1765, DOI 10.1121/1.2751394
   Deutsch D, 2011, J ACOUST SOC AM, V129, P2245, DOI 10.1121/1.3562174
   DOWLING WJ, 1978, PSYCHOL REV, V85, P341, DOI 10.1037/0033-295X.85.4.341
   Fitch WT, 2005, ANN NY ACAD SCI, V1060, P29, DOI 10.1196/annals.1360.004
   Hauser MD, 2003, NAT NEUROSCI, V6, P663, DOI 10.1038/nn1080
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hutchins S, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00236
   Hyde KL, 2004, PSYCHOL SCI, V15, P356, DOI 10.1111/j.0956-7976.2004.00683.x
   Hyde KL, 2008, NEUROPSYCHOLOGIA, V46, P632, DOI 10.1016/j.neuropsychologia.2007.09.004
   Hyde KL, 2007, J NEUROSCI, V27, P13028, DOI 10.1523/JNEUROSCI.3039-07.2007
   Hyde KL, 2011, CEREB CORTEX, V21, P292, DOI 10.1093/cercor/bhq094
   Kleber B, 2010, CEREB CORTEX, V20, P1144, DOI 10.1093/cercor/bhp177
   Koelsch S, 2002, NEUROIMAGE, V17, P956, DOI 10.1016/S1053-8119(02)91154-7
   Krishnan A, 2005, COGNITIVE BRAIN RES, V25, P161, DOI 10.1016/j.cogbrainres.2005.05.004
   Krumhansl C.L., 1990, COGNITIVE FDN MUSICA
   Lee YS, 2011, NEUROIMAGE, V57, P293, DOI 10.1016/j.neuroimage.2011.02.006
   Loui P, 2009, J NEUROSCI, V29, P10215, DOI 10.1523/JNEUROSCI.1701-09.2009
   Maess B, 2001, NAT NEUROSCI, V4, P540, DOI 10.1038/87502
   Miller SE, 2010, J ACOUST SOC AM, V128, P435, DOI 10.1121/1.3397384
   Musacchia G, 2007, P NATL ACAD SCI USA, V104, P15894, DOI 10.1073/pnas.0701498104
   Nicholson KG, 2002, NEUROCASE, V8, P314, DOI 10.1076/neur.8.3.314.16195
   Özdemir E, 2006, NEUROIMAGE, V33, P628, DOI 10.1016/j.neuroimage.2006.07.013
   Patel A. D., 2008, Music, Language, and the Brain
   Patel AD, 1998, BRAIN LANG, V61, P123, DOI 10.1006/brln.1997.1862
   Patel AD, 2010, P SPEECH PROS MAY 11
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Pell MD, 2006, BRAIN LANG, V96, P221, DOI 10.1016/j.bandl.2005.04.007
   Peretz I, 1999, NEUROCASE, V5, P21, DOI 10.1093/neucas/5.1.21
   PERETZ I, 1994, BRAIN, V117, P1283, DOI 10.1093/brain/117.6.1283
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rogalsky C, 2011, J NEUROSCI, V31, P3843, DOI 10.1523/JNEUROSCI.4515-10.2011
   Ross D, 2007, P NATL ACAD SCI USA, V104, P9852, DOI 10.1073/pnas.0703140104
   ROSS ED, 1981, ARCH NEUROL-CHICAGO, V38, P561, DOI 10.1001/archneur.1981.00510090055006
   Schön D, 2010, NEUROIMAGE, V51, P450, DOI 10.1016/j.neuroimage.2010.02.023
   Schönwiesner M, 2005, EUR J NEUROSCI, V22, P1521, DOI 10.1111/j.1460-9568.2005.04315.x
   Schwartz DA, 2003, J NEUROSCI, V23, P7160, DOI 10.1523/JNEUROSCI.23-18-07160.2003
   Stewart L, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0001470
   Tillmann B, 2003, COGNITIVE BRAIN RES, V16, P145, DOI 10.1016/S0926-6410(02)00245-8
   Tillmann B, 2011, J ACOUST SOC AM, V130, P4089, DOI 10.1121/1.3658447
   TRAINOR LJ, 1992, J EXP PSYCHOL HUMAN, V18, P394, DOI 10.1037/0096-1523.18.2.394
   Warrier CM, 2002, PERCEPT PSYCHOPHYS, V64, P198, DOI 10.3758/BF03195786
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   Zarate JM, 2008, NEUROIMAGE, V40, P1871, DOI 10.1016/j.neuroimage.2008.01.026
   Zatorre RJ, 2002, TRENDS COGN SCI, V6, P37, DOI 10.1016/S1364-6613(00)01816-7
NR 46
TC 108
Z9 119
U1 1
U2 48
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1544-9173
EI 1545-7885
J9 PLOS BIOL
JI PLoS. Biol.
PD JUL
PY 2012
VL 10
IS 7
AR e1001372
DI 10.1371/journal.pbio.1001372
PG 6
WC Biochemistry & Molecular Biology; Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Life Sciences & Biomedicine - Other
   Topics
GA 984AX
UT WOS:000307161000013
PM 22859909
OA gold, Green Submitted, Green Published
DA 2024-01-09
ER

PT J
AU Nikolsky, A
AF Nikolsky, Aleksey
TI The Pastoral Origin of Semiotically Functional Tonal Organization of
   Music
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE tonal organization; animal communication; honest signal; semiosis;
   aspects of expression; domestication; kulning vs; yodel; motherese
ID MOTIVATION-STRUCTURAL RULES; LACTASE-PERSISTENCE; DOG DOMESTICATION;
   INFANTS CRIES; EVOLUTION; PERCEPTION; LANGUAGE; PITCH; EMOTIONS;
   PERFORMANCE
AB This paper presents a new line of inquiry into when and how music as a semiotic system was born. Eleven principal expressive aspects of music each contains specific structural patterns whose configuration signifies a certain affective state. This distinguishes the tonal organization of music from the phonetic and prosodic organization of natural languages and animal communication. The question of music's origin can therefore be answered by establishing the point in human history at which all eleven expressive aspects might have been abstracted from the instinct-driven primate calls and used to express human psycho-emotional states. Etic analysis of acoustic parameters is the prime means of cross-examination of the typical patterns of expression of the basic emotions in human music versus animal vocal communication. A new method of such analysis is proposed here. Formation of such expressive aspects as meter, tempo, melodic intervals, and articulation can be explained by the influence of bipedal locomotion, breathing cycle, and heartbeat, long before Homo sapiens. However, two aspects, rhythm and melodic contour, most crucial for music as we know it, lack proxies in the Paleolithic lifestyle. The available ethnographic and developmental data leads one to believe that rhythmic and directional patterns of melody became involved in conveying emotion-related information in the process of frequent switching from one call-type to another within the limited repertory of calls. Such calls are usually adopted for the ongoing caretaking of human youngsters and domestic animals. The efficacy of rhythm and pitch contour in affective communication must have been spontaneously discovered in new important cultural activities. The most likely scenario for music to have become fully semiotically functional and to have spread wide enough to avoid extinctions is the formation of cross-specific communication between humans and domesticated animals during the Neolithic demographic explosion and the subsequent cultural revolution. Changes in distance during such communication must have promoted the integration between different expressive aspects and generated the basic musical grammar. The model of such communication can be found in the surviving tradition of Scandinavian pastoral music - kulning. This article discusses the most likely ways in which such music evolved.
EM aleksey@braavo.org
RI Nikolsky, Aleksey/AAS-6142-2021
OI Nikolsky, Aleksey/0000-0001-5572-9438
CR ABLER WL, 1989, J SOC BIOL STRUCT, V12, P1, DOI 10.1016/0140-1750(89)90015-8
   Addessi A. R., 2000, MUSIC SCI, V4, P31, DOI DOI 10.1177/102986490000400102
   Adorno T. W., 1942, POPULAR MUSIC
   Agawu K, 2004, MUSIC ANAL, V23, P267, DOI 10.1111/j.0262-5245.2004.00204.x
   Agawu V. K., 2003, REPRESENTING AFRICAN
   Ahlback S., 2007, TONALITY OLDER SWEDI
   Aiello LC, 1998, MEM CALIF ACAD SCI, P21
   Aikio Ante, 2006, Finnisch-Ugrische Forschungen, V59, P9
   Aksyonov A. N., 1964, TUVAN FOLK MUSIC MAT
   Alekseyev E. Y., 1981, MODELS YAKUT VOCAL F
   Alekseyev E. Y., 1995, VOICE RITUAL, P33
   Alekseyev E. Y., 1976, PROBLEMS GENESIS MUS
   Alekseyev E. Y., 1986, MUSICAL INTONATION E
   Altenmuller E., 2013, EVOLUTION EMOTIONAL, P339
   Altenmuller E., 2013, EVOLUTION EMOTIONAL, P75
   Altenmuller E., 2013, EVOLUTION EMOTIONAL, DOI [10.1093/acprof:oso/9780199583560.001.0001, DOI 10.1093/ACPROF:OSO/9780199583560.001.0001]
   Altenmuller E., 2013, Sound-perception-performance, V1, P131, DOI DOI 10.1007/978-3-319-00107-4_5
   ALVAREZPEREYRE F, 1993, WORLD MUSIC, V35, P7
   Amaya K, 1996, PROC GRAPH INTERF, P222
   Ambrose SH, 2001, SCIENCE, V291, P1748, DOI 10.1126/science.1059487
   Ambrose SH, 2010, CURR ANTHROPOL, V51, pS135, DOI 10.1086/650296
   [Anonymous], 1996, An Ethnography of the Neolithic: Early Prehistoric Societies in Southern Scandinavia
   [Anonymous], 2010, PALAEOLITHIC ORIGINS
   [Anonymous], 1996, MUSICAL BEGINNINGS
   [Anonymous], 1994, A Theory of Musical Semiotics
   [Anonymous], 2013, ANAL APPROACHES WORL
   [Anonymous], 1991, DEUTSCHLAND STEINZEI
   [Anonymous], 1995, MUSIC THERAPY, DOI DOI 10.1093/MT/13.1.47
   [Anonymous], 2005, ARCHAEOLOGICAL SERIE
   [Anonymous], 2001, NEW GROVE DICT MUSIC
   [Anonymous], 1995, MUSIC MIND MACHINE P
   [Anonymous], 1981, NATURJODEL SCHWEIZ W
   [Anonymous], 2009, WORLD 6 SONGS MUSICA
   [Anonymous], 1964, The nature of cultural things
   [Anonymous], 2006, MENC HDB MUSICAL COG, DOI DOI 10.1093/ACPROF:OSO/9780195304565.003.0005
   [Anonymous], 1967, SOVETSKAYA MUZYKA
   [Anonymous], 2004, P 2 INT C SPEECH PRO
   [Anonymous], 1985, TEXTURE MUSIC
   [Anonymous], 1994, ESQUISSE HIST HARMON
   [Anonymous], 1990, AUDITORY SCENE ANAL
   [Anonymous], 2004, SCI BIRDSONG
   [Anonymous], 2002, HIST MUSIC CULTURE S
   [Anonymous], 1967, LANGUAGE RELATION UN, DOI DOI 10.1515/9783111657158
   [Anonymous], 2003, ANIMALS SIGNALS
   [Anonymous], 2005, ORIGINS LANGUAGE CON
   [Anonymous], 1999, The performance of music. The psychology of music, DOI DOI 10.1016/B978-012213564-4/50015-9
   [Anonymous], 1951, THEMATIC PROCESS MUS
   [Anonymous], 1979, STRUCTURING MUSICAL
   [Anonymous], 2004, THESIS
   [Anonymous], 1987, HIST CULTURE CHUKC H
   [Anonymous], 1995, MUSICAL SIGNIFICATIO
   [Anonymous], 1990, INTERCULTURAL MUSIC
   [Anonymous], 1980, VERGLEICHENDE MUSIKW
   [Anonymous], 2004, RITE FOLKLORE SIBERI
   [Anonymous], 1976, MUSICAL EXPERIENCE P
   [Anonymous], 1999, E FOLKLORE MYTHOLOGY
   [Anonymous], MUSIC MIND SCI
   [Anonymous], 2001, Music and Emotion, DOI DOI 10.1525/MP.2004.21.4.561
   [Anonymous], 2003, FOOD CULTURE IDENTIT
   [Anonymous], PSYCHOL MUSIC
   [Anonymous], 1984, COGNITIVE PROCESSES
   [Anonymous], PHILOS MUSIC ED REV
   [Anonymous], 2015, U BERGEN ARCHAEOLOGI
   [Anonymous], 2014, Biocommunication of Animals
   Anthony DW, 2015, ANNU REV LINGUIST, V1, P199, DOI 10.1146/annurev-linguist-030514-124812
   ANTHONY DW, 1995, ANTIQUITY, V69, P554, DOI 10.1017/S0003598X00081941
   Aranovsky M G, 1991, SYNTACTIC STRUCTURE
   Aranovsky M. G., 1998, MUSICAL TEXT STRUCTU
   Arom S., 2004, African polyphony and polyrhythm: Musical structure and methodology
   Arom S., 1997, GARLAND ENCY WORLD M, P254
   Arom S, 2010, MUSIC SCI, P295
   Aronsson K, 1991, FOREST REINDEER HERD
   Atkinson Q, 2005, T PHILOL SOC, V103, P193, DOI 10.1111/j.1467-968X.2005.00151.x
   AUGUST PV, 1987, J MAMMAL, V68, P1, DOI 10.2307/1381039
   Axelsson E, 2013, NATURE, V495, P360, DOI 10.1038/nature11837
   Bader Rolf, 2018, SPRINGER HDB SYSTEMA
   Balari Sergio, 2011, Int J Evol Biol, V2011, P382679, DOI 10.4061/2011/382679
   Banshchikov G., 1997, RULES FUNCTIONAL INS
   BARTEL Dietrich, 1997, Musica Poetica: musical -rhetorical figures in German Baroque music
   BAUMAN MMP, 1993, WORLD MUSIC, V35, P34
   Baumann Max Peter, 1976, MUSIKFOLKLORE MUSIKF
   BECKER J, 1986, MUSIC QUART, V72, P341
   Beliaev V., 1963, J INT FOLK MUSIC COU, V15, P4, DOI [10.2307/836227, DOI 10.2307/836227]
   Beliayev V. M., 1990, VIKTOR MIKHAILOVICH
   Beliayev V. M., 1990, VIKTOR MIKHAILOVICH, P223
   Belin P, 2008, P ROY SOC B-BIOL SCI, V275, P473, DOI 10.1098/rspb.2007.1460
   Bellwood P., 2008, HDB ARCHAEOLOGICAL T, P225
   Benjamin T., 2015, CENGAGE LEARNING
   Benson D. J., 2007, Music: A Mathematical Offering
   Benward B., 2009, MUSIC THEORY PRACTIC, V2
   Berliner PF, 1993, SOUL MBIRA MUSIC TRA
   Bernicchia A, 2010, Parallel Distributed Processing, Workshops and Phd Forum (IPDPSW), 2010 IEEE International Symposium on
   Berry W., 1987, Structural functions in music
   Bersaglieri T, 2004, AM J HUM GENET, V74, P1111, DOI 10.1086/421051
   Berthon R., 2014, CAUCASIAN ARCHAEOLOG, V2, P4
   Blacking J, 1974, HOW MUSICAL IS MAN
   Blacking John, 1967, VENDA CHILDRENS SONG
   Blake E. C., 2011, THESIS
   Bläuer A, 2013, J ARCHAEOL SCI, V40, P1646, DOI 10.1016/j.jas.2012.10.033
   Blench R, 2013, AZANIA, V48, P31, DOI 10.1080/0067270X.2013.771016
   Bobrovsky V. P., 1978, FUNCTIONAL BASICS MU
   Bogucki P., 1988, Forest farmers and stockherders: early agriculture and its consequences in north-central Europe
   Boivin N, 2004, CAMB ARCHAEOL J, V14, P235, DOI 10.1017/S0959774304000150
   Boivin N, 2007, J ROY ANTHROPOL INST, V13, P267, DOI 10.1111/j.1467-9655.2007.00428.x
   Bonfeld M., 2006, MUSIC LANGUAGE SPEEC
   Bordzhanova T. G., 2007, RITUAL POETRY KALMYK
   Boyd Robert., 2005, Not by Genes Alone: How Culture, Transformed Human Evolution
   Braudo I. A., 1961, ARTICULATION PRONOUN
   Bresin R, 2011, CORTEX, V47, P1068, DOI 10.1016/j.cortex.2011.05.009
   Briefer EF, 2012, J ZOOL, V288, P1, DOI 10.1111/j.1469-7998.2012.00920.x
   Brodskiy I. A., 1976, TRADITSIONNOE SOVREM, P244
   Brooks R.R.R., 1976, STONE AGE PAINTING I
   Brown KS, 2009, SCIENCE, V325, P859, DOI 10.1126/science.1175028
   Brown S, 2000, ORIGINS OF MUSIC, P271
   Brown S, 2007, MUSIC SCI, V11, P3, DOI 10.1177/102986490701100101
   Brown S, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01894
   Brown W. N., 1964, ECON POLIT WEEKLY, V16, P245
   Burger J, 2007, P NATL ACAD SCI USA, V104, P3736, DOI 10.1073/pnas.0607187104
   Bytchkov Y. N., 1997, DIALECTICS FORMATION
   Bytchkov Y. N., 1987, THESIS, DOI [10.1073/pnas.0607187104, DOI 10.1073/PNAS.0607187104]
   Cabouret M., 1984, THESIS
   Cambouropoulos E, 2008, MUSIC PERCEPT, V26, P75, DOI 10.1525/MP.2008.26.1.75
   Cambouropoulos E, 2010, MUSIC SCI, P131
   Campbell Anthony K., 2005, Science Progress, V88, P157, DOI 10.3184/003685005783238408
   Campbell J, 2017, The Masks of God: Occidental Mythology
   Camps M., 2006, BIOLINGUISTIC TURN I, P34
   Caramelli D., 2006, HUM EVOL, V21, P107
   CHANG HW, 1977, J EXP CHILD PSYCHOL, V24, P324, DOI 10.1016/0022-0965(77)90010-8
   Chang W, 2015, LANGUAGE, V91, P194, DOI 10.1353/lan.2015.0005
   Charlton D., 2009, OPERA AGE ROUSSEAU M
   Chase PG, 2006, EMERGENCE OF CULTURE: THE EVOLUTION OF A UNIQUELY HUMAN WAY OF LIFE, P1
   Cheape H, 1996, FOLK LIFE, V35, P7, DOI 10.1179/043087796798254498
   Cheng J, 2009, J NEAR EASTERN STUD, V68, P163, DOI 10.1086/613988
   Chew G., 2001, ARTICULATION PHRASIN, DOI 10.1093/gmo/9781561592630.001.0001/omo-9781561592630-e-00000
   Christensen T., 2008, CAMBRIDGE HIST W MUS
   Clarke E. F., 1999, The Psychology of Music, V2nd ed., P473, DOI DOI 10.1016/B978-012213564-4/50014-7
   Clayton Martin, 2000, Time in Indian Music: Rhythm, Metre and Form in North Indian Rag Performance
   Conard NJ, 2009, NATURE, V460, P737, DOI 10.1038/nature08169
   Cook N. D., 2002, Tone of voice and mind: The connections between intonation, emotion, cognition, and consciousness, V47
   Cooke, 1959, LANGUAGE MUSIC
   Cramp LJE, 2014, P ROY SOC B-BIOL SCI, V281, DOI 10.1098/rspb.2014.0819
   Crickmore L., 2009, ARCHAEOMUSICOLOGICAL, P1
   Cross Ian, 2006, ARCHAEOACOUSTICS, P107
   Crossley-Holland P., 1967, JB MUSIKALISCHE VOLK, P9, DOI DOI 10.1515/9783111448503-002
   Curry A, 2013, NATURE, V500, P20, DOI 10.1038/500020a
   CYNX J, 1990, J COMP PSYCHOL, V104, P3, DOI 10.1037/0735-7036.104.1.3
   D'Errico F, 1998, ANTIQUITY, V72, P65, DOI 10.1017/S0003598X00086282
   d'Errico F, 2011, PHILOS T R SOC B, V366, P1060, DOI 10.1098/rstb.2010.0340
   Dahlhaus Carl, 1989, Nineteenth-Century Music
   Dasen P. R., 2012, P 4 AFRICA REGION C, P55
   Davidson M., 1970, AFRICAN MUSIC, V4, P103, DOI [10.21504/amj.v4i4.1685, DOI 10.21504/AMJ.V4I4.1685]
   de Gotzen A., 2004, P 7 INT C DIG AUD EF, P5
   Dean RT, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018591
   DEMANY L, 1977, NATURE, V266, P718, DOI 10.1038/266718a0
   DENNETT DC, 1983, BEHAV BRAIN SCI, V6, P343, DOI 10.1017/S0140525X00016393
   Deutsch D, 2013, PSYCHOLOGY OF MUSIC, THIRD EDITION, P249, DOI 10.1016/B978-0-12-381460-9.00007-9
   Diamond J, 2003, SCIENCE, V300, P597, DOI 10.1126/science.1078208
   Diedrich CG, 2015, ROY SOC OPEN SCI, V2, DOI 10.1098/rsos.140022
   DISSANAYAKE E., 2005, MUSIC MANIPULATION S, P31
   Dissanayake E., 2008, Mus. Sci, V12, P169, DOI [10.1177/1029864908012001081, DOI 10.1177/1029864908012001081]
   Dobzhanskaya O., 2011, C C P 2 ALL RUSS C F, P300
   Dobzhanskaya O. E., 2016, ANTHR ARCHEOL EURASI, V55, P7, DOI [10.1080/10611959.2016.1263485, DOI 10.1080/10611959.2016.1263485]
   Dobzhanskaya O. E., 2012, 16 TZARSKOSELSK READ, P256
   Doherty NA, 2009, AT WAR WITH THE WEATHER: MANAGING LARGE-SCALE RISKS IN A NEW ERA OF CATASTROPHES, P3
   Dor R., 2005, TURCICA, V27, P199, DOI 10.2143/turc.27.0.2004362
   Dor R., 2008, DIOGENE, V200, P129, DOI [10.3917/dio.200.0129, DOI 10.3917/DIO.200.0129]
   Dor R., 1993, ETUDES TURQUES OTTOM, V3, P27
   Driscoll CA, 2009, P NATL ACAD SCI USA, V106, P9971, DOI 10.1073/pnas.0901586106
   Druzhkova AS, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057754
   Dumbrill R., 1998, MUSICOLOGY ORGANOLOG
   Duncan-Kemp AM., 1952, STRANGE PATHS GO
   Dzenzelevskii I. A., 1984, SLAVIC BALKAN FOLKLO, P256
   Edwards CJ, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0015922
   Eerola T, 2001, MUSIC PERCEPT, V18, P275, DOI 10.1525/mp.2001.18.3.275
   Eerola T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00487
   Eerola T, 2013, MUSIC PERCEPT, V30, P307, DOI [10.1525/mp.2012.30.3.307, 10.1525/MP.2012.30.1.49]
   Eklund R., 2019, P FONETIK 2019 STOCK, P61
   Eklund R., 2015, P ICPHS 2015 AUG 201, P10
   Emsheimer E., 1991, STUDIA ETHNOMUSICOLO, P41
   Etzel JA, 2006, INT J PSYCHOPHYSIOL, V61, P57, DOI 10.1016/j.ijpsycho.2005.10.025
   Fabian D, 2008, MUSIC SCI, V12, P177, DOI 10.1177/102986490801200201
   Fagg M. Catherine, 1997, ROCK MUSIC, P6
   Fallows D., 2001, NEW GROVE DICT MUSIC
   Fanner H. G., 1965, Islamic Studies, V4, P25
   Farber W., 1990, ANTHR INT Z VOLKER U
   Felius Marleen, 2014, Diversity-Basel, V6, P705, DOI 10.3390/d6040705
   Fenk-Oczlon G, 2009, MUSIC SCI, P201
   Filippi P, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01393
   Fitch W. T., 2012, Language and music as cognitive systems, P73
   Fitch WT, 2006, COGNITION, V100, P173, DOI 10.1016/j.cognition.2005.11.009
   Fitch WT, 2010, EVOLUTION OF LANGUAGE, PROCEEDINGS, P137
   FLATZ G, 1973, LANCET, V2, P76
   Forster Peter, 2006, Phylogenetic Methods and the Prehistory of Languages, P91
   Fraisse P., 1982, PSYCHOL MUSIC, P149, DOI [DOI 10.1016/B978-0-12-213562-0.50010-3, 10.1016/B978-0-12-213562-0.50010-3]
   Franklin J. C., 2006, J ANC NEAR EAST RELI, V6, P463
   Frenk-Oczlon Gertraud, 2009, P 7 TRIENN C EUR SOC, P110
   Friberg A, 1999, J ACOUST SOC AM, V105, P1469, DOI 10.1121/1.426687
   Frodin J., 1929, FABODBEBYGGELSENS UT, P176
   Gabrielsson A, 2003, SER AFFECTIVE SCI, P503
   Garbuzov N., 1950, ZONAL NATURE TEMPO R
   Garbuzov N., 1956, ZONAL NATURE HEARING
   Garbuzov N., 1955, ZONAL NATURE HEARING
   Garbuzov N A, 1948, ZONAL NATURE PITCH H
   Garroway K. H., 2019, GROWING ANCIENT ISRA
   Gerbault P, 2013, IUBMB LIFE, V65, P983, DOI 10.1002/iub.1227
   Germonpré M, 2012, J ARCHAEOL SCI, V39, P184, DOI 10.1016/j.jas.2011.09.022
   GIMBUTAS M, 1993, WORD, V44, P205, DOI 10.1080/00437956.1993.11435900
   Gioia T., 2006, Work songs, DOI DOI 10.1515/9780822387688
   Golub H. L., 1985, Infant Crying: Theoretical and Research Perspectives, P59
   Gordon Bryan, 2003, Rangifer, P15
   GOURLAY KA, 1982, ETHNOMUSICOLOGY, V26, P411, DOI 10.2307/850689
   GOURLAY KA, 1984, WORLD MUSIC, V26, P25
   Gray RD, 2003, NATURE, V426, P435, DOI 10.1038/nature02029
   Gray RD, 2011, PHILOS T R SOC B, V366, P1090, DOI 10.1098/rstb.2010.0378
   Grewe O, 2005, ANN NY ACAD SCI, V1060, P446, DOI 10.1196/annals.1360.041
   GUILFORD T, 1991, ANIM BEHAV, V42, P1, DOI 10.1016/S0003-3472(05)80600-1
   Halpern AR, 1998, MUSIC PERCEPT, V15, P335
   Hancock AM, 2010, P NATL ACAD SCI USA, V107, P8924, DOI 10.1073/pnas.0914625107
   Hansen L. I., 2014, HUNTERS TRANSITION O
   Harding R. E. M., 1983, METRONOME ITS PRECUR
   HARRIS M, 1990, CAN LITERATURE, P41
   Hauser A., 1999, SOCIAL HIST ART PREH
   Hauser Marc D., 1996, EVOL COMMUN
   Hauser MD, 2000, COGNITIVE SCI, V24, P445, DOI 10.1207/s15516709cog2403_5
   HEADLAND TN, 1990, FRONT ANTHR, P13
   Heggarty P., 2015, GLOBAL PREHISTORY HU, P157
   Helmer R. H. P., 1975, EUROPEAN PASTORAL CA
   Helskog K., 2012, FENNOSCANDIA ARCHAEO, V29, P29
   Hershkovitz I, 2015, TUBERCULOSIS, V95, pS122, DOI 10.1016/j.tube.2015.02.021
   Hillert DG, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01796
   Hiltebeitel A., 2011, GODDESS WAS WOMAN, P399
   HIRSHPASEK K, 1982, J CHILD LANG, V9, P229, DOI 10.1017/S0305000900003731
   Holahan J. M., 1987, MUSIC CHILD DEV, P96
   Honing H, 2003, COMPUT MUSIC J, V27, P66, DOI 10.1162/014892603322482538
   Horvdth T., 2012, RITUAL KILLING BURIA, P115
   Hubbard T. L., 2003, ANTHR CONSCIOUSNESS, V14, P40
   Hurford J. R., 2012, LANGUAGE LIGHT EVOLU
   HURON D, 1989, PROCEEDINGS : 1989 INTERNATIONAL COMPUTER MUSIC CONFERENCE, NOVEMBER 2-5, P131
   HURON DAVID, 2006, SWEET ANTICIPATION M, P148, DOI DOI 10.7551/MITPRESS/6575.001.0001
   Ingold T., 1986, Anthropol. Today, V2, P5, DOI DOI 10.2307/3032710
   Ingold Tim, 1994, Companion Encyclopedia of Anthropology, P366
   Ivarsdotter A., 2004, Pecus. Man and animal in antiquity, P146
   Ivarsdotter A., 1995, LOCKROP VALLATAR ANC
   Ivarsdotter A., 1986, THESIS
   Jerkert J., 2003, MEASUREMENTS MODELS
   Johnson A., 1979, SVENSK TIDSKRIFT MUS, V60, P5
   Johnson A., 1982, DEP SPEECH MUSIC HEA, V23, P99
   Johnson A., 1984, YEARB TRADIT MUSIC, V16, P42
   Jones M. R., 2016, OXFORD HDB MUSIC PSY, P125, DOI DOI 10.1093/OXFORDHB/9780198722946.013.13
   JONES MR, 1991, MEM COGNITION, V19, P8, DOI 10.3758/BF03198492
   Jordania J., 2011, Why do People Sing? Music in Human Evolution
   JURGENS U, 1995, CURRENT TOPICS IN PRIMATE VOCAL COMMUNICATION, P199
   Juslin P. N., 2011, Music and the mind: Essays in honour of John Sloboda, P113
   Juslin P. N., 2005, MUSICAL COMMUNICATIO, P85, DOI [DOI 10.1093/ACPROF:OSO/9780198529361.003.0005, 10.1093/acprof:oso/9780198529361.003.0005]
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P600, DOI 10.1017/S0140525X08005554
   Juslin PN, 2013, PHYS LIFE REV, V10, P235, DOI 10.1016/j.plrev.2013.05.008
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN., 2001, Music and Emotion, P309, DOI 10.1093/oso/9780192631886.003.0014
   Kan-ool A. K., 2012, B E SIBERIAN ACAD CU, V1, P31
   Keller H., 1973, PHRASING ARTICULATIO
   Kendall R.A., 1993, Contemporary Music Review, V9, P51, DOI DOI 10.1080/07494469300640341
   Khannanov I. I., 2005, THESIS
   Kharlap M., 1972, EARLY FORMS ART, P246
   Kholopov Y., 2005, HARMONY PROBLEMS SCI, P135
   Kholopov Y., 1976, ENCY MUSIC, V3, P130
   Kholopov Y., 2006, INTRO MUSICAL FORM
   Kholopova V., 2002, THEORY MUSIC MELOS R
   Kirnarskaya D., 2003, PSYCHOL MUSICAL ACTI
   Kolinsky R, 2009, COGNITION, V112, P1, DOI 10.1016/j.cognition.2009.02.014
   Kolltveit G., 2008, STUDIES MUSIC ARCHAE, P147
   Kondratyeva N. M., 1996, THESIS
   Kondratyeva N. M., 2017, J MUSICAL SCI, V3, P77
   Kondratyeva N. M., 1989, FOLKLORIC HERITAGE M, P20
   Kondratyeva N. M., 1999, LANG INDIGENOUS PEOP, V6, P19
   Korom FJ, 2000, ASIAN FOLKLORE STUD, V59, P181, DOI 10.2307/1178915
   Kozlowski JK, 2015, QUATERN INT, V359, P3, DOI 10.1016/j.quaint.2014.03.025
   Kreitner K., 2001, NEW GROVE DICT MUSIC
   Krumhansl C.L., 1990, COGNITIVE FDN MUSICA
   Krumhansl CL, 2002, CURR DIR PSYCHOL SCI, V11, P45, DOI 10.1111/1467-8721.00165
   Kubik Gerhard, 1999, AFRICA AND THE BLUES
   KVAMME M, 1988, CULTURAL LANDSCAPE P, P349
   Kyrgys Z.K., 2002, Tuvan throat singing: An ethnomusicological study
   Large E. W., 1994, Connection Science, V6, P177, DOI 10.1080/09540099408915723
   Large EW, 2008, PSYCHOLOGY OF TIME, P189, DOI 10.1016/B978-0-08046-977-5.00006-5
   Large EW, 1999, PSYCHOL REV, V106, P119, DOI 10.1037/0033-295X.106.1.119
   Larson G, 2012, P NATL ACAD SCI USA, V109, P8878, DOI 10.1073/pnas.1203005109
   Lerdahl F., 1985, A Generative Theory of Tonal Music
   Lester Joel, 1989, Between Modes and Keys: German Theory, 1592-1802
   Levin T. C., 2006, RIVERS MOUNTAINS SIN
   LEVITIN DJ, 1994, PERCEPT PSYCHOPHYS, V56, P414, DOI 10.3758/BF03206733
   Lieberman P., 1985, INFANT CRYING THEORE, V2, P29
   Lodrick DO, 2005, DIALECT ANTHROPOL, V29, P61, DOI 10.1007/s10624-005-5809-8
   LOMAX A, 1977, WORLD MUSIC, V19, P117
   London J., 2004, Hearing in Time: Psychological Aspects of Musical Meter, DOI 10.1093/acprof:oso/9780195160819.003.0002
   Lougas L, 2007, ARCHAEOFAUNA, V16, P21
   Loui P, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01664
   Madison G, 2010, J ACOUST SOC AM, V128, P3032, DOI 10.1121/1.3493462
   Maier A., 2017, MITTEILUNGEN GESELLS, V26, P83
   Malmström H, 2010, BMC EVOL BIOL, V10, DOI 10.1186/1471-2148-10-89
   Manser MB, 2010, HBK BEHAV NEUROSCI, V19, P477, DOI 10.1016/B978-0-12-374593-4.00043-7
   Manuel P, 2011, ROUTL PHILOS COMPAN, P245
   Marciniak A, 2013, PUBL INST ARCHAEOL, V59, P221
   Marciniak S, 2017, NAT REV GENET, V18, DOI 10.1038/nrg.2017.65
   Marler P, 2000, ORIGINS OF MUSIC, P31
   Marler P, 1997, J NEUROBIOL, V33, P501
   Marler P., 2008, BEHAVIOUR, V109, P20, DOI [10.1163/156853989x00141, DOI 10.1163/156853989X00141]
   Marlowe FW, 2005, EVOL ANTHROPOL, V14, P54, DOI 10.1002/evan.20046
   Marshack A., 1990, EMERGENCE MODERN HUM, P457
   Mathiesen, 1999, APOLLOS LYRE GREEK M
   MATHIESEN TJ, 1984, J MUSICOLOGY, V3, P264, DOI 10.1525/jm.1984.3.3.03a00050
   Mattheson, 1981, J MATTHESONS VOLLKOM
   Mazel L. A., 1967, ANAL MUSICAL WORKS
   Mazepus V. V., 1997, MUSICAL CULTURE SIBE
   Mazepus V. V., 1993, UNIVERSAL GRAMMATIC
   McAdams S, 2004, MUSIC PERCEPT, V22, P207, DOI 10.1525/mp.2004.22.2.207
   McAuley JD, 2010, SPRINGER HANDB AUDIT, V36, P165, DOI 10.1007/978-1-4419-6114-3_6
   McBrearty S, 2000, J HUM EVOL, V39, P453, DOI 10.1006/jhev.2000.0435
   McConnell P.B., 1991, Perspectives in Ethology, V9, P165
   McConnell P. B., 2002, OTHER END LEASH WHY
   MCCONNELL PB, 1985, Z TIERPSYCHOL, V67, P302
   MCCONNELL PB, 1990, ANIM BEHAV, V39, P897, DOI 10.1016/S0003-3472(05)80954-6
   McCreless Patrick., 2002, CAMBRIDGE HIST W MUS, P847, DOI DOI 10.1111/J.1439-0310.1985.TB01396.X
   McDermott JH, 2010, CURR BIOL, V20, P1035, DOI 10.1016/j.cub.2010.04.019
   McInerney J, 2010, CATTLE OF THE SUN: COWS AND CULTURE IN THE WORLD OF THE ANCIENT GREEKS, P1
   Medushevsky V. V., 2010, RULES MEANS ARTISTIC
   Meier Bernhard, 1956, MUSICA DISCIPLINA, V10, P67
   Mellars P., 2004, SPECIATION MODERN HO, P31
   MESSNER GF, 1993, WORLD MUSIC, V35, P81
   Meyer J., 2009, Acoustics and the Performance of Music
   MIKLOSI A, 2015, DOG BEHAV EVOLUTION
   Miller R.J., 2014, CONT ORCHESTRATION P
   Mills S, 2016, AUDITORY ARCHAEOLOGY
   Milne L. S., 2017, INCANTATIO INT J CHA, V6, P78
   Mitchell RW, 2001, RES LANG SOC INTERAC, V34, P183, DOI 10.1207/S15327973RLSI34-2_2
   Mitchell Stephen A., 2001, COSMOS, V17, P59
   Moberg C.-A., 1955, SVENSK TIDSKRIFT R M, V37, P1
   MOBERG CA, 1971, STUDIEN SCHWEDISCHEN
   Mohn C, 2011, PSYCHOL MUSIC, V39, P503, DOI 10.1177/0305735610378183
   MOLINO J, 1990, MUSIC ANAL, V9, P105, DOI 10.2307/854225
   MONAHAN CB, 1987, PERCEPT PSYCHOPHYS, V41, P576, DOI 10.3758/BF03210491
   MONAHAN CB, 1985, MUSIC PERCEPT, V3, P1
   Monelle Raymond., 2006, MUSICAL TOPIC HUNT M
   Monelle Raymond, 1992, LINGUISTICS SEMIOTIC
   Monelle Raymond., 2000, The Sense of Music: Semiotic Essays
   Montagu J., 2004, GALPIN SOC J, V57, P171
   Moore A. F., 2011, POPULAR MUSIC HIST, V4, P289, DOI [10.1558/pomh.v4i3.289, DOI 10.1558/POMH.V4I3.289]
   Morley I., 2013, The Prehistory of Music. Human Evolution, Archaeology, and the Origins of Musicality
   Morley I., 2006, OXFORD J ARCHAEOL, V25, P317, DOI [DOI 10.1111/J.1468-0092.2006.00264.X, DOI 10.1111/j.1468-0092.2006.00264.x]
   MORTON ES, 1977, AM NAT, V111, P855, DOI 10.1086/283219
   Munzel S., 2009, EISZEIT KUNST KULTUR, P317
   Murashkin A., 2016, NEW SITES NEW METHOD, P185
   Myers Helen, 1993, ETHNOMUSICOLOGY HIST
   Nakata T, 2004, INFANT BEHAV DEV, V27, P455, DOI 10.1016/j.infbeh.2004.03.002
   NARMOUR E., 1992, ANAL COGNITION MELOD
   Nash PH, 1996, CAN GEOGR-GEOGR CAN, V40, P69, DOI 10.1111/j.1541-0064.1996.tb00433.x
   Nattiez J. J., 2012, HUM SOC STUD, V1, P67, DOI [10/gmnfnk, DOI 10.2478/v10317-012-0005-2, 10.2478/v10317-012-0005-2, DOI 10.2478/V10317-012-0005-2]
   Nattiez J. -J., 1990, MUSIC DISCOURSE SEMI
   Nawrot ES., 2003, Psychol. Music, V31, P75, DOI DOI 10.1177/0305735603031001325
   Nazaikinsky Y. V., 1972, PSYCHOL HUMAN MUSICA
   Nazaikinsky Y. V., 1982, LOGIC MUSICAL COMPOS
   Nazaikinsky Y. V., 1973, MUSICAL ART SCI, P59
   Nazaikinsky Y. V., 2013, STYLE GENRE MUSIC
   Nazaikinsky Y. V., 1988, SONIC WORLD MUSIC
   Nazaikinsky Y. V., 1964, APPL ACOUSTIC METHOD, P79
   Nettl B, 2010, NETTL'S ELEPHANT: ON THE HISTORY OF ETHNOMUSICOLOGY, P1
   Nettl B., 2005, The Study of Ethnomusicology: Thirty-one Issues and Concepts
   Nielsen GH, 1997, WHO REG PUB, P241
   Nikolsky A., 2020, ORIGINS LANGUAGE REV, P139, DOI [10.1007/978-981-15-4250-3_7, DOI 10.1007/978-981-15-4250-3_7]
   Nikolsky A., 2015, MUSICA CUERPO ESTUDI, P241, DOI [10.13140/RG.2.1.2737.0008, DOI 10.13140/RG.2.1.2737.0008]
   Nikolsky A, 2020, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.03051
   Nikolsky A, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00075
   Nikolsky A, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00211
   Nikolsky A, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01405
   Noorden L., 1975, TEMPORAL COHERENCE P
   Oatley, 2010, HDB EMOTIONS, P102
   Oma KA, 2013, SOC ANIM, V21, P162, DOI 10.1163/15685306-12341300
   Oma KA, 2010, WORLD ARCHAEOL, V42, P175, DOI 10.1080/00438241003672724
   Owren MJ, 2001, EVOL ANTHROPOL, V10, P58, DOI 10.1002/evan.1014.abs
   Oxenham AJ, 2013, PSYCHOLOGY OF MUSIC, THIRD EDITION, P1, DOI 10.1016/B978-0-12-381460-9.00001-8
   Panksepp J, 2002, BEHAV PROCESS, V60, P133, DOI 10.1016/S0376-6357(02)00080-3
   Panteleeva O, 2019, SLAVON E EUR REV, V97, P73, DOI 10.5699/slaveasteurorev2.97.1.0073
   Parncutt R., 2011, J INTERDISCIPLINARY, V5, P119, DOI 10.4407/jims.2011.11.002
   Patel A., 2010, EMERGING DISCIPLINES, P91
   Patel A. D., 2008, MUSIC ITS EVOLUTION
   Patel AD, 2006, EMPIR MUSICOL REV, V1, P166, DOI 10.18061/1811/24011
   Patterson RD, 2010, SPRINGER HANDB AUDIT, V36, P13, DOI 10.1007/978-1-4419-6114-3_2
   Payne K, 2000, ORIGINS OF MUSIC, P135
   Pegg C., 2001, MONGOLIAN MUSIC DANC
   Pegg Carole, 1992, British Journal of Ethnomusicology, V1, P31
   Peretz I., 2013, HDB MUSIC EMOTION TH, P99, DOI [10.1093/acprof:oso/9780199230143.003.0005, DOI 10.1093/ACPROF:OSO/9780199230143.003.0005]
   Perlovsky L, 2012, MUSIC SCI, V16, P185, DOI 10.1177/1029864912448327
   PETERS G, 1984, Z SAUGETIERKD, V49, P157
   Petrucelli JR, 2017, PREVENTING FRAUD AND MISMANAGEMENT IN GOVERNMENT: SYSTEMS AND STRUCTURES, P247
   Pfordresher PQ, 2017, J COGN PSYCHOL, V29, P35, DOI 10.1080/20445911.2015.1132024
   PIKE KL, 1990, FRONT ANTHR, P28
   Pikovsky A., 2002, Synchronization: a Universal Concept in Nonlinear Science
   Plantenga Bart, 2004, YODEL AY EE OOOO SEC
   Plantinga TS, 2012, EUR J HUM GENET, V20, P778, DOI 10.1038/ejhg.2011.254
   Plotnikova A. A., 1999, WORLD SOUND SILENCE, P295
   Plotnikova A. A., 1999, WORLD SOUND SILENCE, P73
   Potter DD, 2009, CORTEX, V45, P103, DOI 10.1016/j.cortex.2008.01.004
   Powell A, 2009, SCIENCE, V324, P1298, DOI 10.1126/science.1170165
   Powers H., 2001, NEW GROVE DICT MUSIC, V16, P777
   Powers Harold S., 2001, GROVE MUSIC ONLINE, DOI [10.1093/gmo/9781561592630.001.0001/omo-9781561592630-e-0000043718#omo-9781561592630, DOI 10.1093/GMO/9781561592630.001.0001/OMO-9781561592630-E-0000043718#OMO-9781561592630]
   Prakash O., 1961, FOOD DRINKS ANCIENT
   Prince JB, 2014, J EXP PSYCHOL HUMAN, V40, P2319, DOI 10.1037/a0038010
   Prince JB, 2009, MEM COGNITION, V37, P368, DOI 10.3758/MC.37.3.368
   Quam RM, 2017, SPRINGER HANDB AUDIT, V63, P201, DOI 10.1007/978-3-319-59478-1_8
   Rags Y. N., 1999, AESTHETICS BOTTOM AE
   Rags Y. N., 1980, GARBUZOV NA MUSICIAN
   Ratner Leonard G., 1980, Classic Music: Expression, Form, and Style
   Ravens Simon, 2014, SUPERNATURAL VOICE H
   Reimers E., 2006, Rangifer, V26, P55
   Renfrew C.A., 1987, Archaeology and language
   Repp B. H., 1998, PERCEPTION PRODUCTIO
   REPP BH, 1995, J ACOUST SOC AM, V97, P3862, DOI 10.1121/1.413065
   Reznikoff I., 2008, J. Acoust. Soc. Am, V123, P3603, DOI [DOI 10.1121/1.2934773, 10.1121/1.2934773]
   RICE T, 1987, ETHNOMUSICOLOGY, V31, P469, DOI 10.2307/851667
   Richerson PJ, 2009, HUM BIOL, V81, P211, DOI 10.3378/027.081.0306
   ROBB J, 1991, ANTIQUITY, V65, P287, DOI 10.1017/S0003598X00079758
   ROBB J, 1993, ANTIQUITY, V67, P747, DOI 10.1017/S0003598X00063766
   Roed KH, 2008, P ROY SOC B-BIOL SCI, V275, P1849, DOI 10.1098/rspb.2008.0332
   Roed KH, 2018, J ARCHAEOL SCI-REP, V19, P279, DOI 10.1016/j.jasrep.2018.02.048
   Roesner E. H., 2001, RHYTHMIC MODES MODAL
   Rosenberg S., 2003, KULNING MUSIKEN METO
   Rosenberg S., 2014, VOICE SPEECH REV, V8, P100, DOI DOI 10.1080/23268263.2013.829712
   Rothstein W. N., 1989, Phrase Rhythm in Tonal Music
   Rouget G, 2011, YEARB TRADIT MUSIC, V43, P89
   Rowley-Conwy P, 2013, PUBL INST ARCHAEOL, V59, P283
   Rowley-Conwy P, 2011, CURR ANTHROPOL, V52, pS431, DOI 10.1086/658368
   RUWET N, 1987, MUSIC ANAL, V6, P11
   Sachs ME, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00404
   Sadie Stanley, 2001, The New Grove Dictionary of Music and Musicians
   Samson J., 2001, GENRE NEW GROVE DICT
   Saña M, 2013, PUBL INST ARCHAEOL, V59, P195
   Sandell GJ, 1995, MUSIC PERCEPT, V13, P209
   Schiavio A, 2017, PHENOMENOL COGN SCI, V16, P785, DOI 10.1007/s11097-016-9477-8
   Schubert E., 2015, CHILD MUSICIAN HDB M, P221
   Schulting R, 2013, PUBL INST ARCHAEOL, V59, P313
   SEARCY WA, 1992, NATO ADV SCI I A-LIF, V228, P175
   Sebeok T., 1994, Signs: Introduction to Semiotics
   Seyfarth RM, 2017, PSYCHON B REV, V24, P79, DOI 10.3758/s13423-016-1059-9
   Shatkovsky G. I., 1986, DEV MUSICAL HEARING
   Sheikin Y. I., 2017, HIST WORLD MUSICAL C
   Shestakov V.P., 1975, ETHOS AFFECT HIST MU
   Shevtsov V. N., 1988, MUSICAL ETHNOGRAPHY, P108
   Shvachkin N. H., 1948, PROBLEMS PSYCHOL PER, P101
   Sicoli M.A., 2015, The Handbook of Discourse Analysis, V2, P105
   Sikora M, 2019, NATURE, V570, P182, DOI 10.1038/s41586-019-1279-z
   Silvia PJ, 2011, PSYCHOL AESTHET CREA, V5, P208, DOI 10.1037/a0021914
   Simpson BS, 1997, VET CLIN N AM-SMALL, V27, P445, DOI 10.1016/S0195-5616(97)50048-9
   Sjögren KG, 2013, J ARCHAEOL SCI, V40, P690, DOI 10.1016/j.jas.2012.08.001
   Slater P., 2001, ORIGINS MUSIC, P49
   Slater P., 2011, OXFORD HDB LANGUAGE, DOI [10.1093/oxfordhb/9780199541119.013.0008, DOI 10.1093/OXFORDHB/9780199541119.013.0008]
   SMITH JM, 1976, AM SCI, V64, P41
   Snowdon C. T., 2013, EVOLUTION EMOTIONAL, V24, P133
   Snowdon CT, 2015, PROG BRAIN RES, V217, P17, DOI 10.1016/bs.pbr.2014.11.019
   Snowdon CT, 2003, SER AFFECTIVE SCI, P457
   Sodgerel T., 2016, B SAINT PETERSBURG S, V3, P126
   Sodgerel T., 2012, CULTURE MONGOL SPEAK, P60
   Soffer O, 2000, CURR ANTHROPOL, V41, P511, DOI 10.1086/317381
   Sorensen L, 2014, J ARCHAEOL SCI, V51, P98, DOI 10.1016/j.jas.2012.08.042
   Stebbins W. C., 2011, COMP HEARING MAMMALS, P97, DOI [10.1007/978-1-4612-2700-7_4, DOI 10.1007/978-1-4612-2700-7_4]
   Stépanoff C, 2017, CURR ANTHROPOL, V58, P57, DOI 10.1086/690120
   Straehley Ian C., 2014, PSYCHOMUSICOLOGY, V24, P21, DOI DOI 10.1037/PMU0000032
   Stricklin W. Ray, 2001, P83, DOI 10.1079/9780851993973.0083
   Stuart C. K., 2008, LIFE MARRIAGE SKYA R
   Suisman David, 2009, Selling Sounds: The Commercial Revolution in American Music
   SUNDBERG Johan, 1987, The science of singing voice
   Sutton R. A., 1991, Traditions of gamelan music in Java: Musical pluralism and regional identity
   Swain J. P., 2002, HARMONIC RHYTHM ANAL
   Swanwick K., 1986, British Journal of Music Education, V3, P305, DOI 10.1017/S0265051700000814
   Tagg P., 2012, MUSICS MEANING MODER
   Tallerman M, 2013, J LINGUIST, V49, P455, DOI 10.1017/S0022226713000017
   Tarasti E, 2012, SEMIOT COMMUN COGNIT, V10, P1, DOI 10.1515/9781614511410
   Tarr B, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01096
   Tchotchkina M. P., 2003, ALTAIC CHILDREN FOLK
   Ted Gioia, 2006, HEALING SONGS
   Tesch Sten, 1992, ARCHAEOLOGY CULTURAL, V19, P283
   Thiemel M., 2001, DYNAMICS NEW GROVE D, DOI [10.1093/gmo/9781561592630.article.08458, DOI 10.1093/GMO/9781561592630.ARTICLE.08458]
   Thompson Nicholas S., 2000, Bird Behavior, V13, P93
   Titon JT, 2015, MUZIKOLOSKI ZB, V51, P175, DOI 10.4312/mz.51.2.175-185
   Titze I.R., 1988, J. Voice, V2, P183, DOI [10.1016/S0892-1997(88)80075-4, DOI 10.1016/S0892-1997(88)80075-4]
   Titze IR, 2020, J VOICE, V34, P44, DOI 10.1016/j.jvoice.2018.08.008
   Tiukhteneva S. P., 2017, ORIENTAL STUD, V34, P62
   TODD NPM, 1992, J ACOUST SOC AM, V91, P3540, DOI 10.1121/1.402843
   Touma H. H., 1996, MUSIC ARABS PORTLAND
   Trainor L, 2010, PHYS LIFE REV, V7, P44, DOI 10.1016/j.plrev.2010.01.010
   Trainor LJ, 2013, PSYCHOLOGY OF MUSIC, THIRD EDITION, P423, DOI 10.1016/B978-0-12-381460-9.00011-0
   Trehub SE, 2008, BEHAV BRAIN SCI, V31, P598, DOI 10.1017/S0140525X08005530
   Trehub SE, 2006, COGNITION, V100, P73, DOI 10.1016/j.cognition.2005.11.006
   TREHUB SE, 1993, INFANT BEHAV DEV, V16, P285, DOI 10.1016/0163-6383(93)80036-8
   Tresset A, 2011, CR BIOL, V334, P182, DOI 10.1016/j.crvi.2010.12.010
   Trevarthen C., 2019, EARLY INTERACTION DE, V1, P1, DOI DOI 10.1007/978-3-030-04769-6_1
   Trost WJ, 2017, NEUROPSYCHOLOGIA, V96, P96, DOI 10.1016/j.neuropsychologia.2017.01.004
   Tull HW, 1996, INDO-IRAN J, V39, P223, DOI 10.1007/BF00161863
   Tuniz C, 2012, ARCHAEOMETRY, V54, P581, DOI 10.1111/j.1475-4754.2011.00630.x
   Turino T, 2014, ETHNOMUSICOLOGY, V58, P185
   Turk I, 2014, DIVJE BABE
   Turk I, 2001, ARHEOLOSKI VESTN, V52, P25
   [Anonymous], 1992, MUSICAL THEMATICISM
   [Anonymous], 2009, FOLKLORIC THEATER YA
   [Anonymous], COGN STUD, DOI DOI 10.11225/jcss.12.153
   Renfrew A. C., 2014, The Cambridge World Prehistory West and Central Asia and Europe, V3, P1753, DOI DOI 10.1017/CHO9781139017831.105
   Uspensky B., 1995, SEMIOTICS ART
   Uttman M. T., 2002, SWEDISH J MUSIC RES, V5, P1
   Vashkevich N., 2006, SEMANTICS MUSICAL SP
   Ventsel A, 2006, NOMAD PEOPLES, V10, P68, DOI 10.3167/nP.2006.100205
   Vorren O., 1973, CIRCUMPOLAR PROBLEMS, P185, DOI DOI 10.1016/B978-0-08-017038-1.50026-1
   Walker R, 1997, J NEW MUSIC RES, V26, P315, DOI 10.1080/09298219708570733
   WALLIN NL, 1983, WORLD MUSIC, V25, P46
   Wallin NL, 1991, Biomusicology: neurophysiological, neuropsychological, and evoluitonary perspectives on the orgins and purposes of music
   WASER PM, 1977, Z TIERPSYCHOL, V43, P239
   Welch G. F., 2006, CHILD MUSICIAN HDB M, P311, DOI [DOI 10.1093/ACPROF:OSO/9780198530329.003.0016, 10.1093/acprof:oso/9780198530329.003.0016]
   Wermke K, 2007, CLIN LINGUIST PHONET, V21, P961, DOI 10.1080/02699200701659243
   Wermke K, 2009, MUSIC SCI, P151, DOI 10.1177/1029864909013002081
   Whiten A, 2011, PHILOS T R SOC B, V366, P997, DOI 10.1098/rstb.2010.0334
   Whittaker J. C., 1994, FLINTKNAPPING MAKING
   Whittle M., 2007, Gait Analysis: An Introduction
   Wildgen Wolfgang., 2004, EVOLUTION HUMAN LANG
   Wiley RH, 1983, Animal Behaviour, V2, P156
   Winnington-Ingram R. P., 2015, MODE ANCIENT GREEK M
   Wulstan D., 1971, STUD E CHANT, V2, P4
   Wyatt S., 2016, STUDIEN MUSIKARCHAOL, P169
   Yemelyanov V., 2000, VOICE DEV COORDINATI
   Yip MJ, 2006, TRENDS COGN SCI, V10, P442, DOI 10.1016/j.tics.2006.08.001
   Yoon Sunmin, 2018, MUSICULTURES, V45, P92
   Yust J., 2018, Organized time: Rhythm, tonality, and form
   Zeder MA, 2008, P NATL ACAD SCI USA, V105, P11597, DOI 10.1073/pnas.0801317105
   Zemtsovsky I, 1997, ETHNOMUSICOLOGY, V41, P185, DOI 10.2307/852602
   Zemtsovsky I., 2002, MUSIC ACAD, V4, P100
   Zemtsovsky I., 1983, POPULAR SONG PROBLEM, P22
   Zemtsovsky I., 2005, MUZIKOLOSKOG I SRPSK, V5, P195, DOI [10.2298/MUZ0505195Z, DOI 10.2298/MUZ0505195Z]
   Zemtsovsky I., 2011, CLASSIC FOLKLORE TOD, P199
   Zemtsovsky I., 1979, STYLISTIC TRENDS SOV, P137
   Zeskind P. S., 1985, INFANT CRYING, P159, DOI 10.1007/978-1-4613-2381-5_8
   Zimmermann E., 2013, Evolution of emotional communication: From sounds in nonhuman mammals to speech and music in men, P117, DOI [10.1093/acprof:oso/9780199583560.001.0001, DOI 10.1093/ACPROF:OSO/9780199583560.001.0001]
   Zuberbühler K, 2017, SPRINGER HANDB AUDIT, V63, P175, DOI 10.1007/978-3-319-59478-1_7
   Zubrow E. B. W., 2006, ARCHAEOACOUSTICS
NR 539
TC 2
Z9 2
U1 2
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD JUL 23
PY 2020
VL 11
AR 1358
DI 10.3389/fpsyg.2020.01358
PG 45
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA NB5BD
UT WOS:000560526700001
PM 32848961
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Rozlozsniková, H
AF Rozlozsnikova, Hana
TI Poem - Text and/or Image: Louise Dupre and Anouk Van Renterghem
SO ROMANICA OLOMUCENSIA
LA French
DT Article
DE poem; imaginary; imagination; pastels; mediation
AB The collection Carnet Ocre by Louise Dupre, a poet, novelist, and playwright from Quebec, and Anouk Van Renterghem, an artist from Brussels, approaches the intimate meditation of the personal experience of the quest for the poetic and creative voice emerging and radiating from the heart of the "Earth-ocher" because, as Louise Dupre states in the dedication: "we are Earthlings and we love the Earth, which gives us life". This collection succeeds in meeting the challenge of playing the score of the emotion of the encounter in the textual and graphic universe. Each poem is accompanied by a dry pastel that communicates directly to the text beside it by answering and supplementing it. What interests us in this versatile universe is the artistic strategies ensuring the correspondences, the analogies, and the union of these two main components - text and image, the whole of which forms the basis of the texto-scriptural imaginary. As for the way in which the "poems-pastels" of Louise Dupre and Anouk Van Renterghem are analysed, the focus on them of this paper will be from a thematic/symbolic point of view (cf. the instance of the imagination) by relying on semantic analytical (cf. mediation theory), musical (cf. prosodic harmony), and artistic (cf. chromatic circle theory, additive and subtractive theory) tools. This extension has helped to understand the evolution of the poetics and mediations that constitute the universe of the imaginary - the dynamic Earth poetics that come from the creation. The Imagination under study translates the process of birth, affirmation, and rebirth of the great voice of the lyrical subjectKeywords:
C1 [Rozlozsnikova, Hana] Univ W Bohemia, Katedra Romanskych Jazyku, Fak Filozoficka, Sedlackova 38, Plzen 30614, Czech Republic.
C3 University of West Bohemia Pilsen
RP Rozlozsniková, H (corresponding author), Univ W Bohemia, Katedra Romanskych Jazyku, Fak Filozoficka, Sedlackova 38, Plzen 30614, Czech Republic.
EM rozlozsnikovah@seznam.cz
OI Rozlozsnikova, Hana/0000-0001-6689-5685
CR [Anonymous], 1979, PHOTOGRAPHIE
   [Anonymous], 1982, POETIQUE IMAGINAIRE
   Bachelard G., 2010, TERRE REVERIES REPOS
   Bachelard Gaston, 1994, LAIR ET LES SONGES
   Bachelard Gaston, 2004, TERRE REVERIES VOLON
   Didi-Huberman Georges, 2008, MEDIAMORPHOSES
   Groupe, 1977, RHETORIQUE POESIE LE
   Gusdorf Georges, 1960, CLASSIQUES SCI SOCIA, P11
   Jung Carl Gustav, 1950, TYPES PSYCHOLOGIQUES
   Louise Dupre, 2018, CARNET OCRE
   Piaget J., 1945, FORMATION SYMBOLE CH
   Schelling Friedrich Wilhelm, 1927, PHILOS ART
NR 12
TC 0
Z9 0
U1 0
U2 0
PU PALACKY UNIV, DEPT ROMANCE PHILOSOPHICAL FAC
PI OLOMOUC
PA KRIZKOVSKEHO 10, OLOMOUC, 77180, CZECH REPUBLIC
SN 1803-4136
J9 ROMANICA OLOMUC
JI Romanica Olomuc.
PY 2020
VL 32
IS 2
BP 359
EP 381
DI 10.5507/ro.2020.020
PG 23
WC Literature, Romance
WE Emerging Sources Citation Index (ESCI)
SC Literature
GA QF6ZU
UT WOS:000617043300009
OA gold
DA 2024-01-09
ER

PT J
AU Reybrouck, M
   Podlipniak, P
AF Reybrouck, Mark
   Podlipniak, Piotr
TI Preconceptual Spectral and Temporal Cues as a Source of Meaning in
   Speech and Music
SO BRAIN SCIENCES
LA English
DT Review
DE preconceptual meaning; affective vocalizations; action-oriented embodied
   approach; affect burst; speech prosody; musical expressiveness
ID INFANT PREFERENCE; MACACA-MULATTA; COMMUNICATION; CALLS; RECOGNITION;
   PERCEPTION; EXPRESSION; EVOLUTION; RESPONSES; EMOTION
AB This paper explores the importance of preconceptual meaning in speech and music, stressing the role of affective vocalizations as a common ancestral instrument in communicative interactions. Speech and music are sensory rich stimuli, both at the level of production and perception, which involve different body channels, mainly the face and the voice. However, this bimodal approach has been challenged as being too restrictive. A broader conception argues for an action-oriented embodied approach that stresses the reciprocity between multisensory processing and articulatory-motor routines. There is, however, a distinction between language and music, with the latter being largely unable to function referentially. Contrary to the centrifugal tendency of language to direct the attention of the receiver away from the text or speech proper, music is centripetal in directing the listener's attention to the auditory material itself. Sound, therefore, can be considered as the meeting point between speech and music and the question can be raised as to the shared components between the interpretation of sound in the domain of speech and music. In order to answer these questions, this paper elaborates on the following topics: (i) The relationship between speech and music with a special focus on early vocalizations in humans and non-human primates; (ii) the transition from sound to meaning in speech and music; (iii) the role of emotion and affect in early sound processing; (iv) vocalizations and nonverbal affect burst in communicative sound comprehension; and (v) the acoustic features of affective sound with a special emphasis on temporal and spectrographic cues as parts of speech prosody and musical expressiveness.
C1 [Reybrouck, Mark] Univ Leuven, KU Leuven, Musicol Res Grp, B-3000 Leuven, Belgium.
   [Reybrouck, Mark] Univ Ghent, IPEM, Dept Musicol, B-9000 Ghent, Belgium.
   [Podlipniak, Piotr] Adam Mickiewicz Univ, Inst Musicol, Ul Umultowska 89D, PL-61614 Poznan, Poland.
C3 KU Leuven; Ghent University; Adam Mickiewicz University
RP Reybrouck, M (corresponding author), Univ Leuven, KU Leuven, Musicol Res Grp, B-3000 Leuven, Belgium.; Reybrouck, M (corresponding author), Univ Ghent, IPEM, Dept Musicol, B-9000 Ghent, Belgium.
EM Mark.Reybrouck@kuleuven.be; podlip@amu.edu.pl
OI Podlipniak, Piotr/0000-0002-4326-559X; Reybrouck,
   Mark/0000-0001-9237-1017
CR Ackermann H, 2014, BEHAV BRAIN SCI, V37, DOI 10.1017/S0140525X1400003X
   Altenmuller E., 2013, The Evolution of Emotional Communication: From Sounds in Nonhuman Mammals to Speech and Music in Man, V1st ed.
   [Anonymous], 2010, Adam's tongue: How Humans Made Language, How Language Made Humans
   [Anonymous], 1999, MUSICAE SCI, DOI DOI 10.1177/10298649000030S109
   [Anonymous], 2006, SINGING NEANDERTHALS
   [Anonymous], P ISCA WORKSH SPEECH
   [Anonymous], MUSICAL BEGINNINGS
   [Anonymous], [No title captured]
   [Anonymous], BIOALGORITHMS MED SY
   Arias P, 2018, CURR BIOL, V28, pR782, DOI 10.1016/j.cub.2018.05.084
   Arnal LH, 2015, CURR BIOL, V25, P2051, DOI 10.1016/j.cub.2015.06.043
   Aryani A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0198430
   Aryani A, 2018, BEHAV SCI-BASEL, V8, DOI 10.3390/bs8060056
   Aryani A, 2018, BRAIN SCI, V8, DOI 10.3390/brainsci8060094
   Aryani Arash, 2018, THESIS
   Aubergé V, 2003, SPEECH COMMUN, V40, P87, DOI 10.1016/S0167-6393(02)00077-8
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Bänziger T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0136675
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   BIRD S, 1990, J LINGUIST, V26, P33, DOI 10.1017/S0022226700014419
   Bradley MM, 2000, PSYCHOPHYSIOLOGY, V37, P204, DOI 10.1111/1469-8986.3720204
   Brandt A, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00327
   BROWMAN CP, 1992, PHONETICA, V49, P155, DOI 10.1159/000261913
   Brown S, 2000, ORIGINS OF MUSIC, P271
   Brown S, 2000, ORIGINS OF MUSIC, P3
   Bryant Gregory A, 2013, Front Psychol, V4, P990, DOI 10.3389/fpsyg.2013.00990
   Chi TS, 1999, J ACOUST SOC AM, V106, P2719, DOI 10.1121/1.428100
   Clynes M, 1977, SENTICS TOUCH EMOTIO
   COOPER RP, 1990, CHILD DEV, V61, P1584, DOI 10.2307/1130766
   Cross I, 2001, ANN NY ACAD SCI, V930, P28, DOI 10.1111/j.1749-6632.2001.tb05723.x
   Cross I., 2001, PSYCHOL MUSIC, V29, P95, DOI DOI 10.1177/0305735601291007
   Cross I, 2009, MUSIC SCI, P179
   Darwin G., 1871, P423
   Drake Carolyn, 2003, The cognitive neuroscience of music, P21, DOI DOI 10.1093/ACPROF:OSO/9780198525202.003.0002
   Ekman Paul, 2002, A HUMAN FACE, V2, P3
   Ewens G., 1995, KLANGE AFRIKAS ZEITG
   Fassbender C., 1996, Musical Beginnings: Origins and Development of Musical Competence, DOI [10.1093/acprof:oso/9780198523321.003.0003, DOI 10.1093/ACPROF:OSO/9780198523321.003.0003]
   Fenk-Oczlon G, 2009, MUSIC SCI, P201
   FERNALD A, 1987, INFANT BEHAV DEV, V10, P279, DOI 10.1016/0163-6383(87)90017-8
   FERNALD A, 1991, DEV PSYCHOL, V27, P209, DOI 10.1037/0012-1649.27.2.209
   Filippi P, 2017, P ROY SOC B-BIOL SCI, V284, DOI 10.1098/rspb.2017.0990
   Fischer J, 2017, NEUROSCI BIOBEHAV R, V82, P22, DOI 10.1016/j.neubiorev.2016.10.014
   Fitch W.T., 2013, EVOLUTION EMOTIONAL, V16, P27
   Fitch WT, 2006, MUSIC PERCEPT, V24, P85, DOI 10.1525/mp.2006.24.1.85
   Fitch WT, 2006, COGNITION, V100, P173, DOI 10.1016/j.cognition.2005.11.009
   Fitch WT, 2016, SCI ADV, V2, DOI 10.1126/sciadv.1600723
   Fitch WT, 2013, BIRDSONG, SPEECH, AND LANGUAGE: EXPLORING THE EVOLUTION OF MIND AND BRAIN, P489
   Fort M, 2015, LANG SPEECH, V58, P247, DOI 10.1177/0023830914534951
   Frayer DW, 2000, ORIGINS OF MUSIC, P217
   Fu QJ, 1998, J ACOUST SOC AM, V104, P505, DOI 10.1121/1.423251
   Gallese V, 1996, BRAIN, V119, P593, DOI 10.1093/brain/119.2.593
   Geissmann T, 2000, ORIGINS OF MUSIC, P103
   Ghazanfar AA, 2007, CURR BIOL, V17, P425, DOI 10.1016/j.cub.2007.01.029
   Gil-Da-Costa R, 2004, P NATL ACAD SCI USA, V101, P17516, DOI 10.1073/pnas.0408077101
   Hauser M., 1999, DESIGN ANIMAL COMMUN
   Hauser Marc D., 1996, EVOL COMMUN
   Hauser MD, 2003, NAT NEUROSCI, V6, P663, DOI 10.1038/nn1080
   Hauser MD, 2000, ORIGINS OF MUSIC, P77
   HEFFNER HE, 2016, ACOUST TODAY, V12, P20, DOI DOI 10.1063/1.5038516
   Hellbernd N, 2018, SOC COGN AFFECT NEUR, V13, P604, DOI 10.1093/scan/nsy034
   HERZOG M, 1984, AM J PRIMATOL, V7, P99, DOI 10.1002/ajp.1350070204
   Hurford J. R, 2007, The Origins of Meaning: Language in the Light of Evolution
   Huron D., 2003, COGNITIVE NEUROSCIEN, P57, DOI [DOI 10.1093/ACPROF:OSO/9780198525202.003.0005, 10.1111/j.17496632.2001.tb05724.x, DOI 10.1111/J.1749-6632.2001.TB05724.X, 10.1093/acprof:oso/9780198525202.003.0005]
   Huron D., 2015, MUSIC ANAL SEMIOTICS, P185
   Huron David, 2016, VOICE LEADING SCI MU
   Järvikivi J, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0012603
   Johnstone T., 2000, HDB EMOTIONS, V01
   Koelsch S, 2004, NAT NEUROSCI, V7, P302, DOI 10.1038/nn1197
   Kohler W., 1947, Gestalt Psychology: An Introduction to New Concepts in Modern Psychology
   Kyndrup M., 2011, WHY STUDY LIT, P85
   LEHISTE I, 1965, LANGUAGE, V41, P447, DOI 10.2307/411787
   Lewis PA, 2007, CEREB CORTEX, V17, P742, DOI 10.1093/cercor/bhk024
   Ma WY, 2015, P NATL ACAD SCI USA, V112, P14563, DOI 10.1073/pnas.1515087112
   Malloch S., 1999, Musicae Scientiae, P29, DOI [10.1177/10298649000030-104, DOI 10.1177/10298649000030S104]
   Malloch S, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01680
   Masataka N, 1999, DEV PSYCHOL, V35, P1001, DOI 10.1037/0012-1649.35.4.1001
   McAdams S., 2008, OXFORD HDB MUSIC PSY, V1, P72, DOI DOI 10.1093/OXFORDHB/9780199298457.013.0007
   McDermott J, 2005, MUSIC PERCEPT, V23, P29, DOI 10.1525/mp.2005.23.1.29
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Merker B, 2002, MUSIC SCI, V6, P3, DOI 10.1177/102986490200600101
   Merker B, 2000, ORIGINS OF MUSIC, P315
   Merker B., 2003, P 5 TRIENN C EUR SOC, P402
   Meyer J, 2008, J INT PHON ASSOC, V38, P69, DOI 10.1017/S0025100308003277
   Monaghan P, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0299
   Monrad-Krohn G.H., 1963, Problems in Dynamic Neurology, P101
   MORTON ES, 1977, AM NAT, V111, P855, DOI 10.1086/283219
   Nadel J., 1999, IMITATION INFANCY
   Newman JD, 2007, BEHAV BRAIN RES, V182, P155, DOI 10.1016/j.bbr.2007.02.011
   Ohala J, 2009, EMPIR MUSICOL REV, V4, P101, DOI 10.18061/1811/44532
   Owings D. H., 1998, Animal vocal communication: A new approach
   Owings DH, 2004, VIENNA SER THEOR BIO, P151
   Owren MJ, 2011, AM J PRIMATOL, V73, P530, DOI 10.1002/ajp.20913
   OWREN MJ, 1993, DEV PSYCHOBIOL, V26, P389, DOI 10.1002/dev.420260703
   Panksepp J, 2002, BEHAV PROCESS, V60, P133, DOI 10.1016/S0376-6357(02)00080-3
   Panksepp J, 2005, CONSCIOUS COGN, V14, P30, DOI 10.1016/j.concog.2004.10.004
   PAPOUAEK Mechthild, 1996, Musical Beginnings. Origins and Development of Musical Competence, P88
   Paquette S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00509
   Peng SC, 2012, TRENDS AMPLIF, V16, P67, DOI 10.1177/1084713812451159
   Rendall D, 1998, J ACOUST SOC AM, V103, P602, DOI 10.1121/1.421104
   Rendall D, 2010, HBK BEHAV NEUROSCI, V19, P177, DOI 10.1016/B978-0-12-374593-4.00018-8
   Rendall D, 2009, J ACOUST SOC AM, V125, P1792, DOI 10.1121/1.3068453
   Reybrouck M, 2013, BIOSEMIOTICS-NETH, V6, P585, DOI 10.1007/s12304-013-9192-6
   Roberts G, 2015, COGNITION, V141, P52, DOI 10.1016/j.cognition.2015.04.001
   Roederer J. G., 2003, Entropy, V5, DOI 10.3390/e5010003
   Rubin David C., 1995, Memory in oral traditions. The cognitive psychology of epic, ballads
   Scherer KR, 2011, INT J PSYCHOL, V46, P401, DOI 10.1080/00207594.2011.626049
   SCHERER KR, 1995, J VOICE, V9, P235, DOI 10.1016/S0892-1997(05)80231-0
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Scherer KR, 2003, SER AFFECTIVE SCI, P433
   SCHERER KR, 1978, EUR J SOC PSYCHOL, V8, P467, DOI 10.1002/ejsp.2420080405
   Schröber M, 2003, SPEECH COMMUN, V40, P99, DOI 10.1016/S0167-6393(02)00078-X
   Seifert U, 2013, STRUNGMANN FORUM REP, P203
   SEYFARTH RM, 1980, SCIENCE, V210, P801, DOI 10.1126/science.7433999
   Sievers B, 2013, P NATL ACAD SCI USA, V110, P70, DOI 10.1073/pnas.1209023110
   Snowdon CT, 2010, BIOL LETTERS, V6, P30, DOI 10.1098/rsbl.2009.0593
   Stainsby T., 2008, OXFORD HDB MUSIC PSY, P47, DOI [10.1093/oxfordhb/9780199298457.013.0005, DOI 10.1093/OXFORDHB/9780199298457.013.0005]
   Steinbeis N, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0002226
   Studdert-Kennedy M., 1987, LANGUAGE PERCEPTION, P67
   Suomi K, 2005, J PHONETICS, V33, P291, DOI 10.1016/j.wocn.2005.01.002
   Theunissen FE, 2014, NAT REV NEUROSCI, V15, P355, DOI 10.1038/nrn3731
   Thompson WF, 2012, P NATL ACAD SCI USA, V109, P19027, DOI 10.1073/pnas.1210344109
   Tolbert E., 2001, PSYCHOL MUSIC, V29, P84, DOI DOI 10.1177/0305735601291006
   Trainor LJ, 1996, INFANT BEHAV DEV, V19, P83, DOI 10.1016/S0163-6383(96)90046-6
   Trainor LJ, 1997, INFANT BEHAV DEV, V20, P383, DOI 10.1016/S0163-6383(97)90009-6
   Trehub S.E., 2003, COGNITIVE NEUROSCIEN, P2, DOI [10.1093/acprof:oso/9780198525202.003.0001, DOI 10.1093/ACPROF:OSO/9780198525202.003.0001]
   Trehub SE, 2006, COGNITION, V100, P73, DOI 10.1016/j.cognition.2005.11.006
   TREHUB SE, 1993, INFANT BEHAV DEV, V16, P285, DOI 10.1016/0163-6383(93)80036-8
   Ullrich S, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01200
   Wallin NL, 1991, Biomusicology: neurophysiological, neuropsychological, and evoluitonary perspectives on the orgins and purposes of music
   Watson SK, 2015, CURR BIOL, V25, P495, DOI 10.1016/j.cub.2014.12.032
   WERKER JF, 1989, CAN J PSYCHOL, V43, P230, DOI 10.1037/h0084224
   Wermke K, 2009, MUSIC SCI, P151, DOI 10.1177/1029864909013002081
   WierOd L.M.L., 2015, MUSIC ANAL SEMIOTICS, P135
   Xu L, 2005, J ACOUST SOC AM, V117, P3255, DOI 10.1121/1.1886405
   Zentner MR, 1996, NATURE, V383, P29, DOI 10.1038/383029a0
   Zimmermann E., 2013, Evolution of emotional communication: From sounds in nonhuman mammals to speech and music in men, P117, DOI [10.1093/acprof:oso/9780199583560.001.0001, DOI 10.1093/ACPROF:OSO/9780199583560.001.0001]
NR 136
TC 14
Z9 14
U1 2
U2 15
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3425
J9 BRAIN SCI
JI Brain Sci.
PD MAR 1
PY 2019
VL 9
IS 3
AR 53
DI 10.3390/brainsci9030053
PG 18
WC Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Neurosciences & Neurology
GA HT1YU
UT WOS:000464361200003
PM 30832292
OA Green Published, gold, Green Submitted
DA 2024-01-09
ER

PT J
AU Christensen, JF
   Gaigg, SB
   Gomila, A
   Oke, P
   Calvo-Merino, B
AF Christensen, Julia F.
   Gaigg, Sebastian B.
   Gomila, Antoni
   Oke, Peter
   Calvo-Merino, Beatriz
TI Enhancing emotional experiences to dance through music: the role of
   valence and arousal in the cross-modal bias
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE cross-modal; affective body movement; multisensory; neuroentrainment;
   psychology of emotion; neuroesthetics; arousal; valence
ID GALVANIC SKIN-RESPONSES; INFLUENCE RECOGNITION; COLLEGE-STUDENTS; BRAIN;
   PERCEPTION; STIMULI; VOICE; EXPRESSIONS; MECHANISMS; PICTURES
AB It is well established that emotional responses to stimuli presented to one perceptive modality (e.g., visual) are modulated by the concurrent presentation of affective information to another modality (e.g., auditory) an effect known as the cross-modal bias. However, the affective mechanisms mediating this effect are still not fully understood. It remains unclear what role different dimensions of stimulus valence and arousal play in mediating the effect, and to what extent cross-modal influences impact not only our perception and conscious affective experiences, but also our psychophysiological emotional response. We addressed these issues by measuring participants' subjective emotion ratings and their Galvanic Skin Responses (GSR) in a cross-modal affect perception paradigm employing videos of ballet dance movements and instrumental classical music as the stimuli. We chose these stimuli to explore the cross-modal bias in a context of stimuli (ballet dance movements) that most participants would have relatively little prior experience with. Results showed (i) that the cross-modal bias was more pronounced for sad than for happy movements, whereas it was equivalent when contrasting high vs. low arousal movements; and (ii) that movement valence did not modulate participants' GSR, while movement arousal did, such that GSR was potentiated in the case of low arousal movements with sad music and when high arousal movements were paired with happy music. Results are discussed in the context of the affective dimension of neuroentrainment and with regards to implications for the art community.
C1 [Christensen, Julia F.; Gomila, Antoni] Univ Balearic Isl, Dept Psychol & Human Evolut & Cognit IFISC CSIC, Palma De Mallorca 07122, Spain.
   [Gaigg, Sebastian B.; Oke, Peter; Calvo-Merino, Beatriz] City Univ London, Dept Psychol, Sch Arts & Social Sci, London EC1V 0HB, England.
   [Calvo-Merino, Beatriz] Univ Complutense Madrid, Dept Psychol, Madrid, Spain.
C3 Universitat de les Illes Balears; City University London; Complutense
   University of Madrid
RP Christensen, JF (corresponding author), Univ Balearic Isl, Dept Psychol & Human Evolut & Cognit IFISC CSIC, Univ Campus,Bldg Guillem Cifre de Colonya, Palma De Mallorca 07122, Spain.
EM julia.christensen@ulb.es
RI Gomila, Antoni/I-1342-2012; Christensen, Julia F./AAK-4477-2021;
   Calvo-Merino, Beatriz/V-8924-2018
OI Christensen, Julia F./0000-0003-0381-5101; Gaigg,
   Sebastian/0000-0003-2644-7145; Calvo-Merino, Beatriz/0000-0003-4669-4573
FU Spanish Government: Ministry of Economy and Competitiveness
   [FFI2010-20759]; FPU PHD scholarship from the Spanish Ministry of
   Education, Culture and Sports [AP2009-2889]; Spanish Ministry of Economy
   and Competitiveness [RYC-2008-03090, PSI2012-34558]
FX The study was funded by the research project FFI2010-20759 (Spanish
   Government: Ministry of Economy and Competitiveness). Julia Frimodt
   Christensen was supported by FPU PHD scholarship from the Spanish
   Ministry of Education, Culture and Sports (AP2009-2889). Beatriz
   Calvo-Merino was supported by the grant RYC-2008-03090 and PSI2012-34558
   from the Spanish Ministry of Economy and Competitiveness.
CR [Anonymous], POWERLAB DAT ACQ UN
   [Anonymous], 2011, P SIGCHI C HUMAN FAC, DOI DOI 10.1145/1978942.1979210
   [Anonymous], GISELLE
   [Anonymous], RITE SPRING
   [Anonymous], BOLERO
   [Anonymous], SWAN LAKE
   [Anonymous], LABCHART 7 V7 3 1
   [Anonymous], EXPRESSION PERFORMIN
   [Anonymous], 2000, COGNITIVE NEUROSCIEN
   [Anonymous], 1977, MUSIC BRAIN STUDIES
   [Anonymous], J MUSIC THER
   Bastiaansen JACJ, 2009, PHILOS T R SOC B, V364, P2391, DOI 10.1098/rstb.2009.0058
   Baumgartner T, 2006, INT J PSYCHOPHYSIOL, V60, P34, DOI 10.1016/j.ijpsycho.2005.04.007
   Baumgartner T, 2006, BRAIN RES, V1075, P151, DOI 10.1016/j.brainres.2005.12.065
   Baumgartner T, 2007, NEUROREPORT, V18, P261, DOI 10.1097/WNR.0b013e328012272e
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Bradley MM, 2001, EMOTION, V1, P276, DOI 10.1037//1528-3542.1.3.276
   Calvo-Merino B, 2008, CONSCIOUS COGN, V17, P911, DOI 10.1016/j.concog.2007.11.003
   Carvalho S, 2012, APPL PSYCHOPHYS BIOF, V37, P279, DOI 10.1007/s10484-012-9201-6
   Chatterjee A., 2010, EMPIR STUD ARTS, V28, P207, DOI DOI 10.2190/EM.28.2.F
   Christensen JF, 2014, PERCEPTION, V43, P178, DOI 10.1068/p7581
   Christensen JF, 2013, PSYCHOL AESTHET CREA, V7, P76, DOI 10.1037/a0031827
   Cohen J, 1988, STAT POWER ANAL BEHA, V12, P13
   Cross ES, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00102
   de Gelder B, 2000, COGNITION EMOTION, V14, P289, DOI 10.1080/026999300378824
   de Gelder B, 1999, NEUROSCI LETT, V260, P133, DOI 10.1016/S0304-3940(98)00963-X
   Eitan Z, 2006, MUSIC PERCEPT, V23, P221, DOI 10.1525/mp.2006.23.3.221
   Ethofer T, 2006, HUM BRAIN MAPP, V27, P707, DOI 10.1002/hbm.20212
   Green AC, 2008, NEUROREPORT, V19, P711, DOI 10.1097/WNR.0b013e3282fd0dd8
   Grosbras MH, 2012, BRAIN STIMUL, V5, P130, DOI 10.1016/j.brs.2012.03.013
   Holbrook M.B., 1990, Psychology of Music, V18, P150, DOI [10.1177/0305735690182004, DOI 10.1177/0305735690182004]
   James W., 1894, PSYCHOL REV, V1, P516, DOI [10.1037/h0065078, DOI 10.1037/H0065078]
   Jang SH, 2011, DANCE RES, V29, P352, DOI 10.3366/drs.2011.0024
   Jefferies LN, 2008, PSYCHOL SCI, V19, P290, DOI 10.1111/j.1467-9280.2008.02082.x
   Jeong JW, 2011, NEUROIMAGE, V54, P2973, DOI 10.1016/j.neuroimage.2010.11.017
   Jola C, 2011, DANCE RES, V29, P378, DOI 10.3366/drs.2011.0025
   Jola C, 2012, PHENOMENOL COGN SCI, V11, P17, DOI 10.1007/s11097-010-9191-x
   Khalfa S, 2005, NEUROREPORT, V16, P1981, DOI 10.1097/00001756-200512190-00002
   Kreibig SD, 2010, BIOL PSYCHOL, V84, P394, DOI 10.1016/j.biopsycho.2010.03.010
   Krumhansl C., 1997, MUSIC SCI, V1, P63, DOI [DOI 10.1177/102986499700100105, DOI 10.1111/J.1469-8986.1969]
   Laird JD, 2014, EMOT REV, V6, P27, DOI 10.1177/1754073913494899
   LeDoux J, 2003, CELL MOL NEUROBIOL, V23, P727, DOI 10.1023/A:1025048802629
   LeDoux J, 2012, NEURON, V73, P653, DOI 10.1016/j.neuron.2012.02.004
   Logeswaran N, 2009, NEUROSCI LETT, V455, P129, DOI 10.1016/j.neulet.2009.03.044
   Massaro DW, 1996, PSYCHON B REV, V3, P215, DOI 10.3758/BF03212421
   McDonald J. H., 2009, HANDBOOKOFBIOLOGICAL, V2nd
   Mitterschiffthaler MT, 2007, HUM BRAIN MAPP, V28, P1150, DOI 10.1002/hbm.20337
   Pallesen KJ, 2005, ANN NY ACAD SCI, V1060, P450, DOI 10.1196/annals.1360.047
   Rickard N. S., 2004, Psychology of Music, V32, P371, DOI [10.1177%2F0305735604046096, DOI 10.1177/0305735604046096, 10.1177/0305735604046096]
   Rothman K J, 1990, Epidemiology, V1, P43, DOI 10.1097/00001648-199001000-00010
   Salimpoor VN, 2013, SCIENCE, V340, P216, DOI 10.1126/science.1231059
   Salimpoor VN, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0007487
   SAVILLE DJ, 1990, AM STAT, V44, P174, DOI 10.2307/2684163
   SCHACHTER S, 1962, PSYCHOL REV, V69, P379, DOI 10.1037/h0046234
   SCHNEIDER F, 1994, PSYCHIAT RES, V51, P19, DOI 10.1016/0165-1781(94)90044-2
   Shapiro KL, 1997, J EXP PSYCHOL HUMAN, V23, P504, DOI 10.1037/0096-1523.23.2.504
   Sievers B, 2013, P NATL ACAD SCI USA, V110, P70, DOI 10.1073/pnas.1209023110
   Sloboda J.A., 2010, HDB MUSIC EMOTION TH, P879
   Stein BE, 1996, J COGNITIVE NEUROSCI, V8, P497, DOI 10.1162/jocn.1996.8.6.497
   Van den Stock J, 2007, EMOTION, V7, P487, DOI 10.1037/1528-3542.7.3.487
   Van den Stock J, 2009, BRAIN TOPOGR, V21, P216, DOI 10.1007/s10548-009-0099-0
   Van den Stock J, 2008, BRAIN RES, V1242, P185, DOI 10.1016/j.brainres.2008.05.040
   VANDERARK SD, 1992, PERCEPT MOTOR SKILL, V74, P1079, DOI 10.2466/PMS.74.4.1079-1090
   VANDERARK SD, 1993, PERCEPT MOTOR SKILL, V77, P227, DOI 10.2466/pms.1993.77.1.227
   Vines BW, 2011, COGNITION, V118, P157, DOI 10.1016/j.cognition.2010.11.010
   Vorst HCM, 2001, PERS INDIV DIFFER, V30, P413, DOI 10.1016/S0191-8869(00)00033-7
   Vroomen J, 2000, J EXP PSYCHOL HUMAN, V26, P1583, DOI 10.1037/0096-1523.26.5.1583
   Vuilleumier P, 2005, TRENDS COGN SCI, V9, P585, DOI 10.1016/j.tics.2005.10.011
NR 68
TC 34
Z9 37
U1 3
U2 51
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD OCT 6
PY 2014
VL 8
DI 10.3389/fnhum.2014.00757
PG 9
WC Neurosciences; Psychology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Neurosciences & Neurology; Psychology
GA AQ1QC
UT WOS:000342554900001
PM 25339880
OA Green Accepted, Green Published, gold
DA 2024-01-09
ER

PT J
AU Moshe, M
AF Moshe, Mira
TI The normalization of fear: Geo-cultural vs. universal emotional
   sensibilities as reflected in the annual Israeli Radio Hit Parade
SO INTERNATIONAL SOCIOLOGY
LA English
DT Article
DE Fear; emotional sensibilities; geo-cultural; popular music; universal
ID POPULAR-MUSIC; LEBANON WAR; TERROR; SPACE; BOYS; MASCULINITY; SOCIOLOGY;
   DISCOURSE; GEOGRAPHY; POLITICS
AB Music plays an important socio-cultural role in constructing and/or reflecting geo-cultural and universal emotional states by giving voice to personal emotional sensibilities, such as self-searching, romantic longing, and desire, alongside collective spatial sentiments, patriotism, etc. Moreover, popular song lyrics reveal the socio-cultural values, norms, tastes, and emotional conventions of both their creators and their audience. Thus, this article focuses on decoding geo-cultural vs. universal emotional sensibilities via narrative analysis of the first place winners of the annual Israeli Hit Parades between 1963 and 2018, broadcast on the two major Israeli radio stations, Kol Yisrael and Galgalatz, every year on the eve of the Jewish New Year. This long-standing tradition offers a unique opportunity to examine ongoing changes in socio-emotional coping with fear and death, wars and terror while providing a contemporary conceptual and practical inquiry into the normalization of emotions within a culture and politics of fear.
C1 [Moshe, Mira] Ariel Univ, Dept Sociol & Anthropol, 108 H Tavor St,POB 1543, IL-6082418 Shoham, Israel.
C3 Ariel University
RP Moshe, M (corresponding author), Ariel Univ, Dept Sociol & Anthropol, 108 H Tavor St,POB 1543, IL-6082418 Shoham, Israel.
EM miram@ariel.ac.il
OI Moshe, Mira/0000-0001-9063-5904
CR Allen L, 2007, MEN MASC, V10, P137, DOI 10.1177/1097184X05284221
   [Anonymous], 1998, J CULT GEOGR
   [Anonymous], 1997, ISR STUD
   Barrett FS, 2010, EMOTION, V10, P390, DOI 10.1037/a0019006
   Beck JS., 2011, Cognitive therapy of anxiety disorders; science and practice
   Bericat E, 2016, CURR SOCIOL, V64, P491, DOI 10.1177/0011392115588355
   Berland Jody, 2009, N EMPIRE ESSAYS CULT
   Bilu Y., 2000, Israel Studies, V5, P1
   Bleiker R, 2008, REV INT STUD, V34, P115, DOI 10.1017/S0260210508007821
   Bondi L., 2002, Subjectivities, Knowledges, and Feminist Geographies: The Subjects and Ethics of Social Research
   Bosacki SL, 2015, INT J ADOLESC YOUTH, V20, P228, DOI 10.1080/02673843.2013.785438
   Bourke J., 2006, Fear: A Cultural History
   Bowlby J., 1982, Attachment, V1, DOI DOI 10.1093/SW/26.4.355
   Bulag UE, 2003, AM ANTHROPOL, V105, P452, DOI 10.1525/aa.2003.105.2.452
   BYKLUM D, 1994, J GEOGR, V93, P274, DOI 10.1080/00221349408979833
   Canova N, 2013, SOC CULT GEOGR, V14, P861, DOI 10.1080/14649365.2013.839824
   Cidra R, 2018, POSTCOLONIAL STUD-UK, V21, P433, DOI 10.1080/13688790.2018.1542575
   Clewell T, 2004, J AM PSYCHOANAL ASS, V52, P43, DOI 10.1177/00030651040520010601
   Connell J, 2003, CRITICAL GEOGRAPHIES, P1
   Connell R, 2008, SPORT EDUC SOC, V13, P131, DOI 10.1080/13573320801957053
   Daiute C., 2004, Narrative analysis: Studying the development o f individuals in society
   Davidson J, 2004, SOC CULT GEOGR, V5, P523, DOI 10.1080/1464936042000317677
   Davis D, 2003, PERS SOC PSYCHOL B, V29, P871, DOI 10.1177/0146167203029007006
   Drewett M., 2008, Consumption Markets and Culture, V11, P287, DOI 10.1080/10253860802391292
   ESLINGER RL, 2002, WEB PREACHING NEW OP
   FERBER I, 2006, E REA REV ELECT ETUD, V4, P66
   Friedman-Peleg K, 2011, TRANSCULT PSYCHIATRY, V48, P416, DOI 10.1177/1363461511410239
   Frith Simon, 1996, PERFORMING RITES VAL
   Furedi F., 2006, Culture of Fear Revisited, V4
   Garfinkel SN, 2014, J NEUROSCI, V34, P6573, DOI 10.1523/JNEUROSCI.3507-13.2014
   GOLDBERG H, 2000, HAZARDS BEING MALE S
   GREEN L, 1994, CULT ANTHROPOL, V9, P227, DOI 10.1525/can.1994.9.2.02a00040
   Grossmann K, 2002, SOC DEV, V11, P307
   HADIDA AE, 2015, REFLECTION ISRAELI S
   Hamilton K, 2011, CRIT STUD TERROR, V4, P127, DOI 10.1080/17539153.2011.586199
   Hesmondhalgh D., 2008, Consumption Markets and Culture, V11, P329, DOI 10.1080/10253860802391334
   Horowitz A, 1999, J AM FOLKLORE, V112, P450, DOI 10.2307/541372
   *ISR CULT TEAM, 2020, PRAH BA QAN
   JAEGER CS, 2003, CODIERUNGEN EMOTIONE, V1, pR7
   Jakubowski K, 2021, PSYCHOL MUSIC, V49, P649, DOI 10.1177/0305735619888803
   James Robin., 2015, RESILIENCE MELANCHOL
   Jennings M, 2014, CULT RELIG-ABINGDON, V15, P211, DOI 10.1080/14755610.2014.911195
   Jordan E., 1995, Genero y Educacion, V7, P69, DOI [10.1080/713668458, DOI 10.1080/713668458]
   Jordan MF, 2013, POP COMMUN, V11, P99, DOI 10.1080/15405702.2013.779484
   Juslin P., 2010, Handbook of Music and Emotion: Theory, Research, Applications, P453, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0017
   Kallinen K., 2005, Psychology of Music, V33, P373, DOI DOI 10.1177/0305735605056147
   KAPLAN D, 2011, ISRAELI SOCIOLOGY, V13, P135
   Kaplan D, 2012, POETICS, V40, P217, DOI 10.1016/j.poetic.2012.03.001
   Kaplan D, 2009, CULT ANTHROPOL, V24, P313, DOI 10.1111/j.1548-1360.2009.01133.x
   Katz Y, 2014, ISR AFF, V20, P271, DOI 10.1080/13537121.2014.889888
   Kemper T. D., 1978, A Social Interactional Theory of Emotions
   Kitiarsa P, 2009, INTER-ASIA CULT STUD, V10, P381, DOI 10.1080/14649370902949374
   Kober A, 2008, J STRATEGIC STUD, V31, P3, DOI 10.1080/01402390701785211
   KONENI VJ, 2010, SERIES AFFECTIVE SCI, P698
   KONG L, 1995, PROG HUM GEOG, V19, P183, DOI 10.1177/030913259501900202
   LaCapra D., 2001, WRITING HIST WRITING
   Lewandowski GW, 2006, PERS RELATIONSHIP, V13, P317, DOI 10.1111/j.1475-6811.2006.00120.x
   LOMSKYFEDER E, 1998, THERE WAS WAR
   LOMSKYFEDER E, 2011, PRACTICE WAR, P111
   MALIN BJ, 2005, AM MASCULINITY CLINT, V7
   Mantie R, 2013, J RES MUSIC EDUC, V61, P334, DOI 10.1177/0022429413497235
   Margold JA, 1999, CRIT ANTHROPOL, V19, P63, DOI 10.1177/0308275X9901900102
   Marik M, 2016, MUSIC SCI, V20, P53, DOI 10.1177/1029864915622055
   Mason AE, 2012, PERS RELATIONSHIP, V19, P551, DOI 10.1111/j.1475-6811.2011.01378.x
   McCarthy E. Doyle, 1989, SOCIOLOGY EMOTIONS O, P51
   Miranda D, 2011, EUR REV APPL PSYCHOL, V61, P1, DOI 10.1016/j.erap.2010.10.002
   MLANIK P, 2018, DRUZBOSLOVNE RAZPRAV, V34, P113
   MURPHEY T, 1992, TESOL QUART, V26, P770, DOI 10.2307/3586887
   Musiyiwa M, 2008, MUZIKI, V5, P11, DOI 10.1080/18125980802633011
   Nash PH, 1996, CAN GEOGR-GEOGR CAN, V40, P69, DOI 10.1111/j.1541-0064.1996.tb00433.x
   Neiger M, 2011, MEDIA CULT SOC, V33, P971, DOI 10.1177/0163443711415741
   Ochs J, 2011, ETHNOGR POLIT VIOLEN, P1
   Pain R, 2009, PROG HUM GEOG, V33, P466, DOI 10.1177/0309132508104994
   Pain Rachel., 2008, Fear: Critical geopolitics and everyday life
   Pribram ED, 2011, CRIT STUD, V34, P21
   Pyka M, 2019, J EUR STUD, V49, P448, DOI 10.1177/0047244119859178
   Regev M, 2004, POPULAR MUSIC AND NATIONAL CULTURE IN ISRAEL, P1
   Renold E, 2001, BRIT J SOCIOL EDUC, V22, P369, DOI 10.1080/01425690120067980
   Reshef Y, 2012, ISR STUD, V17, P157, DOI 10.2979/israelstudies.17.1.157
   Riessman CK., 1993, NARRATIVE ANAL
   Ritzarev M, 2018, NAUKA TELEVIDENIYA, V14, P28, DOI 10.30628/1994-9529-2018-14.3-28-72
   Rubenstein Roberta, 2001, HOME MATTERS LONGING
   Shah TM, 2013, INT SOCIOL, V28, P513, DOI 10.1177/0268580913496920
   Sharp J, 2011, GEOFORUM, V42, P297, DOI 10.1016/j.geoforum.2011.04.005
   Shobe H, 2010, J GEOGR, V109, P87, DOI 10.1080/00221341.2010.482160
   Simmons RV, 1997, J ASIAN STUD, V56, P757, DOI 10.2307/2659615
   Skattebol J, 2006, GENDER EDUC, V18, P507, DOI 10.1080/09540250600881667
   Slotter EB, 2010, PERS SOC PSYCHOL B, V36, P147, DOI 10.1177/0146167209352250
   Spielmann SS, 2016, J PERS, V84, P799, DOI 10.1111/jopy.12222
   Srbljinovic A, 2014, EMOT REV, V6, P152, DOI 10.1177/1754073913503371
   Thompson WF, 2019, PSYCHOL POP MEDIA CU, V8, P218, DOI 10.1037/ppm0000184
   Trapido J, 2010, J AFR CULT STUD, V22, P121, DOI 10.1080/13696815.2010.491316
   Ugilt R, 2012, METAPHYSICS TERROR I
   Valassopoulos A, 2014, POP MUSIC SOC, V37, P638, DOI 10.1080/03007766.2014.910905
   van Venrooij A, 2009, POETICS, V37, P315, DOI 10.1016/j.poetic.2009.06.005
   Ware P. D., 2006, Language Arts, V84, P45
   Webb M, 2008, MUSICOL AUST, V30, P147, DOI 10.1080/08145857.2008.10416752
   Wickberg D, 2007, AM HIST REV, V112, P661, DOI 10.1086/ahr.112.3.661
   Witztum E, 2001, ISRAEL J PSYCHIAT, V38, P157
   YALCNKAYA CT, 2008, NEO MACQUARIE U FACU, P1
   Young A., 1997, The harmony of illusions: Inventing post-traumatic stress disorder
NR 101
TC 1
Z9 1
U1 0
U2 2
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0268-5809
EI 1461-7242
J9 INT SOCIOL
JI Int. Sociol.
PD JUL
PY 2021
VL 36
IS 4
SI SI
BP 532
EP 553
AR 0268580921993334
DI 10.1177/0268580921993334
EA MAY 2021
PG 22
WC Sociology
WE Social Science Citation Index (SSCI)
SC Sociology
GA TE4EZ
UT WOS:000653318500001
DA 2024-01-09
ER

PT J
AU Klorman, E
AF Klorman, Edward
TI Koch, Carpani, and Momigny: Theorists of Agency in the Classical String
   Quartet?
SO MUSIC THEORY ONLINE
LA English
DT Article
DE agency; Carpani; conversation; Hauptstimme; Haydn; Koch; Momigny;
   Mozart; multiple agency; Schulz; string quartet; Sulzer; texture
ID HAYDN
AB This study examines historical writings about the "Classical" string quartet, a genre often compared to artful conversation. The conversation metaphor implicitly suggests "multiple agency" (Klorman 2016), whereby the four parts (or players) are interpreted as representing independent characters or personas. This paradigm contrasts sharply with the more monological musical personifications advanced in many recent writings on musical agency, such as Cone's influential The Composer's Voice (1974), which posit a "central intelligence" representing the "mind" of the composition, its fictional protagonist, or its composer. Focusing principally on discussions of Haydn's and Mozart's quartets in H. C. Koch's Versuch (1793), J. J. de Momigny's Cours complet (1806), and G. Carpani's Le Haydine (1812), I examine whether instrumental personas postulated by each author constitute genuine agents, according to criteria developed in Monahan 2013. At issue is whether personas are described as possessing (1) such anthropomorphic qualities as sentience, volition, and emotion; and (2) a capacity for independent action or utterance.
C1 [Klorman, Edward] McGill Univ, Schulich Sch Mus, 555 Rue Sherbrooke O, Montreal, PQ H3A 1E3, Canada.
C3 McGill University
RP Klorman, E (corresponding author), McGill Univ, Schulich Sch Mus, 555 Rue Sherbrooke O, Montreal, PQ H3A 1E3, Canada.
EM edward.klorman@mcgill.ca
CR [Anonymous], COURS COMPLET HARMON
   [Anonymous], 1974, J AM MUSICOLOGICAL S, V27, P212
   [Anonymous], 2004, MUSIC ART, V29, P134
   [Anonymous], 1799, ESSAY PRACTICAL MUSI
   [Anonymous], 1812, HAYDINE OVVERO LETT
   Baillot Pierre, 1839, CARACTERE DIVE UNPUB, P2
   Bent Ian, 1994, Music Analysis in the Nineteenth Century
   Burke P, 1993, The Art of Conversation
   Byros V, 2012, MUSIC ANAL, V31, P273, DOI 10.1111/j.1468-2249.2012.00344.x
   Caplin WE, 2004, J AM MUSIC SOC, V57, P51, DOI 10.1525/jams.2004.57.1.51
   Cone Edward T., 1974, THE COMPOSERS VOICE
   de Momigny Jerome-Joseph, 1806, EXCERPT COMPLETE COU, P826
   de Stael Anne-Louise-Germaine, 1813, DE LALLEMAGNE, V1
   de Stael Anne-Louise-Germaine, 1861, GERMANY, V1
   della Casa Giovanni, 1558, IL GALATEO
   Eisen Cliff, 2003, THE CAMBRIDGE COMPAN, P105
   Finscher Ludwig, 1974, STUDIEN GESCH STREIC
   Framery Nicolas Etienne, 1818, ENCY METHODIQUE MUSI, V2
   Gretry Andre, 1789, MEMOIRES ESSAI MUSIQ, V1
   HEPOKOSKI James, 2006, Elements of sonata theory: Norms, types, and deformations in the late-eighteenth-century sonata
   Joachim Quaniz Joseph, 1985, ON PLAYING THE FLUTE
   Joachim Quaniz Joseph, 1752, VERSUCH ANWEISUNG FL
   Keefe Simon P, 2001, Mozart's Piano Concertos: Dramatic Dialogue in the Age of Enlightenment
   Klorman Edward, 2016, MOZARTS MUSIC FRIEND
   Koch Heinrich Christoph, 1793, INTRODUCTORY ESSAY C
   Koch Heinrich Christoph, 1802, Musikalisches Lexikon
   Koch Heinrich Christoph, 1793, VERSUCH ANLEITUNG CO, V3
   Levy Janet M, 1971, THESIS
   Monahan S, 2013, J MUSIC THEORY, V57, P321, DOI 10.1215/00222909-2323497
   Morabito Fabio, 2015, THESIS
   O'Hara William, 2017, NEWSLETTER MOZART SO, V21, P5
   Palm Albert, 1962, MOZART JB, P256
   Proctor Gregory, 1978, THESIS
   Rosen Charles, 1997, The Classical Style: Haydn, Mozart, Beethoven
   Rousseau Jean-Jacques, 1779, Dictionnaire de musique
   Schenker H., 1954, HARMONY
   Stendhal Henri-Marie Beyle, 1961, VIAGGIO ITALIANO 182
   Sulzer Johann Georg, 1771, Allgemeine Theorie der schonen Kunste
   Sulzer Johann Georg, 1996, AESTHETICS ART MUSIC
   Vayer Francois la Mothe, 1644, OPUSCULES PETITS TRA
   WEBSTER J, 1977, MUSIC QUART, V63, P390
   Webster James, 1976, J AM MUSICOLOGICAL S, V29, P413
   Will R, 1997, MUSIC LETT, V78, P175, DOI 10.1093/ml/78.2.175
NR 43
TC 0
Z9 0
U1 0
U2 0
PU SOC FOR MUSIC THEORY
PI CHICAGO
PA UNIV, CHICAGO, EPT MUSIC, 1010 EAST 59TH STREET, CHICAGO, IL 60637-1512
   USA
SN 1067-3040
J9 MUSIC THEORY ONLINE
JI Music Theory Online
PD DEC
PY 2018
VL 24
IS 4
AR 24.4.3
PG 19
WC Music
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music
GA HI5YY
UT WOS:000456531400004
DA 2024-01-09
ER

PT J
AU Graber, KJ
   Sumera, M
AF Graber, Katie J.
   Sumera, Matthew
TI Interpretation, resonance, embodiment: affect theory and ethnomusicology
SO ETHNOMUSICOLOGY FORUM
LA English
DT Article
DE Affect; interpretation; resonance; embodiment; ethnomusicology; sound
   studies
ID IDENTITY; POLITICS
AB Theorising the relationship between music and affect is nothing new; scholars have long engaged the ways music expresses and influences emotions and bodily intensities. Why is it, then, that (ethno)musicologists now find themselves following rather than leading a theoretical debate that adopts so many concepts we have used for generations: intensity, embodiment, performance, resonance? This Special Issue will draw on (ethno)musicological literature that anticipated the contemporary resurgence of affect theory, and also call for an intervention in which fine-grained, ethnographically informed analysis can newly invigorate theories about the inbetweenness and intensity of encounter. The interpositions we propose centre on three ethnomusicological concepts that complicate, nuance, and refine affect theory: interpretation, resonance, and embodiment. The introduction will explicate these theoretical propositions, and the following articles will ground those concepts in fieldwork and musical particulars. The broad-ranging articles will discuss electronic dance music in Berlin, nineteenth-century operatic voices in the USA, tambura music in the USA, and musical experiences of grief. These studies will investigate and critique both affect theory and ethnomusicological methods and analysis.
C1 [Graber, Katie J.] Ohio State Univ, Sch Mus, Columbus, OH 43210 USA.
   [Sumera, Matthew] Hamline Univ, Anthropol Dept, St Paul, MN USA.
C3 University System of Ohio; Ohio State University; Mitchell Hamline
   School of Law
RP Graber, KJ (corresponding author), Ohio State Univ, Sch Mus, Columbus, OH 43210 USA.
EM katiejgraber@gmail.com
FU Hamline University's Anthropology Department
FX Special thanks to Ashley T. Thorne for copy editing assistance and to
   Hamline University's Anthropology Department for funding her position.
CR Altman Rick, 1992, SOUND THEORY SOUND P, P15
   [Anonymous], 1966, The Journal of Aesthetics and Art Criticism, DOI [10.2307/427969, DOI 10.2307/427969]
   Augoyard Jean-Francois, 2011, SONIC EXPERIENCE GUI
   Barthes Roland, 1977, Image Music Text., P142
   Becker J., 2004, Deep listeners: Music emotions and trancing
   Behnke EA, 1997, HUM STUD, V20, P181, DOI 10.1023/A:1005372501258
   Bennett Jane, 2009, Vibrant Matter: A Political Ecology of Things
   Bourdieu P., 1990, The logic ofpractice, DOI DOI 10.1017/CBO9780511812507
   Brubaker R, 2000, THEOR SOC, V29, P1, DOI 10.1023/A:1007068714468
   Butler Judith., 2009, Frames of War: When Is Life Grievable?
   Clough Patricia, 2007, The Affective Turn: Theorizing the Social
   CSORDAS TJ, 1993, CULT ANTHROPOL, V8, P135, DOI 10.1525/can.1993.8.2.02a00010
   Cusick Suzanne G., 2008, RADICAL MUSICOLOGY, V3
   Daughtry J. Martin, 2015, Listening to War: Sound, Music, Trauma and Survival in Wartime Iraq
   Deleuze G., 2005, A Thousand Plateaus: Capitalism and Schizophrenia
   Doubleday Veronica., 2008, Ethnomusicology Forum, V17, P3, DOI [https://doi.org/10.1080/17411910801972909, DOI 10.1080/17411910801972909]
   Downey G, 2002, ETHNOMUSICOLOGY, V46, P487, DOI 10.2307/852720
   Erlmann V, 2015, Keywords in Sound, P175
   Erlmann V., 2010, Reason and Resonance: A History of Modern Aurality
   Feld S., 1994, Music grooves: Essays and dialogues, P77
   Feld S., 1982, Sound and Sentiment: Birds, Weeping, Poetics, and Song in Kaluli Expression
   Feld Steven, 1996, Senses of Place, P91
   Friedson Steven M., 2009, REMAINS RITUAL NO GO
   Garcia L-M, 2016, SOUND STUD, V1, P59, DOI [10.1080/20551940.2015.1079072, DOI 10.1080/20551940.2015.1079072.]
   Garcia LuisManuel, 2015, J URBAN CULT STUD, V2, P121, DOI 10.1386/jucs.2.1-2.121_1
   Gilbert J., 2004, CULTURE MACHINE, V6
   Gill Denise, 2017, Melancholic Modalities: Affect, Islam, and Turkish Classical Musicians
   Goodman Steve, 2012, Sonic Warfare: Sound, Affect, and the Ecology of Fear
   Gray Lila Ellen, 2013, Fado Resounding: Affective Politices and Urban Life
   Gregg M., 2010, The Affect Theory Reader
   Grossberg L., 1984, Popular Music, V4, P225
   Grossberg Lawrence, 2010, AFFECT THEORY READER, P309, DOI DOI 10.1215/9780822393047-014
   Guilbault J, 2019, J WORLD POP MUS, V6, P173, DOI 10.1558/jwpm.40172
   Hennessy S, 2015, TECHNOL PEDAGOG EDUC, V24, P1, DOI 10.1080/1475939X.2015.1092466
   Hofmann T, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.122801
   Hood M., 1960, Ethnomusicology, V4, P55, DOI DOI 10.2307/924263
   Hutchinson George, 2019, Cane, pxiii
   James Robin, 2019, The Sonic Episteme: Acoustic Resonance, Neoliberalism, and Biopolitics, DOI 10.1515/CCLM.2001.070
   Johnson B, 2009, ASHG POP FOLK MUSIC, P1
   Kassabian A, 2013, UBIQUITOUS LISTENING: AFFECT, ATTENTION, AND DISTRIBUTED SUBJECTIVITY, P1
   KEIL C, 1995, ETHNOMUSICOLOGY, V39, P1, DOI 10.2307/852198
   Keil C., 1987, Cultural Anthropology, V2, P275, DOI [10.1525/can.1987.2.3.02a00010, DOI 10.1525/CAN.1987.2.3.02A00010]
   Kohn E., 2013, How Forests Think: Toward an Anthropology beyond the Human
   Langer S., 1942, Philosophy in a New Key, V2
   Leys Ruth, 2017, The Ascent of Affect: Genealogy and Critique
   LOMAX A, 1959, AM ANTHROPOL, V61, P927, DOI 10.1525/aa.1959.61.6.02a00030
   MacMillen Ian., 2019, PLAYING IT DANGEROUS
   Massumi B, 1996, CULT CRIT, V31, P83, DOI [10.2307/1354446, DOI 10.2307/1354446]
   Massumi B., 2002, Parables for the virtual: Movement, affect, sensation
   McAllester David Park., 1954, Enemy Way Music: A Study of Social and Esthetic Values as Seen in Navaho Music
   McCann B. J., 2017, The Mark of Criminality: Rhetoric, Race, and Gangsta Rap in the War-on-Crime Era
   McCann BJ, 2013, CULT STUD-CRIT METHO, V13, P408, DOI 10.1177/1532708613496392
   Messeri L, 2017, AM ETHNOL, V44, P131, DOI 10.1111/amet.12431
   Meyer LB., 1956, Emotion and meaning in music
   Neumark N, 2017, LEONARDO SER, P1, DOI 10.7551/mitpress/9780262036139.001.0001
   Ngai Sianne., 2005, Ugly Feelings
   Nketia J. H. Kwabena, 1974, The Music of Africa
   Paasonen S, 2013, SOMATECHNICS, V3, P351, DOI 10.3366/soma.2013.0102
   Pettman Dominic, 2017, Sonic Intimacy: Voice, Species, Technics or, How To Listen to the World
   Pink S., 2015, Doing sensory ethnography
   Polak R, 2000, WORLD MUSIC, V42, P7
   Qureshi R., 2000, AM ETHNOL, V27, P805, DOI DOI 10.1525/ae.2000.27.4.805
   Qureshi RB, 1997, YEARB TRADIT MUSIC, V29, P1, DOI 10.2307/768295
   Rice T, 2010, ETHNOMUSICOLOGY, V54, P318
   SEDGWICK EK, 1995, CRIT INQUIRY, V21, P496, DOI 10.1086/448761
   SEEGER C, 1977, STUDIES MUSICOLOGY 1, P16
   Shouse E., 2005, M C J, V8, P26, DOI DOI 10.5204/MCJ.2443
   Sprengel D, 2019, POP MUSIC, V38, P54, DOI 10.1017/S0261143018000715
   Stewart Kathleen, 2007, ORDINARY AFFECTS
   Stoller Paul., 1997, Sensuous Scholarship
   Sumera Matthew., 2020, THEORISING MEDIA CON, P116
   Sumera Matthew, 2013, OXFORD HDB SOUND IMA, P310
   Tatro K, 2014, ETHNOMUSICOLOGY, V58, P431
   Thompson M, 2013, RSC DETECT SCI SER, V1, P1, DOI 10.1039/9781849735414
   Thrift, 2008, NONREPRESENTATIONAL
   Titon JT, 2015, MUZIKOLOSKI ZB, V51, P175, DOI 10.4312/mz.51.2.175-185
   Tomkins Silvan, 1995, Shame and Its Sisters: A Silvan Tomkins Reader. Ed
   Tomkins Silvan, 1965, Affect, Cognition, and Personality: Empirical Studies, P72
   Tomlinson G, 2016, BOUNDARY TWO, V43, P143, DOI 10.1215/01903659-3340673
   Turino T, 1999, ETHNOMUSICOLOGY, V43, P221, DOI 10.2307/852734
   Turino T, 2014, ETHNOMUSICOLOGY, V58, P185
   van Beek M, 2000, CULT ANTHROPOL, V15, P525, DOI 10.1525/can.2000.15.4.525
   Volcler Juliette, 2013, Extremely Loud: Sound as a Weapon
   Wetherell M., 2012, Affect and emotion. A new social science understanding
NR 84
TC 9
Z9 10
U1 2
U2 9
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1741-1912
EI 1741-1920
J9 ETHNOMUSICOL FORUM
JI Ethnomusicol. Forum
PD JAN 2
PY 2020
VL 29
IS 1
SI SI
BP 3
EP 20
DI 10.1080/17411912.2020.1808501
EA SEP 2020
PG 18
WC Music
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music
GA OA2KY
UT WOS:000569832600001
DA 2024-01-09
ER

PT J
AU Podlipniak, P
AF Podlipniak, Piotr
TI The evolutionary origin of pitch centre recognition
SO PSYCHOLOGY OF MUSIC
LA English
DT Article
DE emotion; evolution; functions of music; pitch; tonality
ID EMOTIONAL RESPONSES; TONAL HIERARCHIES; WORKING-MEMORY; MUSIC;
   PERCEPTION; LANGUAGE; EXPECTANCY; CRITIQUE; BIRDSONG
AB The ability to recognize a pitch centre in sound sequences belongs to the basic mental tools which are intuitively used by humans when they listen to music. It is also one of the abilities used by listeners in order to establish a tonal hierarchy. The organization of pitches around a pitch centre is one of the most ubiquitous syntactic rules observed in music of all cultures. As far as we know, there is nothing similar to this rule in other human sound expressions nor in animals' vocal communication. Thus, the recognition of pitch centricity seems to be the unique and species-specific ability of Homo sapiens, which suggests its evolutionary origin. It is proposed in the article that in the course of hominine evolution, the ability of pitch centre recognition became an adaptive innovation which enabled a more effective social consolidation. It is also suggested that the origin of this ability has its roots in the Baldwin effect' which led to the emergence of a predisposition to join three originally separate abilities - the implicit recognition of the frequency of pitch occurrence, working memory and the emotional assessment of predicted stimuli - into a new mental tool.
C1 [Podlipniak, Piotr] Adam Mickiewicz Univ, Ul Slowackiego 20, PL-60823 Poznan, Poland.
C3 Adam Mickiewicz University
RP Podlipniak, P (corresponding author), Adam Mickiewicz Univ, Ul Slowackiego 20, PL-60823 Poznan, Poland.
EM podlip@poczta.onet.pl
OI Podlipniak, Piotr/0000-0002-4326-559X
FU Polish National Center of Science [0101/B/H03/2011/40]
FX This work was supported by the Polish National Center of Science [grant
   number 0101/B/H03/2011/40].
CR Alcock J, 2001, ANIMAL BEHAV EVOLUTI
   Alcorta CS, 2008, BEHAV BRAIN SCI, V31, P576, DOI 10.1017/S0140525X08005311
   Ambrazeviius R., 2009, J INTERDISCIPLINARY, V3, P45
   [Anonymous], MUSICAL PERCEPTIONS
   [Anonymous], 1863, Die Lehre von den Tonempfindungen als Physiologische Grundlage fur die Theorie der Musik
   [Anonymous], 2006, SINGING NEANDERTHALS
   [Anonymous], 2010, Recursion and Human Language
   [Anonymous], 2004, P 8 INT C MUS PERC C
   [Anonymous], 1997, Keeping Together in Time: Dance and Drill in Human History
   Arthur C., 2014, P ICMPC APSCOM 2014, P194
   Baldwin, 1896, AM NAT, V30, P441, DOI [10.1086/276408, DOI 10.1086/276408]
   Bannan N., 2012, MUSIC LANGUAGE HUMAN, P288, DOI [10.1093/acprof:osobl/9780199227341.003.0012, DOI 10.1093/ACPROF:OSOBL/9780199227341.003.0012]
   Berwick RC, 2011, TRENDS COGN SCI, V15, P113, DOI 10.1016/j.tics.2011.01.002
   Bharucha J.J., 2011, LANGUAGE MUSIC COGNI, P139, DOI [10.1093/acprof:oso/9780199553426.003.0016, DOI 10.1093/ACPROF:OSO/9780199553426.003.0016]
   Bharucha Jamshed J., 1994, Musical Perceptions, P213
   Bharucha JJ, 1996, MUSIC PERCEPT, V13, P383
   BHARUCHA JJ, 1984, COGNITIVE PSYCHOL, V16, P485, DOI 10.1016/0010-0285(84)90018-5
   Bickerton D, 2009, ADAMS TONGUE
   Brown S, 2000, ORIGINS OF MUSIC, P271
   Brown S, 2013, PSYCHOL MUSIC, V41, P229, DOI 10.1177/0305735611425896
   BUTLER D, 1989, MUSIC PERCEPT, V6, P219
   CASTELLANO MA, 1984, J EXP PSYCHOL GEN, V113, P394, DOI 10.1037/0096-3445.113.3.394
   Clay Z, 2009, ANIM BEHAV, V77, P1387, DOI 10.1016/j.anbehav.2009.02.016
   Cosmides L., 1992, The Adapted Mind: Evolutionary Psychology and the Generation of Culture, P163, DOI DOI 10.1098/RSTB.2006.1991
   Cross I, 2005, Musical communication, P27, DOI DOI 10.1093/ACPROF:OSO/9780198529361.003.0002
   Cross I, 2014, PSYCHOL MUSIC, V42, P809, DOI 10.1177/0305735614543968
   Cross I, 2013, STRUNGMANN FORUM REP, P541
   Curtis ME, 2009, MUSIC PERCEPT, V26, P365, DOI 10.1525/MP.2009.26.4.365
   Darwin G., 1871, P423
   Dawkins R., 1982, pi
   Dennett D. C., 1991, CONSCIOUSNESS EXPLAI
   Dennett D. C., 1995, Darwin s Dangerous Idea: Evolution and the Meanings ofLife
   Dor D., 2000, PRAGMAT COGN, V8, P325, DOI 10.1075/pc.8.2.03dor
   Dor D., 2000, SELECTION, V1, P33, DOI [10.1556/Select.1.2000.1-3.5, DOI 10.1556/SELECT.1.2000.1-3.5]
   Dor D., 2001, TRENDS LINGUISTICS S, V133, P147
   Dutton D., 2009, The Art Instinct: Beauty, Pleasure, Human Evolution
   DUTTON DG, 1974, J PERS SOC PSYCHOL, V30, P510, DOI 10.1037/h0037031
   Eerola T, 2009, MUSIC SCI, V13, P231, DOI 10.1177/102986490901300203
   Ellis C. J., 1965, ETHNOMUSICOLOGY, V9, P126
   Fitch W. T., 2013, EVOLUTION EMOTIONAL, P26, DOI DOI 10.1093/ACPROF:OSO/9780199583560.003.0002
   Fitch WT, 2006, COGNITION, V100, P173, DOI 10.1016/j.cognition.2005.11.009
   Fitch WT, 2013, STRUNGMANN FORUM REP, P499
   Fitch WT, 2013, BIRDSONG, SPEECH, AND LANGUAGE: EXPLORING THE EVOLUTION OF MIND AND BRAIN, P489
   Gazzaniga M. S., 2008, Human: The Science behind What Makes Your Brain Unique
   Gentner TQ, 2006, NATURE, V440, P1204, DOI 10.1038/nature04675
   GOULD SJ, 1979, PROC R SOC SER B-BIO, V205, P581, DOI 10.1098/rspb.1979.0086
   GOULD SJ, 1982, PALEOBIOLOGY, V8, P4, DOI 10.1017/S0094837300004310
   Gouzoules H, 2000, ANIM BEHAV, V59, P501, DOI 10.1006/anbe.1999.1318
   Hariri AR, 2000, NEUROREPORT, V11, P43, DOI 10.1097/00001756-200001170-00009
   Harrigan J. A., 2005, NEW HDB METHODS NONV, P65, DOI DOI 10.1093/ACPROF:OSO/9780198529620.003.0003
   Hauser Marc D., 1996, EVOL COMMUN
   Hinton G. E., 1987, Complex Systems, V1, P495
   HUOVINEN E, 2002, ACTA MUSICOLOGICA FE, V23
   HURON DAVID, 2006, SWEET ANTICIPATION M, P148, DOI DOI 10.7551/MITPRESS/6575.001.0001
   Jablonka E., 2005, EVOLUTION DIMENSIONS
   Jablonka E, 2012, PHILOS T R SOC B, V367, P2152, DOI 10.1098/rstb.2012.0117
   JACOB F, 1977, SCIENCE, V196, P1161, DOI 10.1126/science.860134
   Janik VM, 1997, ADV STUD BEHAV, V26, P59, DOI 10.1016/S0065-3454(08)60377-0
   Juslin P. N., 2001, THEORY RES SERIES AF, P309
   Juslin P. N., 2005, MUSICAL COMMUNICATIO, P85, DOI [DOI 10.1093/ACPROF:OSO/9780198529361.003.0005, 10.1093/acprof:oso/9780198529361.003.0005]
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   KEEFE DH, 1991, MUSIC PERCEPT, V8, P449
   KESSLER EJ, 1984, MUSIC PERCEPT, V2, P131
   Koelsch S, 2005, ANN NY ACAD SCI, V1060, P412, DOI 10.1196/annals.1360.034
   Koelsch S, 2009, HUM BRAIN MAPP, V30, P859, DOI 10.1002/hbm.20550
   Krumhansl CL, 2010, SPRINGER HANDB AUDIT, V36, P51, DOI 10.1007/978-1-4419-6114-3_3
   KRUMHANSL CL, 1987, MUSIC PERCEPT, V5, P31
   Krumhansl CL, 1997, CAN J EXP PSYCHOL, V51, P336, DOI 10.1037/1196-1961.51.4.336
   KRUMHANSL CL, 1990, OXFORD PSYCHOL SERIE, V17
   Lantz ME, 2014, PSYCHOL MUSIC, V42, P580, DOI 10.1177/0305735613483847
   Large Edward W., 2011, Mathematics and Computation in Music. Proceedings of the Third International Conference, MCM 2011, P115, DOI 10.1007/978-3-642-21590-2_9
   Large EW, 2005, ANN NY ACAD SCI, V1060, P53, DOI 10.1196/annals.1360.046
   Large EW, 2012, ANN NY ACAD SCI, V1252, pE1, DOI 10.1111/j.1749-6632.2012.06594.x
   Lerdahl F., 2001, Tonal Pitch Space
   Lerdahl F, 2007, MUSIC PERCEPT, V24, P329, DOI 10.1525/MP.2007.24.4.329
   Lerdahl F, 2013, STRUNGMANN FORUM REP, P257
   Lerdahl Fred, 1983, A generative theory of tonal music
   Lindström BR, 2011, COGNITION EMOTION, V25, P1196, DOI 10.1080/02699931.2010.527703
   LIST G, 1971, ETHNOMUSICOLOGY, V15, P399, DOI 10.2307/850640
   Llin├a┬is RR., 2002, I VORTEX NEURONS SEL
   London J., 2004, Hearing in Time: Psychological Aspects of Musical Meter, DOI 10.1093/acprof:oso/9780195160819.003.0002
   Margulis Elizabeth Hellmuth, 2014, On Repeat: How Music Plays the Mind
   Merker B., 2009, Communicative Musicality, P45
   Merker B., 2006, Musical Creativity: Multidisciplinary Research in Theory and Practice, P25
   Merker B., 2003, P 5 TRIENN C EUR SOC, P402
   Merker B., 2012, Music, Language and Human Evolution, P215, DOI 10.1093/acprof:osobl/9780199227341.003.0009
   Merker B, 2005, ANN NY ACAD SCI, V1060, P17, DOI 10.1196/annals.1360.003
   Millikan R. G., 1995, WHITE QUEEN PSYCHOL, P31
   Mithen Steven, 1996, The prehistory of the mind: A search for the origins of art, religion and science
   Moll H, 2007, PHILOS T R SOC B, V362, P639, DOI 10.1098/rstb.2006.2000
   Morgan C. L., 1896, HABITAT AND INSTINCT
   Morley I, 2002, CAMB ARCHAEOL J, V12, P195, DOI 10.1017/S0959774302000100
   Morley I., 2013, The Prehistory of Music. Human Evolution, Archaeology, and the Origins of Musicality
   Morley I, 2009, BECOMING HUMAN: INNOVATION IN PREHISTORIC MATERIAL AND SPIRITUAL CULTURE, P159
   Mortillaro M., 2013, EVOLUTION EMOTIONAL, P3, DOI DOI 10.1093/ACPROF:OSO/9780199583560.003.0001
   Müller V, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0024893
   Nettl B, 2000, ORIGINS OF MUSIC, P463
   Nettl B., 2005, The Study of Ethnomusicology: Thirty-one Issues and Concepts
   Ochsner KN, 2005, TRENDS COGN SCI, V9, P242, DOI 10.1016/j.tics.2005.03.010
   Ockelford A, 2013, PSYCHOL MUSIC, V41, P139, DOI 10.1177/0305735612442582
   Osborn H. F., 1896, Transactions of the New York Academy of Sciences, V15, P141
   Ouattara K, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0007808
   Panksepp J, 1998, AFFECTIVE NEUROSCIEN
   Panksepp Jaak, 2012, The Archaeology of Mind: Neuroevolutionary Origins of Human Emotions
   Patel A. D., 2008, Music, Language, and the Brain
   Patel AD, 2013, STRUNGMANN FORUM REP, P329
   Podlipniak P., 2014, P ICMPC APSCOM 2014, P4
   Podlipniak P., 2013, P 3 INT C MUS EM ICM
   Rhoades BL, 2009, J APPL DEV PSYCHOL, V30, P310, DOI 10.1016/j.appdev.2008.12.012
   Riemann H., 1896, HARMONY SIMPLIFIED T
   Rothenberg D, 2014, HEARING RES, V308, P71, DOI 10.1016/j.heares.2013.08.016
   ROWELL T. E., 1962, PROC ZOOL SOC LONDON, V138, P279
   Scherer K. R., 2001, MUSIC EMOTION THEORY, P361, DOI DOI 10.1080/0929821042000317822
   Scherer KR, 2013, STRUNGMANN FORUM REP, P107
   Sethares WA., 2005, Tuning, Timbre, Spectrum, Scale, V2nd ed
   SIMPSON GG, 1953, EVOLUTION, V7, P110, DOI 10.2307/2405746
   Sloboda J. A., 1986, OXFORD PSYCHOL SERIE, V5
   SMITH JM, 1987, NATURE, V329, P761, DOI 10.1038/329761a0
   Snyder B., 2000, MUSIC MEMORY INTRO
   Soard CM, 2009, ANIM BEHAV, V78, P1447, DOI 10.1016/j.anbehav.2009.09.026
   Striedter G. F., 2005, Principles of brain evolution
   Temperley D, 1999, MUSIC PERCEPT, V17, P65
   Thompson-Schill S, 2013, STRUNGMANN FORUM REP, P289
   Thomson W., 1999, TONALITY MUSIC GENER
   Tillmann B, 2000, PSYCHOL REV, V107, P885, DOI 10.1037/0033-295X.107.4.885
   Tomasello M, 2005, BEHAV BRAIN SCI, V28, P675, DOI 10.1017/S0140525X05000129
   Tomasello M, 2008, JEAN NICOD LECT, P1
   Wilson E., 1978, On human nature
   Woolley SC, 2008, PLOS BIOL, V6, P525, DOI 10.1371/journal.pbio.0060062
   Wright AA, 2000, J EXP PSYCHOL GEN, V129, P291, DOI 10.1037/0096-3445.129.3.291
   Zeifman DM, 2001, DEV PSYCHOBIOL, V39, P265, DOI 10.1002/dev.1005
   Zimmermann E., 2013, Evolution of emotional communication: From sounds in nonhuman mammals to speech and music in men, P117, DOI [10.1093/acprof:oso/9780199583560.001.0001, DOI 10.1093/ACPROF:OSO/9780199583560.001.0001]
NR 132
TC 10
Z9 10
U1 1
U2 17
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0305-7356
EI 1741-3087
J9 PSYCHOL MUSIC
JI Psychol. Music
PD MAY
PY 2016
VL 44
IS 3
BP 527
EP 543
DI 10.1177/0305735615577249
PG 17
WC Psychology, Educational; Psychology, Applied; Music; Psychology,
   Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Psychology; Music
GA DK6LR
UT WOS:000375035900015
DA 2024-01-09
ER

PT J
AU Landless, BM
   Dvorak, AL
   Hadley, S
   Bradt, J
AF Landless, Bronwen M.
   Dvorak, Abbey L.
   Hadley, Susan
   Bradt, Joke
TI Music therapy with people experiencing homelessness: a narrative review
SO JOURNAL OF SOCIAL DISTRESS AND THE HOMELESS
LA English
DT Review; Early Access
DE Homelessness; music therapy; narrative review; research methods;
   marginalization
ID WORLD; VOICE
AB The experience of homelessness goes beyond being houseless and requires a whole-person-in-context approach. Although scant and varied, research with people experiencing homelessness suggests positive benefits from music therapy. Narrative reviews are helpful to synthesize literature with varied levels of evidence and research perspectives. The purpose of this narrative literature review is to provide a critical overview of the extant music therapy literature related to people experiencing homelessness and to inform recommendations for future research and practice. The 22 studies that meet inclusion criteria focused on three main areas of knowledge: (a) the impact of music therapy on people experiencing homelessness, (b) considerations for using music therapy with people experiencing homelessness, and (c) both a and b. Studies about the impact of music therapy indicate benefits including experiencing, regulating, and expressing emotions; engaging in meaningful connection and support; and developing and expressing identities that resist oppression. Other studies offer considerations related to musical preferences, aspects of the therapeutic process, and the therapists' position in terms of culture and power. Ongoing research about the role of music therapy in approaching and understanding homelessness is recommended.
C1 [Landless, Bronwen M.] Shenandoah Univ, Winchester, VA 22601 USA.
   [Dvorak, Abbey L.] Univ Iowa, Iowa, IA USA.
   [Hadley, Susan] Slippery Rock Univ, Slippery Rock, PA USA.
   [Bradt, Joke] Drexel Univ, Creat Arts Therapies, Philadelphia, PA USA.
C3 Shenandoah University; University of Iowa; Pennsylvania State System of
   Higher Education (PASSHE); Slippery Rock University - Pennsylvania;
   Drexel University
RP Landless, BM (corresponding author), Shenandoah Univ, Winchester, VA 22601 USA.
EM blandles@su.edu
RI Dvorak, Abbey/L-1331-2013
OI Dvorak, Abbey/0000-0003-0397-3310
CR American Music Therapy Association, 2021, AM MUS THER ASS
   [Anonymous], 2005, Nordic Journal of Music Therapy, DOI DOI 10.1080/08098130509478133
   [Anonymous], 2005, SONGWRITING METHODS
   Australian Music Therapy Association, 2022, AUSTR MUS THER ASS
   Baines S, 2021, ART PSYCHOTHER, V75, DOI 10.1016/j.aip.2021.101828
   Barile JP, 2020, J COMMUNITY APPL SOC, V30, P262, DOI 10.1002/casp.2440
   Bassuk EL, 2010, AM J ORTHOPSYCHIAT, V80, P496, DOI 10.1111/j.1939-0025.2010.01052.x
   Batterham D, 2019, HOUS THEORY SOC, V36, P274, DOI 10.1080/14036096.2018.1481142
   Blackburn PJ, 2012, HOUS CARE SUPPORT, V15, P66, DOI 10.1108/14608791211254180
   Bolger L., 2015, QUALITATIVE INQUIRIE, V10, P77
   Bolger L, 2018, MUSIC THER PERSPECT, V36, P257, DOI 10.1093/mtp/miy002
   Bruscia KE, 2014, Defining music therapy, V2nd
   Certification Board for Music Therapists, 2019, CERT BOARD MUS THER
   Cronley C, 2018, J SOC DISTRESS HOMEL, V27, P64, DOI 10.1080/10530789.2018.1447269
   Desmond Matthew, 2016, Evicted: Poverty and Profit in the American City
   Ehmling A., 2018, PEOPLE EXPERIENCING
   Ensign J, 2004, QUAL HEALTH RES, V14, P1239, DOI 10.1177/1049732304268795
   Fairchild R, 2019, NORD J MUSIC THER, V28, P88, DOI 10.1080/08098131.2018.1509106
   Fairchild R, 2017, MUSIC THER PERSPECT, V35, P36, DOI 10.1093/mtp/miw004
   Ferrari R., 2015, MED WRIT, V24, P230, DOI DOI 10.1179/2047480615Z.000000000329
   Frechette J, 2020, INT J QUAL METH, V19, DOI 10.1177/1609406920907254
   Greene-Moton E, 2020, HEALTH PROMOT PRACT, V21, P142, DOI 10.1177/1524839919884912
   Gregory AT, 2018, HEART LUNG CIRC, V27, P893, DOI 10.1016/j.hlc.2018.03.027
   Hadley S, 2013, ART PSYCHOTHER, V40, P373, DOI 10.1016/j.aip.2013.05.007
   Henry M., 2020, 2020 ANN HOMELESS AS
   Hernández-Ruiz E, 2005, J MUSIC THER, V42, P140, DOI 10.1093/jmt/42.2.140
   Hernandez-Ruiz E, 2020, MUSIC THER PERSPECT, V38, P3, DOI 10.1093/mtp/miaa005
   Iliya YA, 2011, MUSIC THER PERSPECT, V29, P14, DOI 10.1093/mtp/29.1.14
   Johnstone M, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00739
   Jurgensmeier, 2012, EFFECTS LYRIC ANAL S
   Kang HJ, 2017, ART PSYCHOTHER, V53, P72, DOI 10.1016/j.aip.2017.01.009
   Lahue K., 2021, UNHOUSED PERSONS PER, DOI [https://doi.org/10.1093/mtp/miab025, DOI 10.1093/MTP/MIAB025]
   Marinaro R., 2013, EFFECT GROUP SONGWRI
   Mramor KM, 2001, J PALLIATIVE CARE, V17, P182
   Murakami B., 2021, ECOS-Revista Cientifica de Musicoterapia y Disciplinas Afines, V6, P003, DOI [DOI 10.24215/27186199E003, https://doi.org/10.24215/27186199e003]
   Murphy ER, 2020, BRIT J SOC WORK, V50, P157, DOI 10.1093/bjsw/bcz155
   National Alliance to End Homelessness, 2020, NAT ALL END HOM
   Perry J, 2015, TREND UROL MENS HEAL, V6, P19, DOI 10.1002/tre.445
   Resick PA, 2008, J CONSULT CLIN PSYCH, V76, P243, DOI 10.1037/0022-006X.76.2.243
   Sample K., 2019, SOUNDTRACK HOMELESSN
   Schwan KJ, 2018, CHILD YOUTH SERV REV, V93, P355, DOI 10.1016/j.childyouth.2018.08.002
   Seager M, 2011, MENT HEALTH SOC INCL, V15, P183, DOI 10.1108/20428301111186822
   Shapiro N, 2005, MUSIC THER PERSPECT, V23, P29, DOI 10.1093/mtp/23.1.29
   Smith J, 2012, INT J CHILD YOUTH FA, V3, P272
   STAUM MJ, 1993, J MUSIC THER, V30, P236, DOI 10.1093/jmt/30.4.236
   STAUM MJ, 1995, J MUSIC THER, V32, P248, DOI 10.1093/jmt/32.4.248
   Torraco RJ, 2016, HUM RESOUR DEV REV, V15, P404, DOI 10.1177/1534484316671606
   Whipple J., 1999, MUSIC THER PERSPECT, V17, P61, DOI [https://doi.org/10.1093/mtp/17.2.61, DOI 10.1093/MTP/17.2.61]
   Williams K. C., 2013, OPEN GROUP MUSIC THE
   Willse Craig, 2015, The Value of Homelessness: Managing Surplus Life in the United States
   Yates G.J., 2016, VOICES WORLD FORUM M, V16, DOI [https://doi.org/10.15845/voices.v16i3.887, DOI 10.15845/VOICES.V16I3.887]
NR 51
TC 0
Z9 0
U1 0
U2 1
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1053-0789
EI 1573-658X
J9 J SOC DISTRESS HOMEL
JI J. Soc. Distress Homeless
PD 2023 MAR 17
PY 2023
DI 10.1080/10530789.2023.2190952
EA MAR 2023
PG 13
WC Social Work
WE Emerging Sources Citation Index (ESCI)
SC Social Work
GA 9X7NT
UT WOS:000949954000001
DA 2024-01-09
ER

PT J
AU Rueda, LFV
   Arbeláez, AS
AF Valencia Rueda, Luis Fernando
   Samper Arbelaez, Andres
TI A Paradox, a Few Traces, and a Light: The Pains and Fears of Musicians
   as Silent Echoes of the Paradigms of Western Musical Tradition
SO CUADERNOS DE MUSICA ARTES VISUALES Y ARTES ESCENICAS
LA Spanish
DT Article
DE music; pathologies of the musician; pedagogical paradigms; music and
   healing; somatic and musical education; music and spirituality
AB This paper presents some reflections on the paradox that emerges in some musicians between a facet of the musical experience that is spontaneous and anchored in enjoyment, and another that has somehow been "contaminated" by physical, emotional and mental marks, with an emphasis on fear in the relationship with music. We propose, based on our experience as musicians, educational managers, and teachers, that, in the formal music education system, we find the origin to several of these traces when it turns too much towards the product and towards the mastery of the means (techniques, analytical knowledge, etc.) as ends and not as means for sensitive expression. We find a friction between the institutional habitus and the idiosyncrasy of the musician in training who is permanently situated in an "interstitial tension" between the canon and his own inner world. We propose that this type of education focused on the technical and analytical mastery of canonical knowledge neglects the link of musicians with their own inner world and its expression through music, and thus the power of individual voices is wasted and the appearance of pathologies (physical, emotional, mental) that manifest themselves with different levels of intensity in people, is overlooked. Finally, we propose, as an alternative, a somatic perspective that provides light on the development of self-awareness integrating body, mind and emotion, and that favors the search for one's own voice in the artistic context of the musician in relation to himself, to others and to the life situations he goes through. A perspective in which a permanent question is at the center of the sense of the profession: Why do we make music?
C1 [Valencia Rueda, Luis Fernando] Pontificia Univ Javeriana, Carrera Estudios Mus, Bogota, Colombia.
   [Samper Arbelaez, Andres] Pontificia Univ Javeriana, Bogota, Colombia.
C3 Pontificia Universidad Javeriana; Pontificia Universidad Javeriana
RP Rueda, LFV (corresponding author), Pontificia Univ Javeriana, Carrera Estudios Mus, Bogota, Colombia.
EM valencia.luis@javeriana.edu.co; a.samper@javeriana.edu.co
CR [Anonymous], 2007, LATIN AM MUSIC REV
   [Anonymous], 1997, MYSTICISM SOUND
   [Anonymous], 2008, ROOF WORLD MUSIC PRA
   Becker J., 2004, Deep listeners: Music emotions and trancing
   Bourdieu P., 1988, La distincion: Criterios y bases sociales del gusto
   Bourdieu Pierre, 2011, Las estrategias de la reproduccion social
   Castro Carvajal Julia, 1998, EDUCACION FISICA DEP, V20, P31
   Cumming Naomi, 2000, SONIC SELF MUSICAL S
   Delgado Camilo, 2019, THESIS
   Escobar Ochoa, 2012, THESIS
   Gabrielsson A., 2011, Strong Experiences with Music
   Gouk Penelope, 2000, Musical Healing in Cultural Contexts
   Grun Anselm, 2010, ESCUCHADME VIVIREIS
   Hanna Thomas., 1986, Somatics: Magazine-journal of the bodily arts and Sciences, V5, P4
   Joselovsky Ariel, 2016, ANSIEDAD COMO FRENAR
   Mendivil J., 2016, En contra de la musica
   Mesa Rincon, 2019, THESIS
   Prieto Guevara, 2018, THESIS
   Quintero Quintero, 2020, THESIS
   Salgar Hernandez, 2009, THESIS
   Samper Arbelaez Andres, 2018, THESIS
   Small C, 1987, Musicking: The Meanings of Performing and Listening
   Weintraub Mauricio, 2016, MUSICA EMOCIONES MIR
   Zuluaga German, 1991, 1 ENC NAC MUS BOG CO
NR 24
TC 0
Z9 0
U1 0
U2 1
PU PONTIFICIA UNIV JAVERIANA, FAC ARTES
PI BOGOTA
PA CARRERA 7 NO 40-62, EDIF PABLO VI PISO 2, BOGOTA, 00000, COLOMBIA
SN 1794-6670
EI 2215-9959
J9 CUAD MUSIC ARTES ESC
JI Cuad. Music Artes Escen.
PD JAN-JUN
PY 2021
VL 16
IS 1
BP 336
EP 355
DI 10.11144/javeriana.mavae16-1.elmy
PG 20
WC Humanities, Multidisciplinary
WE Emerging Sources Citation Index (ESCI)
SC Arts & Humanities - Other Topics
GA PO5BJ
UT WOS:000605184100016
OA gold, Green Submitted
DA 2024-01-09
ER

PT J
AU Kim, YJ
   Song, MK
AF Kim, You Jin
   Song, Moo Kyoung
TI Visiting virtuosos' expressivity across cultures: Acoustic analysis of a
   <i>sanjo</i> virtuoso's performance
SO PSYCHOLOGY OF MUSIC
LA English
DT Article
DE virtuoso's expressivity; music performance; acoustic analysis; sanjo;
   performer's individuality
ID MUSIC PERFORMANCE; VOCAL EXPRESSION; EMOTION; COMMUNICATION; PERCEPTION;
   DYNAMICS; PATTERNS
AB Studies on music performance have received greater attention in the last several decades since the establishment of musical performance studies, and emotional expressivity has taken an important place in the study of emotional communication. The methodological or thematic integration of these domains in the study of music performance may expand the rationale for studying performance. The purpose of this study was to explore a virtuoso's expressivity in terms of sanjo-specific features, including jangdan, indicating a rhythmic pattern, and jo, a structural feature that conveys emotional meanings. We investigated tempo and dynamics in the melodies within the unit of a jangdan across jo and those acoustic cues related to the jo transition. The findings suggest that the virtuoso, Kim Juk-pa, differentiated tempo and dynamics in the conveyance of structural features of jo. Tempo and dynamics were indicative of a jo shift, acting as a clue for her individuality. This provides current performers with critical sources for understanding the virtuoso's expressivity corresponding with jo's changes. The sanjo virtuoso's individuality could be further elaborated via multi-dimensional analysis of historically informed recordings; this approach to music performance would lead to improved learning, transmission, and creation of new forms of music across cultures.
C1 [Kim, You Jin] Kyung Hee Univ, Seoul, South Korea.
   [Song, Moo Kyoung] Yonsei Univ, 262 Seongsanno, Seoul 120749, South Korea.
C3 Kyung Hee University; Yonsei University
RP Song, MK (corresponding author), Yonsei Univ, 262 Seongsanno, Seoul 120749, South Korea.
EM msong999@yonsei.ac.kr
RI Kim, You Jin/AAN-4025-2021
OI Kim, You Jin/0000-0003-0082-140X
FU Ministry of Education of the Republic of Korea; National Research
   Foundation of Korea [NRF-2019S1A5A2A01034848]
FX The author(s) disclose receipt of the following financial support for
   the research, authorship, and/or publication of this article: This work
   was supported by the Ministry of Education of the Republic of Korea and
   the National Research Foundation of Korea(NRF-2019S1A5A2A01034848).
CR [Anonymous], 1989, Musical Structure and Performance
   [Anonymous], 2009, The Cambridge Companion to Recorded Music
   [Anonymous], 2016, OXFORD HDB MUSIC PSY
   [Anonymous], 2003, Psychology of Music, DOI [DOI 10.1177/03057356030313003, 10.1177/03057356030313003]
   antan-Dack M., 2012, Music Performance Research, V5, P34
   Argstatter H, 2016, PSYCHOL MUSIC, V44, P674, DOI 10.1177/0305735615589214
   Aucouturier JJ, 2017, COGNITION, V161, P94, DOI 10.1016/j.cognition.2017.01.019
   Balkwill LL, 1999, MUSIC PERCEPT, V17, P43, DOI 10.2307/40285811
   Boersma P., 2020, Praat: Doing phonetics by computer: Version 6.1.28
   Cannam C., 2010, ACM MULTIMEDIA 2010
   Clarke E. F., 1988, Generative processes in music: The psychology of performance, improvisation and composition, P1
   Clayton M, 2019, MUSIC SCI, V23, P304, DOI 10.1177/1029864919844809
   Cook Nicholas., 2001, MUSIC THEORY ONLINE, V7, P1
   Cook Nicholas., 2013, Beyond the Score: Music as Performance
   Dahl S, 2007, MUSIC PERCEPT, V24, P433, DOI 10.1525/MP.2007.24.5.433
   Eerola T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00487
   Gabrielson A, 1999, B COUN RES MUSIC ED, P47
   Godoy Rolf I., 2010, Musical Gestures: Sound, Movement, and Meaning, P103, DOI DOI 10.4324/9780203863411
   Gritten Anthony, 2006, Music and Gesture, P1
   HATTEN Robert S., 2004, Interpreting Musical Gestures, Topics, and Tropes
   Howard K., 2008, KOREAN KAYAGUM SANJO
   Juslin P. N., 2000, MUSICAE SCI, V4, P151, DOI DOI 10.1177/102986490000400202
   Juslin P. N., 1996, PSYCHOL MUSIC, V24, P68, DOI [10.1177/0305735696241007, DOI 10.1177/0305735696241007]
   Juslin PN, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00596
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Kim Y. J., 2016, THESIS U TEXAS AUSTI
   Kim Y. W., 2020, INTRO KOREAN TRADITI, V2nd
   Lee Y., 2009, SANJO
   Leech-Wilkinson D, 2006, J MUSICOL RES, V25, P233, DOI 10.1080/01411890600859412
   Leech-Wilkinson D, 2018, MUSIC SCI, V22, P558, DOI 10.1177/1029864918790304
   Leech-Wilkinson D, 2010, MUSIC SCI, V14, P57, DOI 10.1177/102986491001400203
   Merriam-Webster, MERR WEBST COM DICT
   Palmer C, 1997, ANNU REV PSYCHOL, V48, P115, DOI 10.1146/annurev.psych.48.1.115
   Repp B. H., 1994, PSYCHOL MUSIC, V22, P157, DOI [10.1177/0305735694222005, DOI 10.1177/0305735694222005]
   REPP BH, 1992, J ACOUST SOC AM, V92, P2546, DOI 10.1121/1.404425
   REPP BH, 1990, J ACOUST SOC AM, V88, P622, DOI 10.1121/1.399766
   RINK J, 1990, MUSIC ANAL, V9, P319, DOI 10.2307/853982
   Rink J, 2011, SEMPRE STUD PSYCHOL, P267
   Rink John, 2002, Musical Performance: A Guide to Understanding, P35
   Scherer KR, 2017, J ACOUST SOC AM, V142, P1805, DOI 10.1121/1.5002886
   Seashore C., 1938, Psychology of Music
   Song B. S., 2007, HIST KOREAN MUSIC
   Song Moo Kyoung, 2017, [Journal of Music and Theory, 음악이론연구], V29, P8
   Spiro N, 2010, MUSIC SCI, V14, P23, DOI 10.1177/102986491001400202
   Stachó L, 2018, MUSIC SCI, V22, P449, DOI 10.1177/1029864918803053
   Thompson MR, 2012, MUSIC SCI, V16, P19, DOI 10.1177/1029864911423457
   Timmers R, 2007, MUSIC PERCEPT, V25, P117, DOI 10.1525/MP.2007.25.2.117
   Timmers R, 2007, MUSIC SCI, V11, P237, DOI 10.1177/102986490701100205
   TODD NPM, 1992, J ACOUST SOC AM, V91, P3540, DOI 10.1121/1.402843
   Zhou DQ, 2021, MUSIC SCI, V25, P252, DOI 10.1177/1029864919873124
NR 51
TC 1
Z9 1
U1 1
U2 2
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0305-7356
EI 1741-3087
J9 PSYCHOL MUSIC
JI Psychol. Music
PD MAR
PY 2023
VL 51
IS 2
BP 640
EP 654
DI 10.1177/03057356221109332
EA AUG 2022
PG 15
WC Psychology, Educational; Psychology, Applied; Music; Psychology,
   Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Psychology; Music
GA 9O5UH
UT WOS:000846747100001
DA 2024-01-09
ER

PT J
AU Xue, F
   Fang, GZ
   Yang, P
   Zhao, E
   Brauth, SE
   Tang, YZ
AF Xue, Fei
   Fang, Guangzhan
   Yang, Ping
   Zhao, Ermi
   Brauth, Steven E.
   Tang, Yezhong
TI The biological significance of acoustic stimuli determines ear
   preference in the music frog
SO JOURNAL OF EXPERIMENTAL BIOLOGY
LA English
DT Article
DE Right ear advantage; REA; Auditory perception; Conspecific calls; Mating
   strategy; Emotion
ID LATERALIZED BRAIN-FUNCTION; HEMISPHERIC-SPECIALIZATION; TREE FROG;
   ASYMMETRY; EVOLUTION; RESPONSES; DOGS; BEHAVIOR; FEAR; VOCALIZATIONS
AB Behavioral and neurophysiological studies support the idea that right ear advantage (REA) exists for perception of conspecific vocal signals in birds and mammals. Nevertheless, few studies have focused on anuran species that typically communicate through vocalization. The present study examined the direction and latencies of orientation behaviors in Emei music frogs (Babina daunchina) produced in response to six auditory stimuli emitted by a speaker placed directly behind the subjects. The stimuli included male advertisement calls produced from within burrow nests, which have been shown to be highly sexually attractive (HSA), calls produced from outside burrows, which are of low sexual attractiveness (LSA), screech calls produced when frogs are attacked by snakes, white noise, thunder and silence. For all sound stimuli except the screech, the frogs preferentially turned to the right. Right ear preference was strongest for HSA calls. For the screech and thunder stimuli, there was an increased tendency for subjects to move further from the speaker rather than turning. These results support the idea that in anurans, right ear preference is associated with perception of positive or neutral signals such as the conspecific advertisement call and white noise, while a left ear preference is associated with perception of negative signals such as predatory attack.
C1 [Xue, Fei; Zhao, Ermi] Sichuan Univ, Sch Life Sci, Key Lab Bioresources & Ecoenvironm, Minist Educ, Chengdu 610064, Sichuan, Peoples R China.
   [Xue, Fei; Fang, Guangzhan; Yang, Ping; Zhao, Ermi; Tang, Yezhong] Chinese Acad Sci, Chengdu Inst Biol, Dept Herpetol, Chengdu 610041, Sichuan, Peoples R China.
   [Brauth, Steven E.] Univ Maryland, Dept Psychol, College Pk, MD 20742 USA.
C3 Sichuan University; Chinese Academy of Sciences; Chengdu Institute of
   Biology, CAS; University System of Maryland; University of Maryland
   College Park
RP Tang, YZ (corresponding author), Chinese Acad Sci, Chengdu Inst Biol, Dept Herpetol, 9 Sect 4,Renmin South Rd, Chengdu 610041, Sichuan, Peoples R China.
EM fanggz@cib.ac.cn; tangyz@cib.ac.cn
RI fang, guangzhan/AAH-1098-2020; fang, ke/HNQ-1480-2023
OI Fang, Guangzhan/0000-0003-1803-6610
FU National Natural Science Foundation of China [31372217]
FX This work was supported by the grant from the National Natural Science
   Foundation of China (no. 31372217) to G.F.
CR Andrew R. J., 1983, ADV VERTEBRATE NEURO, P477
   [Anonymous], 1989, Handbook of Neuropsychology
   [Anonymous], 1984, Emotion, cognition, and behavior
   [Anonymous], 2012, COLORED ATLAS CHINES
   Arnott G, 2008, ANIM BEHAV, V76, P529, DOI 10.1016/j.anbehav.2008.04.019
   Basile M, 2009, ANIM COGN, V12, P611, DOI 10.1007/s10071-009-0220-5
   BAUER RH, 1993, PSYCHOBIOLOGY, V21, P243
   Bisazza A, 1996, NATURE, V379, P408, DOI 10.1038/379408a0
   Bisazza A, 1997, Laterality, V2, P49, DOI 10.1080/713754252
   Böye M, 2005, EUR J NEUROSCI, V21, P1727, DOI 10.1111/j.1460-9568.2005.04005.x
   Broom M, 2005, BEHAV ECOL, V16, P534, DOI 10.1093/beheco/ari024
   BRUCE LL, 1995, BRAIN BEHAV EVOLUT, V46, P224, DOI 10.1159/000113276
   Butler A. B., 2005, Comparative vertebrate neuroanatomy: evolution and adaptation
   Cabanac AJ, 2004, J THERM BIOL, V29, P669, DOI 10.1016/j.jtherbio.2004.08.039
   Cabanac M, 1999, JPN J PHYSIOL, V49, P1, DOI 10.2170/jjphysiol.49.1
   Caldwell MS, 2014, J COMP PHYSIOL A, V200, P265, DOI 10.1007/s00359-014-0882-6
   Chen Q, 2011, J HERPETOL, V45, P406
   Christensen-Dalsgaard J, 2005, SPR HDB AUD, V25, P67, DOI 10.1007/0-387-28863-5_4
   Cooper WE, 2007, J THEOR BIOL, V244, P59, DOI 10.1016/j.jtbi.2006.07.011
   CROWNE DP, 1987, BEHAV NEUROSCI, V101, P134, DOI 10.1037/0735-7044.101.1.134
   Cui JG, 2012, BIOL LETTERS, V8, P337, DOI 10.1098/rsbl.2011.1091
   Cui JG, 2010, ANIM BEHAV, V80, P181, DOI 10.1016/j.anbehav.2010.05.012
   CYNX J, 1992, P NATL ACAD SCI USA, V89, P1372, DOI 10.1073/pnas.89.4.1372
   DAVIDSON RJ, 1990, J PERS SOC PSYCHOL, V58, P330, DOI 10.1037/0022-3514.58.2.330
   Davidson RJ., 1984, Approaches to emotion, V2, P39
   DENENBERG VH, 1981, BEHAV BRAIN SCI, V4, P1, DOI 10.1017/S0140525X00007330
   Denver RJ, 2009, ANN NY ACAD SCI, V1163, P1, DOI 10.1111/j.1749-6632.2009.04433.x
   DILL LM, 1977, CAN J ZOOL, V55, P1926, DOI 10.1139/z77-248
   Ducker G, 1986, ZOOL BEITR, V29, P377
   EHRET G, 1987, NATURE, V325, P249, DOI 10.1038/325249a0
   Fang GZ, 2014, BEHAV BRAIN RES, V266, P77, DOI 10.1016/j.bbr.2014.02.042
   Fang GZ, 2014, ANIM COGN, V17, P483, DOI 10.1007/s10071-013-0680-5
   Fang GZ, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0052364
   Fang GZ, 2011, LECT NOTES COMPUT SC, V6675, P139, DOI 10.1007/978-3-642-21105-8_18
   FAURE JM, 1983, BIOL BEHAV, V8, P103
   Fernández-Carriba S, 2002, BRAIN RES BULL, V57, P561, DOI 10.1016/S0361-9230(01)00685-2
   FITCH RH, 1993, BEHAV NEUROSCI, V107, P844, DOI 10.1037/0735-7044.107.5.844
   Galac S, 1997, ANIM WELFARE, V6, P9
   Ghirlanda S, 2004, P ROY SOC B-BIOL SCI, V271, P853, DOI 10.1098/rspb.2003.2669
   Greenfield MD, 2000, ETHOLOGY, V106, P331, DOI 10.1046/j.1439-0310.2000.00525.x
   Güven M, 2003, INT J NEUROSCI, V113, P1675, DOI 10.1080/00207450390249258
   HAUSER MD, 1994, P NATL ACAD SCI USA, V91, P3946, DOI 10.1073/pnas.91.9.3946
   HEFFNER HE, 1995, CURRENT TOPICS IN PRIMATE VOCAL COMMUNICATION, P207
   Hopkins WD, 2003, DEVELOPMENTAL SCI, V6, P55, DOI 10.1111/1467-7687.00254
   HURLBERT SH, 1984, ECOL MONOGR, V54, P187, DOI 10.2307/1942661
   Kanwal JS, 2012, EUR J NEUROSCI, V35, P257, DOI 10.1111/j.1460-9568.2011.07951.x
   Kimura D, 2011, BRAIN COGNITION, V76, P214, DOI 10.1016/j.bandc.2010.11.009
   Kirkpatrick M, 2006, ANIM BEHAV, V71, P1215, DOI 10.1016/j.anbehav.2005.11.010
   Knecht S, 2000, BRAIN, V123, P2512, DOI 10.1093/brain/123.12.2512
   Laberge F, 2006, BRAIN BEHAV EVOLUT, V67, P177, DOI 10.1159/000091119
   Lippolis G, 2002, LATERALITY, V7, P163, DOI 10.1080/13576500143000221
   MacNeilage PF, 2009, SCI AM, V301, P60, DOI 10.1038/scientificamerican0709-60
   MAGNHAGEN C, 1991, TRENDS ECOL EVOL, V6, P183, DOI 10.1016/0169-5347(91)90210-O
   Malashichev YB, 2002, LATERALITY, V7, P1, DOI 10.1080/13576500143000032
   McGregor Peter K., 2000, Acta Ethologica, V3, P3, DOI 10.1007/s102110000023
   MCGREGOR PK, 1992, NATO ADV SCI I A-LIF, V228, P1
   Ocklenburg S, 2013, LATERALITY, V18, P1, DOI 10.1080/1357650X.2011.626561
   Pence Sadrettin, 2002, Journal of Basic and Clinical Physiology and Pharmacology, V13, P41
   Perlaki G, 2013, BRAIN COGNITION, V82, P319, DOI 10.1016/j.bandc.2013.05.005
   PETERSEN MR, 1978, SCIENCE, V202, P324, DOI 10.1126/science.99817
   Prather MD, 2001, NEUROSCIENCE, V106, P653, DOI 10.1016/S0306-4522(01)00445-6
   Pyron RA, 2011, MOL PHYLOGENET EVOL, V61, P543, DOI 10.1016/j.ympev.2011.06.012
   Quaranta A, 2007, CURR BIOL, V17, pR199, DOI 10.1016/j.cub.2007.02.008
   Reinholz-Trojan A, 2012, BEHAV PROCESS, V91, P202, DOI 10.1016/j.beproc.2012.07.001
   REZNICK D, 1992, TRENDS ECOL EVOL, V7, P42, DOI 10.1016/0169-5347(92)90104-J
   Robins A, 1998, ANIM BEHAV, V56, P875, DOI 10.1006/anbe.1998.0877
   Robins A, 2002, LATERALITY, V7, P261, DOI 10.1080/13576500244000049
   Robins A, 2006, ANIM BEHAV, V72, P843, DOI 10.1016/j.anbehav.2006.01.022
   Rogers L.J., 2002, COMP VERTEBRATE LATE
   Rogers LJ, 2000, BRAIN LANG, V73, P236, DOI 10.1006/brln.2000.2305
   Rogers LJ, 2004, P ROY SOC B-BIOL SCI, V271, pS420, DOI 10.1098/rsbl.2004.0200
   Rogers LJ, 2002, LATERALITY, V7, P219, DOI 10.1080/13576500244000012
   Rogers LJ, 2013, DIVIDED BRAINS BIOL
   Ryan M. J., 1985, The tungara frog
   Siniscalchi M, 2013, CURR BIOL, V23, P2279, DOI 10.1016/j.cub.2013.09.027
   Siniscalchi M, 2010, BEHAV BRAIN RES, V208, P516, DOI 10.1016/j.bbr.2009.12.042
   Siniscalchi M, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003349
   SLOTNICK BM, 1973, PHYSIOL BEHAV, V11, P717, DOI 10.1016/0031-9384(73)90258-8
   Sutton SK, 1997, PSYCHOL SCI, V8, P204, DOI 10.1111/j.1467-9280.1997.tb00413.x
   Teufel C, 2010, BEHAV NEUROSCI, V124, P437, DOI 10.1037/a0019925
   Toledo LF, 2015, ACTA ETHOL, V18, P87, DOI 10.1007/s10211-014-0194-4
   Vallortigara G, 2000, BRAIN LANG, V73, P189, DOI 10.1006/brln.2000.2303
   Vallortigara G, 1998, NEUROREPORT, V9, P3341, DOI 10.1097/00001756-199810050-00035
   Vallortigara G, 1999, BRAIN RES REV, V30, P164, DOI 10.1016/S0165-0173(99)00012-0
   Vallortigara G, 2005, BEHAV BRAIN SCI, V28, P575, DOI 10.1017/S0140525X05000105
   Vallortigara G, 2006, DEV PSYCHOBIOL, V48, P418, DOI 10.1002/dev.20166
   Vallortigara G, 2011, WIRES COGN SCI, V2, P146, DOI 10.1002/wcs.100
   Wallez C, 2011, BRAIN COGNITION, V75, P164, DOI 10.1016/j.bandc.2010.11.004
   Wilczynski W., 1988, P209
   Wilczynski W., 2006, HEARING SOUND COMMUN, P221
   Yang P, 2014, J COMP PHYSIOL A, V200, P117, DOI 10.1007/s00359-013-0866-y
   Yao M, 2004, J NEUROENDOCRINOL, V16, P880, DOI 10.1111/j.1365-2826.2004.01246.x
   Zhu J, 2002, PHILOS PSYCHOL, V15, P19, DOI 10.1080/09515080120109397
NR 93
TC 18
Z9 20
U1 0
U2 28
PU COMPANY BIOLOGISTS LTD
PI CAMBRIDGE
PA BIDDER BUILDING, STATION RD, HISTON, CAMBRIDGE CB24 9LF, ENGLAND
SN 0022-0949
EI 1477-9145
J9 J EXP BIOL
JI J. Exp. Biol.
PD MAR
PY 2015
VL 218
IS 5
BP 740
EP 747
DI 10.1242/jeb.114694
PG 8
WC Biology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Life Sciences & Biomedicine - Other Topics
GA CD0HR
UT WOS:000350751900019
PM 25740903
OA Bronze
DA 2024-01-09
ER

PT J
AU Knight, S
   Spiro, N
AF Knight, Sarah
   Spiro, Neta
TI Tracing change during music therapy for depression: Toward a
   markers-based understanding of communicative behaviors
SO MUSICAE SCIENTIAE
LA English
DT Article
DE music; mental health; behavioral markers; interaction
ID DIRECTED SPEECH; ACOUSTIC MEASURES; VOCAL EXPRESSION; RATING-SCALE;
   SEVERITY; RESPONSIVENESS; PERFORMANCE; SYNCHRONY; EMOTIONS; TIME
AB This article focuses on behavioral markers-changes in communicative behaviors that reliably indicate the presence and severity of mental health conditions. We explore the potential of behavioral markers to provide new insights and approaches to diagnosis, assessment, and monitoring, with a particular focus on music therapy for depression. We propose a framework for understanding these markers that encompasses three broad functional categories fulfilled by communicative behaviors: semantic, pragmatic, and phatic. The disordered interactions observed in those with depression reflect changes in many types of communicative behavior, but much research has focused on pragmatic behaviors. However, changes in phatic behaviors also seem likely to be important, given their crucial role in facilitating interpersonal relationships. Given the strong phatic element of music-making, music represents a fertile context in which to explore these behaviors. We argue here that the uniquely multimodal and profoundly interactive environment of music therapy in particular allows for the identification of changes in pragmatic and phatic communicative behaviors that reliably indicate depression presence/severity. By identifying these behavioral markers, we open the door to new ways of assessing depression, and improving diagnosis and monitoring. Furthermore, this markers-based approach has broad implications, being applicable beyond depression and beyond music therapy.
C1 [Knight, Sarah] Univ York, York, N Yorkshire, England.
   [Spiro, Neta] Royal Coll Mus, London, England.
C3 University of York - UK; Royal College of Music - UK
RP Knight, S (corresponding author), Univ York, Dept Psychol, York YO10 5DD, N Yorkshire, England.
EM sarah.knight3@york.ac.uk
CR Aalbers Sonja, 2017, Cochrane Database Syst Rev, V11, pCD004517, DOI 10.1002/14651858.CD004517.pub3
   Kenneth A, 2014, MUSIC THER PERSPECT, V32, P18, DOI 10.1093/mtp/miu006
   Alpert M, 2001, J AFFECT DISORDERS, V66, P59, DOI 10.1016/S0165-0327(00)00335-9
   [Anonymous], 1995, British Journal of Music Therapy
   [Anonymous], 1969, Prosodic systems and intonation in English
   Bargh JA, 1999, AM PSYCHOL, V54, P462, DOI 10.1037/0003-066x.54.7.462
   Bhatia S, 2017, IEEE INT CONF AUTOMA, P754, DOI 10.1109/FG.2017.94
   Bibb J, 2017, COMMUNITY MENT HLT J, V53, P747, DOI 10.1007/s10597-017-0127-6
   BOUHUYS AL, 1991, J AFFECT DISORDERS, V23, P63, DOI 10.1016/0165-0327(91)90093-8
   Cannizzaro M, 2004, BRAIN COGNITION, V56, P30, DOI 10.1016/j.bandc.2004.05.003
   Carr C, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0070252
   Chartrand TL, 1999, J PERS SOC PSYCHOL, V76, P893, DOI 10.1037/0022-3514.76.6.893
   Cross I., 2008, PREHISTORY LANGUAGE, P113, DOI DOI 10.1093/ACPROF:OSO/9780199545872.003.0005
   Cummins N, 2015, SPEECH COMMUN, V71, P10, DOI 10.1016/j.specom.2015.03.004
   Dibeklioglu H, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P307, DOI 10.1145/2818346.2820776
   Drake C, 2000, COGNITION, V77, P251, DOI 10.1016/S0010-0277(00)00106-2
   DRAKE C, 1993, MUSIC PERCEPT, V10, P343
   Erkkila J., 2007, MICROANALYSIS MUSIC, P134
   Erkkilä J, 2011, BRIT J PSYCHIAT, V199, P132, DOI 10.1192/bjp.bp.110.085431
   Fachner J, 2013, BRAIN TOPOGR, V26, P338, DOI 10.1007/s10548-012-0254-x
   FERNALD A, 1987, INFANT BEHAV DEV, V10, P279, DOI 10.1016/0163-6383(87)90017-8
   FERNALD A, 1984, DEV PSYCHOL, V20, P104, DOI 10.1037/0012-1649.20.1.104
   Field T, 2010, INFANT BEHAV DEV, V33, P1, DOI 10.1016/j.infbeh.2009.10.005
   Fiquer JT, 2013, J AFFECT DISORDERS, V150, P1114, DOI 10.1016/j.jad.2013.05.002
   Girard JM, 2015, CURR OPIN PSYCHOL, V4, P75, DOI 10.1016/j.copsyc.2014.12.010
   Girard JM, 2014, IMAGE VISION COMPUT, V32, P641, DOI 10.1016/j.imavis.2013.12.007
   Gold C, 2009, CLIN PSYCHOL REV, V29, P193, DOI 10.1016/j.cpr.2009.01.001
   Grabe E, 2002, PHONOL PHONET, V4-1, P515
   GRICE HP, 1957, PHILOS REV, V66, P377, DOI 10.2307/2182440
   Gussenhoven C., 2004, The Phonology of Tone and Intonation
   Hadar U, 2004, J LANG SOC PSYCHOL, V23, P204, DOI 10.1177/0261927X04263825
   Hawkins S., 2013, MUSIC LANGUAGE INTER, P285
   Hove MJ, 2009, SOC COGNITION, V27, P949, DOI 10.1521/soco.2009.27.6.949
   Jakobson R., 1980, FRAMEWORK LANGUAGE
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   KAPLAN PS, 1995, INFANT BEHAV DEV, V18, P209, DOI 10.1016/0163-6383(95)90050-0
   Kim J, 2009, AUTISM, V13, P389, DOI 10.1177/1362361309105660
   Kirschner S, 2010, EVOL HUM BEHAV, V31, P354, DOI 10.1016/j.evolhumbehav.2010.04.004
   Kirschner S, 2009, J EXP CHILD PSYCHOL, V102, P299, DOI 10.1016/j.jecp.2008.07.005
   Knight S, 2017, PSYCHOL MUSIC, V45, P99, DOI 10.1177/0305735616648008
   Kuhlen AK, 2013, PSYCHON B REV, V20, P54, DOI 10.3758/s13423-012-0341-8
   Lakin JL, 2003, PSYCHOL SCI, V14, P334, DOI 10.1111/1467-9280.14481
   Lidji P, 2011, PSYCHON B REV, V18, P1035, DOI 10.3758/s13423-011-0163-0
   Local J, 2012, J INT PHON ASSOC, V42, P255, DOI 10.1017/S0025100312000187
   London J., 2004, Hearing in Time: Psychological Aspects of Musical Meter, DOI 10.1093/acprof:oso/9780195160819.003.0002
   Malinowski B., 1994, LANGUAGE LITERACY SO
   Maratos AS, 2008, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD004517.pub2
   Maratos A, 2011, BRIT J PSYCHIAT, V199, P92, DOI 10.1192/bjp.bp.110.087494
   Marchi E, 2016, INTERSPEECH, P1182
   Maricchiolo F., 2005, 2 INT SOC GESTURE ST
   MAUS FE, 1988, MUSIC THEOR SPECTRUM, V10, P56, DOI 10.1525/mts.1988.10.1.02a00050
   Miles LK, 2011, EXP BRAIN RES, V211, P495, DOI 10.1007/s00221-011-2641-z
   Miles LK, 2010, EUR J SOC PSYCHOL, V40, P52, DOI 10.1002/ejsp.721
   Mundt JC, 2007, J NEUROLINGUIST, V20, P50, DOI 10.1016/j.jneuroling.2006.04.001
   Murray L, 2015, IDENTIFYING PERINATAL DEPRESSION AND ANXIETY: EVIDENCE-BASED PRACTICE IN SCREENING, PSYCHOSOCIAL ASSESSMENT, AND MANAGEMENT, P139
   Nakata T, 2004, INFANT BEHAV DEV, V27, P455, DOI 10.1016/j.infbeh.2004.03.002
   Nolan F., 2006, HDB ENGLISH LINGUIST, P385, DOI DOI 10.1002/9780470753002.CH19
   Nordoff P., 1977, Creative music therapy
   Odell-Miller H, 2018, INT RES ART THER, P154
   Ogden R, 2006, J PRAGMATICS, V38, P1752, DOI 10.1016/j.pragma.2005.04.011
   PAVLICEVIC M, 1994, J MUSIC THER, V31, P86, DOI 10.1093/jmt/31.2.86
   Perilli G.G., 1995, MUSIC THER PERSPECT, V13, P104, DOI [10.1093/mtp/13.2.104, DOI 10.1093/MTP/13.2.104]
   Ramus F, 2000, COGNITION, V75, DOI 10.1016/S0010-0277(00)00101-3
   Rana R, 2019, EUR J CANCER CARE, V28, DOI 10.1111/ecc.13033
   Robb L., 1999, MUSIC SCI, V3, P123, DOI DOI 10.1177/10298649000030S108
   Robledo J.P., 2016, PROC SPEECH PROSODY, V2016, P1071
   Rolvsjord R., 2005, Nord J Music Ther, V14, P15, DOI DOI 10.1080/08098130509478122
   Saarikallio S, 2011, PSYCHOL MUSIC, V39, P307, DOI 10.1177/0305735610374894
   Santor DA, 2001, PSYCHOL ASSESSMENT, V13, P127, DOI 10.1037/1040-3590.13.1.127
   Scherer S, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P135, DOI 10.1145/2522848.2522886
   Schöttler MA, 2014, FRONT PLANT SCI, V5, DOI [10.3389/fpls.2014.00188, 10.3389/fpsyg.2014.00808]
   Segrin C, 2000, CLIN PSYCHOL REV, V20, P379, DOI 10.1016/S0272-7358(98)00104-4
   Senft Gunter, 2009, Culture and language use, P226, DOI DOI 10.1075/HOPH.2
   Shannon TTE, 2016, ASIAPAC SIGN INFO PR
   SLOBODA JA, 1983, Q J EXP PSYCHOL-A, V35, P377, DOI 10.1080/14640748308402140
   Sperber Dan., 1995, Relevance: Communication and cognition, V2nd ed.
   Spiro N, 2018, MUSIC THER PERSPECT, V36, P67, DOI 10.1093/mtp/mix011
   Spiro N, 2016, PHILOS T R SOC B, V371, DOI 10.1098/rstb.2015.0374
   Spiro N, 2010, AGING MENT HEALTH, V14, P891, DOI 10.1080/13607863.2010.519328
   Storm S., 2013, THESIS AALBORG U
   Streeter E., 2010, THESIS U YORK
   Thiessen ED, 2005, INFANCY, V7, P53, DOI 10.1207/s15327078in0701_5
   Torous J, 2021, WORLD PSYCHIATRY, V20, P318, DOI 10.1002/wps.20883
   Trainor LJ, 2000, PSYCHOL SCI, V11, P188, DOI 10.1111/1467-9280.00240
   Trevarthen C., 2000, NORD J MUSIC THER, V9, P3, DOI [DOI 10.1080/08098130009477996, 10.1080/08098130009477996]
   Watt R.J., 1998, MUSIC SCI, V2, P33, DOI DOI 10.1177/102986499800200103
   Wharton T., 2009, PRAGMATICS NONVERBAL, DOI DOI 10.1017/CB09780511635649
   Wigram T, 2006, CHILD CARE HLTH DEV, V32, P535, DOI 10.1111/j.1365-2214.2006.00615.x
   Wigram T., 2004, Improvisation: Methods and Techniques for Music Therapy Clinicians, Educators, and Students
   Wilson M, 2005, PSYCHON B REV, V12, P957, DOI 10.3758/BF03206432
   Wiltermuth SS, 2009, PSYCHOL SCI, V20, P1, DOI 10.1111/j.1467-9280.2008.02253.x
   Yang Y, 2013, IEEE T AFFECT COMPUT, V4, P142, DOI 10.1109/T-AFFC.2012.38
   Zimmerman M, 2005, J CLIN PSYCHOPHARM, V25, P105, DOI 10.1097/01.jcp.0000155824.59585.46
NR 93
TC 0
Z9 0
U1 3
U2 10
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1029-8649
EI 2045-4147
J9 MUSIC SCI
JI Music Sci.
PD SEP
PY 2023
VL 27
IS 3
BP 637
EP 654
DI 10.1177/10298649221116024
EA AUG 2022
PG 18
WC Music; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music; Psychology
GA X3MB9
UT WOS:000840956700001
OA hybrid
DA 2024-01-09
ER

PT J
AU Broomhead, P
   Skidmore, JB
   Eggett, DL
   Mills, MM
AF Broomhead, Paul
   Skidmore, Jon B.
   Eggett, Dennis L.
   Mills, Melissa M.
TI The Effects of a Positive Mindset Trigger Word Pre-Performance Routine
   on the Expressive Performance of Junior High Age Singers
SO JOURNAL OF RESEARCH IN MUSIC EDUCATION
LA English
DT Article
DE expressive performance; performance psychology; positive mindset;
   singing expression; trigger words
ID MUSIC PERFORMANCE; VOCAL EXPRESSION; MENTAL PRACTICE; COMMUNICATION;
   EMOTIONS; MOTION
AB The effects of a positive mindset trigger word intervention on the expressive performance of individual junior high singers were tested in this study. Participants (N = 155) were assigned randomly to a control group or an experimental group. Members of the experimental group participated in a 40-min intervention while members of the control group participated in normal rehearsal. The intervention involved a pre-performance routine of breathing and silently repeating the words bold, confident, and free. It also involved practice activities for applying the technique to performance. Participants were tested individually directly before and after the intervention and 2 weeks later. Results indicated a significant positive effect on Overall Expressive Performance (p <.001) and on the subcategories Dynamics (p <.001), Performance Factors (p <.001), and Timing (p <.001). There was no significant effect on subcategories Articulation (p =.195) and Tone (p =.035). Implications were that (I) use of positive mindset trigger words in a pre-performance routine may bring immediate improvement in expressive performance for junior high age singers, (2) junior high age singers may possess higher levels of expressive performance skill than they or teachers recognize, and (3) review and repetition likely are needed for junior high age students to retain the intervention benefits.
C1 [Broomhead, Paul; Skidmore, Jon B.; Eggett, Dennis L.] Brigham Young Univ, Provo, UT 84602 USA.
C3 Brigham Young University
RP Broomhead, P (corresponding author), Brigham Young Univ, C-550 HFAC, Provo, UT 84602 USA.
EM paul_broomhead@byu.edu
CR [Anonymous], 2003, Psychology of Music, DOI DOI 10.1177/03057356030313002
   [Anonymous], MUSICAE SCI S, DOI DOI 10.1177/10298649020050S104
   [Anonymous], 2003, Psychology of Music, DOI [DOI 10.1177/03057356030313003, 10.1177/03057356030313003]
   [Anonymous], 2001, Music and Emotion, DOI DOI 10.1525/MP.2004.21.4.561
   Arent SM, 2003, RES Q EXERCISE SPORT, V74, P436, DOI 10.1080/02701367.2003.10609113
   Brandfonbrener AG, 1999, MED PROBL PERFORM AR, V14, P101
   Broomhead P, 2001, J RES MUSIC EDUC, V49, P71, DOI 10.2307/3345811
   Broomhead P., 1999, DISS ABSTR INT, V60, P2419
   Broomhead P., 2009, UPDATE APPL RES MUSI, V27, P52, DOI DOI 10.1177/8755123308329869
   Broomhead P., 2006, B COUNCIL RES MUSIC, V167, P7
   Broomhead Paul, 2010, CONTRIBUTIONS MUSIC, V37, P65
   Campbell D. T., 1966, Experimental and quasi-experimental designs for research
   Chaffin R, 2010, PSYCHOL MUSIC, V38, P3, DOI 10.1177/0305735608100377
   Cheng E, 2008, J NEW MUSIC RES, V37, P325, DOI 10.1080/09298210802711660
   Collier GL, 2002, MUSIC PERCEPT, V19, P463, DOI 10.1525/mp.2002.19.3.463
   Cook N, 2007, MUSIC SCI, V11, P183, DOI 10.1177/102986490701100203
   De Poli G, 2004, J NEW MUSIC RES, V33, P189, DOI 10.1080/0929821042000317796
   DRISKELL JE, 1994, J APPL PSYCHOL, V79, P481, DOI 10.1037/0021-9010.79.4.481
   Dweck C., 2016, Mindset: The New Psychology of Success
   Edmundson D. D, 1996, DISS ABSTR INT, V59, P3507
   Fabiani M, 2008, LECT NOTES COMPUT SC, V4969, P288
   FELTZ DL, 1983, J SPORT PSYCHOL, V5, P25, DOI 10.1123/jsp.5.1.25
   FRIBERG A, 1991, COMPUT MUSIC J, V15, P56, DOI 10.2307/3680917
   Friberg A, 2000, J NEW MUSIC RES, V29, P199, DOI 10.1076/jnmr.29.3.199.3093
   Friberg A., 1987, ACTION PERCEPTION RH, V55, P49
   Friberg Anders, 2002, SCI PSYCHOL MUSIC PE, P199
   Gabrielsson A, 1999, PSYCHOL MUSIC, P601
   Gabrielsson A, 2001, MUSIC SCI, V5, P123, DOI 10.1177/10298649020050S105
   GOEBL W., 2009, MODERN METHODS MUSIC, P93
   Goebl W., 2008, SOUND SENSE SENSE SO, P178
   Hatzigeorgiadis A, 2009, PSYCHOL SPORT EXERC, V10, P186, DOI 10.1016/j.psychsport.2008.07.009
   Honing H, 2003, COMPUT MUSIC J, V27, P66, DOI 10.1162/014892603322482538
   JOHNSON CM, 1996, J RES MUSIC EDUC, V44, P84, DOI 10.2307/3345415
   Juslin P. N., 2000, MUSICAE SCI, V4, P151, DOI DOI 10.1177/102986490000400202
   Juslin P. N., 1996, PSYCHOL MUSIC, V24, P68, DOI [10.1177/0305735696241007, DOI 10.1177/0305735696241007]
   Juslin P. N., 2004, MUSICAL EXCELLENCE S, P247
   Juslin PN, 2006, J EXP PSYCHOL-APPL, V12, P79, DOI 10.1037/1076-898X.12.2.79
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Juslin PN, 1999, MUSIC PERCEPT, V17, P197
   Karlsson J, 2008, PSYCHOL MUSIC, V36, P309, DOI 10.1177/0305735607086040
   KENDRICK MJ, 1982, J CONSULT CLIN PSYCH, V50, P353, DOI 10.1037/0022-006X.50.3.353
   Laukka P, 2005, COGNITION EMOTION, V19, P633, DOI 10.1080/02699930441000445
   LEHRER PM, 1987, J RES MUSIC EDUC, V35, P143, DOI 10.2307/3344957
   Lisboa T, 2005, MUSIC SCI, V9, P75, DOI 10.1177/102986490500900103
   Mazzola G, 2002, J NEW MUSIC RES, V31, P221, DOI 10.1076/jnmr.31.3.221.14190
   Mazzola Guerino, 2002, The Topos of Music: Geometric Logic of Concepts, Theory, and Performance
   MURPHY SM, 1992, ADV SPORT PSYCHOL, P222
   Ramirez R, 2008, COMPUT MUSIC J, V32, P38, DOI 10.1162/comj.2008.32.1.38
   REPP BH, 1992, J ACOUST SOC AM, V92, P2546, DOI 10.1121/1.404425
   Robinson E., 2004, CANADIAN MUSIC ED, V46, P17
   Rosenthal R, 2009, B COUN RES MUSIC ED, P37
   Seligman MEP., 1990, Learned Optimism
   Sheldon DA, 2004, J RES MUSIC EDUC, V52, P357, DOI 10.2307/3345388
   SILVA JM, 1982, BEHAV MODIF, V6, P443, DOI 10.1177/01454455820064001
   Sloboda JA., 2001, MUSIC EMOTION THEORY, P71
   Sundberg J, 2000, J NEW MUSIC RES, V29, P183, DOI 10.1076/jnmr.29.3.183.3089
   SUNDBERG J, 1989, CONT MUSIC REV, V3, P89, DOI DOI 10.1080/07494468900640071
   TODD N, 1985, MUSIC PERCEPT, V3, P33
   TODD NPM, 1992, J ACOUST SOC AM, V91, P3540, DOI 10.1121/1.402843
   Widmer G, 2004, J NEW MUSIC RES, V33, P203, DOI 10.1080/0929821042000317804
   Widmer G, 2003, J NEW MUSIC RES, V32, P259, DOI 10.1076/jnmr.32.3.259.16860
   Widmer G, 2002, J NEW MUSIC RES, V31, P37, DOI 10.1076/jnmr.31.1.37.8103
   Woody, 2000, RES STUDIES MUSIC ED, V14, P14, DOI [DOI 10.1177/1321103X0001400102, 10.1177/1321103X0001400102]
   Woody RH, 2003, J RES MUSIC EDUC, V51, P51, DOI 10.2307/3345648
   Woody RH, 1999, J RES MUSIC EDUC, V47, P331, DOI 10.2307/3345488
   Woody RH, 2006, J RES MUSIC EDUC, V54, P125, DOI 10.1177/002242940605400204
   Woody RH, 2006, J RES MUSIC EDUC, V54, P21, DOI 10.2307/3653453
NR 69
TC 14
Z9 21
U1 0
U2 28
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0022-4294
EI 1945-0095
J9 J RES MUSIC EDUC
JI J. Res. Music Educ.
PD APR
PY 2012
VL 60
IS 1
BP 62
EP 80
DI 10.1177/0022429411435363
PG 19
WC Education & Educational Research; Music
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Education & Educational Research; Music
GA 913UR
UT WOS:000301903400005
DA 2024-01-09
ER

PT J
AU Alexander, G
   Allen, RE
   Atala, A
   Bowen, WP
   Coley, AA
   Goodenough, JB
   Katsnelson, MI
   Koonin, EV
   Krenn, M
   Madsen, LS
   Månsson, M
   Mauranyapin, NP
   Melvin, AI
   Rasel, E
   Reichl, LE
   Yampolskiy, R
   Yasskin, PB
   Zeilinger, A
   Lidström, S
AF Alexander, Gerianne
   Allen, Roland E.
   Atala, Anthony
   Bowen, Warwick P.
   Coley, Alan A.
   Goodenough, John B.
   Katsnelson, Mikhail, I
   Koonin, Eugene, V
   Krenn, Mario
   Madsen, Lars S.
   Mansson, Martin
   Mauranyapin, Nicolas P.
   Melvin, Art, I
   Rasel, Ernst
   Reichl, Linda E.
   Yampolskiy, Roman
   Yasskin, Philip B.
   Zeilinger, Anton
   Lidstrom, Suzy
TI The sounds of science-a symphony for many instruments and voices
SO PHYSICA SCRIPTA
LA English
DT Article
DE lithium-ion battery; sodium-ion battery; Bose-Einstein condensates;
   Chaos; entropy; singularities
ID GRAVITATIONAL COLLAPSE; STATISTICAL PHYSICS; FACIAL EXPRESSIONS;
   GENERAL-RELATIVITY; SEX-DIFFERENCES; TIME-TRAVEL; QUANTUM; ROTATION;
   ENTROPY; EMOTION
AB Sounds of Science is the first movement of a symphony for many (scientific) instruments and voices, united in celebration of the frontiers of science and intended for a general audience. John Goodenough, the maestro who transformed energy usage and technology through the invention of the lithium-ion battery, opens the programme, reflecting on the ultimate limits of battery technology. This applied theme continues through the subsequent pieces on energy-related topics-the sodium-ion battery and artificial fuels, by Martin Mansson-and the ultimate challenge for 3D printing, the eventual production of life, by Anthony Atala. A passage by Gerianne Alexander follows, contemplating a related issue: How might an artificially produced human being behave? Next comes a consideration of consciousness and free will by Roland Allen and Suzy Lidstrom. Further voices and new instruments enter as Warwick Bowen, Nicolas Mauranyapin and Lars Madsen discuss whether dynamical processes of single molecules might be observed in their native state. The exploitation of chaos in science and technology, applications of Bose-Einstein condensates and the significance of entropy follow in pieces by Linda Reichl, Ernst Rasel and Roland Allen, respectively. Mikhail Katsnelson and Eugene Koonin then discuss the potential generalisation of thermodynamic concepts in the context of biological evolution. Entering with the music of the cosmos, Philip Yasskin discusses whether we might be able to observe torsion in the geometry of the Universe. The crescendo comes with the crisis of singularities, their nature and whether they can be resolved through quantum effects, in the composition of Alan Coley. The climax is Mario Krenn, Art Melvin and Anton Zeilinger's consideration of how computer code can be autonomously surprising and creative. In a harmonious counterpoint, his 'Guidelines for considering AIs as coauthors', Roman Yampolskiy concludes that code is not yet able to take responsibility for coauthoring a paper. An interlude summarises a speech by Zdenek Papousek. In a subsequent movement, new themes emerge as we seek to comprehend how far we have travelled along the path to understanding, and speculate on where new physics might arise. Who would have imagined, 100 years ago, a global society permeated by smartphones and scientific instruments so sophisticated that genes can be modified and gravitational waves detected?
C1 [Alexander, Gerianne] Texas A&M Univ, Dept Psychol & Brain Sci, College Stn, TX USA.
   [Allen, Roland E.; Lidstrom, Suzy] Texas A&M Univ, Dept Phys & Astron, College Stn, TX 77843 USA.
   [Atala, Anthony] Wake Forest Inst Regenerat Med, 391 Technol Way, Winston Salem, NC 27157 USA.
   [Bowen, Warwick P.; Mauranyapin, Nicolas P.] Univ Queensland, Sch Math & Phys, St Lucia, Qld 4072, Australia.
   [Bowen, Warwick P.; Madsen, Lars S.] Univ Queensland, Australian Ctr Engn Quantum Syst, St Lucia, Qld 4072, Australia.
   [Coley, Alan A.] Dalhousie Univ, Dept Math & Stat, Halifax, NS B3H 4R2, Canada.
   [Goodenough, John B.] Univ Texas Austin, Cockrell Inst, Walker Dept Mech Engn, Austin, TX 78712 USA.
   [Katsnelson, Mikhail, I] Radboud Univ Nijmegen, Inst Mol & Mat, NL-6525 AJ Nijmegen, Netherlands.
   [Koonin, Eugene, V] Natl Lib Med, Natl Ctr Biotechnol Informat, Bethesda, MD 20894 USA.
   [Krenn, Mario; Melvin, Art, I; Zeilinger, Anton] Austrian Acad Sci, Inst Quantum Opt & Quantum Informat IQOQI, Boltzmanngasse 3, A-1090 Vienna, Austria.
   [Krenn, Mario] Univ Toronto, Dept Chem, Toronto, ON, Canada.
   [Mansson, Martin] KTH Royal Inst Technol, Dept Appl Phys, SE-16440 Kista, Sweden.
   [Melvin, Art, I; Zeilinger, Anton] Univ Vienna, Fac Phys, Vienna Ctr Quantum Sci & Technol VCQ, Boltzmanngasse 5, A-1090 Vienna, Austria.
   [Rasel, Ernst] Inst Quantenopt, Welfengarten 1, D-30167 Hannover, Germany.
   [Rasel, Ernst] Leibnitz Univ Hannover, QUEST LFS DLR Inst Satellite Geodesy & Inertial S, Welfengarten 1, D-30167 Hannover, Germany.
   [Reichl, Linda E.] Univ Texas Austin, Ctr Complex Quantum Syst, Austin, TX 78712 USA.
   [Reichl, Linda E.] Univ Texas Austin, Dept Phys, Austin, TX 78712 USA.
   [Yampolskiy, Roman] Univ Louisville, Duthie Ctr Engn, Dept Comp Engn & Comp Sci, Louisville, KY 40292 USA.
   [Yasskin, Philip B.] Texas A&M Univ, Dept Math, College Stn, TX 77843 USA.
C3 Texas A&M University System; Texas A&M University College Station; Texas
   A&M University System; Texas A&M University College Station; Wake Forest
   University; University of Queensland; University of Queensland;
   Dalhousie University; University of Texas System; University of Texas
   Austin; Radboud University Nijmegen; National Institutes of Health (NIH)
   - USA; NIH National Library of Medicine (NLM); Austrian Academy of
   Sciences; University of Toronto; Royal Institute of Technology;
   University of Vienna; Leibniz University Hannover; University of Texas
   System; University of Texas Austin; University of Texas System;
   University of Texas Austin; University of Louisville; Texas A&M
   University System; Texas A&M University College Station
RP Lidström, S (corresponding author), Texas A&M Univ, Dept Phys & Astron, College Stn, TX 77843 USA.
EM galexander@tamu.edu; allen@physics.tamu.edu; regenmed@wakehealth.edu;
   w.bowen@uq.edu.au; aac@mathstat.dal.ca; jgoodenough@mail.utexas.edu;
   mario.krenn@univie.ac.at; m.lars@uq.edu.au; condmat@kth.se;
   n.mauranyapin@uq.edu.au; art.i.melvin@gmail.com;
   rasel@iqo.uni-hannover.de; roman.yampolskiy@louisville.edu;
   yasskin@math.tamu.edu; anton.zeilinger@univie.ac.at;
   suzy.lidstrom@gmail.com
RI Bowen, Warwick P/A-7630-2010; Mansson, Martin/C-1134-2014; Biradar,
   Nirmala/AAY-2295-2020; Krenn, Mario/A-2799-2013; Katsnelson, Mikhail
   I./D-4359-2012
OI Bowen, Warwick P/0000-0001-8127-1715; Mansson,
   Martin/0000-0002-3086-9642; Krenn, Mario/0000-0003-1620-9207;
   Mauranyapin, Nicolas/0000-0001-8724-5390; Lidstrom,
   Suzanne/0000-0003-0050-413X
FU Air Force Office of Scientific Research [FA2386-14-1-4046]; NSERC of
   Canada
FX The work presented by W B was supported by the Air Force Office of
   Scientific Research (grant number: FA2386-14-1-4046). P G would like to
   express his deep thanks to Alexia Auffeves and Nayla Farouki for many
   discussions and contributions. A.A.C. would like to thank Aron Wall for
   helpful comments and acknowledge the financial support provided by NSERC
   of Canada. Mr. Zdenek Hofman and Dr. Zdenek Papouek are thanked for
   providing a translation of the transcript of Dr. Zdenek Papouek's speech
   given at the Rudolfium and for permission to cite it here.
CR Abend S, 2016, PHYS REV LETT, V117, DOI 10.1103/PhysRevLett.117.203003
   Agarwal G, 2018, J MOD OPTIC, V65, P1261, DOI 10.1080/09500340.2018.1454525
   Ahlers H, 2016, PHYS REV LETT, V116, DOI 10.1103/PhysRevLett.116.173601
   Alexander GM, 2009, ARCH SEX BEHAV, V38, P427, DOI 10.1007/s10508-008-9430-1
   Alexander GM, 2003, ARCH SEX BEHAV, V32, P7, DOI 10.1023/A:1021833110722
   Alexander GM, 2002, EVOL HUM BEHAV, V23, P467, DOI 10.1016/S1090-5138(02)00107-1
   Allen R E, 2017, ARXIV11010586HEPTH
   Allen RE, 2020, J MOD OPTIC, V67, P35, DOI 10.1080/09500340.2018.1563724
   Allen RE, 2019, PHYS SCRIPTA, V94, DOI 10.1088/1402-4806/aaef19
   Allen RE, 2017, PHYS SCRIPTA, V92, DOI 10.1088/0031-8949/92/1/012501
   Allen RE, 2017, MOD PHYS LETT A, V32, DOI 10.1142/S0217732317300221
   [Anonymous], 2017, P 31 INT C NEUR INF
   [Anonymous], 2016, WASHINGTON POST 0930
   [Anonymous], 2017, PHYS REV LETT, DOI DOI 10.1103/PHYSREVLETT.118.080401
   [Anonymous], METHOD
   [Anonymous], 2017, ARXIV170706170
   [Anonymous], 2016, ARXIV161007997
   [Anonymous], 2017, ARXIV171204020
   [Anonymous], 1929, What life means to Einstein
   [Anonymous], 2008, PHOTONIC CRYSTALS
   [Anonymous], AKAD WISS SITZUNGSBE
   [Anonymous], ARXIV13111213
   [Anonymous], 2017, ARXIV170505363
   [Anonymous], 1999, GENETICAL THEORY NAT
   Asenbaum P, 2017, PHYS REV LETT, V118, DOI 10.1103/PhysRevLett.118.183602
   Ashtekar A, 2006, PHYS REV LETT, V96, DOI 10.1103/PhysRevLett.96.141301
   Ashtekar A, 2006, CLASSICAL QUANT GRAV, V23, P391, DOI 10.1088/0264-9381/23/2/008
   Ashtekar A, 2009, PHYS REV D, V80, DOI 10.1103/PhysRevD.80.123532
   Ashtekar A, 2009, PHYS REV D, V79, DOI 10.1103/PhysRevD.79.083535
   Baars B. J., 1989, COGNITIVE THEORY CON
   Barceló C, 2017, J HIGH ENERGY PHYS, DOI 10.1007/JHEP05(2017)054
   Barton NH, 2009, J THEOR BIOL, V259, P317, DOI 10.1016/j.jtbi.2009.03.019
   Becker D, 2018, NATURE, V562, P391, DOI 10.1038/s41586-018-0605-1
   BELINSKI.VA, 1970, ADV PHYS, V19, P525, DOI 10.1080/00018737000101171
   BELINSKII VA, 1982, ADV PHYS, V31, P639, DOI 10.1080/00018738200101428
   Benedek P, 2019, SUSTAIN ENERG FUELS, V3, P508, DOI 10.1039/c8se00389k
   Berg P, 2015, PHYS REV LETT, V114, DOI 10.1103/PhysRevLett.114.063002
   Berger Beverly K, 2002, Living Rev Relativ, V5, P1, DOI 10.12942/lrr-2002-1
   Bloch I, 2008, REV MOD PHYS, V80, P885, DOI 10.1103/RevModPhys.80.885
   Bojowald M, 2001, PHYS REV LETT, V86, P5227, DOI 10.1103/PhysRevLett.86.5227
   Brehm B, 2016, ARXIV160608058
   Candland Douglas Keith, 1993, Feral Children Clever Animals: Reflections on Human Nature
   Cardoso GL, 2000, J HIGH ENERGY PHYS
   Cardoso GL, 2000, NUCL PHYS B, V567, P87, DOI 10.1016/S0550-3213(99)00560-X
   Carleo G, 2017, SCIENCE, V355, P602, DOI 10.1126/science.aag2302
   Carrasquilla J, 2017, NAT PHYS, V13, P431, DOI [10.1038/NPHYS4035, 10.1038/nphys4035]
   Carroll S., 2016, The Big Picture; On the Origins of Life, Meaning, and the Universe Itself
   Cartan E., 1923, ANN SCIENT EC NORM S, V40, P325, DOI DOI 10.24033/ASENS.751
   Cartan E., 1922, CR HEBD ACAD SCI, V174, P593
   Cartan Elie, 1925, Annales Scientifiques de l'Ecole Normale Superieure, V42, P17, DOI [/10.24033/asens.761, DOI 10.24033/ASENS.761]
   Cartan Elie, 1924, Serie, V41, P1, DOI /10.24033/asens.753
   Castro A, 2008, INT J MOD PHYS A, V23, P613, DOI 10.1142/S0217751X08039724
   Chalmers D., 1995, J CONSCIOUSNESS STUD, V2, P200, DOI [10.1093/acprof:oso/9780195311105.003.0001, DOI 10.1093/ACPR0F:0S0/9780195311105.003.0001]
   Coley AA, 2020, CLASSICAL QUANT GRAV, V37, DOI 10.1088/1361-6382/ab49b6
   Coley AA, 2017, CLASSICAL QUANT GRAV, V34, DOI 10.1088/1361-6382/34/3/035008
   Coley AA, 2016, CLASSICAL QUANT GRAV, V33, DOI 10.1088/0264-9381/33/21/215010
   Coley AA, 2017, PHYS SCRIPTA, V92, DOI 10.1088/1402-4896/aa83c1
   Corichi A, 2017, CLASSICAL QUANT GRAV, V34, DOI 10.1088/1361-6382/aa54c5
   Corichi A, 2016, CLASSICAL QUANT GRAV, V33, DOI 10.1088/0264-9381/33/5/055006
   Curtarolo S, 2013, NAT MATER, V12, P191, DOI [10.1038/NMAT3568, 10.1038/nmat3568]
   Czuchry E, 2017, PHYS REV D, V95, DOI 10.1103/PhysRevD.95.024014
   DAVIES PCW, 1977, P ROY SOC LOND A MAT, V356, P237, DOI 10.1098/rspa.1977.0130
   De Luna P, 2017, NATURE, V552, P23, DOI 10.1038/d41586-017-07820-6
   De Risi G, 2007, PHYS REV D, V76, DOI 10.1103/PhysRevD.76.103531
   Dehaene S., 2014, Consciousness and the Brain: Deciphering How the Brain Codes Our Thoughts
   DEWITT BS, 1967, PHYS REV, V160, P1113, DOI 10.1103/PhysRev.160.1113
   Diener P, 2014, CLASSICAL QUANT GRAV, V31, DOI 10.1088/0264-9381/31/10/105015
   DOBZHANSKY T, 1973, AM BIOL TEACH, V35, P125, DOI 10.2307/4444260
   Domes G, 2009, J PERS DISORD, V23, P6, DOI 10.1521/pedi.2009.23.1.6
   Dutta I, 2016, PHYS REV LETT, V116, DOI 10.1103/PhysRevLett.116.183003
   Einstein A, 1905, ANN PHYS-BERLIN, V17, P132
   Einstein A, 1916, ANN PHYS-BERLIN, V49, P769
   EKMAN P, 1992, PSYCHOL SCI, V3, P34, DOI 10.1111/j.1467-9280.1992.tb00253.x
   Engelhardt N, 2016, PHYS REV D, V93, DOI 10.1103/PhysRevD.93.026005
   England JL, 2013, J CHEM PHYS, V139, DOI 10.1063/1.4818538
   Evans JA, 2011, SCIENCE, V331, P721, DOI 10.1126/science.1201765
   Everitt C, 1972, EXPT GRAVITATION ENR, P331
   Fang B, 2016, J PHYS CONF SER, V723, DOI 10.1088/1742-6596/723/1/012049
   Feinberg T E, 2018, CONSCIOUSNESS DEMYST
   Feynman RP., 1998, Statistical Mechanics
   Freier C, 2016, J PHYS CONF SER, V723, DOI 10.1088/1742-6596/723/1/012050
   FROLOV V, 1993, PHYS REV D, V48, P4545, DOI 10.1103/PhysRevD.48.4545
   Garoby R, 2018, PHYS SCRIPTA, V93, DOI 10.1088/1402-4896/aa9bff
   Gebbe M, 2019, ARXIV190708416
   GIBBONS GW, 1977, PHYS REV D, V15, P2752, DOI 10.1103/PhysRevD.15.2752
   Giedd JN, 1999, NAT NEUROSCI, V2, P861, DOI 10.1038/13158
   GOLDFIELD BA, 1990, J CHILD LANG, V17, P171, DOI 10.1017/S0305000900013167
   Goodenough JB, 2018, DALTON T, V47, P645, DOI 10.1039/c7dt03026f
   Graham N, 2007, PHYS REV D, V76, DOI 10.1103/PhysRevD.76.064001
   Hahn A, 2018, SCIENCE, V360, P620, DOI 10.1126/science.aat4318
   Hardman KS, 2016, PHYS REV LETT, V117, DOI 10.1103/PhysRevLett.117.138501
   Harris LJ, 1997, BIOCHEMISTRY-US, V36, P1581, DOI 10.1021/bi962514+
   Hawking Stephen, 2018, Brief Answers to the Big Questions
   Hawking SW, 2016, PHYS REV LETT, V116, DOI 10.1103/PhysRevLett.116.231301
   HAWKING SW, 1970, PROC R SOC LON SER-A, V314, P529, DOI 10.1098/rspa.1970.0021
   HAWKING SW, 1975, COMMUN MATH PHYS, V43, P199, DOI 10.1007/BF02345020
   Heinzle JM, 2012, PHYS REV D, V86, DOI 10.1103/PhysRevD.86.104049
   Heinzle JM, 2009, CLASSICAL QUANT GRAV, V26, DOI 10.1088/0264-9381/26/7/075016
   Henrich C. C., 2000, APPL DEV SCI, V4, P15, DOI [DOI 10.1207/S1532480XADS0401_2, 10.1207/s1532480xads0401_2]
   HIOE FT, 1983, PHYS LETT A, V99, P150, DOI 10.1016/0375-9601(83)90965-9
   Horowitz GT, 2005, NEW J PHYS, V7, DOI 10.1088/1367-2630/7/1/201
   Hubeny V. E., 2005, JHEP-Journal of High Energy Physics, V2005, DOI 10.1088/1126-6708/2005/05/035
   Inge B, 1990, INFANT MENT HEALTH J, V11, P237, DOI [10.1002/1097-0355(199023)11:3<237::AID-IMHJ2280110306>3.0.CO;2-X, DOI 10.1002/1097-0355(199023)11:3<237::AID-IMHJ2280110306>3.0.CO;2-X]
   Itti L., 2005, Vision Research, V49, P1295, DOI [DOI 10.1016/J.VISRES.2008.09.007, 10.1016/j.visres.2008.09.007]
   Juranyi F, 2015, EPJ WEB CONF, V83, DOI 10.1051/epjconf/20158302008
   Kang HW, 2016, NAT BIOTECHNOL, V34, P312, DOI 10.1038/nbt.3413
   Karremans JC, 2010, EVOL HUM BEHAV, V31, P182, DOI 10.1016/j.evolhumbehav.2009.10.001
   Katsnelson MI, 2018, PHYS SCRIPTA, V93, DOI 10.1088/1402-4896/aaaba4
   Kesti M, 2015, ADV FUNCT MATER, V25, P7406, DOI 10.1002/adfm.201503423
   Kim H, 2018, ADV ENERGY MATER, V8, DOI 10.1002/aenm.201702384
   Kitayama S, 2011, ANNU REV PSYCHOL, V62, P419, DOI 10.1146/annurev-psych-120709-145357
   Koonin EV, 2016, PHILOS T R SOC A, V374, DOI 10.1098/rsta.2015.0065
   Kraus P, 2006, J HIGH ENERGY PHYS, DOI 10.1088/1126-6708/2006/01/022
   Kraus P, 2005, J HIGH ENERGY PHYS
   Krauss Lawrence M., 2012, A Universe from Nothing: Why There Is Something Rather than Nothing
   Krenn M, 2017, PHYS REV LETT, V119, DOI 10.1103/PhysRevLett.119.240403
   Krenn M, 2016, PHYS REV LETT, V116, DOI 10.1103/PhysRevLett.116.090405
   Kubota K, 2018, CHEM REC, V18, P459, DOI 10.1002/tcr.201700057
   Kuhl PK, 2000, P NATL ACAD SCI USA, V97, P11850, DOI 10.1073/pnas.97.22.11850
   Landau L., 1932, PHYS Z SOWJETUNION, V2, P46
   Landry MP, 2009, BIOPHYS J, V97, P2128, DOI 10.1016/j.bpj.2009.07.048
   Le Sage D, 2013, NATURE, V496, P486, DOI 10.1038/nature12072
   Lidström S, 2019, J PHYS CONF SER, V1275, DOI 10.1088/1742-6596/1275/1/012021
   Lim WC, 2009, PHYS REV D, V79, DOI 10.1103/PhysRevD.79.123526
   Liu J, 2006, NATURE, V442, P208, DOI 10.1038/nature04719
   Livadiotis G, 2017, KAPPA DISTRIBUTIONS: THEORY AND APPLICATIONS IN PLASMAS, P1
   Lynch M., 2007, ORIGINS GENOME ARCHI
   Lynch M, 2007, P NATL ACAD SCI USA, V104, P8597, DOI 10.1073/pnas.0702207104
   MACCOBY EE, 1988, DEV PSYCHOL, V24, P755, DOI 10.1037/0012-1649.24.6.755
   Maguire EA, 2006, HIPPOCAMPUS, V16, P1091, DOI 10.1002/hipo.20233
   Majorek KA, 2012, MOL IMMUNOL, V52, P174, DOI 10.1016/j.molimm.2012.05.011
   Maldacena J., 1999, International Journal of Theoretical Physics, V38, P1113, DOI 10.1023/A:1026654312961
   Mann E, 2017, THESIS
   Månsson M, 2014, J PHYS CONF SER, V551, DOI 10.1088/1742-6596/551/1/012037
   Månsson M, 2014, J PHYS CONF SER, V551, DOI 10.1088/1742-6596/551/1/012035
   Månsson M, 2013, PHYS SCRIPTA, V88, DOI 10.1088/0031-8949/88/06/068509
   Martin CL, 2002, PSYCHOL BULL, V128, P903, DOI 10.1037//0033-2909.128.6.903
   Matsese T, 2018, NAT COMMUN, V9, P3823, DOI [10.1038/s41467-018-06343-6, DOI 10.1038/S41467-018-06343-6]
   Matsumoto D, 2009, J PERS SOC PSYCHOL, V96, P1, DOI 10.1037/a0014037
   Mauranyapin NP, 2017, NAT PHOTONICS, V11, P477, DOI [10.1038/nphoton.2017.99, 10.1038/NPHOTON.2017.99]
   May A, 2011, TRENDS COGN SCI, V15, P475, DOI 10.1016/j.tics.2011.08.002
   McGreevy J., 2005, JHEP-Journal of High Energy Physics, V2005, DOI 10.1088/1126-6708/2005/08/090
   Medarde M, 2013, PHYS REV LETT, V110, DOI 10.1103/PhysRevLett.110.266401
   Mirsaidov U, 2008, PHYS REV E, V78, DOI 10.1103/PhysRevE.78.021910
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Moerner WE, 2007, P NATL ACAD SCI USA, V104, P12596, DOI 10.1073/pnas.0610081104
   Müntinga H, 2013, PHYS REV LETT, V110, DOI 10.1103/PhysRevLett.110.093602
   Mukai K, 2013, RSC ADV, V3, P11634, DOI 10.1039/c3ra40878g
   Na K, 2004, PHYS REV A, V70, DOI 10.1103/PhysRevA.70.063405
   NAGEL T, 1974, PHILOS REV, V83, P435, DOI 10.2307/2183914
   Nockel JU, 1997, NATURE, V385, P45, DOI 10.1038/385045a0
   Noether E., 1918, KONIG GESELL WISS MP, V2, P235
   Nugent K., 2015, PHYSICS, V8, P19
   Oikonomou T, 2019, PHYS REV E, V99, DOI 10.1103/PhysRevE.99.032134
   Page DN, 2005, NEW J PHYS, V7, DOI 10.1088/1367-2630/7/1/203
   Penrose R, 2002, GEN RELAT GRAVIT, V34, P1141, DOI 10.1023/A:1016578408204
   PENROSE R, 1965, PHYS REV LETT, V14, P57, DOI 10.1103/PhysRevLett.14.57
   Penrose R., 2002, General Relativity and Gravitation, V34, P1141, DOI 10.1023/A:1016578408204
   Polchinski J., 1998, Superstring Theory and Beyond, V2
   Polchinski J., 1998, An Introduction to the Bosonic String, V1
   POLZIK ES, 1992, PHYS REV LETT, V68, P3020, DOI 10.1103/PhysRevLett.68.3020
   Porter MD, 2017, PHYS REV E, V95, DOI 10.1103/PhysRevE.95.052213
   Raya-Rivera AM, 2014, LANCET, V384, P329, DOI 10.1016/S0140-6736(14)60542-0
   Redding B, 2015, P NATL ACAD SCI USA, V112, P1304, DOI 10.1073/pnas.1419672112
   Ree S, 1999, PHYS REV E, V60, P1607, DOI 10.1103/PhysRevE.60.1607
   Rees M.., 2018, On the Future. Prospects for humanity
   Reichl, 2004, TRANSITION CHAOS, DOI [DOI 10.1007/978-1-4757-4350-0, 10.1007/978-1-4757-4350-0]
   Rhodes G, 2006, ANNU REV PSYCHOL, V57, P199, DOI 10.1146/annurev.psych.57.102904.190208
   Ringström H, 2004, MATH PROC CAMBRIDGE, V136, P485, DOI 10.1017/S0305004103007321
   Ringström H, 2004, CLASSICAL QUANT GRAV, V21, pS305, DOI 10.1088/0264-9381/21/3/019
   Ringström H, 2001, ANN HENRI POINCARE, V2, P405, DOI 10.1007/PL00001041
   Ringström H, 2000, CLASSICAL QUANT GRAV, V17, P713, DOI 10.1088/0264-9381/17/4/301
   Romare M., 2017, STUDY FOCUS CURRENT
   Ruble D, 1998, HDB CHILD PSYCHOL, V3, P933
   Rudolph J, 2015, NEW J PHYS, V17, DOI 10.1088/1367-2630/17/6/065001
   Rzhetsky A, 2015, P NATL ACAD SCI USA, V112, P14569, DOI 10.1073/pnas.1509757112
   Sarkar S, 2019, PHYS REV E, V100, DOI 10.1103/PhysRevE.100.022414
   Schliwa M, 2003, NATURE, V422, P759, DOI 10.1038/nature01601
   Schmidt M, 2009, SCIENCE, V324, P81, DOI 10.1126/science.1165893
   Sella G, 2005, P NATL ACAD SCI USA, V102, P9541, DOI 10.1073/pnas.0501865102
   Senovilla JMM, 2015, CLASSICAL QUANT GRAV, V32, DOI 10.1088/0264-9381/32/12/124008
   Shi F, 2015, SOC NETWORKS, V43, P73, DOI 10.1016/j.socnet.2015.02.006
   Siano P, 2014, RENEW SUST ENERG REV, V30, P461, DOI 10.1016/j.rser.2013.10.022
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Silver David, 2016, ARXIV161208810
   SIMON W, 1986, ARCH SEX BEHAV, V15, P97, DOI 10.1007/BF01542219
   SINGH D, 1993, J PERS SOC PSYCHOL, V65, P293, DOI 10.1037/0022-3514.65.2.293
   Singh P, 2014, CLASSICAL QUANT GRAV, V31, DOI 10.1088/0264-9381/31/3/035010
   Sittadjody S, 2013, BIOMATERIALS, V34, P2412, DOI 10.1016/j.biomaterials.2012.11.059
   Song QH, 2010, PHYS REV LETT, V105, DOI 10.1103/PhysRevLett.105.103902
   Sowa Y, 2005, NATURE, V437, P916, DOI 10.1038/nature04003
   STOEGER WR, 1979, GEN RELAT GRAVIT, V11, P427, DOI 10.1007/BF00759306
   Suddendorf T, 2007, BEHAV BRAIN SCI, V30, P299, DOI 10.1017/S0140525X07001975
   Sugiyama J, 2018, JPS C P, V21, DOI 10.7566/JPSCP.21.011016
   Sugiyama J., 2018, JPS C P, V21
   Sugiyama J, 2019, SUSTAIN ENERG FUELS, V3, P956, DOI 10.1039/c8se00568k
   Sugiyama J, 2015, PHYS REV B, V92, DOI 10.1103/PhysRevB.92.014417
   Sugiyama J, 2013, PHYS REV B, V87, DOI 10.1103/PhysRevB.87.024409
   Sugiyama J, 2012, PHYS REV B, V85, DOI 10.1103/PhysRevB.85.054111
   Sugiyama J, 2011, PHYS REV B, V84, DOI 10.1103/PhysRevB.84.054430
   Sugiyama J, 2010, PHYS REV B, V82, DOI 10.1103/PhysRevB.82.224412
   Sugiyama J, 2010, PHYS REV B, V81, DOI 10.1103/PhysRevB.81.092103
   Sugiyama J, 2009, PHYS REV LETT, V103, DOI 10.1103/PhysRevLett.103.147601
   SZATHMARY E, 1995, NATURE, V374, P227, DOI 10.1038/374227a0
   Szathmáry E, 2015, P NATL ACAD SCI USA, V112, P10104, DOI 10.1073/pnas.1421398112
   Taylor MA, 2016, PHYS REP, V615, P1, DOI 10.1016/j.physrep.2015.12.002
   Taylor MA, 2013, NAT PHOTONICS, V7, P229, DOI [10.1038/NPHOTON.2012.346, 10.1038/nphoton.2012.346]
   Tenne R, 2019, NAT PHOTONICS, V13, P116, DOI 10.1038/s41566-018-0324-z
   TERRACE HS, 1979, SCIENCE, V206, P891, DOI 10.1126/science.504995
   Terry DJ, 1999, BRIT J SOC PSYCHOL, V38, P225, DOI 10.1348/014466699164149
   The_Nobel_Committee, 2019, SCI BACKGR NOB PRIZ
   Throm M, 2019, MOD PHYS LETT A, V34, DOI 10.1142/S0217732319300015
   Tsallis C., 2009, Introduction to Nonextensive Statistical Mechanics
   Uggla C, 2003, PHYS REV D, V68, DOI 10.1103/PhysRevD.68.103502
   Uggla C, 2013, GEN RELAT GRAVIT, V45, P1669, DOI 10.1007/s10714-013-1556-3
   Umegaki I., 2018, JPS C P, V21
   Umegaki I, 2017, PHYS CHEM CHEM PHYS, V19, P19058, DOI 10.1039/c7cp02047c
   Unruh WG, 2017, REP PROG PHYS, V80, DOI 10.1088/1361-6633/aa778e
   Vahlbruch H, 2016, PHYS REV LETT, V117, DOI 10.1103/PhysRevLett.117.110801
   van Nieuwenburg EPL, 2017, NAT PHYS, V13, P435, DOI [10.1038/NPHYS4037, 10.1038/nphys4037]
   VANNIEUWENHUIZEN P, 1981, PHYS REP, V68, P189, DOI 10.1016/0370-1573(81)90157-5
   Vismara LA, 2010, ANNU REV CLIN PSYCHO, V6, P447, DOI 10.1146/annurev.clinpsy.121208.131151
   Vitanov NV, 2017, REV MOD PHYS, V89, DOI 10.1103/RevModPhys.89.015006
   Wäldchen S, 2015, SCI REP-UK, V5, DOI 10.1038/srep15348
   Waldorp M, 2017, NATL GEOGRAPHIC
   Wall AC, 2013, CLASSICAL QUANT GRAV, V30, DOI 10.1088/0264-9381/30/16/165003
   Wall AC, 2012, PHYS REV D, V85, DOI 10.1103/PhysRevD.85.104049
   Wall AC, 2010, PHYS REV D, V81, DOI 10.1103/PhysRevD.81.024038
   Weisskopf V, 1990, JOY INSIGHT PASSIONS
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Wertsch J. V., 1985, Vygotsky and the social formation of the mind
   Willis B.T.M., 2013, EXPT NEUTRON SCATTER
   Wilson-Ewing E, ARXIV171110943
   Wissner-Gross AD, 2013, PHYS REV LETT, V110, DOI 10.1103/PhysRevLett.110.168702
   Wu XJ, 2017, OPTICA, V4, P1545, DOI 10.1364/OPTICA.4.001545
   Xu WJ, 2017, PHYS REV A, V96, DOI 10.1103/PhysRevA.96.063606
   Yampolskiy R, 2013, TOPOI-INT REV PHILOS, V32, P217, DOI 10.1007/s11245-012-9128-9
   Yampolskiy RomanV., 2015, Artificial superintelligence: A futuristic approach
   Yaouanc A., 2011, Muon Spin Rotation, Relaxation, and Resonance: Applications to Condensed Matter
   Yasskin P, 1979, THESIS
   YASSKIN PB, 1980, PHYS REV D, V21, P2081, DOI 10.1103/PhysRevD.21.2081
   Yun M, 2003, EMBO J, V22, P5382, DOI 10.1093/emboj/cdg531
   Zeilinger A, 2017, PHYS SCRIPTA, V92, P1, DOI 10.1088/1402-4896/aa736d
   Zener C, 1932, P R SOC LOND A-CONTA, V137, P696, DOI 10.1098/rspa.1932.0165
   [No title captured]
NR 245
TC 6
Z9 6
U1 1
U2 27
PU IOP PUBLISHING LTD
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 0031-8949
EI 1402-4896
J9 PHYS SCRIPTA
JI Phys. Scr.
PD JUN
PY 2020
VL 95
IS 6
AR 062501
DI 10.1088/1402-4896/ab7a35
PG 50
WC Physics, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Physics
GA LT1IA
UT WOS:000536827100001
OA Green Published, hybrid, Green Submitted
DA 2024-01-09
ER

PT J
AU Lucarini, V
   Grice, M
   Cangemi, F
   Zimmermann, JT
   Marchesi, C
   Vogeley, K
   Tonna, M
AF Lucarini, Valeria
   Grice, Martine
   Cangemi, Francesco
   Zimmermann, Juliane T.
   Marchesi, Carlo
   Vogeley, Kai
   Tonna, Matteo
TI Speech Prosody as a Bridge Between Psychopathology and Linguistics: The
   Case of the Schizophrenia Spectrum
SO FRONTIERS IN PSYCHIATRY
LA English
DT Review
DE communication; non-emotional; prosody; pragmatics; psychopathology;
   linguistics; schizophrenia spectrum
ID HIGHER-ORDER LANGUAGE; ANCILLARY ARTICLE; EMOTIONAL PROSODY; SOCIAL
   COGNITION; MUSICAL PATTERNS; RECOGNITION; ABNORMALITIES; PHENOMENOLOGY;
   DISTURBANCES; EXPRESSION
AB Patients with schizophrenia spectrum disorders experience severe difficulties in interpersonal communication, as described by traditional psychopathology and current research on social cognition. From a linguistic perspective, pragmatic abilities are crucial for successful communication. Empirical studies have shown that these abilities are significantly impaired in this group of patients. Prosody, the tone of voice with which words and sentences are pronounced, is one of the most important carriers of pragmatic meaning and can serve a range of functions from linguistic to emotional ones. Most of the existing literature on prosody of patients with schizophrenia spectrum disorders focuses on the expression of emotion, generally showing significant impairments. By contrast, the use of non-emotional prosody in these patients is scarcely investigated. In this paper, we first present a linguistic model to classify prosodic functions. Second, we discuss existing studies on the use of non-emotional prosody in these patients, providing an overview of the state of the art. Third, we delineate possible future lines of research in this field, also taking into account some classical psychopathological assumptions, for both diagnostic and therapeutic purposes.
C1 [Lucarini, Valeria; Marchesi, Carlo] Univ Parma, Med Fac, Dept Med & Surg, Psychiat Unit, Parma, Italy.
   [Grice, Martine; Cangemi, Francesco] Univ Cologne, IfL Phonet, Cologne, Germany.
   [Zimmermann, Juliane T.; Vogeley, Kai] Univ Cologne, Med Fac, Dept Psychiat & Psychotherapy, Cologne, Germany.
   [Vogeley, Kai] Res Ctr Julich, Inst Neurosci & Med, Cognit Neurosci INM 3, Julich, Germany.
   [Tonna, Matteo] Azienda Unita Sanit Locale Parma, Dept Mental Hlth, Parma, Italy.
C3 University of Parma; University of Cologne; University of Cologne;
   Helmholtz Association; Research Center Julich
RP Lucarini, V (corresponding author), Univ Parma, Med Fac, Dept Med & Surg, Psychiat Unit, Parma, Italy.
EM valeria.lucarini@studenti.unipr.it
RI Vogeley, K T/E-4860-2012
OI Vogeley, K T/0000-0002-5891-5831; Lucarini, Valeria/0000-0002-3553-8818;
   cangemi, francesco/0000-0003-1016-5178
FU German Research Foundation (DFG) [SFB 1252]
FX The research for this paper has been funded by the German Research
   Foundation (DFG) as part of the SFB 1252 "Prominence in Language" in
   project A02 "Individual behavior in encoding and decoding prosodic
   prominence" at the University of Cologne.
CR Alpert M, 2000, PSYCHIAT RES, V97, P107, DOI 10.1016/S0165-1781(00)00231-6
   Bambini V, 2016, COMPR PSYCHIAT, V71, P106, DOI 10.1016/j.comppsych.2016.08.012
   Bedwell JS, 2014, J NERV MENT DIS, V202, P745, DOI 10.1097/NMD.0000000000000184
   Bernardini F, 2016, PSYCHIAT RES, V239, P253, DOI 10.1016/j.psychres.2016.03.037
   Bleuler E, 2014, DEMENTIA PRAECOX ODE, P445
   Caletti E, 2018, COMPR PSYCHIAT, V86, P31, DOI 10.1016/j.comppsych.2018.07.004
   Cannizzaro MS, 2005, COGN BEHAV NEUROL, V18, P206, DOI 10.1097/01.wnn.0000185278.21352.e5
   Castagna F, 2013, PSYCHIAT RES, V205, P192, DOI 10.1016/j.psychres.2012.08.038
   Champagne-Lavau M, 2010, J NEUROLINGUIST, V23, P285, DOI 10.1016/j.jneuroling.2009.08.009
   Cohen AS, 2013, SCHIZOPHR RES, V146, P249, DOI 10.1016/j.schres.2013.02.002
   Cohen AS, 2011, J PERS DISORD, V25, P478, DOI 10.1521/pedi.2011.25.4.478
   Colle L, 2013, J COMMUN DISORD, V46, P294, DOI 10.1016/j.jcomdis.2013.01.003
   Compton MT, 2018, SCHIZOPHR RES, V197, P392, DOI 10.1016/j.schres.2018.01.007
   Couture SM, 2006, SCHIZOPHRENIA BULL, V32, pS44, DOI 10.1093/schbul/sbl029
   Covington MA, 2005, SCHIZOPHR RES, V77, P85, DOI 10.1016/j.schres.2005.01.016
   Covington MA, 2012, SCHIZOPHR RES, V142, P93, DOI 10.1016/j.schres.2012.10.005
   Crow TJ, 2000, BRAIN RES REV, V31, P118, DOI 10.1016/S0165-0173(99)00029-6
   Dickey CC, 2012, SCHIZOPHR RES, V142, P20, DOI 10.1016/j.schres.2012.09.006
   Doerr-Zegers O, 2016, J PSYCHOPATHOL, V22, P55
   Edwards Jane, 2001, Schizophrenia Research, V48, P235, DOI 10.1016/S0920-9964(00)00099-2
   Fuchs T, 2015, WORLD PSYCHIATRY, V14, P178, DOI 10.1002/wps.20209
   GOLDSTEIN K, 1959, J ABNORM SOC PSYCH, V59, P146, DOI 10.1037/h0045400
   Green MF, 2008, SCHIZOPHRENIA BULL, V34, P670, DOI 10.1093/schbul/sbn045
   Grice M., 2007, Non-native prosody. Phonetic description and teaching practice. Trends in linguistics. Studies and monographs [TiLSM], P25, DOI DOI 10.1515/9783110198751.1.25
   Grice M., 2016, CULTURE BRAIN, V4, P38, DOI [10.1007/s40167-016-0035-6, DOI 10.1007/S40167-016-0035-6]
   Hoekert M, 2007, SCHIZOPHR RES, V96, P135, DOI 10.1016/j.schres.2007.07.023
   Insel T, 2010, AM J PSYCHIAT, V167, P748, DOI 10.1176/appi.ajp.2010.09091379
   Joyal M, 2016, PSYCHIAT RES, V240, P88, DOI 10.1016/j.psychres.2016.04.010
   Kantrowitz JT, 2014, PSYCHOL MED, V44, P25, DOI 10.1017/S0033291713000834
   Kraepelin E, 1899, PSYCHIAT LEHRBUCH ST, P364
   Kruger M, 2018, P 9 INT C SPEECH PRO, P182, DOI [10.21437/SpeechProsody.2018-37, DOI 10.21437/SPEECHPROSODY.2018-37]
   Kruger M., 2018, THESIS
   Kuperberg GR, 2010, LANG LINGUIST COMPAS, V4, P576, DOI 10.1111/j.1749-818x.2010.00216.x
   Kuperberg GR, 2010, LANG LINGUIST COMPAS, V4, P590, DOI 10.1111/j.1749-818x.2010.00217.x
   Kupper Z, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0145882
   Lado-Codesido M, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0210816
   Leentjens AFG, 1998, J NEUROL NEUROSUR PS, V64, P375, DOI 10.1136/jnnp.64.3.375
   Lehiste I, 1976, CONT ISSUES EXPT PHO, P256
   Lehiste I, 1970, SUPRASEGMENTALS, P194
   Leitman DI, 2006, PSYCHOL MED, V36, P1075, DOI 10.1017/S0033291706007653
   Lin Y, 2018, J CLIN MED, V7, DOI 10.3390/jcm7100363
   Martínez-Sánchez F, 2015, SPAN J PSYCHOL, V18, DOI 10.1017/sjp.2015.85
   Matsumoto K, 2006, BRIT J PSYCHIAT, V189, P180, DOI 10.1192/bjp.bp.105.009332
   Michelas A, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00755
   Minkowski E, 1933, TEMPS VECU ETUDES PH, P432
   MURPHY D, 1990, J NEUROL NEUROSUR PS, V53, P727, DOI 10.1136/jnnp.53.9.727
   Nicholson KG, 2003, BRAIN COGNITION, V52, P382, DOI 10.1016/S0278-2626(03)00182-9
   Patel AD, 1998, BRAIN LANG, V61, P123, DOI 10.1006/brln.1997.1862
   Pawelczyk A, 2019, EARLY INTERV PSYCHIA, V13, P369, DOI 10.1111/eip.12482
   Pawelczyk A, 2018, PSYCHIAT RES, V267, P63, DOI 10.1016/j.psychres.2018.05.070
   Pawelczyk A, 2018, SCHIZOPHR RES, V192, P274, DOI 10.1016/j.schres.2017.04.030
   Pienkos E, 2017, PSYCHOPATHOLOGY, V50, P83, DOI 10.1159/000455195
   Rabagliati H, 2019, PSYCHOL MED, V49, P1335, DOI 10.1017/S0033291718001952
   Ruesch J, 1957, DISTURBED COMMUNICAT, P337
   Sass L, 2017, PSYCHOPATHOLOGY, V50, P10, DOI 10.1159/000454928
   Shriberg LD, 2001, J SPEECH LANG HEAR R, V44, P1097, DOI 10.1044/1092-4388(2001/087)
   Stanghellini G, 2000, SCHIZOPHRENIA BULL, V26, P775, DOI 10.1093/oxfordjournals.schbul.a033493
   Stanghellini G, 2017, PSYCHOPATHOLOGY, V50, P75, DOI 10.1159/000456037
   Vogeley K, 2007, SCHIZOPHRENIA BULL, V33, P157, DOI 10.1093/schbul/sbl056
   Wehrle S, 2018, P PHON PHON DEUTSCHS, P136
NR 60
TC 13
Z9 13
U1 1
U2 8
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-0640
J9 FRONT PSYCHIATRY
JI Front. Psychiatry
PD SEP 15
PY 2020
VL 11
AR 531863
DI 10.3389/fpsyt.2020.531863
PG 8
WC Psychiatry
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Psychiatry
GA NY1TU
UT WOS:000576181500001
PM 33101074
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Hill, J
AF Hill, Juniper
TI Improvisation, Exploration, Imagination: Techniques for Composing Music
   Orally
SO REVUE DE MUSICOLOGIE
LA English
DT Article
ID CONTEMPORARY FOLK-MUSIC
AB This article illustrates creative techniques for composing, improvising and arranging music orally. Three categories of techniques are discussed playing with patterns, playing with tools, and playing with limits. The first involves developing through oral transmission and aural memory storage, a bank of patterns that can be manipulated in melodic improvisation, variation, and oral composition. The second comprises arranging tools, such as drones, ostinati, grooves, soundscapes, parallel and countermelodies, Western harmony, Eastern European harmonies, and other forms of polyphony. These techniques are particularly useful for collective creativity in ensemble composition and improvisation. The third entails exploring-and sometimes transcending or transforming-the limits of various systems, such as genre forms, pitch sets, instruments and idiomatic conventions, as well as self-consciously imposed temporary boundaries. Strategies for stimulating inspiration include invoking narratives or visualizations, imagining ways of recreating the past, conducting artistic research, exploring the inner self; communicating life experiences, and expressing emotions. Prioritizing learning practicing performing and creating music orally enhances musicians' creative fluency and capacity. Ideology, learning methods, and cultural practices shape the opportunities musicians have to engage fully in the spectrum of possible creative techniques. Examples are drawn from ethnographic research on contemporary folk musicians in Finland, who employ both traditional and contemporary approaches Privileging the voices of creative practitioners provides insight into how musicians themselves experience creative processes.
C1 [Hill, Juniper] Univ Cape Town, ZA-7700 Rondebosch, South Africa.
C3 University of Cape Town
RP Hill, J (corresponding author), Univ Cambridge, Cambridge CB2 1TN, England.
EM jhill@wesleyan.edu
OI Hill, Juniper Lynn/0009-0001-8999-2290
CR Alakotila Timo, 2008, COMMUNICATION
   [Anonymous], CREATIVITY FLOW AND
   Asplund Anneli, 1981, KANSANMUSIIKKI, P18
   Barz Gregory F., 2008, SHADOWS IN THE FIELD, V2nd
   Boden Margaret, 2004, THE CREATIVE MIND MY, P3
   Hargreaves DJ, 2012, PSYCHOL MUSIC, V40, P539, DOI 10.1177/0305735612444893
   Hill J., 2009, ETHNOMUSICOL FORUM, V18, P205
   Hill J., INNOVATION AND CULTU
   Hill J., 2012, MUSICAL IMAGINATIONS, P87, DOI [10.1093/acprof:oso/9780199568086.003.0006, DOI 10.1093/ACPROF:OSO/9780199568086.003.0006]
   Hill J., 2009, MUSIK INTERKULTURELL, P91
   Hill J, 2007, YEARB TRADIT MUSIC, V39, P50
   Hill J, 2009, ETHNOMUSICOLOGY, V53, P86
   Hill Juniper, THE OXFORD HANDBOOK
   Hill Juniper, 2005, THESIS, P263
   Hill Juniper, 2011, MUSIIKIN SUUNTA, V4, P53
   Ilmonen Kristiina, 2008, COMMUNICATION
   Ilmonen Kristiina, 2004, COMMUNICATION
   Joutsenlahti Leena, 1999, MAKALE, P84
   Joutsenlahti Leena, 2004, COMMUNICATION
   Juslin PN, 2010, HANDBOOK OF MUSIC AN, VXIV
   Kastinen Arja, 2000, RESEARCH ON THE ACOU
   Kastinen Arja, 2003, COMMUNICATION
   Kyhala J., 2012, COMMUNICATION
   Kyhala Jouko, 2003, COMMUNICATION
   Kyhala Jouko, 2012, COMMUNICATION
   LAITINEN H, COMMUNICATION
   Laitinen H., 2008, COMMUNICATION
   Laitinen Heikki, 2004, COMMUNICATION
   Liedes Anna-Kaisa, 2005, MATKOJA ANEW MAAILMA, P5
   Logren Lassi, 2001, STEMMASOITTOA VIULUL
   Lord A., 2000, THE SINGER OF TALES, P99
   Lord Albert B., 1983, S WHOL RANG DISC ETH, P158
   McLucas Anne Dhu, 2011, THE MUSICAL EAR ORAL
   Merker B., 2006, Musical Creativity: Multidisciplinary Research in Theory and Practice, P25
   Nieminen Rauno, 2007, JOUHIKKO THE BOWED L
   Pulkkinen Outi, 2012, COMMUNICATION
   Pulkkinen Outi, 2010, MYYTY NEITO RUNO LAU
   Pulkkinen Outi, 2010, KALEVALAMHTAISEN RUN, P319
   Rice Timothy, 1994, MAY IT FILL YOUR SOU, P3
   RIVAS C., 2012, RES SOC CULTURE, P366
   Titon Jeff Todd, 1994, EARLY DOWNHOME BLUES
   Wilhelms J., COMMUNICATION
   Wilhelms Jenny, 2004, COMMUNICATION
NR 43
TC 0
Z9 0
U1 0
U2 8
PU EDITIONS TRANSATLANTIQUES
PI PARIS
PA 50 RUE JOSEPH DE MAISTRE, 75018 PARIS, FRANCE
SN 0035-1601
J9 REV MUSICOL
JI Rev. Music.
PY 2012
VL 98
IS 1
BP 85
EP 106
PG 22
WC Music
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music
GA 237BG
UT WOS:000325842600004
DA 2024-01-09
ER

PT J
AU Chan, E
AF Chan, Eleanor
TI The 'English' cadence: reading an early modern musical trope
SO EARLY MUSIC
LA English
DT Article
DE history of ornament; visual culture; English cadence; false relation;
   choral music; polyphony
ID EMOTION
AB Twisting through a dissonant flattened 7th now more commonly recognized as the Jazz 'blue' 7th, the 'English' cadence is a distinctive feature of early modern English music. Typically embedded within the texture of a piece in an inner part, this distinctive voice-leading pattern works by pulling against its own regularity: it highlights its predictability, the regularity of the cadence, by spiralling, just briefly, into the unpredictable. Nevertheless, ever since Thomas Morley dubbed it a thing 'naught and stale' the 'English' cadence has had a dubious reception, both in terms of its Englishness and its role within early modern musical textures. Much of this doubt derives from the status of the cadence as 'ornament' or 'decoration'. As such the 'English' cadence is often viewed as superfluous to the tonality of the music as a whole. However, these interpretations do not take into account contemporary thinking about ornament and decoration in early modern England. This article seeks to demonstrate that by looking beyond the scant contemporary accounts of the 'English' cadence in musical theoretical treatises towards the visual culture of the period, it is possible to move towards a more nuanced understanding of the way the cadence communicates.
C1 [Chan, Eleanor] Univ Manchester, Mus Dept, Manchester, Lancs, England.
C3 University of Manchester
RP Chan, E (corresponding author), Univ Manchester, Mus Dept, Manchester, Lancs, England.
EM eleanor.chan@manchester.ac.uk
OI Chan, Ellie/0000-0002-7314-297X
CR [Anonymous], 2013, DETAILS CONSEQUENCE
   [Anonymous], 2007, Picturing Space, Displacing Bodies: Anamorphosis in Early Modern Theories o fPerspective
   [Anonymous], 1997, The Invention of Infinity: Mathematics and Art in the Renaissance
   [Anonymous], 1984, LUTES VIOLS TEMPERAM
   Apel Willi, 1990, ITALIAN VIOLIN MUSIC, P56
   Atkinson N., 2017, NOISY RENAISSANCE SO
   Bain J, 2003, J MUSIC THEORY, V47, P325, DOI 10.1215/00222909-47-2-325
   Baxandall Michael, 1990, ENGLAND CONTINENTAL, P203
   Bhogal G. K., 2007, TWENT-CENTURY MUSIC, Viii, P171
   Bhogal T., 2014, ROUTLEDGE COMPANION, P191
   Blackburn BJ, 2015, EROTICISM IN EARLY MODERN MUSIC, P19
   Burmeister Joachim, 1606, Musica Poetica
   Butler K, 2018, LIBRARY, V19, P174, DOI 10.1093/library/19.2.174
   Byrd William, 1589, CANTIONES SACRAE
   Cave T, 2014, PARAGRAPH, V37, P1, DOI 10.3366/para.2014.0106
   Champion Matthew S, 2017, The Fullness of Time: Temporalities of the Fifteenth Century Low Countries
   Chesters T, 2014, PARAGRAPH, V37, P62, DOI 10.3366/para.2014.0110
   Clark A, 2016, COMMUN CONTROL ENG, P1, DOI 10.1007/978-3-319-26977-1
   Clark A, 2018, J CONSCIOUSNESS STUD, V25, P71
   Collinson Patrick, 1988, BIRTHPANGS PROTESTAN, P119
   Cooke D., 1959, LANGUAGE MUSIC, P57
   Cornysh William, GENTLE ROBIN HENRY V
   Crane Mary Thomas, 2001, SHAKESPEARES BRAIN R
   Davies John, 1599, NOSCE TEIPSUM, P43
   de la Primaudaye Pierre, 1594, SECOND PART FRENCH A
   Dekker Thomas, 1608, BELMAN LONDON
   Dennis F, 2019, CAMB HIST MUSIC, P260
   des Prez Josquin, ADIEU MES AMOURS
   Everist M, 2018, DISCOVERING MEDIEVAL SONG: LATIN POETRY AND MUSIC IN THE CONDUCTUS, P151
   Evett David., 1990, LIT VISUAL ARTS TUDO, P10
   Feldman Barrett L., 2017, How emotions are made: The secret life of the brain
   Feldman H, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00215
   Fleming J, 2006, WORD IMAGE, V22, P165, DOI 10.1080/02666280500239297
   Fleming J., 2016, CULTURAL GRAPHOLOGY, P84
   Fleming J, 2008, J MEDIEV EARLY MOD S, V38, P345, DOI 10.1215/10829636-2007-029
   Fleming J, 2013, MAT READ EARLY MOD, P179
   Foucault M., 1970, The Order of Things: An Archaeology of the Human Sciences
   Fraunce Abraham, 1588, ARCADIAN RHETORICKE
   Friston KJ, 2009, TRENDS COGN SCI, V13, P293, DOI 10.1016/j.tics.2009.04.005
   Fumerton Patricia, 1991, Cultural Aesthetics: Renaissance Literature and the Practice of Social Ornament
   Gent L., 1995, PICTURE POETRY 1560, P379
   Gibbons Orlando, 1635, HOSANNA SON DAVID
   Gombrich E.H., 1979, The Sense of Order: A Study of the Psychology of Decorative Art
   Guest Clare Lapraik., 2016, The Understanding of Ornament in the Italian Renaissance
   Harvey E. Ruth., 1975, The Inward Wits: Psychological Theory in the Middle Ages and the Renaissance
   Harwood I., 2002, WIRE STRINGS HELMING, P2
   Herissone R., 2001, MUSIC THEORY 17 CENT, P170
   Huron D., 2018, VOICE LEADING SCI MU
   Jones O., 1982, GRAMMAR ORNAMENT
   Jones Owen, 1856, The Grammar of Ornament
   K E., 1579, SHEPHEARDES CALENDAR
   Kain E., 1993, PROBLEMS STYLE FDN H
   Kant Immanuel, 2008, Critique of Judgement
   Kavaler E.M., 2012, Renaissance Gothic
   Kury G., ALBIONS CLASSICISM, P395
   Leach EE, 2006, MUSIC THEOR SPECTRUM, V28, P1, DOI 10.1525/mts.2006.28.1.1
   Lindley Mark., 1993, Mathematical Models of Musical Scales
   Lyne R., 2011, SHAKESPEARE RHETORIC, P29
   Lyne Shakespeare, 2011, SHAKESPEARE RHETORIC
   MacLeod C., 2019, ELIZABETHAN TREASURE, P8
   Margulis Elizabeth Hellmuth, 2014, On Repeat: How Music Plays the Mind
   Massey L., 1997, TREATISE PERSPECTIVE
   McCarthy Kerry, 2013, BYRD, P146
   McColley Diane Kelsey, 1997, POETRY MUSIC 17 CENT, P77
   Merriam S., 2012, 17 CENTURY FLEMISH G, P8
   MILSOM J, 1985, MUSIC TIMES, V126, P658, DOI 10.2307/965035
   Mirabella B, 2011, ORNAMENTALISM: THE ART OF RENAISSANCE ACCESSORIES, P59
   Morley Thomas, 1597, PLAINE EASIE INTRO P, P154
   Morley Thomas, 1600, MADRIGALS FOURE VOIC, P2
   Murray T., 2014, T MORLEY ELIZABETHAN
   Olson Rebecca, 2013, ARRAS HANGING TEXTIL
   Ormerod George, 1882, HIST CHESHIRE, P154
   Page C., 2015, GUITAR TUDOR ENGLAND, P60
   Peacham Henry, 1612, GRAPHICE ART DRAWING, P45
   Peacham Henry, 1622, COMPLEAT GENTLEMAN, P103
   Pearce MT, 2012, TOP COGN SCI, V4, P625, DOI 10.1111/j.1756-8765.2012.01214.x
   Phillips P., 1991, ENGLISH SACRED MUSIC, P56
   PIKE L, 1993, MUSIC LETT, V74, P68, DOI 10.1093/ml/74.1.68
   Purcell Henry, I WAS GLAD, P210
   Ruskin J., 2010, WORKS J RUSKIN
   Scott W, 2013, MODEL OF POESY, P1
   Semper Gottfried, 1863, Der Stil in den technischen und tektonischen Kunsten oder die praktische Asthetik
   Seth AK, 2013, TRENDS COGN SCI, V17, P565, DOI 10.1016/j.tics.2013.09.007
   Shephard T., 2014, ECHOING HELICON MUSI, P141
   Sherry Richard, 1550, TREATISE SCHEMES TRO
   Smith Bruce, 2009, The Key of Green: Passion and Perception in Renaissance Culture
   Smith Helen, 2011, Renaissance Paratexts, P48
   Stoichita V., 1997, SELF AWARE IMAGE INS, P23
   Strong Roy, 1983, ENGLISH RENAISSANCE
   Summerly Jeremy, 1996, LEADING NOTES, V6, P7
   Summers David, 1987, The Judgment of Sense: Renaissance Naturalism and the Rise of Aesthetics
   Tobin Vera, 2018, Elements of surprise: Our mental limits and the satisfactions of plot
   Tomkis Thomas, 1607, LINGUA COMBAT TONGUE
   Uhler J. E., 1955, MUSIC LETT, Vxxxvi, P313
   van Helmholtz Hermann, 1867, HDB PSYSIOLOGISCHEN
   van Wilder Philip, 1546, 31 CHANSONS NOUVELLE, V6
   Varwig B, 2009, MUSIC LETT, V90, P215, DOI 10.1093/ml/gcn092
   Vickers Brian., 1988, In Defense of Rhetoric
   Vuust P, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01111
   Vuust P, 2009, CORTEX, V45, P80, DOI 10.1016/j.cortex.2008.05.014
   Wegman RC, 1996, J AM MUSIC SOC, V49, P409, DOI 10.1525/jams.1996.49.3.03a00030
   Weldon John, 1266, FULL FATHOM 5, P1266
   Wesley J, 2015, RENAISSANCE QUART, V68, P1265, DOI 10.1086/685126
   Williams D, 2020, SYNTHESE, V197, P1749, DOI 10.1007/s11229-018-1768-x
   Wilson Thomas, 1553, ARTE RHETORIQUE, P91
   Wilson Thomas, 1553, The Arte of Rhetorique
   Wright Thomas, 1604, PASSIONS MINDE GEN, P168
NR 107
TC 1
Z9 1
U1 0
U2 0
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 0306-1078
EI 1741-7260
J9 EARLY MUSIC
JI Early Music
PD FEB
PY 2021
VL 49
IS 1
BP 17
EP +
DI 10.1093/em/caaa082
EA APR 2021
PG 19
WC Music
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music
GA XG4AI
UT WOS:000724696700019
OA Green Published, hybrid
DA 2024-01-09
ER

PT J
AU Monahan, S
AF Monahan, Seth
TI Action and Agency Revisited
SO JOURNAL OF MUSIC THEORY
LA English
DT Article
ID MUSICAL FORCES
AB For centuries, metaphors of agency have pervaded music-analytical writing. Today, as in generations past, critics routinely vivify their analytical narrations by ascribing sentience, emotion, and volition to musical works, their internal elements (pitch classes, contrapuntal voices, etc.), and fictionalized versions of their composers. This study investigates the use of such agential conceits and the conventions that seem to govern them, using the opening of Beethoven's A-minor Quartet, op. 132, as a central test case. The descriptive model it constructs borrows key concepts from the seemingly incompatible agential theories of Edward T. Cone, who heard music's agencies as obligatory and hierarchically nested, and Fred E. Maus, who clarified the poietic function of such agential ascriptions while stressing their provisional, ad hoc, and often ephemeral nature. After arriving at a fourfold hierarchy of fictional agent types-the individuated element, the work-persona, the fictional composer, and the analyst-the study then examines their relational logic, with special interest in (1) the ways that explicit agency claims at one level can spin off implicit claims at another and (2) the deeper consistencies that underlie seemingly contradictory accounts in which agency shifts from one locus to another. It also considers the various alternative guises (or avatars) that these agent classes take and the kinds of semantic ambiguities that often arise from their use.
C1 Eastman Sch Mus, Rochester, NY 14627 USA.
C3 University of Rochester
RP Monahan, S (corresponding author), Eastman Sch Mus, Rochester, NY 14627 USA.
CR Agawu Victor Kofi, 1991, Playing with Signs: A Semiotic Interpretation of Classical Music
   Almén B, 2003, J MUSIC THEORY, V47, P1, DOI 10.1215/00222909-47-1-1
   Almen Byron., 2008, A Theory of Musical Narrative. Musical Meaning and Interpretation .
   [Anonymous], 1994, A Theory of Musical Semiotics
   [Anonymous], BEETHOVEN QUARTETS
   [Anonymous], 2007, GEN MUSICAL INTERVAL
   [Anonymous], 1997, Theory and Practice
   [Anonymous], 1997, Theory and Practice
   [Anonymous], 1965, COLL MUSIC SYM, V5, P49
   [Anonymous], 1995, RINK 1995
   [Anonymous], MUSIC MEANING
   [Anonymous], 2011, MUSIC THEORY ONLINE
   [Anonymous], SEM 2009 SEM TIM P A
   [Anonymous], 1859, L VANBEETHOVEN LEBEN
   [Anonymous], 1990, Music, Art, and Metaphysics
   Baileyshea M, 2007, NINETEEN CENT MUSIC, V31, P3, DOI 10.1525/ncm.2007.31.1.003
   Bekker Paul, 1925, BEETHOVEN
   Bekker Paul, 1969, G MAHLERS SINFONIEN
   BENT Ian, 1994, Fugue, Form and Style, V1, P157
   Bent Ian, 1805, HERMENEUTIC APPROACH, V2, P127
   Bent Ian, 1846, HERMENEUTIC APPROACH, P62
   Bent Ian, 1885, HERMENEUTIC APPROACH, V2, P242
   Bernard, 1997, MUSIC THEORY CONCEPT, P433
   Bloom Harold, 1998, Shakespeare: The Invention of the Human
   Burnham Scott, 1995, BEETHOVEN HERO
   Caballero R, 2009, HUM COGN PROCESS, V25, P277
   Cadwallader Allen, 2007, ANAL TONAL MUSIC SCH
   Chua Daniel., 1995, The galitzin quartets of Beethoven
   Cohn, 2012, AUDACIOUS EUPHONY CH
   COHN R, 1996, MUSIC ANAL, V15, P9, DOI 10.2307/854168
   Cohn RL, 1999, NINETEEN CENT MUSIC, V22, P213
   CONE Edward T., 1974, The Composer's Voice
   Cone EdwardT, 1967, PERSPECT NEW MUSIC, V6, P33
   CONE ET, 1982, NINETEEN CENT MUSIC, V5, P233
   CONE ET, 1989, COLL MUSIC SYM, V29, P75
   Cook Nicholas, 1999, RETHINKING MUSIC, P217
   Cumming N, 1997, MUSIC ANAL, V16, P5, DOI 10.2307/854112
   Cumming Naomi, 2000, SONIC SELF MUSICAL S
   CUSICK SG, 1994, PERSPECT NEW MUSIC, V32, P8, DOI 10.2307/833149
   DAHLHAUS CARL, 1987, L VANBEETHOVEN SEINE, P126
   Drabkin William, 2004, TONWILLE, V1, P25
   Duane B, 2012, J MUSIC THEORY, V56, P87, DOI 10.1215/00222909-1546976
   Dunsby Jonathan, 2010, J MUSIC THEORY PEDAG, V24, P175
   Fludernik M., 1996, NATURAL NARRATOLOGY
   FORTE A, 1983, J MUSIC THEORY, V27, P255, DOI 10.2307/843519
   GUCK MA, 1994, MUSIC THEOR SPECTRUM, V16, P217, DOI 10.1525/mts.1994.16.2.02a00040
   Guck Marion, 1994, THEORY ANAL MEANING, P57
   Haimo E, 1996, MUSIC THEOR SPECTRUM, V18, P167, DOI 10.1525/mts.1996.18.2.02a00020
   Hanning Barbara R., 1989, EIGHTEENTH-CENT STUD, V22, P512
   HATTEN Robert S., 1994, Musical Meaning in Beethoven: Markedness, Correlation, and Interpretation
   HATTEN Robert S., 2004, Interpreting Musical Gestures, Topics, and Tropes
   Hepokoski J, 2001, NINETEEN CENT MUSIC, V25, P127
   Hepokoski J, 2006, NINETEEN CENT MUSIC, V30, P4
   HEPOKOSKI James, 2006, Elements of sonata theory: Norms, types, and deformations in the late-eighteenth-century sonata
   Hopkins Antony, 1996, 9 SYMPHONIES BEETHOV
   Jephcott Edmund, 1992, Mahler: A Musical Physiognomy
   Karl G, 1997, MUSIC THEOR SPECTRUM, V19, P13, DOI 10.1525/mts.1997.19.1.02a00020
   Keefe Simon P, 2001, Mozart's Piano Concertos: Dramatic Dialogue in the Age of Enlightenment
   Kivy Peter, 2009, ANTITHETICAL ARTS AN, P119
   Klein M, 2004, MUSIC THEOR SPECTRUM, V26, P23, DOI 10.1525/mts.2004.26.1.23
   Kramer Lawrence, 2001, MUSICAL MEANING CRIT
   Krebs Harald., 1999, FANTASY PIECES METRI
   Lang Paul Henry, 1963, CREATIVE WORLD MOZAR, P56
   Larson S, 2005, MUSIC PERCEPT, V23, P119, DOI 10.1525/mp.2005.23.2.119
   Larson S, 2004, MUSIC PERCEPT, V21, P457, DOI 10.1525/mp.2004.21.4.457
   Larson S, 2002, MUSIC PERCEPT, V19, P351, DOI 10.1525/mp.2002.19.3.351
   Larson Steve, 2006, MUSIC AND GESTURE, P61
   LEWIN D, 1986, MUSIC PERCEPT, V3, P327
   LEWIN D, 1983, PERSPECT NEW MUSIC, V21, P312
   LEWIN D, 1982, NINETEEN CENT MUSIC, V6, P47
   Lewin David., 2007, MUSICAL FORM TRANSFO
   Leydon Rebecca, 1996, THESIS MCGILL U
   MAUS FE, 1993, PERSPECT NEW MUSIC, V31, P264, DOI 10.2307/833390
   MAUS FE, 1988, MUSIC THEOR SPECTRUM, V10, P56, DOI 10.1525/mts.1988.10.1.02a00050
   MAUS FE, 1992, J MUSICOLOGY, V10, P273, DOI 10.1525/jm.1992.10.3.03a00010
   MAUS FE, 1989, COLL MUSIC SYM, V29, P31
   Maus FE., 1991, Indiana Theory Rev, V12, P1
   McClary Susan., 2000, CONVENTIONAL WISDOM
   Monahan S, 2007, NINETEEN CENT MUSIC, V31, P53, DOI 10.1525/ncm.2007.31.1.053
   Monahan S, 2011, J AM MUSIC SOC, V64, P119, DOI 10.1525/jams.2011.64.1.119
   NEHAMAS A, 1986, J PHILOS, V83, P685, DOI 10.5840/jphil1986831118
   NEHAMAS A, 1981, CRIT INQUIRY, V8, P133, DOI 10.1086/448144
   Oulibicheff Alexandre, 1857, BEETHOVEN SES CRITIQ
   Painter Karen, 1996, THESI COLUMBIA U
   Pastille William, 1895, THEORIA-SPAIN, V3, P86
   Pierce Alexandra., 2007, Deepening Musical Performance Through Movement: The Theory and Practice of Embodied Interpretation
   Rabinow Paul, 1984, The Foucault Reader, P101
   Rings Steven., 2011, TONALITY TRANSFORMAT
   RINK J, 1994, MUSIC ANAL, V13, P99, DOI 10.2307/854282
   Samarotto Frank, 2009, MUSIC THEORY ONLINE, V15
   Schenker H., 1979, Free Composition
   Scher Steven, 1992, MUSIC TEXT CRITICAL, P177
   Schmalzriedt Siegfried, 1978, VONFORM SINN MUSIK G, P170
   SNARRENBERG R, 1997, SCHENKERS INTERPRETI
   SOLIE RA, 1980, NINETEEN CENT MUSIC, V4, P147
   Straus JN, 2003, MUSIC THEOR SPECTRUM, V25, P305, DOI 10.1525/mts.2003.25.2.305
   Straus Joseph N., 1998, UNFOLDINGS ESSAYS SC, P161
   Temperley D, 2011, MUSIC THEOR SPECTRUM, V33, P146, DOI 10.1525/mts.2011.33.2.146
   Temperley David., 2001, Current Musicology, V66, P66
   TOVEY DF, 1935, ESSAYS MUSICAL ANAL, V1
   Tovey Donald Francis, 1936, ESSAYS MUSICAL ANAL, VIII
   TREITLER L, 1980, NINETEEN CENT MUSIC, V3, P193
   TREITLER L, 1982, J MUSICOLOGY, V1, P153, DOI 10.1525/jm.1982.1.2.03a00010
   TREITLER L, 1989, MUSIC HIST IMAGINATI, P176
   Tymoczko D., 2011, GEOMETRY MUSIC HARMO
   Van Thal Herbert, 1963, TESTAMENT MUSIC, P240
   WALLACE R, 1989, J MUSICOLOGY, V7, P3, DOI 10.1525/jm.1989.7.1.03a00010
   ZBIKOWSKI Lawrence, 2002, Conceptualizing Music: Cognitive Structure, Theory, and Analysis, DOI 10.1093/acprof:oso/9780195140231.001.0001
   Zbikowski LM, 2008, CAMB HANDB PSYCHOL, P502
   Zuckerkandl Victor, 1956, SOUND SYMBOL
NR 110
TC 41
Z9 86
U1 0
U2 4
PU DUKE UNIV PRESS
PI DURHAM
PA 905 W MAIN ST, STE 18-B, DURHAM, NC 27701 USA
SN 0022-2909
EI 1941-7497
J9 J MUSIC THEORY
JI J. Music Theory
PD FAL
PY 2013
VL 57
IS 2
BP 321
EP 371
DI 10.1215/00222909-2323497
PG 51
WC Music
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music
GA 252ZR
UT WOS:000327051900004
DA 2024-01-09
ER

PT J
AU Oba, SI
   Galvin, JJ
   Fu, QJ
AF Oba, Sandra I.
   Galvin, John J., III
   Fu, Qian-Jie
TI Minimal effects of visual memory training on auditory performance of
   adult cochlear implant users
SO JOURNAL OF REHABILITATION RESEARCH AND DEVELOPMENT
LA English
DT Article
DE auditory learning; auditory perception; auditory training; cochlear
   implant; digit span; hearing loss; memory training; music perception;
   rehabilitation; speech recognition
ID HEARING-IMPAIRED CHILDREN; WORKING-MEMORY; SPEECH RECOGNITION; DISTORTED
   SPEECH; DEAF-CHILDREN; NOISE; PERCEPTION; LISTENERS; PROGRAM; SYSTEM
AB Auditory training has been shown to significantly improve cochlear implant (CI) users' speech and music perception. However, it is unclear whether posttraining gains in performance were due to improved auditory perception or to generally improved attention, memory, and/or cognitive processing. In this study, speech and music perception, as well as auditory and visual memory, were assessed in 10 CI users before, during, and after training with a nonauditory task. A visual digit span (VDS) task was used for training, in which subjects recalled sequences of digits presented visually. After the VDS training, VDS performance significantly improved. However, there were no significant improvements for most auditory outcome measures (auditory digit span, phoneme recognition, sentence recognition in noise, digit recognition in noise), except for small (but significant) improvements in vocal emotion recognition and melodic contour identification. Posttraining gains were much smaller with the nonauditory VDS training than observed in previous auditory training studies with CI users. The results suggest that posttraining gains observed in previous studies were not solely attributable to improved attention or memory and were more likely due to improved auditory perception. The results also suggest that CI users may require targeted auditory training to improve speech and music perception.
C1 [Oba, Sandra I.; Galvin, John J., III; Fu, Qian-Jie] House Ear Res Inst, Div Commun & Auditory Neurosci, Los Angeles, CA 90057 USA.
   [Fu, Qian-Jie] Univ So Calif, Dept Biomed Engn, Los Angeles, CA 90089 USA.
   [Fu, Qian-Jie] Univ So Calif, Neurosci Program, Los Angeles, CA 90089 USA.
C3 House Research Institute; University of Southern California; University
   of Southern California
RP Oba, SI (corresponding author), House Ear Res Inst, Div Commun & Auditory Neurosci, 2100 West 3rd St, Los Angeles, CA 90057 USA.
EM soba@hei.org
FU National Institutes of Health National Institute on Deafness and Other
   Communication Disorders [R01-DC004792]
FX This material is based on work supported by the National Institutes of
   Health National Institute on Deafness and Other Communication Disorders
   (grant R01-DC004792).
CR Amitay S, 2006, NAT NEUROSCI, V9, P1446, DOI 10.1038/nn1787
   [Anonymous], J ACAD REHABILITATIV
   [Anonymous], 2000, J ACAD REHABIL AUDIO
   Cleary M, 2001, EAR HEARING, V22, P395, DOI 10.1097/00003446-200110000-00004
   Davis MH, 2005, J EXP PSYCHOL GEN, V134, P222, DOI 10.1037/0096-3445.134.2.222
   Donaldson GS, 2011, EAR HEARING, V32, P238, DOI 10.1097/AUD.0b013e3181fb8390
   Firszt JB, 2009, OTOL NEUROTOL, V30, P146, DOI 10.1097/MAO.0b013e3181924ff8
   Fu QJ, 2008, HEARING RES, V242, P198, DOI 10.1016/j.heares.2007.11.010
   Fu QJ, 2005, ACOUST RES LETT ONL, V6, P106, DOI 10.1121/1.1898345
   Fu QJ, 2003, J ACOUST SOC AM, V113, P1065, DOI 10.1121/1.1537708
   Galvin JJ, 2007, EAR HEARING, V28, P302, DOI 10.1097/01.aud.0000261689.35445.20
   Hawkey DJC, 2004, NAT NEUROSCI, V7, P1055, DOI 10.1038/nn1315
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Kronenberger WG, 2011, J SPEECH LANG HEAR R, V54, P1182, DOI 10.1044/1092-4388(2010/10-0119)
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Loebach JL, 2008, J ACOUST SOC AM, V123, P1126, DOI 10.1121/1.2823453
   Loebach JL, 2009, EAR HEARING, V30, P662, DOI 10.1097/AUD.0b013e3181b9c92d
   Mahncke HW, 2006, P NATL ACAD SCI USA, V103, P12523, DOI 10.1073/pnas.0605194103
   Moore DR, 2009, PHILOS T R SOC B, V364, P409, DOI 10.1098/rstb.2008.0187
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469
   Nogaki G, 2007, EAR HEARING, V28, P132, DOI 10.1097/AUD.0b013e3180312669
   Oba SI, 2011, EAR HEARING, V32, P573, DOI 10.1097/AUD.0b013e31820fc821
   Owen AM, 2010, NATURE, V465, P775, DOI 10.1038/nature09042
   Papp KV, 2009, ALZHEIMERS DEMENT, V5, P50, DOI 10.1016/j.jalz.2008.10.008
   Pisoni David B, 2011, Ear Hear, V32, p60S, DOI 10.1097/AUD.0b013e3181ffd58e
   Pisoni DB, 2003, EAR HEARING, V24, p106S, DOI 10.1097/01.AUD.0000051692.05140.8E
   Pisoni DB, 2000, ANN OTO RHINOL LARYN, V109, P92, DOI 10.1177/0003489400109S1240
   Plant K, 2007, EAR HEARING, V28, P381, DOI 10.1097/AUD.0b013e31804793ac
   Rosen S, 1999, J ACOUST SOC AM, V106, P3629, DOI 10.1121/1.428215
   Shannon RV, 2004, ACTA OTO-LARYNGOL, V124, P50, DOI 10.1080/03655230410017562
   Shannon RV, 1999, J ACOUST SOC AM, V106, pL71, DOI 10.1121/1.428150
   Smith GE, 2009, J AM GERIATR SOC, V57, P594, DOI 10.1111/j.1532-5415.2008.02167.x
   Stacey PC, 2008, J SPEECH LANG HEAR R, V51, P526, DOI 10.1044/1092-4388(2008/038)
   Stacey PC, 2007, J ACOUST SOC AM, V121, P2923, DOI 10.1121/1.2713668
   Stacey PC, 2010, INT J AUDIOL, V49, P347, DOI 10.3109/14992020903397838
   Strait DL, 2010, HEARING RES, V261, P22, DOI 10.1016/j.heares.2009.12.021
   Vandali AE, 2000, EAR HEARING, V21, P608, DOI 10.1097/00003446-200012000-00008
   Wright BA, 2009, PHILOS T R SOC B, V364, P301, DOI 10.1098/rstb.2008.0262
   Wu JL, 2007, AUDIOL NEURO-OTOL, V12, P307, DOI 10.1159/000103211
   Xin Luo, 2007, Trends Amplif, V11, P301
   Yucel E, 2009, INT J PEDIATR OTORHI, V73, P1043, DOI 10.1016/j.ijporl.2009.04.009
NR 41
TC 18
Z9 21
U1 1
U2 37
PU JOURNAL REHAB RES & DEV
PI BALTIMORE
PA DEPT OF VETERANS AFFAIRS REHABIL RES & DEVELOP CTR 103 SOUTH GAY STREET,
   BALTIMORE, MD 21202-4051 USA
SN 0748-7711
EI 1938-1352
J9 J REHABIL RES DEV
JI J. Rehabil. Res. Dev.
PY 2013
VL 50
IS 1
BP 99
EP 110
DI 10.1682/JRRD.2011.12.0229
PG 12
WC Rehabilitation
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Rehabilitation
GA 149FE
UT WOS:000319303600018
PM 23516087
OA Green Accepted, Bronze
DA 2024-01-09
ER

PT J
AU O'Mathuna, DP
AF O'Mathuna, Donal P.
TI Nursing Ethics Education Thinking, Feeling, and Technology
SO NURSING CLINICS OF NORTH AMERICA
LA English
DT Article
DE Ethical comportment; Educational technology; Emotions; Microethics;
   Macroethics; Motion pictures; Music; Principle-based ethics
ID TEACHING ETHICS; ONLINE
AB Online technology brings many opportunities for ethics education. Virtual learning environments lack some physical classroom features, where teachers can do in-person monitoring of a discussion or exploration of a case study or film clip. For example, additional information can be released as discussions develop, or carefully crafted questions can be asked at opportune times to take the discussion into a deeper or different direction. Students who may not be "getting it" can be more easily identified in person, as can others who may be overwhelmed by emotions or reliving difficult experiences in their own lives. Body language and tone of voice are important elements of in-person discussions, particularly on challenging topics. Online environments, especially asynchronous courses, raise challenges in these areas. At the same time, animated videos, escape rooms, and educational games can be developed or adapted for virtual learning environments to facilitate technology-based discussions. As with any strategy, time must be invested in understanding the strengths and limitations of technology-supported ethics education and ensuring it is molded to the specific learning objectives and context. This fact points to the importance of online educators having the training, technological support, and resources available to adapt their teaching strategies to technology-based learning.
   Ethics education is increasingly being examined to determine whether it helps people become more ethical and better prepared to address ethics in the real world. A focus on the cognitive and knowledge dimensions of ethics is insufficient to prepare nurses for the broader dimensions of ethical comportment and related concepts, which require engaging with the affective, personal, and relational dimensions of ethics. Doing so can not only be more challenging, especially in an online environment, but also more engaging and satisfying. More evaluation of the effectiveness of various teaching strategies is important if we are to prepare nurses and other health care professionals to better address the everyday ethics of practice and explore the emotional dimensions of ethics.
C1 [O'Mathuna, Donal P.] Ohio State Univ, Coll Nursing, 1585 Neil Ave, Columbus, OH 43210 USA.
   [O'Mathuna, Donal P.] Ohio State Univ, Ctr Bioeth & Med Humanities, 1585 Neil Ave, Columbus, OH 43210 USA.
C3 University System of Ohio; Ohio State University; University System of
   Ohio; Ohio State University
RP O'Mathuna, DP (corresponding author), Ohio State Univ, Coll Nursing, 1585 Neil Ave, Columbus, OH 43210 USA.; O'Mathuna, DP (corresponding author), Ohio State Univ, Ctr Bioeth & Med Humanities, 1585 Neil Ave, Columbus, OH 43210 USA.
EM omathuna.6@osu.edu
RI O'Mathúna, Dónal/AAL-7625-2020
CR American Association of Colleges of Nursing (AACN), 2021, ESS COR COMP PROF NU
   Annas George J., 2010, WORST CASE BIOETHICS
   [Anonymous], 2009, BIOETHICS MOVIES
   Beauchamp TL, 2022, PRINCIPLES BIOMEDICA, V8th
   Benner P, 2005, AM J CRIT CARE, V14, P152, DOI 10.4037/ajcc2005.14.2.152
   BENNER P, 1991, ADV NURS SCI, V14, P1
   Benner P., 2010, Educating nurses: A call for radical transformation
   Benner P, 2008, AM J CRIT CARE, V17, P473
   Blasco PG, 2018, ASIAN BIOETHICS REV, V10, P75, DOI 10.1007/s41649-018-0046-z
   Callister LC, 2009, NURS ETHICS, V16, P499, DOI 10.1177/0969733009104612
   Chaos SY, 2017, NURS EDUC TODAY, V55, P31, DOI 10.1016/j.nedt.2017.04.011
   Doane G, 2004, NURS ETHICS, V11, P240, DOI 10.1191/0969733004ne692oa
   Donlan P, 2019, J CONTIN EDUC HEALTH, V39, P124
   Edwards S, 2006, ESSENTIALS TEACHING, P55
   Fowler M., 2021, ONLINE J ISSUES NURS, V26, DOI [10.3912/OJIN.Vol26No02PPT722, DOI 10.3912/OJIN.VOL26NO02PPT722]
   Gallagher A., 2010, ONLINE J ISSUES NURS, V16, P2
   Gintrowicz R, 2020, GMS J MED EDU, V37, DOI 10.3205/zma001373
   Grason S, 2020, J NURS EDUC, V59, P506, DOI 10.3928/01484834-20200817-05
   Greaney AM, 2012, MED HEALTH CARE PHIL, V15, P383, DOI 10.1007/s11019-011-9356-6
   Greenhalgh T, 2021, PATIENT EDUC COUNS, V104, P2643, DOI 10.1016/j.pec.2021.07.022
   Haidt J, 2001, PSYCHOL REV, V108, P814, DOI 10.1037//0033-295X.108.4.814
   Hardin J, 2018, J NURS EDUC, V57, P460, DOI 10.3928/01484834-20180720-03
   Katsarov J, 2020, GAMES ETHICS, P197, DOI DOI 10.1007/978-3-658-28175-5_13
   Kelley MM, 2022, J CLIN NURS, V31, P2167, DOI 10.1111/jocn.16032
   Krautscheid LC, 2014, MICROETHICAL DECISIO
   Liaschenko J, 2006, J MED ETHICS, V32, P672, DOI 10.1136/jme.2005.013060
   Mc Inerney J, 2018, J MED RADIAT SCI, V65, P13, DOI 10.1002/jmrs.258
   McAllister M, 2016, NURSE EDUC PRACT, V16, P119, DOI 10.1016/j.nepr.2015.10.007
   McConnell T, 2009, BIOETHICS MOVIES, P186
   Michl S, 2021, GMS J MED EDU, V38, DOI 10.3205/zma001424
   Mizzoni J, 2006, TEACH ETHICS, V6, P15
   Molewijk B, 2011, BIOETHICS, V25, P383, DOI 10.1111/j.1467-8519.2011.01914.x
   Movies Change People, US
   Nussbaum Martha, 2001, Upheavals of thought. The intelligence of emotions
   O'Mathuna DP, 2008, MONASH BIOETH REV, V27, P42
   Ramirez L, 2021, AM J EMERG MED, V43, P238, DOI 10.1016/j.ajem.2020.03.018
   REICH WT, 1987, SEMIN PERINATOL, V11, P279
   Reyes I, 2020, NURS EDUC, V45, P71, DOI 10.1097/NNE.0000000000000714
   Serembus JF, 2020, NURS EDUC, V45, P68, DOI 10.1097/NNE.0000000000000701
   Trobec I, 2015, NURS ETHICS, V22, P352, DOI 10.1177/0969733014533241
NR 40
TC 0
Z9 0
U1 6
U2 15
PU W B SAUNDERS CO-ELSEVIER INC
PI PHILADELPHIA
PA 1600 JOHN F KENNEDY BOULEVARD, STE 1800, PHILADELPHIA, PA 19103-2899 USA
SN 0029-6465
EI 1558-1357
J9 NURS CLIN N AM
JI Nurs. Clin. North Am.
PD DEC
PY 2022
VL 57
IS 4
BP 613
EP 625
DI 10.1016/j.cnur.2022.06.009
EA OCT 2022
PG 13
WC Nursing
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Nursing
GA 5Z3OP
UT WOS:000879885700011
PM 36280299
DA 2024-01-09
ER

PT J
AU Berman, CJ
   O'Brien, JD
   Zenko, Z
   Ariely, D
AF Berman, Catherine J.
   O'Brien, Julia D.
   Zenko, Zachary
   Ariely, Dan
TI The Limits of Cognitive Reappraisal: Changing Pain Valence, but not
   Persistence, during a Resistance Exercise Task
SO INTERNATIONAL JOURNAL OF ENVIRONMENTAL RESEARCH AND PUBLIC HEALTH
LA English
DT Article
DE reappraisal; exercise; affect; valence; arousal; exertion; pain;
   discomfort; persistence; resistance
ID EMOTION REGULATION STRATEGIES; PHYSICAL-ACTIVITY; VIRTUAL-REALITY;
   PERCEIVED EXERTION; DEPRESSIVE SYMPTOMS; AFFECTIVE RESPONSES; INTENSITY
   EXERCISE; MUSIC; ATTENTION; PLEASURE
AB Physiological discomfort is commonly cited as a barrier for initiating and persisting with exercise. Although individuals may think of physiological discomfort as determined by physical sensations, it can also be influenced by cognitive and emotional factors. We explored the impacts of interpreting the purpose of pain as a sign of muscle building (helpful) vs. a sign of muscle tearing and possible injury (harmful) and tested the effect of cognitive reappraisals, or shifting interpretations of pain, on exercise persistence and the subjective experience of discomfort during exercise. Seventy-eight participants were randomized to listen to voice recordings that framed exercise-related pain as helpful vs. harmful before participating in a standard muscular endurance test using the YMCA protocol. Although the two experimental groups did not differ in the overall number of resistance training repetitions achieved, participants who were asked to think about the benefits (rather than the negative consequences) of pain reported less negative pain valence during exercise. Thus, the experience of pain was influenced by appraisals of the meaning of pain, but differences in pain valence did not impact exercise persistence. Theoretical implications and applications for affect-based exercise interventions are discussed.
C1 [Berman, Catherine J.; O'Brien, Julia D.; Ariely, Dan] Duke Univ, Ctr Adv Hindsight, Durham, NC 27701 USA.
   [Zenko, Zachary] Calif State Coll Bakersfield, Dept Kinesiol, Bakersfield, CA 93311 USA.
C3 Duke University; California State University System; California State
   University Bakersfield
RP Berman, CJ (corresponding author), Duke Univ, Ctr Adv Hindsight, Durham, NC 27701 USA.
EM catherine.j.berman@duke.edu; julie.obrien@duke.edu; zzenko@csub.edu;
   dan@danariely.com
CR Adams R, 1999, CAN FAM PHYSICIAN, V45, P992
   Annesi JJ, 1997, PERCEPT MOTOR SKILL, V85, P835, DOI 10.2466/pms.1997.85.3.835
   [Anonymous], 2013, ACSMS GUIDELINES EXE
   BOUTCHER SH, 1990, J SPORT EXERCISE PSY, V12, P167, DOI 10.1123/jsep.12.2.167
   Brand R, 2017, GER J EXERC SPORT RE, V47, P1, DOI [10.1007/s12662-017-0450-7, 10.1007/s12662-017-0477-9]
   Brand R, 2015, J SPORT EXERCISE PSY, V37, P63, DOI 10.1123/jsep.2014-0018
   Chang Hyukki, 2017, J Exerc Nutrition Biochem, V21, P1, DOI 10.20463/jenb.2017.0012
   Chang YK, 2009, J SPORT EXERCISE PSY, V31, P640, DOI 10.1123/jsep.31.5.640
   Colley Rachel C, 2011, Health Rep, V22, P15
   Connolly CT, 2010, J APPL SOC PSYCHOL, V40, P1123, DOI 10.1111/j.1559-1816.2010.00613.x
   Craig CL, 2003, MED SCI SPORT EXER, V35, P1381, DOI 10.1249/01.MSS.0000078924.61453.FB
   DANDOY AC, 1990, J SOC BEHAV PERS, V5, P275
   Ding D, 2016, LANCET, V388, P1311, DOI 10.1016/S0140-6736(16)30383-X
   Dunton GF, 2008, HEALTH PSYCHOL, V27, P703, DOI 10.1037/0278-6133.27.6.703
   Eccleston C, 1999, PSYCHOL BULL, V125, P356, DOI 10.1037/0033-2909.125.3.356
   Ekkekakis P, 1999, J SPORT EXERCISE PSY, V21, P205, DOI 10.1123/jsep.21.3.205
   Ekkekakis P, 2005, J SPORT SCI, V23, P477, DOI 10.1080/02640410400021492
   Ekkekakis P, 2003, COGNITION EMOTION, V17, P213, DOI 10.1080/02699930302292
   Ekkekakis P, 1999, SPORTS MED, V28, P337, DOI 10.2165/00007256-199928050-00005
   Ekkekakis P., International Review of Sport and Exercise Psychology, V2, P73, DOI DOI 10.1080/17509840802705920
   Ekkekakis P, 2017, CURR OPIN PSYCHOL, V16, P84, DOI 10.1016/j.copsyc.2017.03.018
   Ekkekakis P, 2011, SPORTS MED, V41, P641, DOI 10.2165/11590680-000000000-00000
   EKKEKAKIS Panteleimon, 2012, The Oxford Handbook of Exercise Psychology., DOI DOI 10.1093/OXFORDHB/9780195394313.013.0016
   Fredrickson BL, 2004, PHILOS T R SOC B, V359, P1367, DOI 10.1098/rstb.2004.1512
   Garland EL., 2011, Mindfulness, V2, P59, DOI [DOI 10.1007/S12671-011-0043-8, 10.1007/s12671-011-0043-8]
   Garland EL, 2017, COGNITIVE THER RES, V41, P381, DOI 10.1007/s10608-016-9768-y
   Garnefski N, 2006, PERS INDIV DIFFER, V40, P1659, DOI 10.1016/j.paid.2005.12.009
   Garnefski N, 2004, PERS INDIV DIFFER, V36, P267, DOI 10.1016/S0191-8869(03)00083-7
   Giles GE, 2018, MOTIV EMOTION, V42, P482, DOI 10.1007/s11031-018-9697-z
   Giles GE, 2017, EXP BRAIN RES, V235, P3785, DOI 10.1007/s00221-017-5098-x
   Giles GE, 2014, NEUROREPORT, V25, P1320, DOI 10.1097/WNR.0000000000000266
   Goodin BR, 2009, J PAIN, V10, P180, DOI 10.1016/j.jpain.2008.08.012
   Gross J. J., 1998, Review of General Psychology, V2, P271, DOI [DOI 10.1037/1089-2680.2.3.271, https://doi.org/10.1037/1089-2680.2.3.271]
   Gross J. J., 2007, Handbook of emotion regulation, P3
   Guthold R, 2018, LANCET GLOB HEALTH, V6, pE1077, DOI [10.1016/S2214-109X(18)30357-7, 10.1016/s2214-109x(18)30357-7]
   HARDY CJ, 1989, J SPORT EXERCISE PSY, V11, P304, DOI 10.1123/jsep.11.3.304
   Holtzer R, 2011, J GERONTOL A-BIOL, V66, P879, DOI 10.1093/gerona/glr068
   Hutchinson JC, 2007, PSYCHOL SPORT EXERC, V8, P233, DOI 10.1016/j.psychsport.2006.03.006
   Hutchinson JC, 2018, SPORT EXERC PERFORM, V7, P80, DOI 10.1037/spy0000115
   Ide K, 1999, J APPL PHYSIOL, V87, P1604, DOI 10.1152/jappl.1999.87.5.1604
   Jamieson JP, 2012, J EXP PSYCHOL GEN, V141, P417, DOI 10.1037/a0025719
   Jones L, 2014, J SPORT EXERCISE PSY, V36, P528, DOI [10.1123/jsep.2013-0251, 10.1123/jsep.2014-0251]
   Kalisch R, 2006, J COGNITIVE NEUROSCI, V18, P1266, DOI 10.1162/jocn.2006.18.8.1266
   Karageorghis C. I., 1997, Journal of Sport Behavior, V20, P54
   Karageorghis CI, 2012, INT REV SPORT EXER P, V5, P67, DOI 10.1080/1750984X.2011.631027
   Kashdan TB, 2006, BEHAV RES THER, V44, P1301, DOI 10.1016/j.brat.2005.10.003
   Kounalakis SN, 2012, APPL PHYSIOL NUTR ME, V37, P407, DOI [10.1139/h2012-011, 10.1139/H2012-011]
   LAZARUS RS, 1991, AM PSYCHOL, V46, P819, DOI 10.1037/0003-066X.46.8.819
   Li L, 2014, J SPORT HEALTH SCI, V3, P58, DOI 10.1016/j.jshs.2013.12.003
   Lishner DA, 2008, COGNITION EMOTION, V22, P180, DOI 10.1080/02699930701319139
   Liu J, 2008, PUBLIC HEALTH, V122, P1384, DOI 10.1016/j.puhe.2008.05.007
   Macrae Holden, 2003, Res Sports Med, V11, P261, DOI 10.1080/714041040
   McRae K, 2012, EMOTION, V12, P250, DOI 10.1037/a0026351
   Mestre DR, 2011, STUD HEALTH TECHNOL, V167, P122, DOI 10.3233/978-1-60750-766-6-122
   Mestre DR, 2011, PRESENCE-VIRTUAL AUG, V20, P1, DOI 10.1162/pres_a_00031
   Morgan W P, 1977, Ann N Y Acad Sci, V301, P382, DOI 10.1111/j.1749-6632.1977.tb38215.x
   O'Connor PJ, 2001, MED SCI SPORT EXER, V33, P1046, DOI 10.1097/00005768-200106000-00026
   Ochsner KN, 2002, J COGNITIVE NEUROSCI, V14, P1215, DOI 10.1162/089892902760807212
   Ochsner KN, 2005, TRENDS COGN SCI, V9, P242, DOI 10.1016/j.tics.2005.03.010
   PARFITT G, 1995, PERCEPT MOTOR SKILL, V80, P259, DOI 10.2466/pms.1995.80.1.259
   Plante TG, 2003, COMPUT HUM BEHAV, V19, P495, DOI 10.1016/S0747-5632(02)00074-2
   Quartana PJ, 2009, EXPERT REV NEUROTHER, V9, P745, DOI [10.1586/ern.09.34, 10.1586/ERN.09.34]
   Ray RD, 2008, J PERS SOC PSYCHOL, V94, P133, DOI 10.1037/0022-3514.94.1.133
   Rhodes RE, 2015, ANN BEHAV MED, V49, P715, DOI 10.1007/s12160-015-9704-5
   Rupp T, 2008, EUR J APPL PHYSIOL, V102, P153, DOI 10.1007/s00421-007-0568-7
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Shafir R, 2015, SOC COGN AFFECT NEUR, V10, P1329, DOI 10.1093/scan/nsv022
   Sullivan MJL, 2002, PAIN, V100, P47, DOI 10.1016/S0304-3959(02)00206-3
   SVEBAK S, 1985, J PERS SOC PSYCHOL, V48, P107, DOI 10.1037/0022-3514.48.1.107
   Timinkul A, 2008, NEUROSCI RES, V61, P242, DOI 10.1016/j.neures.2008.03.012
   Troiano RP, 2008, MED SCI SPORT EXER, V40, P181, DOI 10.1249/mss.0b013e31815a51b3
   Tudor-Locke C, 2010, INT J BEHAV NUTR PHY, V7, DOI 10.1186/1479-5868-7-60
   Vlaeyen JWS, 2000, PAIN, V85, P317, DOI 10.1016/S0304-3959(99)00242-0
   Vuori I., 2004, KINESIOLOGY, V36, P123
   Welch AS, 2007, PSYCHOL SPORT EXERC, V8, P401, DOI 10.1016/j.psychsport.2006.09.002
   Wiech K, 2008, TRENDS COGN SCI, V12, P306, DOI 10.1016/j.tics.2008.05.005
   Wiech K, 2006, J NEUROSCI, V26, P11501, DOI 10.1523/JNEUROSCI.2568-06.2006
   Williams DM, 2008, PSYCHOL SPORT EXERC, V9, P231, DOI 10.1016/j.psychsport.2007.04.002
   Williams DM, 2012, ANN BEHAV MED, V44, P43, DOI 10.1007/s12160-012-9362-9
   Zenko Z, 2020, SPORT EXERC PERFORM, V9, P405, DOI 10.1037/spy0000183
   Zenko Z, 2019, FRONT PUBLIC HEALTH, V7, DOI 10.3389/fpubh.2019.00135
   Zhang J, 2013, PREV MED, V56, P75, DOI 10.1016/j.ypmed.2012.11.010
NR 82
TC 4
Z9 4
U1 2
U2 15
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1660-4601
J9 INT J ENV RES PUB HE
JI Int. J. Environ. Res. Public Health
PD OCT
PY 2019
VL 16
IS 19
AR 3739
DI 10.3390/ijerph16193739
PG 14
WC Environmental Sciences; Public, Environmental & Occupational Health
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Environmental Sciences & Ecology; Public, Environmental & Occupational
   Health
GA JK3MF
UT WOS:000494748600235
PM 31590219
OA gold, Green Published
DA 2024-01-09
ER

PT J
AU Eaton, J
   Sharma, A
   Law, D
AF Eaton, Judy
   Sharma, Avnee
   Law, Danielle
TI "I May Look Fake but I'm Real Where It Counts": Positivity and
   Authenticity in the Songs of Dolly Parton
SO PSYCHOLOGY OF AESTHETICS CREATIVITY AND THE ARTS
LA English
DT Article; Early Access
DE positivity; lyrics; linguistic analysis; self-transcendent emotions;
   authenticity
ID EMOTIONAL RESPONSES; LANGUAGE USE; MUSIC; BEHAVIOR; LYRICS; WORDS; SELF;
   US
AB Research has shown that the emotional tone of music lyrics across genres has become less positive over time. Case studies of some individual artists, such as The Beatles and Bob Dylan, have revealed more nuanced findings about how an artist's catalogue might reflect their public persona. Thus far, however, these case studies have focused exclusively on male singer-songwriters. Dolly Parton is well known for both her extensive song catalogue and her public persona of positivity. Given Parton's enduring appeal as both an authentic and positive voice in the music industry, we predicted that her lyrics would be similarly authentic and positive and reflect general themes in positive psychology. Using linguistic analysis software, our analysis showed that, compared to the yearly top 10 songs on Billboard's Hot Country and Pop charts, Parton's lyrics contain a higher percentage of markers of positivity and elevation and that, unlike both country and pop songs, which have significantly decreased in positivity, her use of positive linguistic markers has remained consistent for the past 50 years. These factors are aligned with well-being and social connectedness, and we suggest that they have a unifying power that might help explain her popularity in the current sociocultural environment.
C1 [Eaton, Judy; Sharma, Avnee; Law, Danielle] Wilfrid Laurier Univ, Dept Psychol, Waterloo, ON, Canada.
C3 Wilfrid Laurier University
RP Eaton, J (corresponding author), Wilfrid Laurier Univ, Dept Psychol, Fac Human & Social Sci, 20 Charlotte St, Brantford, ON N3T 2W2, Canada.
EM jeaton@wlu.ca
OI Eaton, Judy/0000-0003-2080-4260
FU Social Sciences and Humanities Research Council
FX We gratefully acknowledge the assistance of Lauren Annandale, Samy
   Masaal, and Gillian Sherman in assembling and checking the lyrics. This
   research was supported in part by funding from the Social Sciences and
   Humanities Research Council. No potential conflict of interest is
   reported by the authors. The data that support the findings of this
   study are available from the corresponding author upon reasonable
   request.
CR Abumrad J., 2019, NPR
   Anglada-Tort M, 2021, PSYCHOL MUSIC, V49, P426, DOI 10.1177/0305735619871602
   [Anonymous], 2007, RES SOCIAL SCI STUDY, DOI [10.1163/ej.9789004158511.i-301, DOI 10.1163/EJ.9789004158511.I-301]
   Bailey E, 2015, J BROADCAST ELECTRON, V59, P603, DOI 10.1080/08838151.2015.1093484
   Bailey J., 2017, DOLLY DOLLY INTERVIE, P46
   Barradas GT, 2022, PSYCHOL MUSIC, V50, P650, DOI 10.1177/03057356211013390
   Blais-Rochette C, 2022, PSYCHOL AESTHET CREA, V16, P370, DOI 10.1037/aca0000347
   Boyd RL., 2022, The development and psychometric properties of LIWC-22, DOI DOI 10.13140/RG.2.2.23890.43205
   Brand CO, 2019, EVOL HUM SCI, V1, DOI 10.1017/ehs.2019.11
   Czechowski K, 2016, PSYCHOL AESTHET CREA, V10, P99, DOI 10.1037/aca0000045
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   DeWall CN, 2011, PSYCHOL AESTHET CREA, V5, P200, DOI 10.1037/a0023195
   Eastman JT, 2015, PSYCHOL POP MEDIA CU, V4, P155, DOI 10.1037/ppm0000019
   Ebert R., 1980, COMMUNICATION 1207
   Edwards L., 2018, DOLLY PARTON GENDER
   Everett W, 1999, BEATLES MUSICIANS
   Freeman H, 2011, THE GUARDIAN 0821
   Greitemeyer T, 2009, PERS SOC PSYCHOL B, V35, P1500, DOI 10.1177/0146167209341648
   Haidt J, 2009, P NATL ACAD SCI USA, V106, P7687, DOI 10.1073/pnas.0903076106
   Hamessley L., 2020, UNLIKELY ANGEL SONGS, DOI [10.5406/j.ctv17nmzvm, DOI 10.5406/J.CTV17NMZVM]
   Happiness Hall of Fame, 2021, HAPP SPEECH
   Holmes T.A, 2013, WALKING LINE COUNTRY
   Hoppe G, 2017, SOUTH CULT, V23, P49, DOI 10.1353/scu.2017.0004
   Jackson LA, 2020, NEW ENGL J MED, V383, P1920, DOI 10.1056/NEJMoa2022483
   Ji QH, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0239050
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Kahn AS, 2021, HUM COMMUN RES, V47, P387, DOI 10.1093/hcr/hqab007
   Kalichman SC, 2023, PSYCHOL AESTHET CREA, V17, P581, DOI 10.1037/aca0000402
   Kernis MH, 2006, ADV EXP SOC PSYCHOL, V38, P283, DOI 10.1016/S0065-2601(06)38006-9
   Kwon L, 2021, JMIR PEDIATR PARENT, V4, DOI 10.2196/26475
   Lewis GH, 1997, J POP CULT, V31, P163, DOI 10.1111/j.0022-3840.1997.3103_163.x
   Library of Congress, 2021, DOLL PART ROOTS COUN
   Lundqvist LO, 2009, PSYCHOL MUSIC, V37, P61, DOI 10.1177/0305735607086048
   Newman ML, 2003, PERS SOC PSYCHOL B, V29, P665, DOI 10.1177/0146167203029005010
   North AC, 2004, ENVIRON BEHAV, V36, P266, DOI 10.1177/0013916503256263
   North AC, 2020, PSYCHOL MUSIC, V48, P846, DOI 10.1177/0305735619830185
   Oliver MB, 2012, HUM COMMUN RES, V38, DOI 10.1111/j.1468-2958.2012.01427.x
   Parton D., 2004, GUIDEPOSTS
   Parton D., 1973, MY TENNESSEE MOUNTAI
   Parton D, 2021, DOLLYS BIRTHDAY WISH
   Parton D., 2008, BACKWOODS BARBIE
   Parton D, 2020, CHRONICLE
   Pennebaker, 2022, LINGUISTIC INQUIRY W
   Pennebaker JW, 2003, ANNU REV PSYCHOL, V54, P547, DOI 10.1146/annurev.psych.54.101601.145041
   Pennebaker JW, 1999, J PERS SOC PSYCHOL, V77, P1296, DOI 10.1037/0022-3514.77.6.1296
   Peterson, 2013, CREATING COUNTRY MUS
   Petrie K. J., 2008, PSYCHOL AESTHET CREA, V2, P197, DOI DOI 10.1037/A0013117
   Pettijohn TF, 2009, J LANG SOC PSYCHOL, V28, P297, DOI 10.1177/0261927X09335259
   Qiu L, 2021, PSYCHOL POP MEDIA, V10, P256, DOI 10.1037/ppm0000282
   Raney AA, 2018, MASS COMMUN SOC, V21, P296, DOI 10.1080/15205436.2017.1413195
   Rentfrow PJ, 2011, J PERS SOC PSYCHOL, V100, P1139, DOI 10.1037/a0022406
   Rogers J.N., 1989, COUNTRY MUSIC MESSAG
   Scofield R, 2016, J POP CULT, V49, P660, DOI 10.1111/jpcu.12420
   Smarsh S., 2020, SHE COME IT NATURAL
   Stellar JE, 2017, EMOT REV, V9, P200, DOI 10.1177/1754073916684557
   Twenge Jean M., 2019, WORLD HAPPINESS REPO
   Valdesolo F., 2021, WALL STR J
   Yang XY, 2018, MULTIMEDIA SYST, V24, P365, DOI 10.1007/s00530-017-0559-4
   Zoladz Lindsay, 2019, New York Times
NR 59
TC 0
Z9 0
U1 3
U2 6
PU EDUCATIONAL PUBLISHING FOUNDATION-AMERICAN PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST, NE, WASHINGTON, DC 20002-4242 USA
SN 1931-3896
EI 1931-390X
J9 PSYCHOL AESTHET CREA
JI Psychol. Aesthet. Creat. Arts.
PD 2022 SEP 29
PY 2022
DI 10.1037/aca0000527
EA SEP 2022
PG 14
WC Humanities, Multidisciplinary; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Arts & Humanities - Other Topics; Psychology
GA 4X6AR
UT WOS:000860922900001
DA 2024-01-09
ER

PT J
AU Hwang, YJ
   Zur, D
AF Hwang, Yoon Joo
   Zur, Dafna
TI When Songs Don't Work: Western Tonalities and Korean Breath in
   Children's Songs of the Colonial Period
SO KOREAN STUDIES
LA English
DT Article
DE Tongyo; sung poems; Korean songs; children's poetry; children's music;
   colonial period; Western music; Chong Sunchol; Yun Kugyong
ID MUSIC
AB In the 1920s, colonial Korean children had different opportunities and materials to sing. Newly established missionary schools adapted hymns for children, and the colonial schools run by the Japanese regime considered song time to be essential to children's emotional and intellectual development. It is from this diverse ecology of musical offerings that original Korean sung poems, or tongyo, emerged. Tongyo were short poems written by often prominent writers that were then set to music by Korean composers, many of whom studied Western music in Japan. Tongyo composers wrote works that, unlike Christian hymns (ch'ansongga) and Japanese school songs (changga), were written in the Korean language and were intended for Korean voices but were structured by what was then novel Western musical conventions. Through an analysis of tongyo by two seminal figures, Yun Ku. gyo.ng and Cho.ng Sunch'o.l, this paper illuminates the musical grammar by which Yun and Cho.ng re-oriented the sensibilities of their young singers. This comparison reveals the challenges of fitting western tonalities to the Korean language, thereby questioning the prevalent assumption that tongyo were national forms whose value hinges on their effortless communication of authentic Korea emotions.
C1 [Hwang, Yoon Joo] Univ Cent Florida, Mus Bassoon, Orlando, FL 32816 USA.
   [Zur, Dafna] Stanford Univ, Korean Literature & Culture, Stanford, CA 94305 USA.
C3 State University System of Florida; University of Central Florida;
   Stanford University
RP Hwang, YJ (corresponding author), Univ Cent Florida, Mus Bassoon, Orlando, FL 32816 USA.
EM Yoon.Hwang@ucf.edu; dafnaz@stanford.edu
CR [Anonymous], 2008, MUSIC EDUCATORS J, DOI DOI 10.1177/0027432108321189
   [Anonymous], 1925, TONGA ILBO 0121
   Brandt A, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00327
   Ch'an Min-kyong, 2005, NANGMAN UMAK, V69, P99
   Ch6ng Sunch6l, 1933, ORINI, V11, P20
   Ch6ng Sunch6l, 1924, SINYOSONG, V6, P52
   Chang HKH, 2020, J KOREAN STUD, V25, P291, DOI 10.1215/07311613-8551992
   Chang HKH, 2018, ETHNOMUSICOL FORUM, V27, P157, DOI 10.1080/17411912.2018.1506941
   Chong Insop, 1975, SAEKTONGHOE ARINI UN
   Chong Sunchol, 1923, AUTOPHAGY, P6
   Creighton A.L., 2013, AUSTR J MUSIC THER, V24, P17, DOI DOI 10.3316/INFORMIT.878211756890697
   Dissanayake E, 2000, ORIGINS OF MUSIC, P389
   Goetze M., 2000, MUSIC EDUC J, V87, P23, DOI [10.2307/3399673, DOI 10.2307/3399673]
   Hall A, 2020, J KOREAN STUD, V25, P115, DOI 10.1215/07311613-7932272
   Hallam S, 2010, INT J MUSIC EDUC, V28, P269, DOI 10.1177/0255761410370658
   Hannon EE, 2007, TRENDS COGN SCI, V11, P466, DOI 10.1016/j.tics.2007.08.008
   Ilari B, 2013, INT J MUSIC EDUC, V31, P202, DOI 10.1177/0255761413487281
   Kim Chonghu, 2020, EUR RESPIR J, V56, P117
   Manabe Noriko, 2012, OXFORD HDB CHILDRENS, DOI [10.1093/oxfordhb/9780199737635.013.0006, DOI 10.1093/OXFORDHB/9780199737635.013.0006]
   Manabe Noriko, 2009, THESIS CITY U NEW YO
   McGary Grace Harmon, 1915, KOREA MISSION FIELD, V11, P103
   Mithen S, 2006, CAMB ARCHAEOL J, V16, P97, DOI 10.1017/S0959774306000060
   Miyashita K, 2012, AM MUSIC, V30, P308, DOI 10.5406/americanmusic.30.3.0308
   Pak Kilsu, 2020, AUTOPHAGY, V4, P97
   Pak Kyongju, 2014, THESIS HANGUK YESUL
   Pak Minyong, 2015, URI OMUN YONGU, V53, P49
   Pieper D, 2019, J KOREAN STUD, V24, P63, DOI 10.1215/21581665-7258055
   Pieters Alex A., 1915, KOREA MISSION FIELD, V11, P113
   Ryu Chiyong, 1925, CA-CANCER J CLIN, P25
   Savage PE, 2021, BEHAV BRAIN SCI, V44, DOI 10.1017/S0140525X20000333
   Soley G, 2016, COGNITION, V148, P106, DOI 10.1016/j.cognition.2015.09.017
   STOKES Martin, 1994, ETHNICITY IDENTITY M, P1
   To Chonghwan, 2011, CHONG SUNCHOL PYONGJ
   Turino T., 2008, MUSIC SOCIAL LIFE PO
   Van Buskirk J.D., 1915, KOREA MISSION FIELD, V11, P100
   Wachs Sylvia Allen, 1915, PHYS REV LETT, V11, P102
   Won Chongchan, 2015, CHANGBI ORINI, V13, P152
   Woods David G., 1987, MUSIC EDUCATORS J, V74, P35, DOI DOI 10.2307/3397939
   Yun Ku.gyong, 2000, YUN KUG YONG CHONJIP
   Yun Yonghae, 2018, HANGUK UMAK YONGU, V63, P269
   Zur Dafna, 2017, Figuring Korean Futures: Children's Literature in Modern Korea
NR 41
TC 0
Z9 0
U1 1
U2 1
PU UNIV HAWAII PRESS
PI HONOLULU
PA 2840 KOLOWALU ST, HONOLULU, HI 96822, UNITED STATES
SN 0145-840X
EI 1529-1529
J9 KOREAN STUD
JI Korean Stud.
PY 2022
VL 46
BP 8
EP 42
DI 10.1353/ks.2022.0002
PG 35
WC Asian Studies
WE Emerging Sources Citation Index (ESCI)
SC Asian Studies
GA 8X4YA
UT WOS:000932018400003
DA 2024-01-09
ER

PT J
AU Frigyesi, J
AF Frigyesi, Judit
TI Gestures of the Soul The Prayer Chant of the East-European Jews
SO STUDIA MUSICOLOGICA
LA English
DT Article
DE prayer chant; East-European Jews; davenen; lernen
AB The basic style of East-European Jewish (East-Ashkenazic) prayer chant (davenen), even when it might seem to be simple on paper, in transcription, has a complex and unique system of micro-structure. This micro-structure, which is evident in subtleties of rhythm and melody, voice quality, form, techniques of variation and ornamentation, is inventive and daring, and creates a compelling aesthetic and spiritual effect in the auditory experience. The present article discusses the question of how this creative compositional practice might have evolved. The article claims that the uniqueness of davenen results from the fact that children begin learning this "art" at a very early age, before they are able to speak and conceptualize the phenomena of the surrounding world. With davenen, a spontaneously felt language before language is learnt: a language in which words and melodies, rhythms and musical gestures and effects, emotions and fantasies and associations are merged into one whole. As a result, in the realization of prayer chant, even in the case of professional prayer leaders, originality and tradition, copying and fantasy occur together in a continual fusion of memory and forgetfulness. This article discusses Eastern European Jewish prayer chant and its learning process on the basis of its author's decades of fieldwork and of literature and memoirs from before WWII.
C1 [Frigyesi, Judit] Bar Ilan Univ, Fac Humanities, Dept Mus, IL-52900 Ramat Gan, Israel.
C3 Bar Ilan University
RP Frigyesi, J (corresponding author), Bar Ilan Univ, Fac Humanities, Dept Mus, IL-52900 Ramat Gan, Israel.
EM jfrigyesi96@gmail.com
CR AGNON S. Y., 1967, BRIDAL CANOPY, P211
   [Anonymous], 2014, JEL VIZ
   [Anonymous], 1994, COP COP INT INT S
   [Anonymous], 1927, KOZEPSO KAPU KIS GYE
   [Anonymous], 2017, PEOPLE BOOK DRAMA FE
   [Anonymous], 1976, SYNAGOGUE LIFE STUDY
   CAHAN Abraham, 1993, RISE D LEVINSKY, P35
   FELDMAN Morton, 2000, GIVE MY REGARDS 8 ST, P2
   Frigyesi Judit, 2008, YIVO ENCY JEWS E EUR, P1222
   Frigyesi Judit, 2005, STUDIES SOURCES INTE, P7
   FRIGYESI NIRAN, 2018, WRITING WATER SOUNDS
   HAMEIRI Avigdor, 2006, DALOLO MAGLYA ADY BI, P29
   JOFFE Judah A., 1959, P AM ACAD JEWISH RES, V28, P77
   MANGER Itzig, 1939, VUNDERLEKHE LEBENSBA
   MUNK Avraham, 2002, ELETEM TORTENETEI, P51
   Musica Nova, 1976, MUSICA NOVA 3 FESTIV
   OLAH Janos, 2018, S ALFRED HETVEN EVES, P113
   Paul Carl MENDELSSOHN, 1863, LETT FM BARTHOLDY 18, P298
   SEROUSSI Edwin, 2018, 4 MELODIES 4 QUESTIO
   SOLOVEITCHIK H, 1994, TRADITION, V28, P64
   UFFENHEIMER Rifka Schatz, 1993, HASIDISM MYSTICISM Q, P238
   WURBS Janina, 2016, YIDD MUS HIST UNPUB
NR 22
TC 1
Z9 1
U1 0
U2 0
PU AKADEMIAI KIADO ZRT
PI BUDAPEST
PA BUDAFOKI UT 187-189-A-3, H-1117 BUDAPEST, HUNGARY
SN 1788-6244
EI 1789-2422
J9 STUD MUSICOL
JI Stud. Musicol.
PD DEC
PY 2019
VL 60
IS 1-4
BP 327
EP 347
DI 10.1556/6.2019.00016
PG 21
WC Music
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music
GA VK0FQ
UT WOS:000652198300016
OA Green Accepted
DA 2024-01-09
ER

PT J
AU Dingle, GA
   Brander, C
   Ballantyne, J
   Baker, FA
AF Dingle, Genevieve A.
   Brander, Christopher
   Ballantyne, Julie
   Baker, Felicity A.
TI 'To be heard': The social and mental health benefits of choir singing
   for disadvantaged adults
SO PSYCHOLOGY OF MUSIC
LA English
DT Article
DE choir singing; disability; mental health; social inclusion; wellbeing
ID GROUP MEMBERSHIPS; IMMUNOGLOBULIN-A; IDENTITY; MUSIC; PREDICTORS;
   OUTCOMES; DIVIDE; LIFE
AB Compared with other members of the general population, adults living with a chronic mental illness or disability tend to participate less frequently in occupational and social interactions. This may exacerbate problems such as emotional flattening and social isolation. Supported activities like choir singing present an opportunity for meaningful activity and social connectedness for these individuals. The aim of this study was to explore the personal experiences of choir members (89% of whom experienced chronic mental health problems, 28% physical disabilities and 11% intellectual disability) in relation to their wellbeing using interpretative phenomenological analysis (IPA). Semi-structured interviews were carried out with 21 members of the choir at three time points in the choir's inaugural year: at the inception of the choir, after six months, and after 12 months. Three content themes emerged: (1) personal impact (positive emotions, emotional regulation, spiritual experience, self-perception, finding a voice); (2) social impact (connectedness within the choir, connection with audience, social functioning); and (3) functional outcomes (health benefits, employment capacity, and routine). A fourth theme of time was also apparent in the data. Results of this study were consistent with the social identity theory notion that forming a new and valued group identity (as a choir member) was associated with emotional and health benefits for the participants.
C1 [Dingle, Genevieve A.; Brander, Christopher] Univ Queensland, Sch Psychol, St Lucia, Qld 4072, Australia.
   [Ballantyne, Julie; Baker, Felicity A.] Univ Queensland, Sch Mus, St Lucia, Qld 4072, Australia.
C3 University of Queensland; University of Queensland
RP Dingle, GA (corresponding author), Univ Queensland, Sch Psychol, St Lucia, Qld 4072, Australia.
EM dingle@psy.uq.edu.au
RI Ballantyne, Julie/AAT-9610-2021; Baker, Felicity/HZI-0263-2023
OI Ballantyne, Julie/0000-0003-1818-2220
CR [Anonymous], 2005, SCHIZOPHRENIA BULL, V31, P793, DOI 10.1093/schbul/sbi065
   [Anonymous], 2010, DEVELOPING DELIVERIN
   [Anonymous], 2005, Psychology of Music, DOI DOI 10.1177/0305735605053734
   [Anonymous], 2010, HDB MUSIC EMOTION
   [Anonymous], 2006, Families, Systems, Health, DOI DOI 10.1037/1091-7527.24.1.3
   [Anonymous], 1999, QUALITATIVE HLTH PSY
   Ansdell G., 2010, MUSIC MED, V2, P29, DOI [DOI 10.1177/1943862109352482, 10.1177/1943862109352482]
   Australian Bureau of Statistics, 2004, 44300 ABS
   Bailey BA, 2002, MUSIC SCI, V6, P221, DOI 10.1177/102986490200600206
   BAILEY BA, 2003, NORD J MUSIC THER, V12, P18, DOI [DOI 10.1080/08098130309478070, 10.1080/08098130309478070]
   Bailis DS, 2008, SOC SCI MED, V66, P1817, DOI 10.1016/j.socscimed.2007.12.028
   Beck RJ, 2000, MUSIC PERCEPT, V18, P87
   Boden-Albala B, 2005, NEUROLOGY, V64, P1888, DOI 10.1212/01.WNL.0000163510.79351.AF
   BORDIEU P, 1979, DISTINCTION CRITIQUE
   Buchanan RW, 2010, SCHIZOPHRENIA BULL, V36, P71, DOI 10.1093/schbul/sbp116
   Clift S., 2010, Journal of Applied Arts and Health, V1, P19, DOI DOI 10.1386/JAAH.1.1.19/1
   Clift SM, 2001, J R SOC PROMO HEALTH, V121, P248, DOI 10.1177/146642400112100409
   Dingle G., 2010, PARITY, V23, P51
   Grape C, 2003, INTEGR PHYS BEH SCI, V38, P65
   Grocke D, 2009, J MUSIC THER, V46, P90, DOI 10.1093/jmt/46.2.90
   Haslam C, 2008, NEUROPSYCHOL REHABIL, V18, P671, DOI 10.1080/09602010701643449
   Haslam SA, 2009, APPL PSYCHOL-INT REV, V58, P1, DOI 10.1111/j.1464-0597.2008.00379.x
   Hunter PG, 2010, SPRINGER HANDB AUDIT, V36, P129, DOI 10.1007/978-1-4419-6114-3_5
   Hyyppa MT, 2010, HLTH TIES SOCIAL CAP
   Iyer A, 2009, BRIT J SOC PSYCHOL, V48, P707, DOI 10.1348/014466608X397628
   Kim S, 2009, SOC INDIC RES, V93, P295, DOI 10.1007/s11205-008-9318-4
   Kreutz G, 2004, J BEHAV MED, V27, P623, DOI 10.1007/s10865-004-0006-9
   Laiho S., 2004, NORD J MUSIC THER, V13, P47, DOI DOI 10.1080/08098130409478097
   Leitman DI, 2010, SCHIZOPHRENIA BULL, V36, P545, DOI 10.1093/schbul/sbn115
   Osuch EA, 2009, NEUROREPORT, V20, P1204, DOI 10.1097/WNR.0b013e32832f4da3
   SANE Australia, 2010, SANE RES B, V12
   Seltzer MM, 1997, FAM RELAT, V46, P13, DOI 10.2307/585602
   Shibusawa T, 2009, J AGING STUD, V23, P188, DOI 10.1016/j.jaging.2007.12.019
   Smith J. A., 2009, INTERPRETIVE PHENOME
   Smith JA, 1996, PSYCHOL HEALTH, V11, P261, DOI 10.1080/08870449608400256
   Tajfel H., 1986, PSYCHOL INTERGROUP R, P7, DOI DOI 10.4324/9780203505984-16
   Tarrant M., 2000, Psychology of Music and Music Education, V28, P166, DOI 10.1177/0305735600282005
   Valentine E, 2001, BRIT J MED PSYCHOL, V74, P115, DOI 10.1348/000711201160849
   Wilkinson AV, 2007, BMC PUBLIC HEALTH, V7, DOI 10.1186/1471-2458-7-226
   Windsor J., 2005, YOUR HLTH ARTS STUDY
   Woods A, 2008, CAN J PSYCHIAT, V53, P725, DOI 10.1177/070674370805301104
NR 41
TC 132
Z9 155
U1 2
U2 51
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0305-7356
EI 1741-3087
J9 PSYCHOL MUSIC
JI Psychol. Music
PD JUL
PY 2013
VL 41
IS 4
BP 405
EP 421
DI 10.1177/0305735611430081
PG 17
WC Psychology, Educational; Psychology, Applied; Music; Psychology,
   Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Psychology; Music
GA AI0DZ
UT WOS:000336517700001
DA 2024-01-09
ER

PT J
AU Amerius-Sargeant, N
AF Amerius-Sargeant, Nickie
TI Music Archetypal Sounds of Life, Healing, and Transformation
SO JUNG JOURNAL-CULTURE & PSYCHE
LA English
DT Article
DE animals; archetypes; auditory processing; autism; ears; fetus; healing;
   health; hearing; listening; music; neuroscience; oxytocin; plants;
   prosody; social engagement; sound; sympathetic and parasympathetic
   nervous systems; threat systems; vagus nerve; vibration; voice; womb
AB From the very beginning there was sound, be it bang, Om, or Logos. Research reveals that plants as well as animals use sound to communicate. We live in a world of sound, be it from earth or sky, tides or storms, katydids or chickens. It informs us that a car or train is near or that a gardener or carpenter is at work. It lets us know if we are in danger, gives us means to express our emotions and values, and expresses our fantasies, visions, and images. Sound is the stuff of attachment and we learn to listen even before we are born. It touches us in our core, links us to one another in heart and body, and can help us heal. Sound and music are intimate conduits to the collective unconscious and carriers of archetypal motifs. For patients, music can birth new, previously unimaginable beginnings. Listening or playing an instrument can be healing and transformative. In an instant music can awaken our spirits, get us moving, bring on tears, take us to a holy place, or lull us to sleep. From the first cry of the newborn to the last breath and beat of a heart, we are enveloped in the rich gift of sound.
C1 [Amerius-Sargeant, Nickie] CG Jung Inst San Francisco, San Francisco, CA 94110 USA.
RP Amerius-Sargeant, N (corresponding author), CG Jung Inst San Francisco, San Francisco, CA 94110 USA.
EM namersarg@gmail.com
CR Campbell Don., 1997, The Mozart Effect: Tapping the Power of Music to Heal the Body, Strengthen the Mind, and Unlock the Creative Spirit
   Chanda ML, 2013, TRENDS COGN SCI, V17, P179, DOI 10.1016/j.tics.2013.02.007
   Codrons E, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0107538
   DECASPER AJ, 1980, SCIENCE, V208, P1174, DOI 10.1126/science.7375928
   Devere Ronald., 2017, Practical Neurology
   Digitale Erin., 2016, Stanford Medicine News
   Doidge Norman., 2016, The Brain's Way of Healing
   goodnewsnetwork, 2023, Good News., Network
   Habib Michael B., 2021, Scientific American
   Haig Matt., 2018, How to Stop Time: A Novel
   Jung C. G., 1978, The Therapy of Music." In C. G. Jung Speaking
   Jung C. G., 1934, The Structure and Dynamics of the Psyche. CW, P8
   Jung C. G., 1989, Memories, Dreams, Reflections
   Jung C. G., 1973, C. G. Jung Letters, Vol. 1
   LittleJohn Val., Ech
   Novotny Amy., 2013, Monitor on Psychology, V44
   Piontelli Alessandra., 1992, From Fetus to Child: An Observational and Psychoanalytic Study
   Puett Michael, 2016, PATH WHAT CHINESE PH
   Sacks O., 2007, Tales of Music and the Brain
   Tomatis Alfred., 1992, The Conscious Ear: My Life of Transformation Through Listening
   Verny Thomas., 1982, The Secret Life of the Unborn Child
NR 21
TC 0
Z9 0
U1 0
U2 0
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1934-2039
EI 1934-2047
J9 JUNG J-CULT PSYCHE
JI Jung J.-Cult. Psyche
PD OCT 2
PY 2023
VL 17
IS 4
BP 3
EP 18
DI 10.1080/19342039.2023.2258751
PG 16
WC Humanities, Multidisciplinary
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Arts & Humanities - Other Topics
GA Z5RQ6
UT WOS:001112648800001
DA 2024-01-09
ER

PT J
AU Milburn, K
AF Milburn, Kevin
TI <i>'Standing still horizontal ellipsis in a moving place'</i> -
   reassessing lyrics and the spaces they construct through the musical
   landscapes of The Blue Nile
SO SOCIAL & CULTURAL GEOGRAPHY
LA English
DT Article; Early Access
DE The Blue Nile; music; movement; stillness; lyrics; music geography
ID CITY; MEMORY; ART
AB This paper calls for a recalibration of how cultural geography engages with music, lyrics, motion, and emotion. Within existing geographical work on music, research on the music itself remains scarce, with reflection on lyrics rarer still. This paper addresses this via a close reading of the work of the Glaswegian group, The Blue Nile. It examines how the trio - and especially their principal songwriter, Paul Buchanan - used lyrics as a means for articulating distinctive conceptions of movement and stillness. The significance of song-words themselves is considered, but so too is their mode of delivery, and their relationship to the enveloping musical settings they are embedded in. The importance of time, space and place in The Blue Nile's work is analysed and the methods by which they are evoked is investigated. The paper moves discussion on from well-covered terrain regarding music as a conduit for expressing youth focussed tropes, such as rebellion and speed, focusing instead on music's facility for voicing ideas of slowness and immobility, particularly in urban settings. In doing so, it demonstrates popular music's value for articulating sensations that are now being encountered with ever greater frequency, including those of stasis, drift, and disconnection.
C1 [Milburn, Kevin] London South Bank Univ, Dept Social Sci, London, England.
C3 London South Bank University
RP Milburn, K (corresponding author), London South Bank Univ, Dept Social Sci, London, England.
EM milburnk@lsbu.ac.uk
FU School of Geography at the University of Nottingham with the support of
   an ESRC Quota Studentship Award [ES/G017417/1]
FX This article relates to my doctoral research, which was undertaken in
   the School of Geography at the University of Nottingham with the support
   of an ESRC Quota Studentship Award - ES/G017417/1.
CR [Anonymous], 2002, GEOGRAFISKKA ANNALER
   [Anonymous], 1985, GEOGRAPHY MEDIA POPU
   [Anonymous], 2007, Bring the Noise: 20 Years of Writing About Hip Rock and Hip Hop
   [Anonymous], 2014, THE ACOUSTIC CITY
   [Anonymous], 2002, ENGAGING FILM GEOGRA
   Armitage S., WORD YOUR EAR
   Ballico C., 2020, MUSIC CITIES EVALUAT
   Brandellero A, 2015, ENVIRON PLANN A, V47, P1574, DOI 10.1177/0308518X15595781
   Brown A., 2010, NILEISM STRANGE COUR
   Butler A., 1994, INFECT IMMUN
   Carlin M., 2011, BLUE AIR
   Crang M., 2001, TimeSpace: Geographies of Temporality, P187, DOI DOI 10.4324/9780203360675
   Cresswell T., 2006, On the move: Mobility in the modern western world
   Dalton S., 2008, TIMES 0711
   Daniels S, 2006, CULT GEOGR, V13, P28, DOI 10.1191/1474474005eu349oa
   DeSilvey C, 2007, J HIST GEOGR, V33, P878, DOI 10.1016/j.jhg.2006.10.020
   Frisby D., 2013, Fragments of Modernity: Theories of Modernity in the Work of Simmel, Kracauer and Benjamin
   Fulford-Jones W., 2008, 1000 SONGS CHANGE YO, P117
   Gilloch G., 1996, MYTH METROPOLIS W BE
   Gold Jr, 1998, MAPPINGS, P249
   Gunderman HC, 2017, J CULT GEOGR, V34, P373, DOI 10.1080/08873631.2016.1264073
   HAGERSTRAND T, 1982, TIJDSCHR ECON SOC GE, V73, P323, DOI 10.1111/j.1467-9663.1982.tb01647.x
   Harvey D., 1989, The Condition of Postmodernity: An Enquiry into the Origins of Cultural Change
   Hetherington K, 2013, SOCIOL REV, V61, P17, DOI 10.1111/1467-954X.12051
   Horton J, 2019, SOC CULT GEOGR, V20, P265, DOI 10.1080/14649365.2018.1559346
   Hracs BJ, 2020, J CONSUM CULT, V20, P478, DOI 10.1177/1469540517745703
   Hubbard P, 2004, ENVIRON PLANN D, V22, P273, DOI 10.1068/d338t
   Irvin J., 1996, MOJO, P40
   Johansson O, 2013, FENNIA, V191, P40, DOI 10.11143/7337
   Jonze T., GUARDIAN 0313
   Kerr J., 2008, BLUE NILE 0712
   Kruse RJ, 2005, J CULT GEOGR, V22, P87, DOI 10.1080/08873630509478240
   Lefebvre H., 2013, Rhythmanalysis: Space, time and everyday life
   Leyshon A., 1998, PLACE MUSIC, P1
   Leyshon Andrew, 2014, Reformatted: Code, Networks, and the Transformation of the Music Industry
   Liu C, 2014, SOC CULT GEOGR, V15, P769, DOI 10.1080/14649365.2014.924156
   Maclaverty R., 2008, CALEDONIA DREAMIN
   Maconie S., 1996, Q JUL, P116
   Marcus Greil, 1989, Lipstick Traces: A Secret History of the Twentieth Century
   May Jon, 2001, TIMESPACE GEOGRAPHIE
   McFarlane C, 2011, ENVIRON PLANN D, V29, P649, DOI 10.1068/d4710
   Milburn K, 2019, SOC CULT GEOGR, V20, P730, DOI 10.1080/14649365.2017.1375550
   Moss, 1992, GEOGR ANN B, V74B, P167, DOI DOI 10.2307/490860
   Moss P, 2011, CULT GEOGR, V18, P343, DOI 10.1177/1474474011410276
   Quantick D., 1989, NME 1007, P40
   Radcliffe M., 1990, BLUE NILE
   Revill G, 2004, CULT GEOGR, V11, P199, DOI 10.1191/14744744004eu302xx
   Rhodes M. A. II, 2021, Journal of Cultural Geography, V38, P378, DOI 10.1080/08873631.2021.1927322
   Roberts C., 1990, GASTROENTEROL CLIN N, P44
   Roberts N., 2010, BBC
   Rose Gillian., 2012, VISUAL METHODOLOGIES
   Rose M, 2006, ENVIRON PLANN D, V24, P475, DOI 10.1068/d2404ed
   Savage M., 2000, Thinking Space, P33
   Scott D., 2018, BBC RADIO SCOTTLAND
   Smith SJ, 2000, ENVIRON PLANN D, V18, P615, DOI 10.1068/d225t
   Stanbridge N. (Reporter), 2008, EVOL DEV
   The Scotsman, 2003, SCOTSMAN
   Tweed F, 2019, AREA, V51, P126, DOI 10.1111/area.12422
   Watson A, 2015, ROUTL STUD HUM GEOGR, P1
   Williams R., 2004, GUARDIAN 0813
   Willment N, 2019, GEOGR COMPASS, V13, DOI 10.1111/gec3.12439
   Wilson E., 1991, The Sphinx in The City: Urban Life, the Control of Disorder, and Women
   Wood N, 2004, SOC CULT GEOGR, V5, P533, DOI 10.1080/1464936042000317686
   Wood N, 2007, ENVIRON PLANN D, V25, P867, DOI 10.1068/d416t
NR 64
TC 1
Z9 1
U1 3
U2 4
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1464-9365
EI 1470-1197
J9 SOC CULT GEOGR
JI Soc. Cult. Geogr.
PD 2023 MAR 23
PY 2023
DI 10.1080/14649365.2022.2157044
EA MAR 2023
PG 19
WC Geography
WE Social Science Citation Index (SSCI)
SC Geography
GA A3SK0
UT WOS:000954360600001
OA hybrid, Green Accepted
DA 2024-01-09
ER

PT J
AU Skjerseth, A
AF Skjerseth, Amy
TI Electric Ladies in Playback The Android Antecedents of Janelle Monae's
   <i>Dirty Computer</i>
SO MUSIC SOUND AND THE MOVING IMAGE
LA English
DT Article
DE Playback technology; sound/image synchronisation; music videos;
   automata; phonographs
ID AESTHETICS; GENDER
AB Playback, the process of separately recording actors' images and voices in cinema and media, has a long history of cultural stereotyping. This article analyses how performers are typecast when media technicians manipulate sound/image synchronisation in lip sync and dubbing. Inspired by Janelle Monae's oeuvre, I focus my study through the figure of the electric lady - female simulacra who are programmed by heteronormative, patriarchal operators. I trace the electric lady back to talking machines (Faber's Euphonia) and early phonograph recordings (minstrelsy and opera singer Agnes Davis) to show how proto- and post-phonographic notions of playback are bound up with racialised and gendered stereotypes. Drawing on the work of Alice Maurice, Mary Ann Doane, Jennifer Fleeger, and others, I illustrate how industrial practices of playback reproduce the sounds and images of ideal femininity and obedient Others. In her `emotion picture' Dirty Computer (2018), Monae transforms history's electric lady from obstinate object to empowered subject by unmasking homogenising operations of playback. Monae lip syncs as multiple personae to showcase the material heterogeneity of her Black, queer, and feminist identities. Ultimately, Monae's hybrid personae mobilise Doane's notion of the masquerade in their defiance of playback norms that would bind Monae to racialised and gendered images.
OI Skjerseth, Amy/0000-0002-4258-6930
CR ADORNO TW, 1990, OCTOBER, P49
   [Anonymous], 1846, PUNCH, V11, P64
   [Anonymous], 1991, VIOLET ORGAN GRINDER
   [Anonymous], 2014, Mismatched Women: The Siren's Song through the Machine
   [Anonymous], 1846, ILLUSTRATED LONDON N, P96
   [Anonymous], 1984, MAT GIRL MUSIC VIDEO
   [Anonymous], 2018, YouTube
   [Anonymous], 1997, 9 LIVES
   [Anonymous], 2010, Dreams of Difference, Songs of the Same: The Musical Moment in Film
   [Anonymous], 1927, METROPOLIS
   [Anonymous], 1986, PARADE
   [Anonymous], 1952, SINGIN RAIN
   [Anonymous], 1846, ILLUSTRATED LONDON N, V9, P59
   Armstrong Julie Buckner, 2011, M TURNER MEMORY LYNC
   Austerlitz Saul, 2007, MONEY NOTHING HIST M
   Black Astro, 1972, SUN RA
   Brooks Daphne, 2014, BLACK PERFORMANCE TH, P204
   Brooks Daphne, 2021, LINER NOTES REVOLUTI, P13
   Cavarero Adriana., 2005, For More Than One Voice: Toward a Philosophy of Vocal Expression
   Chion Michel, 2008, The Voice in Cinema
   Connor Stephen, 2000, Dumbstruck. A Cultural History of Ventriloquism
   Crawford KB, 2014, HIST TECHNOL, V30, P261, DOI 10.1080/07341512.2014.969567
   Crum William C., 1874, ILLUSTRATED HIST WIL, P73
   Cruz Gabriela, 2012, OPERA VIDEO TECHNOLO
   Diehl Matt, 2013, ROLLING STONE 0910
   DOANE MA, 1980, YALE FR STUD, P33, DOI 10.2307/2930003
   Doane Mary Anne, 1991, Femmes Fatales: Feminism, Film Theory and Psychoanalysis
   Donoho Andrew, 2018, DIRTY COMPUTER VISUA
   Edison Thomas, 1878, N AM REV MAY, V126
   Elliott Missy, 1997, RAIN SUPA DUPA FLY S
   Fanon Frantz., 2008, BLACK SKIN WHITE MAS
   Feuer Jane, 1982, HOLLYWOOD MUSICAL
   Geffen Sasha, 2018, VULTURE 0223
   Gitelman Lisa, 2006, ALWAYS ALREADY NEW M
   Gunning T, 2001, SOUNDS OF EARLY CINEMA, P13
   Hansen KA, 2019, TWENT-CENTURY MUSIC, V16, P501, DOI 10.1017/S1478572219000276
   Hansen KA, 2017, POP MUSIC SOC, V40, P164, DOI 10.1080/03007766.2015.1104906
   Haraway Donna., 1991, SIMIANS CYBORGS WOME, P149
   Hollingshead John, 1895, MY LIFETIME
   HUYSSEN A, 1981, NEW GER CRIT, P221, DOI 10.2307/488052
   James R, 2008, J POP MUSIC STUD, V20, P402, DOI 10.1111/j.1533-1598.2008.00171.x
   Jessie M., 2018, MEDIUM 0428
   Jones CL, 2018, FRONTIERS, V39, P42, DOI 10.5250/fronjwomestud.39.1.0042
   Kaempfert Waldemar, 1933, NEW YORK TIMES 0413
   Kohn Eric, 2018, INDIEWIRE
   Lastra James, 2000, Sound Technology and the American Cinema: Perception, Representation, Modernity
   Lawrence Amy, 1991, ECHO NARCISSUS WOMEN
   Lindsay David, 1997, INVENTION TECHNOLOGY, P56
   Lott Eric, 2013, LOVE THEFT BLACKFACE
   Lovato Demi, 2016, STONE COLD MUSIC VID
   Majumdar Neepa, 2001, SOUNDTRACK AVAILABLE, P161
   Maurice Alice, 2013, CINEMA ITS SHADOW RA
   MCGINN RE, 1983, TECHNOL CULT, V24, P38, DOI 10.2307/3104169
   Michael Jackson, 1983, THRILLER
   Monae J., 2010, THE ARCHANDROID
   Monae J., 2013, HELL YOU TALMBOUT EL
   Monae Janelle, 2007, METROPOLIS SUITE 1 C
   Monae Janelle, 2003, AUDITION
   Monae Janelle, 2010, COLD WAR MUSIC VIDEO
   Moore Guernsey, 1908, EDISON PHONOGRAPH MO, VVI, P24
   Morrison MD, 2019, J AM MUSIC SOC, V72, P781, DOI 10.1525/jams.2019.72.3.781
   Moten Fred, 2004, CAMB OPERA J, V16, P269
   Palmer L., 2020, ROCK STAR MOVIE STAR
   Prince The, 1984, DOVES CRY MUSIC VIDE
   Railton D, 2011, MUSIC MOV IMAG, P1, DOI 10.3366/edinburgh/9780748633227.001.0001
   Richardson John, 2013, OXFORD HDB NEW AUDIO, P466
   Rihanna, 2007, UMBRELLA
   Riskin J, 2003, REPRESENTATIONS, P96
   Royster Francesca T., 2013, SOUNDING NO NO QUEER, P186
   Said E., 1978, ORIENTALISM
   Shaviro Steven, 2005, Quarterly Review of Film and Video, V22, P169
   Silverman Kaja., 1988, The Acoustic Mirror: The Female Voice in Psychoanalysis and Cinema
   Simone Nina, 1965, PASTEL BLUES
   Smith J, 2008, VOCAL TRACKS: PERFORMANCE AND SOUND MEDIA, P1
   Spanos Brittany, 2018, ROLLING STONE
   Sterne Jonathan, 2003, The Audible Past
   Stoever Jennifer Lynn, 2016, SONIC COLOR LINE RAC
   Stokowski L, 1932, J ACOUST SOC AM, V4, P11, DOI 10.1121/1.1915582
   Straus Noel, 1937, NEW YORK TIMES 0520
   The Phonograph, 1878, CHICAGO TRIBUNE 0523
   Trainor S, 2014, EARLY AM STUD, V12, P548, DOI 10.1353/eam.2014.0019
   Vernallis C, 2019, J SOC AM MUSIC, V13, P250, DOI 10.1017/S1752196319000154
   Vernallis C, 2017, FILM CRITICISM, V41, DOI 10.3998/fc.13761232.0041.105
   Vernallis Carol, 2004, Experiencing Music Video: Aesthetics and Cultural Context
   Vest J. Martin, 2018, SOUNDING OUT
   Weheliye Alexander G., 2002, Social Text, V20, pS. 21, DOI DOI 10.1215/01642472-20-2_71-21
   Weheliye Alexander G., 2005, Phonographies: Grooves in Sonic Afro
   Westrup Laurel, 2016, PROJECTOR J FILM MED, V16, P19
   Wortham Jenna, 2018, NEW YORK TIMES MAGAZ
   2017, FANTASTIC WOMAN
NR 90
TC 0
Z9 0
U1 1
U2 1
PU LIVERPOOL UNIV PRESS
PI LIVERPOOL
PA 4 CAMBRIDGE ST, LIVERPOOL L69 7ZU, ENGLAND
SN 1753-0768
EI 1753-0776
J9 MUSIC SOUND MOV IMAG
JI Music Sound Mov. Image
PY 2022
VL 16
IS 1
BP 1
EP 27
DI 10.3828/msmi.2022.1
PG 27
WC Film, Radio, Television
WE Emerging Sources Citation Index (ESCI)
SC Film, Radio & Television
GA 3C0KG
UT WOS:000828320700001
DA 2024-01-09
ER

PT J
AU Bell, J
   Bell, P
AF Bell, John
   Bell, Paul
TI And this is what we sing - <i>what</i> do we sing? Exploring the
   football fan songs of the Northern Irish 'Green and White Army'
SO INTERNATIONAL REVIEW FOR THE SOCIOLOGY OF SPORT
LA English
DT Article
DE football fans; Green and White Army; Northern Ireland; sectarianism;
   singing
ID BEHAVIOR
AB This paper draws upon digital recordings of Northern Ireland football fans singing in the stadium during all 10 qualifying matches for the 2016 UEFA European Football Championship. Supplemented by participant observation and interview data with 21 supporters themselves, the paper challenges assertions within the literature which focus upon the predominance of sectarian singing amongst a section of Northern Ireland football supporters. Although vocal manifestations of football fandom may initially appear to be randomly driven by irrational emotions, on the contrary, there is an underlying structure and sequence to fandom in the stadium in which certain factors promote collective singing at particular times. The paper identifies four key themes in particular: the timing in a match; whether or not a goal has been scored; if there is a lull or a break in play; and the use of musical instruments to encourage the wider collective to sing. We argue that it is important to understand the process by which collective singing occurs in the football stadium rather than fixating upon the alleged racist or sectarian psychopathology of the individuals involved. Such knowledge may assist in supporting those fan organisations that seek to challenge discriminatory behaviour in the stadium, particularly in the current context of the European (UEFA) and World football governing bodies (FIFA) punishing fans collectively, regardless of whether or not the majority in the stadium are opposed to what is being sung in their name.
C1 [Bell, John] Ulster Univ, Sch Appl Social & Policy Sci, Shore Rd, Newtownabbey BT37 0QB, North Ireland.
C3 Ulster University
RP Bell, J (corresponding author), Ulster Univ, Sch Appl Social & Policy Sci, Shore Rd, Newtownabbey BT37 0QB, North Ireland.
EM bell-j24@ulster.ac.uk
OI Bell, John/0000-0002-3901-0236
FU Department for Employment and Learning in Northern Ireland
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: The
   research drawn upon in this paper is based upon the lead author's
   doctoral work. Living expenses were funded by a PhD studentship from the
   Department for Employment and Learning in Northern Ireland (September
   2013-September 2016). Flights and accomodation for the five away matches
   in the EURO 2016 campaign were paid for by Ulster University.
CR [Anonymous], 1987, Irish Political Studies, V2, P1
   [Anonymous], 1967, MIND SELF SOC STANDP
   [Anonymous], 1994, FOOTBALL VIOLENCE SO
   [Anonymous], 1999, Lost lives: The stories of the men, women and children who died as a result of the Northern Ireland Troubles
   [Anonymous], 1978, The Rules of Disorder
   [Anonymous], 2011, FIFA DISC COD
   Armstrong G., 1998, Football Hooligans: Knowing the Score
   Bairner A., 2005, SPORT IRISH HISTORIE, P157
   Bairner A, 1999, SPORT DIVIDED SOC, P51
   Bairner Alan, 1997, WHO ARE PEOPLE UNION, P95
   Bell J, 2017, THESIS ULSTER U UK
   Bell J, 2020, INT REV SOCIOL SPORT, V55, P975, DOI 10.1177/1012690219862917
   Bernache-Assollant I, 2011, J SPORT SOC ISSUES, V35, P72, DOI 10.1177/0193723510396667
   Bhaskar R., 1975, A Realist Theory of Science
   Bornman E, 2006, INT J INTERCULT REL, V30, P383, DOI 10.1016/j.ijintrel.2005.09.005
   Bourdieu P., 1990, The logic ofpractice, DOI DOI 10.1017/CBO9780511812507
   Bourdieu P., 1988, Homo Academicus
   Brown A., 1998, Fanatics! power, identity and fandom in football., P50
   Bryman A., 2012, SOCIAL RES METHODS
   Cleland J, 2014, J ETHN MIGR STUD, V40, P638, DOI 10.1080/1369183X.2013.777524
   Collins R., 2004, Interaction ritual chains, DOI 10.1515/9781400851744
   Denzin N.K., 2011, SAGE HDB QUALITATIVE, DOI DOI 10.1017/CBO9781107415324.004
   Dixon K., 2016, Soccer and Society, V17, P140
   Dixon K, 2013, INT REV SOCIOL SPORT, V48, P334, DOI 10.1177/1012690212441157
   Doidge M, 2015, INT REV SOCIOL SPORT, V50, P249, DOI 10.1177/1012690213480354
   Durkheim Emil., 2001, The Elementary Forms of Religious Life
   Giddens A., 1993, New Rules of Sociological Method
   Giddens A., 1984, The constitution of society: outline of the theory of structuration
   Giulianotti R., 1999, Football. A sociology of the global game
   Granström K, 2012, INT REV SOCIOL SPORT, V47, P133, DOI 10.1177/1012690210388458
   Hassan D, 2005, SPORT IRISH HISTORIE, P123
   Hassan D, 2009, SPORT SOC, V12, P709, DOI [10.1080/14660970903239933, 10.1080/17430430902944134]
   Herrera E, 2018, ETHNOMUSICOLOGY, V62, P470, DOI 10.5406/ethnomusicology.62.3.0470
   Hodges A, 2016, INT REV SOCIOL SPORT, V51, P410, DOI 10.1177/1012690214526401
   Jack M, 2013, ETHNOMUSICOLOGY REV, V18
   Keown C, 2020, TRANSL STUD, V13, P216, DOI 10.1080/14781700.2020.1746390
   Lavalette M., 2013, CRIMINAL JUSTICE MAT, V93, P22, DOI [10.1080/09627251.2013.833790, DOI 10.1080/09627251.2013.833790]
   Marra PS, 2019, POP MUSIC, V38, P73, DOI 10.1017/S0261143018000727
   May A, 2015, SOCIOL RES ONLINE, V20, DOI 10.5153/sro.3649
   Mill John Stuart, 1991, LIBERTY OTHER ESSAYS
   Millar SR, 2016, POP MUSIC, V35, P297, DOI 10.1017/S0261143016000519
   More Thomas, 1516, UTOPIA
   Pearson G., 2012, An Ethnography of English Football Fans. Cans
   Poulton E, 2016, INT REV SOCIOL SPORT, V51, P715, DOI 10.1177/1012690214554844
   Reid I. A., 2008, Soccer and Society, V9, P64, DOI 10.1080/14660970701616761
   Rubin H. J., 2005, QUALITATIVE INTERVIE, DOI DOI 10.4135/9781452226651
   Shirlow P., 1997, WHO ARE PEOPLE UNION
   Spaaij R., 2011, Soccer and Society, V12, P633, DOI 10.1080/14660970.2011.599583
   Stott C, 2007, EUR J SOC PSYCHOL, V37, P75, DOI 10.1002/ejsp.338
   Sugden John, 1993, SPORT SECTARIANISM S
   Tajfel Henri, 1979, Organizational Identity: A Reader, P33
   Treadwell J, 2014, FOOTBALL HOOLIGANISM, P92
   UEFA, 2009, TOUS ENS WINS SUPP A
   UEFA, 2016, DISC REG
   Wacquant L.J., 1992, An Invitation to Reflexive Sociology
   Waiton S, 2014, ANTI-SOCIAL BEHAVIOUR IN BRITAIN: VICTORIAN AND CONTEMPORARY PERSPECTIVES, P203
   Wilson E.O., 1975, P1
   Yin R. K., 2009, Case study research: Design and methods, V4th Edition, DOI DOI 10.1097/FCH.0B013-31822DDA9E
NR 58
TC 1
Z9 1
U1 0
U2 3
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1012-6902
EI 1461-7218
J9 INT REV SOCIOL SPORT
JI Int. Rev. Sociol. Sport
PD DEC
PY 2021
VL 56
IS 8
BP 1206
EP 1223
AR 1012690220979715
DI 10.1177/1012690220979715
EA DEC 2020
PG 18
WC Hospitality, Leisure, Sport & Tourism; Sociology
WE Social Science Citation Index (SSCI)
SC Social Sciences - Other Topics; Sociology
GA WM4EJ
UT WOS:000599641900001
OA Green Submitted
DA 2024-01-09
ER

PT J
AU Bordolli, MF
AF Fornaro Bordolli, Marita
TI Wind on the Breakwater: Air and Water in Uruguayan Popular Music
SO CUADERNOS DE MUSICA ARTES VISUALES Y ARTES ESCENICAS
LA Spanish
DT Article
DE Uruguayan popular music; air and metaphors; rhetoric of the performing
   arts; Uruguayan murga; popular musical theatre; Eduardo Darnauchans
AB The article proposes an analysis of the presence of air in music and popular musical theatre in Uruguay, especially in the 1980s and 1990s. It is interesting to establish how the metaphors and allegories of the air meet the physical and symbolic water of the bay of Montevideo, a city that was the natural port par excellence of the South Atlantic during the Colonial period and that is still a meeting point of traditions. From Steven Connor's proposal in Matter of Air 12010), the symbolic presence of air is addressed; elements of the anthropology of emotions and analysis from the rhetoric of the different types of art are integrated. The paper analyzes, in the case of songs, the lyrics and their relationship with music, especially those features linked to the literary content (characteristics of the vocal emission, instrumentation and arrangements), and, in the case of the murga, a genre of carnival musical theater, the link between literature, music, choreography, costumes, scenery and makeup. A more in-depth analysis is made for the show El pianeador de la escollera Sarandk produced by the murga, Curtidores de hongos, during the 2005 carnival of Montevideo, in which literary text and costumes complement each other in the production of meaning, and for two songs performed by Eduardo Darnauchans, a relevant figure of Uruguayan popular music. Also included is a brief presentation of other songs that metaphorically elaborate the visual and sound landscape of the city, with air as the thematic center.
C1 [Fornaro Bordolli, Marita] Univ Republica, Ctr Invest Arles Mus & Escen, Montevideo, Uruguay.
   [Fornaro Bordolli, Marita] Univ Republica, Escuela Univ Mus, Montevideo, Uruguay.
C3 Universidad de la Republica, Uruguay; Universidad de la Republica,
   Uruguay
RP Bordolli, MF (corresponding author), Univ Republica, Ctr Invest Arles Mus & Escen, Montevideo, Uruguay.; Bordolli, MF (corresponding author), Univ Republica, Escuela Univ Mus, Montevideo, Uruguay.
EM maritafornaro@gmail.com
CR Alfaro Milita, 2012, CURTIDORES HONGOS MI
   Alfaro Milita, 2017, J ROOS MONTEVIDEANO
   Alfaro Milita, 1987, J ROOS SONIDO CALLE
   [Anonymous], 2014, CHARLY PAIS ALEGORIA
   Appadurai Arjun, 2001, La modernidad desbordada
   Baskins Cristelle, 2007, EARLY MODERN VISUAL
   Beatty A, 2013, EMOT REV, V5, P414, DOI 10.1177/1754073913490045
   Beatty Andrew, 2013, EMOT REV, V5, P414
   Brown Jane K., 2006, PERSISTENCE ALLEGORY
   Caldas Cervinskis Andre, 2008, PROLINGUA, V2, P72
   Connor Steven, 2010, The Matter of Air: Science and the Art of the Ethereal
   Couto Tabare, 1993, E DARNAUCHANS ESPEJO
   DeNora Tia, 2000, Music in Everyday Life
   Diaz Nelson, 2008, MEMORIAS TROVADOR CO
   Feld S., 1982, Sound and Sentiment: Birds, Weeping, Poetics, and Song in Kaluli Expression
   Finnegan Ruth, 2003, The Cultural Study of Music: A Critical Introduction, P181
   FLETCHER Angus, 2002, ALEGORIA TEORIA MODO
   Fornaro Bordolli Marita, 1999, SONIDO CULTURA TEXTO, V15-16, P139
   Fornaro Bordolli Marita, 2013, REV I INVESTIGACION, V27, P121
   Fornaro Bordolli Marita, 2007, PANDORA REV ETUDES H, V7, P31
   Fornaro Bordolli Marita, 2009, SANSUENA EDICION 30
   Fornaro Bordolli Marita, 2019, CUADERNOS ETNOMUSICO, V13, P184
   Fornaro Bordolli Marita, 2008, QUEMAS E DARNAUCHANS
   Fornaro Bordolli Marita, 2017, THESIS
   Fornaro Bordolli Marita, 2018, MUSIC ART INT J MUSI, V43, P123
   Granizo, 2019, GRANIZO
   Hesmondhalgh D., 2008, Consumption Markets and Culture, V11, P329, DOI 10.1080/10253860802391334
   Honig Edwin, 1966, DARK CONCEIT MAKING
   Le Breton D., 2013, Revista Latinoamericana de Estudios sobre Cuerpos, Emociones y Sociedad, P69
   Rodriguez Marcelo, 2012, DARNAUCHANS ENTRE CU
   Sabaj Silvia, 2017, DARNAUCHANS POESIA C
NR 31
TC 0
Z9 0
U1 1
U2 2
PU PONTIFICIA UNIV JAVERIANA, FAC ARTES
PI BOGOTA
PA CARRERA 7 NO 40-62, EDIF PABLO VI PISO 2, BOGOTA, 00000, COLOMBIA
SN 1794-6670
EI 2215-9959
J9 CUAD MUSIC ARTES ESC
JI Cuad. Music Artes Escen.
PD JUL-DEC
PY 2020
VL 15
IS 2
BP 168
EP 189
DI 10.11144/javeriana.mavae15-2.evel
PG 22
WC Humanities, Multidisciplinary
WE Emerging Sources Citation Index (ESCI)
SC Arts & Humanities - Other Topics
GA MH0YE
UT WOS:000546455300010
OA gold, Green Submitted
DA 2024-01-09
ER

PT J
AU Jansen, N
   Harding, EE
   Loerts, H
   Baskent, D
   Lowie, W
AF Jansen, Nelleke
   Harding, Eleanor E.
   Loerts, Hanneke
   Baskent, Deniz
   Lowie, Wander
TI The relation between musical abilities and speech prosody perception: A
   meta-analysis
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Prosody; Perception; Musical abilities; Meta-analysis
ID ENGLISH-SPEAKING MUSICIANS; IN-NOISE PERCEPTION; LEXICAL TONE;
   CONGENITAL AMUSIA; VOCAL EMOTION; BRAIN-STEM; MANDARIN SPEAKERS;
   ENHANCED PERCEPTION; FOREIGN-LANGUAGE; PITCH-ACCENT
AB Previous research has suggested a relationship between musical abilities and the perception of speech prosody. However, effect sizes and significance differ across studies. In a meta-analysis, we assessed the overall size of this relation across 109 studies and investigated which factors moderated the effect. We found a significant, medium-sized positive correlation between musical abilities and speech prosody perception. This correlation was larger for studies on non-native compared to native prosody perception. We attribute this difference to ceiling performance in native perception, while non-native perception may be more difficult and can thus be facilitated by musical abilities. In addition, prosody perception was more strongly correlated with music perception than with music training, possibly because training metrics disregard untrained individuals with naturally strong musical abilities. Further analyses showed a stronger correlation for prosodic pitch compared to prosodic timing perception, and a stronger correlation for behavioural accuracy measures compared to reaction times. We did not find differences in effects between linguistic and emotional prosody, between L1 tone language users or non-tone language users, or between adults and children. This meta-analysis generally supports theories proposing a connection between music and speech prosody. Furthermore, this study highlights the potential importance of individuals' musical abilities for the acquisition of second language prosody.(c) 2023 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY license (http:// creativecommons.org/licenses/by/4.0/).
C1 [Jansen, Nelleke; Loerts, Hanneke; Lowie, Wander] Univ Groningen, Fac Arts, Ctr Language & Cognit, Dept Appl Linguist, Oude Kijk int Jatstr 26, NL-9712 EK Groningen, Netherlands.
   [Jansen, Nelleke; Harding, Eleanor E.] Univ Groningen, Univ Med Ctr Groningen, Dept Otorhinolaryngol Head & Neck Surg, Hanzepl 1, NL-9713 GZ Groningen, Netherlands.
   [Jansen, Nelleke; Harding, Eleanor E.; Loerts, Hanneke; Lowie, Wander] Univ Groningen, Res Sch Behav & Cognit Neurosci, Postbox 196, NL-9700 AD Groningen, Netherlands.
   [Harding, Eleanor E.] Hanze Univ Appl Sci, Prince Claus Conservatory, Meeuwerderweg 1, Groningen, Netherlands.
C3 University of Groningen; University of Groningen; University of
   Groningen
RP Jansen, N (corresponding author), Univ Groningen, Fac Arts, Ctr Language & Cognit, Dept Appl Linguist, Oude Kijk int Jatstr 26, NL-9712 EK Groningen, Netherlands.
EM n.g.jansen@rug.nl
RI Lowie, Wander/H-7635-2012
OI Lowie, Wander/0000-0002-2241-0276; Baskent, Deniz/0000-0002-6560-1451
FU Faculty of Arts of the University of Groningen; Dorhout Mees Foundation;
   Gratama Foundation; Heinsius Houbolt Funds; Netherlands Organization for
   Scientific Research (NWO) [918-17- 603]; Netherlands Organization for
   Health Research and Development (ZonMw)
FX We thank Marita Everhardt and Jelle Brouwer for their advice on
   meta-analytic methods. This work was supported by the Faculty of Arts of
   the University of Groningen; the Dorhout Mees Foundation; the Gratama
   Foundation; Heinsius Houbolt Funds; and the VICI grant 918-17- 603 from
   the Netherlands Organization for Scientific Research (NWO) and the
   Netherlands Organization for Health Research and Development (ZonMw) .
CR Albouy P, 2020, SCIENCE, V367, P1043, DOI 10.1126/science.aaz3468
   Alexander J. A., 2005, INTERSPEECH 2005, P397, DOI DOI 10.21437/INTERSPEECH.2005-271
   Amino K, 2019, ACOUST SCI TECHNOL, V40, P285, DOI 10.1250/ast.40.285
   Assink M, 2016, QUANT METH PSYCHOL, V12, P154, DOI 10.20982/tqmp.12.3.p154
   Ayotte J, 2002, BRAIN, V125, P238, DOI 10.1093/brain/awf028
   Barbaroux M, 2021, J COGNITIVE NEUROSCI, V33, P8, DOI 10.1162/jocn_a_01629
   Baskent D, 2018, J ACOUST SOC AM, V143, pEL311, DOI 10.1121/1.5034489
   Besson M, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00094
   Bidebnan GM, 2010, BRAIN RES, V1355, P112, DOI 10.1016/j.brainres.2010.07.100
   Bodner E, 2012, J PSYCHOPATHOL BEHAV, V34, P458, DOI 10.1007/s10862-012-9304-7
   Boebinger D, 2015, J ACOUST SOC AM, V137, P378, DOI 10.1121/1.4904537
   Boll-Avetisyan N, 2016, BILING-LANG COGN, V19, P971, DOI 10.1017/S1366728915000425
   Borenstein M., 2011, INTRO METAANALYSIS
   Bowles AR, 2016, LANG LEARN, V66, P774, DOI 10.1111/lang.12159
   Bowling DL, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0031942
   Bradley E. D., 2012, Crosslinguistic perception of pitch in language and music
   Bradley ED, 2018, PSYCHOL REP, V121, P600, DOI 10.1177/0033294117734832
   Brown S, 2013, PSYCHOL MUSIC, V41, P229, DOI 10.1177/0305735611425896
   Bryant GA, 2008, J COGN CULT, V8, P135, DOI 10.1163/156770908X289242
   Burnham D, 2015, PSYCHOL MUSIC, V43, P881, DOI 10.1177/0305735614546359
   Caldwell-Harris CL, 2015, STUD SECOND LANG ACQ, V37, P335, DOI 10.1017/S0272263114000849
   Carr KW, 2016, DEV COGN NEUROS-NETH, V17, P76, DOI 10.1016/j.dcn.2015.12.003
   Chan RKW, 2020, STUD SECOND LANG ACQ, V42, P33, DOI 10.1017/S0272263119000482
   Chen A, 2004, LANG SPEECH, V47, P311, DOI 10.1177/00238309040470040101
   Chen A, 2016, LANG COGN NEUROSCI, V31, P751, DOI 10.1080/23273798.2016.1156715
   Chen S, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0232514
   Chen XZ, 2018, BRAIN STRUCT FUNCT, V223, P2013, DOI 10.1007/s00429-018-1608-2
   Cheung MWL, 2014, PSYCHOL METHODS, V19, P211, DOI 10.1037/a0032968
   Cheung YL, 2021, CLIN LINGUIST PHONET, V35, P101, DOI 10.1080/02699206.2020.1719209
   Chobert J, 2014, CEREB CORTEX, V24, P956, DOI 10.1093/cercor/bhs377
   Chobert J, 2011, J COGNITIVE NEUROSCI, V23, P3874, DOI 10.1162/jocn_a_00088
   Choi W, 2020, MUSIC PERCEPT, V37, P423, DOI 10.1525/MP.2020.37.5.423
   Coffey EBJ, 2017, HEARING RES, V352, P49, DOI 10.1016/j.heares.2017.02.006
   Cooper A, 2012, J ACOUST SOC AM, V131, P4756, DOI 10.1121/1.4714355
   COOPER H., 2019, HDB RES SYNTHESIS ME, V3rd
   Correia AI, 2022, EMOTION, V22, P894, DOI 10.1037/emo0000770
   Cui A, 2019, J ACOUST SOC AM, V146, P4086, DOI 10.1121/1.5134442
   Curtis ME, 2010, EMOTION, V10, P335, DOI 10.1037/a0017928
   Dankovicová J, 2007, LANG SPEECH, V50, P177, DOI 10.1177/00238309070500020201
   Deguchi C, 2012, BRAIN RES, V1455, P75, DOI 10.1016/j.brainres.2012.03.034
   Delogu F, 2010, EUR J COGN PSYCHOL, V22, P46, DOI 10.1080/09541440802708136
   Dittinger E, 2021, J COGNITIVE NEUROSCI, V33, P662, DOI 10.1162/jocn_a_01670
   Dittinger E, 2018, EUR J NEUROSCI, V47, P1504, DOI 10.1111/ejn.13939
   Egger M, 1997, BMJ-BRIT MED J, V315, P629, DOI 10.1136/bmj.315.7109.629
   Fuller CD, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00179
   Gandour J, 2007, HUM BRAIN MAPP, V28, P94, DOI 10.1002/hbm.20255
   Globerson E, 2013, ATTEN PERCEPT PSYCHO, V75, P1799, DOI 10.3758/s13414-013-0518-x
   Gordon E., 1989, Advanced measures of music audiation
   Goss S, 2020, APPL PSYCHOLINGUIST, V41, P25, DOI 10.1017/S0142716419000377
   Harding EE, 2019, NEUROIMAGE, V185, P96, DOI 10.1016/j.neuroimage.2018.10.037
   Harrer M., 2019, DMETAR COMPANION R P
   Harrer M., 2021, Doing Meta Analysis in R
   Heffner CC, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01962
   Holliman AJ, 2010, EDUC PSYCHOL-UK, V30, P247, DOI 10.1080/01443410903560922
   Huang WT, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00829
   Hutchins S, 2012, BRAIN LANG, V123, P234, DOI 10.1016/j.bandl.2012.09.011
   Hutchins S, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00236
   Ilie G, 2006, MUSIC PERCEPT, V23, P319, DOI 10.1525/mp.2006.23.4.319
   Jasmin K, 2020, J EXP PSYCHOL GEN, V149, P914, DOI 10.1037/xge0000688
   Jiang CM, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0041411
   Jiang CM, 2012, MEM COGNITION, V40, P1109, DOI 10.3758/s13421-012-0208-2
   Jiang CM, 2010, NEUROPSYCHOLOGIA, V48, P2630, DOI 10.1016/j.neuropsychologia.2010.05.009
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kaplan E. C., 2019, P 23 INT C ACOUSTICS
   Kaplan EC, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.623787
   Kempe V, 2015, BRIT J PSYCHOL, V106, P349, DOI 10.1111/bjop.12092
   Kempe V, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048623
   Kolinsky R, 2009, MUSIC PERCEPT, V26, P235, DOI 10.1525/MP.2009.26.3.235
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Law LNC, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0052508
   Lee CY, 2008, J ACOUST SOC AM, V124, P3235, DOI 10.1121/1.2990713
   Lee CY, 2014, J ACOUST SOC AM, V135, P1607, DOI 10.1121/1.4864473
   Lee CY, 2011, J ACOUST SOC AM, V130, P526, DOI 10.1121/1.3596473
   Lee CY, 2010, J ACOUST SOC AM, V127, P481, DOI 10.1121/1.3266683
   Lenhard W., 2016, CALCULATION EFFECT S, DOI [DOI 10.13140/RG.2.1.3478.4245, 10.13140/RG.2.2.17823.92329]
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Liu F, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030374
   Liu F, 2010, BRAIN, V133, P1682, DOI 10.1093/brain/awq089
   Liu T, 2017, MUSIC PERCEPT, V34, P335, DOI 10.1525/MP.2017.34.3.335
   Lo CY, 2020, J SPEECH LANG HEAR R, V63, P1990, DOI 10.1044/2020_JSLHR-19-00391
   Madsen CK, 2004, J RES MUSIC EDUC, V52, P77, DOI 10.2307/3345526
   Madsen SMK, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12937-9
   Maggu AR, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-80260-x
   Maggu AR, 2018, INTERSPEECH, P3791, DOI 10.21437/Interspeech.2018-2104
   Maggu AR, 2018, J NEUROLINGUIST, V47, P145, DOI 10.1016/j.jneuroling.2018.05.003
   Magne C, 2006, J COGNITIVE NEUROSCI, V18, P199, DOI 10.1162/089892906775783660
   Mankel K, 2018, P NATL ACAD SCI USA, V115, P13129, DOI 10.1073/pnas.1811793115
   Marie C, 2011, J COGNITIVE NEUROSCI, V23, P2701, DOI 10.1162/jocn.2010.21585
   Marie C, 2011, J COGNITIVE NEUROSCI, V23, P294, DOI 10.1162/jocn.2010.21413
   Marques C, 2007, J COGNITIVE NEUROSCI, V19, P1453, DOI 10.1162/jocn.2007.19.9.1453
   Martínez-Castilla P, 2019, LANG COGN, V11, P455, DOI 10.1017/langcog.2019.27
   Martínez-Castilla P, 2014, BRAIN SCI, V4, P376, DOI 10.3390/brainsci4020376
   Martínez-Montes E, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00084
   Moher D, 2009, J CLIN EPIDEMIOL, V62, P1006, DOI 10.1016/j.jclinepi.2009.06.005
   Mok PKP, 2012, J ACOUST SOC AM, V132, P2711, DOI 10.1121/1.4747010
   Moreno S, 2009, CONTEMP MUSIC REV, V28, P329, DOI 10.1080/07494460903404410
   Moreno S, 2009, CEREB CORTEX, V19, P712, DOI 10.1093/cercor/bhn120
   Morrill TH, 2015, J EXP PSYCHOL GEN, V144, P730, DOI 10.1037/xge0000081
   Mualem O, 2015, INT J MUSIC EDUC, V33, P413, DOI 10.1177/0255761415584292
   Musacchia G, 2008, HEARING RES, V241, P34, DOI 10.1016/j.heares.2008.04.013
   Musacchia G, 2007, P NATL ACAD SCI USA, V104, P15894, DOI 10.1073/pnas.0701498104
   Nan Y, 2018, P NATL ACAD SCI USA, V115, pE6630, DOI 10.1073/pnas.1808412115
   Nan Y, 2016, BIOL PSYCHOL, V113, P59, DOI 10.1016/j.biopsycho.2015.11.010
   Nan Y, 2010, BRAIN, V133, P2635, DOI 10.1093/brain/awq178
   Ning LH, 2015, J PHONETICS, V51, P50, DOI 10.1016/j.wocn.2014.12.003
   Ning LH, 2014, SPEECH COMMUN, V63-64, P55, DOI 10.1016/j.specom.2014.05.001
   Obergfell AL, 2021, READ WRIT, V34, P887, DOI 10.1007/s11145-020-10096-4
   Ong JH, 2020, J ACOUST SOC AM, V148, P3443, DOI 10.1121/10.0002776
   Ong JH, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01189
   Ouzzani M, 2016, SYST REV-LONDON, V5, DOI 10.1186/s13643-016-0384-4
   Parbery-Clark A, 2011, NEUROPSYCHOLOGIA, V49, P3338, DOI 10.1016/j.neuropsychologia.2011.08.007
   Parbery-Clark A, 2012, FRONT AGING NEUROSCI, V4, DOI 10.3389/fnagi.2012.00030
   Parbery-Clark A, 2009, J NEUROSCI, V29, P14100, DOI 10.1523/JNEUROSCI.3256-09.2009
   Park M, 2015, FRONT HUM NEUROSCI, V8, DOI [10.3389/fnhurn.2014.01049, 10.3389/fnhum.2014.01049]
   Patel AD, 2008, MUSIC PERCEPT, V25, P357, DOI 10.1525/MP.2008.25.4.357
   Patel AD, 2014, HEARING RES, V308, P98, DOI 10.1016/j.heares.2013.08.011
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Paulmann S, 2014, COGNITION EMOTION, V28, P230, DOI 10.1080/02699931.2013.812033
   Perdomo M, 2021, SECOND LANG RES, V37, P349, DOI 10.1177/0267658319879196
   Peretz I, 2003, ANN NY ACAD SCI, V999, P58, DOI 10.1196/annals.1284.006
   Peretz I, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00030
   Perrachione TK, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0073372
   Pinheiro AP, 2015, BRAIN LANG, V140, P24, DOI 10.1016/j.bandl.2014.10.009
   Plonsky L., 2011, Research methods in second language acquisition: A practical guide, P275
   Qin Z, 2021, J ACOUST SOC AM, V149, P435, DOI 10.1121/10.0003330
   R Core Team, 2021, R LANG ENV STAT COMP
   Rogalsky C, 2011, J NEUROSCI, V31, P3843, DOI 10.1523/JNEUROSCI.4515-10.2011
   Rosslau K, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0147986
   Sadakata M, 2011, ACTA PSYCHOL, V138, P1, DOI 10.1016/j.actpsy.2011.03.007
   Sares AG, 2018, J SPEECH LANG HEAR R, V61, P496, DOI 10.1044/2017_JSLHR-S-17-0207
   Schellenberg EG, 2015, ANN NY ACAD SCI, V1337, P170, DOI 10.1111/nyas.12627
   Schön D, 2004, PSYCHOPHYSIOLOGY, V41, P341, DOI 10.1111/1469-8986.00172.x
   Schön D, 2010, NEUROIMAGE, V51, P450, DOI 10.1016/j.neuroimage.2010.02.023
   Shen J., 2011, P M ACOUSTICS, V14, DOI [10.1121/2.0000066, DOI 10.1121/2.0000066]
   Sihvonen AJ, 2022, EUR J NEUROL, V29, P873, DOI 10.1111/ene.15148
   Skoe E, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00622
   Slater J, 2016, COGN PROCESS, V17, P79, DOI 10.1007/s10339-015-0740-7
   Smayda KE, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00682
   So CK, 2014, STUD SECOND LANG ACQ, V36, P195, DOI 10.1017/S0272263114000047
   So CK, 2010, LANG SPEECH, V53, P273, DOI 10.1177/0023830909357156
   Stepanov A, 2018, J ACOUST SOC AM, V143, pEL1, DOI 10.1121/1.5019700
   Strange W, 2011, J PHONETICS, V39, P456, DOI 10.1016/j.wocn.2010.09.001
   Tang W, 2016, NEUROPSYCHOLOGIA, V91, P247, DOI 10.1016/j.neuropsychologia.2016.08.003
   Thompson WF, 2003, ANN NY ACAD SCI, V999, P530, DOI 10.1196/annals.1284.067
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Tierney A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00949
   Tillmann B, 2011, J ACOUST SOC AM, V130, P4089, DOI 10.1121/1.3658447
   Tillmann B, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00120
   Torppa R, 2020, EAR HEARING, V41, P395, DOI 10.1097/AUD.0000000000000763
   Tremblay A, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00985
   Trimmer CG, 2008, EMOTION, V8, P838, DOI 10.1037/a0014080
   Twaite J. T., 2016, Examining relationships between basic emotion perception and musical training in the prosodic, facial, and lexical channels of communication and in music
   Vidas D., 2018, Music & Science, V1, DOI [10.1177/2059204318762650, DOI 10.1177/2059204318762650, 10.1177/]
   Viechtbauer W, 2010, J STAT SOFTW, V36, P1, DOI 10.18637/jss.v036.i03
   Wallentin M, 2010, LEARN INDIVID DIFFER, V20, P188, DOI 10.1016/j.lindif.2010.02.004
   Wang X, 2014, J ACOUST SOC AM, V136, P3360, DOI 10.1121/1.4900559
   Wayland R, 2010, J PHONETICS, V38, P654, DOI 10.1016/j.wocn.2010.10.001
   Wayland RP, 2004, LANG LEARN, V54, P681, DOI 10.1111/j.1467-9922.2004.00283.x
   Weidema JL, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00817
   Wiener S, 2023, LANG TEACH RES, V27, P1016, DOI 10.1177/1362168820971791
   Wong PCM, 2007, APPL PSYCHOLINGUIST, V28, P565, DOI 10.1017/S0142716407070312
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   Wu H, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00436
   Zeromskaite I., 2014, Journal of European Psychology Students, V5, P78, DOI [DOI 10.5334/JEPS.CI, 10.5334/jeps.ci]
   Zhang CC, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0183151
   Zhang J, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01965
   Zhang YX, 2018, INTERSPEECH, P2196, DOI 10.21437/Interspeech.2018-91
   Zhao TC, 2016, P NATL ACAD SCI USA, V113, P5212, DOI 10.1073/pnas.1603984113
   Zhao TC, 2015, J ACOUST SOC AM, V138, pEL133, DOI 10.1121/1.4927632
   Zhao TC, 2015, J ACOUST SOC AM, V137, P1452, DOI 10.1121/1.4913457
   Zheng Y, 2018, Q J EXP PSYCHOL, V71, P2627, DOI 10.1177/1747021818757435
   Zioga L, 2016, BRAIN RES, V1650, P267, DOI 10.1016/j.brainres.2016.09.015
NR 172
TC 0
Z9 0
U1 2
U2 2
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
EI 1095-8576
J9 J PHONETICS
JI J. Phon.
PD NOV
PY 2023
VL 101
AR 101278
DI 10.1016/j.wocn.2023.101278
EA NOV 2023
PG 21
WC Linguistics; Language & Linguistics
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Linguistics
GA AV9J2
UT WOS:001121341100001
OA hybrid
DA 2024-01-09
ER

PT J
AU van Dyck, E
   Six, J
   Soyer, E
   Denys, M
   Bardijn, I
   Leman, M
AF van Dyck, Edith
   Six, Joren
   Soyer, Esin
   Denys, Marlies
   Bardijn, Ilka
   Leman, Marc
TI Adopting a music-to-heart rate alignment strategy to measure the impact
   of music and its tempo on human heart rate
SO MUSICAE SCIENTIAE
LA English
DT Article
DE arousal; heart rate; music tempo; regulation; relaxation
ID RELAXING MUSIC; RESPONSES; ANXIETY; PRESSURE; RHYTHM; RELAXATION;
   EMOTIONS; STRESS; OLDER; TIME
AB Music is frequently used as a means of relaxation. Conversely, it is used as a means of arousal in sports and exercise contexts. Previous research suggests that tempo is one of the most significant determinants of music-related arousal and relaxation effects. Here we investigate the specific effect of music tempo, but also more generally, the influence of music on human heart rate. We took the pulses of 32 participants in silence, and then we played them non-vocal, ambient music at a tempo corresponding to their heart rates. Finally, we played the same music again, either with the tempo increased or decreased by a factor of 45%, 30%, or 15%; or maintaining the same tempo as in the first playing. Mixed-design ANOVA tests revealed a significant increase in heart rate while listening to the music as compared with silence (p < .05). In addition, substantial decreases in tempo (-45% or -30%) could account for smaller subsequent heart rate reductions (p < .05). We neither found links between increases in tempo (+15%, +30%, and +45%) and heart rate change, nor small decreases (-15%). In addition, neither effects of gender, music training, nor of musical preference were found. This indicates that during passive music listening, music exerts a general arousal effect on human heart rate, which might be regulated by tempo. These results are a major contribution to the way in which music may be used in everyday activities.
C1 [van Dyck, Edith; Six, Joren; Soyer, Esin; Denys, Marlies; Bardijn, Ilka; Leman, Marc] Univ Ghent, Ghent, Belgium.
C3 Ghent University
RP van Dyck, E (corresponding author), Univ Ghent, Dept Arts Mus & Theatre Sci, IPEM, Technicum Blok 2,Sint Pietersnieuwstr 41, B-9000 Ghent, Belgium.
EM edith.vandyck@ugent.be
RI Van Dyck, Edith/ABE-4913-2020; Van Dyck, Edith/ITU-6709-2023; Six,
   Joren/M-8893-2018
OI Van Dyck, Edith/0000-0001-7239-1918; Van Dyck,
   Edith/0000-0001-7239-1918; Six, Joren/0000-0001-7671-1907; Leman,
   Marc/0000-0002-9780-2194
FU Flemish Government
FX The authors acknowledge the Methusalem project, awarded by the Flemish
   Government, for funding this study.
CR Altenmüller E, 2002, NEUROPSYCHOLOGIA, V40, P2242, DOI 10.1016/S0028-3932(02)00107-0
   BASON PT, 1972, NATURE, V238, P279, DOI 10.1038/238279a0
   Berlyne D. E., 1971, Aesthetics and Psychobiology
   Bernardi L, 2000, J AM COLL CARDIOL, V35, P1462, DOI 10.1016/S0735-1097(00)00595-7
   Bernardi L, 2006, HEART, V92, P445, DOI 10.1136/hrt.2005.064600
   Bernardi L, 2009, CIRCULATION, V119, P3171, DOI 10.1161/CIRCULATIONAHA.108.806174
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Bunt L., 1994, MUSIC THERAPY ART WO
   Chlan L, 1998, HEART LUNG, V27, P169, DOI 10.1016/S0147-9563(98)90004-8
   Cohen J, 1988, STAT POWER ANAL BEHA
   da Silva AG, 2014, COMPLEMENT THER CLIN, V20, P130, DOI 10.1016/j.ctcp.2013.09.004
   DAVIS WB, 1989, J MUSIC THER, V26, P168, DOI 10.1093/jmt/26.4.168
   Dixon S, 2007, J NEW MUSIC RES, V36, P39, DOI 10.1080/09298210701653310
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Flanagan D., 2008, The Ruby Programming Language: Everything you Need to Know
   FONTAINE CW, 1979, PERCEPT MOTOR SKILL, V49, P71, DOI 10.2466/pms.1979.49.1.71
   Gingras B, 2014, Q J EXP PSYCHOL, V67, P1428, DOI 10.1080/17470218.2013.863954
   HAAS F, 1986, J APPL PHYSIOL, V61, P1185, DOI 10.1152/jappl.1986.61.3.1185
   Hilz MJ, 2014, AUTON NEUROSCI-BASIC, V183, P83, DOI 10.1016/j.autneu.2014.02.004
   Iwanaga M, 2005, BIOL PSYCHOL, V70, P61, DOI 10.1016/j.biopsycho.2004.11.015
   IWANAGA M, 1995, PERCEPT MOTOR SKILL, V81, P435, DOI 10.2466/pms.1995.81.2.435
   IWANAGA M, 1995, PERCEPT MOTOR SKILL, V81, P67, DOI 10.2466/pms.1995.81.1.67
   Karageorghis C. I., 1997, Journal of Sport Behavior, V20, P54
   Karageorghis C. I., 2015, SPORT EXERCISE PSYCH, P274
   Karageorghis CI, 2006, RES Q EXERCISE SPORT, V77, P240
   Knight WEJ, 2001, J MUSIC THER, V38, P254, DOI 10.1093/jmt/38.4.254
   Koelsch S, 2006, HUM BRAIN MAPP, V27, P239, DOI 10.1002/hbm.20180
   Krumhansl CL, 1997, CAN J EXP PSYCHOL, V51, P336, DOI 10.1037/1196-1961.51.4.336
   Lee D, 2004, J CLIN NURS, V13, P297, DOI 10.1046/j.1365-2702.2003.00888.x
   Lee KC, 2012, BIOL RES NURS, V14, P78, DOI 10.1177/1099800410396704
   Lingham J, 2009, NORD J MUSIC THER, V18, P150, DOI 10.1080/08098130903062363
   Mahmud A, 2003, HYPERTENSION, V41, P183, DOI 10.1161/01.HYP.0000047464.66901.60
   MilukKolasa B, 1996, J MUSIC THER, V33, P208, DOI 10.1093/jmt/33.3.208
   MOCKEL M, 1994, EUR J APPL PHYSIOL, V68, P451, DOI 10.1007/BF00599512
   Nater UM, 2006, INT J PSYCHOPHYSIOL, V62, P300, DOI 10.1016/j.ijpsycho.2006.05.011
   Nilsson U, 2011, EUR J CARDIOVASC NUR, V10, P73, DOI 10.1016/j.ejcnurse.2010.06.004
   Nomura S., 2003, J MED INFORM TECHNOL, V22, P251
   North AC, 1997, PSYCHOLOGIST, V10, P309
   Palatini P, 1999, HYPERTENSION, V33, P622, DOI 10.1161/01.HYP.33.2.622
   Piccione G, 2009, CHRONOBIOL INT, V26, P47, DOI 10.1080/07420520802689772
   Priest DL, 2004, J SPORT MED PHYS FIT, V44, P77
   Roy M, 2009, INT J PSYCHOPHYSIOL, V71, P37, DOI 10.1016/j.ijpsycho.2008.07.010
   SAPERSTON B, 1995, ART SCI MUSIC THERAP, P58
   Shelley K., 2001, Monitoring, P420
   Spyer K. M., 1999, AUTONOMIC FAILURE TX, P45
   Steelman V M, 1991, Todays OR Nurse, V13, P18
   Szabo A, 1999, J SPORT MED PHYS FIT, V39, P220
   Szmedra L, 1998, INT J SPORTS MED, V19, P32, DOI 10.1055/s-2007-971876
   Thaut M.H., 2005, Rhythm, Music and the Brain: Scientific Foundations and Clinical Applications
   Trappe Hans-Joachim, 2012, Int J Crit Illn Inj Sci, V2, P27, DOI 10.4103/2229-5151.94893
   Tsai JL, 2000, PSYCHOL AGING, V15, P684, DOI 10.1037/0882-7974.15.4.684
   Van Dyck E, 2015, SPORTS MED-OPEN, V1, DOI 10.1186/s40798-015-0025-9
   White J, 1991, Wis Med J, V90, P434
   White J M, 1999, Am J Crit Care, V8, P220
   White J M, 2000, Crit Care Nurs Clin North Am, V12, P219
   WHITSETT TL, 1984, AM J CARDIOL, V53, P918, DOI 10.1016/0002-9149(84)90525-3
   ZIMNY GH, 1963, AM J PSYCHOL, V76, P311, DOI 10.2307/1419170
NR 57
TC 14
Z9 14
U1 13
U2 127
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1029-8649
EI 2045-4147
J9 MUSIC SCI
JI Music Sci.
PD DEC
PY 2017
VL 21
IS 4
BP 390
EP 404
DI 10.1177/1029864917700706
PG 15
WC Music; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music; Psychology
GA FM7HW
UT WOS:000415246900002
OA Green Published
DA 2024-01-09
ER

PT J
AU Parra, A
   Silguero, VHD
AF Parra, Alejandro
   Damian Silguero, Victor Hugo
TI MENTAL HEALTH, NEGATIVE EXPERIENCES IN CHILHOOD, AND ITS IMPACT ON DREAM
   EXPERIENCES
SO REVISTA DE PSICOTERAPIA
LA Spanish
DT Article
DE Nightmare; Childhood trauma; Psychopathological symptoms; Disturbing
   Dreams
ID INITIAL RELIABILITY; SLEEP DISTURBANCES; NIGHTMARE DISTRESS; CHILDHOOD
   TRAUMA; SEXUAL-ABUSE; PREVALENCE; FREQUENCY; VALIDITY; PSYCHOPATHOLOGY
AB Disturbing dreams are vivid dreams characterized by intense negative emotions, which are among the most frequent symptoms of trauma victims, and their related disorders can persist for years and even decades after the trauma. The aim is to evaluate whether individuals who most dream recall, nightmares or bad dreams, score higher on traumatic experiences in their childhood and if they present current disturbing symptoms. Three measures were used over a sample of 446 adults from the general population: The Dream Questionnaire, Child Negative Experiences Questionnaire; and shortened version of the Symptoms Assessment (SA-45). Descriptive results showed specific dream content, such as hearing voices/music in dreams (88%), lucid dreams (79%), nocturnal terror (64%), evil entities (61%), and recurrent disturbing dreams (40%). The results also showed a correlation between the frequency of dream recall and higher scores of negative experiences in childhood, particularly parental abuse (emotional, sexual and physical) and a negative correlation between the dream recall and mental health. In addition, it confirmed the two main hypotheses: negative symptoms could "modulate" in some way the negative dream experiences. Gender differences also were found, i.e. male tended to have higher dream recall compared to female, and female tended to show predominantly more auditory dreams and nocturnal terrors compared to female.
C1 [Parra, Alejandro] Inst Psicol Paranormal, Buenos Aires, DF, Argentina.
   [Damian Silguero, Victor Hugo] Univ Abierta Interamer, Fac Psicol & Relac Humanas, Buenos Aires, DF, Argentina.
RP Parra, A (corresponding author), Inst Psicol Paranormal, Buenos Aires, DF, Argentina.
EM rapp@fibertel.com.ar
CR Agargun MY, 1998, COMPR PSYCHIAT, V39, P198
   Banyard VL, 2001, J TRAUMA STRESS, V14, P697, DOI 10.1023/A:1013085904337
   BELICKI K, 1992, J ABNORM PSYCHOL, V101, P592, DOI 10.1037/0021-843X.101.3.592
   Bernstein DP, 1997, J AM ACAD CHILD PSY, V36, P340, DOI 10.1097/00004583-199703000-00012
   BERNSTEIN DP, 1994, AM J PSYCHIAT, V151, P1132, DOI 10.1176/ajp.151.8.1132
   BERQUIER A, 1992, J ABNORM PSYCHOL, V101, P246, DOI 10.1037/0021-843X.101.2.246
   Cicchetti D., 1995, Developmental Psychopathology (Vol. 2). Risk, P32
   Duval M, 2010, SLEEP MED CLIN, V5, P249, DOI 10.1016/j.jsmc.2010.01.003
   FINK LA, 1995, AM J PSYCHIAT, V152, P1329, DOI 10.1176/ajp.152.9.1329
   Hartmann E, 2003, DREAMING, V13, P61, DOI 10.1023/A:1023398924124
   Hartmann E, 1996, DREAMING, V6, P147, DOI 10.1037/h0094452
   HARTMANN E, 1999, SLEEP HYPNOSIS, V1, P199
   Hill C. E., 2006, LENGUAJE NOCHE
   KRAMER M, 1984, PSYCHIAT J U OTTAWA, V9, P102
   Levin R, 1998, PSYCHIATRY, V61, P206, DOI 10.1080/00332747.1998.11024832
   Levin R, 2002, SLEEP, V25, P205
   Levin R, 2007, PSYCHOL BULL, V133, P482, DOI 10.1037/0033-2909.133.3.482
   Levin R, 2009, J NERV MENT DIS, V197, P606, DOI 10.1097/NMD.0b013e3181b0bd65
   Lopez Romera A., 2006, INTRO PSIQUIATRIA, P697
   Margolin G, 2000, ANNU REV PSYCHOL, V51, P445, DOI 10.1146/annurev.psych.51.1.445
   Mellman TA, 2006, CNS SPECTRUMS, V11, P611, DOI 10.1017/S1092852900013663
   Miro-Morales E., 2004, INT J PSYCHOL PSYCHO, V4, P123
   Molina J. M., 1996, SCI ENG, V57, P4076
   Navarro Egea J., 2006, INT J DEV ED PSYCHOL, V3, P265
   Noll JG, 2006, J PEDIATR PSYCHOL, V31, P469, DOI 10.1093/jpepsy/jsj040
   Ohayon MM, 1997, SLEEP, V20, P340, DOI 10.1093/sleep/20.5.340
   Parra A., 2006, SUENOS COMO INTERPRE
   Parra A., 2009, MUNDO OCULTO SUENOS
   Parra A, 2018, PERSPECT PSICOL MAR, V15, P86
   Parra Alejandro, 2014, Suma Psicol., V21, P63
   Romans SE, 1999, AM J PSYCHIAT, V156, P1080
   Schredl M, 2003, EUR ARCH PSY CLIN N, V253, P241, DOI 10.1007/s00406-003-0438-1
   Schredl M., 2006, Sleep and Hypnosis, V8, P1
   Schreuder BJN, 2000, J TRAUMA STRESS, V13, P453, DOI 10.1023/A:1007733324351
   Van de Castle R. L., 1994, OUR DREAMING MIND SW
   WOOD JM, 1992, J ABNORM PSYCHOL, V101, P219, DOI 10.1037/0021-843X.101.2.219
   WOOD JM, 1990, J ABNORM PSYCHOL, V99, P64, DOI 10.1037/0021-843X.99.1.64
   Zadra A, 2006, J NERV MENT DIS, V194, P249, DOI 10.1097/01.nmd.0000207359.46223.dc
   Zadra A, 2000, J ABNORM PSYCHOL, V109, P273, DOI 10.1037/0021-843X.109.2.273
NR 39
TC 0
Z9 0
U1 3
U2 13
PU REVISTA PSIQUIATRIA & PSICOLOGIA HUMANISTA, S L
PI BARCELONA
PA NUMANCIA, 52, 2O, 2A, BARCELONA, SPAIN
SN 1130-5142
EI 2339-7950
J9 REV PSICOTERAPIA
JI Rev. Psicoterapia
PD NOV
PY 2020
VL 31
IS 117
BP 163
EP 177
DI 10.33898/rdp.v31i117.435
PG 15
WC Psychology, Clinical
WE Emerging Sources Citation Index (ESCI)
SC Psychology
GA OQ4CP
UT WOS:000588733400008
OA Green Published, hybrid
DA 2024-01-09
ER

PT J
AU Kaur, B
   Singh, D
   Roy, PP
AF Kaur, Barjinder
   Singh, Dinesh
   Roy, Partha Pratim
TI A Novel framework of EEG-based user identification by analyzing
   music-listening behavior
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electroencephalography (EEG); User identification; Savtizik-Golay
   filter; Wavelet transform; Hidden Markov Model (HMM); Support Vector
   Machine (SVM)
ID HIDDEN MARKOV-MODELS; NEURONAL ENTRAINMENT; BRAIN; AUTHENTICATION;
   EXTRACTION; BEAT
AB This paper introduces a novel framework for user identification by analyzing neuro-signals. Studies regarding Electroencephalography (EEG) revealed that such bio-signals are sensitive, hard to forge, confidential, and unique which the conventional biometric systems like face, speaker, signature and voice lack. Traditionally, researchers investigated the neuro-signal patterns by asking users to perform various imaginary, visual or calculative tasks. In this work, we have analyzed this neuro-signal pattern using audio as stimuli. The EEG signals are recorded simultaneously while user is listening to music. Four different genres of music are considered as users have their own preference and accordingly they respond with different emotions and interests. The users are also asked to provide music preference which acts as a personal identification mechanism. The framework offers the benefit of uniqueness in neuro-signal pattern even with the same music preference by different users. We used two different classifiers i.e. Hidden Markov Model (HMM) based temporal classifier and Support Vector Machine (SVM) for user identification system. A dataset of 2400 EEG signals while listening to music was collected from 60 users. User identification performance of 97.50 % and 93.83 % have been recorded with HMM and SVM classifiers, respectively. Finally, the performance of the system is also evaluated on various emotional states after showing different emotional videos to users.
C1 [Kaur, Barjinder; Singh, Dinesh] DCRUST, Dept Comp Sci & Engn, Sonipat, India.
   [Roy, Partha Pratim] IIT, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
C3 Deenbandhu Chhotu Ram University of Science & Technology; Indian
   Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Kaur, B (corresponding author), DCRUST, Dept Comp Sci & Engn, Sonipat, India.
EM kaur.barjinder@gmail.com; dinesh.madhav@gmail.com; proy.fcs@iitr.ac.in
RI Roy, Partha Pratim/AAV-9061-2020; singh, dinesh/AAB-4046-2022; Roy,
   Partha Pratim/GPF-4253-2022; Roy, Partha Pratim/AAW-2994-2020
OI singh, dinesh/0000-0002-7614-5789; Roy, Partha
   Pratim/0000-0002-5735-5254; singh, dinesh/0000-0003-0662-5426
CR Abdulkader Sarah N., 2015, Human Aspects of Information Security, Privacy and Trust. Third International Conference, HAS 2015, held as part of HCI International 2015. Proceedings: LNCS 9190, P3, DOI 10.1007/978-3-319-20376-8_1
   Abo-Zahhad M, 2015, PATTERN RECOGN LETT
   Al-Juboori AM, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCES AND APPLICATIONS (CSA), P52, DOI 10.1109/CSA.2013.19
   Alomari MH, 2014, INT J ADV COMPUT SC, V5, P193
   Alzahrani H, 2014, SPIE DEFENSE SECURIT
   [Anonymous], 2014, P INT C REC ADV INN
   [Anonymous], 2016, SPRINGERBRIEFS APPL, DOI DOI 10.1007/978-981-287-670-6_6
   [Anonymous], P INT SOC MUS INF RE
   [Anonymous], 2015, PROC INT JOINT C NEU
   Astigarraga A, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/1435321
   Azami H, 2012, J SIGNAL INFORM PROC
   Badcock NA, 2013, PEERJ, V1, DOI 10.7717/peerj.38
   Breitwieser C, 2012, JOINT INT C PERV COM, P50
   Campbell P, 2011, INT J CULT POLICY, V17, P510, DOI 10.1080/10286632.2010.543461
   Champion C, 2016, COMPUT SPEECH LANG, V36, P347, DOI 10.1016/j.csl.2015.05.001
   Chuang J, 2013, LECT NOTES COMPUT SC, V7862, P1, DOI 10.1007/978-3-642-41320-9_1
   de Mira J, 2015, J SIGNAL PROCESS SYS, V80, P181, DOI 10.1007/s11265-013-0861-0
   Dustor A, 2013, COMM COM INF SC, V370, P456
   Hadjidimitriou SK, 2012, IEEE T BIO-MED ENG, V59, P3498, DOI 10.1109/TBME.2012.2217495
   Hariadi M, 2014, J THEOR APPL INF TEC, V66
   Holzinger Andreas, 2012, Information Technology in Bio- and Medical Informatics. Proceedings of the Third International Conference, ITBAM 2012, P166, DOI 10.1007/978-3-642-32395-9_13
   Iranmanesh V, 2014, SCI WORLD J, DOI 10.1155/2014/381469
   Krishnan SR, 2013, IEEE T SIGNAL PROCES, V61, P380, DOI 10.1109/TSP.2012.2225055
   Kumar AB, 2011, ANESTHESIOLOGY, V114, P964, DOI 10.1097/ALN.0b013e318210f86a
   La Rocca Daria, 2013, Proceedings of the 6th International Conference on Bio-inspired Systems and Signal Processing. BIOSIGNALS 2013, P419
   Lalor EC, 2005, EURASIP J APPL SIG P, V2005, P3156, DOI 10.1155/ASP.2005.3156
   Lee JC, 2012, PATTERN RECOGN LETT, V33, P1520, DOI 10.1016/j.patrec.2012.04.007
   Mahajan K, 2014, INT J COMPUTER SCI M
   Mandal R, 2015, J AM SOC QUESTIONED, V18, P3
   Marcel S, 2007, IEEE T PATTERN ANAL, V29, P743, DOI 10.1109/TPAMI.2007.1012
   Nozaradan S, 2012, J NEUROSCI, V32, P17572, DOI 10.1523/JNEUROSCI.3203-12.2012
   Nozaradan S, 2011, J NEUROSCI, V31, P10234, DOI 10.1523/JNEUROSCI.0411-11.2011
   Obermaier B, 2001, PATTERN RECOGN LETT, V22, P1299, DOI 10.1016/S0167-8655(01)00075-7
   Palaniappan R, 2008, INT J NEURAL SYST, V18, P59, DOI 10.1142/S0129065708001373
   Palaniappan R, 2007, IEEE T PATTERN ANAL, V29, P738, DOI 10.1109/TPAMI.2007.1013
   Pleva M, 2016, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE RADIOELEKTRONIKA (RADIOELEKTRONIKA 2016), P386, DOI 10.1109/RADIOELEK.2016.7477360
   Pratim P, 2012, INT CONF FRONT HAND, P225, DOI 10.1109/ICFHR.2012.270
   Rafiee J, 2011, EXPERT SYST APPL, V38, P6190, DOI 10.1016/j.eswa.2010.11.050
   Ramirez R, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00354
   Ravi H, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY (HST), P147, DOI 10.1109/THS.2013.6698991
   Repovi G, 2010, Informatica Medica Slovenica, V15, P18
   Shah PG, 2015, 2015 IEEE SEVENTH INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INFORMATION SYSTEMS (ICICIS), P116, DOI 10.1109/IntelCIS.2015.7397207
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P211, DOI 10.1109/T-AFFC.2011.37
   Stickel C, 2007, UNIVERSAL ACCESS IN HUMAN-COMPUTER INTERACTION: APPLICATIONS AND SERVICES, PT 3, PROCEEDINGS, P813
   Stytsenko K, 2011, MEI COGSCI C 2011 LI
   Sundararajan A, 2015, 2015 12TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY - NEW GENERATIONS, P139, DOI 10.1109/ITNG.2015.27
   Tatum IV W. O., 2014, Handbook of EEG Interpretation
   Wang YJ, 2008, IEEE ENG MED BIOL, V27, P64, DOI 10.1109/MEMB.2008.923958
   Weston J., 1998, TECHNICAL REPORT
   Wu T, 2008, MEASUREMENT, V41, P618, DOI 10.1016/j.measurement.2007.07.007
   Wu XQ, 2006, IEEE T SYST MAN CY A, V36, P978, DOI 10.1109/TSMCA.2006.871797
   Yeom SK, 2013, PATTERN RECOGN, V46, P1159, DOI 10.1016/j.patcog.2012.10.023
   Yuan-Pin Lin, 2008, 2008 IEEE 10th Workshop on Multimedia Signal Processing (MMSP), P127, DOI 10.1109/MMSP.2008.4665061
   Zúquete A, 2010, BIOSIGNALS 2010: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON BIO-INSPIRED SYSTEMS AND SIGNAL PROCESSING, P103
NR 54
TC 33
Z9 33
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 25581
EP 25602
DI 10.1007/s11042-016-4232-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500004
DA 2024-01-09
ER

PT J
AU Bond, BE
AF Bond, Brian E.
TI Performing pain: Sindhi Sufi music, affect, and Hindu-Muslim relations
   in western India
SO CULTURE THEORY AND CRITIQUE
LA English
DT Article
DE Sufi music; pain; affect; South Asian Islam; Hindu nationalism
ID POLITICS; GUJARAT; EMOTION; THUMRI; POETRY; SONG
AB This article examines the affective enactment of the Sufi emotional concept of the pain of separation by Muslim singers in Kachchh, Gujarat, a border region in western India adjacent to Sindh, Pakistan. In a discussion of two musical genres that feature the Sufi poetry of Shah 'Abdul Latif Bhita'i (1689-1752 CE) - kafi and shah jo rag'' - I argue that the musical performance of pain is ethically efficacious as well as politically salient. Drawing on eighteen months of fieldwork in Kachchh in 2014-2018, the article traces the ways in which poetry performers and enthusiasts conceive of musico-poetic pain as a form of Islamic worship that has ethical benefits for performers and listeners, such as tranquility and the purification of one's heart. It thus demonstrates how Sindhi Sufi music functions as an affective, embodied, gendered and vernacular means of engagement with the Islamic discursive tradition. The latter portion of the article widens the focus, taking the pain of separation as a lens through which to examine Hindu-Muslim relations in Kachchh, where Hindu nationalism and Islamic reform have contributed to socio-religious polarisation since the 1980s. Drawing on examples from local musical history, I explore the political salience of the pain of separation by showing how the musical performance of Shah Bhita'i's female-voice poetry historically facilitated interreligious forms of male sociality in Kachchh.
C1 [Bond, Brian E.] Univ Calif Berkeley, Mus, Berkeley, CA 94720 USA.
C3 University of California System; University of California Berkeley
RP Bond, BE (corresponding author), Univ Calif Berkeley, Mus, Berkeley, CA 94720 USA.
EM brian.e.bond@gmail.com
FU Social Science Research Council; American Institute of Pakistan Studies;
   Graduate Center (City University of New York); Woodrow Wilson
   Foundation's Charlotte W. Newcombe Fellowship
FX I am grateful to Nicole Reisnour, Anaar Desai-Stephens, Jim Sykes, Peter
   Manuel, Jane Sugarman, and the two anonymous reviewers for their helpful
   comments on drafts of this essay. All shortcomings are mine. The
   research for this essay was funded by the Social Science Research
   Council, the American Institute of Pakistan Studies, and The Graduate
   Center (City University of New York). I received support while writing
   from the Woodrow Wilson Foundation's Charlotte W. Newcombe Fellowship.
CR Abbas Shemeem Burney, 2002, The female voice in Sufi ritual: devotional practices of Pakistan and India
   Abu-Lughod Lila, 1990, Language and the Politics of Emotion, P1
   Aghaie Kamran Scot, 2004, The martyrs of Karbala: Shi'i symbols and rituals in modern Iran
   Ahmed S, 2016, WHAT IS ISLAM?: THE IMPORTANCE OF BEING ISLAMIC, pCP1, DOI 10.1515/9781400873586
   Ahmed Sara., 2003, CULTURAL POLITICS EM
   [Anonymous], 1988, Unnatural Emotions
   [Anonymous], 2008, S ASIAN STUD-UK
   [Anonymous], 2000, MADHUMALATI INDIAN S
   [Anonymous], 2009, Enchantments of Modernity: Empire, Nation, Globalization
   [Anonymous], 2002, Economic and Political Weekly
   ASAD T., 1993, Genealogies of Religion
   Asad T., 2003, FORMATIONS SECULAR C
   Asad Talal, 2009, Qui Parle, V17, P1
   ASANI AS, 1988, RELIG LIT, V20, P81
   Ayyagari S, 2012, ASIAN MUSIC, V43, P3, DOI 10.1353/amu.2012.0005
   Bahu Sultan, 1998, DEATH DYING SUFI POE
   Bashir Shahzad, 2011, Sufi Bodies: Religion and Society in Medieval Islam
   Bellamy Carla, 2011, POWERFUL EPHEMERAL E
   Bond BE, 2020, ASIAN MUSIC, V51, P39
   Chittick William C., 2013, Divine love: Islamic literature and the path to God
   Chittick William C., 1983, The Sufi path of love: The spiritual teachings of Rumi
   Chittick William C., 2005, Ibn.Arabi: Heir to the prophets
   Du Perron L, 2002, MOD ASIAN STUD, V36, P173, DOI 10.1017/S0026749X02001051
   Elias Jamal J., 2018, ALEF IS ALLAH CHILDH
   Ernst C., 2016, SUFI MARTYRS LOVE CH
   Ernst Carl, 2016, Refractions of Islam in India: Situating Sufism and Yoga
   Flatley Jonathan, 2008, AFFECTIVE MAPPING ME
   GhassemFachandi P, 2012, POGROM IN GUJARAT: HINDU NATIONALISM AND ANTI-MUSLIM VIOLENCE IN INDIA, P1
   Gill Denise, 2017, Melancholic Modalities: Affect, Islam, and Turkish Classical Musicians
   Glucklich A., 2001, Sacred pain: Hurting the body for the sake of the soul
   Gray Lila Ellen, 2013, Fado Resounding: Affective Politices and Urban Life
   Green N, 2004, ASIAN FOLKLORE STUD, V63, P221
   Hardy Friedhelm, 1983, VIRAHA BHAKTI EARLY
   Hawley John, 2005, Three Bhakti Voices: Mirabai, Surdas, and Kabir in Their Time and Ours
   Hirschkind Charles, 2006, The Ethical Soundscape: Cassette Sermons and Islamic Counterpublics
   Hofman Ana., 2015, Musicology, V18, P35
   Hussain F., 1996, SHAH LATIF KI SHAIRI
   Ibrahim F, 2018, S ASIA, V41, P121, DOI 10.1080/00856401.2018.1388948
   Ibrahim Farhana, 2008, SETTLERS SAINTS SOVE
   Jones A, 1998, RUSS EDUC SOC, V40, P3, DOI 10.2753/RES1060-939340013
   Kalyan Advani, 1994, SHAH JO RISALO
   Khan Dominique-Sila, 2004, Crossing the Threshold: Understanding Religious Identities in South Asia
   Levesque J, 2016, ROUTL ADV S ASIAN ST, V31, P212
   Leys R, 2011, CRIT INQUIRY, V37, P434, DOI 10.1086/659353
   LUTZ C, 1986, ANNU REV ANTHROPOL, V15, P405, DOI 10.1146/annurev.an.15.100186.002201
   Mahmood S, 2005, POLITICS OF PIETY: THE ISLAMIC REVIVAL AND THE FEMINIST SUBJECT, P1
   Manuel P, 2008, ETHNOMUSICOLOGY, V52, P378
   Manuel Peter, 1993, Cassette Culture: Popu lar Music and Technology in North India
   Massumi Brian, 2002, PARABLES VIRTUAL
   Ngai Sianne., 2005, Ugly Feelings
   Norris RS, 2009, RELIGION, V39, P22, DOI 10.1016/j.religion.2008.03.007
   Perkins Judith, 2002, SUFFERING SELF PAIN
   Perman T, 2010, ETHNOMUSICOLOGY, V54, P425
   Petievich Carla, 2007, When Men Speak as Women: Vocal Masquerade in Indo-Muslim Poetry
   Plamper Jan., 2017, The History of Emotions: An Introduction
   RAO V, 1990, ECON POLIT WEEKLY, V25, pWS31
   Reisnour N, 2020, CULT THEORY CRIT, V61, P133, DOI 10.1080/14735784.2021.1884987
   Rosenwein Barbara H, 2006, Emotional Communities in the Early Middle Ages
   Schimmel A., 1997, PAIN GRACE STUDY 2 M
   Schimmel Annemarie, 2003, My Soul is a Woman: The Feminine in Islam
   Schmitz S., 2014, FZG-Freiburger Zeitschrift fur GeschlechterStudien, V20, P13, DOI [10.3224/FZG.v20i2.17137, DOI 10.3224/FZG.V20I2.17137, 10.3224/fzg.v20i2.17137]
   Schubel Vernon J., 1993, Religious performance in contemporary Islam: ShiModified Letter Turned Commai devotional rituals in South Asia
   Shani O, 2007, COMMUNALISM, CASTE AND HINDU NATIONALISM: THE VIOLENCE IN GUJARAT, P1, DOI 10.1017/CBO9780511607936
   Sheikh Samira., 2010, Forging a Region: Sultans, Traders, and Pilgrims in Gujarat, 1200-1500
   Simpson E., 2014, The Political Biography of an Earthquake: Aftermath and Amnesia in Gujarat, India
   Simpson E., 2007, MUSLIM SOC W INDIAN
   Spodek H, 2010, MOD ASIAN STUD, V44, P349, DOI 10.1017/S0026749X08003612
   Stokes Martin, 2010, REPUBLIC LOVE CULTUR
   Vaudeville Charlotte, 1986, BARAHMASA INDIAN LIT
   Weidman A., 2006, SINGING CLASSICAL VO
   Werbner Pnina, 2003, Pilgrims of Love: The Anthropology of a Global Sufi Cult
   Wetherell M., 2012, Affect and emotion. A new social science understanding
   White D, 2017, CULT ANTHROPOL, V32, P175, DOI 10.14506/ca32.2.01
   Wolf RK, 2014, VOICE IN THE DRUM: MUSIC, LANGUAGE, AND EMOTION IN ISLAMICATE SOUTH ASIA, P1
NR 74
TC 1
Z9 2
U1 1
U2 1
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1473-5784
EI 1473-5776
J9 CULT THEORY CRIT
JI Cult. Theory Crit.
PD JUL 2
PY 2020
VL 61
IS 2-3
SI SI
BP 112
EP 132
DI 10.1080/14735784.2020.1848602
PG 21
WC Humanities, Multidisciplinary
WE Emerging Sources Citation Index (ESCI)
SC Arts & Humanities - Other Topics
GA RW2WY
UT WOS:000646389600002
DA 2024-01-09
ER

PT J
AU Reschke-Hernández, AE
AF Reschke-Hernandez, Alaine E.
TI The Clinical Practice Model for Persons with Dementia: Application to
   Music Therapy
SO MUSIC THERAPY PERSPECTIVES
LA English
DT Article
DE Alzheimer disease; dementia; clinical education; music therapy
   education; evidence-based practice; models
ID OLDER-ADULTS; ALZHEIMERS-DISEASE; VOCAL RANGE; INTELLIGIBILITY;
   SYMPTOMS; FEELINGS; EMOTION; SPEECH; SYSTEM; YOUNG
AB Currently, no drug can cure or effectively mitigate symptoms for the growing number of individuals who live with Alzheimer's disease and related dementias. As they experience declines in memory, communication, and thinking-symptoms that undermine social initiative, autonomy, and well-being these individuals become increasingly dependent on others. Evidence regarding the benefits of music therapy for persons with dementia is growing. Nonetheless, limitations in existing research have hindered knowledge regarding the use and appropriate application of music as a form of treatment with this population. Ibis article describes the development of the Clinical Practice Model for Persons with Dementia, which provides a theoretical framework to inform evidence-based practice, illustrated here in application to music therapy. Specifically, the model is intended to prompt purposeful application of strategies documented within a broad literature base within 6 thematic areas (Cognition, Attention, Familiarity, Audibility, Structure, and Autonomy); facilitate clinical decision-making and intervention development, including music interventions; and encourage discourse regarding relationships between characteristics of the intervention, the therapist, the person with dementia, and their response to intervention. The model comprises a set of testable assumptions to provide direction for future research and to facilitate the description and investigation of mechanisms underlying behavioral interventions with this population. Although the model is likely to evolve as knowledge is gained, it offers a foundation for holistically considering an individual's needs and strengths, guidance for applying music and nonmusic strategies in evidence-based practice, and direction for future research.
C1 [Reschke-Hernandez, Alaine E.] Univ Kentucky, Lexington, KY 40506 USA.
C3 University of Kentucky
RP Reschke-Hernández, AE (corresponding author), Univ Kentucky, Coll Fine Arts, Sch Mus, 105 Fine Arts Bldg, Lexington, KY 40506 USA.
EM Alaine.ReschkeHernandez@uky.edu
RI Reschke-Hernandez, Alaine E./AET-7051-2022
OI Reschke-Hernandez, Alaine E./0000-0002-1994-1850
FU University of Iowa Office of Outreach and Engagement Community
   Engagement Grant; Council of Graduate Schools National Dissertation
   Award
FX This work was supported by the University of Iowa Office of Outreach and
   Engagement Community Engagement Grant, Dr. Richard and Mrs. Ellen Caplan
   music therapy gift, and the contributors to a University of Iowa
   GOLDRush crowdfunding campaign.This work was completed in partial
   fulfillment of the Doctor of Philosophy degree at the University of
   Iowa, awarded the Spriestersbach Dissertation Prize, and a finalist for
   the Council of Graduate Schools National Dissertation Award. I offer my
   deepest gratitude to my co-chairs Dr. Kate Gfeller and Dr. Daniel Tranel
   and to my committee Dr. Jeremy Manternach, Dr. Jacob Oleson, and Dr.
   Mary Adamek, for their guidance. I also thank Gabriel, Milan, and Zyania
   Hernandez for their love and support and Milan for his helpful advice on
   the appearance of the model.
CR Alzheimer's Association [AA], 2020, HLTH SYST CLIN MANS
   Alzheimers Assoc, 2015, ALZHEIMERS DEMENT, V11, P332, DOI 10.1016/j.jalz.2015.02.003
   American Midwifery Certification Board, 2020, 2020 DEMOGRAPHIC REP
   American Music Therapy Association (AMTA), 2019, 2019 AMTA MEMB SURV
   American Music Therapy Association (AMTA), 2013, PROF COMP
   American Music Therapy Association [AMTA], 2015, REC CONC MUS THER RE
   American Music Therapy Association [AMTA], 2018, COMM ED CLIN TRAIN 2
   Anderson S. W., 2015, NEUROPSYCHOLOGY CORT, P93
   [Anonymous], 2020, ALZHEIMERS DEMENT, V16, P391, DOI 10.1002/alz.12068
   [Anonymous], 2009, OXFORD HDB MUSIC PSY
   Belfi AM, 2016, MEMORY, V24, P979, DOI 10.1080/09658211.2015.1061012
   Belgrave M., 2020, MUSIC THERAPY MULTIC, P115
   Belgrave M, 2009, J MUSIC THER, V46, P132, DOI 10.1093/jmt/46.2.132
   Bellg AJ, 2004, HEALTH PSYCHOL, V23, P443, DOI 10.1037/0278-6133.23.5.443
   Brewster P, 2019, ALZHEIMERS DEMENT, V15, P995, DOI 10.1016/j.jalz.2018.07.221
   Cevasco AM, 2008, MUSIC THER PERSPECT, V26, P4, DOI 10.1093/mtp/26.1.4
   Charles S. T., 2014, HDB EMOTION REGULATI, P203
   Cho HK, 2018, FRONT MED-LAUSANNE, V5, DOI 10.3389/fmed.2018.00279
   Clair AA, 1996, J MUSIC THER, V33, P234, DOI 10.1093/jmt/33.4.234
   Collister LB, 2008, EMPIR MUSICOL REV, V3, P109, DOI 10.18061/1811/34102
   Colwell C., 2018, MUSIC THERAPY INTRO, P103
   Cornwell B., 2016, Handbook of Aging and the Social Sciences, P181
   ENGEL GL, 1980, AM J PSYCHIAT, V137, P535
   Feil N., 2012, VALIDATION BREAKTHRO
   Ferguson SH, 2014, J ACOUST SOC AM, V135, P3570, DOI 10.1121/1.4874596
   Fingerman K., 2013, GERONTOLOGY PERSPECT, P127
   Gfeller K. E., 2008, INTRO MUSIC THERAPY, P41
   GIBBONS AC, 1977, J MUSIC THER, V14, P180, DOI 10.1093/jmt/14.4.180
   Global Council on Brain Health, 2017, BRAIN SOC CONN GCBH
   GREENWALD MA, 1979, J MUSIC THER, V16, P172, DOI 10.1093/jmt/16.4.172
   Groene R, 2001, J MUSIC THER, V38, P36, DOI 10.1093/jmt/38.1.36
   Gross J. J., 1998, Review of General Psychology, V2, P271, DOI [DOI 10.1037/1089-2680.2.3.271, https://doi.org/10.1037/1089-2680.2.3.271]
   Guzmán-Vélez E, 2014, COGN BEHAV NEUROL, V27, P117, DOI 10.1097/WNN.0000000000000020
   Hall G R, 1987, Arch Psychiatr Nurs, V1, P399
   Hanson N, 1996, J MUSIC THER, V33, P93, DOI 10.1093/jmt/33.2.93
   Hanson-Abromeit D, 2015, MUSIC THER PERSPECT, V33, P25, DOI 10.1093/mtp/miu061
   Janata P, 2012, J EXP PSYCHOL GEN, V141, P54, DOI 10.1037/a0024208
   Juslin PN, 2013, PHYS LIFE REV, V10, P235, DOI 10.1016/j.plrev.2013.05.008
   Kitwood TM., 1997, Dementia Reconsidered: The Person Comes First
   Koelsch S, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00110
   Lezak M. D., 2012, NEUROPSYCHOLOGICAL A, P179
   Manly JJ., 2004, CRIT PERSPECT, P95
   Mitchell Gary, 2015, Nurs Stand, V30, P46, DOI 10.7748/ns.30.7.46.s47
   Moreno-Morales C, 2020, FRONT MED-LAUSANNE, V7, DOI 10.3389/fmed.2020.00160
   Nation D. A., 2015, NEUROPSYCHOLOGY CORT, P3
   Online-Utility.org, 2009, TEXT ANALYZER
   Patel AD, 2014, HEARING RES, V308, P98, DOI 10.1016/j.heares.2013.08.011
   Patton MQ., 2015, Qualitative research and evaluation methods
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   POSNER MI, 1990, ANNU REV NEUROSCI, V13, P25, DOI 10.1146/annurev.ne.13.030190.000325
   Raglio A, 2008, ALZ DIS ASSOC DIS, V22, P158, DOI 10.1097/WAD.0b013e3181630b6f
   Reschke-Hernandez A. E., 2020, NOVEL SOCIAL WORK MU
   Reschke-Hernandez A. E., 2019, THESIS U LOWA
   Reschke-Hernández AE, 2020, J ALZHEIMERS DIS, V78, P1019, DOI 10.3233/JAD-200889
   Robb SL, 2018, COMPLEMENT THER MED, V38, P24, DOI 10.1016/j.ctim.2018.02.008
   Sarafino E.P., 2008, HLTH PSYCHOL BIOPSYC, V6th ed.
   Särkämö T, 2014, GERONTOLOGIST, V54, P634, DOI 10.1093/geront/gnt100
   Sheffler J., 2015, NEUROPSYCHOLOGY CORT, P423
   Staedtler AV, 2015, WORLDV EVID-BASED NU, V12, P108, DOI 10.1111/wvn.12086
   Stevens K., 2016, The Oxford handbook of music psychology, V3rd, P19
   Trainor L. J., 2016, OXFORD HDB MUSIC PSY, V2nd, P285
   TRANEL D, 1993, J COGNITIVE NEUROSCI, V5, P79, DOI 10.1162/jocn.1993.5.1.79
   van der Steen JT, 2018, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD003477.pub4
   Whitbourne S. K., 2010, Adult development and aging: biopsychosocial perspectives
   Wilhelm L. A., 2016, THESIS U LOWA
   Witte K., 1987, AM J ALZHEIMERS DIS, P30, DOI [10.1177/153331758700200106, DOI 10.1177/153331758700200106]
   Woods B, 2012, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD005562.pub2
   Yaffe K, 2002, JAMA-J AM MED ASSOC, V287, P2090, DOI 10.1001/jama.287.16.2090
NR 68
TC 2
Z9 2
U1 3
U2 13
PU OXFORD UNIV PRESS INC
PI CARY
PA JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA
SN 0734-6875
EI 2053-7387
J9 MUSIC THER PERSPECT
JI Music Ther. Perspect.
PD FAL
PY 2021
VL 39
IS 2
BP 133
EP 141
DI 10.1093/mtp/miab006
EA MAY 2021
PG 9
WC Rehabilitation
WE Emerging Sources Citation Index (ESCI)
SC Rehabilitation
GA WQ4SC
UT WOS:000713807200004
DA 2024-01-09
ER

PT J
AU Hurley, BK
   Martens, PA
   Janata, P
AF Hurley, Brian K.
   Martens, Peter A.
   Janata, Petr
TI Spontaneous Sensorimotor Coupling With Multipart Music
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-HUMAN PERCEPTION AND PERFORMANCE
LA English
DT Article
DE synchronization; groove; auditory scene; attention; emotion
ID NEURONAL ENTRAINMENT; OBJECT APPEARANCE; METRIC STRUCTURE; MOTOR; BEAT;
   ATTENTION; RESPONSES; RHYTHM; METER; SYNCHRONIZATION
AB Music often evokes spontaneous movements in listeners that are synchronized with the music, a phenomenon that has been characterized as being in "the groove." However, the musical factors that contribute to listeners' initiation of stimulus-coupled action remain unclear. Evidence suggests that newly appearing objects in auditory scenes orient listeners' attention, and that in multipart music, newly appearing instrument or voice parts can engage listeners' attention and elicit arousal. We posit that attentional engagement with music can influence listeners' spontaneous stimulus-coupled movement. Here, 2 experiments-involving participants with and without musical training-tested the effect of staggering instrument entrances across time and varying the number of concurrent instrument parts within novel multipart music on listeners' engagement with the music, as assessed by spontaneous sensorimotor behavior and self-reports. Experiment 1 assessed listeners' moment-to-moment ratings of perceived groove, and Experiment 2 examined their spontaneous tapping and head movements. We found that, for both musically trained and untrained participants, music with more instruments led to higher ratings of perceived groove, and that music with staggered instrument entrances elicited both increased sensorimotor coupling and increased reports of perceived groove. Although untrained participants were more likely to rate music as higher in groove, trained participants showed greater propensity for tapping along, and they did so more accurately. The quality of synchronization of head movements with the music, however, did not differ as a function of training. Our results shed new light on the relationship between complex musical scenes, attention, and spontaneous sensorimotor behavior.
C1 [Hurley, Brian K.; Janata, Petr] Univ Calif Davis, Dept Psychol, Davis, CA 95618 USA.
   [Hurley, Brian K.; Janata, Petr] Univ Calif Davis, Ctr Mind & Brain, Davis, CA 95618 USA.
   [Martens, Peter A.] Texas Tech Univ, Sch Mus, Lubbock, TX 79409 USA.
C3 University of California System; University of California Davis;
   University of California System; University of California Davis; Texas
   Tech University System; Texas Tech University
RP Hurley, BK (corresponding author), Univ Calif Davis, Ctr Mind & Brain, 267 Cousteau Pl, Davis, CA 95618 USA.
EM bkhurley@ucdavis.edu; pjanata@ucdavis.edu
FU Metanexus Institute
FX This work was supported, in part, by a Templeton Advanced Research
   Program grant from the Metanexus Institute to Petr Janata. We thank
   Corey Chomas, Hannah Whiteside, and Daman Preet Pannu for assistance
   with data collection.
CR Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bengtsson SL, 2009, CORTEX, V45, P62, DOI 10.1016/j.cortex.2008.07.002
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   BHARUCHA JJ, 1986, PERCEPT PSYCHOPHYS, V40, P137, DOI 10.3758/BF03203008
   BLAND JM, 1995, BRIT MED J, V310, P446, DOI 10.1136/bmj.310.6977.446
   Brockmole JR, 2005, PSYCHON B REV, V12, P1061, DOI 10.3758/BF03206444
   Burger B, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00183
   Chen JL, 2008, CEREB CORTEX, V18, P2844, DOI 10.1093/cercor/bhn042
   Cole GG, 2010, Q J EXP PSYCHOL, V63, P147, DOI 10.1080/17470210902853522
   Constantino FC, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0046167
   EEROLA T., 2004, MIDI toolbox: MATLAB tools for music research
   Eramudugolla R, 2005, CURR BIOL, V15, P1108, DOI 10.1016/j.cub.2005.05.051
   Fritz JB, 2007, J NEUROPHYSIOL, V98, P2337, DOI 10.1152/jn.00552.2007
   Fujioka T, 2012, J NEUROSCI, V32, P1791, DOI 10.1523/JNEUROSCI.4107-11.2012
   Grahn JA, 2007, J COGNITIVE NEUROSCI, V19, P893, DOI 10.1162/jocn.2007.19.5.893
   Grahn JA, 2009, J NEUROSCI, V29, P7540, DOI 10.1523/JNEUROSCI.2018-08.2009
   Grewe O, 2007, EMOTION, V7, P774, DOI 10.1037/1528-3542.7.4.774
   HURON D, 1992, MUSIC PERCEPT, V10, P83
   Huron David., 2006, SWEET ANTICIPATION M, DOI DOI 10.7551/MITPRESS/6575.001.0001
   Janata P, 2012, J EXP PSYCHOL GEN, V141, P54, DOI 10.1037/a0024208
   Janata P, 2002, COGN AFFECT BEHAV NE, V2, P121, DOI 10.3758/CABN.2.2.121
   JONES MR, 1989, PSYCHOL REV, V96, P459, DOI 10.1037/0033-295X.96.3.459
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Keller Peter E, 2011, Adv Cogn Psychol, V7, P142, DOI 10.2478/v10053-008-0094-0
   Kung SJ, 2011, EXP BRAIN RES, V210, P269, DOI 10.1007/s00221-011-2630-2
   Large EW, 2009, ANN NY ACAD SCI, V1169, P46, DOI 10.1111/j.1749-6632.2009.04550.x
   Large EW, 1999, PSYCHOL REV, V106, P119, DOI 10.1037/0033-295X.106.1.119
   Lenth R. V., 2013, LSMEANS LEAST SQUARE
   London J., 2004, HEARING TIME PSYCHOL, DOI [10.1093/acprof:oso/9780195160819.001.0001, DOI 10.1093/ACPR0F:0S0/9780195160819.001.0001]
   Luck G, 2010, J RES PERS, V44, P714, DOI 10.1016/j.jrp.2010.10.001
   Madison G, 2006, MUSIC PERCEPT, V24, P201, DOI 10.1525/mp.2006.24.2.201
   Madison G, 2011, J EXP PSYCHOL HUMAN, V37, P1578, DOI 10.1037/a0024323
   Martens PA, 2011, MUSIC PERCEPT, V28, P433, DOI 10.1525/MP.2011.28.5.433
   Neuhoff JG, 1998, NATURE, V395, P123, DOI 10.1038/25862
   Nozaradan S, 2012, J NEUROSCI, V32, P17572, DOI 10.1523/JNEUROSCI.3203-12.2012
   Nozaradan S, 2011, J NEUROSCI, V31, P10234, DOI 10.1523/JNEUROSCI.0411-11.2011
   PATTERSON RD, 1994, J ACOUST SOC AM, V96, P1409, DOI 10.1121/1.410285
   Petkov CI, 2004, NAT NEUROSCI, V7, P658, DOI 10.1038/nn1256
   Phillips DP, 2002, HEARING RES, V167, P192, DOI 10.1016/S0378-5955(02)00393-3
   Phillips-Silver J, 2011, NEUROPSYCHOLOGIA, V49, P961, DOI 10.1016/j.neuropsychologia.2011.02.002
   R Core Team, 2018, R: A Language and Environment for Statistical Computing
   Repp BH, 2005, PSYCHON B REV, V12, P969, DOI 10.3758/BF03206433
   Repp BH, 2013, PSYCHON B REV, V20, P403, DOI 10.3758/s13423-012-0371-2
   Snyder JS, 2005, COGNITIVE BRAIN RES, V24, P117, DOI 10.1016/j.cogbrainres.2004.12.014
   Stupacher J, 2013, BRAIN COGNITION, V82, P127, DOI 10.1016/j.bandc.2013.03.003
   Toiviainen P., 2013, MOCAP TOOLBOX MANUAL
   Toiviainen P, 2010, MUSIC PERCEPT, V28, P59, DOI 10.1525/MP.2010.28.1.59
   Tomic ST, 2007, BEHAV RES METHODS, V39, P635, DOI 10.3758/BF03193036
   Tomic ST, 2008, J ACOUST SOC AM, V124, P4024, DOI 10.1121/1.3006382
   Van Dyck E, 2013, MUSIC PERCEPT, V30, P349, DOI 10.1525/MP.2013.30.4.349
   WOLDORFF MG, 1993, P NATL ACAD SCI USA, V90, P8722, DOI 10.1073/pnas.90.18.8722
   Zatorre RJ, 2007, NAT REV NEUROSCI, V8, P547, DOI 10.1038/nrn2152
NR 52
TC 26
Z9 34
U1 0
U2 15
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0096-1523
EI 1939-1277
J9 J EXP PSYCHOL HUMAN
JI J. Exp. Psychol.-Hum. Percept. Perform.
PD AUG
PY 2014
VL 40
IS 4
BP 1679
EP 1696
DI 10.1037/a0037154
PG 18
WC Psychology; Psychology, Experimental
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Psychology
GA AN3FR
UT WOS:000340471300033
PM 24979362
OA Green Submitted
DA 2024-01-09
ER

PT J
AU Huzjak, M
AF Huzjak, Masa
TI Girl spaces: images of girlhood on the internet
SO CULTURAL STUDIES
LA English
DT Article
DE Girlhood; online culture; authenticity; creativity; girls' labour; girl
   spaces
AB When Rookie, a now-defunct online magazine for teenage girls, launched in 2011, it created a safe space for young women and girls to express themselves through any medium they wanted and in a myriad of different ways. Thus images of girlhood ceased to be just a mystery for the male gaze/brain to solve or portray; they became eclectic, bountiful, contradictory even. Furthermore, since 2012 Instagram has played a vital role in the democratization of publishing one's own art to a larger audience. It has combined the broad reach of an extremely popular social network with what were perceived as 'niche' interests - activities done privately (collage making, bullet journaling, diary keeping) or publicly (photography, poetry, music, art) by often self-taught or self-published teenage girls. Artists like Petra Collins and Ashley Armitage are entering mainstream popular culture and changing perspectives on what it means to be a girl, to feel like a girl or to look like a girl. They document girls' bodies, bedrooms, emotions and material belongings, and offer to the consumer of their art these girl spaces for inspection, questioning and identification. Since the internet requires no (straight, white, cis, male) gatekeepers when it comes to creating an identity or curating art, girls' voices are much easier to hear. This is why I chose to analyse a generation of artists who are gaining momentum because of the internet and subverting, as well as reimagining, the patterns and stereotypes created by centuries of men describing girls' narratives as trivial, mundane and irrelevant.
C1 [Huzjak, Masa] Univ Zagreb, Fac Humanities & Social Sci, Dept Comparat Literature, Zagreb, Croatia.
C3 University of Zagreb
RP Huzjak, M (corresponding author), Univ Zagreb, Fac Humanities & Social Sci, Dept Comparat Literature, Zagreb, Croatia.
EM londresletter@gmail.com
CR [Anonymous], 1998, DELINQUENTS DEBUTANT
   [Anonymous], ALL GIRL CULTURE POW
   [Anonymous], 2018, GUARDIAN
   [Anonymous], 1984, GENDER GENERATION YO
   BanetWeiser Sarah, 2011, Mediated Girlhoods: New Explorations of Girls' Media Culture, P277
   Bralts-Kelly, 2018, ROOKIE
   Chesney-Lind M., 2004, All about the girl, P29
   Chew-Bose D., 2017, GIRL TOO MUCH NOT MO
   Collins Peter., 2015, GRAMMATICAL CHANGE E, P1
   Driscoll Catherine, 2002, GIRLS FEMININE ADOLE
   Gay R., 2014, BAD FEMINST, P51
   Gevinson T, 2015, ROOKIE YB 4, P11
   Gevinson T, CUT
   Harris A., 2004, Future Girl: Young Women in the Twenty -First Century
   Heffernan V., 2016, MAGIC LOSS INTERNET
   Holmes S, 2017, CULT STUD, V31, P1, DOI 10.1080/09502386.2016.1138978
   Hudson Barbara., 1984, Gender and Generation, P31
   Johnson K., 2018, ROOKIE
   Kearney Mary Celeste, 2006, GIRLS MAKE MEDIA
   Kraus Chris, 2016, I Love Dick
   MacCabe Colin, 2018, BISEXUALITY THEORIES, pix, DOI DOI 10.1007/978-3-319-71535-3
   McRobbie A, 2008, CULT STUD, V22, P531, DOI 10.1080/09502380802245803
   McRobbie Angela., 2000, FEMINISM YOUTH CULTU, V2nd
   Orgad S, 2005, FEM MEDIA STUD, V5, P141, DOI 10.1080/14680770500111980
   Solnit R., 2014, Men Explain Things to Me
   Swindle M., 2011, RHIZOMES
   Taft J. K., 2004, ALL GIRL CULTURE POW, P69
   Thornham S, 2009, MEDIA STUDIES READER, P124, DOI [10.3366/j.ctvxcrv1h.18, DOI 10.3366/J.CTVXCRV1H.18]
   Tunnicliffe Ava., 2015, NYLON
   VICELAND, 2018, TAK BACK WHATS OURS
   Zambreno K., 2012, Heroines
NR 31
TC 0
Z9 0
U1 3
U2 5
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 0950-2386
EI 1466-4348
J9 CULT STUD
JI Cult. Stud.
PD SEP 3
PY 2022
VL 36
IS 5
SI SI
BP 732
EP 747
DI 10.1080/09502386.2021.2011931
EA DEC 2021
PG 16
WC Anthropology; Cultural Studies
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Anthropology; Cultural Studies
GA 3P9XA
UT WOS:000732566100001
DA 2024-01-09
ER

PT J
AU Reuther, N
AF Reuther, Nina
TI 'As long as we Dance and Sing we Will Stay Alive': Indigenous North
   American Resistance against Assimilation through Song and Dance
SO COMPARATIVE AMERICAN STUDIES
LA English
DT Article
DE Song and dance; assimilation policies; Indigenous North American
   Resistance; ownership and access right systems to song and dance;
   Religious Crimes Code; Indian Act; Ghost Dance; Wild West Shows;
   contemporary North American Indigenous performers; Indian
   Boarding/Residential Schools
AB In Indigenous American culture singing and dancing hold a central position within the passing on of cultural knowledge from generation to generation. The beat links the people to the earth, the sound to the surroundings. Song and dance express commonly shared emotions and connect the people in the present to the past and to the future. This article focuses on how the colonisation of North America by the settlers has been mirrored, articulated and dealt with through a system of "singing memory" by its original peoples. Contemporary Indigenous musicians are using a combination of present and traditional expressions for voicing out their way of dealing with that impact. The article addresses first aspects of the traditional characteristics of North American Indigenous ways of translating cultural knowledge through song and dance; second draws a historical overview of how changes have been interpreted through this way of expression and under the impact of paradoxical interest by the settlers; and third presents some contemporary musical examples of articulating these experiences. The information is mainly based on personal fieldwork and interviews with contemporary North American Indigenous musicians, reflecting the orally transmitted Indigenous historical perspectives of the issue, as well as on archival research documenting mainly the settler perspective of the question.
C1 [Reuther, Nina] Seetrasse 38, CH-8267 Berlingen, Switzerland.
RP Reuther, N (corresponding author), Seetrasse 38, CH-8267 Berlingen, Switzerland.
EM kontakt@ninareuther.eu
CR [Anonymous], 1907, Games of the North American Indians
   [Anonymous], 1968, FOLK SONG STYLE CULT
   [Anonymous], 2002, Heartbeat of the People: Music and Dance of the Northern Pow-Wow
   [Anonymous], 1985, Canadian University Music Review / Revue de musique des universites canadiennes
   [Anonymous], 2020, OFF STAT CONTR FILM
   Borrows John, 2001, OSGOODE HALL LAW J, V39, P1
   Brown, 1987, BURY MY HEART WOUNDE
   Ellis Clyde, 2003, A Dancing People: Powwow Culture on the Southern Plains
   Frank Waln, 2015, WHAT MAD RED MAN RED
   Glaz A, 2022, ROUTL STUD LINGUIST, P1, DOI 10.4324/9781003018803
   Haig-Brown Celia, 1988, RESISTANCE RENEWAL S
   Hanson E, 2020, The residential school system
   Herzog G, 1935, AM ANTHROPOL, V37, P403, DOI 10.1525/aa.1935.37.3.02a00040
   Hungry Wolf A., 1999, POW WOW DANCERS CRAF
   Joe, 2019, AVENUE MAGAZINE 0614
   Johnson T., 2017, RUMBLE INDIANS WHO R
   Kolstee A.F., 1988, IMPERSONATE SUPERNAT
   Kr?ger G, 2002, ETHNOLOGIE SPORT BEI, V14, P187
   Laforet A, 1981, SONGS INDIANS BRIT C
   Lill J.R., FRIENDS INDIAN THEY
   Native American Netroots, 2011, IND 101 POWW
   Native Americans in Philanthropy and Candid, 2021, BOARD SCH LAND ALL E
   Nisga'a Lisims Government, 2021, AD STOR
   PIQSIQ, 2019, QIM DOGSL RID QUV ME
   Reuther N., 2007, THESIS U STRASBOURG
   Reuther N., 1993, THESIS U PARIS 10 NA
   Reuther N., 1992, BONEGAME SECWEPEMC
   Smoak GE, 2006, GHOST DANCES AND IDENTITY: PROPHETIC RELIGION AND AMERICAN INDIAN ETHNOGENESIS IN THE NINETEENTH CENTURY, P1
   Supaman, 2018, PRAYER LOOP SONG
   Supreme Court of Canada, 1997, DELG V BRIT COL
   Teit, 1912, WAX CYLINDER R UNPUB
   The National Native American Boarding School Healing Commission, 2021, US IND BOARD SCH HIS
   Troutman John William, 2012, Indian Blues: American Indians and the Politics of Music, 1879- 1934
   ULALI, 1998, ALL MY REL
   Venne S.H., 1981, INDIAN ACTS AMENDEME
   Von Hornbostel E.M., 1906, REPRINT F BOAS MEMOR, P447
   Whorf B. L., 1956, Language, thought, and reality: selected writings of Benjamin Lee Whorf
NR 37
TC 0
Z9 0
U1 0
U2 3
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1477-5700
EI 1741-2676
J9 COMP AM STUD
JI Comp. American Studies
PD JUL 3
PY 2021
VL 18
IS 3
SI SI
BP 397
EP 412
DI 10.1080/14775700.2021.2008224
EA DEC 2021
PG 16
WC Humanities, Multidisciplinary
WE Emerging Sources Citation Index (ESCI)
SC Arts & Humanities - Other Topics
GA YK7HW
UT WOS:000724600900001
DA 2024-01-09
ER

PT J
AU Tanveer, M
   Rastogi, A
   Paliwal, V
   Ganaie, MA
   Malik, AK
   Del Ser, J
   Lin, CT
AF Tanveer, M.
   Rastogi, Aryan
   Paliwal, Vardhan
   Ganaie, M. A.
   Malik, A. K.
   Del Ser, Javier
   Lin, Chin-Teng
TI Ensemble deep learning in speech signal tasks: A review
SO NEUROCOMPUTING
LA English
DT Review
DE Deep learning; Ensemble deep learning; Speech signal; Speech
   recognition; Speech enhancement
ID EMOTION RECOGNITION; NEURAL-NETWORKS; GENDER RECOGNITION; ENHANCEMENT;
   SEPARATION; CLASSIFICATION; INFORMATION; ALGORITHM; FUTURE; AGE
AB Machine learning methods are extensively used for processing and analysing speech signals by virtue of their performance gains over multiple domains. Deep learning and ensemble learning are the two most commonly used techniques, which results in benchmark performance across different downstream tasks. Ensemble deep learning is a recent development which combines these two techniques to result in a robust architecture having substantial performance gains, as well as better generalization performance over the individual techniques. In this paper, we extensively review the use of ensemble deep learning methods for different speech signal related tasks, ranging from general objectives such as automatic speech recognition and voice activity detection, to more specific areas such as biomedical applications involving the detection of pathological speech or music genre detection. We provide a discussion on the use of different ensemble strategies such as bagging, boosting and stacking in the context of speech signals, and identify the various salient features and advantages from a broader perspective when coupled with deep learning architectures. The main objective of this study is to comprehensively evaluate existing works in the area of ensemble deep learning, and highlight the future directions that may be explored to further develop it as a tool for several speech related tasks. To the best of our knowledge, this is the first review study which primarily focuses on ensemble deep learning for speech applications. This study aims to serve as a valuable resource for researchers in academia and in industry working with speech signals, supporting advanced novel applications of ensemble deep learning models towards solving challenges in existing speech processing systems.& COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Tanveer, M.; Malik, A. K.] Indian Inst Technol Indore, Dept Math, Indore, Madhya Pradesh, India.
   [Rastogi, Aryan; Paliwal, Vardhan] Indian Inst Technol Indore, Dept Elect Engn, Indore, Madhya Pradesh, India.
   [Ganaie, M. A.] Univ Michigan, Dept Robot, Ann Arbor, MI USA.
   [Del Ser, Javier] TECNALIA, Basque Res & Technol Alliance BRTA, Derio, Spain.
   [Del Ser, Javier] Univ Basque Country UPV EHU, Bilbao, Spain.
   [Lin, Chin-Teng] Univ Technol Sydney, Human Centr AI Ctr, Sch Comp Sci, Sydney, Australia.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Indore; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Indore; University of
   Michigan System; University of Michigan; University of Basque Country;
   University of Technology Sydney
RP Tanveer, M (corresponding author), Indian Inst Technol Indore, Dept Math, Indore, Madhya Pradesh, India.
EM mtanveer@iiti.ac.in; ee190002007@iiti.ac.in; ee190002065@iiti.ac.in;
   mudasirg@umich.edu; phd1801241003@iiti.ac.in;
   javier.delser@tecnalia.com; China-Teng.Lin@uts.edu.au
RI Lin, Chin-Teng (CT)/G-8129-2017
OI Lin, Chin-Teng (CT)/0000-0001-8371-8197
FU National Supercomputing Mission under Department of Science and
   Technology (DST) and MeitY, Govt. of India
   [DST/NSM/R&D_HPC_Appl/2021/03. 29]; DST under Interdisciplinary Cyber
   Physical Systems (ICPS) Scheme [DST/ICPS/CPS-Individual/2018/276]; DST
   under FIST Scheme [SR/FST/MS-I/2018/26]; Department of Education of the
   Basque Government via the Consolidated Research Group MATHMODE
   [IT1456-22]
FX This work is supported by National Supercomputing Mission under
   Department of Science and Technology (DST) and MeitY, Govt. of India
   under Grant No. DST/NSM/R&D_HPC_Appl/2021/03. 29, DST under
   Interdisciplinary Cyber Physical Systems (ICPS) Scheme Grant No.
   DST/ICPS/CPS-Individual/2018/276 and DST under FIST Scheme Grant No.
   SR/FST/MS-I/2018/26. J. Del Ser also acknowledges support from the
   Department of Education of the Basque Government via the Consolidated
   Research Group MATHMODE (IT1456-22).
CR Abbaschian BJ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041249
   Algihab W, 2019, LECT NOTES COMPUT SC, V11578, P15, DOI 10.1007/978-3-030-21902-4_2
   Azarang A, 2020, SPEECH COMMUN, V122, P1, DOI 10.1016/j.specom.2020.04.002
   Bai ZX, 2021, NEURAL NETWORKS, V140, P65, DOI 10.1016/j.neunet.2021.03.004
   Basu S, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P109, DOI 10.1109/ICICCT.2017.7975169
   Bengio Y., 2006, Advances in neural information processing systems, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Bhangale KB, 2022, WIRELESS PERS COMMUN, V125, P1913, DOI 10.1007/s11277-022-09640-y
   Bhangdia Yashwardhan, 2021, 2021 Third International Conference on Inventive Research in Computing Applications (ICIRCA), P96, DOI 10.1109/ICIRCA51532.2021.9544671
   Bird JJ, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P554, DOI 10.1145/3316782.3322780
   Bocklet T, 2008, INT CONF ACOUST SPEE, P1605, DOI 10.1109/ICASSP.2008.4517932
   Bourlard H, 2011, SADHANA-ACAD P ENG S, V36, P885, DOI 10.1007/s12046-011-0050-4
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655
   Buza O, 2006, 2006 IEEE-TTTC INTERNATIONAL CONFERENCE ON AUTOMATION, QUALITY AND TESTING, ROBOTICS, VOL 2, PROCEEDINGS, P360
   Caglayan O, 2019, INT CONF ACOUST SPEE, P8648, DOI 10.1109/ICASSP.2019.8682750
   Cao Y, 2020, NAT MACH INTELL, V2, P500, DOI 10.1038/s42256-020-0217-y
   Chelba C, 2008, IEEE SIGNAL PROC MAG, V25, P39, DOI 10.1109/MSP.200S.917992
   Chen H, 2021, IEEE ACCESS, V9, P28729, DOI 10.1109/ACCESS.2021.3057382
   Chen M, 2020, INTERSPEECH, P374, DOI 10.21437/Interspeech.2020-3156
   Cheng WX, 2021, APPL SOFT COMPUT, V112, DOI 10.1016/j.asoc.2021.107826
   Childers D, 1998, IEEE SIGNAL PROC MAG, V15, P24, DOI 10.1109/79.671130
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Cummins N, 2018, METHODS, V151, P41, DOI 10.1016/j.ymeth.2018.07.007
   Daubener S., ARXIV
   de Lope J, NEUROCOMPUTING
   Deng Li, 2014, 15 ANN C INT SPEECH
   Deng L, 2013, IEEE INT NEW CIRC
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   DIRKS DD, 1982, J SPEECH HEAR DISORD, V47, P114, DOI 10.1044/jshd.4702.114
   Dua M, 2022, J AMB INTEL HUM COMP, V13, P1985, DOI 10.1007/s12652-021-02960-0
   Dwivedi S, 2004, RO-MAN 2004: 13TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P601, DOI 10.1109/ROMAN.2004.1374829
   Fahad Md Shah, 2022, Security, Privacy and Data Analytics: Select Proceedings of ISPDA 2021. Lecture Notes in Electrical Engineering (848), P155, DOI 10.1007/978-981-16-9089-1_13
   Ferragne E., 2019, PHONETIC INTERPRETAB
   Fragopanagos N, 2005, NEURAL NETWORKS, V18, P389, DOI 10.1016/j.neunet.2005.03.006
   Fredouille C., 2005, INTERSPEECH, P149
   Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P148
   Ganaie MA, 2022, ENG APPL ARTIF INTEL, V115, DOI 10.1016/j.engappai.2022.105151
   Ganaie M A, 2022, IEEE/ACM Trans Comput Biol Bioinform, VPP, DOI 10.1109/TCBB.2022.3170351
   Gao T, 2017, SPEECH COMMUN, V95, P28, DOI 10.1016/j.specom.2017.10.003
   Garain A, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114416
   Gawlikowski J., 2021, A survey of uncertainty in deep neural networks
   Ghosal D, 2018, INTERSPEECH, P2087
   Granitto PM, 2005, ARTIF INTELL, V163, P139, DOI 10.1016/j.artint.2004.09.006
   Hao M, 2020, NEUROCOMPUTING, V391, P42, DOI 10.1016/j.neucom.2020.01.048
   Hara K, 2016, LECT NOTES COMPUT SC, V9887, P72, DOI 10.1007/978-3-319-44781-0_9
   Harimi A, 2015, APPL ARTIF INTELL, V29, P675, DOI 10.1080/08839514.2015.1051891
   Hassan A, 2020, PRO BIENN BALT EL C, DOI 10.1109/bec49624.2020.9276993
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423
   Hires M, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105021
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Horng WB, 2001, Tamkang Journal of Science and Engineering, V4, P183, DOI DOI 10.6180/JASE.2001.4.3.05
   Hsu C, 2016, Final Report, DOI DOI 10.1109/APSIPA.2016.7820786
   Hsu JH, 2021, IEEE-ACM T AUDIO SPE, V29, P1675, DOI 10.1109/TASLP.2021.3076364
   Huang Y, 2016, COMM COM INF SC, V663, P721, DOI 10.1007/978-981-10-3005-5_59
   Humayun MA, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9091956
   ITAKURA F, 1975, J ACOUST SOC AM, V57, pS35, DOI 10.1121/1.1995189
   Jo T, 2019, FRONT AGING NEUROSCI, V11, DOI 10.3389/fnagi.2019.00220
   Ju C, 2018, J APPL STAT, V45, P2800, DOI 10.1080/02664763.2018.1441383
   Khalil RA, 2019, IEEE ACCESS, V7, P117327, DOI 10.1109/ACCESS.2019.2936124
   Kim J, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1006, DOI 10.1145/3123266.3123353
   Kim J, 2015, ICMSCE 2018: PROCEEDINGS OF THE 2018 2ND INTERNATIONAL CONFERENCE ON MECHATRONICS SYSTEMS AND CONTROL ENGINEERING, P98, DOI 10.1145/3185066.3185086
   Koumparoulis A, 2020, INTERSPEECH, P3510, DOI 10.21437/Interspeech.2020-3003
   Krishnakumar H., 2019, 2019 IEEE GLOB C SIG, P1
   Kumar Akshi, 2018, 2018 International Conference on Advances in Computing, Communication Control and Networking (ICACCCN). Proceedings, P179, DOI 10.1109/ICACCCN.2018.8748399
   Lakshminarayanan B., ADV NEURAL INFORM PR, V30
   Latif S, 2023, IEEE T AFFECT COMPUT, V14, P1634, DOI 10.1109/TAFFC.2021.3114365
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee HY, 2013, INTERSPEECH, P215
   Lee Stefan, 2016, NIPS
   Li JG, 2020, INT CONF ACOUST SPEE, P2937, DOI [10.1109/ICASSP40776.2020.9053058, 10.1109/icassp40776.2020.9053058]
   Lin YY, 2020, 2020 2ND IEEE INTERNATIONAL WORKSHOP ON SYSTEM BIOLOGY AND BIOMEDICAL SYSTEMS (SBBS), DOI 10.1109/SBBS50483.2020.9314946
   Liu B, 2018, IEEE IJCNN
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Liu Y, 1999, NEURAL NETWORKS, V12, P1399, DOI 10.1016/S0893-6080(99)00073-8
   Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391
   Logan B., 2000, Mel frequency cepstral coefficients for music modeling
   Lu XG, 2014, INTERSPEECH, P885
   Lu XG, 2013, INTERSPEECH, P436
   Luo DQ, 2017, ASIAPAC SIGN INFO PR, P1351, DOI 10.1109/APSIPA.2017.8282242
   Ma J, 2021, BIOMED SIGNAL PROCES, V69, DOI 10.1016/j.bspc.2021.102849
   Malik AK, 2023, Arxiv, DOI arXiv:2203.11316
   Malik A.K., 2022, IEEE ACM T COMPUTATI, P1, DOI [10.1109/TCBB.2022.3202707, DOI 10.1109/TCBB.2022.3202707]
   Malik M, 2021, MULTIMED TOOLS APPL, V80, P9411, DOI 10.1007/s11042-020-10073-7
   Metze F, 2007, INT CONF ACOUST SPEE, P1089
   Milton A., INT J COMPUTER APPL, V69
   Mirsamadi S, 2017, INT CONF ACOUST SPEE, P2227, DOI 10.1109/ICASSP.2017.7952552
   MOHR B, 1971, PHONETICA, V23, P65, DOI 10.1159/000259332
   Moller C, 2006, 9 INT C SPOKEN LANGU
   Nagpal K, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0112-2
   Nanni L, 2018, J NEW MUSIC RES, V47, P383, DOI 10.1080/09298215.2018.1438476
   Nassif AB, 2019, IEEE ACCESS, V7, P19143, DOI 10.1109/ACCESS.2019.2896880
   Nevo S., ARXIV
   Pham NQ, 2019, INTERSPEECH, P66, DOI 10.21437/Interspeech.2019-2702
   Nishikawa K., 2022, COGNITIVE ROBOTICS, V2, P21, DOI [10.1016/j.cogr.2021.12.003, DOI 10.1016/J.COGR.2021.12.003]
   Padmanabhan J, 2015, IETE TECH REV, V32, P240, DOI 10.1080/02564602.2015.1010611
   Park TJ, 2022, COMPUT SPEECH LANG, V72, DOI 10.1016/j.csl.2021.101317
   Petrushin V.A., 2000, 6 INT C SPOK LANG PR
   Po-Sen Huang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P205, DOI 10.1109/ICASSP.2014.6853587
   Povey D, 2002, INT CONF ACOUST SPEE, P105
   Prasetio BH, 2018, 2018 INTERNATIONAL WORKSHOP ON BIG DATA AND INFORMATION SECURITY (IWBIS), P57, DOI 10.1109/IWBIS.2018.8471698
   Praveen K, 2021, IEEE W SP LANG TECH, P111, DOI 10.1109/SLT48900.2021.9383463
   Rajendran S, 2021, INT J SPEECH TECHNOL, V24, P625, DOI 10.1007/s10772-021-09838-8
   Rebai I, 2017, PROCEDIA COMPUT SCI, V112, P316, DOI 10.1016/j.procs.2017.08.003
   Ren Y, 2016, IEEE COMPUT INTELL M, V11, P41, DOI 10.1109/MCI.2015.2471235
   Reynolds DA, 2002, INT CONF ACOUST SPEE, P4072
   Ritwik K.V.S., ARXIV
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sabour S., ADV NEURAL INFORM PR, V30
   Sagi O, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1249
   Sailor HB, 2016, IEEE-ACM T AUDIO SPE, V24, P2341, DOI 10.1109/TASLP.2016.2607341
   Schapire RE, 2003, LECT NOTES STAT, V171, P149, DOI 10.1007/978-0-387-21579-2_9
   Schapire RE, 1998, ANN STAT, V26, P1651
   Sharma R, 2021, APPL SOFT COMPUT, V106, DOI 10.1016/j.asoc.2021.107371
   Shchetinin E.Y, 2020, J PHYS C SERIES, V1703
   Shewalkar A, 2019, J ARTIF INTELL SOFT, V9, P235, DOI 10.2478/jaiscr-2019-0006
   Shi QS, 2021, PATTERN RECOGN, V117, DOI 10.1016/j.patcog.2021.107978
   Shi XJ, 2015, ADV NEUR IN, V28
   Shorfuzzaman M, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3469841
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Siohan O, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P589, DOI 10.1109/ASRU.2015.7404849
   Sun L, 2019, IEEE J-STSP, V13, P827, DOI 10.1109/JSTSP.2019.2920764
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tamati TN, 2013, J AM ACAD AUDIOL, V24, P616, DOI 10.3766/jaaa.24.7.10
   Tao F, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6209, DOI 10.1109/ICASSP.2018.8461617
   Teh YW, 2001, ADV NEUR IN, V13, P908
   Tsanas A, 2012, IEEE T BIO-MED ENG, V59, P1264, DOI 10.1109/TBME.2012.2183367
   Tu YH, 2019, SPEECH COMMUN, V106, P31, DOI 10.1016/j.specom.2018.11.005
   Tu YH, 2017, INTERSPEECH, P394, DOI 10.21437/Interspeech.2017-853
   Valles D, 2021, 2021 IEEE WORLD AI IOT CONGRESS (AIIOT), P55, DOI [10.1109/AIIOT52608.2021.9454174, 10.1109/AIIoT52608.2021.9454174]
   Vaswani A., 2017, P ADV NEUR INF PROC, P6000
   Vavrek L, 2021, 2021 IEEE 19TH WORLD SYMPOSIUM ON APPLIED MACHINE INTELLIGENCE AND INFORMATICS (SAMI 2021), P245, DOI 10.1109/SAMI50585.2021.9378656
   Vincent P., 2008, PROC 25 INT C MACH L, P1096, DOI [DOI 10.1145/1390156.1390294, 10.1145/1390156.1390294]
   Waibel A, 2008, IEEE SIGNAL PROC MAG, V25, P70, DOI 10.1109/MSP.2008.918415
   Wan ZT, 2022, NEUROCOMPUTING, V482, P186, DOI 10.1016/j.neucom.2021.11.039
   Wan ZT, 2021, NEUROCOMPUTING, V421, P1
   Wang DL, 2018, IEEE-ACM T AUDIO SPE, V26, P1702, DOI 10.1109/TASLP.2018.2842159
   Wang X, 2021, NEUROCOMPUTING, V437, P131, DOI 10.1016/j.neucom.2021.01.056
   Wani TM, 2021, IEEE ACCESS, V9, P47795, DOI 10.1109/ACCESS.2021.3068045
   Wasay A., RAPID TRAINING VERY
   Wei W, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/7696035
   Wen GH, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/1945630
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Wu H., ACM T MULTIM COMPUT, V13
   Yang AYQ, 2020, MULTIMED TOOLS APPL, V79, P18767, DOI 10.1007/s11042-020-08746-4
   You SD, 2018, HUM-CENT COMPUT INFO, V8, DOI 10.1186/s13673-018-0158-1
   Youhao Yu, 2012, Proceedings of the 2012 International Conference on Computer Science and Electronics Engineering (ICCSEE 2012), P306, DOI 10.1109/ICCSEE.2012.359
   Yu C, 2020, IEEE-ACM T AUDIO SPE, V28, P2756, DOI 10.1109/TASLP.2020.3025638
   Yu D, 2015, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-4471-5779-3
   Zagagy Ben, 2020, Intelligent Computing. Proceedings of the 2020 Computing Conference. Advances in Intelligent Systems and Computing (AISC 1229), P214, DOI 10.1007/978-3-030-52246-9_15
   Zeng NY, 2018, NEUROCOMPUTING, V320, P195, DOI 10.1016/j.neucom.2018.09.001
   Zhang L, 2022, APPL SOFT COMPUT, V116, DOI 10.1016/j.asoc.2021.108322
   Zhang W, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3292059
   Zhang X.-L., 2014, 15 ANN C INT SPEECH
   Zhang XL, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1745
   Zhang XL, 2016, IEEE-ACM T AUDIO SPE, V24, P252, DOI 10.1109/TASLP.2015.2505415
   Zhang Yi, 2021, Sheng Wu Yi Xue Gong Cheng Xue Za Zhi, V38, P655, DOI 10.7507/1001-5515.202010050
   Zhang Z, 2020, APPL THERM ENG, V164, DOI 10.1016/j.applthermaleng.2019.114516
   Zhang ZX, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3178115
   Zheng CJ, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010205
   Zhou ZH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3553
NR 161
TC 1
Z9 1
U1 20
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD SEP 14
PY 2023
VL 550
AR 126436
DI 10.1016/j.neucom.2023.126436
EA JUN 2023
PG 18
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA N1RH4
UT WOS:001034862800001
DA 2024-01-09
ER

PT J
AU Epstein, S
   Elefant, C
   Thompson, G
AF Epstein, Shulamit
   Elefant, Cochavit
   Thompson, Grace
TI Music Therapists' Perceptions of the Therapeutic Potentials Using Music
   When Working With Verbal Children on the Autism Spectrum: A Qualitative
   Analysis
SO JOURNAL OF MUSIC THERAPY
LA English
DT Article
DE autism spectrum; music therapy; verbal language; children
ID DISORDER; PEOPLE
AB While there are numerous descriptions of the use of music and its therapeutic potential by music therapists working with nonverbal children on the autism spectrum, only limited literature focuses on exploring how music therapists use music and perceive its therapeutic potential when working with children on the spectrum who have verbal skills. This qualitative study aimed to explore music therapists' descriptions of the use of music and its therapeutic potential in their work with children on the autism spectrum who have verbal skills. Semi-structured interviews were conducted with six qualified music therapists from Israel and then analyzed according to the principles of interpretative phenomenological analysis (IPA). Three main themes were identified: (a) musical infrastructure, which describes how the music therapists facilitated musical experiences to support the children's ability to regulate their arousal, attention and emotions; (b) the meeting point between musical and verbal playfulness, which reflects the music therapists' beliefs about how musical experiences add vitality and support the development of both verbal and nonverbal imaginative play; and (c) musical responses, which describes the different ways music therapists use their voice and songs to interact musically with verbal children. The experiences described by the participants emphasize the importance of the therapist musically attuning to the child's emotional, physiological, creative, and playful qualities, even when the child has verbal skills. These musical interactions help to create a shared experience between the child and therapist that are perceived to help the child's different forms of regulation, continuity, and vitality within the play.
C1 [Epstein, Shulamit; Elefant, Cochavit] Univ Haifa, Sch Creat Arts Therapies, Haifa, Israel.
   [Epstein, Shulamit] Levinsky Coll Educ, Tel Aviv, Israel.
   [Thompson, Grace] Univ Melbourne, Melbourne Conservatorium Mus, Melbourne, Vic, Australia.
C3 University of Haifa; University of Melbourne
RP Epstein, S (corresponding author), Kehilat Warsha 19b-10, Tel Aviv, Israel.
EM shushuq@gmail.com
OI Thompson, Grace/0000-0002-7501-5325
CR American Psychiatric Association, 2000, Text revision (DSM-IV-TR), DOI [10.1176/dsm10.1176/appi.books.9780890420249.dsm-iv-tr, DOI 10.1176/DSM10.1176/APPI.BOOKS.9780890420249.DSM-IV-TR]
   Ammaniti M, 2013, INFANT MENT HEALTH J, V34, P367, DOI 10.1002/imhj.21405
   [Anonymous], J BRIT MUSIC THERAPY, DOI DOI 10.1177/135945759400800105
   [Anonymous], 2001, BEING ALIVE BUILDING
   [Anonymous], 2009, Communicative Musicality, DOI [10.1016/B978-0-12-374370-1.X0001-8, DOI 10.1016/B978-0-12-374370-1.X0001-8]
   Association A. P., 2013, DIAGN STAT MAN MENT, DOI [10.1176/appi.books.9780890425596, DOI 10.1176/APPI.BOOKS.9780890425596]
   Baker F, 2009, NORD J MUSIC THER, V18, P32, DOI 10.1080/08098130802496373
   Bieleninik L, 2017, JAMA-J AM MED ASSOC, V318, P525, DOI 10.1001/jama.2017.9478
   Carpente JA, 2017, MUSIC THER PERSPECT, V35, P160, DOI 10.1093/mtp/miw013
   Critchley HD, 2000, BRAIN, V123, P2203, DOI 10.1093/brain/123.11.2203
   Geretsegger M, 2015, J MUSIC THER, V52, P258, DOI 10.1093/jmt/thv005
   Gold C, 2006, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD004381.pub2
   Greenspan S.I., 2006, Engaging autism: Using the Floortime approach to help children relate and think
   Grzadzinski R, 2013, MOL AUTISM, V4, DOI 10.1186/2040-2392-4-12
   Josephson I., 2016, THESIS
   Kim J, 2009, AUTISM, V13, P389, DOI 10.1177/1362361309105660
   Kvale S., 2007, Doing Interviews, DOI DOI 10.4135/9781849208963
   LINCOLN AJ, 1988, J AUTISM DEV DISORD, V18, P505, DOI 10.1007/BF02211870
   Marco EJ, 2011, PEDIATR RES, V69, p48R, DOI [10.1203/PDR.0b013e3182130c54, 10.1109/SPL.2011.5782616]
   Mössler K, 2019, J AUTISM DEV DISORD, V49, P2795, DOI 10.1007/s10803-017-3306-y
   Oldfield A., 2005, SONGWRITING METHODS, P24
   Pasiali V., 2004, MUSIC THER PERSPECT, V22, P11, DOI [DOI 10.1093/MTP/22.1.11, 10.1093/mtp/22.1.11]]
   Rao PA, 2008, J AUTISM DEV DISORD, V38, P353, DOI 10.1007/s10803-007-0402-4
   Salomon-Gimmon M, 2019, NORD J MUSIC THER, V28, P174, DOI 10.1080/08098131.2018.1529698
   Schumacher K., 2008, SYNCHRONISATION DVD
   Schumacher K., 2007, KINDERMUSIKTHERAPIE, P27
   Schumacher K., 2007, MICROANALYSIS MUSIC, P79
   Simpson K, 2011, J AUTISM DEV DISORD, V41, P1507, DOI 10.1007/s10803-010-1172-y
   Smith J., 2009, Interpretative phenomenological analysis: Theory, Method and research, DOI DOI 10.1080/14780880903340091
   Smith JA., 2003, The sage handbook of qualitative research in psychology, P51, DOI [DOI 10.4135/9781848607927, DOI 10.1037/13620-005]
   Stern D, 2010, NORD J MUSIC THER, V19, P88, DOI 10.1080/08098131.2010.497634
   Stern DN, 1985, The interpersonal world of the infant
   Stige B, 2009, QUAL HEALTH RES, V19, P1504, DOI 10.1177/1049732309348501
   Thompson GA, 2014, CHILD CARE HLTH DEV, V40, P840, DOI 10.1111/cch.12121
   Thompson GA, 2019, NORD J MUSIC THER, V28, P347, DOI 10.1080/08098131.2019.1605616
   Thompson I, 2018, TLS-TIMES LIT SUPPL, P31
   Tong A, 2007, INT J QUAL HEALTH C, V19, P349, DOI 10.1093/intqhc/mzm042
   Trondalen G., 2016, Relational Music Therapy: An Intersubjective Perspective
   Wigram~ T, 2009, COMMUNICATIVE MUSICA, P423
NR 39
TC 7
Z9 11
U1 0
U2 31
PU OXFORD UNIV PRESS INC
PI CARY
PA JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA
SN 0022-2917
EI 2053-7395
J9 J MUSIC THER
JI J. Music Ther.
PD SPR
PY 2020
VL 57
IS 1
BP 66
EP 90
DI 10.1093/jmt/thz017
PG 25
WC Music; Rehabilitation
WE Social Science Citation Index (SSCI)
SC Music; Rehabilitation
GA LD2JO
UT WOS:000525858200004
PM 31815286
DA 2024-01-09
ER

PT J
AU Andrushchenko, EY
   Andrievskaya, GP
AF Andrushchenko, Elena Yu
   Andrievskaya, Galina P.
TI Performing Art of Maria Gay: Following the Pages of Russian Musical
   Criticism and Memoiristics
SO PROBLEMY MUZYKALNOI NAUKI-MUSIC SCHOLARSHIP
LA Russian
DT Article
DE operatic-theatrical performance at the turn of the 19th and 20th
   centuries; Maria Gay; Bizet's "Carmen," "light-genre" musical theater;
   art of popular music
AB One of the most important tendencies of development of opera theater at the turn of the 19th and 20th centuries is the fixation on "the truth of life" - a convincing recreation of the emotions and inner experience of the characters in conjugacy with the veracity of stage positions and situations. The aforementioned tendency acquired a full-scale manifestation in the performing activities of a number of celebrated performing musicians who aspired to achieve the maximal "veracity" of well-known operas. A vivid confirmation to the asserted is the artistic biography of Spanish singer Maria Gay (mezzo-soprano, 1879-1943). Her performance renditions of the leading parts in the operas of Giuseppe Verdi, Camille Saint-Saens, Pietro Mascagni and Jules Massenet constantly attracted the attention of connoisseurs of the art of opera and professional musicians to themselves. The culmination of Maria Gay's performance activities is perceived to be the innovative interpretation of the part of Carmen in Georges Bizet's opera with the same name, which is presently acknowledged as a milestone event in the history of 20th century art of the opera stage. An analytical examination of publications of Russian musical criticism of the time period from the 1900s to the 1920s and memoir testimonies makes it possible to characterize certain substantial aspects of the aforementioned interpretative rendition - an exceptional diversity of timbral and phonic "nuancing" of the vocal part, the tightest interconnection of the latter with the choreography of the corresponding role, formation of "plastic counterpoints" to the mise-en-scenes in the "secondary" episodes, etc. At the same time, parallels are discovered between Maria Gay's "experiments" and the artistic processes predominating in the "light genre" musical theater and the popular art of the turn of the 19th and the 20th centuries.
C1 [Andrushchenko, Elena Yu] Rostov State SV Rachmaninoff Conservatory, Producing Performing Arts Dept, Rostov Na Donu 344002, Russia.
   [Andrievskaya, Galina P.] Rostov State SV Rachmaninoff Conservatory, Mus Hist Dept, Rostov Na Donu 344002, Russia.
   [Andrievskaya, Galina P.] Belgorod State Inst Arts & Culture, Mus Theory & Vocal Choral Art Dept, Belgorod 308033, Russia.
RP Andrushchenko, EY (corresponding author), Rostov State SV Rachmaninoff Conservatory, Producing Performing Arts Dept, Rostov Na Donu 344002, Russia.
EM cats-andru@yandex.ru; noob45_91@mail.ru
CR Akopyan L. O, 2010, MUZYKA 20 VEKA ENTSI
   Andruschenko E. Yu., 2018, SINTEZIRUYUSCHIE TEN
   Dzh Lauri-Vol'pi, 2011, PARALLELNYE GOLOSA
   Karatygin V. G., 1965, SELECTED ARTICLES
   Klinko T. N., 1973, MUZYKA ZHIZN STATI O, P215
   Laschenko S. K., 2004, ISTORIYA RUSSKOY MUZ, P556
   Levik S. Yu, 1962, ZAPISKI OPERNOGO PEV
   Ossovskiy A. V., 1971, MUZYKALNO KRITICHESK
   Vakarin M. A, 1949, SOVETSKAYA MUZYKA, P58
   Zakharova O., 2017, NIKOLAY GOLOVANOV EG, V1
NR 10
TC 0
Z9 0
U1 0
U2 1
PU Scholarly Methodical Center - Innovation Art Studies
PI Ufa
PA Richard Sorge str., d. 17, k. 1, of. 306, Ufa, RUSSIA
SN 1997-0854
EI 2587-6341
J9 PROBL MUZYKALNOI NAU
JI Probl. Muzykalnoi Nauk.
PY 2021
IS 2
BP 170
EP 181
DI 10.33779/2587-6341.2021.2.170-181
PG 12
WC Music
WE Emerging Sources Citation Index (ESCI)
SC Music
GA TF4HK
UT WOS:000670678600015
OA gold
DA 2024-01-09
ER

PT J
AU Abdulbaki, H
   Mo, J
   Limb, CJ
   Jiam, NT
AF Abdulbaki, Hasan
   Mo, Jonathan
   Limb, Charles J.
   Jiam, Nicole T.
TI The Impact of Musical Rehabilitation on Complex Sound Perception in
   Cochlear Implant Users: A Systematic Review
SO OTOLOGY & NEUROTOLOGY
LA English
DT Review
DE Auditory rehabilitation; Cochlear implant; Music; Outcomes; Speech;
   Training
ID PITCH PERCEPTION; LISTENING HABITS; DEAF-CHILDREN; RECOGNITION; QUALITY;
   PERFORMANCE; ENJOYMENT; SPEECH; APPRECIATION; INSTRUMENTS
AB Objective: Musical rehabilitation has been used in clinical and nonclinical contexts to improve postimplantation auditory processing in implanted individuals. This systematic review aimed to evaluate the efficacy of music rehabilitation in controlled experimental and quasi-experimental studies on cochlear implant (CI) user speech and music perception.Databases reviewed: PubMed/MEDLINE, EMBASE, Web of Science, PsycARTICLES, and PsycINFO databases through July 2022.Methods: Controlled experimental trials and prospective studies were included if they compared pretest and posttest data and excluded hearing aid-only users. Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines were then used to extract data from 11 included studies with a total of 206 pediatric and adult participants. Interventions included group music therapy, melodic contour identification training, auditory-motor instruction, or structured digital music training. Studies used heterogeneous outcome measures evaluating speech and music perception. Risk of bias was assessed using the National Heart, Lung, and Blood Institute Quality Assessment Tool.Results: A total of 735 studies were screened, and 11 met the inclusion criteria. Six trials reported both speech and music outcomes, whereas five reported only music perception outcomes after the intervention relative to control. For music perception outcomes, significant findings included improvements in melodic contour identification (five studies, p < 0.05), timbre recognition (three studies, p < 0.05), and song appraisal (three studies, p < 0.05) in their respective trials. For speech prosody outcomes, only vocal emotion identification demonstrated significant improvements (two studies, p < 0.05).Conclusion: Music rehabilitation improves performance on multiple measures of music perception, as well as tone-based characteristics of speech (i.e., emotional prosody). This suggests that rehabilitation may facilitate improvements in the discrimination of spectrally complex signals.
C1 [Abdulbaki, Hasan] Univ Calif San Francisco, Sch Med, San Francisco, CA USA.
   [Mo, Jonathan] Univ Calif Davis, Sch Med, Sacramento, CA 95817 USA.
   [Limb, Charles J.] Univ Calif San Francisco, Dept Otolaryngol Head & Neck Surg, San Francisco, CA USA.
   [Jiam, Nicole T.] Harvard Med Sch, Massachusetts Eye & Ear, Dept Otolaryngol Head & Neck Surg, Boston, MA 02115 USA.
C3 University of California System; University of California San Francisco;
   University of California System; University of California Davis;
   University of California System; University of California San Francisco;
   Harvard University; Harvard Medical School; Massachusetts Eye & Ear
   Infirmary
RP Jiam, NT (corresponding author), Massachusetts Eye & Ear, Dept Otolaryngol Head & Neck Surg, 243 Charles St, Boston, MA 02114 USA.
EM Hasan.Abdulbaki@ucsf.edu; jonathanmo1997@gmail.com;
   charles.limb@ucsf.edu; njiam@meei.harvard.edu
RI Mo, Jonathan Tomonaga/HPG-7846-2023
OI Mo, Jonathan/0000-0002-2389-2844
FU Advanced Bionics Corporation; Oticon Medical; MED-EL Corporation
FX C.J.L. serves as a member of the Medical Advisory Board and receives
   research funding and support from Advanced Bionics Corporation, Oticon
   Medical, and MED-EL Corporation. He has served as the Scientific Chair
   of the Music Advisory Board for MED-EL Corporation and is currently the
   Chief Medical Officer and consultant for Spiral Therapeutics. N.T.J. is
   a consultant for Oticon Medical and is the Chief Executive Officer of
   IIAM Corporation.
CR Ab Shukor NF, 2021, CLIN EXP OTORHINOLAR, V14, P15, DOI 10.21053/ceo.2020.00101
   Abdi S, 2001, INT J PEDIATR OTORHI, V59, P105, DOI 10.1016/S0165-5876(01)00460-8
   Alexander AJ, 2011, J OTOLARYNGOL-HEAD N, V40, P1, DOI 10.2310/7070.2010.090085
   [Anonymous], STUD QUAL ASS TOOLS
   Caldwell MT, 2017, LARYNGOSCOPE INVEST, V2, P119, DOI 10.1002/lio2.71
   Carbia C, 2018, NEUROSCI BIOBEHAV R, V90, P332, DOI 10.1016/j.neubiorev.2018.04.013
   Chari DA, 2020, OTOL NEUROTOL, V41, pE422, DOI 10.1097/MAO.0000000000002525
   Chen JKC, 2010, PEDIATRICS, V125, pE793, DOI 10.1542/peds.2008-3620
   Cheng XT, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518759214
   Cosetti MK, 2012, OTOLARYNG CLIN N AM, V45, P155, DOI 10.1016/j.otc.2011.08.023
   Dastgheib S., 2016, J Cereb Blood Flow Metab, V36, P739, DOI [10.1177/0271678X16645239, DOI 10.1177/0271678X16645239]
   Dhanasingh A, 2017, HEARING RES, V356, P93, DOI 10.1016/j.heares.2017.10.005
   Dornhoffer JR, 2022, OTOL NEUROTOL, V43, pE165, DOI 10.1097/MAO.0000000000003417
   Driscoll Virginia D., 2012, Seminars in Hearing, V33, P410, DOI 10.1055/s-0032-1329230
   Driscoll VD, 2009, J AM ACAD AUDIOL, V20, P71, DOI 10.3766/jaaa.20.1.7
   Dritsakis G, 2017, AM J AUDIOL, V26, P268, DOI 10.1044/2017_AJA-16-0120
   Fahmy O, 2021, J CLIN MED, V10, DOI 10.3390/jcm10245723
   Fuller CD, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518765379
   Galvin JJ, 2007, EAR HEARING, V28, P302, DOI 10.1097/01.aud.0000261689.35445.20
   Gfeller K, 2000, J Am Acad Audiol, V11, P390
   Gfeller Kate, 2002, J Am Acad Audiol, V13, P132
   Gfeller Kate, 2015, Cochlear Implants Int, V16 Suppl 3, pS22, DOI 10.1179/1467010015Z.000000000269
   Gfeller K, 2011, MUSIC THER PERSPECT, V29, P39, DOI 10.1093/mtp/29.1.39
   Good A, 2017, EAR HEARING, V38, P455, DOI 10.1097/AUD.0000000000000402
   Jiam NT, 2019, JARO-J ASSOC RES OTO, V20, P247, DOI 10.1007/s10162-018-00704-0
   Koelsch S, 2004, CLIN NEUROPHYSIOL, V115, P966, DOI 10.1016/j.clinph.2003.11.032
   Kosaner Julie, 2012, Cochlear Implants Int, V13, P237, DOI 10.1179/1754762811Y.0000000023
   Laneau J, 2006, AUDIOL NEURO-OTOL, V11, P38, DOI 10.1159/000088853
   Lassaletta L, 2007, ACTA OTO-LARYNGOL, V127, P682, DOI 10.1080/00016480601002112
   Limb CJ, 2014, HEARING RES, V308, P13, DOI 10.1016/j.heares.2013.04.009
   Lo CKL, 2014, BMC MED RES METHODOL, V14, DOI 10.1186/1471-2288-14-45
   Lo CY, 2020, J SPEECH LANG HEAR R, V63, P1990, DOI 10.1044/2020_JSLHR-19-00391
   Looi Valerie, 2012, Seminars in Hearing, V33, P361, DOI 10.1055/s-0032-1329225
   Looi V, 2011, INT J AUDIOL, V50, P503, DOI 10.3109/14992027.2011.562246
   Luo X, 2019, JARO-J ASSOC RES OTO, V20, P57, DOI 10.1007/s10162-018-00701-3
   Magele A, 2022, J PERS MED, V12, DOI 10.3390/jpm12030443
   McDermott Hugh J, 2004, Trends Amplif, V8, P49, DOI 10.1177/108471380400800203
   Migirov L, 2009, ANN OTO RHINOL LARYN, V118, P350, DOI 10.1177/000348940911800506
   Mitani C, 2007, EAR HEARING, V28, p29S, DOI 10.1097/AUD.0b013e318031547a
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.1016/j.ijsu.2010.02.007, 10.1136/bmj.i4086, 10.1016/j.ijsu.2010.07.299, 10.1186/2046-4053-4-1, 10.1371/journal.pmed.1000097, 10.1136/bmj.b2535, 10.1136/bmj.b2700]
   Patel AD, 2014, HEARING RES, V308, P98, DOI 10.1016/j.heares.2013.08.011
   Petersen B., 2012, Psychomusicol Music Mind Brain, V22, P134, DOI DOI 10.1037/A0031140
   Plant Geoff, 2015, Seminars in Hearing, V36, P296, DOI 10.1055/s-0035-1564460
   Prevoteau C, 2018, AURIS NASUS LARYNX, V45, P895, DOI 10.1016/j.anl.2017.11.008
   Riley PE, 2018, OTOLARYNG HEAD NECK, V158, P1002, DOI 10.1177/0194599818760559
   Roman S, 2016, HEARING RES, V337, P89, DOI 10.1016/j.heares.2016.05.003
   Smith L, 2017, OTOL NEUROTOL, V38, pE262, DOI 10.1097/MAO.0000000000001447
   Torppa R, 2019, HEARING RES, V380, P108, DOI 10.1016/j.heares.2019.06.003
   van Besouw RM, 2016, MUSIC PERCEPT, V33, P493, DOI 10.1525/MP.2016.33.4.493
   Vandali A, 2015, EAR HEARING, V36, pE1, DOI 10.1097/AUD.0000000000000109
   Vongpaisal Tara, 2016, Front Psychol, V7, P835, DOI 10.3389/fpsyg.2016.00835
   WILSON BS, 1991, NATURE, V352, P236, DOI 10.1038/352236a0
   Yucel E, 2009, INT J PEDIATR OTORHI, V73, P1043, DOI 10.1016/j.ijporl.2009.04.009
NR 53
TC 0
Z9 0
U1 1
U2 1
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 1531-7129
EI 1537-4505
J9 OTOL NEUROTOL
JI Otol. Neurotol.
PD DEC
PY 2023
VL 44
IS 10
BP 965
EP 977
DI 10.1097/MAO.0000000000004025
PG 13
WC Clinical Neurology; Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Neurosciences & Neurology; Otorhinolaryngology
GA X9HE7
UT WOS:001101471700012
PM 37758325
DA 2024-01-09
ER

PT J
AU Parncutt, R
AF Parncutt, Richard
TI Mother Schema, Obstetric Dilemma, and the Origin of Behavioral Modernity
SO BEHAVIORAL SCIENCES
LA English
DT Article
DE behavioral modernity; evolutionary psychology; mother schema; obstetric
   dilemma; language; music; origin; religion; reflective consciousness
ID SEX-DIFFERENCES; NEONATAL RESPONSIVENESS; COGNITIVE NEUROSCIENCE;
   PRENATAL DEVELOPMENT; NORMATIVE PROCESSES; RELIGIOUS PRACTICES;
   GENDER-DIFFERENCES; OBJECT RELATIONS; GROUP-SIZE; EVOLUTION
AB What triggered the emergence of uniquely human behaviors (language, religion, music) some 100,000 years ago? A non-circular, speculative theory based on the mother-infant relationship is presented. Infant "cuteness" evokes the infant schema and motivates nurturing; the analogous mother schema (MS) is a multimodal representation of the carer from the fetal/infant perspective, motivating fearless trust. Prenatal MS organizes auditory, proprioceptive, and biochemical stimuli (voice, heartbeat, footsteps, digestion, body movements, biochemicals) that depend on maternal physical/emotional state. In human evolution, bipedalism and encephalization led to earlier births and more fragile infants. Cognitively more advanced infants survived by better communicating with and motivating (manipulating) mothers and carers. The ability to link arbitrary sound patterns to complex meanings improved (proto-language). Later in life, MS and associated emotions were triggered in ritual settings by repetitive sounds and movements (early song, chant, rhythm, dance), subdued light, dull auditory timbre, psychoactive substances, unusual tastes/smells and postures, and/or a feeling of enclosure. Operant conditioning can explain why such actions were repeated. Reflective consciousness emerged as infant-mother dyads playfully explored intentionality (theory of mind, agent detection) and carers predicted and prevented fatal infant accidents (mental time travel). The theory is consistent with cross-cultural commonalities in altered states (out-of-body, possessing, floating, fusing), spiritual beings (large, moving, powerful, emotional, wise, loving), and reports of strong musical experiences and divine encounters. Evidence is circumstantial and cumulative; falsification is problematic.
C1 [Parncutt, Richard] Karl Franzens Univ Graz, Ctr Systemat Mus, A-8010 Graz, Austria.
C3 University of Graz
RP Parncutt, R (corresponding author), Karl Franzens Univ Graz, Ctr Systemat Mus, A-8010 Graz, Austria.
EM parncutt@uni-graz.at
OI Parncutt, Richard/0000-0002-1332-7841
FU University of Graz
FX Open Access Funding by the University of Graz.
CR Abboub N, 2016, BRAIN LANG, V162, P46, DOI 10.1016/j.bandl.2016.08.002
   ABITBOL MM, 1993, AM J PHYS ANTHROPOL, V91, P367, DOI 10.1002/ajpa.1330910309
   Abrams R M, 2000, J Perinatol, V20, pS31
   Abrams RM, 1998, MUSIC PERCEPT, V15, P307
   Ahnert L, 2004, CHILD DEV, V75, P639, DOI 10.1111/j.1467-8624.2004.00698.x
   AIELLO LC, 1993, CURR ANTHROPOL, V34, P184, DOI 10.1086/204160
   AINSWORTH MD, 1969, CHILD DEV, V40, P969, DOI 10.1111/j.1467-8624.1969.tb04561.x
   Alcorta CS, 2005, HUM NATURE-INT BIOS, V16, P323, DOI 10.1007/s12110-005-1014-3
   Alexander GM, 2009, ARCH SEX BEHAV, V38, P427, DOI 10.1007/s10508-008-9430-1
   Alston William P., 1993, Perceiving God: The Epistemology of Religious Experience
   Anderson AL, 2013, NEUROSCI BIOBEHAV R, V37, P2220, DOI 10.1016/j.neubiorev.2013.03.013
   [Anonymous], 1982, Social Cognition, DOI [DOI 10.1521/SOCO.1982.1.3.191, 10.1521/soco.1982.1.3.191]
   [Anonymous], 1966, IDEA HOLY INQUIRY NO
   [Anonymous], PHILOS MIND CONT INT
   [Anonymous], 2005, NATURE NURTURE ESSAY
   [Anonymous], 1975, L'equilibration des structures cognitives: probleme central du developpement
   [Anonymous], 2013, International Journal of Transpersonal Studies, DOI DOI 10.24972/IJTS.2012.31.2.47
   [Anonymous], 2010, RUZHYA MIKROBY STALI
   [Anonymous], 1996, HUMAN EVOLUTION LANG
   [Anonymous], PRENATAL PERCEPTION
   [Anonymous], 1989, PSYCHOL LEARNING BEH
   [Anonymous], 2004, Dreaming
   Atran Scott, 2010, Biology Theory, V5, P18, DOI 10.1162/BIOT_a_00018
   Baibazarova E, 2013, PSYCHONEUROENDOCRINO, V38, P907, DOI 10.1016/j.psyneuen.2012.09.015
   BALDWIN MW, 1992, PSYCHOL BULL, V112, P461, DOI 10.1037/0033-2909.112.3.461
   Balme J, 2009, QUATERN INT, V202, P59, DOI 10.1016/j.quaint.2008.10.002
   Bar-Yosef O, 2002, ANNU REV ANTHROPOL, V31, P363, DOI 10.1146/annurev.anthro.31.040402.085416
   Barrett H. Clark, 2005, HDB EVOLUTIONARY PSY, P200, DOI DOI 10.1002/9780470939376.CH7
   Barrow JD., 1991, Theories of Everything: The Quest for Ultimate Explanation
   Bartlett F. C., 1995, Remembering
   Becker J., 2004, Deep listeners: Music emotions and trancing
   Belfer-Cohen A, 2010, CURR ANTHROPOL, V51, pS167, DOI 10.1086/649835
   Benabou R., 2015, 21105 NBER, DOI [10.3386/w21105, DOI 10.3386/W21105]
   Berwick R. C., 2017, Why only us: Language and evolution
   Bickhard MH, 2005, PHILOS PSYCHOL, V18, P205, DOI 10.1080/09515080500169306
   BIRNHOLZ JC, 1978, AM J ROENTGENOL, V130, P537, DOI 10.2214/ajr.130.3.537
   Black RE, 2010, LANCET, V375, P1969, DOI 10.1016/S0140-6736(10)60549-1
   Blacking J, 1974, HOW MUSICAL IS MAN
   Blass EM, 2001, DEV PSYCHOL, V37, P762, DOI 10.1037//0012-1649.37.6.762
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Bloom P, 2007, DEVELOPMENTAL SCI, V10, P147, DOI 10.1111/j.1467-7687.2007.00577.x
   Bowlby John, 1982, Attachment and loss Attachment, V1
   Bregman A.S., 1990, AUDITORY SCENE ANAL, DOI DOI 10.7551/MITPRESS/1486.001.0001
   BROOKS J, 1976, CHILD DEV, V47, P323, DOI 10.2307/1128785
   Brown S, 2001, ANN NY ACAD SCI, V930, P372, DOI 10.1111/j.1749-6632.2001.tb05745.x
   Brown S., 2009, Neuroaesthetics, P43
   Brown S, 2013, PSYCHOL MUSIC, V41, P229, DOI 10.1177/0305735611425896
   Bulbulia J, 2004, BIOL PHILOS, V19, P655, DOI 10.1007/s10539-005-5568-6
   BUTLER J, 1988, THEATRE J, V40, P519, DOI 10.2307/3207893
   CALVIN WH, 1983, J THEOR BIOL, V104, P121, DOI 10.1016/0022-5193(83)90405-8
   Campbell R, 2000, AM J COMMUN PSYCHOL, V28, P773, DOI 10.1023/A:1005159716099
   Carter CS, 2014, ANNU REV PSYCHOL, V65, P17, DOI 10.1146/annurev-psych-010213-115110
   Cashdan E, 1998, J NONVERBAL BEHAV, V22, P209, DOI 10.1023/A:1022967721884
   Chalmers D., 1995, J CONSCIOUSNESS STUD, V2, P200, DOI [10.1093/acprof:oso/9780195311105.003.0001, DOI 10.1093/ACPR0F:0S0/9780195311105.003.0001]
   Chenail RJ, 2011, QUAL REP, V16, P255
   Christiansen MH, 2008, BEHAV BRAIN SCI, V31, P489, DOI 10.1017/S0140525X08004998
   Christophe A, 2008, LANG SPEECH, V51, P61, DOI 10.1177/00238309080510010501
   CIANI AC, 1992, LANGUAGE ORIGIN MULT, P51
   Clift S., 2010, Journal of Applied Arts and Health, V1, P19, DOI DOI 10.1386/JAAH.1.1.19/1
   Cochrane T, 2010, MUSIC ANAL, V29, P264, DOI 10.1111/j.1468-2249.2011.00321.x
   Cohen E, 2008, ETHNOS, V73, P101, DOI 10.1080/00141840801927558
   Conard NJ, 2009, NATURE, V460, P737, DOI 10.1038/nature08169
   Connellan J, 2000, INFANT BEHAV DEV, V23, P113, DOI 10.1016/S0163-6383(00)00032-1
   Corbeil M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00372
   Coutinho E, 2013, COGNITION EMOTION, V27, P658, DOI 10.1080/02699931.2012.732559
   Cross Ian, 2009, Communicative musicality: exploring the basis of human companionship, P61
   Csikszentmihalyi M., 1990, Flow: The Psychology of Optimal Experience
   Curley JP, 2011, BEHAV NEUROSCI, V125, P273, DOI 10.1037/a0022939
   Cutler A, 2017, 21 CENTURY PSYCHOLIN
   d'Errico F, 2003, J WORLD PREHIST, V17, P1, DOI 10.1023/A:1023980201043
   De Foligno S.A., 1927, LIVRE EXPERIENCE VRA
   Decety J, 2016, PHILOS T R SOC B, V371, DOI 10.1098/rstb.2015.0077
   DENHAM WW, 1974, J ANTHROPOL RES, V30, P191, DOI 10.1086/jar.30.3.3629843
   Deutsch D., 2012, The psychology of music
   Deutsch D, 2008, J ACOUST SOC AM, V124, P589, DOI 10.1121/1.2931957
   Di Paolo E., 2010, Enaction: Toward a New Paradigm for Cognitive Science
   Díaz-Andreu M, 2012, J ARCHAEOL SCI, V39, P3591, DOI 10.1016/j.jas.2012.06.034
   Diller Karl, 2009, CRADLE LANGUAGE, P135
   Dissanayake E, 2000, ORIGINS OF MUSIC, P389
   Dissanayake E., 2008, Mus. Sci, V12, P169, DOI [10.1177/1029864908012001081, DOI 10.1177/1029864908012001081]
   Dissanayake E., 2003, J CANADIAN ASS CURRI, V1, P13
   Dissanayake Ellen, 2000, Art and intimacy: How the arts began
   Draghi-Lorenz R, 2001, DEV REV, V21, P263, DOI 10.1006/drev.2000.0524
   Dunbar RIM, 2012, EVOL PSYCHOL-US, V10, P688, DOI 10.1177/147470491201000403
   DUNBAR RIM, 1993, BEHAV BRAIN SCI, V16, P681, DOI 10.1017/S0140525X00032325
   Dunsworth H, 2015, ANNU REV ANTHROPOL, V44, P55, DOI 10.1146/annurev-anthro-102214-013918
   Durkheim Emile, 1995, ELEMENTARY FORMS REL
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   Eilam D, 2006, NEUROSCI BIOBEHAV R, V30, P456, DOI 10.1016/j.neubiorev.2005.08.003
   Einspieler C, 2008, Z PSYCHOL, V216, P147, DOI 10.1027/0044-3409.216.3.147
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Epley N, 2007, PSYCHOL REV, V114, P864, DOI 10.1037/0033-295X.114.4.864
   ERICSSON KA, 1993, PSYCHOL REV, V100, P363, DOI 10.1037/0033-295X.100.3.363
   Erikson E. H., 1994, Identity and the life cycle
   Esling J. H., 2014, P 38 ANN M BERK LING, V38, P121, DOI [DOI 10.3765/BLS.V38I0.3325, 10.3765/bls.v38i0.3325]
   Falk D, 2004, BEHAV BRAIN SCI, V27, P491
   FALK D, 1990, BEHAV BRAIN SCI, V13, P333, DOI 10.1017/S0140525X00078973
   Fazenda B, 2017, J ACOUST SOC AM, V142, P1332, DOI 10.1121/1.4998721
   FEDIGAN LM, 1986, ANNU REV ANTHROPOL, V15, P25, DOI 10.1146/annurev.an.15.100186.000325
   Fellerer Karl Gustav, 1953, The Musical Quarterly, V39, P576
   FERNALD A, 1989, CHILD DEV, V60, P1497, DOI 10.2307/1130938
   FERNALD A, 1993, CHILD DEV, V64, P657, DOI 10.1111/j.1467-8624.1993.tb02934.x
   Fitch WT, 2000, TRENDS COGN SCI, V4, P258, DOI 10.1016/S1364-6613(00)01494-7
   Fitch WT, 2001, P ROY SOC B-BIOL SCI, V268, P1669, DOI 10.1098/rspb.2001.1704
   FRECSKA E, 1989, ETHOS, V17, P70, DOI 10.1525/eth.1989.17.1.02a00040
   Freud Sigmund, 1930, Das Unbehagen in der Kultur
   Frith U, 1999, MIND LANG, V14, P1
   Fuller R. C., 2009, WONDER EMOTION SPIRI
   Gabrielsson A., 2011, Strong Experiences with Music
   Gao W, 2017, NEUROSCIENTIST, V23, P169, DOI 10.1177/1073858416635986
   Gay B., 2011, American International Journal of Contemporary Research, V1, P24
   Gergely G., 2018, DEV SCI PSYCHOANALYS, P45
   Gervain J, 2015, CURR OPIN NEUROBIOL, V35, P13, DOI 10.1016/j.conb.2015.05.004
   Gibson E.J., 1969, Principles of Perceptual Learning and Development
   Gibson JJ, 1966, SENSES CONSIDERED PE
   Gjersoe NL, 2015, COGNITIVE DEV, V34, P28, DOI 10.1016/j.cogdev.2014.12.002
   Goddard C, 2015, AUST ABORIG STUD, P43
   Gogate LJ, 2000, CHILD DEV, V71, P878, DOI 10.1111/1467-8624.00197
   Goodall J., 1986, CHIMPANZEES GOMBE PA
   Granqvist P, 1998, J SCI STUD RELIG, V37, P350, DOI 10.2307/1387533
   Granqvist P., 2013, APA HDB PSYCHOL RELI, V1, P139, DOI DOI 10.1037/14045-007
   Granqvist P, 2012, J PERS SOC PSYCHOL, V103, P804, DOI 10.1037/a0029344
   Granqvist P, 2010, PERS SOC PSYCHOL REV, V14, P49, DOI 10.1177/1088868309348618
   GREENE WA, 1958, J NERV MENT DIS, V126, P225, DOI 10.1097/00005053-195803000-00003
   Groome LJ, 1997, CHILD DEV, V68, P1
   GUTHRIE S, 1980, CURR ANTHROPOL, V21, P181, DOI 10.1086/202429
   Halloy A, 2012, ETHNOS, V77, P177, DOI 10.1080/00141844.2011.586465
   Hamdan A., 2010, Contemplative Prac Action Spirituality Meditation Health, V12, P122
   Hanson R. P. C., 2005, SEARCH CHRISTIAN DOC, P318
   HARLOW HF, 1959, SCI AM, V200, P68, DOI 10.1038/scientificamerican0659-68
   Harnad S, 2008, BEHAV BRAIN SCI, V31, P524, DOI 10.1017/S0140525X08005153
   Hastings PD, 2000, DEV PSYCHOL, V36, P531, DOI [10.1037/0012-1649.36.5.531, 10.1037//0012-1649.36.5.531]
   Hatfield E, 2009, SOCIAL NEUROSCIENCE OF EMPATHY, P19
   Hauser MT, 2014, FRONT PLANT SCI, V5, DOI [10.3389/fpls.2014.00320, 10.3389/fpsyg.2014.00401]
   Hauser MD, 2001, COGNITION, V78, pB53, DOI 10.1016/S0010-0277(00)00132-3
   Hawley PH, 2008, INT J BEHAV DEV, V32, P76, DOI 10.1177/0165025407084054
   HAY D, 1979, J SCI STUD RELIG, V18, P164, DOI 10.2307/1385938
   HAYDEN B, 1972, WORLD ARCHAEOL, V4, P205, DOI 10.1080/00438243.1972.9979533
   Henshilwood C, 2009, BECOMING HUMAN: INNOVATION IN PREHISTORIC MATERIAL AND SPIRITUAL CULTURE, P29
   Hepper P, 2015, CHILD DEV PERSPECT, V9, P38, DOI 10.1111/cdep.12104
   Hepper PG, 1996, ACTA PAEDIATR, V85, P16, DOI 10.1111/j.1651-2227.1996.tb14272.x
   HEPPER PG, 1991, IRISH J PSYCHOL, V12, P95, DOI 10.1080/03033910.1991.10557830
   Hepper PG., 1994, FETAL MATERNAL MED R, V6, P167, DOI DOI 10.1017/S0965539500001108
   Hewlett BS, 2016, ROY SOC OPEN SCI, V3, DOI 10.1098/rsos.150403
   Hickok G, 2017, PSYCHON B REV, V24, P56, DOI 10.3758/s13423-016-1100-z
   Hill K, 2001, J HUM EVOL, V40, P437, DOI 10.1006/jhev.2001.0469
   Hill K, 2009, EVOL ANTHROPOL, V18, P187, DOI 10.1002/evan.20224
   Hodnett ED, 2002, AM J OBSTET GYNECOL, V186, pS160, DOI 10.1067/mob.2002.121141
   Hofer MA, 2006, CURR DIR PSYCHOL SCI, V15, P84, DOI 10.1111/j.0963-7214.2006.00412.x
   HOFFMAN HS, 1973, PSYCHOL REV, V80, P527, DOI 10.1037/h0035533
   Honing H, 2015, PHILOS T R SOC B, V370, P5, DOI 10.1098/rstb.2014.0088
   Hopkins B., 2005, PRENATAL DEV POSTNAT
   Horowitz MJ, 1988, PERSON SCHEMAS MALAD, P13
   Howell RJ, 2008, CASE FOR QUALIA, P125
   Hrdy S. B., 2009, Mothers and others
   Hudson Robyn, 1993, Current Opinion in Neurobiology, V3, P548, DOI 10.1016/0959-4388(93)90054-3
   HUHEEY JE, 1977, BEHAV GENET, V7, P29
   Huron D, 2001, ANN NY ACAD SCI, V930, P43, DOI 10.1111/j.1749-6632.2001.tb05724.x
   HYDE JS, 1988, PSYCHOL BULL, V104, P53, DOI 10.1037/0033-2909.104.1.53
   Iannace G, 2014, ARCH ACOUST, V39, P583, DOI 10.2478/aoa-2014-0062
   JACKSON F, 1986, J PHILOS, V83, P291, DOI 10.2307/2026143
   JACQUES SL, 1987, PHOTOCHEM PHOTOBIOL, V45, P637, DOI 10.1111/j.1751-1097.1987.tb07391.x
   Jahn RG, 1996, J ACOUST SOC AM, V99, P649, DOI 10.1121/1.414642
   James W., 1902, COMMUNICATION
   Janata P, 2012, J EXP PSYCHOL GEN, V141, P54, DOI 10.1037/a0024208
   Jankelevitch Vladimir, 2003, Music and the Ineffable
   Johnson D. D. P., 2006, EVOLUTIONARY PSYCHOL, V4, P219, DOI DOI 10.1177/147470490600400119
   Jong J., 2018, DEATH ANXIETY RELIG
   Joseph R, 2001, ZYGON, V36, P105, DOI 10.1111/0591-2385.00343
   Juslin P. N., 2011, HDB MUSIC EMOTION TH
   Kaplan M.A., 2007, EXPERIENCE DIVINE GU
   Kelly George, 1992, The Psychology of Personal Constructs
   Keltner D, 2003, COGNITION EMOTION, V17, P297, DOI 10.1080/02699930302297
   Kirkpatrick L. A., 2006, ARCH PSYCHOL RELIG, V28, P3, DOI [10.1163/008467206777832616, DOI 10.1163/008467206777832616]
   Kirschner S, 2010, EVOL HUM BEHAV, V31, P354, DOI 10.1016/j.evolhumbehav.2010.04.004
   Kisilevsky BS, 2009, INFANT BEHAV DEV, V32, P59, DOI 10.1016/j.infbeh.2008.10.002
   KLEIN RG, 1995, J WORLD PREHIST, V9, P167, DOI 10.1007/BF02221838
   KLINNERT MD, 1986, DEV PSYCHOL, V22, P427, DOI 10.1037/0012-1649.22.4.427
   Kohler HP, 2005, POPUL DEV REV, V31, P407, DOI 10.1111/j.1728-4457.2005.00078.x
   Konecni V. J., 2008, Psychol. Aesthetics, Creativity, Arts, V2, P115, DOI DOI 10.1037/1931-3896.2.2.115
   Koyama R, 2006, SOC BEHAV PERSONAL, V34, P1087, DOI 10.2224/sbp.2006.34.9.1087
   Krippner S., 1999, TRANSPERSONAL HYPNOS, P141
   Kuhn T. S., 1996, The structure of scientific revolutions, V3rd
   Kurjak A, 2005, J PERINAT MED, V31, P496
   LaBar KS, 2006, NAT REV NEUROSCI, V7, P54, DOI 10.1038/nrn1825
   Lamb S., 2014, HDB MORAL BEHAV DEV, P193
   Laski Marghanita., 1961, ECSTASY STUDY SOME S
   LESLIE AM, 1987, PSYCHOL REV, V94, P412, DOI 10.1037/0033-295X.94.4.412
   LEUTENEGGER W, 1974, J HUM EVOL, V3, P207, DOI 10.1016/0047-2484(74)90179-1
   Levman Bryan G., 2000, Musicae Scientiae, V4, P185
   Lieberman MD, 2007, ANNU REV PSYCHOL, V58, P259, DOI 10.1146/annurev.psych.58.110405.085654
   Lorenz K., 1943, Zeitschrift fuer Tierpsychologie Berlin, V5, P235
   LOVEJOY CO, 1988, SCI AM, V259, P118, DOI 10.1038/scientificamerican1188-118
   LUCKMANN T, 1990, SOCIOL ANAL, V51, P127, DOI 10.2307/3710810
   MacLean KA, 2012, J SCI STUD RELIG, V51, P721, DOI 10.1111/j.1468-5906.2012.01685.x
   Maestripieri D, 1998, HORM BEHAV, V34, P223, DOI 10.1006/hbeh.1998.1470
   MAIN M, 1983, INFANT BEHAV DEV, V6, P167, DOI 10.1016/S0163-6383(83)80024-1
   Mampe B, 2009, CURR BIOL, V19, P1994, DOI 10.1016/j.cub.2009.09.064
   Margulis EH, 2013, EMPIR STUD ARTS, V31, P45, DOI 10.2190/EM.31.1.c
   Margulis Elizabeth Hellmuth, 2014, On Repeat: How Music Plays the Mind
   Marlier L, 1998, CHILD DEV, V69, P611, DOI 10.2307/1132193
   Maselko J, 2006, SOC SCI MED, V62, P2848, DOI 10.1016/j.socscimed.2005.11.008
   Maslow A.H., 1954, MOTIVATION PSYCHOL
   Maslow AH., 1964, Religions, values, and peak-experiences
   Masson J.M., 1980, ORIGINS RELIG SENTIM
   Mastropieri D, 1999, DEV PSYCHOBIOL, V35, P204, DOI 10.1002/(SICI)1098-2302(199911)35:3<204::AID-DEV5>3.0.CO;2-V
   Matthiesen AS, 2001, BIRTH-ISS PERINAT C, V28, P13, DOI 10.1046/j.1523-536x.2001.00013.x
   May L, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00222
   MCGINN C, 1989, MIND, V98, P349
   McNamara R.A., 2019, COGNITIVE SCI RELIG, P41
   MELTZOFF AN, 1995, DEV PSYCHOL, V31, P838, DOI 10.1037/0012-1649.31.5.838
   Mennella JA, 2001, PEDIATRICS, V107, part. no., DOI 10.1542/peds.107.6.e88
   Merker BH, 2009, CORTEX, V45, P4, DOI 10.1016/j.cortex.2008.06.011
   Mithen Steven, 1998, CREATIVITY HUMAN EVO
   Monaghan P, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0299
   Moon C M, 2000, J Perinatol, V20, pS37
   Morin A, 2006, CONSCIOUS COGN, V15, P358, DOI 10.1016/j.concog.2005.09.006
   Morris PH, 2008, COGNITION EMOTION, V22, P3, DOI 10.1080/02699930701273716
   Muhammad A, 2011, BRAIN RES, V1400, P53, DOI 10.1016/j.brainres.2011.05.038
   Mullally SL, 2014, DEV COGN NEUROS-NETH, V9, P12, DOI 10.1016/j.dcn.2013.12.006
   Murray AD, 2000, J GENET PSYCHOL, V161, P133, DOI 10.1080/00221320009596700
   MYERS DG, 1977, J APPL SOC PSYCHOL, V7, P341, DOI 10.1111/j.1559-1816.1977.tb00758.x
   NAGEL T, 1974, PHILOS REV, V83, P435, DOI 10.2307/2183914
   Nelson EE, 1998, NEUROSCI BIOBEHAV R, V22, P437, DOI 10.1016/S0149-7634(97)00052-3
   Nilsson Ulrica, 2008, AORN J, V87, P780, DOI 10.1016/j.aorn.2007.09.013
   Nishimura T, 2003, PRIMATES, V44, P41, DOI 10.1007/s10329-002-0005-9
   Nishimura T, 2006, J HUM EVOL, V51, P244, DOI 10.1016/j.jhevol.2006.03.005
   Norenzayan A, 2006, COGNITIVE SCI, V30, P531, DOI 10.1207/s15516709cog0000_68
   Oades-Sese GV, 2011, PSYCHOL SCHOOLS, V48, P707, DOI 10.1002/pits.20583
   ORAHILLY R, 1975, EXP EYE RES, V21, P93, DOI 10.1016/0014-4835(75)90075-5
   Palkovich EN, 2015, CHILD LIT EDUC, V46, P175, DOI 10.1007/s10583-015-9252-4
   Panksepp J, 2011, EMOT REV, V3, P387, DOI 10.1177/1754073911410741
   Panneton R., 2006, RES HUMAN DEV, V3, P7, DOI [DOI 10.1207/S15427617RHD0301_2, 10.1207/s15427617rhd0301_2]
   PANZARELLA R, 1980, J HUMANIST PSYCHOL, V20, P69, DOI 10.1177/002216788002000105
   PAPOUAEK Mechthild, 1996, Musical Beginnings. Origins and Development of Musical Competence, P88
   PAPOUSEK M, 1991, INFANT BEHAV DEV, V14, P415, DOI 10.1016/0163-6383(91)90031-M
   Parncutt R, 2012, Harmony: A psychoacoustical approach, V19
   Parncutt R, 2019, MUSIC SCI, V23, P403, DOI 10.1177/1029864917738130
   Parncutt R, 2009, MUSIC SCI, P119, DOI 10.1177/1029864909013002071
   Patterson N, 2006, NATURE, V441, P1103, DOI 10.1038/nature04789
   Peirano P, 2003, J PEDIATR-US, V143, pS70, DOI 10.1067/S0022-3476(03)00404-9
   Penn DC, 2007, PHILOS T R SOC B, V362, P731, DOI 10.1098/rstb.2006.2023
   Petermann F., 2012, PSYCHOL VERTRAUENS
   Phumdoung Sasitorn, 2003, Pain Manag Nurs, V4, P54, DOI 10.1016/S1524-9042(02)54202-8
   Piaget J., 2005, ED PSYCHOL CONTEXT R, P98
   Piaget Jean, 1936, The Origin of intelligence in the child
   PINKER S, 1990, BEHAV BRAIN SCI, V13, P707, DOI 10.1017/S0140525X00081061
   Pinker S, 2003, LANGUAGE INSTINCT MI
   Plooij FX., 1984, The behavioral development of free-living chimpanzee babies and infants
   Prechtl HFR, 1984, CONTINUITY NEURAL FU
   Preston SD, 2013, PSYCHOL BULL, V139, P1305, DOI 10.1037/a0031755
   PRICEWILLIAMS D, 1994, ETHOS, V22, P373, DOI 10.1525/eth.1994.22.3.02a00050
   Provine RR, 2004, BEHAV BRAIN SCI, V27, P520, DOI 10.1017/S0140525X04410115
   Pullum GK, 2002, LINGUIST REV, V19, P9, DOI 10.1515/tlir.19.1-2.9
   Pyysiäinen I, 2010, TRENDS COGN SCI, V14, P104, DOI 10.1016/j.tics.2009.12.007
   Rabin JS, 2010, J COGNITIVE NEUROSCI, V22, P1095, DOI 10.1162/jocn.2009.21344
   Raffman D., 1993, Language, Music, and Mind
   Ramsey JL, 2004, DEVELOPMENTAL SCI, V7, P201, DOI 10.1111/j.1467-7687.2004.00339.x
   Rappaport Roy A., 1999, RITUAL RELIG MAKING
   REED GL, 1983, INT J BEHAV DEV, V6, P51, DOI 10.1177/016502548300600104
   Regehr JD, 2009, TRANSPORT RES REC, P35, DOI 10.3141/2097-05
   Relier J.P., 1996, NEONATOLOGY, V69, P201, DOI [10.1159/000244309, DOI 10.1159/000244309]
   Repp BH, 2004, PSYCHOL RES-PSYCH FO, V68, P252, DOI 10.1007/s00426-003-0143-8
   Richter J, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00485
   Rickard N. S., 2004, Psychology of Music, V32, P371, DOI [10.1177%2F0305735604046096, DOI 10.1177/0305735604046096, 10.1177/0305735604046096]
   Robinson SR, 2008, INFANCY, V13, P204, DOI 10.1080/15250000802004288
   Robinson WS, 2007, J CONSCIOUSNESS STUD, V14, P27
   ROSENBERG KR, 1992, YEARB PHYS ANTHROPOL, V35, P89
   Rosenthal D., 1990, 401990 ZIF U BIEL RE
   Rossano MJ, 2006, REV GEN PSYCHOL, V10, P346, DOI 10.1037/1089-2680.10.4.346
   Rouget Gilbert, 1985, Music and trance: A theory of the relations between music and possession
   Rowlands M, 2001, MIND LANG, V16, P290, DOI 10.1111/1468-0017.00171
   Saarikallio S., 2007, Psychol. Music, V35, P88, DOI [10.1177/0305735607068889, DOI 10.1177/0305735607068889]
   Saffran JR, 2003, CURR DIR PSYCHOL SCI, V12, P110, DOI 10.1111/1467-8721.01243
   Saroglou V, 2011, J CROSS CULT PSYCHOL, V42, P1320, DOI 10.1177/0022022111412267
   Schacter D, 2011, PSYCHOLOGY, V2nd
   Schacter DL, 2007, NAT REV NEUROSCI, V8, P657, DOI 10.1038/nrn2213
   Schäfer T, 2014, PSYCHOL MUSIC, V42, P525, DOI 10.1177/0305735613482024
   Scherer K, 2008, BEHAV BRAIN SCI, V31, P595, DOI 10.1017/S0140525X08005505
   Schwadel P, 2011, REV RELIG RES, V53, P161, DOI 10.1007/s13644-011-0007-4
   Shahar E, 1997, J Eval Clin Pract, V3, P109, DOI 10.1046/j.1365-2753.1997.00092.x
   Shaver P. R., 2008, HDB ATTACHMENT THEOR, P906
   Shayit M, 2003, BEHAV NEUROSCI, V117, P446, DOI 10.1037/0735-7044.117.3.446
   Shimojo S, 2001, CURR OPIN NEUROBIOL, V11, P505, DOI 10.1016/S0959-4388(00)00241-5
   Silvia PJ, 2015, PSYCHOL AESTHET CREA, V9, P376, DOI 10.1037/aca0000028
   Simmons-Stern NR, 2010, NEUROPSYCHOLOGIA, V48, P3164, DOI 10.1016/j.neuropsychologia.2010.04.033
   Simon H.A., 2002, Simplicity, Inference and Modelling: Keeping It Sophisticatedly Simple, P32
   Simon-Thomas ER, 2009, EMOTION, V9, P838, DOI 10.1037/a0017810
   Singleton A., 2004, INT J CHILD SPIRITUA, V9, P247, DOI [DOI 10.1080/1364436042000292176, 10.1080/1364436042000292176]
   Skinner B. F., 2019, BEHAV ORGANISMS EXPT
   Slocombe KE, 2011, ANIM BEHAV, V81, P919, DOI 10.1016/j.anbehav.2011.02.002
   Slone D. J, 2019, The cognitive science of religion: A methodological introduction to key empirical studies
   Sluckin W., 2017, IMPRINTING EARLY LEA, V2nd
   Smotherman W.P., 1998, COMP PSYCHOL HDB, P586
   SMOTHERMAN WP, 1990, PSYCHOL SCI, V1, P97, DOI 10.1111/j.1467-9280.1990.tb00075.x
   Sosis R, 2004, AM SCI, V92, P166, DOI 10.1511/2004.46.928
   Sosis R, 2009, J COGN CULT, V9, P315, DOI 10.1163/156770909X12518536414411
   SPIELMANN KA, 1989, HUM ECOL, V17, P321, DOI 10.1007/BF00889022
   Strathearn L, 2009, NEUROPSYCHOPHARMACOL, V34, P2655, DOI 10.1038/npp.2009.103
   Suárez R, 2005, J CULT HERIT, V6, P307, DOI 10.1016/j.culher.2005.03.005
   Suchocki Marjorie H., 1994, Hypatia, V9, P57
   Suddendorf T, 2007, BEHAV BRAIN SCI, V30, P299, DOI 10.1017/S0140525X07001975
   Sullivan R, 2011, CLIN PERINATOL, V38, P643, DOI 10.1016/j.clp.2011.08.011
   SWINBURNE RG, 1964, MIND, V73, P434
   Tallet C, 2016, SCI REP-UK, V6, DOI 10.1038/srep37238
   Tamis-LeMonda CS, 2014, CURR DIR PSYCHOL SCI, V23, P121, DOI 10.1177/0963721414522813
   Tarr B, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01096
   Teie D, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01158
   Ternstrom Sten, 1993, Voice (UK), V2, P55
   Thomas E., 2017, CONVERSATION
   Thompson E, 2001, TRENDS COGN SCI, V5, P418, DOI 10.1016/S1364-6613(00)01750-2
   THOMPSON NS, 1998, EVOLUTION COMMUNICAT, V2, P25, DOI DOI 10.1075/eoc.2.1.03tho
   Tomasello M., 1997, PRIMATE COGNITION
   Tostevin G. B., 2007, Rethinking the human revolution: new behavioural and biological perspectives on the origin and dispersal of modern humans, P341
   Trainor LJ, 1998, INFANT BEHAV DEV, V21, P799, DOI 10.1016/S0163-6383(98)90047-9
   Tramacchi D., 2004, RAVE CULTURE RELIG, P141
   TREHUB SE, 1993, ADV CHILD DEV BEHAV, V24, P1, DOI 10.1016/S0065-2407(08)60298-0
   Trehub SE, 1997, CAN J EXP PSYCHOL, V51, P385, DOI 10.1037/1196-1961.51.4.385
   Trehub SE, 2001, ANN NY ACAD SCI, V930, P1
   Trevarthen C, 2001, J CHILD PSYCHOL PSYC, V42, P3, DOI 10.1017/S0021963001006552
   Trevarthen C., 1979, Before speech, P321
   TREVARTHEN Colwyn, 2008, Musicae Scientiae, P15, DOI [10.1177/1029864908012001021, 10.1177/102986490801200102, DOI 10.1177/102986490801200102]
   Trevathan W.R., 2016, COSTLY CUTE HELPLESS
   Trevathan WR., 1990, PRE AND PERINATAL PS, V4, P267
   Turner V., 2017, The Ritual Process: Structure and Anti-Structure, DOI 10.4324/9781315134666
   Ullal-Gupta S, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00048
   Underwood LG., 2006, ARCH PSYCHOL RELIG, V28, P181, DOI DOI 10.1163/008467206777832562
   van Heteren CF, 2000, LANCET, V356, P1169, DOI 10.1016/S0140-6736(00)02766-5
   VAN IJZENDOORN MH, 1995, SOC DEV, V4, P115
   Vishkin A., 2014, Religion and spirituality across cultures, P247
   Vrticka P, 2013, FRONT HUM NEUROSCI, V6, DOI [10.3389/fnhum.2012.00212, 10.3389/fnhum.2012.00358]
   Waller S. J., 2002, J. Acoust. Soc. Am, V112, P2284, DOI [DOI 10.1121/1.4779166, 10.1121/1.4779166]
   WALLER SJ, 1993, NATURE, V363, P501, DOI 10.1038/363501a0
   Walton D.N., 1995, PHILOS RHETOR, V28, P171
   Warrington SA, 2001, ARCH DIS CHILD, V85, P104, DOI 10.1136/adc.85.2.104
   WASHBURN SL, 1960, SCI AM, V203, P63
   Watson JB, 1913, PSYCHOL REV, V20, P158, DOI 10.1037/h0074428
   Watt R.J., 1998, MUSIC SCI, V2, P33, DOI DOI 10.1177/102986499800200103
   Webb AR, 2015, P NATL ACAD SCI USA, V112, P3152, DOI 10.1073/pnas.1414924112
   Weiss EM, 2003, PERS INDIV DIFFER, V35, P863, DOI 10.1016/S0191-8869(02)00288-X
   Weller A, 2003, PEPTIDES, V24, P779, DOI 10.1016/S0196-9781(03)00118-9
   Whitehouse, 2002, METH THEORY STUD REL, V14, P293, DOI [10.1163/157006802320909738, DOI 10.1163/157006802320909738]
   Wilbrecht L, 2003, MENT RETARD DEV D R, V9, P135, DOI 10.1002/mrdd.10073
   Wilson M, 2002, PSYCHON B REV, V9, P625, DOI 10.3758/BF03196322
   Winkelman M, 2004, ZYGON, V39, P193, DOI 10.1111/j.1467-9744.2004.00566.x
   Winkler I, 2009, P NATL ACAD SCI USA, V106, P2468, DOI 10.1073/pnas.0809035106
   Wittman AB, 2007, OBSTET GYNECOL SURV, V62, P739, DOI 10.1097/01.ogx.0000286584.04310.5c
   Young LJ, 2001, HORM BEHAV, V40, P133, DOI 10.1006/hbeh.2001.1691
   Yu C, 2005, COGNITIVE SCI, V29, P961, DOI 10.1207/s15516709cog0000_40
   Zeanah CH, 1997, J AM ACAD CHILD PSY, V36, P165, DOI 10.1097/00004583-199702000-00007
   Zelazo PD, 2004, TRENDS COGN SCI, V8, P12, DOI 10.1016/j.tics.2003.11.001
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
   ZIHLMAN AL, 1987, YEARB PHYS ANTHROPOL, V30, P11
   Zoia S, 2007, EXP BRAIN RES, V176, P217, DOI 10.1007/s00221-006-0607-3
   Zosuls KM, 2009, DEV PSYCHOL, V45, P688, DOI 10.1037/a0014053
NR 355
TC 0
Z9 0
U1 0
U2 7
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-328X
J9 BEHAV SCI-BASEL
JI Behav. Sci.
PD DEC
PY 2019
VL 9
IS 12
AR 142
DI 10.3390/bs9120142
PG 43
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA KA1VG
UT WOS:000505586300012
PM 31817739
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Ji, X
   Han, JW
   Jiang, X
   Hu, XT
   Guo, L
   Han, JG
   Shao, L
   Liu, TM
AF Ji, Xiang
   Han, Junwei
   Jiang, Xi
   Hu, Xintao
   Guo, Lei
   Han, Jungong
   Shao, Ling
   Liu, Tianming
TI Analysis of music/speech via integration of audio content and functional
   brain response
SO INFORMATION SCIENCES
LA English
DT Article
DE Audio analysis; fMRI; fMRI-measured feature; Multi-view learning
ID CLASSIFICATION; PATTERNS; SOUNDS; VOICE
AB Effective analysis of music/speech data such as clustering, retrieval, and classification has received significant attention in recent years. Traditional methods mainly rely on the low-level acoustic features derived from digital audio stream, and the accuracy of these methods is limited by the well-known semantic gap. To alleviate this problem, we propose a novel framework for music/speech clustering, retrieval, and classification by integrating the low-level acoustic features derived from audio content with the functional magnetic resonance imaging (fMRI) measured features that represent the brain's functional response when subjects are listening to the music/speech excerpts. First, the brain networks and regions of interest (ROIs) involved in the comprehension of audio stimuli, such as the auditory, emotion, attention, and working memory systems, are located by a new approach named dense individualized and common connectivity-based cortical landmarks (DICC-COLs). Then the functional connectivity matrix measuring the similarity between the fMRI signals of different ROIs is adopted to represent the brain's comprehension of audio semantics. Afterwards, we propose an improved twin Gaussian process (ITGP) model based on self-training to predict the fMRI-measured features of testing data without fMRI scanning. Finally, multi-view learning algorithms are proposed to integrate acoustic features with fMRI-measured features for music/speech clustering, retrieval, and classification, respectively. The experimental results demonstrate the superiority of our proposed work in comparison with existing methods and suggest the advantage of integrating functional brain responses via fMRI data for music/speech analysis. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Ji, Xiang; Han, Junwei; Hu, Xintao; Guo, Lei] Northwestern Polytech Univ, Sch Automat, Xian 710072, Peoples R China.
   [Jiang, Xi; Liu, Tianming] Univ Georgia, Dept Comp Sci, Cort Architecture Imaging & Discovery Lab, Athens, GA 30602 USA.
   [Jiang, Xi; Liu, Tianming] Univ Georgia, Bioimaging Res Ctr, Athens, GA 30602 USA.
   [Han, Jungong] Civolut Technol, Eindhoven, Netherlands.
   [Shao, Ling] Univ Sheffield, Sheffield S1 3JD, S Yorkshire, England.
C3 Northwestern Polytechnical University; University System of Georgia;
   University of Georgia; University System of Georgia; University of
   Georgia; University of Sheffield
RP Han, JW (corresponding author), Northwestern Polytech Univ, Sch Automat, Xian 710072, Peoples R China.
EM junweihan2010@gmail.com
RI Han, Jungong/ABE-6812-2020; Shao, Ling/D-3535-2011; Liu,
   Tianming/AAA-4602-2022
OI Shao, Ling/0000-0002-8264-6117; Jiang, Xi/0000-0003-3711-0847; Hu,
   Xintao/0000-0001-5633-3806
FU National Science Foundation of China [91120005, 61473231, 61103061,
   61473234]; NSF CAREER [IIS-1149260]; NIH [R01 DA-033393, R01 AG-042599];
   NSF [CBET-1302089, BCS-143905]
FX J. Han was supported by the National Science Foundation of China under
   Grant 91120005 and 61473231. X. Hu was supported by the National Science
   Foundation of China under Grant 61103061 and 61473234. T. Liu was
   supported by NSF CAREER Award (IIS-1149260), NIH R01 DA-033393, NIH R01
   AG-042599, NSF CBET-1302089, and NSF BCS-143905.
CR Abramowitz M., 1964, HDB MATH FUNCTIONS F
   Adler J, 2010, CYTOM PART A, V77A, P733, DOI 10.1002/cyto.a.20896
   Aler R, 2012, INFORM SCIENCES, V215, P53, DOI 10.1016/j.ins.2012.05.012
   Amigó E, 2009, INFORM RETRIEVAL, V12, P461, DOI 10.1007/s10791-008-9066-8
   [Anonymous], 2005, P ICML WORKSH LEARN
   [Anonymous], IEEE T SPEECH AUDIO
   [Anonymous], BRAIN IMAG BEHAV
   [Anonymous], 2011, FRONT PSYCHOL
   [Anonymous], P 20 ACM INT C MULT
   [Anonymous], P 12 ANN ACM INT C M
   [Anonymous], 2010, INT J COMPUT VISION, DOI DOI 10.1007/s11263-008-0204-y
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Blaschko M. B., 2008, CVPR 2008 IEEE C, P1
   Bloch G, 2008, INFORM SCIENCES, V178, P3813, DOI 10.1016/j.ins.2008.05.016
   Cahill ND, 2010, LECT NOTES COMPUT SC, V6204, P258, DOI 10.1007/978-3-642-14366-3_23
   Casey MA, 2008, P IEEE, V96, P668, DOI 10.1109/JPROC.2008.916370
   Formisano E, 2008, SCIENCE, V322, P970, DOI 10.1126/science.1164318
   Fu ZY, 2011, IEEE T MULTIMEDIA, V13, P303, DOI 10.1109/TMM.2010.2098858
   Fujihara H, 2010, IEEE T AUDIO SPEECH, V18, P638, DOI 10.1109/TASL.2010.2041386
   Hadjidimitriou SK, 2013, IEEE T AFFECT COMPUT, V4, P161, DOI 10.1109/T-AFFC.2013.6
   Hall M. A., 1999, Proceedings of the Twelfth International Florida AI Research Society Conference, P235
   Han JW, 2014, INFORM SCIENCES, V281, P781, DOI 10.1016/j.ins.2013.12.039
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   He JR, 2006, IEEE T IMAGE PROCESS, V15, P3170, DOI 10.1109/TIP.2006.877491
   Hu XT, 2012, IEEE T MULTIMEDIA, V14, P314, DOI 10.1109/TMM.2011.2172201
   Huang Jin, 2013, P 27 AAAI C ART INT
   Khunarsal P, 2013, INFORM SCIENCES, V243, P57, DOI 10.1016/j.ins.2013.04.014
   Kumar A., 2011, P ADV NEUR INF PROC, P1413
   Lartillot O., 2007, P INT C DIG AUD EFF, DOI DOI 10.1007/978-3-540-78246-9_31
   Leaver AM, 2010, J NEUROSCI, V30, P7604, DOI 10.1523/JNEUROSCI.0296-10.2010
   Lee S, 2013, IEEE T CONSUM ELECTR, V59, P652, DOI 10.1109/TCE.2013.6626252
   Liu TM, 2014, IEEE T HUM-MACH SYST, V44, P270, DOI 10.1109/THMS.2013.2296871
   Lo YL, 2009, INFORM SCIENCES, V179, P2662, DOI 10.1016/j.ins.2009.03.019
   Lopatka K, 2014, INFORM SCIENCES, V285, P223, DOI 10.1016/j.ins.2013.11.030
   McClosky D, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P337
   Miotto R, 2012, IEEE T AUDIO SPEECH, V20, P1096, DOI 10.1109/TASL.2011.2172423
   PANDYA DN, 1995, REV NEUROL, V151, P486
   Powers D. M. W., 2011, Journal of Machine Learning Technologies, V2, P37, DOI DOI 10.9735/2229-3981
   Ren JM, 2012, IEEE T AUDIO SPEECH, V20, P1134, DOI 10.1109/TASL.2011.2172426
   Staeren N, 2009, CURR BIOL, V19, P498, DOI 10.1016/j.cub.2009.01.066
   Tsunoo E, 2011, IEEE T AUDIO SPEECH, V19, P1003, DOI 10.1109/TASL.2010.2073706
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   van Gestel T, 2002, NEURAL PROCESS LETT, V15, P35
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Yuan YX, 2013, NEUROINFORMATICS, V11, P47, DOI 10.1007/s12021-012-9165-y
   Zhou DY, 2004, ADV NEUR IN, V16, P169
   Zhu DJ, 2013, CEREB CORTEX, V23, P786, DOI 10.1093/cercor/bhs072
NR 47
TC 8
Z9 9
U1 0
U2 44
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0020-0255
EI 1872-6291
J9 INFORM SCIENCES
JI Inf. Sci.
PD MAR 10
PY 2015
VL 297
BP 271
EP 282
DI 10.1016/j.ins.2014.11.020
PG 12
WC Computer Science, Information Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AY9HW
UT WOS:000347862200015
DA 2024-01-09
ER

PT J
AU Ghisalberti, G
AF Ghisalberti, Giosue
TI Listening to hymns and tears of mourning in Augustine's
   <i>Confessions</i>, Book 9
SO EARLY MUSIC
LA English
DT Article
DE Augustine; Confessions; hymns; psalms; mourning
AB Prior to his conversion in the summer of 386, Augustine of Hippo (354-430) could not decide if the practice of singing in church was appropriate, despite the long-standing tradition of religious singing in Judaism, and the hymns of early Christianity. He could not yet disassociate singing and music from its history, derived as it was from polytheism, and its use in Greek symposiums and the Roman theatre; in both cases music was used to venerate the gods and arouse passions. In the church of Milan, while listening to hymns and psalms, he succumbs to a persistent melancholia, as though the beauty of the melody and the human voice in church causes him to weep. Augustine may not consider the pleasure of listening to music and song in church to be a sin, but he does admit, at several inter-related moments in the Confessions, Book 9, to a deep disquiet about it. The emotions aroused by listening to singing in church unsettle him, and he cannot understand the source of these intense feelings; but when his writings in the Confessions are interpreted, being overwhelmed and crying can be attributed to an unacknowledged, but consistent, reason: Augustine mourns, intensely. In mourning, he recalls both the death of others and feels a relentless sense of loss in himself that he neither understands nor overcomes until a series of events outlined in his autobiography. Understanding the meaning of these important inter-related events will allow him ultimately to reconcile his conflicted feelings and, as a presbyter and bishop of Hippo, adopt the singing of hymns in his own church.
C1 Humber Coll, Dept Liberal Studies, Humanities, Toronto, ON, Canada.
RP Ghisalberti, G (corresponding author), Humber Coll, Dept Liberal Studies, Humanities, Toronto, ON, Canada.
EM giosue.ghisalberti@humber.ca
CR Ambrose Hexameron, 1961, FATHERS CHURCH, Vxlii, p[3, 69]
   Anderson W. D., 1994, MUSIC MUSICIANS ANCI, P5
   Augustine, 1949, DE MUSICS A SYNOPSIS, P102
   Barton Carlin A., 1993, The Sorrows of the Ancient Romans: The Gladiator and the Monster
   Beare W., 1950, ROMAN STAGE SHORT HI
   Borruso S., 2007, ON ORDER, P13
   BRENNAN B, 1988, VIGILIAE CHRISTIAN, V42, P267, DOI 10.1163/157007288X00255
   Burton P., 2007, LANGUAGE CONFESSIONS, P141
   Dodaro R., 2004, CHRIST JUST SOC THOU, P151
   Fitzgerald R., 1961, ODYSSEY, P127
   Gerson-Kiwi E., 1980, MIGRATIONS MUTATIONS
   Grube G. M. A., 1974, REPUBLIC, P68
   Hengel M., 1983, JESUS PAUT STUDIES E
   Kennedy G. A., 1983, GREEL RHETORIC CHRIS, P147
   Kittel B. Pedrotti, 1981, HUMNS WUMRAN TRANSLA
   Lim Timothy, 2005, The Dead Sea Scrolls: A Very Short Introduction
   MacMullen Ramsay, 1984, Christianizing the Roman Empire: (A.D. 100-400)
   Marrou H. I., 1964, A History of Education in Antiquity
   McKinnon J., 1987, MUSIC EARLY CHRISTIA, P1
   McLynn N. B., 1994, AMBROSE MILAN CHURCH, P194
   O'Connell R. J., 1978, ART CHRISTIAN INTELL, P35
   Paredi A., 1964, SAINTAMBROSE HIS LIF
   Pine-Coffin R. S., 1961, CONFESSIONS, P57
   Quasten J., 1983, MUSIC WORKSH PAGAN C
   Schnusenberg C. C., 1988, RELATIONSHIP CHRURCH
   Slavitt D. R., 1994, METAMORPHOSES, P60
   Smith JA, 2011, MUSIC IN ANCIENT JUDAISM AND EARLY CHRISTIANITY, P1
   Smith William, 1877, A Dictionary of Christian Biography, Literature, Sects and Doctrines during the First Eight Centuries
NR 28
TC 0
Z9 1
U1 0
U2 0
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 0306-1078
EI 1741-7260
J9 EARLY MUSIC
JI Early Music
PD MAY
PY 2015
VL 43
IS 2
BP 247
EP +
DI 10.1093/em/cav014
PG 9
WC Music
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music
GA CI4FW
UT WOS:000354704300006
DA 2024-01-09
ER

PT J
AU King, CM
AF King, Caitlin Merrett
TI Unsure Theory: Ambivalence as Methodology
SO ARTS
LA English
DT Article
DE autotheory; memory; visual arts; art practise; contemporary art; social
   history; critical writing; art writing; ambivalence; affect theory
AB Ambivalence is often regarded as a 'negative' emotion-an 'ugly feeling' as Sianne Ngai outlines-where not knowing and being unsure are seen as suspicious or mentally unhealthy. In this article, I outline the initial exploratory stage of the development of a new affective theory that I have termed 'Unsure Theory', in which ambivalence is observed as a mobile and aporetic state that, from an individual perspective, embraces the holding of multiple contradictory personal opinions. Unsure Theory also outlines ambivalence as an appropriate contemporary, meta-modernist response to late stage capitalism, our current socio-political moment, and its often negative impact on mental health. The aesthetics of ambivalence is explored through embracing a hesitant vernacular, an oscillating humorous, dry and ironic to sincere tone, and an internal, anecdotal first person voice that often addresses the reader. This exploration of Unsure Theory operates in an adjacent, feminist lineage of, and in homage to, Sad Girl Theory, as coined by writer, critic and artist Audrey Wollen, and Sick Woman Theory, by artist, writer and musician Johanna Hedva, as well as Lauren Fournier's critical responses to both. Written within the genre of art writing and in reference to my own interdisciplinary creative practice, this article exemplifies autotheoretical writing as an extension of contemporary visual art practice. This article is partially situated within my own personal experience of Cognitive Behavioural Therapy from 2020-2022 and reading the autotheoretical novel Chelsea Girls by Eileen Myles at the beginning of 2021. Through unpacking these personal experiences, I begin to outline an argument for embracing ambivalence, particularly within autotheoretical practice, where Unsure Theory seeks to repoliticise uncertainty towards a new generative, critical and personal perspective on not knowing.
C1 [King, Caitlin Merrett] Glasgow Sch Art, 167 Renfrew St, Glasgow G3 6RQ, Lanark, Scotland.
C3 Glasgow School of Art
RP King, CM (corresponding author), Glasgow Sch Art, 167 Renfrew St, Glasgow G3 6RQ, Lanark, Scotland.
EM c.mking1@student.gsa.ac.uk
CR Ahmed Sara, 2014, Feminist Killjoy
   Barron Benjamin., 2014, R PRINCE A WOLLEN SA
   Benjamin Tova, 2015, ROOKIE MAG
   Berlant L, 1998, CRIT INQUIRY, V24, P281, DOI 10.1086/448875
   Berlant L., 2011, CRUEL OPTIMISM
   Berlant L., 2010, The affect theory reader, DOI [10.1515/9780822393047, DOI 10.1515/9780822393047]
   Castro Jordan., 2022, THENOVELISTBYJORDANC
   Castro Jordan., 2022, NOVELIST NOVEL
   Craig Pollard, 2020, AESTHETIC ACTS CONFI
   Dante Alighieri, 1867, DIVINE COMEDY
   Dimitrova Maria., 2016, WHITE REV
   Elkin Lauren., 2013, WHITE REV
   Fournier Lauren, 2018, Auto/Biography Studies, V33, P643
   Fusco Maria., 2011, FRIEZE
   Gamble Ione., 2022, POLYESTER ZINE
   Greep Monica., 2022, MAILONLINE
   HALBERSTAM Jack, 2011, The Queer Art of Failure
   Hardt Michael, 1996, Radical Thought in Italy: A Potential Politics
   Haynes Laura, 2017, GLASGOW SCH ART
   Hedva Johanna., 2022, MASK MAGAZINE JAN
   Heller RachelS.F., 2010, ATTACHED
   Jones Amelia, 2006, SelfImage: Technology, Representation, and the Contemporary Subject
   King A. J., 2022, UNSURETHEORYPICS
   Lorde A., 2018, The master's tools will never dismantle the master's House
   Melville H, 2016, BILLY BUDD BARTLEBY
   Myles Eileen., 2016, I MUST BE LIVING TWI
   Nelson Maggie, 2016, The Argonauts
   Ngai S, 2017, CRIT INQUIRY, V43, P466, DOI 10.1086/689672
   Ngai Sianne., 2005, Ugly Feelings
   Ngai Sianne, 2020, THEORY GIMMICK AESTH
   OED Online, 2022, AMB
   OED Online, 2022, AMB ADJ
   Paul Kari., 2022, GUARDIAN US 0314
   Russell L., 2020, Glitch Feminism: A Manifesto
   Savage Ellena., 2017, TEXT
   Tunnicliffe Ava., 2015, NYLON
   Turner L, 2015, NOTES METAMODERNISM
   Whitman W., 1891, LEAVES GRASS, P29
NR 38
TC 1
Z9 1
U1 1
U2 1
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-0752
J9 ARTS
JI Arts
PD AUG
PY 2022
VL 11
IS 4
AR 78
DI 10.3390/arts11040078
PG 14
WC Humanities, Multidisciplinary
WE Emerging Sources Citation Index (ESCI)
SC Arts & Humanities - Other Topics
GA 4D2CR
UT WOS:000846954700001
OA gold
DA 2024-01-09
ER

PT J
AU Sinka, K
AF Sinka, Krisztina
TI MUSICAL SYMBOLS IN THE OPERA <i>THE THREE SISTERS</i> BY PETER EOTVOS
SO STUDIA UNIVERSITATIS BABES-BOLYAI MUSICA
LA English
DT Article
DE Peter Eotvos; opera; Three Sisters; libretto; musical symbolism; triad;
   third-parallels; instrumental symbolism; prose; sung speech; song
AB Opera, as a stage and acting genre, also uses theatrical elements (costumes, dramaturgy, etc.) to convey the work. Opera composers typically use musical symbols as well. I collected these devices of Peter Eotvos' best-known opera in my study based on literature research. Dramaturgically divided into three sequences, the work always examines its relationship with the other two central figures from the point of view of the central figure of the given part. One of the musical cornerstones of this is changing the internal relationships of triads. The two extreme notes of the triad are always constant (distance of a fifth), but the note located between them characterizes not only the quality of the chord, but also the state of the character connected to it. The unstable balance and reorganization of relationships is well represented by this construction principle. The author also uses the third-parallel, known since Mozart, as a classical musical representation of love. The choices of instrument also have symbolic power. The Prozorov family is represented by the group of woodwind instruments. A kind of irony on the part of the author is the use of cow bells to depict the behavior of the disgusting and unbearable Natasha. Soldiers are naturally represented by brass. Although Solioniy is a soldier, he is not accompanied by brass instruments, but by percussionists, hinting at his personality. The characters speak in different ways of the human voice. From prose to sung speech through to the melodies, there are all kinds of expressions of emotion.
C1 [Sinka, Krisztina] Univ Nyiregyhaza, Inst Mus, Nyiregyhaza, Hungary.
C3 University of Nyiregyhaza
RP Sinka, K (corresponding author), Univ Nyiregyhaza, Inst Mus, Nyiregyhaza, Hungary.
EM sinka.krisztina@nye.hu
CR Chekhov Anton Pavlovich, 1992, THE 3 SISTERS
   Csehy Zoltan, 2015, EXPERIMENTUM MUNDI P
   Eotvos Peter, 2015, PARLANDO RUBATO
   Grabocz Marta, 2013, RADIOTHER ONCOL
   Lang Zsolt, 2020, KORUNK
   Tallian Tibor, 2000, MUZSIKA, V43
NR 6
TC 0
Z9 0
U1 0
U2 0
PU UNIV BABES-BOLYAI
PI CLUJ-NAPOCA
PA MIHAIL KOGALNICEANU NR. 1, CLUJ-NAPOCA RO-3400, ROMANIA
SN 1844-4369
EI 2065-9628
J9 STUD U BABES-BOL MUS
JI Stud. Univ. Babes-Bolyai Mus.
PD DEC
PY 2022
VL 67
SI 2
BP 65
EP 72
DI 10.24193/subbmusica.2022.spiss2.05
PG 8
WC Music
WE Emerging Sources Citation Index (ESCI)
SC Music
GA 9B8HG
UT WOS:000934972400005
OA gold
DA 2024-01-09
ER

PT J
AU Trappe, HJ
AF Trappe, Hans-Joachim
TI The effects of music on the cardiovascular system and cardiovascular
   health
SO HEART
LA English
DT Review
ID HEART; EMOTIONS; SURGERY; THERAPY
AB Music may not only improve quality of life but may also effect changes in heart rate and heart rate variability. It has been shown that cerebral flow was significantly lower when listening to 'Va pensiero' from Verdi's 'Nabucco' (70.4 +/- 3.3 cm/s) compared with 'Libiam nei lieti calici' from Verdi's 'La Traviata' (70.2 +/- 3.1 cm/s) (p<0.02) or Bach's Cantata No. 169 'Gott soll allein mein Herze haben' (70.9 +/- 2.9 cm/s) (p<0.02). There was no significant difference in cerebral flow during rest (67.6 +/- 3.3 cm/s) or when listening to Beethoven's Ninth Symphony (69.4 +/- 3.1 cm/s). It was reported that relaxing music significantly decreases the level of anxiety of patients in a preoperative setting (State-Trait Anxiety Inventory (STAI)-X-1 score 34)-to a greater extent even than orally administered midazolam (STAI-X-1 score 36) (p<0.001). In addition the score was better after surgery in the music group (STAI-X-1 score 30) compared with the midazolam group (STAI-X-1 score 34) (p<0.001). Higher effectiveness and absence of apparent adverse effects make relaxing, preoperative music a useful alternative to midazolam for premedication. In addition, there is sufficient practical evidence of stress reduction suggesting that a proposed regimen of listening to music while resting in bed after open-heart surgery is important in clinical use. After 30 min of bed rest, there was a significant difference in cortisol levels between the music (484.4 mmol/l) and the non-music group (618.8 mmol/l) (p<0.02). Vocal and orchestral music produce significantly better correlations between cardiovascular or respiratory signals compared with music with a more uniform emphasis (p<0.05). The greatest benefit on health is visible with classical music and meditation music, whereas heavy metal music or techno are not only ineffective but possibly dangerous and can lead to stress and/or life-threatening arrhythmias. The music of many composers most effectively improves quality of life, will increase health and probably prolong life, particularly music by Bach, Mozart or Italian composers.
C1 Univ Bochum, Dept Cardiol & Angiol, D-44625 Herne, Germany.
C3 Ruhr University Bochum
RP Trappe, HJ (corresponding author), Univ Bochum, Dept Cardiol & Angiol, Hoelkeskampring 40, D-44625 Herne, Germany.
EM hans-joachim.trappe@ruhr-uni-bochum.de
CR Altenmüller E, 2002, NEUROPSYCHOLOGIA, V40, P2242, DOI 10.1016/S0028-3932(02)00107-0
   Antonietti A, 2009, STUD HEALTH TECHNOL, V145, P179, DOI 10.3233/978-1-60750-018-6-179
   Argstatter H, 2006, CLIN RES CARDIOL, V95, P514, DOI 10.1007/s00392-006-0425-4
   Bernardi L, 2006, HEART, V92, P445, DOI 10.1136/hrt.2005.064600
   Bernardi L, 2009, CIRCULATION, V119, P3171, DOI 10.1161/CIRCULATIONAHA.108.806174
   Bernatzky G, 2004, NEUROSCI LETT, V361, P4, DOI 10.1016/j.neulet.2003.12.022
   Bringman H, 2009, ACTA ANAESTH SCAND, V53, P759, DOI 10.1111/j.1399-6576.2009.01969.x
   Chan MF, 2009, INT J MENT HEALTH NU, V18, P285, DOI 10.1111/j.1447-0349.2009.00614.x
   Goertz W, 2009, CLIN RES CARDIOL, V86, P802
   Grandjean D, 2008, CONSCIOUS COGN, V17, P484, DOI 10.1016/j.concog.2008.03.019
   Grewe O, 2005, ANN NY ACAD SCI, V1060, P446, DOI 10.1196/annals.1360.041
   Koelsch S, 2005, TRENDS COGN SCI, V9, P578, DOI 10.1016/j.tics.2005.10.001
   Koelsch S, 2009, ANN NY ACAD SCI, V1169, P374, DOI 10.1111/j.1749-6632.2009.04592.x
   Krout Robert E, 2003, Am J Hosp Palliat Care, V20, P129, DOI 10.1177/104990910302000211
   Mansky PJ, 2006, CANCER J, V12, P425, DOI 10.1097/00130404-200609000-00011
   Mramor KM, 2001, J PALLIATIVE CARE, V17, P182
   Nakahara H, 2009, ANN NY ACAD SCI, V1169, P359, DOI 10.1111/j.1749-6632.2009.04788.x
   Nilsson U, 2009, J CLIN NURS, V18, P2153, DOI 10.1111/j.1365-2702.2008.02718.x
   Nilsson U, 2009, HEART LUNG, V38, P201, DOI 10.1016/j.hrtlng.2008.07.008
   Norton A, 2009, ANN NY ACAD SCI, V1169, P431, DOI 10.1111/j.1749-6632.2009.04859.x
   Panksepp J, 2002, BEHAV PROCESS, V60, P133, DOI 10.1016/S0376-6357(02)00080-3
   Särkämö T, 2008, BRAIN, V131, P866, DOI 10.1093/brain/awn013
   Storm F, 2006, HEILEN TONEN, P17
   Trappe HJ, 2009, DEUT MED WOCHENSCHR, V134, P2601, DOI 10.1055/s-0029-1243066
   Trappe HJ, 2009, KARDIOLOGE, V3, P461
   USANOVA LD, 2009, MED TEKH, V2, P45
   Yoshie M, 2009, EXP BRAIN RES, V199, P117, DOI 10.1007/s00221-009-1979-y
NR 27
TC 78
Z9 89
U1 3
U2 93
PU BMJ PUBLISHING GROUP
PI LONDON
PA BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND
SN 1355-6037
EI 1468-201X
J9 HEART
JI Heart
PD DEC
PY 2010
VL 96
IS 23
BP 1868
EP 1871
DI 10.1136/hrt.2010.209858
PG 4
WC Cardiac & Cardiovascular Systems
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Cardiovascular System & Cardiology
GA 677LZ
UT WOS:000283995200003
PM 21062776
DA 2024-01-09
ER

PT J
AU Eerola, T
   Vuoskoski, JK
   Peltola, HR
   Putkinen, V
   Schäfer, K
AF Eerola, Tuomas
   Vuoskoski, Jonna K.
   Peltola, Henna-Riikka
   Putkinen, Vesa
   Schafer, Katharina
TI An integrative review of the enjoyment of sadness associated with music
SO PHYSICS OF LIFE REVIEWS
LA English
DT Review
DE Music; Emotions; Sadness; Pleasure; Hedonic shift; Enjoyment
ID SAD MUSIC; INDIVIDUAL-DIFFERENCES; CULTURAL-DIFFERENCES;
   EMOTIONAL-REACTIONS; PERSONALITY-TRAITS; VOCAL EXPRESSION; NEGATIVITY
   BIAS; RESPONSES; EXPERIENCE; OXYTOCIN
AB The recent surge of interest towards the paradoxical pleasure produced by sad music has generated a handful of theories and an array of empirical explorations on the topic. However, none of these have attempted to weigh the existing evidence in a systematic fashion. The present work puts forward an integrative framework laid out over three levels of explanation - biological, psycho social, and cultural - to compare and integrate the existing findings in a meaningful way. First, we review the evidence pertinent to experiences of pleasure associated with sad music from the fields of neuroscience, psychophysiology, and endocrinology. Then, the psychological and interpersonal mechanisms underlying the recognition and induction of sadness in the context of music are combined with putative explanations ranging from social surrogacy and nostalgia to feelings of being moved. Finally, we address the cultural aspects of the paradox - the extent to which it is embedded in the Western notion of music as an aesthetic, contemplative object by synthesising findings from history, ethnography, and empirical studies. Furthermore, we complement these explanations by considering the particularly significant meanings that sadness portrayed in art can evoke in some perceivers. Our central claim is that one cannot attribute the enjoyment of sadness fully to any one of these levels, but to a chain of functionalities afforded by each level. Each explanatory level has several putative explanations and its own shift towards positive valence, but none of them deliver the full transformation from a highly negative experience to a fully enjoyable experience alone. The current evidence within this framework ranges from weak to non-existent at the biological level, moderate at the psychological level, and suggestive at the cultural level. We propose a series of focussed topics for future investigation that would allow to deconstruct the drivers and constraints of the processes leading to pleasurable music-related sadness. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Eerola, Tuomas] Univ Durham, Durham, England.
   [Vuoskoski, Jonna K.; Peltola, Henna-Riikka; Putkinen, Vesa; Schafer, Katharina] Univ Jyvaskyla, Jyvaskyla, Finland.
   [Vuoskoski, Jonna K.] Univ Oslo, Oslo, Norway.
C3 Durham University; University of Jyvaskyla; University of Oslo
RP Eerola, T (corresponding author), Univ Durham, Durham, England.
EM tuomas.eerola@durham.ac.uk
RI Vuoskoski, Jonna K/B-4944-2018; Peltola, Henna-Riikka/GRS-2315-2022;
   Eerola, Tuomas/K-7596-2019; Putkinen, Vesa/JCP-4689-2023
OI Vuoskoski, Jonna K/0000-0003-0049-4373; Eerola,
   Tuomas/0000-0002-2896-929X; Peltola, Henna-Riikka/0000-0002-9372-1805
CR Abou-Saleh MT, 1998, PSYCHONEUROENDOCRINO, V23, P465
   Adolphs R, 2017, SOC COGN AFFECT NEUR, V12, P24, DOI 10.1093/scan/nsw153
   AGAWU VK, 1988, ETHNOMUSICOLOGY, V32, P75, DOI 10.2307/852226
   Andrews PW, 2009, PSYCHOL REV, V116, P620, DOI 10.1037/a0016242
   [Anonymous], HDB EMOTION
   [Anonymous], ADULT CRYING BIOPSYC
   [Anonymous], 1990, Music, Art, and Metaphysics
   [Anonymous], 2002, Musical Meaning: Toward a Critical History
   Archer J., 1999, The nature of grief: The evolution and psychology of reactions to loss
   Aubé W, 2015, SOC COGN AFFECT NEUR, V10, P399, DOI 10.1093/scan/nsu067
   Aucouturier JJ, 2017, COGNITION, V161, P94, DOI 10.1016/j.cognition.2017.01.019
   Augustine AA, 2009, COGNITION EMOTION, V23, P1181, DOI 10.1080/02699930802396556
   Balkwill LL, 2004, JPN PSYCHOL RES, V46, P337, DOI 10.1111/j.1468-5584.2004.00265.x
   Barr-Zisowitz C, 2000, HDB EMOTIONS, P607
   Barrett FS, 2010, EMOTION, V10, P390, DOI 10.1037/a0019006
   Barrett L. F., 2015, The psychological construction of emotion
   Barrett LF, 2006, PERSPECT PSYCHOL SCI, V1, P28, DOI 10.1111/j.1745-6916.2006.00003.x
   Barrett LF, 2015, NAT REV NEUROSCI, V16, P419, DOI 10.1038/nrn3950
   Barrett LF, 2009, ADV EXP SOC PSYCHOL, V41, P167, DOI 10.1016/S0065-2601(08)00404-8
   BARTEL Dietrich, 1997, Musica Poetica: musical -rhetorical figures in German Baroque music
   Baumgartner T, 2006, INT J PSYCHOPHYSIOL, V60, P34, DOI 10.1016/j.ijpsycho.2005.04.007
   Benedek M, 2011, BIOL PSYCHOL, V86, P320, DOI 10.1016/j.biopsycho.2010.12.012
   Bennett MP, 2008, EVID-BASED COMPL ALT, V5, P37, DOI 10.1093/ecam/nem041
   Bicknell J, 2009, WHY MUSIC MOVES US, P1, DOI 10.1057/9780230233836
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Boiger M, 2013, PERS SOC PSYCHOL B, V39, P540, DOI 10.1177/0146167213478201
   Bowlby J, 1981, Attachment and loss Loss: Sadness and depression, V3
   Brattico E, 2016, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00676
   Brattico E, 2013, PSYCHOL AESTHET CREA, V7, P48, DOI 10.1037/a0031624
   BRIGGS CL, 1993, AM ANTHROPOL, V95, P929, DOI 10.1525/aa.1993.95.4.02a00080
   Brown S, 2004, NEUROREPORT, V15, P2033, DOI 10.1097/00001756-200409150-00008
   Chen L, 2007, MEDIA PSYCHOL, V9, P695, DOI 10.1080/15213260701283293
   Christopher Small, 1998, MUSICKING MEANINGS P
   Codispoti M, 2003, PSYCHOPHYSIOLOGY, V40, P863, DOI 10.1111/1469-8986.00104
   Cohen J, 2006, PSYCHOLOGY OF ENTERTAINMENT, P183
   COX A., 2001, Musicae Scientiae, V5, P195, DOI [10.1177/102986490100500204, DOI 10.1177/102986490100500204]
   Cox A., 2016, Music and Embodied Cognition: Listening, Moving, Feeling, and Thinking
   Cross I., 2008, MUSIC SCI, V12, P147, DOI [DOI 10.1177/1029864908012001071, 10.1177/1029864908012001071]
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Davies S., 2011, Empathy: Philosophical and psychological perspectives, P134, DOI [10.1093/acprof:oso/9780199539956.003.0010, DOI 10.1093/ACPROF:OSO/9780199539956.003.0010]
   DAVIS MH, 1983, J PERS SOC PSYCHOL, V44, P113, DOI 10.1037/0022-3514.44.1.113
   Decety Jean, 2004, Behav Cogn Neurosci Rev, V3, P71, DOI 10.1177/1534582304267187
   DeMarco TC, 2015, PSYCHOL AESTHET CREA, V9, P81, DOI 10.1037/a0038691
   DEWIED M, 1995, POETICS, V23, P91, DOI 10.1016/0304-422X(94)00010-4
   Drake JE, 2012, PSYCHOL AESTHET CREA, V6, P255, DOI 10.1037/a0026909
   Eagleton Terry, 2003, SWEET VIOLENCE IDEA
   Eeroia T, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01176
   Eerola T, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157444
   Eerola T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00487
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   Elfenbein HA, 2002, PSYCHOL BULL, V128, P203, DOI 10.1037//0033-2909.128.2.203
   Evans P, 2008, MUSIC SCI, V12, P75, DOI 10.1177/102986490801200105
   Evers S, 2000, EUR ARCH PSY CLIN N, V250, P144, DOI 10.1007/s004060070031
   Fancourt D, 2014, BRAIN BEHAV IMMUN, V36, P15, DOI 10.1016/j.bbi.2013.10.014
   Fiveash A, 2016, PSYCHOL MUSIC, V44, P1346, DOI 10.1177/0305735615628057
   Fivush R, 2003, AUTOBIOGRAPHICAL MEMORY AND THE CONSTRUCTION OF A NARRATIVE SELF: DEVELOPMENTAL AND CULTURAL PERSPECTIVES, P149
   Frijda NH, 2007, PERSPECT PSYCHOL SCI, V2, P227, DOI 10.1111/j.1745-6916.2007.00042.x
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   Gabrielsson A., 2011, Strong Experiences with Music
   Gabrielsson A, 2001, MUSIC SCI, V5, P123, DOI 10.1177/10298649020050S105
   Gangestad SW, 2017, HORM BEHAV, V91, P122, DOI 10.1016/j.yhbeh.2016.08.005
   Garrido S, 2011, MUSIC PERCEPT, V28, P279, DOI 10.1525/MP.2011.28.3.279
   Gerra G, 1998, INT J PSYCHOPHYSIOL, V28, P99, DOI 10.1016/S0167-8760(97)00071-8
   Gibson R., 2000, EMPIR STUD ARTS, V18, P43, DOI DOI 10.2190/B51G-8U0W-N0EQ-MJUU
   Goldenberg Jamie L, 1999, Media Psychology, V1, P313, DOI [DOI 10.1207/S1532785XMEP0104_2, 10.1207/S1532785XMEP0104_2, 10.1207/s1532785xmep0104_2]
   Goldstein TR, 2009, PSYCHOL AESTHET CREA, V3, P232, DOI 10.1037/a0015343
   Gomez P, 2004, INT J PSYCHOPHYSIOL, V53, P91, DOI 10.1016/j.ijpsycho.2004.02.002
   Grape C, 2003, INTEGR PHYS BEH SCI, V38, P65
   Green AC, 2008, NEUROREPORT, V19, P711, DOI 10.1097/WNR.0b013e3282fd0dd8
   Greenwood DN, 2009, COMMUN RES, V36, P637, DOI 10.1177/0093650209338906
   Hamilton Ch., 2016, PHILOS TRAGEDY
   Hanich J, 2014, PSYCHOL AESTHET CREA, V8, P130, DOI 10.1037/a0035690
   Heinrichs M, 2003, BIOL PSYCHIAT, V54, P1389, DOI 10.1016/S0006-3223(03)00465-7
   Herman D, 2007, NARRATIVE, V15, P306, DOI 10.1353/nar.2007.0023
   HILL CA, 1991, J PERS SOC PSYCHOL, V60, P112
   Hunter PG, 2011, EMOTION, V11, P1068, DOI 10.1037/a0023749
   Huron D, 2011, MUSIC SCI, V15, P146, DOI 10.1177/1029864911401171
   HURON DAVID, 2006, SWEET ANTICIPATION M, P148, DOI DOI 10.7551/MITPRESS/6575.001.0001
   Ishizu T, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021852
   Istók E, 2009, MUSIC SCI, V13, P183, DOI 10.1177/102986490901300201
   Jackendoff R, 2006, COGNITION, V100, P33, DOI 10.1016/j.cognition.2005.11.005
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2015, AM J PSYCHOL, V128, P281
   Juslin PN, 2014, PSYCHOL MUSIC, V42, P599, DOI 10.1177/0305735613484548
   Juslin PN, 2013, PHYS LIFE REV, V10, P235, DOI 10.1016/j.plrev.2013.05.008
   Juslin PN, 2010, MUSIC ANAL, V29, P334, DOI 10.1111/j.1468-2249.2011.00323.x
   Juslin PN, 2011, MUSIC SCI, V15, P174, DOI 10.1177/1029864911401169
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Juslin PN, 1997, MUSIC PERCEPT, V14, P383
   Keltner D, 2003, COGNITION EMOTION, V17, P297, DOI 10.1080/02699930302297
   Keltner D., 2006, Evolution and social psychology, P115
   Kidd DC, 2013, SCIENCE, V342, P377, DOI 10.1126/science.1239918
   Kiecolt-Glaser JK, 2010, NEUROSCI BIOBEHAV R, V35, P33, DOI 10.1016/j.neubiorev.2009.09.003
   Kiecolt-Glaser JK, 2002, ANNU REV PSYCHOL, V53, P83, DOI 10.1146/annurev.psych.53.100901.135217
   Kim J, 2017, NEUROIMAGE, V148, P42, DOI 10.1016/j.neuroimage.2017.01.002
   Kivy P., 1990, Music Alone: Philosophical Reflections on the Purely Musical Experience
   Knobloch-Westerwick S, 2013, COMMUN RES, V40, P747, DOI 10.1177/0093650212437758
   Kober H, 2008, NEUROIMAGE, V42, P998, DOI 10.1016/j.neuroimage.2008.03.059
   Koelsch S, 2006, HUM BRAIN MAPP, V27, P239, DOI 10.1002/hbm.20180
   Koelsch S, 2014, NAT REV NEUROSCI, V15, P170, DOI 10.1038/nrn3666
   Konecni VJ, 2005, B PSYCHOL ARTS, V5, P27, DOI DOI 10.1037/E674862010-005
   Koopmann-Holm B, 2014, J PERS SOC PSYCHOL, V107, P1092, DOI 10.1037/a0037684
   Kosfeld M, 2005, NATURE, V435, P673, DOI 10.1038/nature03701
   Kottler J.A., 2001, ADULT CRYING BIOPSYC, P1
   Kragel PA, 2016, TRENDS COGN SCI, V20, P444, DOI 10.1016/j.tics.2016.03.011
   Kreibig SD, 2007, PSYCHOPHYSIOLOGY, V44, P787, DOI 10.1111/j.1469-8986.2007.00550.x
   Laukka P, 2013, EMOTION, V13, P434, DOI 10.1037/a0031388
   Launay J, 2015, EMPIR MUSICOL REV, V10, P30
   Lee CJ, 2013, J CONSUM RES, V40, P382, DOI 10.1086/670609
   Leichtman MD, 2003, CULTURAL VARIATIONS, P73
   Leng G., 2016, J. Neuroendocrinol, V28, DOI [DOI 10.1111/JNE.12413, 10.1111/jne.12413]
   Levenson RW, 2003, ANN NY ACAD SCI, V1000, P348, DOI 10.1196/annals.1280.016
   Levinson J., 2006, Contemplating art: essays in aesthetics
   Lindquist KA, 2012, BEHAV BRAIN SCI, V35, P121, DOI 10.1017/S0140525X11000446
   Lippman JR, 2012, J ADOLESCENT RES, V27, P751, DOI 10.1177/0743558412447853
   Livingstone SR, 2009, MUSIC SCI, P83, DOI 10.1177/1029864909013002061
   Luminet O, 2000, COGNITION EMOTION, V14, P661, DOI 10.1080/02699930050117666
   Mar RA, 2008, PERSPECT PSYCHOL SCI, V3, P173, DOI 10.1111/j.1745-6924.2008.00073.x
   Menninghaus W, 2017, BEHAV BRAIN SCI, V40, DOI 10.1017/S0140525X17000309
   Menninghaus W, 2015, COGNITION, V143, P48, DOI 10.1016/j.cognition.2015.05.026
   Menninghaus W, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0128451
   Menon V, 2005, NEUROIMAGE, V28, P175, DOI 10.1016/j.neuroimage.2005.05.053
   Mesquita B, 2003, BEHAV RES THER, V41, P777, DOI 10.1016/S0005-7967(02)00189-4
   Mesquita B, 2001, ROLE CULTURE APPRAIS, P33
   Mesquita B, 2016, CURR OPIN PSYCHOL, V8, P31, DOI 10.1016/j.copsyc.2015.09.015
   Meyer LB., 1956, Emotion and meaning in music
   Meyer RK, 1998, MUSIC PERCEPT, V16, P135
   Mills S., 2012, MORTALITY, V17, P145, DOI DOI 10.1080/13576275.2012.675231
   Mitterschiffthaler MT, 2007, HUM BRAIN MAPP, V28, P1150, DOI 10.1002/hbm.20337
   Miu AC, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030618
   Miyamoto Y, 2011, EMOTION, V11, P1346, DOI 10.1037/a0025135
   Molnar-Szakacs I, 2006, SOC COGN AFFECT NEUR, V1, P235, DOI 10.1093/scan/nsl029
   Nesse RM, 2009, AM PSYCHOL, V64, P129, DOI 10.1037/a0013503
   Niedenthal P., 2009, EMOTION DIFFERENCES
   Nieminen S, 2012, MUSIC SCI, V16, P372, DOI 10.1177/1029864912450454
   Nilsson U, 2009, J CLIN NURS, V18, P2153, DOI 10.1111/j.1365-2702.2008.02718.x
   Nussbaum M., 2003, Upheavals of Thought: The Intelligence of Emotions
   Oatley K, 2009, EMOT REV, V1, P206, DOI 10.1177/1754073909103588
   Oliver MB, 2012, HUM COMMUN RES, V38, DOI 10.1111/j.1468-2958.2012.01427.x
   Oliver MB, 2011, J COMMUN, V61, P984, DOI 10.1111/j.1460-2466.2011.01585.x
   OLIVER MB, 1993, HUM COMMUN RES, V19, P315, DOI 10.1111/j.1468-2958.1993.tb00304.x
   Palisca A., 2000, NORTON ANTHOLOGY W M
   Panksepp J, 2005, CONSCIOUS COGN, V14, P30, DOI 10.1016/j.concog.2004.10.004
   Park M, 2013, BRAIN RES, V1523, P68, DOI 10.1016/j.brainres.2013.05.042
   Pelowski M, 2017, PHYS LIFE REV, V21, P80, DOI 10.1016/j.plrev.2017.02.003
   Peltola HR, 2016, MUSIC SCI, V20, P84, DOI 10.1177/1029864915611206
   Peltola HR, 2014, MUSIC SCI, V18, P292, DOI 10.1177/1029864914536199
   Perlovsky Leonid, 2017, MUSIC PASSIONS COGNI
   Petersson M, 2007, PSYCHONEUROENDOCRINO, V32, P959, DOI 10.1016/j.psyneuen.2007.06.015
   Pinker S., 1997, How the mind works
   Posner J, 2005, DEV PSYCHOPATHOL, V17, P715, DOI 10.1017/S0954579405050340
   Preller KH, 2017, CURR BIOL, V27, P451, DOI 10.1016/j.cub.2016.12.030
   Preston SD, 2002, BEHAV BRAIN SCI, V25, P1, DOI 10.1017/S0140525X02000018
   Prossin AR, 2016, MOL PSYCHIATR, V21, P243, DOI 10.1038/mp.2015.110
   Reber R, 2004, PERS SOC PSYCHOL REV, V8, P364, DOI 10.1207/s15327957pspr0804_3
   Rimé B, 2009, EMOT REV, V1, P60, DOI 10.1177/1754073908097189
   Robinson J., 2005, Deeper than Reason: Emotion and its Role in Literature, Music, and Art
   Routledge C, 2012, MEMORY, V20, P452, DOI 10.1080/09658211.2012.677452
   Rozin P, 2001, PERS SOC PSYCHOL REV, V5, P296, DOI 10.1207/S15327957PSPR0504_2
   Russell JA, 2003, ANNU REV PSYCHOL, V54, P329, DOI 10.1146/annurev.psych.54.101601.145102
   Ryff CD, 2008, J HAPPINESS STUD, V9, P13, DOI 10.1007/s10902-006-9019-0
   RYFF CD, 1995, J PERS SOC PSYCHOL, V69, P719
   Saarikallio S., 2007, Psychol. Music, V35, P88, DOI [10.1177/0305735607068889, DOI 10.1177/0305735607068889]
   Saarimäki H, 2016, CEREB CORTEX, V26, P2563, DOI 10.1093/cercor/bhv086
   Sachs ME, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00404
   Salimpoor VN, 2015, TRENDS COGN SCI, V19, P86, DOI 10.1016/j.tics.2014.12.001
   Salimpoor VN, 2011, NAT NEUROSCI, V14, P257, DOI 10.1038/nn.2726
   Schachter S., 1959, The Psychology of Affiliation
   Scherer K. R., 2001, MUSIC EMOTION THEORY, P361, DOI DOI 10.1080/0929821042000317822
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   Schramm H, 2010, POETICS, V38, P319, DOI 10.1016/j.poetic.2010.03.002
   Schubert E., 1996, PSYCHOL MUSIC, V24, P18, DOI DOI 10.1177/0305735696241003
   Shweder R. A., 2000, HDB EMOTIONS, P397
   Singer JA, 2004, J PERS, V72, P437, DOI 10.1111/j.0022-3506.2004.00268.x
   Smuts A, 2009, PHILOS COMPASS, V4, P39, DOI 10.1111/j.1747-9991.2008.00199.x
   Stearns PN, 1996, EMOTIONS SOCIAL CULT, P133
   TAGG P, 1993, CRIT QUART, V35, P54, DOI 10.1111/j.1467-8705.1993.tb00469.x
   Taruffi L, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-14849-0
   Taruffi L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0110490
   Ter Bogt TFM, 2017, PSYCHOL MUSIC, V45, P155, DOI 10.1177/0305735616650029
   TOLBERT E, 1990, YEARB TRADIT MUSIC, V22, P80, DOI 10.2307/767933
   Tomasello M, 2005, BEHAV BRAIN SCI, V28, P675, DOI 10.1017/S0140525X05000129
   Tooby J, 2001, SUB-STANCE, P6
   Trost W, 2012, CEREB CORTEX, V22, P2769, DOI 10.1093/cercor/bhr353
   Turner RA, 2002, STRESS, V5, P269, DOI 10.1080/1025389021000037586-1
   Twenge JM, 2007, BRIT J SOC PSYCHOL, V46, P205, DOI 10.1348/014466605X90793
   Vaish A, 2008, PSYCHOL BULL, V134, P383, DOI 10.1037/0033-2909.134.3.383
   van den Burg EH, 2011, J MOL NEUROSCI, V43, P200, DOI 10.1007/s12031-010-9452-8
   Van den Tol AJM, 2015, PSYCHOL MUSIC, V43, P473, DOI 10.1177/0305735613517410
   Van den Tol AJM, 2013, PSYCHOL MUSIC, V41, P440, DOI 10.1177/0305735611430433
   van Goethem A, 2011, MUSIC SCI, V15, P208, DOI 10.1177/1029864911401174
   Vuoskoski JK, 2017, BEHAV BRAIN SCI, V40, DOI 10.1017/S0140525X1700187X
   Vuoskoski JK, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00439
   Vuoskoski JK, 2015, PSYCHOL MUSIC, V43, P262, DOI 10.1177/0305735613502373
   Vuoskoski JK, 2012, PSYCHOL AESTHET CREA, V6, P204, DOI 10.1037/a0026937
   Wagner V, 2014, PSYCHOL AESTHET CREA, V8, P120, DOI 10.1037/a0036126
   Wassiliwizky E, 2017, SOC COGN AFFECT NEUR, V12, P1229, DOI 10.1093/scan/nsx069
   Wassiliwizky E, 2015, PSYCHOL AESTHET CREA, V9, P405, DOI 10.1037/aca0000023
   Watt R.J., 1998, MUSIC SCI, V2, P33, DOI DOI 10.1177/102986499800200103
   Waugh CE, 2012, BEHAV BRAIN SCI, V35, P170, DOI 10.1017/S0140525X11001646
   Wildschut T, 2006, J PERS SOC PSYCHOL, V91, P975, DOI 10.1037/0022-3514.91.5.975
   Wirth W, 2012, HUM COMMUN RES, V38, P406, DOI 10.1111/j.1468-2958.2012.01434.x
   Woolfolk R., 2002, J THEORETICAL PHILOS, V22, P19, DOI DOI 10.1037/H0091192
   Wright CE, 2005, BRAIN BEHAV IMMUN, V19, P345, DOI 10.1016/j.bbi.2004.10.003
   Zachar P, 2014, EMOT REV, V6, P324, DOI 10.1177/1754073914534499
   Zickfeld JH, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00723
NR 207
TC 64
Z9 68
U1 2
U2 60
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1571-0645
EI 1873-1457
J9 PHYS LIFE REV
JI Phys. Life Rev.
PD AUG
PY 2018
VL 25
BP 100
EP 121
DI 10.1016/j.plrev.2017.11.016
PG 22
WC Biology; Biophysics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Life Sciences & Biomedicine - Other Topics; Biophysics
GA GR8MJ
UT WOS:000442977700021
PM 29198528
OA Green Accepted, Green Submitted, Green Published, hybrid
DA 2024-01-09
ER

PT J
AU Parncutt, R
AF Parncutt, Richard
TI The emotional connotations of major versus minor tonality: One or more
   origins?
SO MUSICAE SCIENTIAE
LA English
DT Article
DE emotion; leading tone; major; minor; pitch; prolongation; salience;
   speech; uncertainty; Schenker; music and evolution
ID COMBINATION TONES; PHASE SENSITIVITY; CHORALE SEQUENCES; YOUNG-CHILDREN;
   VIRTUAL-PITCH; MUSIC; PERCEPTION; CONSONANCE; INFANTS; FREQUENCY
AB The association between major/minor tonality and positive/negative emotional valence is psychologically robust, but without a single accepted explanation. I compare six partially related theories. Dissonance: On average, passages in minor keys are more dissonant because, on average, the minor triad is more dissonant (rougher, less harmonic) or because tonal structure is more complex. Alterity and markedness: Major triads and scales are more common than minor, and positive valence is more common than negative. Major and positive valence are the norm; minor and negative are marked Others. Uncertainty: The minor triad has a more ambiguous (less salient) root than the major, and the minor scale has more variable form and a more ambiguous (less stable) tonic; uncertainty is associated with anger, sadness, distress, and grief. Speech: By comparison to major triads and scales, minor contain pitch(es) that are lower than expected - just as sad speech is lower than expected. Salience: In diatonic chord progressions, flattened diatonic scale degrees are more salient than sharpened because their harmonics better match the prevailing scale. Scale degrees 3 and 6 are more likely to destabilize tonality in minor than major tonalities. Familiarity: Arbitrary emotional differences between major and minor were reinforced in a historical process of cultural differentiation. For each theory, there are credible arguments and evidence for and against. All theories are broadly consistent with Terhardt's pattern-recognition model of pitch perception (non-musical perceptual familiarity with the harmonic series), Schenker's concept of prolongation (specifically, tonal voice leading as a prolongation of the tonic triad), evolutionary explanations of the emotional connotations of alterity, and a psychohistory of tonality in which melody, polyphony, leading tones, and the major-minor system emerged at different times, explicable by different psychological principles.
C1 [Parncutt, Richard] Graz Univ, Graz, Austria.
C3 University of Graz
RP Parncutt, R (corresponding author), Graz Univ, Ctr Systemat Musicol, Merangasse 70, Graz, Austria.
EM parncutt@uni-graz.at
CR [Anonymous], 1962, STRUCTURAL HEARING T
   [Anonymous], SCI PSYCHOL MUSIC PE
   [Anonymous], 1995, ANAL FUGUE SCHENKERI
   [Anonymous], 1954, On the Sensations of Tone
   [Anonymous], HIGH CONTRAST RACE G
   [Anonymous], SCHENKER STUDIES
   [Anonymous], J AESTHETICS ART CRI
   [Anonymous], 1994, ENTSTEHUNG TONAL ENK
   [Anonymous], 1995, BACHS MODAL CHORALES
   [Anonymous], 1993, CONTEMP MUSIC REV
   [Anonymous], 1890, TONPSYCHOLOGIE
   ARMSTRONG SL, 1983, COGNITION, V13, P263, DOI 10.1016/0010-0277(83)90012-4
   Bänziger T, 2005, SPEECH COMMUN, V46, P252, DOI 10.1016/j.specom.2005.02.016
   Battistella E. L., 1990, MARKEDNESS EVALUATIO
   Baumeister R. F., 2001, Rev. Gen. Psychol, V5, P323, DOI [DOI 10.1037/1089-2680.5.4.323, 10.1037/1089-2680.5.4.323]
   BERGER K, 2004, MUSICA FICTA THEORIE
   Bharucha JJ, 1996, MUSIC PERCEPT, V13, P383
   Bregman A.S., 1990, AUDITORY SCENE ANAL, DOI DOI 10.7551/MITPRESS/1486.001.0001
   BRYDEN JR, 1969, INDEX GREGORIAN CHAN, V1
   BURNS EM, 1978, J ACOUST SOC AM, V63, P456, DOI 10.1121/1.381737
   CACIOPPO JT, 1994, PSYCHOL BULL, V115, P401, DOI 10.1037/0033-2909.115.3.401
   Cadwaller A., 2010, ANAL TONAL MUSIC SCH
   Carstensen LL, 2000, J PERS SOC PSYCHOL, V79, P644, DOI 10.1037//0022-3514.79.4.644
   Cazden N, 1972, INT REV AESTHETICS S, V3, P217
   CUDDY LL, 1992, PSYCHOL RES-PSYCH FO, V54, P51, DOI 10.1007/BF00937133
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Darwin C., 1872, The Expression of the Emotions in Man and Animals
   Diener E., 1991, SUBJECTIVE WELL BEIN, P119, DOI DOI 10.1007/978-90-481-2354-4_10
   Ebeling Martin, 2007, VERSCHMELZUNG NEURON
   Fehr E, 2002, NATURE, V415, P137, DOI 10.1038/415137a
   Forte A., 1982, Introduction to Schenkerian Analysis
   Fricke J., 2010, P 2 VIENN TALK MUS A, P68
   Gabrielsson A, 2003, MUSIC SCI, V7, P157, DOI 10.1177/102986490300700201
   Gagnon L, 2003, COGNITION EMOTION, V17, P25, DOI 10.1080/02699930302279
   GERARDI GM, 1995, MUSIC PERCEPT, V12, P279
   Gibson EJ, 2000, ECOL PSYCHOL, V12, P53, DOI 10.1207/S15326969ECO1201_5
   Gibson JJ, 1937, J EXP PSYCHOL, V20, P453, DOI 10.1037/h0059826
   Gibson JJ, 1966, SENSES CONSIDERED PE
   Gottschaldt K., 1950, SOURCEBOOK GESTALT P, P109122
   Gregory AH, 1996, MOTIV EMOTION, V20, P341, DOI 10.1007/BF02856522
   HATTEN Robert S., 2004, Interpreting Musical Gestures, Topics, and Tropes
   Hesse H.-P., 1993, INT MUS K MOZ 1991 B, P669
   Hevner K, 1936, AM J PSYCHOL, V48, P246, DOI 10.2307/1415746
   Hevner K, 1935, AM J PSYCHOL, V47, P103, DOI 10.2307/1416710
   HEYDUK RG, 1975, PERCEPT PSYCHOPHYS, V17, P84, DOI 10.3758/BF03204003
   HURON D, 1991, MUSIC PERCEPT, V9, P135
   Huron D, 2001, MUSIC PERCEPT, V19, P1, DOI 10.1525/mp.2001.19.1.1
   HURON D., 2010, INT C MUS PERC COGN
   Huron D, 2008, EMPIR MUSICOL REV, V3, P59, DOI 10.18061/1811/31940
   HURON DAVID, 2006, SWEET ANTICIPATION M, P148, DOI DOI 10.7551/MITPRESS/6575.001.0001
   JUDD CC, 1985, MUSIC ANAL, V4, P201, DOI 10.2307/854096
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   KASTNER MP, 1990, MUSIC PERCEPT, V8, P189
   Khalfa S, 2008, INT J PSYCHOPHYSIOL, V68, P17, DOI 10.1016/j.ijpsycho.2007.12.001
   Koelsch S, 2004, NAT NEUROSCI, V7, P302, DOI 10.1038/nn1197
   Krumhansl C.L., 1990, COGNITIVE FDN MUSICA
   KRUMHANSL CL, 1982, PSYCHOL REV, V89, P334, DOI 10.1037/0033-295X.89.4.334
   Krumhansl CL, 1997, CAN J EXP PSYCHOL, V51, P336, DOI 10.1037/1196-1961.51.4.336
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Leman M, 2000, MUSIC PERCEPT, V17, P481
   LERDAHL F, 1988, MUSIC PERCEPT, V5, P315
   McDermott JH, 2010, CURR BIOL, V20, P1035, DOI 10.1016/j.cub.2010.04.019
   McLachlan N, 2013, J EXP PSYCHOL GEN, V142, P1142, DOI 10.1037/a0030830
   MEDDIS R, 1991, J ACOUST SOC AM, V89, P2883, DOI 10.1121/1.400726
   Merikle PM, 2001, COGNITION, V79, P115, DOI 10.1016/S0010-0277(00)00126-8
   Meyer LB., 1956, Emotion and meaning in music
   MOORE BCJ, 1992, J ACOUST SOC AM, V91, P2881, DOI 10.1121/1.402925
   MOORE BCJ, 1986, J ACOUST SOC AM, V80, P479, DOI 10.1121/1.394043
   Nesse RM, 2004, PHILOS T R SOC B, V359, P1333, DOI 10.1098/rstb.2004.1511
   NEUBERG SL, 1988, SOC COGNITION, V6, P207, DOI 10.1521/soco.1988.6.3.207
   North AC., 1995, PSYCHOMUSICOLOGY, V14, P77, DOI [10.1037/h0094090, DOI 10.1037/H0094090]
   Osgood C. E., 1957, Themeasurement ofmeaning
   Panksepp J., 2004, Affective Neuroscience
   Panksepp Jaak, 2007, The Oxford Handbook of Evolutionary Psychology, P145
   Parncutt Richard, 2011, Mathematics and Computation in Music. Proceedings of the Third International Conference, MCM 2011, P366, DOI 10.1007/978-3-642-21590-2_35
   Parncutt R., 1997, Music, Gestalt, and Computing. Studies in Cognitive and Systematic Musicology, P181, DOI 10.1007/BFb0034114
   PARNCUTT R, 1988, MUSIC PERCEPT, V6, P65
   Parncutt R, 2000, MUSIC PERCEPT, V18, P25
   Parncutt R., 2001, P INT S MUS AC PER I
   PARNCUTT R., 2008, INT C MUS PERC COGN
   Parncutt R, 2012, Harmony: A psychoacoustical approach, V19
   Parncutt R., 2011, COMMUNICATION
   Parncutt R., 2011, J INTERDISCIPLINARY, V5, P119, DOI 10.4407/jims.2011.11.002
   Parncutt R, 2012, EMPIR MUSICOL REV, V7, P118
   Parncutt R, 2011, MUSIC PERCEPT, V28, P333, DOI 10.1525/MP.2011.28.4.333
   Parncutt R, 2009, COMM COM INF SC, V37, P124
   PATTERSON RD, 1973, J ACOUST SOC AM, V53, P1565, DOI 10.1121/1.1913504
   PLOMP R, 1968, J ACOUST SOC AM, V43, P764, DOI 10.1121/1.1910894
   PLOMP R, 1965, J ACOUST SOC AM, V37, P1110, DOI 10.1121/1.1909532
   PLOMP R, 1965, J ACOUST SOC AM, V38, P548, DOI 10.1121/1.1909741
   Powell J, 2005, MUSIC SCI, V9, P289, DOI 10.1177/102986490500900208
   Pressing Jeff., 1978, JAZZFORSCHUNG, V9, P25
   Rahn J., 1980, Basic Atonal Theory
   Reichweger G., 2010, THESIS U GRAZ AUSTRI
   Rigg MG, 1940, J EXP PSYCHOL, V27, P566, DOI 10.1037/h0058652
   RITOSSA D.A., 2004, PSYCHOL MUSIC, V32, P5, DOI DOI 10.1177/0305735604039281
   ROSCH E, 1975, COGNITIVE PSYCHOL, V7, P573, DOI 10.1016/0010-0285(75)90024-9
   Rozin P, 2001, PERS SOC PSYCHOL REV, V5, P296, DOI 10.1207/S15327957PSPR0504_2
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Sander D. E., 2009, The Oxford companion to emotion and the affective sciences
   Schenker H., 1923, TONWILLE, P5
   Schubart Christian Friedrich Daniel, 1806, IDEEN AESTHETIK TONK
   SHONLE JI, 1976, J ACOUST SOC AM, V59, P469, DOI 10.1121/1.380858
   SMOORENBURG GF, 1972, J ACOUST SOC AM, V52, P603, DOI 10.1121/1.1913151
   STOLL G, 1987, ACUSTICA, V63, P111
   Temperley D., 2007, Music and probability
   Temperley D, 2013, MUSIC PERCEPT, V30, P237, DOI 10.1525/mp.2012.30.3.237
   TERHARDT E, 1974, J ACOUST SOC AM, V55, P1061, DOI 10.1121/1.1914648
   TERHARDT E, 1982, J ACOUST SOC AM, V71, P671, DOI 10.1121/1.387543
   TERHARDT E., 1988, QUALITATSASPEKTE MUS, P1
   THOMAS DL, 1990, J PERS SOC PSYCHOL, V59, P291, DOI 10.1037/0022-3514.59.2.291
   Thompson J., P INT SOC MUS INF RE
   THOMPSON WF, 1989, MUSIC PERCEPT, V7, P151
   Tillmann B, 1998, PSYCHOL RES-PSYCH FO, V61, P157, DOI 10.1007/s004260050022
   Trainor LJ, 1998, INFANT BEHAV DEV, V21, P77, DOI 10.1016/S0163-6383(98)90055-8
   TRAINOR LJ, 1992, J EXP PSYCHOL HUMAN, V18, P394, DOI 10.1037/0096-1523.18.2.394
   Tramo MJ, 2001, ANN NY ACAD SCI, V930, P92, DOI 10.1111/j.1749-6632.2001.tb05727.x
   TREHUB SE, 1987, PERCEPT PSYCHOPHYS, V41, P635, DOI 10.3758/BF03210495
   VALIMAKI V, 1996, ORGAN SOUND, V1, P75, DOI DOI 10.1017/S1355771896000039
   van Noorden L., 1975, THESIS TU EINDHOVEN
   WATT R, 1998, MUSIC SCI, V2, P33
   Winkielman P, 1998, J PERS SOC PSYCHOL, V75, P719, DOI 10.1037/0022-3514.75.3.719
   Zentner M, 2008, EMOTION, V8, P494, DOI 10.1037/1528-3542.8.4.494
NR 124
TC 39
Z9 40
U1 5
U2 39
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1029-8649
EI 2045-4147
J9 MUSIC SCI
JI Music Sci.
PD SEP
PY 2014
VL 18
IS 3
SI SI
BP 324
EP 353
DI 10.1177/1029864914542842
PG 30
WC Music; Psychology, Experimental
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Music; Psychology
GA AT8FG
UT WOS:000345168700006
DA 2024-01-09
ER

PT J
AU Hess, J
AF Hess, Juliet
TI When the Project is Not Understanding: Music Education for the
   Incomprehensible
SO STUDIES IN PHILOSOPHY AND EDUCATION
LA English
DT Article
DE Music education; Music; Dehumanization; Empathy; Useless knowledge;
   Discomfort
ID PEDAGOGY; EMPATHY; VOICES
AB In this paper, I consider pedagogical moments when the project of pedagogy is to not understand, as understanding would entail complicity with dehumanization. I explore the slipperiness of understanding and parse when understanding is helpful and when it reinscribes structures of dehumanization. I examine when it might be important in music education pedagogy to foster a refusal to understand, specifically in cases of extreme suffering that might occur in projects of dehumanization, atrocity, and genocide. Then, I explore the ethics embedded in different forms of understanding and consider why not understanding is sometimes the ethical path and tease out the complexities of such refusals to understand. Subsequently, I focus on what music might contribute to this pedagogical approach. I then explore and critique empathy and the project of empathy in education. Ultimately, I consider the role of discomfort in music education to facilitate these kinds of refusals. I center the work of several scholars in this discussion: Sherene Razack (Dark threats and White knights: The Somalia Affair, peacekeeping, and the new imperialism University of Toronto Press Toronto, ON, 2004, Rev Educ Pedag Cult Stud 29 (4): 375-394, 2007), Megan Boler (Feeling power: Emotions and education. Routledge, New York, NY, 1999), Jennifer Geddes (Hypatia 18 (1):104-115, 2003), Charlotte Delbo (Auschwitz and after. Yale University Press, New Haven, 1995/2014), Hannah Arendt (Eichmann in Jerusalem: A report on the banality of evil. Penguin Books, New York, NY, 1963/2006), Marie Hallander (Ethics Educ 10(2): 175-185, 2015, Stud Philos Educ 38: 467-480, 2019), Barbara Applebaum (Being White, being good: White complicity, White moral responsibility, and social justice pedagogy. Lexington Books, New York 2010, White educators negotiating complicity: Roadblocks paved with good intentions. Lexington Books, New York, NY, 2022), and Liora Gubkin (Teach Theol Relig 18(2): 103-120, 2015).
C1 [Hess, Juliet] Michigan State Univ, Coll Mus, Mus Practice Bldg,345 W Circle Dr,Room 214, E Lansing, MI 48824 USA.
C3 Michigan State University
RP Hess, J (corresponding author), Michigan State Univ, Coll Mus, Mus Practice Bldg,345 W Circle Dr,Room 214, E Lansing, MI 48824 USA.
EM jlhess@msu.edu
RI Hess, Juliet/HZK-1487-2023; Hess, Juliet/O-8330-2018
OI Hess, Juliet/0000-0003-3007-330X
CR Adami R, 2015, J PHILOS EDUC, V49, P1, DOI 10.1111/1467-9752.12089
   Ahmed S, 2014, CULTURAL POLITICS OF EMOTION, 2ND EDITION, P1
   [Anonymous], 2009, Exploring social justice: How music education might matter
   Applebaum Barbara., 2022, WHITE ED NEGOTIATING
   Applebaum Barbara., 2010, Being White, Being Good: White Complicity, White Moral Responsibility, and Social Justice Pedagogy
   Arendt Hannah, 1963, Eichmann in Jerusalem
   Boler M., 1999, FEELING POWER
   Bradley Deborah, 2022, TRAUMA RESILIENCE MU
   Brown Brene, 2018, Dare to lead: brave work, tough conversations, whole hearts
   Carniel J, 2018, PEDAGOG CULT SOC, V26, P141, DOI 10.1080/14681366.2017.1364784
   Caruth Cathy, 1995, Trauma: Explorations in Memory, P256
   Cesaire Aime, 2000, Discourse on Colonialism
   Cho E, 2022, PSYCHOL MUSIC, V50, P1121, DOI 10.1177/03057356211031663
   Delbo Charlotte, 2014, AUSCHWITZ, V2nd
   Dobbs TL, 2013, PHILOS MUSIC EDUC RE, V21, P156, DOI 10.2979/philmusieducrevi.21.2.156
   Emerson C., 1984, Problems of Dostoevsky's Poetics
   Foucault M., 1997, M FOUCAULT STRUCTURA, P253
   Geddes JenniferL., 2003, HYPATIA, V18, P104, DOI DOI 10.1111/J.1527-2001.2003.TB00781.X
   Giroux Henry A., 2006, STORMY WEATHER KATRI
   Goldberg D. T., 1993, Racist Culture: Philosophy and the Politics of Meaning
   Gordon Emma C., 2022, DOWDEN INTERNET ENCY
   Grimm Stephen., 2021, STANDFORD ENCY PHILO
   Gubkin L, 2015, TEACH THEOL RELIG, V18, P103, DOI 10.1111/teth.12273
   Hållander M, 2019, STUD PHILOS EDUC, V38, P467, DOI 10.1007/s11217-019-09663-2
   Hållander M, 2015, ETHICS EDUC, V10, P175, DOI 10.1080/17449642.2015.1051853
   HARRIS CI, 1993, HARVARD LAW REV, V106, P1707, DOI 10.2307/1341787
   Hartman Saidiya V., 1997, Scenes of Subjection: Terror, Slavery, and Self- Making in Nineteenth- Century America, Race and American Culture
   Heller-Roazen Daniel, 2008, REMNANTS AUSCHWITZ W
   Hendricks K. S., 2018, Compassionate music teaching: A framework for motivation and engagement in the 21st century
   Hendricks KS, 2021, FRONT EDUC, V6, DOI 10.3389/feduc.2021.648776
   HESS J., 2021, DIFFERENCE DIVISION, P56
   Hess J., 2019, Music education for social change: Constructing an activist music education
   Hess J., 2015, ACTION CRITICISM THE, V14, P66
   Hess J, 2020, STUD PHILOS EDUC, V39, P429, DOI 10.1007/s11217-020-09706-z
   Kvanvig JL, 2003, VALUE KNOWLEDGE PURS, DOI DOI 10.1017/CBO9780511498909
   Laird L., 2015, Music Educators Journal, V101, P56, DOI [10.1177/0027432115572230, DOI 10.1177/0027432115572230]
   Langer Lawrence L., 2014, AUSCHWITZ
   Lanzmann Claude, 1995, Trauma: Explorations in Memory, P200
   Levinas Emanuel, 1998, ENTRE NOUS THINKING
   Mills Charles, 1997, The Racial Contract
   Perkins JD, 2022, TRAUMA AND RESILIENCE IN MUSIC EDUCATION, P127, DOI 10.4324/9781003124207-9
   Pritchard D, 2009, ROY I PHILOS SUPPL, V64, P19, DOI 10.1017/S1358246109000046
   Razack SH, 2007, REV EDUC PEDAGOG CUL, V29, P375, DOI 10.1080/10714410701454198
   Razack Sherene H., 2004, DARK THREATS WHITE K
   Sahlins Marshall, 1995, How "Natives" Think: About Captain Cook, For Example, DOI DOI 10.7208/CHICAGO/9780226733715.001.0001
   Silverman Marissa., 2015, GIVING VOICE DEMOCRA, P157
   Sontag Susan, 2003, Regarding the Pain of Others, DOI 10.3917/dio.201.0127
   Spruce, 2015, OXFORD HDB SOCIAL JU
   Stein E., 1917, On the problem of empathy
   Thobani S., 2007, EXALTED SUBJECTS STU
   Winter R, 2013, PHILOS MUSIC EDUC RE, V21, P103, DOI 10.2979/philmusieducrevi.21.2.103
   Wynter S, 2003, CR-NEW CENTEN REV, V3, P257, DOI 10.1353/ncr.2004.0015
   Zembylas M, 2015, ETHICS EDUC, V10, P163, DOI 10.1080/17449642.2015.1039274
   Zhang YY, 2017, INT J MUSIC EDUC, V35, P425, DOI 10.1177/0255761416647191
NR 54
TC 0
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0039-3746
EI 1573-191X
J9 STUD PHILOS EDUC
JI Stud. Philos. Educ.
PD MAY
PY 2023
VL 42
IS 3
BP 261
EP 282
DI 10.1007/s11217-022-09861-5
EA DEC 2022
PG 22
WC Education & Educational Research; Philosophy
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Education & Educational Research; Philosophy
GA D9ZG3
UT WOS:000905451300002
DA 2024-01-09
ER

PT J
AU Senn, O
   Bullerjahn, C
   Kilchenmann, L
   von Georgi, R
AF Senn, Olivier
   Bullerjahn, Claudia
   Kilchenmann, Lorenz
   von Georgi, Richard
TI Rhythmic Density Affects Listeners' Emotional Response to Microtiming
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE groove; microtiming; emotions; rhythmic density; popular music
ID SELF-ASSESSMENT MANNEQUIN; SENSORIMOTOR SYNCHRONIZATION; TIMING
   MICROSTRUCTURE; MUSIC PERFORMANCE; PERCEIVED GROOVE; PERCEPTION; TEMPO;
   TIME; DISCRIMINATION; DURATION
AB Microtiming has been assumed to be vital for the experience of groove, but past research presented conflicting results: some studies found thatmicrotiming is irrelevant for groove, others reported that microtiming has a detrimental effect on the groove experience, yet others described circumstances under which microtiming has no negative impact on groove. The three studies in this paper aim at explaining some of these discrepancies by clarifying to what extent listeners' emotional responses to microtiming depend on the distribution of microtiming deviations across instrumental parts (voicing) or other moderating factors like tempo or rhythmic density. The studies use data fromtwo listening experiments involving expert bass and drums duo recordings in swing and funk style.
   -Study A investigates the effect of fixed time displacements within and between the parts played by different musicians. Listeners (n = 160) reacted negatively to irregularities within the drum track, but the mutual displacement of bass vs. drums did not have an effect.
   -Study B develops three metrics to calculate the average microtiming magnitude in a musical excerpt. The experiment showed that listeners' (n = 160) emotional responses to expert performance microtiming aligned with each other across styles, when microtiming magnitude was adjusted for rhythmic density. This indicates that rhythmic density is a unifyingmoderator for listeners' emotional response tomicrotiming in swing and funk.
   -Study C used the data from both experiments in order to compare the effect of fixed microtiming displacements (from Study A) with scaled versions of the originally performed microtiming patterns (from Study B). It showed that fixed snare drum displacements irritated expert listeners more than the more flexible deviations occurring in the original performances. This provides some evidence that listeners' emotional response to microtiming deviations not only depends on the magnitude of the deviations, but also on the kind and origin of the microtiming patterns (fixed lab displacements vs. flexible performance microtiming).
C1 [Senn, Olivier; Kilchenmann, Lorenz] Lucerne Univ Appl Sci & Arts, Sch Mus, Luzern, Switzerland.
   [Bullerjahn, Claudia; von Georgi, Richard] Justus Liebig Univ Giessen, Inst Musicol & Music Educ, Dept Social Sci & Cultural Studies, Giessen, Germany.
   [von Georgi, Richard] SRH Hsch Popularen Kunste, Media Psychol Dept, Berlin, Germany.
C3 Justus Liebig University Giessen
RP Senn, O (corresponding author), Lucerne Univ Appl Sci & Arts, Sch Mus, Luzern, Switzerland.
EM olivier.senn@hslu.ch
RI Bullerjahn, Claudia/H-9445-2016
OI Bullerjahn, Claudia/0000-0001-8157-5057; Kilchenmann,
   Lorenz/0000-0003-3723-6298
FU Swiss National Science Foundation [100012L 137794]; Deutsche
   Forschungsgemeinschaft [BU 2259/1-1]
FX This research was part of the project "The Relevance of Participatory
   Discrepancies for the Perception of Groove in Jazz and Funk," supported
   by the Swiss National Science Foundation (grant 100012L 137794 to OS)
   and the Deutsche Forschungsgemeinschaft (grant BU 2259/1-1 to CB).
CR ABEL SM, 1972, J ACOUST SOC AM, V52, P519, DOI 10.1121/1.1913139
   [Anonymous], 1999, AUDITORY SCENE ANAL
   [Anonymous], 1966, The Journal of Aesthetics and Art Criticism, DOI [10.2307/427969, DOI 10.2307/427969]
   [Anonymous], 2016, THESIS
   [Anonymous], 2008, THESIS OPEN U UK
   [Anonymous], 1997, MUSIC SCI, DOI [10.1177/102986499700100206, DOI 10.1177/102986499700100206]
   Backs RW, 2005, EXP AGING RES, V31, P421, DOI 10.1080/03610730500206808
   BARON RM, 1986, J PERS SOC PSYCHOL, V51, P1173, DOI 10.1037/0022-3514.51.6.1173
   Benadon F., 2015, MUSIC PERFORMANCE RE, V7, P1
   BENGTSSON I, 1980, SCAND J PSYCHOL, V21, P257, DOI 10.1111/j.1467-9450.1980.tb00369.x
   Bengtsson I., 1977, RHYTHM RES UPPSALA
   Bengtsson I., 1974, HAMBURGER JB MUSIKWI, V1, P195
   Beran J, 2000, COMPUT MATH APPL, V39, P99, DOI 10.1016/S0898-1221(00)00049-3
   Berliner Paul, 1994, THINKING IN JAZZ, DOI DOI 10.7208/CHICAGO/9780226044521.001.0001
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Butterfield M, 2010, MUSIC PERCEPT, V27, P157, DOI 10.1525/MP.2010.27.3.157
   Cabanac M, 2002, BEHAV PROCESS, V60, P69, DOI 10.1016/S0376-6357(02)00078-5
   Cheng E, 2008, J NEW MUSIC RES, V37, P325, DOI 10.1080/09298210802711660
   CLARKE EF, 1982, ACTA PSYCHOL, V50, P1, DOI 10.1016/0001-6918(82)90047-6
   Cohen J., 2013, APPL MULTIPLE REGRES, DOI DOI 10.4324/9780203774441
   Cohen J, 1988, STAT POWER ANAL BEHA
   COOK N, 1987, MUSIC ANAL, V6, P257, DOI 10.2307/854205
   Dalton Brian H., 2007, Occupational Ergonomics, V7, P153
   Danielsen A., 2006, PRESENCE PLEASURE FU
   Davies M, 2013, MUSIC PERCEPT, V30, P497, DOI 10.1525/MP.2013.30.5.497
   Dittmar C., 2015, P ISMIR 2015, V16, P271
   Dodson A, 2011, MUSIC THEOR SPECTRUM, V33, P59, DOI 10.1525/mts.2011.33.1.59
   DRAKE C, 1993, PERCEPT PSYCHOPHYS, V54, P277, DOI 10.3758/BF03205262
   Ehrlé N, 2005, BRAIN COGNITION, V58, P133, DOI 10.1016/j.bandc.2004.09.014
   Fischinger T., 2009, PSYCHOL RHYTHMUS PRA
   FRAISSE P, 1967, ANN PSYCHOL, V67, P43
   Fraisse P, 1956, STRUCTURES RHYTHMIQU
   FRIBERG A, 1995, J ACOUST SOC AM, V98, P2524, DOI 10.1121/1.413218
   Friberg A, 2002, MUSIC PERCEPT, V19, P333, DOI 10.1525/mp.2002.19.3.333
   Friberg A., 2006, ADV COGN PSYCHOL, V2, P145, DOI [DOI 10.2478/V10053-008-0052-X, 10.2478/v10053-008-0052-x]
   Frühauf J, 2013, MUSIC SCI, V17, P246, DOI 10.1177/1029864913486793
   Fujii S, 2011, MUSIC PERCEPT, V28, P491, DOI 10.1525/mp.2011.28.5.491
   GABRIELSSON A, 1974, SCAND J PSYCHOL, V15, P63, DOI 10.1111/j.1467-9450.1974.tb00557.x
   Gomez P, 2007, EMOTION, V7, P377, DOI 10.1037/1528-3542.7.2.377
   HALPERN AR, 1982, PERCEPT PSYCHOPHYS, V31, P86, DOI 10.3758/BF03206204
   Hasty Christopher, 1997, METER AS RHYTHM
   Hellmer K, 2015, MUSIC PERCEPT, V33, P147, DOI 10.1525/MP.2015.33.2.147
   Helton WS, 2005, BRIT J PSYCHOL, V96, P249, DOI 10.1348/000712605X38369
   Hibi S., 1983, Journal of the Acoustical Society of Japan (E), V4, P83, DOI 10.1250/ast.4.83
   HIRSH IJ, 1990, PERCEPT PSYCHOPHYS, V47, P215, DOI 10.3758/BF03204997
   Hodson Robert, 2007, INTERACTION IMPROVIS
   Hofmann A, 2017, J NEW MUSIC RES, V46, P329, DOI 10.1080/09298215.2017.1355394
   HONG JL, 2003, PSYCHOL MUSIC, V31, P340
   Hove MJ, 2007, PERCEPT PSYCHOPHYS, V69, P699, DOI 10.3758/BF03193772
   HUBERTY CJ, 1989, PSYCHOL BULL, V105, P302, DOI 10.1037/0033-2909.105.2.302
   Janata P, 2012, J EXP PSYCHOL GEN, V141, P54, DOI 10.1037/a0024208
   Jones MR, 2006, COGNITIVE PSYCHOL, V53, P59, DOI 10.1016/j.cogpsych.2006.01.003
   KEIL C, 1995, ETHNOMUSICOLOGY, V39, P1, DOI 10.2307/852198
   Keil C., 1987, Cultural Anthropology, V2, P275, DOI [10.1525/can.1987.2.3.02a00010, DOI 10.1525/CAN.1987.2.3.02A00010]
   Keil Charles, 2010, POPSCRIPTUM, V11, P1
   Kilchenmann L, 2011, P INT S PERF SCI 201, P593
   Kilchenmann L, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01232
   Large EW, 1999, PSYCHOL REV, V106, P119, DOI 10.1037/0033-295X.106.1.119
   London J., 2004, Hearing in Time: Psychological Aspects of Musical Meter, DOI 10.1093/acprof:oso/9780195160819.003.0002
   LUNNEY HWM, 1974, NATURE, V249, P592, DOI 10.1038/249592a0
   MacRitchie J., 2011, THESIS
   Madison G, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00894
   Madison G, 2014, ACTA PSYCHOL, V147, P10, DOI 10.1016/j.actpsy.2013.10.002
   Madison G, 2011, J EXP PSYCHOL HUMAN, V37, P1578, DOI 10.1037/a0024323
   Matsushita S, 2016, MUSIC PERCEPT, V34, P123, DOI 10.1525/MP.2016.34.2.123
   Merker B, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00454
   MICHON JA, 1964, ACTA PSYCHOL, V22, P441, DOI 10.1016/0001-6918(64)90032-0
   Moelants D, 2011, MUSIC PERCEPT, V28, P449, DOI 10.1525/mp.2011.28.5.449
   Monson Ingrid, 1996, Saying Something: Jazz Improvisation and Interaction
   NAKAJIMA Y, 1992, PERCEPT PSYCHOPHYS, V51, P504, DOI 10.3758/BF03211646
   NAKAJIMA Y, 1987, PERCEPTION, V16, P485, DOI 10.1068/p160485
   Naveda L, 2011, J NEW MUSIC RES, V40, P225, DOI 10.1080/09298215.2011.603833
   NORDMARK JO, 1968, J ACOUST SOC AM, V44, P1533, DOI 10.1121/1.1911293
   Parasuraman R., 2000, ATTENTIVE BRAIN
   Philip Robert, 2004, Performing Music in the Age of Recording
   Rasch R. A., 1988, Generative processes in music, P70
   Repp BH, 2005, PSYCHON B REV, V12, P969, DOI 10.3758/BF03206433
   REPP BH, 1995, MUSIC PERCEPT, V13, P39
   Repp BH, 2002, MUSIC PERCEPT, V19, P565, DOI 10.1525/mp.2002.19.4.565
   REPP BH, 1992, J ACOUST SOC AM, V92, P2546, DOI 10.1121/1.404425
   Repp BH, 1998, J EXP PSYCHOL HUMAN, V24, P791, DOI 10.1037/0096-1523.24.3.791
   Repp BH, 1998, PSYCHOL RES-PSYCH FO, V61, P33, DOI 10.1007/s004260050011
   Repp BH, 2013, PSYCHON B REV, V20, P403, DOI 10.3758/s13423-012-0371-2
   Sasaki T, 1998, MUSIC PERCEPT, V16, P201
   SCERBO MW, 1987, CURR PSYCHOL RES REV, V5, P335
   Seeger Charles, 1958, The Musical Quarterly, V44, P184, DOI DOI 10.1093/MQ/XLIV.2.184
   Senn O, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01487
   Senn Olivier, 2012, DISSONANCE, V120, P31
   Senn Olivier, 2009, P INT S PERF SCI 200, P107
   SIDAK Z, 1967, J AM STAT ASSOC, V62, P626, DOI 10.2307/2283989
   Sioros G, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01036
   Stupacher J, 2016, MUSIC PERCEPT, V33, P571, DOI 10.1525/MP.2016.33.5.571
   Sundberg J, 2003, J NEW MUSIC RES, V32, P317, DOI 10.1076/jnmr.32.3.317.16867
   TENHOOPEN G, 1995, PERCEPTION, V24, P577, DOI 10.1068/p240577
   Thomas K., 2007, J SCI PSYCHOL, V2, P14
   Winkler I, 2009, TRENDS COGN SCI, V13, P532, DOI 10.1016/j.tics.2009.09.003
   Witek MAG, 2017, MUSIC ANAL, V36, P138, DOI 10.1111/musa.12082
   Witek MAG, 2017, EXP BRAIN RES, V235, P995, DOI 10.1007/s00221-016-4855-6
   Witek MAG, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0094446
   Zbikowski LM, 2004, J ROY MUSIC ASSN, V129, P272, DOI 10.1093/jrma/129.2.272
NR 100
TC 8
Z9 8
U1 0
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD OCT 12
PY 2017
VL 8
AR 1709
DI 10.3389/fpsyg.2017.01709
PG 21
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA FJ5MW
UT WOS:000412796600001
PM 29075210
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Radulovic, I
   Petkovits, IHR
AF Radulovic, Ifigenija
   Petkovits, Ismene Helen Radoulovits
TI Laughter from Hades: Aristophanic Voice Today
SO POPULAR ENTERTAINMENT STUDIES
LA English
DT Article
DE Aristophanes; Aristophaniad; contemporary life; Hades;
   laughter/spoudaiogeloion; philosophical theatre; politics; poverty;
   reality
AB The current Greek political situation again brings to light, and on stage, many ancient dramas. Contemporary Greek theatre professionals, not turning a blind eye to reality, have come up with 'the revival' of old texts, staging them in new circumstances. Aristophaniad is an original play with a subversive content inspired by Aristophanes and a contemporary street graffito reflecting contemporary Athenian life. It is a mixture of various comic and other dramatic elements, such as ancient comedy, grotesque, pantomime, musical, ballet, opera, standup, even circus. Additionally, staging methods developed by the Greek director, Karolos Koun (1908-1987) are also evident in the production. Idea Theatre Company, exploiting excerpts from Aristophanes' plays and starring the comediographer himself manages to depict a fictional and real world in one. The performance starts with the rehearsal of Aristophanes' new play, Poverty, which is in danger of being left unfinished since Hades plans to take Aristophanes to the Underworld. The play ends with Plutus. In the meantime, the performance entertains its audience, leading them to experience Aristotelian catharsis through laughter. This collective 'purification' of the soul is supposed to be mediated by laughter and provoked by references to serious life issues, given in comic mode and through a vast range of human emotions. The article deals with those comic features and supports the thesis that in spite of the fact that times change, people never cease to fight fora better society. Ifigenija Radulovie is an associate professor of Classics in the Faculty of Philosophy at the University of Novi Sad. She deals with the reception of Antiquity in different historical periods and with ancient Greek rhetoric and drama as historical sources. Ismene Helen Radoulovits Petkovits holds a BA in English, MA in Greek Philology and is writing a PhD thesis in Comparative Literature at the National and Kapodistrian University of Athens. She translates from Greek/English into Serbian and Croatian and vice-versa, and collaborates with many Greek and Serbian Theatres on modern adaptations of the classical repertoire.
C1 [Radulovic, Ifigenija] Univ Novi Sad, Novi Sad, Serbia.
   [Petkovits, Ismene Helen Radoulovits] Univ Athens, Athens, Greece.
C3 University of Novi Sad; National & Kapodistrian University of Athens
RP Radulovic, I (corresponding author), Univ Novi Sad, Novi Sad, Serbia.
CR [Anonymous], 1962, ARISTOFANE AUTORE TE
   Berardi Franco, 2011, AFTER THE FUTURE, P128
   Berari Franco, 2009, SOUL WORK ALIENATION, P43
   Bezbradica Mikojan, PHILOS THEATRE LECT
   Diamantakou-Agathou Kaiti, 2015, CAHIERS BALKANIQUES, P1
   Djuric Milos N., 1990, HIST HELLENIC LIT, P342
   Emeljanow Victor, 2010, POPULAR ENTERTAINMEN, V1, P1
   Hall E, 2007, ARISTOPHANES IN PERFORMANCE 421 BC-AD 2007: PEACE, BIRDS AND FROGS, P1
   Idea Theatre Company, 2016, AR, P6
   Inwood Cristine Sourvinou, 2003, TRAGEDY ATHENIAN REL, P11
   Kotzamani Marina, 2007, CLOWNS FOOLS PICAROS, P179
   Maricic Gordan, 2016, ISTRAZIVANJA, V27, P58
   Panagiotarakou Eleni, 2015, MONTREAL GAZETTE
   Papageorgiou I, 2014, POP ENTERTAIN STUD, V5, P79
   SIFAKIS GM, 1992, J HELLENIC STUD, V112, P123, DOI 10.2307/632156
   Solomos A., 1961, LIVING ARISTOPHANES
   Solomos Alexis, 1961, ARISTOPHANES PERFORM
   Tsipras Alexis, 2015, COMMUNICATION   0126
   Tsipras Alexis, 2015, COMMUNICATION   0921
   Van den Dries's Luk, MOUNT OLYMPUS 24H
   Varakis Angeliki, 2013, CLASSICS MODERN WORL, P216
   Varufakis Yannis, 2016, WEAK SUFFER WHAT THE
NR 22
TC 0
Z9 0
U1 0
U2 3
PU UNIV NEWCASTLE
PI CALLAHAN
PA SCH DRAMA, FINE ART & MUSIC, UNIVERSITY DR, CALLAHAN, NSW 2308,
   AUSTRALIA
SN 1837-9303
J9 POP ENTERTAIN STUD
JI Pop. Entertain. Stud.
PY 2019
VL 10
IS 1-2
BP 51
EP 71
PG 21
WC Theater
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Theater
GA KE6JQ
UT WOS:000508660700005
DA 2024-01-09
ER

PT J
AU Malloch, S
   Trevarthen, C
AF Malloch, Stephen
   Trevarthen, Colwyn
TI The Human Nature of Music
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE musicking; motor intelligence; gestural narrative; infant musicality;
   cultural learning
ID HOMO PROVOCANS; THERAPY; MOTHER; IMITATION; MOTIVES; INFANTS; SCIENCE;
   IMITANS; RHYTHM; BRAIN
AB Music is at the centre of what it means to be human - it is the sounds of human bodies and minds moving in creative, story-making ways. We argue that music comes from the way in which knowing bodies (Merleau-Ponty) prospectively explore the environment using habitual 'patterns of action,' which we have identified as our innate 'communicative musicality.' To support our argument, we present short case studies of infant interactions using micro analyses of video and audio recordings to show the timings and shapes of intersubjective vocalizations and body movements of adult and child while they improvise shared narratives of meaning. Following a survey of the history of discoveries of infant abilities, we propose that the gestural narrative structures of voice and body seen as infants communicate with loving caregivers are the building blocks of what become particular cultural instances of the art of music, and of dance, theatre and other temporal arts. Children enter into a musical culture where their innate communicative musicality can be encouraged and strengthened through sensitive, respectful, playful, culturally informed teaching in companionship. The central importance of our abilities for music as part of what sustains our well-being is supported by evidence that communicative musicality strengthens emotions of social resilience to aid recovery from mental stress and illness. Drawing on the experience of the first author as a counsellor, we argue that the strength of one person's communicative musicality can support the vitality of another's through the application of skilful techniques that encourage an intimate, supportive, therapeutic, spirited companionship. Turning to brain science, we focus on hemispheric differences and the affective neuroscience of Jaak Panksepp. We emphasize that the psychobiological purpose of our innate musicality grows from the integrated rhythms of energy in the brain for prospective, sensation-seeking affective guidance of vitality of movement. We conclude with a Coda that recalls the philosophy of the Scottish Enlightenment, which built on the work of Heraclitus and Spinoza. This view places the shared experience of sensations of living - our communicative musicality - as inspiration for rules of logic formulated in symbols of language.
C1 [Malloch, Stephen] Univ Sydney, Sydney Med Sch, Westmead Psychotherapy Program, Sydney, NSW, Australia.
   [Malloch, Stephen] Western Sydney Univ, MARCS Inst Brain Behav & Dev, Sydney, NSW, Australia.
   [Trevarthen, Colwyn] Univ Edinburgh, Sch Philosophy Psychol & Language Sci, Dept Psychol, Edinburgh, Midlothian, Scotland.
C3 University of Sydney; Western Sydney University; University of Edinburgh
RP Malloch, S (corresponding author), Univ Sydney, Sydney Med Sch, Westmead Psychotherapy Program, Sydney, NSW, Australia.; Malloch, S (corresponding author), Western Sydney Univ, MARCS Inst Brain Behav & Dev, Sydney, NSW, Australia.; Trevarthen, C (corresponding author), Univ Edinburgh, Sch Philosophy Psychol & Language Sci, Dept Psychol, Edinburgh, Midlothian, Scotland.
EM stephen.malloch@heartmind.com.au; c.trevarthen@ed.ac.uk
CR [Anonymous], 1963, FROM 2 TO 5
   [Anonymous], 1923, I THOU
   [Anonymous], 1984, CLIN DEV MED
   [Anonymous], 2005, SINGING NEANDERTHALS
   [Anonymous], 1979, Before Speech: The Beginning of Interpersonal Communication
   [Anonymous], MAN HIS NATURE
   [Anonymous], 2005, METAPHOR PLAY ORIGIN
   [Anonymous], 2008, MUSICAE SCI S, DOI DOI 10.1177/1029864908012001021
   [Anonymous], 1984, ADV PSYCHOL, DOI DOI 10.1016/S0166-4115(08)61374-6
   [Anonymous], 1958, The child's construction of reality
   [Anonymous], 1992, MUSE CREATIVITY COMM
   [Anonymous], NEW PERSPECTIVES EAR, DOI DOI 10.1016/B978-0-08-097086-8.23160-7
   [Anonymous], 1979, SPEECH BEGINNING HUM
   [Anonymous], 1999, MUSICAE SCI, DOI DOI 10.1177/10298649000030S109
   [Anonymous], RHYTHMS RELATING STO
   [Anonymous], DEV PSYCHOL SOC
   [Anonymous], 1992, Human Minds: An Exploration
   [Anonymous], MOTOR DEV CHILDREN A
   [Anonymous], 2009, COMMUNICATIVE MUSICA
   [Anonymous], 1979, Before Speech: The Beginning of Interpersonal Communication
   [Anonymous], 2009, COMMUNICATIVE MUSICA
   [Anonymous], CONTEXTS YOUNG CHILD
   [Anonymous], 2000, INTERPERSONAL WORLD
   [Anonymous], 2009, COMMUNICATIVE MUSICA
   [Anonymous], 1976, MUSICAL EXPERIENCE P
   [Anonymous], NATURE CULTURE
   [Anonymous], MUSICAL BEGINNINGS
   [Anonymous], 1999, MUSIC THERAPY INTIMA
   [Anonymous], 2001, I of the Vortex: From Neurons to Self
   [Anonymous], 1966, The Psychology of Intelligence
   [Anonymous], DAS ICH UND DAS ES
   [Anonymous], 2009, Communicative Musicality, DOI [10.1016/B978-0-12-374370-1.X0001-8, DOI 10.1016/B978-0-12-374370-1.X0001-8]
   Barrett MS, 2011, PSYCHOL MUSIC, V39, P403, DOI 10.1177/0305735610373054
   Bateson M. C., 1971, Quarterly Progress Report of the Research Laboratory of Electronics, MIT, V100, P170
   Bateson P, 2013, PLAY, PLAYFULNESS, CREATIVITY AND INNOVATION, P1
   Bernstein N., 1967, COORDINATION REGULAT
   Bernstein N., 1966, MOTOR CONTROL, V3, P225
   Birdwhistell R. L., 1970, KINESICS AND CONTEXT
   Blacking J., 1995, CHICAGO STUDIES ETHN
   BOWLBY J, 1958, INT J PSYCHOANAL, V39, P350
   Bowman W., 2012, OXFORD HDB MUSIC ED
   BRAZELTON T, 1961, J PEDIATR-US, V58, P508, DOI 10.1016/S0022-3476(61)80184-4
   Brazelton T.B., 1995, Neonatal behavioral assessment scale
   Brazelton T. B., 1973, CLINICS DEV MED
   Bruner J., 1983, Child's talk: Learning to use language
   Bruner J. S., 1996, The Culture of Education
   Bruner J. S., 1968, H WERNER LECT 1968
   Bruner J.S., 1966, THEORY INSTRUCTION, VVolume 59
   Bruner Jerome, 2003, Making stories: law, literature, life
   BUSNEL MC, 1992, ANN NY ACAD SCI, V662, P118, DOI 10.1111/j.1749-6632.1992.tb22857.x
   Buzsaki G, 2006, Rhythms of the Brain, DOI DOI 10.1093/ACPROF:OSO/9780195301069.001.0001
   Champagne R. A., 1990, SEMIOTIC WEB 1989, P61
   Chiron C, 1997, BRAIN, V120, P1057, DOI 10.1093/brain/120.6.1057
   CHOMSKY N., 1965, Aspects of the theory of syntax
   Custodero L. A., 2009, Communicative musicality: Exploring the basis of human companionship, P513
   Damasio A, 2010, Self comes to mind-constructing the conscious brain
   Damasio A.R., 1999, FEELING WHAT HAPPENS
   Damasio A. R., 2003, Looking for Spinoza: Joy, sorrow, and the feeling brain
   Delamont RS, 1999, J CLIN NEUROPHYSIOL, V16, P146, DOI 10.1097/00004691-199903000-00007
   Dewey J., 1938, Experience and Education
   Donald Merlin, 1991, ORIGINS MODERN MIND
   Eckerdal P., 2009, Communicative musicality: Exploring the basis of human companionship, P241
   Eibl-Eibesfeldt I., 1989, Human Ethology
   Eisenberg N, 2012, EMOT REV, V4, P34, DOI 10.1177/1754073911421381
   Ekman P., 1975, Unmasking the face: a guide to recognizing emotions from facial clues
   Flohr J.W., 2008, NEUROSCIENCES MUSIC, P53
   Frank B., 2012, MOVING OURSELVES MOV, P261, DOI DOI 10.1075/CEB.6.11FRA
   Frohlich C., 2009, COMMUNICATIVE MUSICA, P495
   Gibson James J., 1979, 'The Theory of Affordances'. The Ecological Approach to Visual Perception
   Goodrich BG, 2010, REV NEUROSCIENCE, V21, P331
   Gratier M, 2008, J CONSCIOUSNESS STUD, V15, P122
   Hadamard J., 1945, An Essay on the Psychology of Invention in the Mathematical Field
   Hay D., 1998, The Spirit of the Child
   HEPPER PG, 1991, IRISH J PSYCHOL, V12, P95, DOI 10.1080/03033910.1991.10557830
   Hess W.R., 1954, Diencephalon, Autonomic and Extrapyramidal Functions
   Hobson R.F., 1985, Forms of Feeling
   Hume D., 1739, TREATISE HUMAN NATUR
   Hutcheson Frances, 1755, 3 BOOKS
   Hutcheson Francis, 2004, An Inquiry into the Original of Our Ideas of Beauty and Virtue
   Imberty M, 2000, ORIGINS OF MUSIC, P449
   IMBERTY M, 1981, ECRITURE TEMPS
   INGOLD Tim, 2018, Anthropology and/as education, DOI [10.4324/9781315227191, DOI 10.4324/9781315227191]
   James W., 1892, Psychology: A Briefer Course
   Juslin, 1997, PSYCHOMUSICOLOGY, V16, P77, DOI DOI 10.1037/H0094065
   Juslin P. N., 1996, PSYCHOL MUSIC, V24, P68, DOI [10.1177/0305735696241007, DOI 10.1177/0305735696241007]
   Juslin PN., 2001, Music and Emotion, P309, DOI 10.1093/oso/9780192631886.003.0014
   Kirschner S, 2010, EVOL HUM BEHAV, V31, P354, DOI 10.1016/j.evolhumbehav.2010.04.004
   Kugiumutzakis G., 2015, INT ENCY SOCIAL BEHA, P481, DOI [10.1016/B978-0-08-097086-8.23160-7, DOI 10.1016/B978-0-08-097086-8.23160-7]
   Kukhl O., 2007, MUSICAL SEMANTICS EU, DOI [10.3726/978-3-0351-0271-0, DOI 10.3726/978-3-0351-0271-0]
   Kurth Ernst, 1991, Selected Writings
   Langer S., 1948, Philosophy in a New Key: A Study in the Symbolism ofReason, Rite, andArt
   Lashley KS., 1951, In: Cerebral mechanisms in behavior. The Hixon Symposium, P112, DOI DOI 10.1016/J.HUMOV.2007.04.001
   MacDonald R, 2004, LEARNING TO COLLABORATE, COLLABORTING TO LEARN, P133
   MacDonald R., 2002, Musical Identities
   Malloch S., 2009, COMMUNICATIVE MUSICA
   Malloch S. N., 1997, P I ACOUSTICS, V19, P495
   Malloch S.N., 1999, MUSIC SCI, V3, P29, DOI [10.1177/10298649000030S104, DOI 10.1177/10298649000030S104]
   Malloch S, 2012, INFANT MENT HEALTH J, V33, P386, DOI 10.1002/imhj.21346
   Maratos O., 1998, CHILDREN AUTISM DIAG, P203
   Maratos O, 1973, THESIS
   Maratos O., 1982, REGRESSIONS MENTAL D, P81, DOI DOI 10.4324/9781315180922-4
   Maturana H. R., 2008, ORIGIN HUMANNESS BIO
   Maturana Humberto, 1995, Biological Research, V28, P15
   Maturana Humberto R., 1980, Autopoiesis and cognition: The realization of the living
   Mazokopaki K, 2009, COMMUNICATIVE MUSICA, P185
   McGilchrist I., 2021, The master and his emissary: The divided brain and the making of the western world
   Meares Russell., 2016, POETS VOICE MAKING M, DOI [10.4324/9781315670638, DOI 10.4324/9781315670638]
   MELTZOFF AN, 1977, SCIENCE, V198, P75, DOI 10.1126/science.198.4312.75
   Merker B., 2009, Communicative Musicality, P45
   Merleau-Ponty Maurice, 2002, Phenomenology of Perception
   Murray L., 1985, SOCIAL PERCEPTION IN, P177
   Nagy E, 2004, INFANT BEHAV DEV, V27, P54, DOI 10.1016/j.infbeh.2003.06.004
   NAGY E, 1994, INT J PSYCHOPHYSIOL, V18, P128
   Nagy E, 2011, INFANT CHILD DEV, V20, P3, DOI 10.1002/icd.683
   Narvaez D., 2014, NEUROBIOLOGY DEV HUM
   Ockelford A., 2017, COMP NOTES WE MAKE S
   Osborne N., 2009, Communicative musicality, P331
   Osborne N., 2017, RHYTHMS RELATING CHI, P14
   Otteson J. R., 2000, A SMITH MORAL PHILOS
   Panksepp J, 2002, BEHAV PROCESS, V60, P133, DOI 10.1016/S0376-6357(02)00080-3
   Panksepp J., 2004, Affective Neuroscience
   Panksepp J, 2009, COMMUNICATIVE MUSICA, P105
   Panksepp J, 2012, J CONSCIOUSNESS STUD, V19, P6
   Panksepp Jaak, 2012, The Archaeology of Mind: Neuroevolutionary Origins of Human Emotions
   Pavlicevic M, 2000, J MUSIC THER, V37, P269, DOI 10.1093/jmt/37.4.269
   Pavlicevic M., 1997, MUSIC THERAPY CONTEX, P4341
   Pavlicevic M., 2009, Communicative Musicality. Exploring the Basis of Human Companionship, P357
   Pinker S., 1997, How the mind works
   Porges S., 2011, Norton Series on Interpersonal Neurobiology, DOI DOI 10.1051/978-2-7598-2620-9
   Reddy V., 2008, How Infants Know Minds
   Reid T., 1764, INQUIRY HUMAN MIND P, DOI [10.1037/11974-000, DOI 10.1037/11974-000]
   Rodrigues H., 2009, COMMUNICATIVE MUSICA, P585
   Rogoff Barbara, 2003, The Cultural Nature of Human Development
   Sachs Curt, 1943, The Rise of Music in the Ancient World: East and West
   Sacks O, 2006, BRAIN, V129, P2528, DOI 10.1093/brain/awl234
   Sander L., 1975, EXPLORATIONS CHILD P, P129
   Sander L. W., 2008, LIVING SYSTEMS EVOLV, V26
   SANDER LW, 1964, J CHILD PSYCHOL PSYC, V3, P231, DOI 10.1016/S0002-7138(09)61920-8
   Scheflen A. E., 1972, STREAM STRUCTURE COM
   Schögler B, 2007, ADV CONSC RES, V68, P281
   Small C, 1987, Musicking: The Meanings of Performing and Listening
   Smith A., 1777, GLASGOW EDITION WORK, V3
   Smith Adam, 1759, The theory of moral sentiments
   Solms M, 2012, BRAIN SCI, V2, P147, DOI 10.3390/brainsci2020147
   Spitz Rene, 1957, NO YES GENESIS HUMAN
   Spitz RA, 1946, GENET PSYCHOL MONOGR, V34, P57
   Spitz RA, 1945, PSYCHOANAL STUD CHIL, V1, P53, DOI 10.1080/00797308.1945.11823126
   Stern D.N., 1995, Motherhood Constellation
   Stern D. N., 2010, Forms of vitality: Exploring dynamic experience in psychology, the arts, psychotherapy, and development, DOI [10.1093/med:psych/9780199586066.001.0001, DOI 10.1093/MED:PSYCH/9780199586066.001.0001, https://doi.org/10.1093/med:psych/9780199586066.001.0001]
   Stern D. N., 2004, The present moment in psychotherapy and everyday life
   STERN DN, 1971, J AMER ACAD CHILD PS, V10, P501, DOI 10.1016/S0002-7138(09)61752-0
   Stern DN, 1998, INT J PSYCHOANAL, V79, P903
   Stern DN, 1985, The interpersonal world of the infant
   Stige B, 2002, CULTURE CTRED MUSIC
   Tafuri Johannella., 2008, INFANT MUSICALITY NE
   THATCHER RW, 1987, SCIENCE, V236, P1110, DOI 10.1126/science.3576224
   Trainor LJ, 2015, ANN NY ACAD SCI, V1337, P45, DOI 10.1111/nyas.12649
   Trehub S. E., 1998, Advances in Infancy Research, V12, P43
   Trehub SE, 2006, COGNITION, V100, P73, DOI 10.1016/j.cognition.2005.11.006
   Trehub SE, 2003, NAT NEUROSCI, V6, P669, DOI 10.1038/nn1084
   TREVARTHEN C, 1974, Neurosciences Research Program Bulletin, V12, P570
   Trevarthen C, 2001, INFANT MENT HEALTH J, V22, P95, DOI 10.1002/1097-0355(200101/04)22:1<95::AID-IMHJ4>3.0.CO;2-6
   TREVARTHEN C, 2004, OXFORD COMPANION MIN, P116
   Trevarthen C., 2018, CHILDS CURRICULUM UN
   Trevarthen C., 2017, OXFORD HDB MUSICAL I, P155, DOI [DOI 10.1093/ACPROF:OSO/9780199679485.001.0001, 10.1093/acprof:oso/9780199679485.003.0009, DOI 10.1093/ACPROF:OSO/9780199679485.003.0009]
   Trevarthen C., 1984, Approaches to Emotion, P129
   Trevarthen C., 2000, NORD J MUSIC THER, V9, P3, DOI [DOI 10.1080/08098130009477996, 10.1080/08098130009477996]
   Trevarthen C., 1977, Studiesin mother-infantinteraction, P227
   Trevarthen C., 1990, BRAIN CIRCUITS FUNCT, P334
   Trevarthen C., 1990, SEMIOTIC WEB 1989, P689, DOI DOI 10.1515/9783110874099.689
   Trevarthen C., 2017, ANTHR BEAUTY AESTHET, P115
   Trevarthen C, 2005, J CHILD PSYCHOTHER, V31, P91, DOI 10.1080/00754170500079651
   Trevarthen C, 2016, J CONSCIOUSNESS STUD, V23, P258
   Trevarthen C, 2015, COGNITIVE DEV, V36, P130, DOI 10.1016/j.cogdev.2015.09.008
   Trevarthen C, 2009, MUSIC THAT WORKS, P221, DOI 10.1007/978-3-211-75121-3_16
   Trevarthen Colwyn, 2005, Attachment and bonding: A new synthesis, P55
   Turner V., 1983, THE WORLD OF PLAY, P217
   Turner Victor, 1982, From Ritual to Theatre: The Human Seriousness o fPlay
   Valiente C, 2012, CHILD DEV PERSPECT, V6, P129, DOI 10.1111/j.1750-8606.2011.00192.x
   van Rees S., 1993, SCHEYVENHOFWEG, V12, P6093
   Vygotsky L., 1966, LEARNING THINK LEARNING THINK, P32
   Whitehead A. N., 1929, The aims of education and other essays
   Whiten A., 2000, DESCENT MIND
   Zeedyk MS, 2006, INFANT CHILD DEV, V15, P321, DOI 10.1002/icd.457
   Zentner M, 2010, P NATL ACAD SCI USA, V107, P5768, DOI 10.1073/pnas.1000121107
NR 185
TC 34
Z9 36
U1 5
U2 59
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD OCT 4
PY 2018
VL 9
AR 1680
DI 10.3389/fpsyg.2018.01680
PG 21
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA GV8CW
UT WOS:000446364400001
PM 30337892
OA Green Published, gold
DA 2024-01-09
ER

PT J
AU Gamboa-Montero, JJ
   Alonso-Martin, F
   Castillo, JC
   Malfaz, M
   Salichs, MA
AF Jose Gamboa-Montero, Juan
   Alonso-Martin, Fernando
   Carlos Castillo, Jose
   Malfaz, Maria
   Salichs, Miguel A.
TI Detecting, locating and recognising human touches in social robots with
   contact microphones
SO ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Acoustic sensing; Social robots; Touch gesture recognition; Touch
   localisation; Human-robot interaction; Machine learning applications
ID COMMUNICATION; RECOGNITION; EMOTION
AB There are many situations in our daily life where touch gestures during natural human-human interaction take place: meeting people (shaking hands), personal relationships (caresses), moments of celebration or sadness (hugs), etc. Considering that robots are expected to form part of our daily life in the future, they should be endowed with the capacity of recognising these touch gestures and the part of its body that has been touched since the gesture's meaning may differ. Therefore, this work presents a learning system for both purposes: detect and recognise the type of touch gesture (stroke, fickle, tap and slap) and its localisation. The interpretation of the meaning of the gesture is out of the scope of this paper.
   Different technologies have been applied to perceive touch by a social robot, commonly using a large number of sensors. Instead, our approach uses 3 contact microphones installed inside some parts of the robot. The audio signals generated when the user touches the robot are sensed by the contact microphones and processed using Machine Learning techniques. We acquired information from sensors installed in two social robots, Maggie and Mini (both developed by the RoboticsLab at the Carlos III University of Madrid), and a real-time version of the whole system has been deployed in the robot Mini. The system allows the robot to sense if it has been touched or not, to recognise the kind of touch gesture, and its approximate location. The main advantage of using contact microphones as touch sensors is that by using just one, it is possible to "cover" a whole solid part of the robot. Besides, the sensors are unaffected by ambient noises, such as human voice, TV, music etc. Nevertheless, the fact of using several contact microphones makes possible that a touch gesture is detected by all of them, and each may recognise a different gesture at the same time. The results show that this system is robust against this phenomenon. Moreover, the accuracy obtained for both robots is about 86%.
C1 [Jose Gamboa-Montero, Juan; Alonso-Martin, Fernando; Carlos Castillo, Jose; Malfaz, Maria; Salichs, Miguel A.] Univ Carlos III Madrid, Robot Lab, Av Univ 30, Madrid 28911, Spain.
C3 Universidad Carlos III de Madrid
RP Gamboa-Montero, JJ (corresponding author), Univ Carlos III Madrid, Robot Lab, Av Univ 30, Madrid 28911, Spain.
EM jgamboa@ing.uc3m.es; famartin@ing.uc3m.es; jocastil@ing.uc3m.es;
   mmalfaz@ing.uc3m.es; salichs@ing.uc3m.es
RI Castillo, José Carlos/ABC-2793-2021; Martín, Fernando Alonso/B-7185-2013
OI Alonso Martin, Fernando/0000-0003-3013-968X; CASTILLO MONTOYA, JOSE
   CARLOS/0000-0003-0454-9466; SALICHS, MIGUEL ANGEL/0000-0002-0263-6606;
   MALFAZ, MARIA/0000-0003-2317-3329
FU Spanish "Ministerio de Ciencia, Innovacion y Universidades, Spain";
   RoboCity2030-DIH-CM, Madrid Robotics Digital Innovation Hub - "Programas
   de Actividades I+D en la Comunidad de Madrid" [S2018/NMT-4331]; EU,
   Slovak Republic
FX The research leading to these results has received funding from the
   projects: "Robots Sociales para Estimulacion Fisica, Cognitiva y
   Afectiva de Mayores (ROSES)", funded by the Spanish "Ministerio de
   Ciencia, Innovacion y Universidades, Spain" and from
   RoboCity2030-DIH-CM, Madrid Robotics Digital Innovation Hub,
   S2018/NMT-4331, funded by "Programas de Actividades I+D en la Comunidad
   de Madrid" and cofunded by Structural Funds of the EU, Slovak Republic.
CR Albawi S., 2018, COMPUT INTEL NEUROSC, V2018, P1
   Alonso-Martín F, 2014, ACMIEEE INT CONF HUM, P114, DOI 10.1145/2559636.2563706
   Alonso-Martín F, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17051138
   Alonso-Martin F, 2013, LECT NOTES ARTIF INT, V8239, P64, DOI 10.1007/978-3-319-02675-6_7
   Alonso-Martín F, 2013, SENSORS-BASEL, V13, P15549, DOI 10.3390/s131115549
   Altun K, 2015, PATTERN RECOGN LETT, V66, P31, DOI 10.1016/j.patrec.2014.10.016
   [Anonymous], 2015, OPEN J INTERNET THIN
   Appice A, 2007, LECT NOTES ARTIF INT, V4701, P502
   Argall BD, 2010, ROBOT AUTON SYST, V58, P1159, DOI 10.1016/j.robot.2010.07.002
   Madeo RCB, 2016, EXPERT SYST APPL, V56, P100, DOI 10.1016/j.eswa.2016.02.021
   Bielza C, 2011, INT J APPROX REASON, V52, P705, DOI 10.1016/j.ijar.2011.01.007
   Brasileiro F, 2011, COMPUT COMMUN NETW S, P53, DOI 10.1007/978-0-85729-439-5_3
   BREIMAN L, 1992, J AM STAT ASSOC, V87, P738, DOI 10.2307/2290212
   Carlson A., 1968, MCGRAW HILL ELECT EL
   COCHRAN WT, 1967, PR INST ELECTR ELECT, V55, P1664, DOI 10.1109/PROC.1967.5957
   Cooney MD, 2012, IEEE INT C INT ROBOT, P1420, DOI 10.1109/IROS.2012.6385956
   Firouzi K, 2016, IEEE T ULTRASON FERR, V63, P2174, DOI 10.1109/TUFFC.2016.2608781
   Gallace A, 2010, NEUROSCI BIOBEHAV R, V34, P246, DOI 10.1016/j.neubiorev.2008.10.004
   Godbole S, 2004, LECT NOTES ARTIF INT, V3056, P22
   Gonzalez-Pacheco V, 2011, INT J SOC ROBOT, V3, P371, DOI 10.1007/s12369-011-0109-8
   Goris K, 2011, INT J HUM ROBOT, V8, P481, DOI 10.1142/S0219843611002563
   Hastie T., 2009, SPRINGER SERIES STAT, P764, DOI [10.1007/b94608., DOI 10.1007/B94608]
   Hertenstein MJ, 2006, GENET SOC GEN PSYCH, V132, P5, DOI 10.3200/MONO.132.1.5-94
   Hertenstein MJ, 2009, EMOTION, V9, P566, DOI 10.1037/a0016108
   Holmes G., 1994, Proceedings of the 1994 Second Australian and New Zealand Conference on Intelligent Information Systems (Cat. No.94TH8019), P357, DOI 10.1109/ANZIIS.1994.396988
   Hughes Dana, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2315, DOI 10.1109/ICRA.2017.7989267
   Jung MM, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P387, DOI 10.1145/2818346.2829993
   KAVITHA CR, 2016, IJRET INT J RES ENG, V5, P330, DOI DOI 10.15623/IJRET.2016.0509050
   Kim YM, 2010, IEEE T CONSUM ELECTR, V56, P1979, DOI 10.1109/TCE.2010.5606355
   Marques RZN, 2015, 2015 FOURTEENTH MEXICAN INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (MICAI), P152, DOI 10.1109/MICAI.2015.29
   Minato T, 2007, IEEE-RAS INT C HUMAN, P557, DOI 10.1109/ICHR.2007.4813926
   Morita T, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P3183, DOI 10.1109/ROBOT.1999.774083
   Müller S, 2018, LECT NOTES COMPUT SC, V10894, P476, DOI 10.1007/978-3-319-93399-3_41
   Murray-Smith R, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1299
   NICHOLLS HR, 1989, INT J ROBOT RES, V8, P3, DOI 10.1177/027836498900800301
   Nikolovski F.D., 1996, EP0784783, Patent No. EP0784783
   Nikolovski JP, 2013, IEEE T ULTRASON FERR, V60, P1178, DOI 10.1109/TUFFC.2013.2680
   Paradiso J. A., 2002, Proceedings of IEEE Sensors 2002. First IEEE International Conference on Sensors (Cat. No.02CH37394), P521, DOI 10.1109/ICSENS.2002.1037150
   Read J, 2016, J MACH LEARN RES, V17
   Robinson S, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2733
   Sabanovic Selma, 2013, IEEE Int Conf Rehabil Robot, V2013, P6650427, DOI 10.1109/ICORR.2013.6650427
   Salichs E., 2016, NEW FRIENDS 2016, P31, DOI DOI 10.3926/NEWFRIENDS2016
   Salichs MA, 2006, 2006 IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS, VOLS 1 AND 2, P862
   Schmid AJ, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P58
   Sharkey A., 2014, AISB 2014 50 ANN C A, P5
   Silvera-Tawil D, 2014, INT J SOC ROBOT, V6, P489, DOI 10.1007/s12369-013-0223-x
   Stiehl WD, 2005, 2005 IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN), P408
   Tang D, 2015, EXPERT SYST APPL, V42, P4540, DOI 10.1016/j.eswa.2015.01.016
   Tawil David Silvera, 2011, 2011 IEEE International Conference on Robotics and Automation, P3770
   THOMSON WT, 1950, J APPL PHYS, V21, P89, DOI 10.1063/1.1699629
   Tucker DG, 1966, APPL UNDERWATER ACOU
   Walker G, 2012, J SOC INF DISPLAY, V20, P413, DOI 10.1002/jsid.100
   Wang Y., 2019, EXPERT SYST APPL
   Wilhelm FH, 2001, BIOL PSYCHOL, V58, P181, DOI 10.1016/S0301-0511(01)00113-2
   Yohanan S, 2012, INT J SOC ROBOT, V4, P163, DOI 10.1007/s12369-011-0126-7
   Zhou N, 2016, COMM COM INF SC, V662, P164, DOI 10.1007/978-981-10-3002-4_14
NR 56
TC 12
Z9 15
U1 1
U2 14
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0952-1976
EI 1873-6769
J9 ENG APPL ARTIF INTEL
JI Eng. Appl. Artif. Intell.
PD JUN
PY 2020
VL 92
AR 103670
DI 10.1016/j.engappai.2020.103670
PG 16
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Engineering, Multidisciplinary; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Automation & Control Systems; Computer Science; Engineering
GA LT2XL
UT WOS:000536934900015
OA Green Accepted
DA 2024-01-09
ER

PT J
AU Tyaglova, SA
   Ermakova, VA
AF Tyaglova, Svetlana A.
   Ermakova, Viktoriya A.
TI AMATEUR CHORUS AS A FORM OF LEISURE ACTIVITY IN THE 21ST CENTURY
SO VESTNIK TOMSKOGO GOSUDARSTVENNOGO UNIVERSITETA-KULTUROLOGIYA I
   ISKUSSTVOVEDENIE-TOMSK STATE UNIVERSITY JOURNAL OF CULTURAL STUDIES AND
   ART HISTORY
LA English
DT Article
DE amateur chorus; specifics of choral performance; leisure activity of
   adults
AB The article deals with the development of amateur choral art as a form of leisure activities for adults at the present stage. Choral singing has not lost its relevance today due to the rich educational potential laid down throughout the development of Russian culture. Participation in collective performance contributes to the maintenance and development of vocal functions, socialization (non- verbal communication skills, teamwork, performance in public, communication of different generations, communication with like-minded people, continuity, etc.), mental health (development of the emotional sphere, self-realization, self-expression, meeting the need for communication, a sense of the importance of personal contribution to the success of a common cause, and others), cognitive interest in the field of art and related fields. Considering the formation of amateur choral singing in a historical retrospective, we note that it has always been an integral part of the education and upbringing of many generations.Modern society is not fully aware of the full range of choral performance opportunities in the process of solving social and educational issues. In our opinion, at the present stage, choral art should be implemented in a wider context of metasubjectness, revealing as many links with the natural and human sciences as possible. The issue of updating choral amateur performances as the most popular and accessible type of musical performance, which has a great educational potential and wide opportunities for the sociocultural development of a person, and the insufficient realization of this potential in the leisure activities of the modern generation is a problem of research. The authors studied the experience of the amateur choir collective "Flower Rhapsody" in the city of Irbit, Sverdlovsk Region, conducted a survey of the team members and an interview with the choir leader. Based on the material obtained, the motives for the participation of singers in choral amateur performances (self-actualization, communication with like-minded people, concert performances, health improvement, rest from work, positive emotions) are identified, the implementation of which contributes to the development of sociocultural competences (inclusion of a person in social, labor activities and social environment forms of interpersonal communication, the development of mental and aesthetic functions, and others.). Consequently, the actualization of amateur choral art is necessary, and will be successful, provided: - understanding of art as an integral part in the process of education, socio-cultural development of the individual, - realizing its health-saving potential, - consideration of amateur choral art as a phenomenon of interdisciplinary communications, - transformation of forms (in conjunction with traditional) classroom and out-of-class work of the choir, - create a special creative environment, - a combination of tradition and innovation, - reorientation of people's views on the opportunity to study at any age.
C1 [Tyaglova, Svetlana A.] Tyumen Ind Univ, Tyumen, Russia.
   [Ermakova, Viktoriya A.] Univ Tyumen, Tyumen, Russia.
C3 Tyumen Industrial University; Tyumen State University
RP Tyaglova, SA (corresponding author), Tyumen Ind Univ, Tyumen, Russia.
EM ST4182@mail.ru
CR Aleksandrova E.V., 2017, AKMEOLOGICHESKOE RAZ, V3, P15
   Baklanova T.I., 1979, THESIS MOSCOW
   Chabannyy V.F., 1990, THESIS LENINGRAD
   Kritskiy B.D., 2017, CHELOVEK OBRAZOVANIE, V1, P77
   Krupina O.A., 2010, CHELOVEK OBRAZOVANIE, V4
   Markov A.P., 1982, THESIS
   Pankova V.V., 2008, MESTO SAMODEYATELNOG
   Tarakanova E.V., 1998, PSIKHOLOGO PEDAGOGIC
NR 8
TC 0
Z9 0
U1 4
U2 4
PU TOMSK STATE UNIV
PI TOMSK
PA LENIN AVE, 36, TOMSK, 634050, RUSSIA
SN 2222-0836
EI 2311-3685
J9 VESTN TOMSK GOS U KU
JI Vestn. Tomsk. Gos. Univ.-Kulturologiya Iskusstvovedenie
PD MAR
PY 2023
VL 49
BP 241
EP 248
DI 10.17223/22220836/49/19
PG 8
WC Humanities, Multidisciplinary
WE Emerging Sources Citation Index (ESCI)
SC Arts & Humanities - Other Topics
GA J6TA8
UT WOS:001010911600019
DA 2024-01-09
ER

PT J
AU Mikhaylovsky, MN
   Lopatkova, IV
   Komarova, NM
   Rueva, EO
   Tereschuk, KS
   Emelyanenkova, AV
AF Mikhaylovsky, Mikhail N.
   Lopatkova, Irina, V
   Komarova, Nataliya M.
   Rueva, Evgeniya O.
   Tereschuk, Konstantin S.
   Emelyanenkova, Anna, V
TI Cyberbulling as a new form of a threat: a physiological, psychological
   and medicinal aspects
SO ELECTRONIC JOURNAL OF GENERAL MEDICINE
LA English
DT Article
DE deviant behavior; cyberbullying; diagnosis; mental and
   psycho-psychological health; social and biological factors; emotional
   disorders; prevention; correction
AB Objectives: Our goal is to study the effect of the phenomenon of cyberbullying on teenagers and teenagers at the physiological, psychological and medical level, as well as to determine the content of medical and psychological prevention of cyberbullying. The goal of the study determined our objectives: to determine the theoretical approaches to the substantiation of the phenomenon of "cyberbullying"; to identify methods and means of assistance to a teenager who has become a victim of cyberbullying at the physiological, psychological and medical level; to describe the activities of a specialist to provide assistance and follow-up for a teenager who has become a victim of cyberbullying.
   Materials: In solving these tasks, the following research methods were used: system analysis and synthesis of international and domestic literature on the research problem; systematization of facts; the analysis of regulations; psychophysiological diagnostics (t.pping-test, kopping-test, Dot cancellation test), psychological research methods (survey in the form of questioning, testing).
   Results: We can draw a conclusion about the causal interdependence of psychological, physiological and clinical and the consequences of cyberbullying for teenagers. Most teenagers who were victims of cyberbullying have a high and medium level of anxiety (which indicates their inherent increased anxiety, which may be accompanied by depression, isolation, unwillingness to maintain existing social contacts and make new ones); a decrease in activity and, as a result, a decrease in school performance; a high level of frustration (which is accompanied by such negative emotions as disappointment, irritation, a teenager has a general sense of wreck); high and medium level of constriction (teenagers with a high level of constriction have significant difficulties in the process of adaptation, which significantly affects the social side of their lives and significantly affects the resolution of emerging problems).
   Conclusions: When providing assistance to teenagers clinical psychologist need to rely on the following principles: systemic; subject-subjectivity, or communication; adaptation and endurance; safety and reliability. These principles will work successfully if the following individual and group methods of psychotherapy are used: creating a new cognitive model of life activity; affective reassessment of traumatic experience; restoration of a sense of self-esteem and the ability to exist in the world; colloquial psychotherapy (logotherapy, which involves the coincidence of verbal argumentation and the internal state of a teenager, leading to self-realization, when a teenager focuses on personal experiences, thoughts, feelings, desires); game therapy, art therapy, music therapy (through the perception of music), vocal therapy (through singing); kinesitherapy and psychodrama.
C1 [Mikhaylovsky, Mikhail N.] Sechenov First Moscow State Med Univ, Moscow, Russia.
   [Lopatkova, Irina, V] Moscow Pedag State Univ, Fed State Budgetary Educ Inst Higher Educ, Moscow, Russia.
   [Komarova, Nataliya M.] Moscow Reg State Univ, Moscow, Russia.
   [Rueva, Evgeniya O.] Plekhanov Russian Univ Econ, Moscow, Russia.
   [Tereschuk, Konstantin S.] Russian State Social Univ, Moscow, Russia.
   [Emelyanenkova, Anna, V] Ulyanovsk State Univ, Ulyanovsk, Russia.
C3 Sechenov First Moscow State Medical University; Moscow Region State
   University; Plekhanov Russian University of Economics; Russian State
   Social University (RSSU); Ulyanovsk State University
RP Emelyanenkova, AV (corresponding author), Ulyanovsk State Univ, Ulyanovsk, Russia.
EM ann_emel@mail.ru
RI Mikhaylovsky, Mikhail N./AAF-7872-2019
OI Mikhaylovsky, Mikhail N./0000-0002-3671-9071; RUEVA,
   Evgeniya/0000-0002-9134-4356; RUEVA, Evgeniya/0000-0003-4637-449X
CR Ackerman N., 2008, FAMILY PSYCHOTHERAPY
   [Anonymous], J SCH VIOLENCE, DOI DOI 10.1300/J202V01N02_04
   Babieva NS, 2019, EKOLOJI, V28, P629
   Badmaev SA, 1999, FUNDAMENTALS PREVENT
   Belichev SA., 2013, DIAGNOSIS CORRECTION
   Belsey B., CYBERBULLYING EMERGI
   Erofeeva M.A., 2019, EURASIA J BIOSCI, V13, pP135
   Eysenck G, 2012, MEASURE PERSONALITY
   Feldstein DI, 1998, PSYCHOL DEV PERSONAL
   GNEDOVA SB, 2015, ASIAN SOCIAL SCI, V11, P168, DOI DOI 10.5539/ASS.V11N3P168
   Goloshumova G.S., 2019, EKOLOJI, V28, P6013
   GRINENKO AV, 2019, EURASIAN J BIOSCIENC, V13, P1
   Kalenik EN, 2018, ELECTRON J GEN MED, V15, DOI 10.29333/ejgm/100635
   Kalinina N.V., 2016, IEJME MATH ED, V11, P2527
   Keith S., 2005, RECLAIMING CHILDREN, V13, P224, DOI DOI 10.1016/J.PAID.2006.03.008
   Klementovich I, 2008, MODERN FAMILY STRUCT
   Kovaleva NB, 2014, Psikhol Nauk Obrazov, V19, P64
   KOVALEVA NB, 2015, AZIMUTH SCI RES PEDA, V4, P120
   Kowalski R. M, 2011, CYBERBULLYING BULLYI
   Lekareva E.E., 2018, EURASIAN J ANALYTICA, V13, pM84, DOI [10.29333/ejac/102249, DOI 10.29333/EJAC/102249]
   Makarova EV, 2019, EUR J SCI THEOL, V15, P97
   Masalimova A.R., 2016, MATH ED, V11, P1796
   Masalimova A. R., 2019, EURASIA J MATH SCI T, V15, P1695, DOI 10.29333/ejmste/103565
   Mendelevich VD, 2008, PSYCHOL DEVIANT BEHA
   Mitin S. N., 2016, SIMBIRSK SCI B, V4, P31
   Moskvichev VV, 2003, SOCIAL WORK MINORS E
   Mukhametshin R. Z., 2019, IJEEP, V9, P224
   Naidyonova L., CYBER BULLYING DANGE
   OSCHEPKOV AA, 2016, SIMBIRSK SCI J VESTN, V2, P37
   Osipov IS., CYBERBULLYING ITS EF
   Parfentev U., 2009, CHILDREN INFORM SOC, P66
   Salakhova V. B., 2017, SIMBIRSK SCI J VESTN, V2, P46
   Salakhova V.B., 2016, INT J ENV SCI ED, V11, P9883
   Salakhova V.B., 2016, INT J ENV SCI ED, V11, P10609
   Salakhova V.B., 2016, INT J ENV SCI ED, V11, P9017
   Salakhova VB, 2018, ELECTRON J GEN MED, V15, DOI 10.29333/ejgm/100633
   Sokolovskaya IE, 2019, EKOLOJI, V28, P659
   Ybarra ML, 2004, CYBERPSYCHOL BEHAV, V7, P247, DOI 10.1089/109493104323024500
   Zotova OI, 2006, PROBLEMS DEVIANT BEH
NR 39
TC 4
Z9 5
U1 6
U2 31
PU MODESTUM LTD
PI LONDON
PA STE 124 CHALLENGE HOUSE 616 MITCHAM RD, CROYDON, LONDON, CRO 3AA,
   ENGLAND
SN 2516-3507
J9 ELECTRON J GEN MED
JI Electron. J. Gen. Med.
PY 2019
VL 16
IS 6
AR em161
DI 10.29333/ejgm/114268
PG 9
WC Medicine, General & Internal
WE Emerging Sources Citation Index (ESCI)
SC General & Internal Medicine
GA JV8DU
UT WOS:000502590900007
OA gold
DA 2024-01-09
ER

PT J
AU Mohammed, S
AF Mohammed, Sihan
TI Rhythm in the Qur'an and its Forms
SO SAKARYA UNIVERSITESI ILAHIYAT FAKULTESI DERGISI-JOURNAL OF SAKARYA
   UNIVERSITY FACULTY OF THEOLOGY
LA English
DT Article
DE Arabic Language and Rhetoric; Rhythm in the Qur'an; The Performances;
   Forms of Rhythm
AB The Qur'anic rhythmicity, represented in the intonations of the music emitted in folds of the Great Qur'an came as the basis for the passion for recitation and listening pleasure. Although there have been several studies on this subject, the focus of the research has been on rhythmic forms: What they are, their composition, and the effect of their representation in Qur'anic styles as a kind of renewed vision, understanding, and perception of Qur'anic discourse.The research, the-refore, followed the approach of characterizing these forms and analyzing them by devising the bonds that made the rhythm spread meaning differently. It began by referring to the role of music provided by the rhythms of the Qur'anic verses in paying attention to the vocal miracle, next presents the basic types of this rhythm and shows the foundations of this study that support the idea of its presence in the verses, to highlight its role in clarifying the meaning. This study focused on illustrating the forms of rhythm, ranging from the splendid through the rhythm of the suggestive rhythm, and ending with the syllabic rhythm, by describing each form and searching for it between letters, words, structures, and methods. Besides, it pays attention to rhythm's effects and indicates its reflection on meaning. The research has shown that the rhythm makes emotion peak, showing meaning embodied in terms. This embodiment represents the power of performance in demonstrating the exact purpose of speech choices within specific contexts and through various exquisite styles colored in psychological meanings.The importance and objectives of the research Rhythm are directly related to the different connotations it generates. Phonetic formations are activities and interactions between meanings. The sound structure, an essential element in the Holy Qur'an, is one of the elements that form the rhythm in the structure of the verses of the Qur'an. Its interaction with other elements cont-ributes to shaping the Qur'anic discourse with its creative vision and artistic and aesthetic dimen-sions while showing verbal consistency, collecting homogeneous words, and linking words. Com-mon and synonymous in one sentence is something that avoids the language, and we find it common in the language of the Qur'an to the maximum extent, to give it a harmonious rhythm distinct from the rhythm of poetry among the Arabs, and this is what attracted them to it and prompted them to pay attention to what it conveyed to them. The research aims to explain the importance of rhythm in the verses of the Holy Qur'an, in addition to highlighting the relationship between rhythm, meaning, and context in the texts of the Qur'an, and its role in making this rhythm an element of the Qur'anic miracle, as it has thus denoted a distinct Qur'anic rhythm that made it that strange phenomenon that characterizes the Qur'an in paving his letters and arranging his words in order without every arrangement and system used by people in their speech.Previous studies: The interest in the rhythm of the Qur'an as part of a whole appeared in their talk about the miraculousness of the Qur'an according to al-Rumani, al-Khattabi, al-Askari, al-Baqalani, al-Jurjani, al-Sakaki, and al-Zamakhshari, through his interest in the phonetic beauty of the Holy Qur'an in terms of application, while he was partly independent of the study according to contemporaries.
   Where Al-Rafi'i saw that this wonderful literary characteristic of the Qur'anic discourse lies in the elegant rhythm, and he worked on studying the commas and their effects, and Subhi Al-Saleh followed him in studying the internal music of the Qur'an, and After him, Naim Al-Yafi came to lay down nine rules for the formation of the melody in the music of the Qur'aan, as Bakri Sheikh focused Amin and other scholars on Qur'anic rhythm, among them Muhammad Abdullah Daraz, and Al-Mubarak. While the study of rhythm in poetry was independent by Kamal Abu Deeb in his book (On the Rhythmic Structure of Arabic Poetry), and Muhammad Al-Ayashi in his book (The Theory of Rhythm in Arabic Poetry).Research methodology and plan: In terms of the fact that the research aimed to shed light on the forms of Qur'anic rhythm, clarify the relationship between meaning and rhythm, and what rhythm offers to mean in terms of vision, understanding and realization of the Qur'anic discourse, and making it in papers accessible to anyone who wants, without delving or going too deep and going too far, The approach in this matter is not limitless. The research began with an introduction in which he explained the importance of the research and its objective in addition to the metho-dology it followed. Then the research was presented in two frameworks:A theoretical framework that spoke briefly about sounds and rhythm in Arabic, in two points.A practical framework in which the rhythmic forms were identified between the rhythmic rhythms of the Budaiya, the rhythmic suggestive, and the rhythmic syllables, and then the Qur'anic evidence was mentioned on these forms and their branches, with their analysis, and a reference to the conclusions that were reached, then the conclusion.
C1 [Mohammed, Sihan] Sakarya Univ, Fac Theol, Dept Arab Language & Rhetor, Sakarya, Turkiye.
C3 Sakarya University
RP Mohammed, S (corresponding author), Sakarya Univ, Fac Theol, Dept Arab Language & Rhetor, Sakarya, Turkiye.
EM smohammed@sakarya.edu.tr
CR Cinni Ibn, 1952, EBUL FETH OSMAN EL H, V2
   Diraz Muhammed Abdul azim, 1984, ENNEBEUL AZIM
   Ebu Dib Kemal., 1974, FIL BUNYETIL IKAIYYE, V1
   el-Antaki Muhammed, 1971, EL MUHIT FI ESVATIL, V4
   el-Askeri Ebu Hilal Hasan b. Abdullah b., 1952, KITABUS SINAATEYN KI, V1
   el-Baki Naim, 1984, MECELLETUT TURASIL A, P15
   el-Bakillani Muhammed b., 1954, EBU BEKR ICAZUL KURA
   el-Curcani Abdulkahir b. Abdurrahman b. Muhammed, 1983, DELAILUL ICAZ
   el-Hasnavi Muhammed, 2000, EL FASILA FIL KUR, V2
   el-Hitabi Ahmed b. Muhammed b. Ibrahim, 1976, BEYANU ICAZIL KUR, V3
   el-Mubarek Muhammed, 1960, FIKHUL LUGA HASAISUL, V1
   el-Mutfi Abdulazim., 1992, HASAISUT TABIRIL KUR, V1
   Enis Ibrahim, 1991, DELALETUL ELFAZ, V6
   Enis Ibrahim, 1981, MUSIKAS SIIR, V5
   er-Rumani Ali b., 1976, ISA B ALI B ABDULLAH, V3
   ez-Zemahseri Carullah Muhammed b., 1954, OMER EL HEVARIZMI EL
   ez-Zerkani Muhammed Abdulazim, 2001, MENALUL IRFAN FI ULU, V2
   Fadl Salah., 1992, BELAGATUL HITABILMUN
   Ibn Ebi'l-Isba' (el-Misri) Zekiyuddin Abdulazim b. Vahit, BEDIUL KUR
   Kutub Seyyit, 1993, ET TASVIRUL FENNI FI, V14
   Muhammed el-Hiyasi, 1986, NAZARIYYETU IKAIS SI
   Rafii Mustafa Sadik, 1945, ICAZUL KURAN VEL BEL
   Salih Subhi, 1983, MEBAHIS FIULUMIL KUR, V15
   Sekkaki Yusuf b. Ebi Bekr b. Muhammed b. Ali, MIFTAHUL ULUM
   Seyh Emin Bekri, 1980, ET TABIRUL FENNI FIL, V4
   Suyuti Celaluddin Abdurraman b., 1996, EBI BEKR B MUHAMMED, V3
   Temmam Hasan, 2000, EL BEYAN FI REVAIIL, V2
   Ullmann Stephen, 1972, DEVRUL KELIME FIL LU, V3
NR 28
TC 0
Z9 0
U1 0
U2 0
PU SAKARYA UNIV
PI SAKARYA
PA KEMALPASA MAHALLESI UNIV CADDESI ESENTEPE KAMPUSU, SAKARYA, SERDIVAN
   54050, TURKEY
SN 2146-9806
EI 1304-6535
J9 SAKARYA U ILAHIYAT F
JI Sakarya Univ. Ilah. Fak. Derg.
PD JUN
PY 2023
VL 25
IS 47
BP 35
EP 54
DI 10.17335/sa-kaifd.1246383
PG 20
WC Religion
WE Emerging Sources Citation Index (ESCI)
SC Religion
GA L1PJ2
UT WOS:001021043000002
DA 2024-01-09
ER

EF